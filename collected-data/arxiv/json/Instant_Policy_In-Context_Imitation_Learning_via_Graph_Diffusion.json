{
    "title": "INSTANT POLICY: IN-CONTEXT IMITATION",
    "abstract": "Followingtheimpressivecapabilitiesofin-contextlearningwithlargetransform- ers,In-ContextImitationLearning(ICIL)isapromisingopportunityforrobotics. We introduce Instant Policy, which learns new tasks instantly (without further training) from just one or two demonstrations, achieving ICIL through two key components. First, weintroduceinductivebiasesthroughagraphrepresentation andmodelICILasagraphgenerationproblemwithalearneddiffusionprocess, enabling structured reasoning over demonstrations, observations, and actions. Second, weshowthatsuchamodelcanbetrainedusingpseudo-demonstrations – arbitrary trajectories generated in simulation – as a virtually infinite pool of training data. Simulated and real experiments show that Instant Policy enables rapidlearningofvariouseverydayrobottasks. Wealsoshowhowitcanserveasa foundationforcross-embodimentandzero-shottransfertolanguage-definedtasks. Codeandvideosareavailableathttps://www.robot-learning.uk/instant-policy. Figure1: InstantPolicyacquiresskillsinstantlyafterprovidingdemosattesttime. Wemodelin- contextimitationlearningasagraph-baseddiffusionprocess,trainedusingpseudo-demonstrations. 1 INTRODUCTION RobotpoliciesacquiredthroughImitationLearning(IL)haverecentlyshownimpressivecapabili- ties,buttoday’sBehaviouralCloning(BC)methodsstillrequirehundredsorthousandsofdemon- strationspertask(Zhaoetal.). Meanwhile,languageandvisioncommunitieshaveshownthatwhen large transformers are trained on sufficiently large and diverse datasets, we see the emergence of In-Context Learning (ICL) (Brown, 2020). Here, trained models can use test-time examples of a noveltask(thecontext),andinstantlygeneralisetonewinstancesofthistaskwithoutupdatingthe model’sweights. ThisnowoffersapromisingopportunityofIn-ContextImitationLearning(ICIL) inrobotics. Tothisend,wepresentInstantPolicy,whichenablesnewtaskstobelearnedinstantly: after providing just one or two demonstrations, new configurations of that task can be performed immediately, without any further training. This is far more time-efficient and convenient than BC methods,whichrequirenumerousdemonstrationsandhoursofnetworktrainingforeachnewtask. ICLinlanguageandvisionbenefitsfromhugeandreadilyavailabledatasets,whichdonotexistfor robotics.Assuch,wearefacedwithtwoprimarychallenges.1)Giventhelimitedavailabledata,we needappropriateinductivebiasesinobservationandactionrepresentationsforefficientlearningin 1 4202 voN 91 ]OR.sc[ 1v33621.1142:viXra",
    "body": "INSTANT POLICY: IN-CONTEXT IMITATION\nLEARNING VIA GRAPH DIFFUSION\nVitalisVosyliusandEdwardJohns\nTheRobotLearningLabatImperialCollegeLondon\nvitalis.vosylius19@imperial.ac.uk\nABSTRACT\nFollowingtheimpressivecapabilitiesofin-contextlearningwithlargetransform-\ners,In-ContextImitationLearning(ICIL)isapromisingopportunityforrobotics.\nWe introduce Instant Policy, which learns new tasks instantly (without further\ntraining) from just one or two demonstrations, achieving ICIL through two key\ncomponents. First, weintroduceinductivebiasesthroughagraphrepresentation\nandmodelICILasagraphgenerationproblemwithalearneddiffusionprocess,\nenabling structured reasoning over demonstrations, observations, and actions.\nSecond, weshowthatsuchamodelcanbetrainedusingpseudo-demonstrations\n– arbitrary trajectories generated in simulation – as a virtually infinite pool of\ntraining data. Simulated and real experiments show that Instant Policy enables\nrapidlearningofvariouseverydayrobottasks. Wealsoshowhowitcanserveasa\nfoundationforcross-embodimentandzero-shottransfertolanguage-definedtasks.\nCodeandvideosareavailableathttps://www.robot-learning.uk/instant-policy.\nFigure1: InstantPolicyacquiresskillsinstantlyafterprovidingdemosattesttime. Wemodelin-\ncontextimitationlearningasagraph-baseddiffusionprocess,trainedusingpseudo-demonstrations.\n1 INTRODUCTION\nRobotpoliciesacquiredthroughImitationLearning(IL)haverecentlyshownimpressivecapabili-\nties,buttoday’sBehaviouralCloning(BC)methodsstillrequirehundredsorthousandsofdemon-\nstrationspertask(Zhaoetal.). Meanwhile,languageandvisioncommunitieshaveshownthatwhen\nlarge transformers are trained on sufficiently large and diverse datasets, we see the emergence of\nIn-Context Learning (ICL) (Brown, 2020). Here, trained models can use test-time examples of a\nnoveltask(thecontext),andinstantlygeneralisetonewinstancesofthistaskwithoutupdatingthe\nmodel’sweights. ThisnowoffersapromisingopportunityofIn-ContextImitationLearning(ICIL)\ninrobotics. Tothisend,wepresentInstantPolicy,whichenablesnewtaskstobelearnedinstantly:\nafter providing just one or two demonstrations, new configurations of that task can be performed\nimmediately, without any further training. This is far more time-efficient and convenient than BC\nmethods,whichrequirenumerousdemonstrationsandhoursofnetworktrainingforeachnewtask.\nICLinlanguageandvisionbenefitsfromhugeandreadilyavailabledatasets,whichdonotexistfor\nrobotics.Assuch,wearefacedwithtwoprimarychallenges.1)Giventhelimitedavailabledata,we\nneedappropriateinductivebiasesinobservationandactionrepresentationsforefficientlearningin\n1\n4202\nvoN\n91\n]OR.sc[\n1v33621.1142:viXra\n3Dspace;2)Giventheinefficiencyandcostofmanuallycollectingroboticsdata,weneedameans\ntoeasilycollecttrainingdatainascalableway. Inthiswork,weproposesolutionstoboththese.\nWe address the first challenge by introducing a novel graph-based representation that integrates\ndemonstrations, current point cloud observations, and the robot’s actions within a unified graph\nspace. WethencastICILasadiffusion-basedgraphgenerationproblem,enablingdemonstrations\nandobservationstobeinterpretedeffectivelyinordertopredicttherobot’sactions. Toaddressthe\nsecond challenge, we observe that in traditional BC, the model’s weights directly encode policies\nforaspecificsetoftasks,whereasinICIL,themodel’sweightsshouldencodeamoregeneral,task-\nagnosticabilitytointerpretandactuponthegivencontext. Duetothis,wefoundthatwewereable\ntotrainthemodelusingpseudo-demonstrations–setsofprocedurallygeneratedrobottrajectories,\nbutwhereeachsetofdemonstrationsforataskissemanticallyconsistent. Thisapproachallowsus\ntogeneratevirtuallyinfinitetrainingdatabyscalingupthesimulateddata.\nOurexperiments,withbothsimulatedandreal-worldtasks,showthatInstantPolicycanlearnvari-\nouseverydaytasks,whilstachievinghighertasksuccessratesthanstate-of-the-artbaselinestrained\non the same data. As an emergent ability, we also observed generalisation capabilities to object\ngeometriesunseenfromthetest-timedemonstrations. Importantly,wefoundthatperformanceim-\nprovesasmoredataisgeneratedandusedforsimultaneoustraining,offeringscalableopportunities\nwithabundantsimulateddata. Inourfurtherexperimentsondownstreamapplications,InstantPol-\nicyalsoachievescross-embodimenttransferfromhuman-handdemonstrationstorobotpolicies,and\nzero-shottransfertolanguage-definedtaskswithoutneedinglargelanguage-annotateddatasets.\nOur contributions are as follows: 1) We cast In-Context Imitation Learning as a diffusion-based\ngraphgenerationproblem;2)Weshowthatthismodelcanbetrainedusingprocedurallygenerated\npseudo-demonstrations; 3) We evaluate in simulation and the real world across various everyday\ntasks,showingstrongperformance,encouragingscalingtrends,andpromisingdownstreamuses.\n2 RELATED WORK\nIn-ContextLearning(ICL).ICLisanemergingparadigminmachinelearningwhichallowsmod-\nelstoadapttonewtasksusingasmallnumberofexamples,withoutrequiringexplicitweightupdates\norretraining. InitiallypopularisedinnaturallanguageprocessingwithmodelslikeGPT-3(Brown,\n2020), ICL has been applied to enable robots to rapidly adapt to new tasks by using foundation\nmodels (Di Palo & Johns, 2024), finding consistent object alignments (Vosylius & Johns, 2023a),\nidentifying invariant regions of the state space (Zhang & Boularias, 2024), and directly training\npoliciesaimedattaskgeneralisation(Duanetal.,2017;Fuetal.,2024)orcross-embodimenttrans-\nfer(Jangetal.,2022;Jainetal.,2024;Vogtetal.,2017). Despitetheseadvancements,challenges\nremaininachievinggeneralisationtotasksunseenduringtrainingandnovelobjectgeometries. In-\nstantPolicyaddressesthisbyleveragingsimulatedpseudo-demonstrationstogenerateabundantand\ndiversedata,whileitsstructuredgraphrepresentationensuresthatthisdataisutilisedefficiently.\nDiffusion Models. Diffusion models (Ho et al., 2020) have garnered significant attention across\nvariousdomains,duetotheirabilitytoiterativelyrefinerandomlysamplednoisethroughalearned\ndenoisingprocess,ultimatelygeneratinghigh-qualitysamplesfromtheunderlyingdistribution. Ini-\ntiallypopularisedforimagegeneration(Rameshetal.,2021),diffusionmodelshaverecentlybeen\nappliedtorobotics.Theyhavebeenutilisedforcreatingimageaugmentations(Yuetal.,2023;Man-\ndlekaretal.,2023)tohelprobotsadapttodiverseenvironments,generating‘imagined’goals(Kape-\nlyukhetal.,2023)orsubgoals(Blacketal.,2023)forguidingroboticpolicies,andlearningprecise\ncontrolpolicies(Chietal.,2023;Vosyliusetal.,2024). Incontrast,ourworkproposesanoveluse\nofdiffusionmodelsforgraphgeneration,enablingstructuredlearningofcomplexdistributions.\nGraph Neural Networks (GNNs). Graph Neural Networks (GNNs) allow learning on structured\ndata using message-passing or attention-based strategies. These capabilities have been applied\nacross a wide range of domains, including molecular chemistry Jha et al. (2022), social network\nanalysis(Huetal.,2021),andrecommendationsystems(Shietal.,2018). Inrobotics,GNNshave\nbeen employed for obtaining reinforcement learning (RL) policies (Wang et al., 2018; Sferrazza\netal.,2024),managingobjectrearrangementtasks(Kapelyukh&Johns,2022),andlearningaffor-\ndancemodelsforskilltransferVosylius&Johns(2023b).Inourwork,webuildonthesefoundations\nbystudyingstructuredgraphrepresentationsforICIL,enablinglearningoftherelationshipsbetween\ndemonstrations,observations,andactions.\n2\n3 INSTANT POLICY\n3.1 OVERVIEW&PROBLEMFORMULATION\nOverview.WeaddresstheproblemofIn-ContextImitationLearning,wherethegoalisfortherobot\ntocompleteanoveltaskimmediatelyaftertheprovideddemonstrations. Attesttime,oneorafew\ndemosofanoveltaskareprovidedtodefinethecontext,whichourtrainedInstantPolicynetwork\ninterprets together with the current point cloud observation, and infers robot actions suitable for\nclosed-loopreactivecontrol(seeFigure1). Thisenablesinstantaneouspolicyacquisition, without\nextensive real-world data collection or training. We achievethis througha structuredgraph repre-\nsentation(Section3.2),alearneddiffusionprocess(Section3.3),andanabundantsourceofdiverse\nsimulatedpseudo-demonstrations(Section3.4).\nProblem Formulation. We express robot actions a as end-effector displacements T ∈ SE(3)\nEA\n(which, when time-scaled, correspond to velocities), along with binary open-close commands for\nthe gripper, a ∈ {0,1}. Such actions move the robot’s gripper from frame E to a new frame\ng\nA and change its binary state accordingly. Our observations, o at timestep t, consist of seg-\nt\nmented point clouds Pt, the current end-effector pose in the world frame W, Tt ∈ SE(3),\nWE\nand a binary gripper state st ∈ {0,1}. Formally, our goal is to find a probability distribution,\ng\np(at:t+T | o ,{(o ,a )L }N ), from which robot actions can be sampled and executed. Here,\nt ij ij i=1 j=1\nT denotestheactionpredictionhorizon,whileLandN representthedemonstrationlengthandthe\nnumberofdemonstrations,respectively. Forconciseness,fromnowonwardswerefertothedemon-\nstrations, whichdefinethetaskattesttimeandarenotusedduringtraining, ascontextC, andthe\nactionpredictionsasa. Analyticallydefiningsuchadistributionisinfeasible,thereforeweaimto\nlearnitfromsimulatedpseudo-demonstrationsusinganovelgraph-baseddiffusionprocess.\n3.2 GRAPHREPRESENTATION\nTo learn the described conditional probability of actions, we first need to choose a suitable repre-\nsentation that would capture the key elements of the problem and introduce appropriate inductive\nbiases. We proposea heterogeneousgraph that jointlyexpresses context, currentobservation, and\nfutureactions,capturingcomplexrelationshipsbetweentherobotandtheenvironmentandensuring\nthat the relevant information is aggregated and propagated in a meaningful manner. This graph is\nconstructedusingsegmentedpointcloudobservations,asshowninFigure2.\nState Representation Joint Demo, Current State and Future Actions Representation\nContext Current State Action 1 Action T\nSequence of States\n1 2 L\nFigure2: (Left)Alocalgraph,G ,representingtherobot’sstate(bluenodes)andlocalgeometries\nl\noftheobjects(greennodes). (Right)Agraphrepresenting2demos(3waypointseach),thecurrent\nstate,and2futureactions. Edgecoloursrepresentdifferentedgetypesinaheterogeneousgraph.\nLocal Representation. The core building block of our representation is the observation at time\nstep t, which we express as a local graph Gt(Pt,Tt ,s ) (Figure 2, left). First, we sample M\nl WE g\npoints from a dense point cloud Pt using the Furthest Point Sampling Algorithm and encode lo-\ncal geometry around them with Set Abstraction (SA) layers (Qi et al., 2017), obtaining feature\nvectors F and positions p as {Fi,pi}M = ϕ(Pt). The separately pre-trained ϕ, an implicit oc-\ni=1\n3\n1\nomeD\nN\nomeD\ncupancynetwork(Meschederetal.,2019),ensuresthesefeaturesdescribelocalgeometries(details\nin Appendix A). We then represent the gripper’s state in the same format, {Fi,pi}6 , by rigidly\ng g i=1\ntransformingkeypointsp ontheend-effector,p =T ×p andassigningthemembeddings\nkp g WE kp\nthat encode node distinction and gripper state information Fi = [fi,ϕ (s )]T. Finally, we link\ng g g g\nscene and gripper nodes with directional edges and assign edge attributes e representing relative\npositions in Cartesian space. To increase the precision and capture high-frequency changes in the\npositions of the described nodes, we represent edges as e = (sin(20π(p −p )),cos(20π(p −\nij j i j\np )),...,sin(2D−1π(p −p )),cos(2D−1π(p −p ))),similartoZhouetal.(2023).\ni j i j i\nContext Representation. While Gt captures the environment state, a sequence of such graphs,\nl\ninterleavedwithactions,definesatrajectorywithincontextC (Figure2,middle). Weperformthis\ninterleaving by linking gripper nodes across time to represent their relative movement (red edges)\nandconnectingalldemonstrationgrippernodestothecurrentonestopropagaterelevantinformation\n(greyedges).Thisenablesthegraphtoefficientlyhandleanynumberofdemos,regardlessoflength,\nwhilst ensuring that the number of edges grows linearly. The result, G (Gt,{G1:L}N), enables a\nc l l 1\nstructuredflowofinformationbetweenthecontextandthecurrentobservation.\nAction Representation. To express future actions a = (T ,a ) within the graph repre-\nEA g\nsentation, we construct local graphs as if the actions were executed and the gripper moved:\nGa(Pt,Tt ×T ,a ). This allows ‘imagining’ spatial implications of actions. Thus, the ac-\nl WE EA g\ntions are fully described within the positions and the features of the nodes of these local graphs.\nTo represent actions as relative movements from the current gripper pose, we then add edges\nbetween current and future gripper nodes with position-based embeddings that represent relative\nmovement between subsequent timesteps. These edges propagate the information from the cur-\nrentobservation(andindirectlythecontext)tothenodesrepresentingtheactions. Thefinalgraph,\nG(Ga(a),G (Gt,{G1:L}N)), aggregates relevant information from the context and the current ob-\nl c l l 1\nservationandpropagatesittonodesrepresentingtheactions,enablingeffectivereasoningaboutthe\nrobotactionsbyensuringtheobservationsandactionsareexpressedinthesamegraphspace.\n3.3 LEARNINGROBOTACTIONVIAGRAPHDIFFUSION\nTo utilise our graph representation effectively, we frame ICIL as a graph generation problem and\nlearn a distribution over previously described graphs p (G) using a diffusion model, depicted in\nθ\nFigure3. ThisapproachinvolvesforwardandbackwardMarkov-chainprocesses,wherethegraph\nisalteredandreconstructedineachphase.Attesttime,themodeliterativelyupdatesonlythepartsof\nthegraphrepresentingrobotactions,implicitlymodellingthedesiredconditionalactionprobability.\nFigure 3: (Left) High-level structure of the network used to train graph-based diffusion model.\n(Right)Positionofgripperactionnodesduringthedenoisingprocessforoneofthepredictedactions.\nTraining. Trainingourdiffusionmodelincludes,firstly,theforwardprocess,wherenoiseisitera-\ntivelyaddedtothesamplesextractedfromtheunderlyingdatadistributionq(G). Inthisphase,we\nconstructanoise-alteredgraphbyaddingnoisetotherobotactionsaccordingtoHoetal.(2020):\n(cid:112)\nq(Gk |Gk−1)=G(Ga(N(ak; 1−β ak−1,β I),G )), k =1,...,K (1)\nl k k c\n4\nHere, N represents the normal distribution, β the variance schedule, and K the total number of\nk\ndiffusionsteps. Thisprocessgraduallytransitionsthegroundtruthgraphrepresentationintoagraph\nconstructedusingactionssampledfromaGaussiandistribution.\nInversely, in the reverse diffusion process, the aim is to reconstruct the original data sample, in\nour case the graph, from its noise-altered state, utilising a parameterised model p (Gk−1 | Gk).\nθ\nIntuitively,suchamodelneedstolearnhowthegrippernodesrepresentingtherobotactionsshould\nbeadjusted,suchthatthewholegraphmovesclosertothetruedatadistributionq(G). Formally,the\nparameterisedmodellearnsadenoisingprocessofactionsusingourgraphrepresentationG(a)as:\nGk−1 =G(Ga(α(ak−γε (Gk,k))+N(0,σ2I)),G ) (2)\nl θ c\nHere, ε (.) can be interpreted as effectively predicting the gradient field, based on which a single\nθ\nnoisy gradient descent step is taken (Chi et al., 2023). As we represent actions as collections of\nnodes with their associated positions p and features, that depend on the binary gripper actions a ,\ng\nsuch a gradient field has two components ε = [∇p,∇a ]T. As we will discuss later, ∇a can\nθ g g\nbeuseddirectlyinthediffusionprocess,whileasetof∇ppredictionsisanover-parameterisation\nof a gradient direction on the SE(3) manifold, and additional steps need to be used to compute a\nprecisedenoisingupdate. However,thiscanresultinalargetranslationdominatingasmallrotation,\nandviceversa, preventingpreciselylearningbothcomponentswell. Toaddressthis, werepresent\nthe denoising directions as a combination of centre-of-mass movement and rotation around it, ef-\nfectivelydecouplingthetranslationandrotationpredictionswhileremaininginCartesianspaceas\n[∇pˆ,∇pˆ ]T =[t0 −tk ,R0 ×p −Rk ×p ]T,with∇pˆ=∇pˆ +∇pˆ representingflow\nt r EA EA EA kp EA kp t r\n(redarrowsinFigure3,left). Here,t ∈ R3 andR ∈ SO(3)definetheSE(3)transformation\nEA EA\nrepresentingactionsT . Thuswelearnε bymakingper-nodepredictionsεk ∈ R7 andoptimis-\nEA θ\ningthevariationallowerboundofthedatalikelihoodwhichhasbeenshown(Hoetal.,2020)tobe\nequivalenttominimisingMSE(εk−ε (Gk)).Asourparameterisedmodel,weuseaheterogeneous\nθ\ngraphtransformer,whichupdatesfeaturesofeachnodeinthegraph,F ,as(Shietal.,2020):\ni\nF′ =W F + (cid:88) att (W F +W e ); att =softmax(cid:18) (W 3F i)T(W √4F j +W 5e ij)(cid:19)\ni 1 i i,j 2 j 5 ij i,j\nd\nj∈N(i)\n(3)\nHere,W representlearnableweights. Equippingourmodelwithsuchastructuredattentionmech-\ni\nanism allows for selective and informative information aggregation which is propagated through\nthe graph in a meaningful way, while ensuring that memory and computational complexity scales\nlinearlywithincreasingcontextlength(bothN andL). MoredetailscanbefoundinAppendixC.\nDeployment. Duringtesttime,wecreatethegraphrepresentationusingactionssampledfromthe\nnormaldistribution,togetherwiththecurrentobservationandthedemonstrationsasthecontext. We\nthenmakepredictionsdescribinghowgrippernodesshouldbeadjusted,andupdatethepositionsof\nthesenodesbytakingadenoisingstepaccordingtotheDDIM(Songetal.,2020):\n(cid:114)\npk−1 =√ α pˆ0+ 1−α k−1 (cid:0) pk−√ α pˆ0(cid:1) . (4)\ng k−1 g 1−α g k g\nk\nHere, pˆ0 = pk +∆p +∆p . This leaves us with two sets of points pk−1 and pk, that implicitly\ng g t r g g\nrepresent gripper poses at denoising time steps k−1 and k. As we know the ground truth corre-\nspondences between them, we can extract an SE(3) transformation that would align them using a\nSingularValueDecomposition(SVD)(Arunetal.,1987)as:\nT = argmin ||pk−1−T ×pk||2 (5)\nk−1,k k−1,k\nTk−1,k∈SE(3)\nFinally, the ak−1 is calculated by applying calculated transformation T to ak. Note that for\nk−1,k\ngripper opening and closing actions utilising Equation 4 directly is sufficient. This process is re-\npeated K times until the graph that is in distribution is generated and, as a byproduct, final a0\nactionsareextracted,allowingustosamplefromtheinitiallydescribeddistributionp(a|o ,C).\nt\n5\n3.4 ANINFINITEPOOLOFDATA\nNow that we can learn the conditional distribution of actions, we need to answer the question of\nwhereasufficientlylargeanddiversedatasetwillcomefrom,toensurethatthelearnedmodelcan\nbeusedforawiderangeofreal-worldtasks. WithIn-ContextLearning,themodeldoesnotneedto\nencodetask-specificpoliciesintoitsweights.Thusitispossibletosimulate‘arbitrarybutconsistent’\ntrajectoriesastrainingdata. Here,consistentmeansthatwhilethetrajectoriesdiffer,they‘perform’\nthesametypeofpseudo-taskatasemanticlevel. Wecallsuchtrajectoriespseudo-demonstrations.\nData Generation. Firstly, to ensure generalisation across object geometries, we populate a simu-\nlatedenvironmentusingadiverserangeofobjectsfromtheShapeNetdataset(Changetal.,2015).\nWethencreatepseudo-tasksbyrandomlysamplingobject-centricwaypointsnearorontheobjects,\nthat the robot needs to reach in sequence. Finally, by virtually moving the robot gripper between\nthemandoccasionallymimickingrigidgraspsbyattachingobjectstothegripper,wecreatepseudo-\ndemonstrations– trajectoriesthat resemblevarious manipulationtasks. Furthermore, randomising\ntheposesoftheobjectsandthegripper,allowsustocreatemanypseudo-demonstrationsperforming\nthesamepseudo-task,resultinginthedatathatweusetotrainourIn-Contextmodel.\nPseudo-Task 1 Pseudo-Task 2\nFigure4: Examplesofthesimulatedtrajectories-3pseudo-demonstrationsfor2pseudo-tasks.\nIn practice, to facilitate more efficient learning of common skills, we bias sampling towards way-\npointsresemblingtaskslikegraspingorpick-and-place. Notethatastheenvironmentdynamicsand\ntask specifications, such as feasible grasps, are defined as context at inference, we do not need to\nensurethatthesetrajectoriesaredynamicallyorevenkinematicallyfeasible. Intheory,withenough\nrandomisation,theconvexhullofthegeneratedtrajectorieswouldencapsulateallthepossibletest-\ntimetasks. MoreinformationaboutthedatagenerationprocesscanbefoundinAppendixD.\nDataUsage. Duringtraining,wesampleN pseudo-demonstrationsforagivenpseudo-task,using\nN−1todefinethecontextwhilethemodellearnstopredictactionsfortheNth. Althoughpseudo-\ndemonstrationsaretheprimarytrainingdata,ourapproachcanintegrateadditionaldatasourcesin\nthesameformat,allowingthemodeltoadapttospecificsettingsorhandlenoisierobservations.\n4 EXPERIMENTS\nWeconductedexperimentsintwodistinctsettings:1)simulationwithRLBench(Jamesetal.,2020)\nand ground truth segmentations, and 2) real-world everyday tasks. Our experiments study perfor-\nmancerelativetobaselines,tounderstandtheeffectofdifferentdesignchoices,torevealthescaling\ntrends,andtoshowcaseapplicabilityincross-embodimentandmodalitytransfer. Videosareavail-\nableonouranonymouswebpageathttps://www.robot-learning.uk/instant-policy.\nExperimentalSetup. Here,wedescribeparametersusedacrossallourexperimentsunlessexplic-\nitlystatedotherwise.WeuseasinglemodeltoperformvariousmanipulationtasksbyprovidingN=2\ndemos, which we express as L=10 waypoints as context and predict T=8 future actions. We train\nthis model for 2.5M optimisation steps using pseudo-demonstrations that are being continuously\ngenerated. Whenwediscussintegratingadditionaltrainingdatabeyondpseudo-demonstrations,we\nrefertomodelsfine-tunedforanadditional100Koptimisationstepsusinga50/50mixofpseudo-\ndemonstrationsandnewdata. Formoreinformation,pleaserefertoAppendixE.\nBaselines. WecompareInstantPolicyto3baselineswhichalsoenableIn-ContextImitationLearn-\ning,namely: BC-Z(Jangetal.,2022),Vid2Robot(Jainetal.,2024),andaGPT2-stylemodel(Rad-\nfordetal.,2019). BC-Zcombineslatentembeddingofthedemonstrationswiththecurrentobserva-\ntionandusesanMLP-basedmodeltopredictrobotactions,Vid2RobotutilisesaPerceiverResam-\npler (Jaegle et al., 2021) and cross-attention to integrate information from the context and current\nobservation,andGPT2usescausalself-attentiontopredictthenexttokensinthesequence,whichin\n6\nourcasearerobotactions. Forafaircomparison,weimplementedallbaselinesbyadaptingthemto\nworkwithpointcloudobservationusingthesamepre-trainedencoder,andallhaveroughlythesame\nnumberoftrainableparameters. Additionally,allcomponentsthatrelyonlanguage-annotateddata,\nsuch as auxiliary losses, were removed because our generated pseudo-demonstrations do not have\nsuchinformation. Tohighlightthis,weaddanasterisktothesemethodswhendiscussingresults.\n4.1 SIMULATEDEXPERIMENTS\nThe aim of our first set of experiments is two-fold: 1) to evaluate the effectiveness of Instant Pol-\nicyinperformingvariousmanipulationtasksbycomparingittostate-of-the-artbaselines,and2)to\ninvestigate the role the training data plays in generalising to unseen scenarios. We use a standard\nRLBenchsetupusingtheFrankaEmikaPandaandtestInstantPolicy(IP)andthebaselineson24\ntasks,100rolloutseach,randomisingtheposesoftheobjectsintheenvironmenteachtime. Addi-\ntionally,wetestmodelstrainedusingonlypseudo-demonstrations(PDonly)andacombinationof\npseudo-demonstrationsand20demonstrationsforeachof12outofthe24RLBenchtasks(PD++).\nResults&Discussion.Thefirstnotableobservationfromtheresults,presentedinTable1,isthatall\nmethodsachievenon-zerosuccessrateswhenonlypseudo-demonstrationsareusedandcanperform\nwell on at least the simpler tasks. This indicates that these pseudo-demonstrations are a powerful\nsourceoflimitlessdataforIn-ContextImitationLearning. Oursecondobservationisthatincorpo-\nratingadditionaldemonstrationsfromthesamedomaincangreatlyboosttheperformance,helping\nwith generalisation to unseen tasks and novel object poses. Our third observation is that Instant\nPolicyachievessignificantlyhighersuccessratesthanthebaselines,showingtheimportanceofour\ngraphrepresentationanditsabilitytointerpretthecontext. Wefurtherdemonstratethisbyvisual-\nisingattentionweights(Figure5),whichrevealthemodel’sabilitytounderstandthetask’scurrent\nstageandidentifytherelevantinformationinthecontext. WediscussfailurecasesinAppendixG.\nTasks InstantPolicy BC-Z* Vid2Robot* GPT2* Tasks InstantPolicy BC-Z* Vid2Robot* GPT2*\nOpenbox 0.94/0.99 0.22/0.98 0.30/0.97 0.25/0.95 Slidebuzzer 0.35/0.94 0.04/0.26 0.05/0.19 0.00/0.00\nClosejar 0.58/0.93 0.00/0.06 0.00/0.11 0.00/0.22 Plateout 0.81/0.97 0.26/0.55 0.11/0.52 0.31/0.40\nToiletseatdown 0.85/0.93 0.40/0.88 0.54/0.85 0.38/0.83 Closelaptop 0.91/0.95 0.64/0.65 0.45/0.57 0.53/0.72\nClosemicrowave 1.00/1.00 0.55/0.60 0.72/0.87 0.76/1.00 Closebox 0.77/0.99 0.81/1.00 0.89/0.88 0.42/0.41\nPhoneonbase 0.98/1.00 0.51/0.50 0.48/0.51 0.28/0.55 Openjar 0.52/0.78 0.12/0.28 0.15/0.30 0.22/0.51\nLiftlid 1.00/1.00 0.82/0.82 0.90/0.91 0.88/0.94 Toiletseatup 0.94/1.00 0.62/0.63 0.58/0.64 0.31/0.34\nTakeumbrellaout 0.88/0.91 0.42/0.64 0.90/0.90 0.75/0.89 Meatoffgrill 0.77/0.9 0.75/0.64 0.76/0.33 0.80/0.30\nSlideblock 0.75/1.00 0.10/0.14 0.12/0.16 0.08/0.16 Openmicrowave 0.23/0.56 0.00/0.13 0.00/0.02 0.00/0.00\nPushbutton 0.60/1.00 0.75/0.81 0.85/0.88 0.80/0.91 Paperrolloff 0.70/0.95 0.32/0.53 0.29/0.55 0.26/0.48\nBasketballinhoop 0.66/0.97 0.02/0.09 0.00/0.06 0.03/0.07 Putrubishinbin 0.97/0.99 0.11/0.11 0.12/0.14 0.18/0.17\nMeatongrill 0.78/1.00 0.64/0.88 0.51/0.77 0.53/0.81 Putumbrella 0.31/0.37 0.35/0.34 0.41/0.28 0.28/0.39\nFlipswitch 0.40/0.94 0.15/0.63 0.05/0.16 0.11/0.42 Lampon 0.42/0.41 0.00/0.00 0.00/0.00 0.00/0.00\nAverage(PD++)Seen 0.97 0.59 0.60 0.65 Average(PD++)Unseen 0.82 0.43 0.37 0.31\nAverage(PDonly)All 0.71 0.36 0.38 0.34\nTable 1: Success rates for Instant Policy and baselines on 24 tasks. 100 rollouts for each (trained\nusingonlypseudo-demonstrations/withadditionaldemosfromthe12RLBenchtasksontheleft).\nStart Grasping point Placing point Task Snapshots\n1.0 t=20\nDemonstration\nt=50\n0.0\nFigure5: Attentionweightsvisualisedonsub-graphedgesattwodifferenttimestepsinthephone-\non-basetask,showingthemodel’sabilitytotracktaskprogressandaggregaterelevantinformation.\n4.2 INSTANTPOLICYDESIGNCHOICES&SCALINGTRENDS\nOurnextsetofexperimentsinvestigatestheimpactofvarioushyperparametersontheperformance\nof our method, focusing on design choices requiring model re-training, inference parameters that\n7\nthgieW\nnoitnettA\naltermodelbehaviourattesttime,andscalingtrendsasmodelcapacityandtrainingtimeincrease.\nForthedesignchoicesandinferenceparameters,wecalculatetheaveragechangeinsuccessrateon\n24unseenRLBenchtasks, withrespecttothebasemodelusedintheprevioussetofexperiments,\nwhileforthescalingtrends,wereportvalidationlossonahold-outsetofpseudo-demonstrationsto\nseehowwellitcancapturetheunderlyingdatadistribution.\nDesignChoices InferenceParameters\nAction Diffusion Prediction #Diffusion Demo #Demos\n∆% ∆% ∆% ∆% ∆% ∆%\nMode Mode Horizon(T) Steps(K) Length(L) (N)\n∆p -15 Flow 0 1 -52 1 -16 1 -71 1 -12\n(∆pt,∆pr) 0 Sample -6 4 -13 2 -2 5 -26 2 0\n(∆t,∆q) -37 Noise -7 8 0 4 0 10 0 3 2\n(∆t,∆θ) -21 NoDiff -29 16 -4 8 0 15 1 4 -1\nTable2: Performancechangeofablationvariantswhencomparedtothebasemodel.\nDesignChoices. Wenowexaminethefollowing: actionmode,diffusionmode,andtheprediction\nhorizon. Foractionmodes,wecompareourproposedparameterisation,whichdecouplestranslation\nandrotation,againstanapproachwithoutsuchdecoupling,andmoreconventionalapproacheslike\ncombiningtranslationwithquaternionorangle-axisrepresentations. Fordiffusionmode,weevalu-\natepredictingflowversusaddednoise,directsample,andomittingdiffusion,regressingtheactions\ndirectly. Lastly,weassesstheimpactofpredictingdifferentnumbersofactions. Theresults,shown\ninTable2(left),showthatthesechoicesgreatlyinfluenceperformance. Decouplingtranslationand\nrotation in Cartesian space allows for precise low-level action learning. The diffusion process is\nvital for capturing complex action distributions, with predicting flow showing the best results. Fi-\nnally,predictingmultipleactionsishelpful,butthisalsoincreasescomputationalcomplexity. Fora\ndetaileddiscussionofotherdesignchoices,includingunsuccessfulones,pleaserefertoAppendixH.\nInferenceParameters. Usingadiffusionwithaflexiblerepresentationthathandlesarbitrarycon-\ntext lengths allows us to adjust model performance at inference. We investigate the impact of the\nnumberofdiffusionsteps,thedemonstrationlength,andthenumberofdemonstrationsinthecon-\ntext,asshowninTable2(right). Resultsshowthatevenwithjusttwodenoisingsteps,goodperfor-\nmancecanbeachieved. Demonstrationlengthiscritical;itmustbedenseenoughtoconveyhowthe\ntaskshouldbesolved,asthisinformationisnotencodedinthemodelweights. Thisisevidentwhen\nonlythefinalgoalisprovided(demonstrationlength=1),leadingtopoorperformance. However,\nextendingitbeyondacertainpointshowsminimalimprovement,astheRLBenchtaskscanoftenbe\ndescribedbyjustafewwaypoints. Formorecomplextasks,densedemonstrationswouldbecrucial.\nFinally,performanceimproveswithmultipledemonstrations,thoughusingmorethantwoseemsto\nbe unnecessary. This is because two demonstrations are sufficient to disambiguate the task when\ngeneralisingonlyoverobjectposes. However,aswewillshowinotherexperiments,thisdoesnot\nholdwhenthetestobjectsdifferingeometryfromthoseinthedemonstrations.\nScaling Trends. The ability to continuously\n0.04\ngeneratetrainingdatainsimulationallowsour 69M\nmodel’s performance to be limited only by 3×102 117M\n178M\navailablecompute(trainingtime)andmodelca-\npacity(numberoftrainableparameters). Toas- 0.02\nsess how these factors influence our approach,\nwe trained three model variants with different\nnumbers of parameters and evaluated them af-\n0.01\ntervaryingnumbersofoptimisationsteps(Fig-\nure 6). The results show that the model’s\nability to capture the data distribution (as re- 6×103\n0.005\nflected by decreasing validation loss) scales 100K 200K 400K 800K 1.6M 2.5M\nOptimisation Steps\nwell with both training time and model com-\nplexity. This offers some promise that scaling\nFigure6:Validationlosscurvesforthreedifferent\ncompute alone could enable the development\nmodelsizes.\nof high-performing models for robot manipu-\nlation. Qualitatively, we observed a similar performance trend on unseen RLBench tasks. With\nincreased training, we see an increase in performance. However, it plateaus eventually. Similarly,\nbyincreasingthemodel’scapacityfrom69Mto117M,thesuccessratereachedbeforeplateauing\n8\nssoL\nnoitadilaV\nincreases significantly. However, further increasing the number of trainable parameters to 178M\nresultsinonlyminor,insignificantimprovementsinperformance. Thissuggeststheneedformore\ndiverseandrepresentativedata. Suchdatacouldcomefromavailableroboticsdatasetsorthegener-\nationofpseudo-demonstrationsthatmorecloselyresemblerealtasks.\n4.3 REAL-WORLDEXPERIMENTS\nInreal-worldexperiments,weevaluateourmethod’sabilitytolearneverydaytasksandgeneralise\nto novel objects, unseen in both the training data and the context. We use a Sawyer robot with a\nRobotiq2F-85gripperandtwoexternalRealSenseD415depthcameras.Weobtainsegmentationby\nseedingtheXMem++(Bekuzarovetal.,2023)objecttrackerwithinitialresultsfromSAM(Kirillov\netal.,2023),andweprovidedemonstrationsusingkinestheticteaching. Tohelpthemodelhandle\nimperfectsegmentationsandnoisypointcloudsmoreeffectively,wefurtherco-fine-tunedthemodel\nusedinourpreviousexperimentsusing5demosfrom5tasksnotincludedintheevaluation.\nInsert Paper Roll Open Airfryer Flip Bottle Stack Bowls Knock over Creeper Kettle on Stove Close Coffee Machine Hang Cable\nOpen Box Turn Tap Right Turn Tap Left Take Rose Out Push Cans Together Pick up Kettle Close Box Open Cash Register\nFigure7: The16tasksusedinourreal-worldevaluation.\nReal-World Tasks. To evaluate our model’s ability to tackle various tasks in the real world, we\ntested it and the baselines on 16 everyday tasks (Figure 7). We evaluated all methods using 10\nrollouts, randomisingtheposesoftheobjectsintheenvironmenteachtime. Fromtheresults(Ta-\nble3),wecanseethatInstantPolicyisabletocompletevariouseverydaytasksfromjustacouple\nofdemonstrationswithahighsuccessrate,outperformingthebaselinesbyalargemargin.\nInsert Open Flip Stack Knockover Kettleon Close Hang\nPaperRoll Airfryer Bottle Bowls Creeper Stove CoffeeMachine Cable\nInstantPolicy 9/10 9/10 7/10 10/10 8/10 10/10 10/10 7/10\nBC-Z* 1/10 5/10 0/10 2/10 5/10 1/10 1/10 0/10\nVid2Robot* 3/10 6/10 0/10 1/10 7/10 3/10 4/10 1/10\nGPT2* 1/10 6/10 0/10 4/10 5/10 5/10 5/10 1/10\nOpen TurnTap TurnTap Take PushCans Pickup Close Open\nAverage,%\nBox Right Left RoseOut Together Kettle Box Register\nInstantPolicy 8/10 10/10 10/10 9/10 5/10 10/10 10/10 10/10 88.75\nBC-Z* 8/10 2/10 3/10 0/10 2/10 10/10 7/10 8/10 34.38\nVid2Robot* 9/10 4/10 3/10 0/10 1/10 10/10 7/10 6/10 40.63\nGPT2* 0/10 5/10 5/10 0/10 0/10 10/10 5/10 7/10 36.88\nTable3: Real-worldsuccessratesforInstantPolicyandthebaselines,with10rolloutseach.\nGeneralisationtoNovelObjects. Whileallof\nOpen Box Fold in Half\nour previous experiments focused on evaluat- Demo Test Demo Test\ningourmethod’sperformanceonthesameob- 4 4 3\njects used in the demonstrations, here we aim\n1 1\n3\nto test its ability to generalise to novel object 2\ngeometries at test time. We do so by provid- 2\ning demonstrations (i.e., defining the context) Place a mug on a plate Unplug Charger\nDemo Test Demo Test\nwithdifferentsetsofobjectsfromthesamese- 4 3\n3 4\nmantic category, and testing on a different ob-\nject from that same category. For the evalua- 1\n2 1 2\ntion,weusefourdifferenttasks(Figure8),each\nwith six sets of objects (four for the demon-\nFigure 8: Objects used in the generalisation ex-\nstrations/context and two for evaluation). We\nperiment(#indicatedemoorderinthecontext).\nevaluate our method with a different number\n9\nof demonstrations in the context, randomising the poses of the test objects during each roll-\nout (5 rollouts for each unseen object set). The results, presented in Table 4, show that, with\nan increasing number of demonstrations across different objects, the performance on completely\nnovel object geometries increases. This indicates that Instant Policy is capable of selectively ag-\ngregating and interpolating the information present in the context to disambiguate the task and\nthe parts of the objects that are relevant to it. It is important to note that this is an emer-\ngent behaviour, as we never trained our model with objects from different geometries across the\ncontext, and is enabled by the graph representation and structured cross-attention mechanism.\n4.3.1 DOWNSTREAMAPPLICATIONS\nCross-embodimenttransfer. Sinceourmodel\nOpen Fold Mug Unplug Average,\nuses segmented point clouds and defines the N\nBox inHalf onPlate Charger %\nrobot state by the end-effector pose and grip-\n1 2/10 7/10 7/10 0/10 40\nperstate,differentembodimentscanbeusedto 2 5/10 8/10 8/10 0/10 52.5\ndefine the context and roll out the policy, pro- 3 10/10 10/10 9/10 5/10 85\n4 10/10 10/10 9/10 7/10 90\nvidedthemappingbetweenthemisknown. We\ndemonstratethisbyusinghuman-handdemon-\nTable 4: Success rates of Instant Policy with a\nstrations with a handcrafted mapping to the\ndifferentnumberofdemonstrations(N),enabling\ngripperstate,allowingustotransferthepolicy\ngeneralisationtonovelobjectgeometries.\ndirectlytotherobot.Inqualitativeexperiments,\nweachievesimilarsuccessratesonsimpletasks,likepick-and-place,comparedtokinestheticteach-\ning. However, for more complex tasks, this approach is limited by the handcrafted mapping. See\nourwebpageforvideoexamplesandrefertoAppendixIformoreinformationaboutthismapping.\nModality change. While obtaining a policy immediately after demonstrations is a powerful and\nefficient tool, it still requires human effort in providing those demonstrations. We can circumvent\nthisbyexploitingthebottleneckofourtrainedmodel,whichholdstheinformationaboutthecontext\nandthecurrentobservationneededtopredictactions. Thisinformationisaggregatedinthegripper\nnodesofthecurrentobservations. Ifweapproximatethisbottleneckrepresentationusingdifferent\nmodalities, such as language, we can bypass using demonstrations as context altogether. This can\nbeachievedwithasmaller,language-annotateddatasetandacontrastiveobjective. Usinglanguage-\nannotatedtrajectoriesfromRLBenchandrolloutdatafrompreviousexperiments, wequalitatively\ndemonstratezero-shottaskcompletionbasedsolelyonlanguagecommands. Formoredetails,see\nAppendixJ,andforvideos,visitourwebpageathttps://www.robot-learning.uk/instant-policy.\n5 DISCUSSION\nLimitations.WhileInstantPolicydemonstratesstrongperformance,ithasseverallimitations.First,\nlike many similar approaches, we assume the availability of segmented point clouds for sufficient\nobservability. Second,pointcloudobservationslackcolourorothersemanticallyrichinformation.\nThird,ourmethodfocusesonrelativelyshort-horizontaskswheretheMarkovianassumptionholds.\nFourth,InstantPolicyissensitivetothequalityanddownsamplingofdemonstrationsatinference.\nFifth,itdoesnotaddresscollisionavoidanceorprovideend-to-endcontrolofthefullconfiguration\nspaceoftherobotarm. Finally,itlackstheprecisionneededfortaskswithextremelylowtolerances\norrichcontactdynamics.However,webelievemanyoftheselimitationscanbeaddressedprimarily\nthrough improvements in generation of the pseudo-demonstrations, such as accounting for colli-\nsions,incorporatinglong-horizontasks,andbyimprovingthegraphrepresentationwithadditional\nfeaturesfromvisionmodels,forceinformation,orpastobservations.\nConclusions.Inthiswork,weintroducedInstantPolicy,anovelframeworkforIn-ContextImitation\nLearningthatenablesimmediateroboticskillacquisitionfollowingoneortwotest-timedemonstra-\ntions.Thisisacompellingalternativeparadigmtotoday’swidespreadbehaviouralcloningmethods,\nwhichrequirehundredsorthousandsofdemonstrations. Weshowedthatournovelgraphstructure\nenables data from demonstrations, current observations, and future actions, to be propagated ef-\nfectively via a novel graph diffusion process. Importantly, Instant Policy can be trained with only\npseudo-demonstrations generated in simulation, providing a virtually unlimited data source that is\nconstrained only by available computational resources. Experiments showed strong performance\nrelative to baselines, the ability to learn everyday real-world manipulation tasks, generalisation to\nnovelobjectgeometries,andencouragingpotentialforfurtherdownstreamapplications.\n10\nREFERENCES\nK Somani Arun, Thomas S Huang, and Steven D Blostein. Least-squares fitting of two 3-d point\nsets. IEEETransactionsonpatternanalysisandmachineintelligence,(5):698–700,1987.\nJimmyLeiBa. Layernormalization. arXivpreprintarXiv:1607.06450,2016.\nMaksymBekuzarov,ArianaBermudez,Joon-YoungLee,andHaoLi. Xmem++: Production-level\nvideosegmentationfromfewannotatedframes. In ProceedingsoftheIEEE/CVFInternational\nConferenceonComputerVision,pp.635–644,2023.\nKevinBlack,MitsuhikoNakamoto,PranavAtreya,HomerWalke,ChelseaFinn,AviralKumar,and\nSergeyLevine. Zero-shotroboticmanipulationwithpretrainedimage-editingdiffusionmodels.\narXivpreprintarXiv:2310.10639,2023.\nTomBBrown. Languagemodelsarefew-shotlearners. arXivpreprintarXiv:2005.14165,2020.\nAngel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li,\nSilvioSavarese,ManolisSavva,ShuranSong,HaoSu,etal. Shapenet: Aninformation-rich3d\nmodelrepository. arXivpreprintarXiv:1512.03012,2015.\nCheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shu-\nran Song. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint\narXiv:2303.04137,2023.\nNormanDiPaloandEdwardJohns. Keypointactiontokensenablein-contextimitationlearningin\nrobotics. arXivpreprintarXiv:2403.19578,2024.\nYan Duan, Marcin Andrychowicz, Bradly Stadie, OpenAI Jonathan Ho, Jonas Schneider, Ilya\nSutskever, Pieter Abbeel, and Wojciech Zaremba. One-shot imitation learning. Advances in\nneuralinformationprocessingsystems,30,2017.\nLetian Fu, Huang Huang, Gaurav Datta, Lawrence Yunliang Chen, William Chung-Ho Panitch,\nFangchenLiu,HuiLi,andKenGoldberg.In-contextimitationlearningvianext-tokenprediction.\narXivpreprintarXiv:2408.15980,2024.\nDan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus). arXiv preprint\narXiv:1606.08415,2016.\nJonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advancesin\nneuralinformationprocessingsystems,33:6840–6851,2020.\nWeihuaHu,MatthiasFey,HongyuRen,MahoNakata,YuxiaoDong,andJureLeskovec. Ogb-lsc:\nAlarge-scalechallengeformachinelearningongraphs. arXivpreprintarXiv:2103.09430,2021.\nAndrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David\nDing, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, et al. Perceiver io: A\ngeneralarchitectureforstructuredinputs&outputs. arXivpreprintarXiv:2107.14795,2021.\nVidhi Jain, Maria Attarian, Nikhil J Joshi, Ayzaan Wahid, Danny Driess, Quan Vuong, Pannag R\nSanketi, Pierre Sermanet, Stefan Welker, Christine Chan, et al. Vid2robot: End-to-end video-\nconditionedpolicylearningwithcross-attentiontransformers. arXivpreprintarXiv:2403.12943,\n2024.\nStephen James, Zicong Ma, David Rovick Arrojo, and Andrew J Davison. Rlbench: The robot\nlearningbenchmark&learningenvironment. IEEERoboticsandAutomationLetters,5(2):3019–\n3026,2020.\nEricJang,AlexIrpan,MohiKhansari,DanielKappler,FrederikEbert,CoreyLynch,SergeyLevine,\nandChelseaFinn. Bc-z: Zero-shottaskgeneralizationwithroboticimitationlearning. InConfer-\nenceonRobotLearning,pp.991–1002.PMLR,2022.\nKanchan Jha, Sriparna Saha, and Hiteshi Singh. Prediction of protein–protein interaction using\ngraphneuralnetworks. ScientificReports,12(1):8360,2022.\n11\nIvanKapelyukhandEdwardJohns. Myhouse,myrules: Learningtidyingpreferenceswithgraph\nneuralnetworks. InConferenceonrobotlearning,pp.740–749.PMLR,2022.\nIvanKapelyukh, VitalisVosylius, andEdwardJohns. Dall-e-bot: Introducingweb-scalediffusion\nmodelstorobotics. IEEERoboticsandAutomationLetters,8(7):3956–3963,2023.\nAlexanderKirillov, EricMintun, NikhilaRavi, HanziMao, ChloeRolland, LauraGustafson, Tete\nXiao,SpencerWhitehead,AlexanderCBerg,Wan-YenLo,etal. Segmentanything. InProceed-\ningsoftheIEEE/CVFInternationalConferenceonComputerVision,pp.4015–4026,2023.\nJames J Kuffner and Steven M LaValle. Rrt-connect: An efficient approach to single-query path\nplanning. In Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference\nonRoboticsandAutomation.SymposiaProceedings(Cat.No.00CH37065),volume2,pp.995–\n1001.IEEE,2000.\nILoshchilov. Decoupledweightdecayregularization. arXivpreprintarXiv:1711.05101,2017.\nCamilloLugaresi, JiuqiangTang, HadonNash, ChrisMcClanahan, EshaUboweja, MichaelHays,\nFanZhang,Chuo-LingChang,MingGuangYong,JuhyunLee,etal. Mediapipe: Aframework\nforbuildingperceptionpipelines. arXivpreprintarXiv:1906.08172,2019.\nAjay Mandlekar, Soroush Nasiriany, Bowen Wen, Iretiayo Akinola, Yashraj Narang, Linxi Fan,\nYukeZhu,andDieterFox. Mimicgen:Adatagenerationsystemforscalablerobotlearningusing\nhumandemonstrations. arXivpreprintarXiv:2310.17596,2023.\nMatthewMatl. Pyrender. https://github.com/mmatl/pyrender,2019.\nLarsMescheder,MichaelOechsle,MichaelNiemeyer,SebastianNowozin,andAndreasGeiger.Oc-\ncupancynetworks:Learning3dreconstructioninfunctionspace.InProceedingsoftheIEEE/CVF\nconferenceoncomputervisionandpatternrecognition,pp.4460–4470,2019.\nBenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRamamoorthi,and\nRenNg. Nerf:Representingscenesasneuralradiancefieldsforviewsynthesis. Communications\noftheACM,65(1):99–106,2021.\nGeorgios Papagiannis, Norman Di Palo, Pietro Vitiello, and Edward Johns. R+ x: Retrieval and\nexecutionfromeverydayhumanvideos. arXivpreprintarXiv:2407.12957,2024.\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,\nTrevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas\nKopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,\nBenoitSteiner,LuFang,JunjieBai,andSoumithChintala. Pytorch: Animperativestyle,high-\nperformancedeeplearninglibrary.InAdvancesinNeuralInformationProcessingSystems32,pp.\n8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/\n9015-pytorch-an-imperative-style-high-performance-deep-learning-library.\npdf.\nCharlesRuizhongtaiQi,LiYi,HaoSu,andLeonidasJGuibas. Pointnet++: Deephierarchicalfea-\nturelearningonpointsetsinametricspace. Advancesinneuralinformationprocessingsystems,\n30,2017.\nAlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,IlyaSutskever,etal.Language\nmodelsareunsupervisedmultitasklearners. OpenAIblog,1(8):9,2019.\nAdityaRamesh,MikhailPavlov,GabrielGoh,ScottGray,ChelseaVoss,AlecRadford,MarkChen,\nandIlyaSutskever. Zero-shottext-to-imagegeneration. InInternationalconferenceonmachine\nlearning,pp.8821–8831.Pmlr,2021.\nN Reimers. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint\narXiv:1908.10084,2019.\nCarmeloSferrazza,Dun-MingHuang,FangchenLiu,JongminLee,andPieterAbbeel. Bodytrans-\nformer: Leveraging robot embodiment for policy learning. arXiv preprint arXiv:2408.06316,\n2024.\n12\nChuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. Heterogeneous information network\nembeddingforrecommendation. IEEEtransactionsonknowledgeanddataengineering,31(2):\n357–370,2018.\nYunshengShi,ZhengjieHuang,ShikunFeng,HuiZhong,WenjinWang,andYuSun. Maskedlabel\nprediction: Unified message passing model for semi-supervised classification. arXiv preprint\narXiv:2009.03509,2020.\nMohit Shridhar, Lucas Manuelli, and Dieter Fox. Perceiver-actor: A multi-task transformer for\nroboticmanipulation. InConferenceonRobotLearning,pp.785–799.PMLR,2023.\nJiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv\npreprintarXiv:2010.02502,2020.\nJulen Urain, Niklas Funk, Jan Peters, and Georgia Chalvatzaki. Se (3)-diffusionfields: Learning\nsmoothcostfunctionsforjointgraspandmotionoptimizationthroughdiffusion. In2023IEEE\nInternationalConferenceonRoboticsandAutomation(ICRA),pp.5923–5930.IEEE,2023.\nDavid Vogt, Simon Stepputtis, Steve Grehl, Bernhard Jung, and Heni Ben Amor. A system for\nlearningcontinuoushuman-robotinteractionsfromhuman-humandemonstrations. In2017IEEE\nInternationalConferenceonRoboticsandAutomation(ICRA),pp.2882–2889.IEEE,2017.\nVitalisVosyliusandEdwardJohns. Few-shotin-contextimitationlearningviaimplicitgraphalign-\nment. arXivpreprintarXiv:2310.12238,2023a.\nVitalisVosyliusandEdwardJohns. Wheretostart? transferringsimpleskillstocomplexenviron-\nments. InConferenceonRobotLearning,pp.471–481.PMLR,2023b.\nVitalisVosylius,YounggyoSeo,JafarUruc¸,andStephenJames.Renderanddiffuse:Aligningimage\nandactionspacesfordiffusion-basedbehaviourcloning. arXivpreprintarXiv:2405.18196,2024.\nTingwuWang,RenjieLiao,JimmyBa,andSanjaFidler. Nervenet: Learningstructuredpolicywith\ngraphneuralnetworks. InInternationalconferenceonlearningrepresentations,2018.\nTianheYu,TedXiao,AustinStone,JonathanTompson,AnthonyBrohan,SuWang,JaspiarSingh,\nClaytonTan,JodilynPeralta,BrianIchter,etal. Scalingrobotlearningwithsemanticallyimag-\ninedexperience. arXivpreprintarXiv:2302.11550,2023.\nXinyu Zhang and Abdeslam Boularias. One-shot imitation learning with invariance matching for\nroboticmanipulation. arXivpreprintarXiv:2405.13178,2024.\nTonyZZhao,JonathanTompson,DannyDriess,PeteFlorence,SeyedKamyarSeyedGhasemipour,\nChelseaFinn, andAyzaanWahid. Alohaunleashed: Asimplerecipeforrobotdexterity. In8th\nAnnualConferenceonRobotLearning.\nAllan Zhou, Moo Jin Kim, Lirui Wang, Pete Florence, and Chelsea Finn. Nerf in the palm of\nyourhand: Correctiveaugmentationforroboticsvianovel-viewsynthesis. InProceedingsofthe\nIEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.17907–17917,2023.\n13\nAPPENDIX\nA GEOMETRY ENCODER\nHere, we describe the local geometry encoder used to represent observations of the environment\nas a set of nodes. Formally, the local encoder encodes the dense point cloud into a set of feature\nvectors together with their associated positions as: {Fi,pi}M = ϕ(P). Here, each feature Fi\ni=1\ndescribes the local geometry around the point pi. We ensure this by pre-training an occupancy\nnetwork(Meschederetal.,2019),thatconsistsofanencoderϕ ,whichembedslocalpointclouds,\ne\nand a decoder ψ which given this embedding and a query point is tasked to determine whether\ne\nthequerylaysonthesurfaceoftheobject: ψ (ϕ (P),q) → [0,1]. Thehigh-levelstructureofour\ne e\noccupancynetworkcanbeseeninFigure9. Notethateachlocalembeddingisusedtoreconstruct\nonlyapartoftheobject,reducingthecomplexityoftheproblemandallowingittogeneralisemore\neasily.\nFigure9: High-levelstructureoftheoccupancynetwork.\nWeparameteriseϕ asanetworkcomposedof2SetAbstractionlayers(Qietal.,2017)enhanced\ne\nwithNerf-likesine/cosineembeddings(Mildenhalletal.,2021). ItsamplesM centroidsfromthe\ndense point cloud and embeds the local geometries around them into feature vectors of size 512.\nInstead of expressing positions of points relative to the sampled centroids pi as p − pi ∈ R3,\nj\nwe express them as (sin(20π(p −p )),cos(20π(p −p )),...,sin(29π(p −p )),cos(29π(p −\nj i j i j i j\np ))),enablingthemodeltocapturehigh-frequencychangesinthepositionofthedensepointsand\ni\ncapturethelocalgeometrymoreprecisely. Weparametriseψ asaneight-layerMLPwithresidual\ne\nconnections, thatusesthesameNerf-likeembeddingstorepresentthepositionofthequerypoint.\nWe use objects from a diverse ShapeNet (Chang et al., 2015) dataset to generate the training data\nneededtotraintheoccupancynetwork. FortrainingInstantPolicy,wedonotusethedecoderand\nkeeptheencoderfrozen.\nB TRAINING\nTraining our diffusion model involves a forward and backward Markov chain diffusion process,\nwhichisoutlinedinEquations1and2. Intuitively, weaddnoisetothegroundtruthrobotactions\nandlearnhowtoremovethisnoiseinthegraphspace(seeFigure10).\nInpractice,trainingincludes4mainsteps:1)noiseisaddedtothegroundtruthactions,2)noisyac-\ntionsareusedtoconstructourgraphrepresentation,3)thenetworkpredictshownodesrepresenting\nrobot actions need to be adjusted to effectively remove the added noise, and 4) the prediction and\ngroundtruthlabelsareusedtocalculatethelossfunction, andweightsofthenetworkareupdated\naccordingly.\nTo add noise to the action expressed as (T ∈ SE(3),a ∈ R, we first project T to se(3)\nEA g EA\nusing a Logmap, normalise the resulting vectors, add the noise as described by Ho et al. (2020),\nunnormalisetheresultandextractthenoisyend-effectortransformationTk usingExpmap. Such\nEA\naprocesscanbeunderstoodasaddingnoisetoaSE(3)transformationinitstangentialspace. We\n14\nEncoder PointNet\nycnapuccO redoceD\nteN\nFigure 10: High-level overview of the training process. (Left) A data point is sampled from the\ndataset. (Middle)Noiseisaddedtothegroundtruthactions. (Right)Usingdemonstrations,current\nobservationandnoisyactions,agraphrepresentationisconstructed,whichisusedtopredict,how\ntoremovetheaddednoiseinthegraphspace.\ncan do this because around actions (end-effector displacements) are sufficiently small. For bigger\ndisplacements, unnormalised noise should be projected onto the SE(3) manifold directly, as done\nby Vosylius & Johns (2023a) and Urain et al. (2023). Adding noise to real-valued gripper actions\ncanbedonedirectlyusingtheprocessdescribedbyHoetal.(2020).\nC NETWORK ARCHITECTURE\nHere we describe the neural network used to learn the denoising process on graphs, enabling us\nto generate graphs G and implicitly model the conditional action probability. Our parametrised\nneural network takes the constructed graph representation as input and predicts the gradient field\nfor each gripper node representing the actions: ε (Gk). These predictions are then used in the\nθ\ndiffusion process allowing to iteratively update the graph and ultimately extract desired low-level\nrobotactions.Inpractice,forcomputationalefficiencyandmorecontrolledinformationpropagation,\nweareusingthreeseparatenetworksσ, ϕandψ, updatingrelevantpartsofthegraphinsequence\nas:\nε (Gk)=ψ(G(σ(Ga),ϕ(G (σ(Gt),{σ(G1:L)}N))) (6)\nθ l c l l 1\nHere,σoperatesonlocalsubgraphsG andpropagatesinitialinformationaboutthepointcloudob-\nl\nservationtothegrippernodes,φadditionallypropagatesinformationthroughthedemonstratedtra-\njectoriesandallowsalltherelevantinformationfromthecontexttobegatheredatthegrippernodes\nofthecurrentsubgraph.Finally,ψpropagatesinformationtonodesinthegraphrepresentingtheac-\ntions.Usingsuchastructuredandcontrolledpropagationofinformationthroughthegraph,together\nwiththelearnableattentionmechanismdescribedinEquation3, allowsthemodeltocontinuously\naggregate relevant information from the context and make accurate predictions about the actions.\nAdditionally,italsoresultsinaclearandmeaningfulbottleneckinthenetworkwithalltherelevant\ninformation from the context aggregated in a specific set of nodes (ϕ(G (σ(Gt),{σ(G1:L)}N))).\nc l l 1\nThisbottleneckrepresentationcouldbeusedforretrievalorasshowninourexperiments,toswitch\nmodalities,forexampletolanguage,viaasmallerannotateddatasetandacontrastiveobjective.\nEachofthethreeseparatenetworksisaheterogeneousgraphtransformer(Equation3)with2lay-\ners and a hidden dimension of size 1024 (16 heads, each with 64 dimensions). As we are using\nheterogeneousgraphs,eachnodeandedgetypeareprocessedwithseparatelearnableweightsand\naggregatedviasummationtoproduceallnode-wiseembeddings. Thiscanbeunderstoodasasetof\ncross-attentionmechanisms,eachresponsibleforprocessingdifferentpartsofthegraphrepresenta-\ntion. Weuselayernormalisationlayers(Ba,2016)betweeneveryattentionlayerandaddadditional\n15\nresidualconnectionstoensuregoodpropagationofgradientsthroughoutthenetwork. Finally,fea-\nturesofthenodesrepresentingrobotactionsareprocessedwitha2-layerMLPequippedwithGeLU\nactivations(Hendrycks&Gimpel,2016)toproducetheper-nodedenoisingdirections.\nD DATA GENERATION\nOurdatagenerationprocess, firstly,includespopulatingascenewithobjectswithwhichtherobot\nwillinteract. WedosobysamplingtwoobjectsfromtheShapeNetdatasetandplacingthemran-\ndomlyonaplane. Next,wedefineapseudo-taskbysamplingasequenceofwaypointsonornear\nthose objects. The number of these waypoints is also randomly selected to be between 2 and 6,\ninherently modelling various manipulation tasks. We assign one or more waypoints to change the\ngripperstate,mimickingtherigidroboticgraspandrelease. Wethensampleastartingposeforthe\ngripper, where we initialise a mesh of a Robotiq 2F-85 gripper. By moving the gripper between\nthe aforementioned waypoints and attaching or detaching the closest object to it when the gripper\nstatechanges,wecreateapseudo-demonstration. Tofurtherincreasethediversityinpseudo-tasks,\nwe use different interpolation strategies between the waypoints (e.g. linear, cubic or interpolating\nwhilestayingonasphericalmanifold). Werecordgripperposesandsegmentedpointcloudobser-\nvationsusingPyRender(Matl,2019)andthreesimulateddepthcameras.Weensurethatthespacing\nbetween the subsequent spaces is constant and uniform (1cm and 3 degrees, same as used for the\nnormalisation of actions). Moving objects to different poses, choosing a different starting gripper\nposeandrepeatingtheprocessresultsinseveralpseudo-demonstrationsforthesamepseudo-task,\nwhichweusetotrainourIn-Contextmodel. AsmentionedinSection3.4,wedonotneedtoensure\nthatthesegeneratedtrajectoriesaredynamicallyorevenkinematicallyfeasible,astheenvironment\ndynamicsandtaskspecifications,suchasfeasiblegrasp,aredefinedascontextatinference.\nBias Sampling. To facilitate more efficient learning of common skills, we bias the sampling to\nfavour waypoints resembling common tasks such as grasping or pick-and-place. This does not\nrequirecreatingdynamicallyfeasibletrajectoriesbutratherinvolvesdesigningsamplingstrategies\nforwaypointsthatlooselyapproximatethesetasks. Forinstance,byselectingaspecificpartofan\nobject, moving the simulated gripper to that location, and closing the gripper, we can simulate a\ngraspingtask,evenifthegraspitselfisnotphysicallyfeasible. Wedesignsuchsamplingstrategies\nfor common tasks, such as grasping, pick-and-place, opening or closing. Pseudo-demonstrations\nare generated using these strategies for half of the samples, while the rest use completely random\nwaypoints.\nData Augmentation. To facilitate the emergence of recovery behaviour of the learnt policies, we\nfurtheraugmentthegeneratedtrajectories. Firstly,for30%ofthetrajectories,weaddlocaldistur-\nbancesassociatedwithactionsthatwouldbringtherobotbacktothereferencetrajectory,similarly\ntohowitisdonebyZhouetal.(2023). Secondly,for10%ofthedatapoints,wepurposelychange\nthegripper’sopen-closestate. This, wefoundtobecrucial, as, withoutit, thepolicywouldnever\ntrytore-graspanobjectafterinitiallyclosingthegripper.\nE IMPLEMENTATION DETAILS\nHerewediscusstheimplementationdetailsoftheInstantPolicy,whichwefoundtobeimportantin\nmakingthemethodperformwell.\nDemoProcessing. Althoughournetworkcanhandleanarbitrarynumberofdemonstrationsofany\nlength,wedownsamplethedemotrajectoriestoafixedlength(L = 10inourexperiments). First,\nwerecorddemonstrationsatarateof25Hzand10Hzinsimulationandtherealworld,respectively.\nThe lower rate in the real world is caused by the simultaneous segmentation of objects of interest\nbyXmem++(Bekuzarovetal.,2023). Wethenincludethestartandendofthetrajectoriesandall\nthe waypoints where the open-close state of the gripper changed. We then include the waypoints\ninthetrajectory,wherethegrippersufficientlysloweddown,indicatingimportanttrajectorystages\n(similartoShridharetal.(2023)). Finally, ifthecurrentnumberofthetrajectorywaypointisless\nthanL,weaddintermediatewaypointsbetweenthealreadyextractedones.\nData Augmentation. To achieve robust policies, we found that it is crucial to randomise current\nobservationsandsubsequentactionsduringtraining.Thenetworkcaneasilyoverfittobinarygripper\n16\nstates(ifitisopen,justkeepitopen,andifitisclosed,justkeepitclosed). Totacklethis,we,with\na10%probability,flipthecurrentgripperstateusedasaninputtothemodel. Thisgreatlyincreased\nthe robustness of the resulting policies. Additionally, during the pseudo-demonstration generation\nprocess,weaddedlocalperturbationstotheposeofthegripper(adjustingpointcloudobservations\nandactionsaccordingly),furtherincreasingrobustnessandenablingrecoverybehaviour.\nNormalisation. We normalise all the outputs of our mode to be [−1,1], a step that we found\nto be crucial. To this end, we manually define the maximum end-effector displacement between\nsubsequentactionpredictionstobenomorethan1cmintranslationand3deginrotationandclamp\nthenoisyactionstobewithinthisrange. Thustheflowpredictioniscappedtobeatmosttwicethe\nsizeofthisrange. Knowingthis,wenormalise∇pˆ and∇pˆ tobebetween−1and1independently,\nt r\nenablingefficientnetworktraining. Forthegripperopening-closingactions,thiscanbedoneeasily\nas they are expressed as binary states {0,1}. We do not normalise the position of the point cloud\nobservationsbutratherrelyonthesine/cosineembeddings,astrategythatwefoundtobesufficient.\nPointCloudRepresentation. Weusesegmentedpointcloudobservationsofobjectsofinterestin\ntheenvironmentasourobservations. Thesesegmentedpointcloudsdonotincludethepointsonthe\nrobotorotherstaticobjectssuchasthetableordistractors. Inpractice, Wedownsamplethepoint\ncloudstocontain2048pointsandexpressthemintheend-effectorframeasT ×P toachieve\nEW\nstrongerspatialgeneralisationcapabilities. Thesepointcloudsarethenprocessedwithageometry\nencoder, described in Section A, producing M = 16 nodes used to construct our devised graph\nrepresentation.\nActionDenoising. WhenupdatingT duringourdenoisingprocess,weusecalculatedT (as\nEA k,k−1\ndescribedinSection3.3)andcalculatethetransformationrepresentingend-effectoractionsduring\nthedenoisingprocessasTk−1 = T ×Tk . Theseactionsarethenusedtoconstructagraph\nEA k,k−1 EA\nrepresentation that is used in the next denoising step. In practice, because we express point cloud\nobservationsintheend-effectorframe,weapplytheinverseoftheseactionstotheM pointsrepre-\nsentingthesceneandconstructlocalgraphsofactionsasGa(T−1×Pt,Tt ,a ). Asthereareno\nl EA WE g\nabsolutepositionsinthegraph,thisisequivalenttoapplyingtheactionstothegripperposeTt ,\nWE\nbutitallowsustorecomputethegeometryembeddingsofthepointcloudsattheirnewpose,better\nmatchingtheonesfromthedemonstrations.\nTraining. We trained our model using AdamW (Loshchilov, 2017) optimiser with a 1e−5 learn-\ning rate for 2.5M optimisation steps (approx. 5 days on a single NVIDIA GeForce RTX 3080-ti)\nfollowed by a 50K steps learning rate cool-down period. For efficient training, we used float16\nprecisionandcompiledourmodelsusingtorchcompilecapabilities(Paszkeetal.,2019). Training\ndata in the form of pseudo-demonstrations were continuously generated during training, replacing\ntheoldersampletoensurethatthemodeldidnotseethesamedatapointseveraltimes,preventing\noverfitting.\nF SIMULATION EXPERIMENTAL SETUP\nHere, wedescribethe2changeswemadetoastandardRLBenchsetup(Jamesetal.,2020)when\nconductingourexperiments. 1)Wegeneratedallthedemonstrations(forthecontextandforthose\nusedduringtrainingasdescribedinSection4)usingonlyCartesianSpaceplanning-wedisregarded\nall demonstrations that were generated using an RRT-based motion planner (Kuffner & LaValle,\n2000). We did so to ensure that the demonstrations did not have arbitrary motions that would not\nbecapturedbyourobservationsofsegmentedpointcloudsandend-effectorposes. 2)Werestricted\nthe orientations of the objects in the environment to be within [−π/3,π/3]. We did so to match\nthedistributionofobjectposestotheonepresentinourgeneratedpseudo-demonstrations. Italso\nensuredthatmosttaskscouldbesolvedwithoutcomplexmotionsrequiringmotionplanners.\nG FAILURE CASES\nHere we discuss the observed failure modes of Instant Policy during our experiments. Given dif-\nferentsetupsandassumptions, wedosoforeachofourexperimentsindependently. However, the\ndiscussedfailuremodesaresharedacrosstheexperiments.\n17\nSimulated Experiments. During our simulated experiments using RLBench (James et al., 2020),\nweobservedseveralcommonfailuremodesofInstantPolicy. Firstofall, taskssuchasOpenMi-\ncrowave or Put Umbrella into a Rack require extremely high precision in action predictions, oth-\nerwise, the inaccurate dynamics of the simulator will prevent the task from being completed. As\nsuch, sometimes the handle of the microwave would slip from the gripper, or the umbrella would\nflyoffwhenincontactwiththerobot. Second,taskssuchasFlippingaSwitchorPushingaButton\nterminateimmediatelyafterthetaskconditionismet. Aswepredictactionsofnotdoinganything\nat the end of the trajectory, this resulted in the policy stopping before the task is fully completed\natastatevirtuallythesameasthedesiredone. Moreover,ourgeneratedpseudo-demonstrationsdo\nnot include any collision avoidance, which has proven to be a problem for tasks such as Turning\ntheLampOn,wheretherobotoccasionallycollideswiththelampbymovinginastraightlineto-\nwardsthebutton. Finally, otherfailuremodesusuallyincludedpolicystallingatacertainpointor\noscillatingbetweentwoconfigurations. Wehypothesisethatsuchbehaviouriscausedbyconflicting\ninformationintheprovideddemonstrationsandviolatingtheMarkovianassumption. Inthefuture,\nthiscouldbeaddressedbyincorporatingpastobservationsintothegraphrepresentation.\nReal-WorldTasks. Byfar, themostcommonfailuremodeinourreal-worldexperimentswasthe\nsegmentationfailurecausedbyseveralocclusions. Additionally,imperfectsegmentationsometimes\nincludedpartsoftherobotorthetable, causingthepolicytoperformirrelevantactions. Thisalso\nsometimesdegradedthequalityofthedemonstrationsbyincludingirrelevantpoints(andthusnodes\nintheconstructedgraph). Moreover,weobservedthattheoverallqualityofthedemonstrations,in\ntermsofsmoothnessandclearlydirectedmotions,hadamajorimpactontheperformanceofInstant\nPolicy. Ifrecordeddemonstrationsincludedinconsistentandarbitrarymotions, informationinthe\ncontextwasconflicting,resultinginthepolicystallingoroscillating. Finally,otherobservedfailure\ncasesmainlyinvolvedpolicynotcompletingthetaskduetothelackofprecision.\nGeneralisationtoNovelGeometries. WhenevaluatingInstantPolicyusingobjectsunseenneither\nduringtrainingnordemonstrationatinference,policysometimesjustmimickedthemotionobserved\nduring the demonstrations without achieving the desired outcome. With an increasing number of\ndiversitydemosinthecontext,suchbehaviourwasminimised. However,sometasks(e.g. placing\na mug on a plate) were completed mainly due to the high tolerance of the task rather than true\ngeneralisationcapabilities.\nCross-EmbodimentTransfer. Themainfailurecasesduringourcross-embodimenttransferexper-\niments were caused by incorrect mapping of hand poses to end-effector poses and an insufficient\nfield of view in our observations. This caused the robot to occasionally miss the precise grasp-\ning locations, closing the gripper at stages where it was not intended, and, in general, resulted in\ndemonstrationsofpoorerquality.\nModality Transfer. Replacing demonstrations with language descriptions of the task yielded\npromisingresultsinourqualitativeexperiments. However,theobservedbehaviourwassometimes\nmismatchedwiththeobjectgeometriesintheenvironment. Forinstance,thepolicywouldexecute\nappropriatemotions(e.g.,pushingorclosing)butatincorrectlocationsrelativetotheobjects. This\nissuelikelystemsfromobjectfeaturescontainingonlygeometricinformationwithoutanyseman-\ntic context. Incorporating additional features from vision foundation models into the point cloud\nobservationsandexpandingthelanguage-annotateddatasetcouldhelpaddressthislimitation.\nH THINGS THAT DID NOT WORK\nHerewediscussvariousdesignchoicesweconsideredbeforesettlingfortheapproach,describedin\nSection3.\nFully-ConnectedGraph.Initially,weexperimentedwithafullyconnectedgraph,whicheffectively\nacts as a transformer with dense self-attention. While the attention mechanism should, in theory,\nlearnthestructurerelevanttothetask,thisapproachfailedtoproducegoodresults,evenforsimple\ntasks.\nOneBigNetwork.Insteadofusingthreeseparatenetworksinsequence(asdescribedinSectionC),\nweexperimentedwithasinglelargernetwork,whichledtoasignificantdropinperformance. We\nhypothesizethatthisisbecause,earlyon,thenodeslacksufficientinformationtoreasonaboutac-\n18\ntions,causingmuchofthecomputationtobewastedandpotentiallyresultinginconflictinglearning\nsignals.\nMore Gripper Nodes. We express the robot state as a set of six nodes in the graph. In theory,\nwecanuseanarbitrarynumber(>3)ofsuchnodes,allowingmoreflexibleaggregationofrelevant\ninformation.Weexperimentedwithdifferentnumbersofsuchnodesandobservedminimalchanged\ninperformance,whilethecomputationalrequirementsincreasedsignificantly.\nNoPre-trainedGeometryEncoder. DuringthetrainingofInstantPolicy, wekeepthegeometry\nencoderfrozen. Weexperimentedwithtrainingthismodelfromscratchend-to-end,aswellasfine-\ntuningit. Trainingfromscratchdidnotworkatall,whilefine-tuningresultedinsignificantlyworse\nperformance. We also experimented with larger sizes of the encoder and saw no improvement,\nindicatingthatthegeometryinformationwasalreadywellrepresented.\nHomogeneousGraph. Insteadofusingaheterogenousgraphtransformer,whichprocessesdiffer-\nenttypesofnodesandedgesusingseparatesetsoflearnableweights,wetriedusingahomogeneous\nvariant with distinct embeddings added to the nodes and edges. This approach resulted in signifi-\ncantly worse performance, given the same number of trainable parameters. This indicates that by\nnot sharing the same weights, different parts of the network can better focus on aggregating and\ninterpretingrelevantinformation,resultinginmoreefficientlearning.\nPredictingWaypoints. Initially, wetriedpredictingsparewaypointsinsteadoflow-levelactions,\ne.g. velocities, that progress the execution of a task. We found, that because of these waypoints\nrepresent larger end-effector displacements, predicting them with high precision was challenging.\nIntuitively,thisistheresultoftheincreasedactionspacethat,whennormalised,needstoberepre-\nsentedinaninterval[−1,1].\nLarger Learning Rates. For our experiments, we used a relatively small learning rate of 1e−5.\nTospeedupthetrainingprocess, wetriedincreasingit. However, withincreasedlearningratewe\nfound the training process to be unstable, resulting in large gradients and increasing training loss.\nWealsotriedusingseveraldifferentoptimisers,usingAdamW(Loshchilov,2017)resultinginthe\nbestperformance.\nI CROSS-EMBODIMENT TRANSFER\nAsdescribedinSection4.3.1,ourapproachallowsustoprovidedemonstrationsusingoneembod-\niment(e.g. usinghumanhands)andinstantlydeployapolicyonarobot,givenamappingbetween\ndifferentembodimentsisknown.Thisisbecauseourobservationsarecomposedofsegmentedpoint\ncloudsthatdonotincludepointsontherobotanditsend-effectorpose. Thus,bymappingthepose\nofahumanhandtotherobot’send-effectorpose,wecaneffectivelyobtainthesameobservations.In\nourexperiments,weachievethismappingusingahandkeypointdetectorfromMediapipe(Lugaresi\net al., 2019) and manually designing a mapping between these key points and the corresponding\nrobot’send-effectorpose. Wemodelthepositionoftheend-effectortoberepresentedbythemid-\nwaypositionbetweentheindexfingerandthethumbandestimatetheorientationusinganadditional\npoint on the palm of the hand. In this way, we effectively overparametrise the SE(3) pose of the\nhand, modelled as a parallel gripper, using a set of positions. This allows us to complete simple\ntasks, suchasgraspingorpick-and-place. However, formoreprecisetasks, suchacrudemapping\ncanbeinsufficient. Itcouldbeaddressedbyusingmoreelaboratemappingsbetweenhumanhands\nandrobotgrippers,forexample,asdonebyPapagiannisetal.(2024).\nJ MODALITY TRANSFER\nUsing our graph representation together with network architecture, discussed in Section C, results\nin a clear information bottleneck with all the relevant information from the context aggregated in\naspecificsetofnodes(ϕ(G (σ(Gt),{σ(G1:L)}N))). Informationpresentinthenodesofthegraph\nc l l 1\nrepresenting the current information holds all the necessary information to compute precise robot\nactionappropriateforthecurrentsituation,andatrainedψ(.)hasthecapacitytodoit. Weexploit\nthisbottleneckandlearntoapproximateitusingthecurrentobservationandalanguagedescription\nof a task and utilise a frozen ψ(.) to compute the desired robot actions in the same way as done\nwhenthecontextincludesdemonstrations. Welearnthisapproximationusingthelocalgraphrep-\n19\nresentation of the current observation Gt and a language embedding of the task description f ,\nl lang\nproduced by Sentence-BERT (Reimers, 2019). We use a graph transformer architecture, similar\nto the one used to learn σ, and incorporate f as an additional type of node in the graph. We\nlang\ntrain this network using a language-annotated dataset comprising demonstrations from RLBench\nand rollouts from our experiments, along with a contrastive objective. At inference, we provide a\nlanguage description of a task and, based on the current observation, compute the embeddings of\nthe aforementioned bottleneck. We then use it to compute robot actions that are executed closed-\nlooped, allowing for zero-shot generalisation to tasks described by language. Although showing\npromisingperformanceusingonlyasmalllanguage-annotateddataset,furtherimprovementscould\nbeachievedbyincorporatingsemanticinformationintotheobservation,usingavariationallearning\nframeworkandexpandingthedatasetsize. Weleavetheseinvestigationsforfuturework.\n20",
    "pdf_filename": "Instant_Policy_In-Context_Imitation_Learning_via_Graph_Diffusion.pdf"
}