{
    "title": "Brain-inspired Computing Based on Deep Learning for",
    "abstract": "",
    "body": "Brain-inspired Computing Based on Deep Learning for\nHuman-computer Interaction: A Review\nBihuiYua,b, SiboZhanga,b,∗, LiliZhouc, JingxuanWeia,b, LinzhuangSuna,b and LipingBua,b\naShenyangInstituteofComputingTechnology,ChineseAcademyofSciences,Shenyang,110168,China\nbUniversityofChineseAcademyofSciences,Beijing,100049,China\ncHeilongjiangAcademyofSciencesIntelligentManufacturingInstitute,Harbin,150090,China\nARTICLE INFO ABSTRACT\nKeywords: Thecontinuousdevelopmentofartificialintelligencehasaprofoundimpactonbiomedicineandother\nBrain-inspiredcomputing fields,providingnewresearchideasandtechnicalmethods.Brain-inspiredcomputingisanimportant\nHuman-computerinteraction intersectionbetweenmultimodaltechnologyandbiomedicalfield.Focusingontheapplicationscenarios\nMachinelearning ofdecodingtextandspeechfrombrainsignalsinhuman-computerinteraction,thispaperpresentsa\nDeeplearning comprehensivereviewofthebrain-inspiredcomputingmodelsbasedondeeplearning(DL),trackingits\nBiomedicalresearch evolution,applicationvalue,challengesandpotentialresearchtrends.Wefirstreviewsitsbasicconcepts\nanddevelopmenthistory,anddividesitsevolutionintotwostages:recentmachinelearningandcurrent\ndeeplearning,emphasizingtheimportanceofeachstageintheresearchofbrain-inspiredcomputing\nforhuman-computerinteraction.Inaddition,thelatestprogressofdeeplearningindifferenttasksof\nbrain-inspiredcomputingforhuman-computerinteractionisreviewedfromfiveperspectives,including\ndatasetsanddifferentbrainsignals,andtheapplicationofkeytechnologiesinthemodeliselaboratedin\ndetail.Despitesignificantadvancesinbrain-inspiredcomputationalmodels,challengesremaintofully\nexploittheircapabilities,andweprovideinsightsintopossibledirectionsforfutureacademicresearch.\nFormoredetailedinformation,pleasevisitourGitHubpage:https://github.com/ultracoolHub/brain-\ninspired-computing.\nalsohaveimportantsignificanceandvalueforthecognitive\n1. INTRODUCTION\nmechanismandcognitiveabilityofthehumanbrain.\nBrain-inspiredintelligenceisakindofmachineintelli-\nThecontinuousexplorationofthebrainformsthebasisof\ngencewhichisinspiredbyneuralmechanismandcognitive\nbrain-inspiredcomputing,whichnotonlydrawsinspiration\nbehaviormechanismbymeansofcomputationalmodeling\nfrom the complex structure and operation principle of the\nandrealizedbysoftwareandhardwarecooperation.Brain-\nbrain,butalsofocusesontheinnovativeuseofphysiological\ninspiredintelligencesystemisbrain-inspiredininformation\ndataofbrainsignalsforpracticalapplications.Brain-inspired\nprocessingmechanismandhuman-likeincognitivebehavior\ncomputing models can be applied in human-computer in-\nandintelligencelevel.Humanbrainactivityisacomplexand\nteraction(HCI).Andatypicalapplicationisbrain-computer\ncontinuousdynamicprocess,anditscomplexityisfarbeyond\ninterface(BCI) which aims to establish a channel between\ntheupperlimitthatcanbesimulatedbycurrentcomputing\nthe brain and the external environment, which does not\nresources, so people have not given up the exploration of\ndependontheperipheralnervoussystem,andrealizesthe\nthe brain. Brain-inspired computing is founded upon the\ninformation exchange and control between the brain and\nstructuralframeworkandoperationalprinciplesofthehuman\nexternaldeviceswithprocessingorcomputingcapabilities.\nbrain,andintegratesthecurrentcomputationaldevelopment\nThrough the acquisition, analysis and processing of brain\npathofcomputerscienceandneuroscience[1,2,3,4].\nsignals,humancandirectlyinteractwithcomputerswithout\nResearchersareconstantlytryingtounderstandtheneural\nrelyingonexternaldevices.Forexample,themaingoalof\nmechanismsandcognitivebehaviorthroughthestudyofthe\ncognitiveBCIistounderstandandanalyzetheprocessing\nbrain. Traditional DL necessitates an extensive collection\nmechanismofspeechinformationinhumanbrain.Itcanhelp\nof annotated datasets for effective training, and manual\npatientsovercomethedifficultiesinlanguageexpressionand\nannotateddataisexpensiveandaffectedbyhumansubjective\ntextinputbyrecognizingtheideasexpressedbybrainsignals\nconsciousness,sotheannotationresultsarenotcompletely\nandconvertingthemintospeechortextoutput[47].\naccurate. In contrast, the brain weighs about 2.5 pounds\nAs an emerging research field, the exact definition of\nandconsumesonlyabout40%to60%ofthebody’sblood\nbrain-inspiredcomputingisstillunclear.Thisfieldcovers\nsugar[5].Ifpeoplecanusetheirownphysiologicaldatato\ncomputationaltheory,architecturedesign,hardwarespecifica-\ndecodetextorspeechandcompletecodectaskssimilarto\ntions,etc.,whilelearningfrombraininformationprocessing\nmachine translation, it can not only save manpower, but\nmechanismsandbiologicalphysiologicalstructurestobuilda\nAllauthorscontributedequallytothiswork. varietyofmodelsandalgorithms[48].Somecomprehensive\n∗Correspondingauthor. studies systematically review the research progress in the\nyubihui@sict.ac.cn(B.Yu);zhangsibo22@mails.ucas.edu.cn(S. fieldofbrain-inspiredcomputingfrommultipleperspectives.\nZhang);Zhoulilivip@126.com(L.Zhou);weijingxuan20@mails.ucas.edu.cn\nSomestudiesfocusonbrain-inspiredcomputinginanarrow\n(J.Wei);sunlinzhuang21@mails.ucas.ac.cn(L.Sun);buliping@sict.ac.cn\nsense,suchasspike-basedneuralmimiccomputinginvision\n(L.Bu)\nB.H.Yu et al. Page1of26\n4202\nvoN\n91\n]IA.sc[\n4v31270.2132:viXra\nNB[6],SVM[7],KNN[8],\nRecentModels Classification\nLR[9],RF[10],LDA[11],\nBasedon\nEvolutionof MachineLearning FeatureExtraction PCA[12],AR[13],FFT[14],WT[15]\nBrain-inspiredComputing\nforHCI CurrentModels EarlyDLModel CNN[16],RNN[17,18]\nBasedon\nDeepLearning PretrainedModel BERT[19],BART[20,21,22]\n1.ExperimentalDesign.\n2.EEGAcquisition.\nDataAcquisition\n3.FMRIAcquisition.\n4.Eye-trackingAcquisition.\n1.Filterprocessing.\nDataaquisition 2.Artifactremoval.\nandpreprocessing DataPreprocessing 3.Referencereset.\n4.Spatialcorrection.\n5.Time-frequencyanalysis.\nZuCo[23],ZuCo2.0[24],\nPublicDataset\nScience[25],NC[26]\nAutomaticSpeechRecognition[27],\nEEGNet[28],\nRecentProgress EEG-transformer[29],\nEEG-to-text[20],\nModelsbased CSCL[21],DeWave[22]\nonEEG\n1.EEG-to-textDecoding.\nKeyTechnologies 2.CurriculumLearning.\n3.DiscreteCodex.\nContextIntoLanguage[30],\nBrain2word[31],\nApplicationof multi-timescalemodels[32],\nPaper DeepLearning-based RecentProgress Semantic-basedClassification[33],\nStructure Brain-inspiredComputing Self-supervisedLearning[34],\nModelsforHCITasks Cross-madalClozeTask[19],\nModelsbased UniCoRN[35],\nonfMRI SemanticReconstruction[36]\n1.BrainDecodingModel.\nKeyTechnologies\n2.SemanticFeaturesFusion.\nSeq2seqLearning[37],\nDecodingSpeech[38],\nRecentProgress DecodingImaginedandSpokenPhrases[39],\nMEGSensorSelection[40],\nModelsbased\nDecodingSpeech[41]\nonMEG\n1.CNNsAndTransferLearning.\nKeyTechnologies\n2.SignalAlignment.\nMachineTranslation[42],\nBrain2char[43],\nRecentProgress NeuralSpeechDecoding[44],\nDirectSpeechReconstruction[45],\nModelsbased\nSynthesizingSpeech[46]\nonECoG\n1.DecodingApproach.\nKeyTechnologies\n2.NeuralVocoder.\n1.ChallengesforBrainDataset.\nModelTraining 2.ComputationalResourceDemand.\n3.AcuracyandGeneralizationoftheModel.\nChallenges 4.ChallengesforReal-timeProcessing.\nChallengesand ModelApplication\n5.ChallengesforBCITechnology.\nFutureDirectionsof\nDeepLearning-based EthicalChallenges 6.ChallengesforEthicalConcerns.\nBrain-inspiredComputing\n1.LandingApplicationofBrain-inspiredComputing.\nModelsforHCITasks\nFutureDirections 2.BCIsacrossLanguageBoundaries.\n3.SpikingNerualNetwork(SNN).\nFigure1:Anintroductiontothedeeplearning-basedbrain-inspiredcomputingmodelsforHCItasks,includingitshistory,currently\navailable methods and techniques, as well as the challenges encountered and potential solutions, and the direction of future\ndevelopment.\nB.H.Yu et al. Page 2 of 26\napplications[49].Atthesametime,severalstudieshavecom- fromthreeaspects:modeltraining,modelapplication,\nprehensivelyreviewedhybridneuralnetworks,highlighting and ethical issues, and propose potential solutions.\ntheircomprehensivebalancewithrespecttoartificialneural Welookforwardtofutureapplicationssuchascross-\nnetworks and spiking neural networks[50]. There are also lingualBCIandspikingneuralnetworkwithgreater\nstudiesthatexplorecognitiveengineeringapproaches,aiming biologicalplausibility.\ntoassisttheresearchcommunityindesigningmoreconsistent\nThispaperwillorganizetherestfollowingthestructure\nmethodsandtechniquestoadvancecognitivemachines[51].\nshowninFigure1:wewillfirstdelveintothebasicconcepts\nIn addition, some reviews focus on the hardware design\nanddevelopmenthistoryrelatedtobrain-inspiredcomputing,\nofbrain-inspiredcomputingarchitectures[52].Ontheother\nbrain-computerinterfaces,brainsignalsandsoon.Insection\nhand,somereviewsstartfromthechallengesfacedbythe\n2wewillpromoteadeeperunderstandingofthisresearch\nfield of brain-inspired computing and propose a general\narea.Then,insection3,thispaperreviewstheresearchresults,\nframeworkforbrain-inspiredcomputingsystemsinpractical\nprogress and some key technologies of researchers using\napplications[53]. There are also some research from the\ndeeplearningmodelsandalgorithmstostudybrainsignal\nperspective of the application of BCI systems, but only\ndatathroughaseriesofspecificcasestudiestoillustratethe\nsummarize the signal processing and calculation methods\npractical effects. In section 4, we will deeply explore the\nrelatedtoEEGsignal[54,55].\nchallengesandlimitationsofDLmodelsinbrain-inspired\nThesereviewsprovidevaluableinsightsintotheprogress\ncomputing for human-computer interaction tasks, such as\nofbrain-inspiredcomputationalmodels.Inspiredbythese\ndata accuracy requirements and computational resource\nreviews,thispaperdeeplyinvestigatesthedevelopmentof\nrequirements, as well as the limitations and security risks\nbrain-inspired computing models from the perspective of\nofBCIsystems.FutureresearchdirectionssuchasSNNand\nmachinelearning(ML)anddeeplearning(DL),focusingon\ncross-lingualBCIsystemsarediscussedinsection5.This\nthe brain-inspired computing models that decode text or\npaperconcludestheentirediscussioninsection6.\nspeechthroughbrainsignalsinhuman-computerinteraction.\nThis paper summarizes the application scenarios and lim-\nitations of different machine learning algorithms in brain-\n2. BASICCONCEPTSANDEVOLUTION\ninspiredcomputingmodels,andcomprehensivelyreviews\nThis section mainly expounds the related concepts of\nthedeeplearningrelatedmodelsofbrain-inspiredcomputing\nbrain-inspiredcomputing,brain-computerinterfaceandpre-\ninvolvingEEG,fMRI,MEG,ECoGinrecentyears.Atthe\ntrainingmodel,andfocusesonthecommonalgorithmsof\nsametime,theapplicationofkeytechnologiesinthesemodels\nmachine learning in brain-inspired computing for human-\nis described in detail. This paper aims to summarize the\ncomputerinteractiontasks,aswellastheimportantapplica-\nenlightenmentofartificialneuralnetworksinbrain-inspired\ntionsofdeeplearningmodels.\ncomputingmodelsandalgorithmsinhuman-computerinter-\nactionscenariosfromtheperspectiveofgeneralizedbrain-\n2.1. BasicConceptsofBrain-inspiredComputing\ninspiredcomputing,expectingtofillthegapinthereview\nforHCI\nof brain-inspired computing models for human-computer\nBrain-inspiredcomputingcommonlyencompassescom-\ninteractionbasedondeeplearning.Thecontributionsofthis\nputational theories, architectural designs, hardware spec-\nreviewcanbesummarizedinthreemainpoints:\nifications, and various models and algorithms that draw\n• To enhance understanding of deep learning-based inspiration from the information processing mechanisms\nbrain-inspiredcomputingmodelsforhuman-computer andbiophysiologicalstructuresofthebrain[48].Thisreview\ninteraction, we first introduce the fundamental con- studiesbrain-inspiredcomputingfromabroadperspective.\ncepts.Then,wereviewrecentadvancementsinbrain- Learning from the structure and working principle of the\ninspiredcomputingwithinmachinelearninganddeep brain, but not limited to the simulation of the brain, but\nlearning, highlighting the critical role of machine alsoincludingtheintegrationoftraditionalartificialneural\nlearninginfeatureextractionandclassification,and networkwithmorebrain-inspiredcharacteristicsofheteroge-\nleadingtotheprimaryfocusondeeplearning-based neousneuralnetworks,isanintegrationofcurrentcomputer\nbrain-inspiredcomputingmodels. scienceandneuroscienceComputingdevelopmentpath.This\npaperfocusesonthebrain-inspiredcomputingmodelsand\n• After reviewing the progress of the research, we\nalgorithmsfordecodingtextandspeechfrombrainsignals\ndividethetasksrelatedtobrain-inspiredcomputingfor\ninHCItasksthroughMLandDL.\nhuman-computerinteractionbasedondeeplearning\nIn order to better understand the task of brain signal\nmodels into five parts, four of which introduce the\ndecoding,wewillbrieflydiscussthevariousbrainsignalsthat\nprogressbasedondifferentbrainsignals,emphasize\narecommonlyused,includingelectroencephalogram(EEG),\ntheimportanceofexperimentalstimulusdesignand\nfunctionalmagneticresonanceimaging(fMRI),Magnetoen-\ndataacquisitionandpreprocessing,andelaboratethe\ncephalography(MEG)andelectrocorticography(ECoG).\napplicationofkeytechnologiesinthemodel.\nEEG,anon-invasivemethodformeasuringbrainactivity,\n• Inaddition,wehighlightthechallengesfacedbybrain- encapsulatesarichrepositoryofinformationregardingthe\ninspiredcomputationalmodelsbasedondeeplearning intricate workings of the brain, rendering it an appealing\nB.H.Yu et al. Page 3 of 26\ndatasourceforapplicationsinDL.TheadvancementofDL combinedwiththecurrentlyhotpre-trainedlanguagemodel\ntechniques in the analysis of EEG features holds tremen- (PLM)whichhasundergoneaseriesofevolution.Asanearly\ndouspotentialforthedevelopmentofnoveldiagnosticand initiative,ELMo[59]aimedtocapturecontext-awareword\ntherapeutictoolswithintherealmofneurologicaldisorders. representations through the pre-training of a bidirectional\nTypically,EEGsignalsareacquiredthroughtheplacement longshort-termmemorynetwork(biLSTM).Unlikelearning\nof electrodes on the scalp and are represented as a two- fixedwordrepresentations,ELMo’sapproachinvolvesfine-\ndimensional matrix or graph. This representation unfolds tuningthebiLSTMnetworkforspecificdownstreamtasks.\nintimeasonedimensionandspatiallyintermsofelectrode Subsequently,drawingonthehighlyparallelizedtransformer\nlocationsasanother.Researchersinthefieldcommonlytreat architecture[60]andtheself-attentionmechanism,BERT[61]\nmultiple channels as the spatial dimension of EEG data, wasintroduced.BERTentailspre-trainingtwo-waylanguage\naligningwiththetemporaldimension[56,57]. models and specifically designed pre-training tasks using\nFMRIisaanotherpowerfulnon-invasivetoolforstudying alarge-scaleunlabeledcorpus.Thesepre-trained,context-\nbrainfunction[58].Usedforpsychologists,psychiatrists,and awarewordrepresentationsserveashighlyeffective,generic\nneurologists,fMRIprovideshigh-qualityvisualizationsof semantic features, significantly elevating the performance\nbrainactivityinresponsetosensorystimulationorcognitive standardforawiderangeofnaturallanguageprocessingtasks.\nfunctions. Thus, it facilitates the study of the intricate Thisstudyhasspurredasubstantialamountofsubsequent\nworkingsofahealthybrain[20,58].TheobjectiveoffMRI research,establishingaprevalent\"pre-trainandfine-tune\"\nanalysis is to robustly, sensitively, and validly detect the learning paradigm. Following this paradigm, a great deal\nregionsofthebrainthatexhibitheightenedintensityduring of research has been done on PLMs, introducing different\nthemomentswhenstimulationisapplied[21]. architectures such as generative models GPT-2[62] and\nMEGisanon-invasiveneuroimagingtechniqueusedto BART[63], in which PLM often needs to be fine-tuned to\nrecordneuralactivityinthebrain.Itreflectsbrainactivity suitdifferentdownstreamtasks.\nbymeasuringtheweakmagneticfieldsgeneratedbyneurons\nin the brain. These magnetic fields are able to penetrate 2.2. TheEvolutionofBrain-inspiredComputing\nthe skull and tissue without being affected by them, thus forHCI\nprovidingEEGsignalswithhighspatio-temporalresolution. With the rapid development of artificial intelligence\nIn MEG, an array of induction coils is placed around the models,brain-inspiredcomputingmodelsforHCIhavealso\npatient’sheadtodetectandrecordchangesinthemagnetic attracted wide attention. Brain-inspired computing tasks\nfieldcausedbyneuronalactivity.BecauseMEGmeasuresthe thatcanbecompletedareincreasinglycomplexfromearly\nmagneticfieldsgeneratedwithinthebrainbynervecurrents, machinelearningmodelstolarge-scaledeeplearningmodels\nrather than the electrical potentials (such as EEG) on the withhundredsofbillionsofparameters.\nscalpsurface,itprovidesamoreprecisespatialresolution.\nMEG is often used to study functional localization of the 2.2.1. RecentModelsBasedonMachineLearning\nbrain, neuroplasticity, and brain activity associated with Inrecentyears,theuseofmachinelearningtechniques\nneurological diseases. Its non-invasive nature makes it an toanalyzebrainsignalshasattractedalotofattention.For\nimportant tool for studying brain function and abnormal example,thereisgrowingresearchevidencethatmachine\nactivity.MEGisincreasinglyusedinneuroscience,clinical learning can extract meaningful information from high-\nmedicineandcognitiveresearch,providingapowerfulmeans dimensionalandnoisyEEGsignals.Giventheinterestand\ntodeeplyunderstandthecomplexfunctionsofthebrain. widespread use of the technology, this section focuses on\nThethreenon-invasivemethodsdescribedearlier,asa recent examples of researchers using machine learning to\ncontrast,ECoGisatechniquethatrecordselectricalactivity analyzebrainsignalstobuildbrain-inspiredcomputational\nin the brain, but electrodes are implanted directly on the models, including machine learning methods and related\nsurfaceofthepatient’sbrainratherthanplacedonthescalp. applications. As shown in Table 1, two main applications\nBy implanting an array of electrodes on the surface of ofmachinelearningmethodsinthefieldofbrain-inspired\nthe brain[42], ECoG is able to provide EEG signals with computing at different stages, namely classification and\nhigherspatio-temporalresolution.Thismethodiscommonly featureextraction,areshown,andcommonmachinelearning\nused to study epilepsy, neuroplasticity, and brain function algorithmsarelisted.\nlocalization.Comparedtotraditionalelectroencephalograms, Amongtheapplicationsofbrain-inspiredcomputingfor\nECoGprovidesafinerspatialresolution,allowingresearchers human-computerinteraction,brain-computerinterfaceisthe\ntounderstandtheelectricalactivityofspecificbrainregions mostwidespreadone.Brain-computerinterfacetechnology\ningreaterdetail. establishes a connection between the human brain and\nTheabovesummarizesthecommonlyusedbrainsignals. the computer and its external equipment for information\nTheimprovementofdeeplearningalgorithms,especiallythe exchange.AsshowninFigure2,acompletebrain-computer\ndevelopmentofpre-trainedmodels,haspromotedtheperfor- interfacesystemgenerallyincludesthreemodulesofbrainsig-\nmanceimprovementofbrainsignaldecodingtasksinthefield nalacquisition,dataprocessingandBCIapplication,inwhich\nof brain-inspired computing. Most methods of processing differentsignalssuchasEEG,fMRI,MEGandECoGcan\nbrainphysiologicaldatawithdeeplearningtechniquesare beselectedaccordingtotheactualsituation.Dataprocessing\nB.H.Yu et al. Page 4 of 26\nTable 1\nMachine learning algorithms used in brain-inspired computing tasks.\nTask Stage Category Representative Work\nNB, [6]\nSVM, [7]\nKNN, [8]\nClassification\nLR, [9]\nRF, [10]\nModel Based on Machine Learning LDA, [11]\nPCA, [12]\nAR, [13]\nFeature Extraction\nFFT, [14]\nWT, [15]\nFigure 2: Diagram of the BCI system module.\nwillcombinefeatureextractionalgorithmsandclassification moreaccuratemodel[73,74].Thesemethodsareoftenused\nalgorithms to further enhance the collected brain signals, tocompleteclassificationtasksinbrain-inspiredcomputing.\nandthenrealizeinformationexchangewithexternaldevices Forexample,NBisaprobabilisticclassifierthatcanbe\nthroughbraincomputerinterfaceapplications[64,65].The appliedtoEEGsignalanalysis.Itonlyneedsasmallamount\ntypicalapplicationsincludeSSVEP[66,67],P300[68,69], of training data set to classify data according to certain\nMI[70, 71] and some other human-computer interaction features by Bayes’ theorem[75, 76], so it plays a certain\napplicationscenarios. advantageinBCIsystem[77,78].ThetasksofapplyingNB\nAmongtheabovementioneddataprocessingalgorithms, includeemotionrecognition[79],epilepsydetection[80]and\nmachinelearningalgorithmsareusedtosolvetheproblem motorimagery[81,82,83,84,85].However,NBhascertain\nintheearliestbrain-inspiredcomputingmodels. limitations, under its basic assumption, all properties are\nOntheonehand,machinelearningalgorithmsarecom- independentofeachother,andtheeigenvectorhasthesame\nmonly employed in various traditional classification ap- effectontheresult[76].\nproaches,encompassingbothsupervisedandunsupervised Next,SVMiswidelyusedinEEGclassificationandBCI\nlearning.Amongthese,supervisedalgorithmsstandoutasthe systems[86,87,88,89,90].SVMcaneffectivelysegregate\nmostrenownedmethodinEEGdataanalysis[72].Itmainly twodatasets,whetherinalinearornon-linearfashion.For\nincludesnaivebayes(NB),supportvectormachine(SVM), linearseparation,SVMleveragesdiscriminanthyperplanesto\nk-nearestneighbor(KNN),logisticregression(LR),random delineateclasses,whilefornon-linearseparation,itemploys\nforest (RF) and linear discriminant analysis(LDA). Each kernelfunctionstodiscerndecisionboundaries.Compared\nsupervisedmodelemploysalearningalgorithmtoproducea withKNNandothersupervisedalgorithms,SVMhaslower\nB.H.Yu et al. Page 5 of 26\ncomputationalcomplexity[91,92].SVMhavefoundexten- distance.Byprojectingdataintoalow-dimensionalspace,\nsiveapplicationinEEGsignalclassificationowingtotheir it finds the hyperplane that can best distinguish between\nsimplicity and versatility in addressing classification chal- differentcategories,thusachievingdimensionalityreduction\nlenges,includingthediagnosisofbraindiseases[93,94,95]. while maximizing classification accuracy[118, 119, 120].\nInaddition,SVMcanalsobeusedforothertasks,suchas LDA has proven successful in addressing classification\nrobotcontrol[96]andemotionclassification[97].However, challenges within BCI systems[121, 122, 123, 124], such\nSVMperformanceisaffectedbykernelfunctionandpenalty asmotorimagery[85,125],P300spellers[126],brainstates\ncoefficientparameters.Therefore,itisimportanttooptimize decoding[127], and multi-class BCI[128], attributed to its\ntheparametersintroducedintotheSVMclassifier[98]. straightforward usability and minimal computational de-\nFurthermore, the basic idea of KNN algorithm is that mands.Nevertheless,theprimarylimitationofthismodel\nin feature space, if most of the neighbors of an instance liesinitslinearnature,renderingitunsuitableforapplication\nbelong to a certain class, then the instance also belongs tonon-linearEEGdata[103,129].\ntothatclass[8].KNNalgorithmhasstronginterpretability, On the other hand, in addition to the above classi-\neasy implementation, and no parameter adjustment, only fication task algorithms, machine learning also plays an\nneed to select a suitable K value, so it is also used in important role in the stage of feature extraction, several\nthe classification task of BCI system[99, 100, 101, 102]. featureextractionalgorithmsbasedonmachinelearningare\nHowever, KNN algorithm also has some limitations. The reviewednext,includingprincipalcomponentanalysis(PCA),\nalgorithmisrequiredtocomputethedistancebetweeneach autoregressive(AR),fastfouriertransform(FFT)andwavelet\nsampleandalltrainingsamples,soitrequiresalargeamount transform(WT).\nofcomputationonlarge-scaledatasets,andKNNalgorithm Firstly,thefundamentalconceptofthePCAalgorithmis\nissensitivetonoisydata,whichmaybegreatlyaffected,re- totransformhigh-dimensionaldataintoalower-dimensional\nsultingininaccuratepredictionresults.Furthermore,despite space, preserving the main features of the data, while re-\nthedecreaseincomputationalcomplexitywithanincrease movingredundancyandcorrelation[12].ThePCAalgorithm\ninthevalueofkforKNN,itsclassificationperformancealso achieves dimensionality reduction through linear transfor-\ndiminishes[91,103]. mation, making the data easier to visualize and analyze,\nNext,LRalgorithmisacommonclassificationalgorithm[9], whileimprovingtheperformanceandefficiencyofmachine\nitscoreideaistouselogicalfunctionstobuildalinearmodel learningmodels.Therefore,thealgorithmissuitablefora\ntomodeltherelationshipbetweeninputfeaturesandoutput varietyofscenariosandcansimplifycomplexproblems.In\nlabels.Logicalfunctionssuchassigmoidcanmapanyreal brain-inspired models, PCA algorithm is used for feature\nnumber to the interval [0,1] and can therefore be used to extraction[130,131,132,133].However,PCAalsohassome\nrepresentprobabilities.Inordertodeterminetheparameters limitations,forexample,itissensitivetonoiseandoutliers,\nof the model, it is necessary to define a loss function to whichmayleadtothedeviationofdimensionalityreduction\nmeasure the degree of fit of the model. LR algorithm is results from the real situation. In addition, PCA ignores\nsuitable for binary classification problems and has strong thecorrelationbetweensamplesanddoesnotconsiderthe\ninterpretability.Thus,LRalgorithmsarecommonlyusedin importanceoffeatures,whichmayaffectitscomprehensive\nclassificationtaskssuchasEEGclassification[104,105,106] descriptionofthedata.Inaddition,itsinterpretationispoor.\nandBCIsystems[107,108,109].However,italsohassome Secondly, AR is a prediction algorithm based on time\nlimitations,issusceptibletooutliersandredundantfeatures, series,thebasicideaistousetheobservedvalueofthepast\nandislesseffectivewhendealingwithmultipleclassification timesteptopredictthecurrentobservationvalue,thatis,by\nproblems. establishingalinearmodel,thedataofthecurrentmoment\nMoreover,RFisamodelcomposedofmultipledecision andthedataofthepastmomentarelinearlycombined,soas\ntrees,eachtrainedwithadistinctsubsetofdataandfeatures. toobtainthedataofthefuturemoment.Attheheartofthe\nItrandomlyselectsdataandfeatures,andthenintegratesthe ARmodelistheautoregressivecoefficient,whichrepresents\npredictionresultsofeachtreetomakethefinalprediction, therelationshipbetweenthedataatthecurrentmomentand\neffectivelyreducingoverfittingandimprovingtheprediction thedataatthepastmoment.Theautoregressivecoefficient\naccuracy[110].Insolvingclassificationproblems,RF’spar- canbeestimatedbyleastsquaremethodtoobtainanoptimal\nallelstructurehasbetterperformancethanothersupervised autoregressive model[13]. AR models capture trends and\nalgorithmsinprocessinglargeEEGdatasets[82,111,112, historicaldependenciesintimeseriesdata.Theapplication\n113,114].Inaddition,itisusedforimageclassification[115], ofARalgorithmincludesfeatureextractiontasks[134],motor\nbraintumordetection[116]andsomeotherBCItasks[117]. imagery tasks[135] and other BCI tasks[136, 137, 138].\nHowever,over-fittingandinstabilityoftreescanaffectthe However,ARmodelalsohassomelimitations,itcanonly\nperformanceofRFmodels,especiallyfortreesofdifferent capturetheautoregressiverelationship,cannotcapturethe\nsizes[76]. movingaveragerelationship.TheARmodelignorestheerror\nLastly,LDAisasupervisedlearningmethoddesigned termofthepasttimestepandmaynotcapturethemoving\nto identify features that effectively differentiate between averageinthedata.Forsometimeseriesdata,theARmodel\ndifferent classes. Its fundamental concept involves max- mayrequireahigherordertofitthedatawell,resultinginan\nimizing inter-class distance while minimizing intra-class increaseinmodelcomplexity.\nB.H.Yu et al. Page 6 of 26\nMoreover, FFT algorithm reduces the computational 2.2.2. CurrentModelsBasedonDeepLearning\ncomplexity of discrete fourier transform(DFT)[139] algo- Inrecentyears,deeplearningtechnologyhasattracteda\nrithmandmakestheprocessingoflarge-scaledataefficient lotofattentioninseveralresearchfields,andcanbeusedto\nand feasible. Especially for large data sets. This makes provideanovelsolutionforlearningstablerepresentationsin\nit an important tool in signal processing, communication thephysiologicalsignalsofthebrain.Themachinelearning\nsystemsandotherfields[14].ApplicationsinBCIsystems techniques reviewed earlier can extract valid task-relevant\nsuchasgamecontrolling[140],featureextraction[141,142] information from signals. Signal classification plays an\narecommonlyused.However,theFFTalgorithmdemands important role in research tasks and has been applied to\nasubstantialamountofmemoryspaceforbothdatastorage manysignalcontroltasks.Althoughgreatprogresshasbeen\nandresultcomputation.TheaccuracyofFFTalgorithmmay made in this regard, there remains considerable potential\ndecreasefordatawithnon-uniformdistributionornoisydata. forenhancingclassificationaccuracy,andthereisalsoalot\nLastly,WTbuildsuponandenhancestheconceptofshort- of room for exploration in the application of other tasks.\ntimeFouriertransformlocalization,addressingdrawbacks Hence, as a burgeoning frontier in the realm of machine\nlikethefixedwindowsizethatdoesn’tadjustwithfrequency learning,deeplearninghasgarneredtheinterestofnumerous\nchanges.Itsystematicallyconductsmulti-scalerefinement researchersinthefieldofbrainscience.\nofthesignalthroughsuccessivetelescopictranslationopera- Basedon theTransformer[60] architecture,BERT[61]\ntions.Consequently,thetimesubdivisionathighfrequency learns contextual information forward and backward, en-\nand frequency subdivision at low frequency dynamically ablingthemodeltobetterunderstandthemeaningofwords\nconformtothedemandsoftime-frequencysignalanalysis, in sentences. Pre-trained on large-scale text, BERT learns\nallowingforfocusedattentiononanysignaldetails.WTcan a common language representation that can then be fine-\nanalyzeinformationofdifferentfrequencycomponentson tunedforvariousNLPtasks,suchastextclassificationand\nthe same time scale which can adapt to focus on arbitrary namedentityrecognition.BERTmodelhasbeenappliedto\ndetailsofthesignalwhichisparticularlyusefulforanalyzing brain-inspiredcomputingtasks.Forexample,thecross-modal\nnon-stationarysignalsandabruptsignals[15].Thus,WTis cloze task treats the decoding task as a fusion of a direct\ncommonlyusedinfeatureextraction[143,144,145,146]and classificationtaskandaclozetask[19].Innaturallanguage\nother BCI tasks such as SSVEP[147, 148, 149, 150, 151]. processing,clozetaskshavebeeneffectivelyaddressedby\nHowever, the computational complexity of the wavelet BERT, a pre-trained masking language model capable of\ntransformishigherthanthatoftheFouriertransform,andthe randomly masking certain words in the input and subse-\ncomputationtimemaybelongerforlargedatasets.Because quentlypredictingthemaskedwordsbasedoncontext[19].\ntheboundaryofthesignalcannotfullysatisfytheperiodicity By classifying brain images with context into words from\ncondition,therewillbeanendeffect,whichmayaffectthe a large number of words, a given context should provide\naccuracyofthetransformationresult,anditisnecessaryto additionalinformationtopredictwordsbynarrowingdown\nselectasuitablewaveletbase. possiblecandidates.\nIn general, the brain-inspired computing models and BART[63]performsparticularlywellinthecurrentdeep\nalgorithmsestablishedbymachinelearninggenerallyhave learning pre-training models that combine brain-inspired\ncertainlimitations.Firstly,thedatarequirementsarehigh, computing fields. It is unique in its bidirectional and au-\nandthedataqualityanddataquantityhaveagreatimpact toregressivelearningstyle.Throughasequence-to-sequence\non the performance of the model. In addition, due to the trainingapproach,BARTintroducesade-noisingmechanism\ncharacteristicsofsomemethodsthemselves,suchasLDAas that allows the model to capture global text information\narepresentativeoflinearclassificationalgorithmscannot by masking parts of the words of the input sequence and\nsolvethenonlineardataclassificationproblem.LRcanwell attemptingtorestorethem.ThisdesignallowsBARTtoexcel\nsolvethebinaryclassificationproblem,butcannotsolvethe ingenerativetaskssuchastextsummarizationandmachine\nneedsofbrain-inspiredcomputingmodelmulti-classification translation.Wangetal.[20]tooktheleadindecodingopen\nproblem.KNN,FFTandotheralgorithmsaresensitivetodata domainwordsforthefirsttimebasedonZuCodataset,and\nnoise,thebrainsignalacquisitionitselfiseasytobedisturbed thevocabularysizeexpandedfromabout250toabout50000.\nbythesurroundingenvironmentandproducenoise.When TheteamofHIT[21]tookintoaccountthegapbetweentopic\nthesemachinelearningmethodsareonlyusedtosolvebrain- andsemanticonthebasisof[20],andthenretrainedtheEEG\ninspired computing problems, the effect is often not ideal datatonarrowthegapbetweentopics.Thesemanticfeatures\nand the application scenarios are limited. The emergence ofthedataaremorecomplete,andtheSOTAperformanceat\nandrapiddevelopmentofdeeplearningalgorithmshasalso thattimeisachieved.ThemaininnovationofDeWave[22]is\npromotedtheprogressofbrain-inspiredcomputingmodels. that it does not use eye movement dataset which believes\nThe advantages of machine learning algorithms in data that people do not necessarily read words in order, and\npreprocessingandtheadvantagesofdeeplearningalgorithms eventhesegmentationusingeyemovementdataisnotthe\ninmodelinganddecodingcanbecomprehensivelyusedto correspondingsegmentationofdata.Therefore,itisthefirst\nbetterdealwithbrain-inspiredcomputingproblemsinvarious timetotrytorealizethedirecttranslationofrawbrainwave\nHCIapplicationscenarios. totext,althoughthetranslationeffectisnotasgoodasthe\nB.H.Yu et al. Page 7 of 26\nTable 2\nProgress in deep learning models based brain-inspired computing tasks.\nTask Method Category Representative Work\nAutomatic Speech Recognition, [27]\nEEGNet, [28]\nEEG-transformer, [29]\nEEG\nEEG-to-text, [20]\nCSCL, [21]\nDeWave, [22]\nContext Into Language,[30]\nBrain2word, [31]\nmulti-timescale models, [32]\nSemantic-based Classification, [33]\nfMRI\nSelf-supervised Learning, [34]\nCross-modal cloze task, [19]\nUniCoRN, [35]\nSemantic Reconstruction, [36]\nModel Based on Deep Learning\nSeq2seq Learning,[37]\nDecoding Speech(Dash D,et al.),[38]\nMEG Decoding Imagined and Spoken Phrases, [39]\nMEG Sensor Selection, [40]\nDecoding Speech(Défossez A, et al.), [41]\nMachine Translation, [42]\nBrain2char, [43]\nECoG Neural Speech Decoding, [44]\nDirect Speech Reconstruction, [45]\nSynthesizing Speech, [46]\ncombinationofEEGdataandeye-trackingdata.Butatleast sectionwillfocusontheconstructionofhigh-qualitydatasets\nitprovesthatitworks. fromthreeaspects:dataacquisitionstage,datapreprocessing\nInthissection,themachinelearningalgorithmsemployed stageandthepublicdatasets.\ninhuman-computerinteractiontasksrelatedtobrain-inspired\ncomputingaresegmentedintotwogroups:featureextraction 3.1.1. DataAcquisition\nalgorithmsandclassificationalgorithms.Withineachcate- Inthelatestresearchinthefieldofbrainsignals,several\ngory, we explore the relevant scenarios and limitations to key techniques have been widely used. The quality of the\nprovideacomprehensiveunderstandingoftheirapplicability. data is guaranteed and improved, which is convenient for\nthe relevant personnel of computer science to carry out\nsubsequentalgorithmresearch,andthefollowingisabrief\n3. DEEPLEARNINGMODELSFOR introductiontothesekeytechnologies:\nBRAIN-INSPIREDCOMPUTING Stimuli & experimental design: In general, event-\nrelatedpotential(ERP)experimentsusestimulithatarebest\nThissectionwilldiscussindetailtherecentandcurrent\nperceivedassimpleandclear.Ifthepropertiesofthestimulus\ncontributions and research achievements of brain-inspired\n(especiallythecontent,intensity,duration,orlocationofthe\ncomputing models for HCI tasks based on deep learning\nstimulus)arenotrelevanttothepurposeoftheexperimental\nwhich areclassified andlisted inTable2 accordingto the\nstudy,theyneedtobeappropriatelycontrolled.Theso-called\ndifferentbrainsignalsprocessed.Andwewillelaboratethe\n\"control\"istobeasconsistentaspossiblebetweeneachspur\napplicationofkeytechnologiesinthemodel.\nwithintheconditionandbetweendifferentconditions.Ifa\nparameter of the stimulus is not possible to be consistent\n3.1. DataAcquisitionAndPreprocessing\nThe acquisition of brain signal datasets often requires in practice, the researcher should also try to reduce the\nhigh cost and strict experimental conditions. Some high- variability of the parameter within the condition, and the\nquality public datasets provide great convenience for re- difference between the conditions should be statistically\nsearchers in the field of brain-inspired computing. This testedtoensurethatthedifferenceisnotsignificant.\nB.H.Yu et al. Page 8 of 26\nInthefieldofpsychology,theevent-relatedpotentialtech- to standardized procedures across all four data sources,\nnologyisoftenusedtostudy,whichisalsoagreatinspiration encompassingessentialstepssuchasband-passfilteringand\nforthedesignofbrainsignalacquisitionexperiments[152]. artifactremoval[56].\nExperimentaldesign,especiallythedesignofexperimental fMRIacquisition:Functionalmagneticresonanceimag-\nstimuli, greatly affects the quality of collected data, and ing (fMRI) is a technique utilized to measure and map\nfurther affects the algorithms of data preprocessing and brain activity by detecting changes correlated with blood\nthemodelingprocessofbrainsignaldecoding.Inorderto flow[155].Withatemporalresolutionoftwoseconds,fMRI\nimprovethestrengthofbrainsignals,researchersoftendesign captures alterations in blood flow, allowing one scan to\nexperiments by combining internal stimuli and external encompass multiple words during continuous stimuli like\nstimuli.Externalstimulisuchasvisual,auditory,andtactile naturalreadingorstorylistening.Thedatasetsusuallyinclude\nstimulicanfurtherstrengtheninternalstimuli,especiallyfor bothisolatedstimuli[25]andcontinuousstimuli[160].While\ncognitivetasksofbrainsignaldecodingandsomeemotional itiscomparativelysimplertoextractword-levelsignalsfrom\nperceptiontasks.Forexample,whendesigningvisualstimuli, isolated stimuli, continuous stimuli offer the advantage of\nattention should be paid to the center of visual materials extracting signals in context across a broader vocabulary.\n(such as pictures) to reduce or even avoid the appearance FMRI data consists of representations of neural activity\nof eye movement artifacts. If the visual materials are text withinmillimeter-sizedcubesknownasvoxels.Aspartof\nstimuli,certaincontrolproblemscanbeconsideredtoensure the standard fMRI preprocessing procedures prior to the\nthe accuracy of brain signals and enhance the strength of analysis,variouspreprocessingmethods,includingmotion\nbrainsignals.Whendesigningauditorystimuli,theproperties correction,slicetimingcorrection,andco-registration[155],\nof the audio material itself such as pitch, loudness and wereimplemented[56].\ndiscriminationacuityshouldbetakenintoaccount.When In summary, the design of experimental stimuli has a\ndesigningtactilestimuli,onecanfocusontheeffectsofthe profoundimpactonthequalityofthedataset,andcertain\ndurationandfrequencyofthestimuli.Mostofthepublicdata norms should be followed, such as controlling irrelevant\nsets have been verified by a large number of experiments, variables and combining internal and external stimuli to\nandstrictexperimentalschemesareusedtofocusonthedata enhancethestimulussignal.Datacollectionisthekeystep.\nsetcollectiontaskitself,whichcanensurethequalityofthe Aftertheoriginaldatacollectioniscompleted,italsogoes\ncollecteddata,butitmaynotbesuitableforallexperiments. throughaseriesofpreprocessingsuchasdenoisinganddata\nWhentheresearchersneedtodesigntheirownexperiments, segmentation.Subsequentworkwillusetheprocesseddata\nwehopethattheabovetipsintermsofexperimentaldesign tocompletethemodelconstruction,encodinganddecoding.\ncanbringsomeinspirationandhelp.\nEye-tracking acquisition: Eye-tracking serves as an 3.1.2. DataPreprocessing\nindirectindicatorofcognitiveengagement,asgazepatterns Datapreprocessingiscrucialinbrainsignaldecoding,\nexhibitastrongassociationwiththecognitiveworkloadat becauseithelpstoremovenoiseandartifacts,betterhighlight\ndifferentstagesofhumantextprocessing[153].Forinstance, signalcomponentsrelatedtospecificbrainactivities,improve\nfixationdurationtendstobeprolongedforlengthy,uncom- signalqualityandreliability,makesubsequentfeatureextrac-\nmon,andunfamiliarwords[154].Eachdatasetencompasses tionandmodeltrainingmoreaccurateandeffective,strong\ndistinct eye-tracking features, with the most prevalent fea- decodingperformanceandrobustness.Next,somecommon\ntures,namelyfirstfixationduration,firstpassduration,mean pretreatment steps of brain signals such as filtering and\nfixationduration,totalfixationduration[155],andnumberof artifactremovalaresummarized,andtheeffectsofdifferent\nfixations,consistentlyavailableacrossallsevendatasets[56]. pretreatmentstepsondifferentbrainsignalsareexplained.\nEEGacquisition:Electroencephalography(EEG)serves Filter processing: Filter processing is the most basic\nasameanstorecordtheintricateelectricalactivityofthe stepinbrainsignalpreprocessing,whichisusedtoremove\nbrain, capturing voltage fluctuations across the scalp with unwanted frequency components. EEG and ECoG utilize\nexceptional temporal precision. Hauk[156] has presented filteringtoremoveunwantedlowandhighfrequencysignals,\ncompelling evidence supporting the modulation of early and high-pass filtering, typically at 0.1-1 Hz, is used to\nelectrophysiological brain responses influenced by word eliminatelow-frequencydrift,suchasslowvoltagefluctu-\nfrequency, highlighting the rapid nature of lexical access ations in time that can result from poor electrode contact\ntriggered by written word stimuli within a timeframe of or certain condition changes in the scalp[161]. Low-pass\nless than 200 ms post-stimulus presentation. The EEG filtering,typicallybetween30-100Hz,isusedtoremovehigh-\ndatasets employed in this study[155] were derived from frequencyinterferencesuchasmuscleactivitywhilemain-\nsessions involving either the reading of sentences or the tainingfrequencysignalsassociatedwithbrainactivity.In\nlistening to natural speech. The extraction of word-level particular,band-stopfilters(50Hz)areoftenusedtoeliminate\nbrainactivitywasachievedthroughdiversemethodologies, frequencyinterferencefrompowercords,whichoftencomes\nincludingmappingtoeyetrackingcues[23],alignmentwith fromlaboratoryequipmentorexternalelectronics[162].The\nauditory triggers[157], capturing solely the terminal word filteringprocessinMEGissimilar,usingbandpassfiltering\nin each sentence[158], or employing the method of serial to remove low and high frequency signals of no interest\nwordpresentation[159].PreprocessingofEEGdataadhered suchasmuscleelectricalactivityorexternalhigh-frequency\nB.H.Yu et al. Page 9 of 26\ninterference[163],whileaccuratelyfilteringoutpowerline Throughthesetechniques,dynamicEEGrhythmssuchas𝛼\nfrequencynoisetoensuretheaccuracyofthemagneticfield waveand𝛽 wavecanbeanalyzedinspecifictimeperiods.\nsignal. fMRI uses high-pass filtering to remove very low- MEGdatacanalsobeinterpretedbytimespectrumanalysis,\nfrequency drifts, chronic drifts that are often affected by and the inverse problem solving method can be used for\nphysiologicalnoisesuchasheartrateandbreathing,aswell furtherneuralsourcelocalizationanalysis[171].InfMRI,this\naschangesindevicetemperature[164].Thepurposeofhigh- typeofanalysisisusedless,becausefMRIfocusesonspatial\npassfilteringistoexcludenon-signal-relatedlow-frequency analysisandlong-termchangesintimeseriessignals[172].\nchangestoimprovethestabilityoftimeseriesdata. With these processing steps, researchers can more ef-\nArtifact removal: Due to the interference of various fectively remove interference, improve data quality, and\nphysiologicalandnon-physiologicalfactors,thebrainsignals ultimatelyobtainmoreaccurateanalysisofbrainfunction\noftencontainartifacts.DuringEEGandMEG,theelectrode andbehavior.Thesestepsworktogethertoensurethatthe\nsignalissusceptibletointerferencefromeyemovement,heart- mostusefulandaccurateinformationisextractedincomplex\nbeat,andmuscleactivity.Independentcomponentanalysis brainfunctionstudies.\n(ICA) is used to decompose and identify the independent\nsignalsources,andtheneliminatethecomponentsassociated 3.1.3. PublicDataset\nwithartifactstopurifythesignal.EEGartifactcorrectionmay Before establishing the model, it is very important to\nalsoincludemanualexaminationandlabelingofabnormal selecthigh-qualitydataset.Althoughhigh-qualitydatasetcan\nsignalsegments[165].ECoGrequiresartifactremoval,espe- beobtainedafteraseriesofdatapreprocessing,duetothe\nciallyinrelationtoimplantsurgery.Artifactsofelectrode particularityofbrainsignals,dataacquisitionequipmentand\ndisplacementornon-neuralactivitythatmayoccurduring costrequirementsarehigh,sothecollectionconditionsare\nsurgery,suchaspatientbodymovement,canbeidentified notnecessarilyavailable.Mostexperimentsarecompleted\nand corrected by simultaneous video recording to ensure basedonexistingpublicdatasets.Themostcommonlyused\ntherecordedsignalpurity[166].ArtifactcorrectioninfMRI eyetrackingdatasets,EEGdatasets,andfMRIdatasetsare\nfocusesonphysiologicalfluctuations,suchasthosecaused summarizedasshowninTable3.\nby heartbeat and breathing[165]. This is usually done by Eye-trackingtechnologyenablesresearcherstocapture\nrecordingsynchronizedphysiologicalsignalsandapplying participants’ eye movements during silent reading with\nregression analysis methods to isolate the effects of these minimalguidanceorinterferencefromtheresearchers.Addi-\nsignalsfromthefMRIdatawiththegoalofretrievingpure tionally, in contrast to lexical decision tasks, eye-tracking\nBOLDresponses. technology can capture linguistic representations as they\nReference reset: Reference reset of EEG and ECoG naturallyoccurineverydaylife,devoidofinterferencefrom\nis necessary because these techniques rely on measuring additionaldecisioncomponentsorresponsemechanismstypi-\nthepotentialdifferencerelativetoareferencepoint.Using callypresentinlexicaldecision-makingtasks.Utilizingstate-\nanaveragereference,thatis,subtractingtheaverageofall of-the-arteye-trackingdevices,thepositionoftheeyecan\nelectrodesfromtheindividualelectrodesignals,canreduce bepreciselydeterminedeverymillisecondwithhighspatial\nthe non-uniformity of local areas, thus making the spatial accuracy,generatingarichanddetaileddataset.Therecorded\ndistributionofsignalsmoreuniformandreliable.Othercom- eyemovementsduringreadingarefrequentlyemployedto\nmonreferencemethodsincludebinauralreference,theuse explore visual word recognition in context[153, 180]. For\nofsymmetricalbodysurfaceelectrodes,whichhelpreduce example,GECO[173]presentsthefirstnaturalreadingeye\ntheartifacteffectoftheoverallreferenceposition[167]. trackingcorpusspecificallyforbilingualsentencereading,\nSpatialcorrection:Avoidingheadmovementartifactsis selecting participants based on their language history and\ncrucialinfMRI,withthehelpofvoxelalignmenttechniques collectingdetailedmeasuresofproficiency.Thesedataare\nsuchasrigidbodytransformationtocorrectheadmovements wellsuitedforresearchatoneormorelanguageprocessing\nduringacquisition[168].Usually,the3Drigidbodyalignment levels[173].Inbrain-inspiredcomputingtasks,eye-tracking\ntechnique is used to adjust the geometric position of each datacanhelpdeterminewordboundaries[20].\nimagerelativetothereferenceimage,soastoavoidtheerror ZuCo[23] is a dataset that integrates EEG and eye-\nintroducedbymotion.Inaddition,slightheadmovements trackingrecordingsofindividualsengagedinreadingnatural\nduringMEGrecordingcanaffectresults,soheadpositioning sentences.Comprisinghigh-densityEEGandeye-tracking\nsensorsareusedtomonitorandcorrectheadmovementsin data,ZuCoincludesrecordsfrom12healthynativeEnglish-\nrealtime.ECoGBecauseofthephysiologicalfixationofthe speaking adults who spent four to six hours each reading\nelectrodeonthesurface,thespatialcorrectionismorerelated naturalEnglishtext.Thisdatasetencompassestwostandard\ntopost-operativefretting,andtheelectrodepositionisoften readingtasksandonetask-specificreadingtask,providing\nrecalibratedbyreferencemarkers[169]. EEG and eye-tracking data for a total of 21,629 words\nTime-frequencyanalysis:EEGandECoGmakeexten- across1,107sentencesand154,173fixationpoints.TheEEG\nsive use of time-frequency analysis to understand the dy- andeye-trackingsignalsfromthisdatasetserveasvaluable\nnamicspectralcharacteristicsofsignals.Short-timeFourier resources for training enhanced machine learning models\ntransform(STFT)andwavelettransformareimportanttools acrossvarioustasks,withaparticularfocusoninformation\ntoobtainfrequencyactivityindifferenttimeperiods[170]. extractiontaskssuchasentityandrelationshipextraction,as\nB.H.Yu et al. Page 10 of 26\nTable 3\nCognitive data sources utilized in this study include the Coverage metric, representing the percentage of vocabulary in the data\nsource that aligns with the list of most frequently occurring English words in the British National Corpus. The statistical results in\nthe table are from [56].\nData type Data source stimulus subject tokens types coverage\nGECO([173]) text 14 68606 5383 95%\nDUNDEE([174]) text 10 58598 9131 94%\nCFILT-SARCASM([175]) text 5 23466 4237 85%\nEYE-TRACKING ZuCo([23]) text 12 13717 4384 90%\nCFILT-SCANPATH([176]) text 5 3677 1314 89%\nPROVO([177]) text 84 2743 1192 95%\nUCL([159]) text 43 1886 711 98%\nZuCo([23]) text 12 13717 4384 90%\nNATURAL SPEECH([157]) speech 19 12000 1625 98%\nEEG\nUCL([178]) text 24 1931 711 98%\nN400([157]) text 9 150 140 100%\nHARRY PORTER([160]) text 8 5169 1295 92%\nALICE([179]) speech 27 2066 588 99%\nfMRI\nPEREIRA([26]) text/image 15 180 180 99%\nNOUNS([25]) image 9 60 60 100%\nwellassentimentanalysis.Furthermore,thedatasetproves Functionalmagneticresonanceimaging(fMRI)stands\ninstrumentalinadvancingresearchonhumanreadingand outamongnon-invasiveneuroimagingtechniques,offering\nlanguagecomprehensionprocesses,delvingintotheintricate thehighestspatialresolution.Thisseriesofinvestigations\ninterplay between brain activity and eye movement at a commenced with Mitchell et al. in 2008, marking the in-\ngranularlevel[155]. auguraldemonstrationofthefeasibilityofdecodingwords\nZuCo2.0[24] introduces a novel and freely accessible from fMRI data. The pioneering approach involved lever-\ncorpus, capturing both eye-tracking and brain electrical agingsemanticrepresentationsofwordsandlearningcross-\nactivityduringnaturalreadingandannotation.Distinguishing modalmappingsbetweenfMRIimagesandwordvectors[25].\nitselfastheinauguraldatasetfacilitatingadirectcomparison Mitchelletal.evaluatedtheirlearnedneurodecoderthrough\nof these two reading paradigms, ZuCo2.0 meticulously apairwiseclassificationtask,abinaryclassificationexercise\ndetails the material and experimental design, undergoing distinguishingwhichoftwostimulicorrespondstoanfMRI\nthoroughvalidationtoensurethedata’squality.Tailoredfor image.Subsequently,thispairedclassificationmethodology\ncognitively inspired Natural Language Processing (NLP), hasbecomewidelyadoptedbyresearchersinnon-invasive\nthiscorpusboastsbroadpotentialforapplicationandreuse. neuraldecodingforworddecodingtasks[19].\nThefurnishedwordlevelandsentenceleveleye-trackingand Insummary,bothEEGandfMRIareusedtostudybrain\nEEGfeaturesofferutilityinenhancingandassessingNLPand activity,andarethetwomostcommonlyusedbrainsignals\nmachine learning methods. Moreover, given the inclusion todecodetextorspeech.Eyemovementdatasetscanplay\nof semantic relational labels and participant comments at anauxiliaryroleindecoding.Thesepublicdatasetspromote\nthesentencelevel,thedatasetprovesvaluableforrelational theresearchofdecodingusingdeeplearningtechniques.\nextraction and classification endeavors. As an upgraded\nversion of the ZuCo dataset. ZuCo2.0 takes into account 3.2. EEG-to-text(speech)\nthe effect of time periods on the test results, intentionally Sensory,language,emotionandotherprocessesarevery\nrepeatingsomestimulustextforbothnormalreadingtasks rapid, and the high temporal resolution of EEG makes it\nandspecialreadingtasks. verysuitableforcapturingthesefast,dynamicandsequential\nAsshowninTable4,thethreetasksandstimuluscontrol cognitiveevents.Therefore,manyresearchersareengaged\nconditionssetintheopendatasetZuCoarelisted.Subjects in the study of decoding text or speech by EEG. The\nrecordEEGdatabyreadingsentencesandansweringcontrol EEG-to-text(speech)taskprovidesaconvenientandwidely\nquestions,whichprovideshighqualityEEGdatasetsrelated applicable means of human-computer interaction by non-\nto natural language processing tasks such as sentiment invasivelymeasuringEEGelectricalsignalsandconverting\nanalysis and information extraction for computer science themintotextorspeech.ThecurrentEEG-to-texttasksaim\nresearchers. toassumethatthehumanbrainactsasaspecialtextencoder,\nimplementinganopenvocabularybrain-to-textsystemusing\nB.H.Yu et al. Page 11 of 26\nTable 4\nIllustration of three task data examples for the ZuCo dataset adapted from[23].\nTask Emotion Classification Entity Extraction Relation Extraction\nPositive, negative, or neutral Wikipedia sentences Wikipedia sentences\nMaterial\nsentences from movie reviews containing specific relations containing specific relations\nTalia Shire (born April 25,\nLincoln was the first\nThe film often achieves a 1946) is an American actress\nData Sample Republican president.\nmesmerizing poetry (positive) of Italian descent.\nRelation: political affiliation\nRelations:nationality,jobtitle\nBased on the previous sentence, Does the sentence contain the\nTask Description how would you rate Talia Shire was a ... political affiliation relation?\n1)singer 2)actress 3)doctor\nthis movie from 1-5? 1)Yes 2)No\nFigure 3: The development of brain-inspired computing models based on deep learning pre-trained language models with EEG\nsignals in recent years.\na pre-trained language model. Figure 3 demonstrates the thecapabilitytoprocessdatafromdiversetopicsandsources,\ndevelopmentofbrain-inspiredcomputingmodelsbasedon indicatingsubstantialpotentialforhigh-performanceopen-\ndeeplearningpre-trainedlanguagemodelswithEEGsignals vocabulary brain-to-text systems as more data becomes\nin recent years. Figure 4 shows the EEG-to-text task flow accessible.\ndiagram.The subjects read sentences on the screen, the In addition, the notable difference between subject-\nresearchers recorded the EEG signal during the reading relevantEEGrepresentationsandsemanticallyrelevanttext\nprocess,andthendecodedthetextthroughtheEEGsignal. representationspresentsasignificantchallengetothistask.\nToaddressthischallenge,Fengetal.[21]proposeacurricular\n3.2.1. RecentProgress SemanticPerceptionContrastiveLearningstrategy(CSCL).\nDecodingbrainstatesintounderstandablerepresentations Thisapproacheffectivelyrecalibratessubject-dependentEEG\nhaslongbeenthefocusofresearch[181].EEGsignalsare representationsintosemanticallydependentEEGrepresenta-\nparticularly favored by researchers because they are non- tions,reducingvariance.CSCLspecificallygroupstogether\ninvasive and easy to record[182, 183]. Traditional EEG semanticallysimilarEEGrepresentationswhileseparating\ndecoding techniques mainly focus on classification tasks, distinctEEGrepresentations.Furthermore,tointroducemore\nsuchasemotionrecognition[184,185,186,187,188],motor meaningfulcontrastpairs,theresearchersmeticulouslyuti-\nimagination[189, 190, 191], robot control[192, 193, 194, lizedcurriculumlearning,notonlyforgeneratingsignificant\n195, 196], and games[197, 198, 199, 200, 201]. However, contrast pairs but also for ensuring progressive learning.\nthesetask-boundtagsarenotsufficientforextensivebrain- Subsequentresearchnotonlydemonstrateditssuperiorityin\ncomputercommunication.Asaresult,interestinbrain-to-text single-agentandlow-resourcesettingsbutalsoshowcased\n(speech)translationhassurgedinrecentyears. stronggeneralizationinzero-samplesettings.\nForexample,theresearchers[20]extendtheproblemto Finally, with the rapid development of large language\nopenwordEEGonnaturalreadingtaskstotextsequence- modelssuchasChatGPT[202,203],in-depthresearchinto\nto-sequence decoding and zero-sample sentence emotion ways to bridge the gap between brain signals and natural\nclassification.Assumingthatthehumanbrainactsasaunique languagerepresentationsbecomescritical.However,theearly\ntextencoder,theauthorsintroduceanovelframeworkthat work[204,205,42,206]andseveralmodelsmentionedabove,\nleveragespre-trainedlanguagemodelsforthefirsttime.The relied on external event markers like handwriting or eye-\nmodel achieved a BLEU-1 score of 40.1% in EEG-to-text trackingfixationswhichmaynotbereadilyavailable.And\ndecodingandanF1scoreof55.6%inzero-sampleEEG-based theorderofeye-trackingdatamaynotcorrespondtotheorder\nternaryemotionclassification,significantlybetterthanthe of spoken words. To address these problems, the authors\nsupervisedbaseline.Furthermore,themodeldemonstrates introduceanovelframework,DeWave[22],whichintegrates\nB.H.Yu et al. Page 12 of 26\nFigure 4: Illustration of the EEG-to-text generation task. The left portion depicts the EEG recording process, where a subject\nreads a sentence on the screen while EEG signals are recorded. Simultaneously, an eye-tracking device facilitates the precise\ndefinitionofwordboundariesthroughfixations.TheobjectiveofthetaskistogeneratethesentencethatelicitstherecordedEEG\nsignals(adapted[21]).\ndiscrete coded sequences into the task of translating open istominimizethecross-entropyloss𝑙 definedby:\n𝑖\nvocabularyEEGtotext.DeWaveusesquantizedvariational\nencoderstoderivediscretecodexcodesandalignthemwith\n𝑙 =−𝑙𝑜𝑔\n𝑒𝑠𝑖𝑚(ℎ 𝑖,ℎ+ 𝑖)∕𝑟\n(2)\npre-trainedlanguagemodels.Thisdiscretecoderepresenta- 𝑖 ∑𝑁 (𝑒𝑠𝑖𝑚(ℎ 𝑖,ℎ+ 𝑖)∕𝜏 +𝑒𝑠𝑖𝑚(ℎ 𝑖,ℎ− 𝑖)∕𝜏)\ntion mitigates sequence mismatches between eye fixation 𝑗=1\nand spoken language and minimizes interference caused where𝜏 isatemperaturehyperparameter.𝑠𝑖𝑚(ℎ,ℎ )isthe\n𝑖 𝑗\nbyindividualdifferencesinbrainwavesbyintroducingtext- cosinesimilarity.\nEEGcontrastalignmenttrainingwhichisthefirsttodecode Secondly,leveragingthecontrastive-trainedpre-encoder,\nEEGsignalsfirstwithouttheneedforword-levelsequential jointlyfine-tuneallparametersoftheBRAINTRANSLATOR\nlabelingscoring20.5BLEU-1and29.5Rouge-1ontheZuCo to minimize the cross-entropy loss in a parallel training\ndataset. corpus(𝐸,𝑆)[57]:\nTo sum up, from decoding words to decoding text to\n∑\ndecodingdirectlywithouttheaidofeye-trackingdata,from 𝐿=− log𝑝(𝑆 |𝐸;𝜃) (3)\nclosed-domain words to open-domain words, researchers (𝐸,𝑆)∈(𝐸,𝑆)\nhaveusedthelatestdeeplearningtechniquesandmethodsto\nDiscrete Codex: The key steps of the DeWave model\ncompleteincreasinglycomplexEEG-to-textdecodingtasks.\nare shown in Figure 5. First, the original brainwave is\nvectorized,thevectorizedfeaturesareencodedintohidden\n3.2.2. KeyTechnologies\nwavevariablesandconvertedintodiscretelatentvariablesby\nEEG-to-text models based on deep learning have ex-\ncodexindex.Finally,thepre-trainedBARTmodelconverts\nperienceddifferentstagesfromclosedvocabularytoopen\nthisdiscretecodexintotext.\nvocabulary,fromdividingwordboundariesbyexternalmeans\nGiven the EEG waves, it is firsted vectorized into em-\ntodirectlytranslatingbrainwaves,andeachmodelhasits\nbedding,where𝑋 istheembeddingsequenceasshownin\nowncontributionsandkeytechniques.\nEquation4.\nEEG-to-textDecoding: Theauthortriestomaximize\nthe probability of decoding the sentence as the following\n𝑧 (𝑋)=𝑧 (𝑥) (4)\nequation: 𝑞 𝑞 𝑖\nAcodexbook𝑐 ∈𝑅𝑘∗𝑚isinitializedwithnumber𝑘oflatent\n𝑇 𝑖\n∏ embeddingwithsize𝑚asshowninEquation5.\n𝑝(𝑆 |𝜀)= 𝑝(𝑠\n𝑡\n∈𝜈 |𝜀,𝑠<𝑡) (1)\n𝑡=1 𝑧 (𝑥)=𝑐 (5)\n𝑞 𝑘\nWhere𝑇 representsthelengthofthetargettextsequence.The\nprimarychallengeintheenvironmentisthatthevocabulary\nThevectorizedfeature𝑋 isencodedinto𝑧 𝑐(𝑋)througha\ntransformerencoderasshowninEquation6.Thediscrete\nsize,denotedas 𝜀 (50,000),isconsiderablylargerthanin\n| | representationisacquiredbycalculatingthenearestembed-\nprevioussequence-to-sequencestudies(250)[42].\nCurriculum Learning: The researchers proposed an dinginthecodexofinputembedding𝑥 ∈ 𝑋 asshownin\nEquation4.\napproachbasedoncurriculumlearning.Theoveralltraining\nprocess adopts a two-step approach. Firstly, CSCL is em-\nployedtotrainthepre-encoder.Formally,acontrastivetriple\n𝑘=𝑎𝑟𝑔𝑚𝑖𝑛 𝑗||𝑧 𝑐(𝑥)−𝑐\n𝑗||2\n(6)\n(𝐸,𝐸+,𝐸−) is obtained for a given anchor 𝐸. After the Dewave directly decodes the translation output given the\n𝑖 𝑖 𝑖 𝑖\ntransformationbythepre-encoder,thecorrespondingvectors representation𝑧 (𝑋).Givenapre-trainedlanguagemodel,\n𝑞\nbecome(ℎ,ℎ+,ℎ−),whereℎ istheaveragedvectorofthe thedecoderpredictstextoutput.\n𝑖 𝑖 𝑖 𝑖\npre-encoderoutputs.Followingthecontrastiveframework Insummary,withthehelpofdeeplearningtechnology,\nin[207,57,73],with𝑁 asthemini-batchsize,theobjective thestudyofEEG-to-textdecodingtaskrelieslessandlesson\ndatasets,andthedecodingaccuracyisgraduallyimproved\nB.H.Yu et al. Page 13 of 26\nFigure 5: The DeWave model vectorizes the original EEG waves into embeddings, the vectorized features are encoded into latent\nvariables by codex indexing into discrete latent variables, and finally, the pre-trained BART model converts this discrete codex\nrepresentation into text(adapted[22]).\n3.3. fMRI-to-text(speech) Secondly,evenwithaperfectlypaireddecoder,theperfor-\nAsfarasverbalstimuliareconcerned,recentresearch manceofdirectclassificationisnotguaranteed.Inorderto\nhasshownthatfMRIscanscanbedecodedintoembeddings addressthesechallengesandadvancerealisticneurodecoders,\nof the words the subject is reading[31]. The fMRI-to-text theauthorsintroduceanovelcross-modalcloze(CMC)task.\n(speech)taskusesfunctionalmagneticresonanceimagingfor Thistaskinvolvespredictingtargetwordsencodedinneural\ntextconversion,andisabletocapturedeepbrainactivitydue imagesusingcontextasacue.Theresultsdemonstratethe\nto its high spatial resolution, providing broad possibilities feasibilityofdecodingasinglewordfromneuralactivityin\nfor human-computer interaction in pursuit of detailed and alargevocabulary[19,20].\ncomplexdecoding.Theresearchofdecodingoftextorspeech AnotherrepresentativeadvancementisUniCoRN.The\nbasedonfMRIisalsograduallyincreasingandfMRIsignals disadvantage of fMRI is its low temporal resolution, and\nhavebeenusedmorerecentlytodecodetext. previous fMRI signal decoding methods often relied on\nfeature extraction for predefined regions of interest (ROI),\n3.3.1. RecentProgress failingtomakefulluseoftimeseriesinformation.UniCoRN\nFMRI provides the best spatial resolution of all non- constructsanefficientencoderthroughsnapshotandsequence\ninvasive neuroimaging techniques[19]. Most of the fMRI- reconstruction,allowingthemodeltodeeplyanalyzethetime\nto-textbasedtasksarepairwiseclassificationtasks[208,206, dependenceandmaximizetheextractionofinformationfrom\n209],ordirectclassificationtasks[31,19]. brainsignals.Specifically,UniCoRNcontainstwokeystages:\nForexample,theauthors[31]proposeamodelfordecod- brainsignalreconstructionandbrainsignaldecoding.The\ningfMRIscansintowords,andverifythedecodingperfor- brain signal reconstruction stage is divided into snapshot\nmanceandgeneralizationperformanceofthemodelthrough reconstruction and sequence reconstruction. The internal\ntwotasksofpair-classificationanddirectclassification.The featuresofeachsnapshotandthetemporalrelationshipofthe\ndirectclassificationtaskistoclassifythebrainscandirectly snapshotsequenceareintegratedbytrainingtheencoder.In\nintooneofthe𝑣wordsinthevocabularyunderconsideration. thebrainsignaldecodingstage,therepresentationofthebrain\nBecausescanningismappedtowordcategoriesratherthanto signalisconvertedintonaturallanguage,eachfMRIframeis\nrepresentationsofwords,thetaskisnotsubjecttolimitations treatedasaword-levelrepresentationofthe\"languagespoken\nassociatedwithspecificvectorrepresentations.Inaddition, bythehumanbrain\",andrealhumanlanguageisgenerated\nwhen there is no data from the target subject at the time throughatextdecoder[35].\nof training, the reserve-one method is used to train the Finally, some researchers have proposed using fMRI\nmodelwithdatafrom𝑛-1subjectsandtestontheremaining signalstoreconstructauditorystimulithatsubjectshearor\nsubjects,repeatingtheprocessforeachsubject.Duetothe imagine[36]. To overcome the low temporal resolution of\nimpossibility of subject-specific preprocessing, the model fMRI, the decoder employs a non-end-to-end strategy of\nrequiresstronggeneralization,andthelackofconsistencyin guessingcandidatewordsequences,assessingthelikelihood\nFMRIscansacrosssubjectsandevenacrossrecordedsessions that each candidate triggers the currently measured brain\nisabigchallenge. response,andselectingthebestcandidatefordecoding.In\nDue to the inherent noise in brain recordings, prior theexperiment,acodingmodelwastrainedforeachsubject\nresearchhassimplifiedbrain-to-worddecodingintoabinary topredictthesemanticrepresentationoftextstimuliandthe\nclassificationtask,aimingtodistinguishwordscorresponding correspondingbrainresponse.Thebeamsearchalgorithm\nto brain signals from incorrect ones. However, this paired isusedtogeneratecandidatesequencesword-by-wordand\nclassificationapproachfaceslimitationsforpracticalneurode- preserve the most likely continuation when detecting new\ncoder development for two reasons. Firstly, it necessitates wordsinbrainactivity.Finally,themostlikelycontinuation\nenumerating all pair combinations in the test set, making ispreservedbyscoringthecodingmodel.\nitinefficientforpredictingwordsinalargevocabulary[19]. Overall, these studies summarize cutting-edge models\nandmethodsfordecodingfMRIsignalsinthebrain-inspired\nB.H.Yu et al. Page 14 of 26\nfield, deepening the understanding of the relationship be-\ntweenbrainactivityandcognitiveprocessessuchaslanguage\nandperception.\n3.3.2. KeyTechnologies\nThebrain-inspiredcomputingmodelbasedonfMRI-to-\ntext has developed from the original binary classification\nmodel to the cross-modal task, which makes the direct\nclassificationtaskpossible.\nBrain Decoding Model: In the model developed in\nthis paper[31], the decoder of the model takes the one-\ndimensional vector of the fMRI scan as input, filling it as\nneeded. By simply changing the output layer and the loss\nfunction,themodelcanbeusedforpairedclassificationtasks. Figure 6: Illustration of the semantic feature fusion method.\nThelossiscalculatedasfollows: Thepre-trainedlanguagemodelBERTisusedtopredicttarget\nwords(adapted[19]).\n𝑣 𝑣\n∑ ∑\n𝜁 reg = cos(𝑦 pr,𝑖,𝑦 true,𝑖)− cos(𝑦 pr,𝑖,𝑦 true,𝑗) (7)\n𝑖=1 𝑗≠𝑖 real-timeresolutionrecordingsofbrainactivityatahigher\nWhere𝑦 isthepredictedwordembeddingsoftheword𝑖, spatialresolutionthanEEGorfMRI[212,213].Accordingto\npr,𝑖\n𝑦\ntrue,𝑗\nisthetruewordembeddingsoftheword𝑗,and𝑐𝑜𝑠() ourresearch,MEGsignalshavebeenusedmorerecentlyto\nisthecosinedistance. decodespeech.TheuniquedatapropertiesofMEGmakeit\nSemantic Features Fusion: Semantic features are ex- suitableforbraindisordersthataretime-andspace-sensitive.\ntractedfromfMRIimagesandcanbeseamlesslyintegrated TheMEG-to-text(speech)taskdecodessignalsbymonitoring\ndirectlyintohiddenstateswithintheBERTembeddinglayer. magneticactivityinthebrain,supportinghuman-computer\nToaddressthecentralityproblem[210],anintermediateword interactionapplicationsthatrequirefastresponseswithits\nembedding is introduced, and a retrieval-based method is superior temporal resolution. Additionally, MEG is quiet\ndevised. The fundamental concept involves utilizing the and,therefore,user-friendly.PriorMEGstudiesonspeech\nintermediate word embedding for cross-modal mapping, perception hold promising prospects for decoding speech\nfollowed by transforming the prediction into the BERT productioninbrainactivitysignals[214,215,216,217,213].\nembeddingspacethroughretrieval[19].\nThefeaturevector𝑓 forfMRItestsampleiscomputed 3.4.1. RecentProgress\n𝑖\nasfollows: Theconvergenceofadvancedmethodologiesandtech-\nnologieshaspavedthewayforbreakthroughsinunderstand-\n1 ∑𝑘 ingthespectralandtemporalcharacteristicsofMEGsignals.\n𝑓 = 𝑤′𝑗 (8)\n𝑖 𝑘 𝑡 Forexample,theresearchersdelvedintothespectraland\n𝑡=1 temporalcharacteristicsofMEGsignalsandtrainedthesefea-\nWhere𝑖={1,…,𝑁}and𝑤′denotesBERTembedding. turesusingCNNtoclassifyneuralsignalscorrespondingto\nTo be specific, let ℎ𝑖 denote the hidden states of specificphrases.ExperimentsshowthatCNNisremarkably\n𝑚𝑎𝑠𝑘\nthe[MASK]token,trytodirectlyupdateℎ𝑖 usingthe effectiveindecodingspeechinperception,imaginationand\n𝑚𝑎𝑠𝑘\nfollowingequation: generationtasks.InordertosolvetheproblemoflongCNN\ntrainingtime,theresearchersusedPCAalgorithmtoreduce\nℎ𝑖 𝑚𝑎𝑠𝑘 =(1−𝛼)ℎ𝑖 𝑚𝑎𝑠𝑘+𝛼𝑓 𝑖 (9) thespatialdimensionofMEGdata,andcarriedoutthemodel\ninitialization through transfer learning. The experimental\nwhere 𝛼 ∈ [0,1] is a tuning parameter that controls how\nresultsshowthattheaccuracyofspeechdecodinginspeech\nmuchinformationtofusein.\ngenerationstageissignificantlyhigherthanthatinperception\nAsillustratedinFigure6,theobjectiveistoincorporate\nandimaginationstage[38].\nfeature vectors extracted from fMRI images into BERT\nInaddition,someresearchersproposeasinglearchitec-\nfor enhanced word prediction. The rationale is that if the\nturedata-drivenapproachfordecodingnaturallanguagefrom\nfeaturevectorcontainsvaluableinformationaboutthetarget\nMEG signals. Convolutional neural networks are used as\nword,integratingitintothemodelshouldenhanceprediction\nencodersofbrainsignalsandtrainedbycontrasttargetsto\nperformance,goingbeyondusingcontextaloneasinput[19].\naligndeepaudiorepresentationsgeneratedbythepre-trained\nInsummary,thesekeytechnologieshaveinnovatedthe\nspeechself-supervisedmodelwav2vec-2.0[218].Inaddition,\nresearchmethodoffMRI-to-texttask,improvedthedecoding\nthe contrast loss of the CLIP[219] model is used to align\naccuracy,andprovidednewideasforsubsequentresearch.\ndeeprepresentationsofthetwomodesoftextandimage,and\nthemodelcanefficientlyencodemultiplelevelsoflinguistic\n3.4. MEG-to-text(speech)\nMEG records magnetic field changes resulting from featuresandhasalinearrelationshipwithbrainactivation.\ncurrent flow in the brain[211] and is capable of obtaining Themethodandideasprovideabasisforsubsequentwork\nB.H.Yu et al. Page 15 of 26\nthat can be effectively migrated to other tasks, including\ndecodingcontinuoustext[41].\nIn summary, as a non-invasive method, MEG has gar-\nneredattentionfromresearchgroupsexploringitsapplication\nindecodingspeechortext.Theseadvancesrepresentthelatest\ninthecurrentMEG-to-text(speech)task.\n3.4.2. KeyTechnologies\nIn the cutting-edge research of MEG signal decoding\ntechnology,thekeytechnologiessuchasconvolutionalneural\nnetworks,transferlearningandsignalalignmenthavenotonly\ndeeplyinfluencedthetheoreticalcognitionofneuroscience,\nbut also promoted the innovation in the field of speech Figure7:ThemodelofthezeroshotMEG-to-speechdecoding\ndecoding. method(adapted[41]).\nCNNsandTransferLearning:Thispaper[38]proposes\nanapproachthattheMEGsignalwasdenoisedbywavelet\nusingmachinelearningtechnology,andthenthePCAspace providing accurate and fast decoding, it is suitable for\ndimensionwasreducedandthePCAcoefficientspectrum human-computer interaction scenarios that require highly\nwas generated. A 3-layer 2D-CNN was then trained using accurateandrapidcontrol.Accordingtoourresearch,ECoG\ndeeplearningtechniquesforeachofthe200gradientsensors. signalshavebeenusedmorerecentlytodecodespeech.Itis\nConv3 features were then extracted from the 200 CNNs particularlysuitableforanalyzingbrainactivityassociated\ntrained to further classify the phrases. Finally, transfer withspeechinhighgamma-band[220,221,46].\nlearningisusedtoreusethepre-trainedmodelfornewdata,\nand transfer the weight of the pre-trained network to the 3.5.1. RecentProgress\nThissectionwillfocusontworecentstudiesthatcover\nnewnetworktoobtainfasterconvergencespeedandbetter\nthe exploration of decoding speech through electrical cor-\nperformance. However, the researchers did not use these\nticography(ECoG)signalsandparsingcontinuoustextusing\npredefinednetworksinMEGsignals,sotheapproachwasto\nmachinetranslationmodels.\nfirstperformneuralspeechdecodingbytrainingCNNSon\nForinstance,employingadeepneuralnetwork-baseden-\nasinglesubject’sdata,andthentransferthelearningweight\ncoderandapre-trainedneuralvocoder,theresearcherseffec-\nofthatsubject’strainedCNNStothenextsubject’sspeech\ntivelyreconstructedspokensentencesfromECoGsignals[46].\ndecoding. The weights of the classification layer, softmax\nWhen 13 participants spoke short sentences, the ECoG\nlayer,andFClayerwerenottrainedusingdatafromanother\nsignalswererecorded,andtheECoGrecordingscouldbe\nsubject[38].\nmapped to spectrographs of spoken sentences using two-\nSignalAlignment:AsshowninFigure7,theresearchers\nway Long short-term memory (BLSTM) or Transformer,\ndecoded speech from brain activity recorded using mag-\ncomparingtheperformanceofthetwoencoders.Inaddition,\nnetoencephalograms or electroencephalograms in healthy\nthecombinationofencodersandneuralvocoderswasevalu-\nparticipantsastheylistenedtosentences.Todothis,their\nated,andtheexperimentfoundthattheuseofTransformer\nmodel extracts deep context representations of 3s speech\nencoders for spectral graph prediction is better than that\nsignalsfromthepre-trainedspeechmodulewav2vec2.0and\nof BLSTM encoders, and their combination with neural\nlearnsthebrain’srepresentations’activityonthecorrespond-\nvocoderscaneffectivelysynthesizespeech[46].\ning 3s window to maximize alignment with these speech\nInthepastresearchondecodingbrainactivity,decoding\nrepresentations with contrast loss. Models with missing\nofcontinuoustextisrelativelyinsufficientandineffective.In\nsentences were input at the time of assessment, and the\nordertodealwiththisproblem,theresearchersconsiderthe\nprobability of each 3-second speech fragment given each\nbrainsignalasthesourcelanguageandthecorresponding\nbrainrepresentationwascalculated.Thus,thefinaldecoding\ncontinuoustextasthetargetlanguage,andusethemachine\ncanbea\"zerosample\"becausetheaudiosnippetpredictedby\ntranslationmodelmethodtodesignasimpleencoder-decoder\nthemodeldoesnotneedtobepresentinthetrainingset[46].\nstructure neural network to decode the continuous text in\nThesetechnicaladvanceshighlightthecontinuousevo-\nthe ECoG signal[42]. By introducing auxiliary loss in the\nlutionofMEGsignaldecoding,andthroughtheintegration\ntrainingstage,themodelisforcedtoaccuratelypredictthe\nof deep learning models, speech processing models and\naudiorepresentationofthespeechatthecorrespondingtime\nneuralsignals,thetechnicalgistofMEGdecodingisdeeply\nbasedonthehiddenlayerrepresentationoftheencoder,so\nunderstood.\nastoimprovetheinformationcaptureabilityoftheencoder.\n3.5. ECoG-to-text(speech) Thestudyachievedsignificantaccuracyimprovements,and\nECoGissuperiortosurfaceEEGintermsofspatiotem- theaverageworderrorrateforsomeparticipantswasreduced\nporal resolution and signal-to-noise ratio[46]. The ECoG- to7%,providingavaluablereferenceforfutureresearch.\nto-text(speech)taskobtainshigh-resolutiondatabydirectly Insummary,ECoGasaninvasivedataacquisitionmethod\nrecording the electrical activity of the cortex, and while has the highest spatial resolution but also has significant\nB.H.Yu et al. Page 16 of 26\nFigure 8: Illustration of the machine translation network architecture. The encoder and decoder are shown unrolled in\ntime(adapted[42]).\nlimitations,andthesenewdevelopmentsfurtherenhancethe sameinputandoutputweights,andarrowsinbothdirections\nunderstandingofECoG-to-speechdecodingtasks. representbidirectionalRNN.\nNeuralVocoder:ParallelWaveGAN[222]isusedtosyn-\n3.5.2. KeyTechnologies thesizespeechwaveforms.ParallelWaveGANisawaveform\nECoGtechnologyhashighspatialandtemporalresolu- generator based on a non-autoregressive WaveNet model\ntionwhenrecordingelectricalactivityinthebrain.Because thatistrainedtosynthesizespeechbasedonagivenMayer\nECoGisclosertothesurfaceofthebrain,itcanprovidemore spectrogram.Theauthorsuseanexistingvocodermodelpre-\naccurateandfine-grainedinformationaboutneuralactivity. trainedonacorpusdatasetcontainingJapanesespeech[46].\nSomeofthelatesttechniquesforECoGsignaldecodingalso Thesetwocoretechnologiesprovidepowerfulwaysto\nincorporateDLmodels. delvedeeperintotherelationshipbetweenbrainsignalsand\nDecodingApproach:Theresearchersconductedacom- speech.\nparisonbetweentheTransformerencoderandtheBLSTM Inthissection,thetasksassociatedwithbrain-inspired\nencoder. The Transformer encoder comprises 𝑋 identical computingforhuman-computerinteractionusingdeeplearn-\nlayers,eachconsistingoftwosub-layers:amulti-headself- ingmodelsarereviewedindetailfromfiveperspectives.In\nattention mechanism and a fully connected feedforward additiontoperspectivesonfourcommonbrainsignals,we\nnetwork.Whenthesetwosub-layersarereplacedbyBLSTM, highlighttheimportanceofdatasets.\nthemodelisreferredtoasaBLSTMencoder[46].Residual\nconnectionandlayernormalizationstrategiesareappliedin\neachofthetwosub-layers.Theoutputfrom𝑋 stacksofthe 4. CHALLENGESANDSOLUTIONS\nsamelayer isfedintoa second-layerfeedforwardnetwork Decodinglanguagefromnon-invasivebrainactivityis\nto represent a sequence of log-mel spectrographs. During of increasing interest to researchers in neuroscience and\nthetrainingoftheencodermodel,theoutputisutilizedto naturallanguageprocessing.Humanbeingshavetheability\napproximate a sequence of log-mel spectrographs with a to adapt to the complex environment, the ability to learn\nlength 𝑁 equal to the output size of the time convolution newthingsindependentlyandtheabilitytocooperatewith\nlayer[46]. avarietyofdifferentcognitiveabilities,butsincethebirth\nThemodelfirstusestime-spanconvolutionforfeature ofartificialintelligence,nogeneralintelligencesystemhas\nextraction, down-sampling the timing features to 16HZ reachedthehumanlevel.Theapplicationofdeeplearning\nand input the features into the LSTM network to generate models in brain-inspired computing for HCI tasks faces\ncontinuous text. In order to guide the encoder to capture several challenges and limitations. These issues must be\nmeaningfulinformation,inadditiontotheend-to-endECoG seriouslyaddressedandresolvedtopromotethedevelopment\nsignaldecodingtexttraining,anadditionalauxiliarylossis andapplicationinthisfield.Inthissection,dividedintosix\nintroducedduringthetrainingphase.Thislossrequiresthe partsfromthreelevels:modeltraining,modelapplication,\nmodeltoaccuratelypredicttheaudiorepresentationofthe and ethical issues, we will delve into the challenges faced\nspeechatthecorrespondingmoment,basedonthehidden bybrain-inspiredcomputingmodelsandproposepotential\nlayerrepresentationoftheencoderateachtimestep[42].The solutions.Specifically,challengesrelatedtomodeltraining\nnetworkarchitectureisshowninFigure8,withencodersand areelaboratedinsections4.1,4.2,and4.3,challengesrelated\ndecodersdisplayedintimeexpansion,i.e.sequenceelements. tomodelapplicationarediscussedinsections4.4and4.5,\nEncoder and decoder all layers in the same row have the and finally, ethical issues are analyzed in section 4.6. The\nB.H.Yu et al. Page 17 of 26\nfollowingarethefactorstoanalyzethechallengesandfuture transfer learning techniques, using models that have been\nresearchdirectionofthesetasks: trained on similar tasks can significantly reduce the need\nfor large-scale data sets and improve model performance\n4.1. ChallengesforBrainDataset insmallsamplecases.Second,throughdataenhancement\nMosthigh-performancemethodsrequiredatafrominva- techniques, small data sets can be manually expanded to\nsivedevices,suchasECoG,whichrequireextremelyhigh improve the generalization ability of the model on more\nconditionstobecollectedandstudied[223,224,225].Non- diverse data. In addition, exploring unsupervised learning\ninvasive device data acquisition, such as fMRI, also has a methodscanreducethedependenceondataannotationand\nlargeequipmentthreshold,andonlyprofessionalinstitutions discoverusefulinformationindatastructures.Intermsof\nhave the acquisition conditions. In addition, due to the computing resources, the development of more efficient\nlimitationofword-levelfeatures,manycurrentmodelsbased trainingandinferencealgorithms,aswellasthedeployment\non EEG data sets need to use eye movement datasets and ofmodelsonspecializedhardwarethatsupportsfastparallel\notherexternalmeanstodemarcatewordboundaries,which computing,canreduceresourcerequirementswithoutsignifi-\nindirectlyincreasesthedifficultyandcostofdatacollection. cantlysacrificingperformance.Combined,thesemethodscan\nAsaresult,therearefewpublichigh-qualitydatasets.For helpresearcherseffectivelyapplydeeplearningmodelsin\nexample,mostoftheEEG-basedbrainsignaldecodingtasks resource-constrainedenvironments,therebyexpandingtheir\nare based on the public ZuCo[23] and ZuCo2.0[24]. The feasibilityandutilityinreal-worldapplications.\nrangeofvocabulariesisalsolimited,andmanymodelsare\nbasedonclosedvocabularies,whichdonotfullyconformto 4.3. AccuracyAndGeneralizationofTheModel\ntheconceptof\"silentspeech\"indirectthoughttranslationby Themostadvancedbrain-to-textsystemshaveachieved\nhumanbrain.Deeplearningmodelstypicallyrequirelarge a degree of precision in using neural networks to decode\ndatasets,andtheirlackofgeneralizationandrobustnessin languagedirectlyfrombrainsignals.However,manycurrent\nsmallsampleenvironmentshasnotbeenfullyaddressed. modelsarelimitedtosmallclosedvocabularies,whichare\nAlthoughthedataobtainedbyinvasivedevicesismore far from sufficient for natural communication. Although\naccurate, researchers should be encouraged to use data DeWave[22] enhances EEG to text translation using dis-\nsets collected by non-invasive devices to improve model cretecodexandrawwavecoding,itsaccuracyisstillpoor\nperformance by improving technical means such as word compared to traditional language-to-language translation.\nembeddingmethods.Forexample,achievingdirectEEG-to- In addition, due to the limitations of data collection in\ntexttranslationisagreatidea,andDeWave[22]’sintroduction EEG-to-text tasks, the maximum number of subjects in\nof discrete coding similar to word embeddings could be the open dataset is 18 at one time[24]. Moreover, due to\na good step toward closing the gap between brainwaves the particularity of EEG data, there are great differences\nand high-level language models. Expand the scope of the among different subjects, so the improvement of model\nvocabularyandconductresearchontheopenvocabularyto generalizationperformanceisalong-termresearchdirection.\nimprovetheusefulnessoffuturebrain-computerinterface. For example. for the fMRI-to-text tasks, how to align\nfMRI signals with individual words when the stimulus is\n4.2. ChallengesforComputationalResource presentedasacontinuoustimeseriesofwordsisthebasisfor\nDemand translatingbrainactivityintotext[19].FortheEEG-to-text\nWhendeeplearningmodelsareappliedtothetraining tasks,wecanstartfromtheperspectiveofwordembedding\nanddecodingofbrainsignaldata,themodelsoftenhavehuge algorithm, compare the characteristics of different word\ndemandsonhugedatasetsandhighcomputationalresources. embeddingalgorithms[56],andimprovetheaccuracyand\nHigh-performancedeeplearningmodelsoftenrequireexten- generalizationperformanceofthemodelbytakingadvantage\nsivetrainingdatatoaccuratelycapturecomplexpatternsand ofgenerativemodelandmachinetranslationmodel.Wecan\nfeatures,butinbrainsignalingresearch,large-scaledatasets alsostartfromtheperspectiveofdatasets,becausedifferent\naredifficulttoobtainbecausethedataacquisitionprocess languages also have a great impact on the generalization\niscomplexandlimitedbyequipmentconditionsandethical performanceofthemodelofconvertingEEGdataintotext.\nconsiderations.Inaddition,thesemodelsarelessrobustin The future needs to collect larger EEG text data sets and\nsmallsampleenvironments,whichmeansthateventhough extendthecurrentframeworktomultilingualenvironments.\ntrainingcostsarehigh,themodelsstruggletoperformwell\nwhenthedataisinsufficient.Inpracticalapplications,dueto 4.4. ChallengesforReal-timeProcessing\nInhuman-computerinteractiveapplications,brain-inspired\nthelimitationofhardwareresources,suchastheprocessing\ncomputing models need to deal with the challenges of\npowerofsmartphonesorthecomputingpowerofportable\nimmediacyanddiversitybroughtbyuserbrainsignalinput\ndevices, this high demand for computing resources often\nwhencombinedwithdeeplearning.First,inordertoprovide\nbecomesanimportantbottleneckinthewideapplicationof\na smooth user experience, the model must respond with\ndeeplearningmodels.\nextremely low latency times, which puts higher real-time\nTo address these challenges, researchers can adopt a\nrequirementsoncomplexdeeplearningmodels.Secondly,\nvarietyofstrategiestooptimizethetrainingandreasoning\nhuman-computer interaction scenarios often require the\nprocesses of deep learning models. First, by introducing\nmodeltoprocessmulti-modalandmulti-channeldata,such\nB.H.Yu et al. Page 18 of 26\nasthecombinationofEEGdataandophthalmicdata,which of physiological signal data is a key issue, because these\nincreases the computational complexity and the burden models need to process a large amount of sensitive brain\nof data processing. In addition, these interactions often signaldata,whichcanleadtopersonalprivacydisclosure\ntake place in resource-constrained environments, such as if improperly used or leaked. Second, algorithmic bias\nsmartphones or wearables, which have limited computing is also an important ethical consideration. When facing\npowerandmemory,makingitmoredifficulttodeployand human-computerinteractionscenarios,themodelneedsto\noperatemodelsefficiently. treatdifferentusergroupsfairly,butifthetrainingdatais\nPotentialsolutionstoimprovethereal-timeperformance incompleteorbiased,itmayleadtodiscriminatoryoutput\nof brain-inspired computational models include a variety andlossofusertrust.\nof strategies. First, model parameters can be reduced by Inaddressingtheseethicalissues,amultifacetedstrategy\nusingmodelcompressionandoptimizationtechniquessuch canbeadopted.Firstofall,intermsofdataprotection,encryp-\nasknowledgedistillationandpruning,effectivelyreducing tiontechnologyanddataanonymizationareadoptedtoensure\nthecomputationalburdenandspeedingupresponsetimes. thesecurityofuserdataduringcollection,transmissionand\nSecondly,deployingedgecomputingcancarryoutpartof storage.Inaddition,strictdatauseprotocolsareimplemented\nthedataprocessingtaskontheterminaldevice,reducingthe tolimitaccesstoanduseofsensitivedata.Secondly,inorder\ndelay of data transmission and achieving more immediate toreducealgorithmbias,themodelshouldbetrainedusing\nfeedback.UsingdedicatedhardwaresuchasGpusinmobile multi-subjectdatasets,anddataenhancementtechniquescan\ndevices or dedicated neural processing units can improve alsobeusedappropriatelytoimprovetherobustnessofthe\nthe speed and efficiency of model execution. In addition, model.Finally,ethicalguidelinesareproposedandfollowed\nlightweight and efficient network architecture is designed, to ensure ethical compliance in technology development\nand asynchronous processing and pipeline optimization andapplication.Throughthesemeasures,wecanensurethe\nallowmultipledatastreamstobeprocessedsimultaneously. ethical and social responsibility of brain-inspired comput-\nThis not only ensures efficient operation in multimodal ingmodelwhilemeetingtheperformancerequirementsof\ninteractions,butalsoensurespersistentreal-timeresponses, human-computerinteraction.\ntherebyenhancingtheoverallhuman-computerinteraction Tosummarise,thissectionpresentssomecurrentchal-\nexperience. lengesandcorrespondingsolutionsforbrain-inspiredcom-\nputationalmodelsappliedtohuman-computerinteraction.\n4.5. ChallengesforBCITechnology\nThecurrentdevelopmentofhuman-computerinteraction\nbasedonbrain-inspiredcomputingisstillfarfromachieving 5. FUTUREDIRECTIONS\ntheperformanceexpectedbyhumanbeings,andfacesmany Thepreviouschaptersummarizessomechallengesfaced\nchallenges:forexample,asignificantfeatureofbrainsignals by HCI for brain-inspired computing models and gives\nishigh-dimensionalandmulti-modal,howtoobtainmore some solutions. This chapter mainly summarizes possible\nbrain data is a difficulty, and the correspondence between future research directions. Inspired by the brain and the\nbrainsignalsandmotion,emotion,language,etc.,needsto continuousprogressanddevelopmentofMLandDLmodels,\nbeexploredmore. theperformanceofHCIforbrain-inspiredcomputingtasks\nInaddition,thecommonnon-invasiveEEGsignalshave and the complexity of tasks that can be solved have been\nseveralproblems:lowsignal-to-noiseratio,lowreliability, improved.Inthefuture,moreapplicationscenarioscanbe\nandunstablesignals.Thesechallengesleadtotheneedfor broadened, BCI systems across language boundaries can\nfurtherexplorationandresearchonefficientalgorithmsto beinvestigated,andparadigmsforshiftingneuralnetwork\nimprove accuracy, solve the curse of dimensionality, and architecturescanbetransformed.\nreducethetimecost.\nMoreover,BCIsystemsrequireuserstobehighlyconcen- 5.1. LandingApplicationofBrain-inspired\ntratedduringtraining,whichwillleadtohighworkloadof Computing\nbrain-computerinteractionsuchasvisualfatigue.Meanwhile, Atpresent,brain-inspiredcomputingmodelsbasedon\nthevolumeandshapeofbrain-computerinterfacedevices machinelearninganddeeplearninghaveexploredmanytasks,\nneedtobefurtherminiaturizedtomakeusersmorecomfort- such as binary classification tasks, information extraction\nableandportable. tasks, and zero-sample emotion recognition tasks. One of\nFurthermore,thebroadeningofbrainchannels,theimple- thefutureresearchdirectionsistoexploremoreapplication\nmentationandperformanceimprovementofbrain-computer scenariosofbrain-inspiredcomputing.Forexample,inthe\ninterface technology give humans the ability to directly fields of medicine and psychology, people with speech\ninterpretandcontrolthoughts,whichinevitablybringsnew disorderscanbehelpedtotrulyachievesilentelectricalbrain\nchallengestohumanprivacyrights,andthereisalsotherisk communication.\nofhacking,whichtouchestheethicalbottomline. The research of human brain intelligence mechanism\ncanalsopromotetheinnovationandexpansionofartificial\n4.6. ChallengesforEthicalConcerns intelligence.Nowadays,neuromorphicchip,brain-computer\nTheethicalproblemsofbrain-inspiredcomputingmodels\ninterfaces, intelligent decision-making and other related\nmainlyfocusonseveralaspects.First,theprivacyprotection\nB.H.Yu et al. Page 19 of 26\nresearchresultsarebasedontheextendeddevelopmentof time relationship between pulses during the information\nbrainscienceandcomputingscienceresearch,thesestudies transmissionprocess,soneuronshavemicroscopicmemory\nstill have a great space for development, and in the future properties[227,228].\nmayevensubvertthecurrenttechnicalcognition.Weshould Asthethirdgenerationofneuralnetworks[229],Spiking\nactively promote the product to create greater value for NeuralNetworks(SNNs)exhibitgreaterbiologicalplausibil-\neconomicdevelopmentandhumansocialprogress. ityacrossmultiplescales.Thisincludesmembranepotential,\nneuronal firing, synaptic transmission, synaptic plasticity,\n5.2. BCIsacrossLanguageBoundaries andthecoordinationofmultiplebrainareas.Crucially,SNNs\nBCIsystemsdecodebrainsignalsintotextorspeechto offerenhancedbiologicalinterpretability,increasedenergy\nassisthumanstointeractwiththeoutsideworld.Different efficiency, and a natural suitability for modeling diverse\nlanguageshavegreatdifferencesinsemanticunderstanding, cognitivefunctionsofthebrain,makingthemwell-suitedfor\nsemanticalignmentandrepresentation.Nowadays,theap- thecreationofbrain-inspiredAI[226].\nplication of both open datasets and existing deep learning Inconclusion,theresearchonbrain-inspiredcomputing\nmodels in brain-inspired computing is mostly based on modelsappliedtoHCIisstillinthepreliminarystage,and\nEnglish.Infact,theapplicationofBCIsystemshouldnotbe therearemanydirectionsworthexploringinthefuture.Cross-\nlimitedtoEnglish-speakingcountries.Forexample,China lingualBcisaremorepractical,whileSNNsthatsimulate\nis a large country with a population of 1.4 billion, and morebiometricfeaturesarealsoafuturetrend.\nthere is also a huge market demand for high-performance\nBCIsystems.Wehopethatoursuggestionscanbringsome\n6. CONCLUSION\ninspiration to researchers to design a dedicated or even\nuniversalBCIsystemforhumansofvariouslanguagesinthe Withthedevelopmentofcomputerscience,neuroscience,\nworldwhichwillbringgoodnewstomorepeoplesuffering braincognitivescienceandpsychology,theacquisitionand\nfromdiseases. analysisofbrainsignalsundervariouscognitivetaskshas\nIn addition, we can consider the brain signal as an becomeanimportantintersection.Focusingonthehuman-\nintermediatebridgeforlanguagetranslation.Forexample,for computer interaction application scenarios of brain signal\nthebrainsignalofthesamething,nomatterwhatlanguagethe decoding text and speech, this study deeply discusses the\nsignalcomesfrom,wecanextractthesemanticinformation brain-inspired computing models based on deep learning,\ncarriedbythebrainsignalitself,andthendecodeanyrequired summarizes the research status, progress and hotspots of\nlanguage.Thisresearchcanenableagreaterdegreeofcross- brain-inspiredcomputingforhuman-computerinteraction,\nlingualBCI. puts forward some existing limitations and gives some\nsolutions. At present, this field is still in the initial stage\n5.3. SpikingNeuralNetwork(SNN) ofdevelopment.Withthecontinuousevolutionofartificial\nIn the past 10 years, artificial intelligence technology intelligencetechnologysuchasdeeplearningandthein-depth\nwith deep neural networks as the main thrust has made intersectionofmulti-disciplinaryfieldssuchasbrainscience,\ngreatprogress.Basedonthis,thatis,thebroaddefinitionof webelievethatnewbreakthroughscanbecontinuouslymade.\nbrain-inspiredcomputing,thispapersummarizestheresearch Therefore, we advocate continuing to pay attention to the\nprogressofbrain-inspiredcomputingmodelsbasedondeep co-evolutionbetweenmulti-disciplines,andsincerelyhope\nlearning and machine learning. In fact, as the most subtle that this review can bring some inspiration to researchers\nintelligentorganinthehumanbody,thehumanbrain,only inthefieldofhuman-computerinteractionofbrain-inspired\noccupies2%to3%ofthebodyweight,butalmostcontrols computingandpromotefutureinnovationandprogress.\nall human behavior, so the performance of brain-inspired\ncomputingbasedondeeplearningisfarlessthanthatofthe\nhuman brain with about 100 billion neurons but very low References\nconsumption. [1] Furber,S.B.:Brain-inspiredcomputing.IETComputers&Digital\nThe human brain possesses the remarkable ability to Techniques10(6),299–305(2016)\n[2] Zhang,Y.,Qu,P.,Ji,Y.,Zhang,W.,Gao,G.,Wang,G.,Song,S.,Li,\nself-organize and coordinate various cognitive functions,\nG.,Chen,W.,Zheng,W.,etal.:Asystemhierarchyforbrain-inspired\nallowingforflexibleadaptationtochangingenvironments.A\ncomputing.Nature586(7829),378–384(2020)\nsignificantchallengeintherealmsofartificialintelligenceand [3] Parhi,K.K.,Unnikrishnan,N.K.:Brain-inspiredcomputing:Models\ncomputationalneuroscienceistheintegrationofmulti-scale andarchitectures.IEEEOpenJournalofCircuitsandSystems1,\nbiologicalprinciplestoconstructbrain-inspiredintelligent 185–204(2020)\n[4] Mehonic,A.,Kenyon,A.J.:Brain-inspiredcomputingneedsamaster\nmodels[226]. SNN is a new generation of artificial neural\nplan.Nature604(7905),255–260(2022)\nnetwork inspired by biology, which is oriented by brain\n[5] Squire,L.R.,Zola-Morgan,S.:Memory:brainsystemsandbehavior.\nscienceanddevelopsalongthedirectionofbrainsimulation. Trendsinneurosciences11(4),170–175(1988)\nIt expresses information flow with 0/1 pulse sequence, [6] Webb,G.I.,Keogh,E.,Miikkulainen,R.:Naïvebayes.Encyclopedia\nthe encoding contains time information, and the internal ofmachinelearning15(1),713–714(2010)\n[7] Noble,W.S.:Whatisasupportvectormachine?Naturebiotechnology\nneuronshavedynamiccharacteristics,suchasevent-driven\n24(12),1565–1567(2006)\nandsparserelease.Itconvertsinputinformationintopulse\n[8] Peterson,L.E.:K-nearestneighbor.Scholarpedia4(2),1883(2009)\nsequence signals through pulse coding. And maintain the\nB.H.Yu et al. Page 20 of 26\n[9] Cox,D.R.:Theregressionanalysisofbinarysequences.Journalof modelsforfmri.Advancesinneuralinformationprocessingsystems\ntheRoyalStatisticalSocietySeriesB:StatisticalMethodology20(2), 31(2018)\n215–232(1958) [31] Affolter,N.,Egressy,B.,Pascual,D.,Wattenhofer,R.:Brain2word:\n[10] Breiman,L.:Randomforests.Machinelearning45,5–32(2001) Improvingbraindecodingmethodsandevaluation.In:MedicalImag-\n[11] Balakrishnama,S.,Ganapathiraju,A.:Lineardiscriminantanalysis- ingMeetsNeuripsWorkshop-34thConferenceonNeuralInformation\na brief tutorial. Institute for Signal and information Processing ProcessingSystems(2020)\n18(1998),1–8(1998) [32] Jain, S., Vo, V., Mahto, S., LeBel, A., Turek, J.S., Huth, A.:\n[12] Wold,S.,Esbensen,K.,Geladi,P.:Principalcomponentanalysis. Interpretablemulti-timescalemodelsforpredictingfmriresponses\nChemometrics and intelligent laboratory systems 2(1-3), 37–52 to continuous natural speech. Advances in Neural Information\n(1987) ProcessingSystems33,13738–13749(2020)\n[13] Shibata,R.:Selectionoftheorderofanautoregressivemodelby [33] Lin,Y.,Hsieh,P.-J.:Neuraldecodingofspeechwithsemantic-based\nakaike’sinformationcriterion.Biometrika63(1),117–126(1976) classification.Cortex154,231–240(2022)\n[14] Nussbaumer,H.J.,Nussbaumer,H.J.:TheFastFourierTransform. [34] Millet,J.,Caucheteux,C.,Boubenec,Y.,Gramfort,A.,Dunbar,E.,\nSpringer,???(1982) Pallier,C.,King,J.-R.,etal.:Towardarealisticmodelofspeech\n[15] Farge,M.:Wavelettransformsandtheirapplicationstoturbulence. processinginthebrainwithself-supervisedlearning.Advancesin\nAnnualreviewoffluidmechanics24(1),395–458(1992) NeuralInformationProcessingSystems35,33428–33443(2022)\n[16] Schirrmeister,R.T.,Springenberg,J.T.,Fiederer,L.D.J.,Glasstetter, [35] Xi,N.,Zhao,S.,Wang,H.,Liu,C.,Qin,B.,Liu,T.:Unicorn:Unified\nM., Eggensperger, K., Tangermann, M., Hutter, F., Burgard, W., cognitivesignalreconstructionbridgingcognitivesignalsandhuman\nBall,T.:Deeplearningwithconvolutionalneuralnetworksforeeg language.arXivpreprintarXiv:2307.05355(2023)\ndecodingandvisualization.Humanbrainmapping38(11),5391– [36] Tang,J.,LeBel,A.,Jain,S.,Huth,A.G.:Semanticreconstruction\n5420(2017) ofcontinuouslanguagefromnon-invasivebrainrecordings.Nature\n[17] Alhagry,S.,Fahmy,A.A.,El-Khoribi,R.A.:Emotionrecognition Neuroscience,1–9(2023)\nbased on eeg using lstm recurrent neural network. International [37] Dash,D.,Ferrari,P.,Malik,S.,Wang,J.:Automaticspeechactivity\nJournal of Advanced Computer Science and Applications 8(10) recognitionfrommegsignalsusingseq2seqlearning.In:20199th\n(2017) InternationalIEEE/EMBSConferenceonNeuralEngineering(NER),\n[18] Sakhavi,S.,Guan,C.,Yan,S.:Learningtemporalinformationfor pp.340–343(2019).IEEE\nbrain-computerinterfaceusingconvolutionalneuralnetworks.IEEE [38] Dash,D.,Ferrari,P.,Heitzman,D.,Wang,J.:Decodingspeechfrom\ntransactionsonneuralnetworksandlearningsystems29(11),5619– singletrialmegsignalsusingconvolutionalneuralnetworksand\n5629(2018) transferlearning.In:201941stAnnualInternationalConferenceof\n[19] Zou,S.,Wang,S.,Zhang,J.,Zong,C.:Cross-modalclozetask:A theIEEEEngineeringinMedicineandBiologySociety(EMBC),pp.\nnewtasktobrain-to-worddecoding.In:FindingsoftheAssociation 5531–5535(2019).IEEE\nforComputationalLinguistics:ACL2022,pp.648–657(2022) [39] Dash, D., Ferrari, P., Wang, J.: Decoding imagined and spoken\n[20] Wang,Z.,Ji,H.:Openvocabularyelectroencephalography-to-text phrasesfromnon-invasiveneural(meg)signals.Frontiersinneu-\ndecodingandzero-shotsentimentclassification.In:Proceedingsof roscience14,290(2020)\ntheAAAIConferenceonArtificialIntelligence,vol.36,pp.5350– [40] Dash,D.,Wisler,A.,Ferrari,P.,Davenport,E.M.,Maldjian,J.,Wang,\n5358(2022) J.:Megsensorselectionforneuralspeechdecoding.IEEEAccess8,\n[21] Feng, X., Feng, X., Qin, B., Liu, T.: Aligning semantic 182320–182337(2020)\nin brain and language: A curriculum contrastive method for [41] Défossez, A., Caucheteux, C., Rapin, J., Kabeli, O., King, J.-R.:\nelectroencephalography-to-textgeneration.IEEETransactionson Decoding speech perception from non-invasive brain recordings.\nNeuralSystemsandRehabilitationEngineering(2023) NatureMachineIntelligence,1–11(2023)\n[22] Duan, Y., Zhou, J., Wang, Z., Wang, Y.-K., Lin, C.-T.: Dewave: [42] Makin, J.G., Moses, D.A., Chang, E.F.: Machine translation of\nDiscreteeegwavesencodingforbraindynamicstotexttranslation. corticalactivitytotextwithanencoder–decoderframework.Nature\narXivpreprintarXiv:2309.14030(2023) neuroscience23(4),575–582(2020)\n[23] Hollenstein,N.,Rotsztejn,J.,Troendle,M.,Pedroni,A.,Zhang,C., [43] Sun, P., Anumanchipalli, G.K., Chang, E.F.: Brain2char: a deep\nLanger,N.:Zuco,asimultaneouseegandeye-trackingresourcefor architecturefordecodingtextfrombrainrecordings.Journalofneural\nnaturalsentencereading.Scientificdata5(1),1–13(2018) engineering17(6),066015(2020)\n[24] Hollenstein, N., Troendle, M., Zhang, C., Langer, N.: Zuco 2.0: [44] Chen, X., Wang, R., Khalilian-Gourtani, A., Yu, L., Dugan, P.,\nAdatasetofphysiologicalrecordingsduringnaturalreadingand Friedman,D.,Doyle,W.,Devinsky,O.,Wang,Y.,Flinker,A.:A\nannotation.arXivpreprintarXiv:1912.00903(2019) neuralspeechdecodingframeworkleveragingdeeplearningand\n[25] Mitchell,T.M.,Shinkareva,S.V.,Carlson,A.,Chang,K.-M.,Malave, speechsynthesis.bioRxiv,2023–09(2023)\nV.L., Mason, R.A., Just, M.A.: Predicting human brain activity [45] Berezutskaya,J.,Freudenburg,Z.V.,Vansteensel,M.J.,Aarnoutse,\nassociatedwiththemeaningsofnouns.science320(5880),1191– E.J.,Ramsey,N.F.,Gerven,M.A.:Directspeechreconstructionfrom\n1195(2008) sensorimotorbrainactivitywithoptimizeddeeplearningmodels.\n[26] Pereira,F.,Lou,B.,Pritchett,B.,Ritter,S.,Gershman,S.J.,Kan- JournalofNeuralEngineering20(5),056010(2023)\nwisher,N.,Botvinick,M.,Fedorenko,E.:Towardauniversaldecoder [46] Shigemi,K.,Komeiji,S.,Mitsuhashi,T.,Iimura,Y.,Suzuki,H.,\noflinguisticmeaningfrombrainactivation.Naturecommunications Sugano, H., Shinoda, K., Yatabe, K., Tanaka, T.: Synthesizing\n9(1),963(2018) speechfromecogwithacombinationoftransformer-basedencoder\n[27] Krishna,G.,Han,Y.,Tran,C.,Carnahan,M.,Tewfik,A.H.:State-of- and neural vocoder. In: ICASSP 2023-2023 IEEE International\nthe-artspeechrecognitionusingeegandtowardsdecodingofspeech ConferenceonAcoustics,SpeechandSignalProcessing(ICASSP),\nspectrumfromeeg.arXivpreprintarXiv:1908.05743(2019) pp.1–5(2023).IEEE\n[28] Cooney,C.,Korik,A.,Folli,R.,Coyle,D.:Evaluationofhyperparam- [47] Daly,J.J.,Wolpaw,J.R.:Brain–computerinterfacesinneurological\neteroptimizationinmachineanddeeplearningmethodsfordecoding rehabilitation.TheLancetNeurology7(11),1032–1043(2008)\nimaginedspeecheeg.Sensors20(16),4629(2020) [48] Qu,P.,Yang,L.,Zheng,W.,Zhang,Y.:Areviewofbasicsoftwarefor\n[29] Lee,Y.-E.,Lee,S.-H.:Eeg-transformer:Self-attentionfromtrans- brain-inspiredcomputing.CCFTransactionsonHighPerformance\nformerarchitecturefordecodingeegofimaginedspeech.In:2022 Computing4(1),34–42(2022)\n10thInternationalWinterConferenceonBrain-ComputerInterface [49] Hendy,H.,Merkel,C.:Reviewofspike-basedneuromorphiccom-\n(BCI),pp.1–4(2022).IEEE putingforbrain-inspiredvision:biology,algorithms,andhardware.\n[30] Jain,S.,Huth,A.:Incorporatingcontextintolanguageencoding JournalofElectronicImaging31(1),010901–010901(2022)\nB.H.Yu et al. Page 21 of 26\n[50] Liu,F.,Zheng,H.,Ma,S.,Zhang,W.,Liu,X.,Chua,Y.,Shi,L., A.Y.:Improvingtheperformanceofp300bcisystemusingdifferent\nZhao,R.:Advancingbrain-inspiredcomputingwithhybridneural methods.NetworkModelingAnalysisinHealthInformaticsand\nnetworks.NationalScienceReview,066(2024) Bioinformatics9,1–13(2020)\n[51] Son,J.,Mishra,A.K.:Asurveyofbraininspiredtechnologiesfor [70] Hamedi,M.,Salleh,S.-H.,Noor,A.M.:Electroencephalographic\nengineering. In: 2016 Pattern Recognition Association of South motorimagerybrainconnectivityanalysisforbci:areview.Neural\nAfrica and Robotics and Mechatronics International Conference computation28(6),999–1041(2016)\n(PRASA-RobMech),pp.1–6(2016).IEEE [71] Jin,J.,Miao,Y.,Daly,I.,Zuo,C.,Hu,D.,Cichocki,A.:Correlation-\n[52] Park,T.J.,Deng,S.,Manna,S.,Islam,A.N.,Yu,H.,Yuan,Y.,Fong, basedchannelselectionandregularizedfeatureoptimizationformi-\nD.D.,Chubykin,A.A.,Sengupta,A.,Sankaranarayanan,S.K.,etal.: basedbci.NeuralNetworks118,262–270(2019)\nComplexoxidesforbrain-inspiredcomputing:Areview.Advanced [72] Fiscon, G., Weitschek, E., Cialini, A., Felici, G., Bertolazzi, P.,\nMaterials35(37),2203352(2023) DeSalvo,S.,Bramanti,A.,Bramanti,P.,DeCola,M.C.:Combining\n[53] Li,G.,Deng,L.,Tang,H.,Pan,G.,Tian,Y.,Roy,K.,Maass,W.: eeg signal processing with supervised methods for alzheimer’s\nBraininspiredcomputing:Asystematicsurveyandfuturetrends. patientsclassification.BMCmedicalinformaticsanddecisionmaking\nAuthoreaPreprints(2023) 18(1),1–10(2018)\n[54] Gu,X.,Cao,Z.,Jolfaei,A.,Xu,P.,Wu,D.,Jung,T.-P.,Lin,C.- [73] Saeidi, M., Karwowski, W., Farahani, F.V., Fiok, K., Taiar, R.,\nT.:Eeg-basedbrain-computerinterfaces(bcis):Asurveyofrecent Hancock, P., Al-Juaid, A.: Neural decoding of eeg signals with\nstudiesonsignalsensingtechnologiesandcomputationalintelligence machinelearning:Asystematicreview.BrainSciences11(11),1525\napproachesandtheirapplications.IEEE/ACMtransactionsoncom- (2021)\nputationalbiologyandbioinformatics18(5),1645–1666(2021) [74] Tan,P.-N.,Steinbach,M.,Kumar,V.:Classification:basicconcepts,\n[55] Kalagi,S.,Machado,J.,Carvalho,V.,Soares,F.,Matos,D.:Brain decisiontrees,andmodelevaluation.Introductiontodatamining1,\ncomputerinterfacesystemsusingnon-invasiveelectroencephalogram 145–205(2006)\nsignal:Aliteraturereview.In:2017InternationalConferenceon [75] Rakshit, A., Khasnobish, A., Tibarewala, D.: A naïve bayesian\nEngineering,TechnologyandInnovation(ICE/ITMC),pp.1578– approachtolowerlimbclassificationfromeegsignals.In:2016\n1583(2017).IEEE 2ndInternationalConferenceonControl,Instrumentation,Energy&\n[56] Hollenstein, N., Torre, A., Langer, N., Zhang, C.: Cognival: A Communication(CIEC),pp.140–144(2016).IEEE\nframeworkforcognitivewordembeddingevaluation.arXivpreprint [76] Hosseini, M.-P., Hosseini, A., Ahi, K.: A review on machine\narXiv:1909.09001(2019) learningforeegsignalprocessinginbioengineering.IEEEreviews\n[57] Wang,B.,Fu,X.,Lan,Y.,Zhang,L.,Xiang,Y.:Largetransformers inbiomedicalengineering14,204–218(2020)\narebettereeglearners.arXivpreprintarXiv:2308.11654(2023) [77] Machado,J.,Balbinot,A.,Schuck,A.:Astudyofthenaivebayes\n[58] Smith, S.M.: Overview of fmri analysis. The British Journal of classifierforanalyzingimaginarymovementeegsignalsusingthe\nRadiology77(suppl_2),167–175(2004) periodogramasspectralestimator.In:2013ISSNIPBiosignalsand\n[59] Peters,M.E.,Neumann,M.,Iyyer,M.,Gardner,M.,Clark,C.,Lee, BioroboticsConference:BiosignalsandRoboticsforBetterandSafer\nK.,Zettlemoyer,L.:Deepcontextualizedwordrepresentations.In: Living(BRC),pp.1–4(2013).IEEE\nProceedingsofthe2018ConferenceoftheNorthAmericanChapter [78] He, L., Hu, D., Wan, M., Wen, Y., Von Deneen, K.M., Zhou,\noftheAssociationforComputationalLinguistics:HumanLanguage M.: Common bayesian network for classification of eeg-based\nTechnologies,Volume1(LongPapers),pp.2227–2237.Association multiclassmotorimagerybci.IEEETransactionsonSystems,man,\nforComputationalLinguistics,NewOrleans,Louisiana(2018).https: andcybernetics:systems46(6),843–854(2015)\n//doi.org/10.18653/v1/N18-1202.https://aclanthology.org/N18- [79] Oktavia,N.Y.,Wibawa,A.D.,Pane,E.S.,Purnomo,M.H.:Human\n1202 emotionclassificationbasedoneegsignalsusingnaïvebayesmethod.\n[60] Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez, In:2019InternationalSeminaronApplicationforTechnologyof\nA.N.,Kaiser,Ł.,Polosukhin,I.:Attentionisallyouneed.Advances InformationandCommunication(iSemantic),pp.319–324(2019).\ninneuralinformationprocessingsystems30(2017) IEEE\n[61] Devlin,J.,Chang,M.-W.,Lee,K.,Toutanova,K.:Bert:Pre-training [80] Lestari,F.P.,Haekal,M.,Edison,R.E.,Fauzy,F.R.,Khotimah,S.N.,\nofdeepbidirectionaltransformersforlanguageunderstanding.arXiv Haryanto,F.:Epilepticseizuredetectionineegsbyusingrandom\npreprintarXiv:1810.04805(2018) treeforest,naïvebayesandknnclassification.In:JournalofPhysics:\n[62] Radford,A.,Wu,J.,Child,R.,Luan,D.,Amodei,D.,Sutskever,I.,et ConferenceSeries,vol.1505,p.012055(2020).IOPPublishing\nal.:Languagemodelsareunsupervisedmultitasklearners.OpenAI [81] Reshmi,G.,Amal,A.:Designofabcisystemforpilotingawheelchair\nblog1(8),9(2019) usingfiveclassmibasedeeg.In:2013ThirdInternationalConference\n[63] Lewis,M.,Liu,Y.,Goyal,N.,Ghazvininejad,M.,Mohamed,A., onAdvancesinComputingandCommunications,pp.25–28(2013).\nLevy,O.,Stoyanov,V.,Zettlemoyer,L.:Bart:Denoisingsequence- IEEE\nto-sequencepre-trainingfornaturallanguagegeneration,translation, [82] Wang,H.,Zhang,Y.,etal.:Detectionofmotorimageryeegsignals\nandcomprehension.arXivpreprintarXiv:1910.13461(2019) employingnaïvebayesbasedlearningprocess.Measurement86,\n[64] Gürkök,H.,Nijholt,A.:Brain–computerinterfacesformultimodal 148–158(2016)\ninteraction:asurveyandprinciples.InternationalJournalofHuman- [83] Sagee,G.,Hema,S.:Eegfeatureextractionandclassificationin\nComputerInteraction28(5),292–307(2012) multiclassmultiusermotorimagerybraincomputerinterfaceusing\n[65] Mridha,M.F.,Das,S.C.,Kabir,M.M.,Lima,A.A.,Islam,M.R., bayesiannetworkandann.In:2017InternationalConferenceon\nWatanobe,Y.: Brain-computerinterface: Advancementandchal- IntelligentComputing,InstrumentationandControlTechnologies\nlenges.Sensors21(17),5746(2021) (ICICICT),pp.938–943(2017).IEEE\n[66] Zhang,Y.,Zhou,G.,Jin,J.,Wang,X.,Cichocki,A.:Ssveprecognition [84] Isa,N.M.,Amir,A.,Ilyas,M.,Razalli,M.:Motorimageryclassifica-\nusingcommonfeatureanalysisinbrain–computerinterface.Journal tioninbraincomputerinterface(bci)basedoneegsignalbyusing\nofneurosciencemethods244,8–15(2015) machinelearningtechnique.BulletinofElectricalEngineeringand\n[67] Luo,A.,Sullivan,T.J.:Auser-friendlyssvep-basedbrain–computer Informatics8(1),269–275(2019)\ninterfaceusingatime-domainclassifier.Journalofneuralengineering [85] Aggarwal,S.,Chugh,N.:Signalprocessingtechniquesformotor\n7(2),026010(2010) imagerybraincomputerinterface:Areview.Array1,100003(2019)\n[68] Fazel-Rezai,R.,Allison,B.Z.,Guger,C.,Sellers,E.W.,Kleih,S.C., [86] Lal,T.N.,Schroder,M.,Hinterberger,T.,Weston,J.,Bogdan,M.,\nKübler,A.:P300braincomputerinterface:currentchallengesand Birbaumer,N.,Scholkopf,B.:Supportvectorchannelselectionin\nemergingtrends.Frontiersinneuroengineering,14(2012) bci.IEEEtransactionsonbiomedicalengineering51(6),1003–1010\n[69] Fouad,I.A.,Labib,F.E.-Z.M.,Mabrouk,M.S.,Sharawy,A.A.,Sayed, (2004)\nB.H.Yu et al. Page 22 of 26\n[87] Arbabi, E., Shamsollahi, M., Sameni, R.: Comparison between stationarymatrixlogisticregressioninbrain–computerinterface.\neffectivefeaturesusedforthebayesianandthesvmclassifiersinbci. IEEEtransactionsonneuralnetworksandlearningsystems27(11),\nIn:2005IEEEEngineeringinMedicineandBiology27thAnnual 2301–2313(2015)\nConference,pp.5365–5368(2006).IEEE [106] Tomioka,R.,Aihara,K.,Müller,K.-R.:Logisticregressionforsingle\n[88] Li,Y.,Guan,C.,Li,H.,Chin,Z.:Aself-trainingsemi-supervisedsvm trialeegclassification.Advancesinneuralinformationprocessing\nalgorithmanditsapplicationinaneeg-basedbraincomputerinterface systems19(2006)\nspellersystem.PatternRecognitionLetters29(9),1285–1294(2008) [107] Fiebig,K.-H.,Jayaram,V.,Peters,J.,Grosse-Wentrup,M.:Multi-\n[89] Hortal,E.,Úbeda,A.,Iáñez,E.,Planelles,D.,Azorin,J.M.:Online tasklogisticregressioninbrain-computerinterfaces.In:2016IEEE\nclassificationoftwomentaltasksusingasvm-basedbcisystem. InternationalConferenceonSystems,Man,andCybernetics(SMC),\nIn: 2013 6th International IEEE/EMBS Conference on Neural pp.002307–002312(2016).IEEE\nEngineering(NER),pp.1307–1310(2013).IEEE [108] Siuly, S., Li, Y., Zhang, Y., Siuly, S., Li, Y., Zhang, Y.: Cross-\n[90] Hou,H.-R.,Meng,Q.-H.,Zeng,M.,Sun,B.:Improvingclassification correlationaidedlogisticregressionmodelfortheidentificationof\nofslowcorticalpotentialsignalsforbcisystemswithpolynomial motorimageryeegsignalsinbciapplications.EEGSignalAnalysis\nfittingandvotingsupportvectormachine.IEEESignalProcessing andClassification:TechniquesandApplications,153–172(2016)\nLetters25(2),283–287(2017) [109] Miladinović,A.,Ajčević,M.,Battaglini,P.P.,Silveri,G.,Ciacchi,\n[91] Palaniappan,R.,Sundaraj,K.,Sundaraj,S.:Acomparativestudy G.,Morra,G.,Jarmolowska,J.,Accardo,A.:Slowcorticalpotential\nofthesvmandk-nnmachinelearningalgorithmsforthediagnosis bciclassificationusingsparsevariationalbayesianlogisticregression\nofrespiratorypathologiesusingpulmonaryacousticsignals.BMC with automatic relevance determination. In: XV Mediterranean\nbioinformatics15,1–8(2014) ConferenceonMedicalandBiologicalEngineeringandComputing–\n[92] Osowski,S.,Siwek,K.,Markiewicz,T.:Mlpandsvmnetworks- MEDICON2019:ProceedingsofMEDICON2019,September26-28,\na comparative study. In: Proceedings of the 6th Nordic Signal 2019,Coimbra,Portugal,pp.1853–1860(2020).Springer\nProcessingSymposium,2004.NORSIG2004.,pp.37–40(2004). [110] Ramzan,M.,Dawn,S.:Learning-basedclassificationofvalence\nIEEE emotionfromelectroencephalography.InternationalJournalofNeu-\n[93] Moctezuma,L.A.,Molinas,M.:Classificationoflow-densityeeg roscience129(11),1085–1093(2019)\nforepilepticseizuresbyenergyandfractalfeaturesbasedonemd. [111] Edla,D.R.,Mangalorekar,K.,Dhavalikar,G.,Dodia,S.:Classifica-\nJournalofbiomedicalresearch34(3),180(2020) tionofeegdataforhumanmentalstateanalysisusingrandomforest\n[94] Trambaiolli,L.R.,Lorena,A.C.,Fraga,F.J.,Kanda,P.A.,Anghinah, classifier.Procediacomputerscience132,1523–1532(2018)\nR.,Nitrini,R.:Improvingalzheimer’sdiseasediagnosiswithmachine [112] Antoniou,E.,Bozios,P.,Christou,V.,Tzimourta,K.D.,Kalafatakis,\nlearningtechniques.ClinicalEEGandneuroscience42(3),160–165 K.,G.Tsipouras,M.,Giannakeas,N.,Tzallas,A.T.:Eeg-basedeye\n(2011) movementrecognitionusingbrain–computerinterfaceandrandom\n[95] Murugavel,A.M.,Ramakrishnan,S.:Hierarchicalmulti-classsvm forests.Sensors21(7),2339(2021)\nwithelmkernelforepilepticeegsignalclassification.Medical& [113] Kumar,J.L.M.,Rashid,M.,Musa,R.M.,Razman,M.A.M.,Sulaiman,\nbiologicalengineering&computing54,149–161(2016) N., Jailani, R., Majeed, A.P.A.: The classification of eeg-based\n[96] Hortal,E.,Planelles,D.,Costa,A.,Iánez,E.,Úbeda,A.,Azorín,J.M., winkingsignals:atransferlearningandrandomforestpipeline.PeerJ\nFernández,E.:Svm-basedbrain–machineinterfaceforcontrollinga 9,11182(2021)\nrobotarmthroughfourmentaltasks.Neurocomputing151,116–121 [114] Peña,D.M.C.,Miranda,M.V.,Pineda,L.V.,García,C.A.R.,Guzmán,\n(2015) A.S.:Eegsignal-basedeyeblinkclassifierusingrandomforestfor\n[97] Mehmood,R.M.,Lee,H.J.:Emotionclassificationofeegbrainsignal bcisystems.In:2022IEEEInternationalConferenceonEngineering\nusing svm and knn. In: 2015 IEEE International Conference on Veracruz(ICEV),pp.1–5(2022).IEEE\nMultimedia&ExpoWorkshops(ICMEW),pp.1–5(2015).IEEE [115] Nayak,D.R.,Dash,R.,Majhi,B.:Brainmrimageclassification\n[98] Du, S.-C., Huang, D.-L., Wang, H.: An adaptive support vector usingtwo-dimensionaldiscretewavelettransformandadaboostwith\nmachine-basedworkpiecesurfaceclassificationsystemusinghigh- randomforests.Neurocomputing177,188–197(2016)\ndefinition metrology. IEEE Transactions on Instrumentation and [116] Anitha,R.,SivaSundharaRaja,D.:Developmentofcomputer-aided\nMeasurement64(10),2590–2604(2015) approachforbraintumordetectionusingrandomforestclassifier.\n[99] Yazdani, A., Ebrahimi, T., Hoffmann, U.: Classification of eeg InternationalJournalofImagingSystemsandTechnology28(1),\nsignals using dempster shafer theory and a k-nearest neighbor 48–53(2018)\nclassifier.In:20094thInternationalIEEE/EMBSConferenceon [117] Okumuş,H.,Aydemır,Ö.:Randomforestclassificationforbrain\nNeuralEngineering,pp.327–330(2009).IEEE computerinterfaceapplications.In:201725thSignalProcessingand\n[100] Rajini,N.H.,Bhavani,R.:Classificationofmribrainimagesusingk- CommunicationsApplicationsConference(SIU),pp.1–4(2017).\nnearestneighborandartificialneuralnetwork.In:2011International IEEE\nConferenceonRecentTrendsinInformationTechnology(ICRTIT), [118] Bandos, T.V., Bruzzone, L., Camps-Valls, G.: Classification of\npp.563–568(2011).IEEE hyperspectralimageswithregularizedlineardiscriminantanalysis.\n[101] Awan,U.I.,Rajput,U.,Syed,G.,Iqbal,R.,Sabat,I.,Mansoor,M.: IEEETransactionsonGeoscienceandRemoteSensing47(3),862–\nEffectiveclassificationofeegsignalsusingk-nearestneighboralgo- 873(2009)\nrithm.In:2016InternationalConferenceonFrontiersofInformation [119] Tharwat,A.,Gaber,T.,Ibrahim,A.,Hassanien,A.E.:Lineardiscrimi-\nTechnology(FIT),pp.120–124(2016).IEEE nantanalysis:Adetailedtutorial.AIcommunications30(2),169–190\n[102] Yudhana,A.,Muslim,A.,Wati,D.E.,Puspitasari,I.,Azhari,A., (2017)\nMardhia,M.M.:Humanemotionrecognitionbasedoneegsignal [120] Lotte,F.,Congedo,M.,Lécuyer,A.,Lamarche,F.,Arnaldi,B.:A\nusingfastfouriertransformandk-nearestneighbor.Adv.Sci.Technol. reviewofclassificationalgorithmsforeeg-basedbrain–computer\nEng.Syst.J5(6),1082–1088(2020) interfaces.Journalofneuralengineering4(2),1(2007)\n[103] Beyer, K., Goldstein, J., Ramakrishnan, R., Shaft, U.: When is [121] Gareis,I.E.,Acevedo,R.C.,Atum,Y.V.,Gentiletti,G.G.,Banuelos,\n“nearestneighbor”meaningful?In:DatabaseTheory—ICDT’99: V.M.,Rufiner,H.L.:Determinationofanoptimaltrainingstrategy\n7thInternationalConferenceJerusalem,Israel,January10–12,1999 for a bci classification task with lda. In: 2011 5th International\nProceedings7,pp.217–235(1999).Springer IEEE/EMBSConferenceonNeuralEngineering,pp.286–289(2011).\n[104] Ryali,S.,Supekar,K.,Abrams,D.A.,Menon,V.:Sparselogistic IEEE\nregressionforwhole-brainclassificationoffmridata.NeuroImage [122] Xu,P.,Yang,P.,Lei,X.,Yao,D.:Anenhancedprobabilisticldafor\n51(2),752–764(2010) multi-classbraincomputerinterface.PloSone6(1),14634(2011)\n[105] Zeng,H.,Song,A.:Optimizingsingle-trialeegclassificationby [123] Ishfaque,A.,Awan,A.J.,Rashid,N.,Iqbal,J.:Evaluationofann,\nB.H.Yu et al. Page 23 of 26\nldaanddecisiontreesforeegbasedbraincomputerinterface.In: quantization.JournalofTelecommunication,ElectronicandCom-\n2013IEEE9thInternationalConferenceonEmergingTechnologies puterEngineering(JTEC)9(2-5),71–74(2017)\n(ICET),pp.1–6(2013).IEEE [141] Amin, H.U., Hafeez, Y., Reza, M.F., Adil, S.H., Hasan, R.A.,\n[124] Rashid, M., Sulaiman, N., Mustafa, M., Khatun, S., Bari, B.S.: Ali,S.S.A.:Eegfeatureextractionwithfastfouriertransformfor\nTheclassificationofeegsignalusingdifferentmachinelearning investigating different brain regions in cognitive and reasoning\ntechniquesforbciapplication.In:RobotIntelligenceTechnology activity.In:2022IEEE5thInternationalSymposiuminRobotics\nandApplications:6thInternationalConference,RiTA2018,Kuala andManufacturingAutomation(ROMA),pp.1–4(2022).IEEE\nLumpur,Malaysia,December16–18,2018,RevisedSelectedPapers [142] Djamal, E.C., Indrawan, R., Pratama, J., Renaldi, F.: Eeg based\n6,pp.207–221(2019).Springer neuropsychologyofadvertisingvideousingfastfouriertransformand\n[125] Molla,M.K.I.,Saha,S.K.,Yasmin,S.,Islam,M.R.,Shin,J.:Trial supportvectormachine.JournalofTelecommunication,Electronic\nregenerationwithsubbandsignalsformotorimageryclassification andComputerEngineering(JTEC)9(3-7),105–109(2017)\ninbciparadigm.IEEEAccess9,7632–7642(2021) [143] Azim,M.R.,Amin,M.S.,Haque,S.A.,Ambia,M.N.,Shoeb,M.A.:\n[126] Bostanov, V.: Bci competition 2003-data sets ib and iib: feature ofhumansleepeegsignalsusingwavelettransformandfouriertrans-\nextractionfromevent-relatedbrainpotentialswiththecontinuous form.In:20102ndInternationalConferenceonSignalProcessing\nwavelettransformandthet-valuescalogram.IEEETransactionson Systems,vol.3,pp.3–701(2010).IEEE\nBiomedicalengineering51(6),1057–1061(2004) [144] Akin,M.:Comparisonofwavelettransformandfftmethodsinthe\n[127] Xia, M., Song, S., Yao, L., Long, Z.: An empirical comparison analysisofeegsignals.Journalofmedicalsystems26,241–247\nofdifferentldamethodsinfmri-basedbrainstatesdecoding.Bio- (2002)\nMedicalMaterialsandEngineering26(s1),1185–1192(2015) [145] Kousarrizi,M.R.N.,Ghanbari,A.A.,Teshnehlab,M.,Shorehdeli,\n[128] Scherer,R.,Muller,G.,Neuper,C.,Graimann,B.,Pfurtscheller, M.A.,Gharaviri,A.:Featureextractionandclassificationofeeg\nG.:Anasynchronouslycontrolledeeg-basedvirtualkeyboard:im- signalsusingwavelettransform,svmandartificialneuralnetworks\nprovementofthespellingrate.IEEETransactionsonBiomedical forbraincomputerinterfaces.In:2009InternationalJointConference\nEngineering51(6),979–984(2004) onBioinformatics,SystemsBiologyandIntelligentComputing,pp.\n[129] Garcia,G.N.,Ebrahimi,T.,Vesin,J.-M.:Supportvectoreegclassi- 352–355(2009).IEEE\nficationinthefourierandtime-frequencycorrelationdomains.In: [146] AlGhayab,H.R.,Li,Y.,Siuly,S.,Abdulla,S.:Afeatureextraction\nFirstInternationalIEEEEMBSConferenceonNeuralEngineering, techniquebasedontunableq-factorwavelettransformforbrainsignal\n2003.ConferenceProceedings.,pp.591–594(2003).IEEE classification.Journalofneurosciencemethods312,43–52(2019)\n[130] Kottaimalai,R.,Rajasekaran,M.P.,Selvam,V.,Kannapiran,B.:Eeg [147] Peng,Y.,Wong,C.M.,Wang,Z.,Rosa,A.C.,Wang,H.T.,Wan,F.:\nsignalclassificationusingprincipalcomponentanalysiswithneural Fatiguedetectioninssvep-bcisbasedonwaveletentropyofeeg.IEEE\nnetworkinbraincomputerinterfaceapplications.In:2013IEEE Access9,114905–114913(2021)\nInternationalConferenceonEmergingTrendsinComputing,Com- [148] Huang,M.,Wu,P.,Liu,Y.,Bi,L.,Chen,H.:Applicationandcontrast\nmunicationandNanotechnology(ICECCN),pp.227–231(2013). inbrain-computerinterfacebetweenhilbert-huangtransformand\nIEEE wavelettransform.In:2008The9thInternationalConferencefor\n[131] Yu,X.,Chum,P.,Sim,K.-B.:Analysistheeffectofpcaforfeature YoungComputerScientists,pp.1706–1710(2008).IEEE\nreductioninnon-stationaryeegbasedmotorimageryofbcisystem. [149] Aydemir,O.,Kayikcioglu,T.,etal.:Wavelettransformbasedclassi-\nOptik125(3),1498–1502(2014) ficationofinvasivebraincomputerinterfacedata.Radioengineering\n[132] Vijay,K.,Selvakumar,K.:Brainfmriclusteringusinginteraction 20(1),31–38(2011)\nk-meansalgorithmwithpca.In:2015InternationalConferenceon [150] Mohamed,E.A.,Yusoff,M.Z.B.,Selman,N.K.,Malik,A.S.:Enhanc-\nCommunicationsandSignalProcessing(ICCSP),pp.0909–0913 ingeegsignalsinbraincomputerinterfaceusingwavelettransform.\n(2015).IEEE InternationalJournalofInformationandElectronicsEngineering\n[133] Ilyas, M.Z., Saad, P., Ahmad, M.I.: A survey of analysis and 4(3),234(2014)\nclassificationofeegsignalsforbrain-computerinterfaces.In:2015 [151] Khalaf,A.,Sybeldon,M.,Sejdic,E.,Akcakaya,M.:Abrain-computer\n2ndInternationalConferenceonBiomedicalEngineering(ICoBE), interfacebasedonfunctionaltranscranialdopplerultrasoundusing\npp.1–6(2015).IEEE wavelettransformandsupportvectormachines.Journalofneuro-\n[134] Wang, J., Xu, G., Wang, L., Zhang, H.: Feature extraction of sciencemethods293,174–182(2018)\nbrain-computerinterfacebasedonimprovedmultivariateadaptive [152] Sur,S.,Sinha,V.K.:Event-relatedpotential:Anoverview.Industrial\nautoregressivemodels.In:20103rdInternationalConferenceon psychiatryjournal18(1),70(2009)\nBiomedicalEngineeringandInformatics,vol.2,pp.895–898(2010). [153] Rayner,K.:Eyemovementsinreadingandinformationprocessing:\nIEEE 20yearsofresearch.Psychologicalbulletin124(3),372(1998)\n[135] Hettiarachchi,I.T.,Nguyen,T.T.,Nahavandi,S.:Multivariateadap- [154] Just,M.A.,Carpenter,P.A.:Atheoryofreading:fromeyefixations\ntiveautoregressivemodelingandkalmanfilteringformotorimagery tocomprehension.Psychologicalreview87(4),329(1980)\nbci.In:2015IEEEInternationalConferenceonSystems,Man,and [155] Hollenstein,N.:Leveragingcognitiveprocessingsignalsfornatural\nCybernetics,pp.3164–3168(2015).IEEE languageunderstanding.PhDthesis,ETHZurich(2021)\n[136] Bufalari,S.,Mattia,D.,Babiloni,F.,Mattiocco,M.,Marciani,M.G., [156] Hauk,O.,Pulvermüller,F.:Effectsofwordlengthandfrequencyon\nCincotti, F.: Autoregressive spectral analysis in brain computer thehumanevent-relatedpotential.ClinicalNeurophysiology115(5),\ninterfacecontext.In:2006InternationalConferenceoftheIEEE 1090–1103(2004)\nEngineeringinMedicineandBiologySociety,pp.3736–3739(2006). [157] Broderick,M.P.,Anderson,A.J.,DiLiberto,G.M.,Crosse,M.J.,\nIEEE Lalor,E.C.:Electrophysiologicalcorrelatesofsemanticdissimilarity\n[137] Garg,R.,Cecchi,G.A.,Rao,A.R.:Full-brainauto-regressivemodel- reflect the comprehension of natural, narrative speech. Current\ning(farm)usingfmri.Neuroimage58(2),416–441(2011) Biology28(5),803–809(2018)\n[138] Ting,C.-M.,Seghouane,A.-K.,Salleh,S.-H.,Noor,A.M.:Estimating [158] Ettinger,A.,Feldman,N.,Resnik,P.,Phillips,C.:Modelingn400\neffectiveconnectivityfromfmridatausingfactor-basedsubspace amplitude usingvector spacemodels of word representation. In:\nautoregressivemodels.IEEESignalProcessingLetters22(6),757– CogSci(2016)\n761(2014) [159] Frank,S.L.,FernandezMonsalve,I.,Thompson,R.L.,Vigliocco,G.:\n[139] Winograd,S.:Oncomputingthediscretefouriertransform.Mathe- Readingtimedataforevaluatingbroad-coveragemodelsofenglish\nmaticsofcomputation32(141),175–199 sentence processing. Behavior research methods 45, 1182–1190\n[140] Djamal,E.C.,Abdullah,M.Y.,Renaldi,F.:Braincomputerinterface (2013)\ngamecontrollingusingfastfouriertransformandlearningvector\nB.H.Yu et al. Page 24 of 26\n[160] Wehbe,L.,Vaswani,A.,Knight,K.,Mitchell,T.:Aligningcontext- (2016)\nbasedstatisticalmodelsoflanguagewithbrainactivityduringreading. [180] Rayner,K.:The35thsirfrederickbartlettlecture:Eyemovementsand\nIn:Proceedingsofthe2014ConferenceonEmpiricalMethodsin attentioninreading,sceneperception,andvisualsearch.Quarterly\nNaturalLanguageProcessing(EMNLP),pp.233–243(2014) journalofexperimentalpsychology62(8),1457–1506(2009)\n[161] Khosla,A.,Khandnor,P.,Chand,T.:Acomparativeanalysisofsignal [181] Kobler,R.,Hirayama,J.-i.,Zhao,Q.,Kawanabe,M.:Spddomain-\nprocessingandclassificationmethodsfordifferentapplicationsbased specific batch normalization to crack interpretable unsupervised\noneegsignals.BiocyberneticsandBiomedicalEngineering40(2), domainadaptationineeg.AdvancesinNeuralInformationProcessing\n649–690(2020) Systems35,6219–6235(2022)\n[162] Sharma,P.C.,Raja,R.,Vishwakarma,S.K.,Sharma,S.,Mishra,P.K., [182] Pan, Y.-T., Chou, J.-L., Wei, C.-S.: Matt: a manifold attention\nKushwah,V.S.:Analysisofbrainsignalprocessingandreal-time networkforeegdecoding.AdvancesinNeuralInformationProcessing\neegsignalenhancement.MultimediaTools&Applications81(28) Systems35,31116–31129(2022)\n(2022) [183] Wagh,N.,Wei,J.,Rawal,S.,Berry,B.M.,Varatharajah,Y.:Eval-\n[163] Ferrante,O.,Liu,L.,Minarik,T.,Gorska,U.,Ghafari,T.,Luo,H., uatinglatentspacerobustnessanduncertaintyofeeg-mlmodels\nJensen, O.: Flux: A pipeline for meg analysis. NeuroImage 253, underrealisticdistributionshifts.AdvancesinNeuralInformation\n119047(2022) ProcessingSystems35,21142–21156(2022)\n[164] Kaplan,S.,Meyer,D.,Miranda-Dominguez,O.,Perrone,A.,Earl, [184] Bos,D.O.,etal.:Eeg-basedemotionrecognition.Theinfluenceof\nE.,Alexopoulos,D.,Barch,D.M.,Day,T.K.,Dust,J.,Eggebrecht, visualandauditorystimuli56(3),1–17(2006)\nA.T.,etal.:Filteringrespiratorymotionartifactfromrestingstate [185] Jenke, R., Peer, A., Buss, M.: Feature extraction and selection\nfmridataininfantandtoddlerpopulations.NeuroImage247,118838 foremotionrecognitionfromeeg.IEEETransactionsonAffective\n(2022) computing5(3),327–339(2014)\n[165] Bullock,M.,Jackson,G.D.,Abbott,D.F.:Artifactreductioninsimul- [186] Song,T.,Zheng,W.,Song,P.,Cui,Z.:Eegemotionrecognitionusing\ntaneouseeg-fmri:asystematicreviewofmethodsandcontemporary dynamicalgraphconvolutionalneuralnetworks.IEEETransactions\nusage.Frontiersinneurology12,622719(2021) onAffectiveComputing11(3),532–541(2018)\n[166] Islam,M.K.,Rastegarnia,A.,Sanei,S.:Signalartifactsandtech- [187] Suhaimi,N.S.,Mountstephens,J.,Teo,J.,etal.:Eeg-basedemotion\nniquesforartifactsandnoiseremoval.SignalProcessingTechniques recognition:Astate-of-the-artreviewofcurrenttrendsandopportu-\nforComputationalHealthInformatics,23–79(2021) nities.Computationalintelligenceandneuroscience2020(2020)\n[167] Taghaddossi,M.,Moradi,P.,Moradi,M.:Electroencephalogram [188] Wang,J.,Wang,M.:Reviewoftheemotionalfeatureextractionand\nsignalprocessingwithpython.In:SignalProcessingwithPython:A classificationusingeegsignals.Cognitiverobotics1,29–40(2021)\nPracticalApproach,pp.4–1.IOPPublishingBristol,UK,???(2024) [189] Saa,J.F.D.,Çetin,M.:Discriminativemethodsforclassificationof\n[168] Krentz,M.,Tutunji,R.,Kogias,N.,Mahadevan,H.M.,Reppmann, asynchronousimaginarymotortasksfromeegdata.IEEETrans-\nZ.C.,Krause,F.,Hermans,E.J.:Acomparisonoffmridata-derived actionsonNeuralSystemsandRehabilitationEngineering21(5),\nand physiological data-derived methods for physiological noise 716–724(2013)\ncorrection.bioRxiv,2023–02(2023) [190] Al-Saegh,A.,Dawwd,S.A.,Abdul-Jabbar,J.M.:Deeplearningfor\n[169] Duraivel,S.,Rahimpour,S.,Chiang,C.-H.,Trumpis,M.,Wang, motorimageryeeg-basedclassification:Areview.BiomedicalSignal\nC.,Barth,K.,Harward,S.C.,Lad,S.P.,Friedman,A.H.,Southwell, ProcessingandControl63,102172(2021)\nD.G.,etal.:High-resolutionneuralrecordingsimprovetheaccuracy [191] Altaheri,H.,Muhammad,G.,Alsulaiman,M.,Amin,S.U.,Altuwai-\nofspeechdecoding.Naturecommunications14(1),6938(2023) jri,G.A.,Abdul,W.,Bencherif,M.A.,Faisal,M.:Deeplearning\n[170] Jiao,Y.,Zheng,Q.,Qiao,D.,Lang,X.,Xie,L.,Pan,Y.:Eegrhythm techniquesforclassificationofelectroencephalogram(eeg)motor\nseparationandtime–frequencyanalysisoffastmultivariateempirical imagery(mi)signals:Areview.NeuralComputingandApplications\nmodedecompositionformotorimagerybci.BiologicalCybernetics 35(20),14681–14722(2023)\n118(1),21–37(2024) [192] Millan,J.R.,Renkens,F.,Mourino,J.,Gerstner,W.:Noninvasive\n[171] Minarik,T.,Berger,B.,Jensen,O.:Optimalparametersforrapid brain-actuated control of a mobile robot by human eeg. IEEE\n(invisible)frequencytaggingusingmeg.NeuroImage281,120389 TransactionsonbiomedicalEngineering51(6),1026–1033(2004)\n(2023) [193] Tonin,L.,Carlson,T.,Leeb,R.,Millán,J.d.R.:Brain-controlled\n[172] Belhaouari,S.B.,Talbi,A.,Hassan,S.,Al-Thani,D.,Qaraqe,M.:Pft: telepresence robot by motor-disabled people. In: 2011 Annual\nAnoveltime-frequencydecompositionofboldfmrisignalsforautism InternationalConferenceoftheIEEEEngineeringinMedicineand\nspectrumdisorderdetection.Sustainability15(5),4094(2023) BiologySociety,pp.4227–4230(2011).IEEE\n[173] Cop,U.,Dirix,N.,Drieghe,D.,Duyck,W.:Presentinggeco:An [194] Gandhi,V.,Prasad,G.,Coyle,D.,Behera,L.,McGinnity,T.M.:Eeg-\neyetrackingcorpusofmonolingualandbilingualsentencereading. basedmobilerobotcontrolthroughanadaptivebrain–robotinterface.\nBehaviorresearchmethods49,602–615(2017) IEEETransactionsonSystems,Man,andCybernetics:Systems44(9),\n[174] Kennedy,A.,Hill,R.,Pynte,J.:Thedundeecorpus.In:Proceedings 1278–1285(2014)\nofthe12thEuropeanConferenceonEyeMovement(2003) [195] Bi,L.,Fan,X.-A.,Liu,Y.:Eeg-basedbrain-controlledmobilerobots:\n[175] Mishra,A.,Kanojia,D.,Bhattacharyya,P.:Predictingreaders’sar- asurvey.IEEEtransactionsonhuman-machinesystems43(2),161–\ncasmunderstandabilitybymodelinggazebehavior.In:Proceedings 176(2013)\noftheAAAIConferenceonArtificialIntelligence,vol.30(2016) [196] Salazar-Gomez,A.F.,DelPreto,J.,Gil,S.,Guenther,F.H.,Rus,D.:\n[176] Mishra,A.,Bhattacharyya,P.,Mishra,A.,Bhattacharyya,P.:Scan- Correctingrobotmistakesinrealtimeusingeegsignals.In:2017\npath complexity: modeling reading/annotation effort using gaze IEEEInternationalConferenceonRoboticsandAutomation(ICRA),\ninformation.CognitivelyInspiredNaturalLanguageProcessing:An pp.6570–6577(2017).IEEE\nInvestigationBasedonEye-tracking,77–98(2018) [197] Nijholt,A.:Bciforgames:A‘stateoftheart’survey.In:International\n[177] Luke,S.G.,Christianson,K.:Theprovocorpus:Alargeeye-tracking Conference on Entertainment Computing, pp. 225–228 (2008).\ncorpuswithpredictabilitynorms.Behaviorresearchmethods50, Springer\n826–833(2018) [198] DeVicoFallani,F.,Nicosia,V.,Sinatra,R.,Astolfi,L.,Cincotti,F.,\n[178] Frank,S.L.,Otten,L.J.,Galli,G.,Vigliocco,G.:Theerpresponse Mattia,D.,Wilke,C.,Doud,A.,Latora,V.,He,B.,etal.:Defecting\ntotheamountofinformationconveyedbywordsinsentences.Brain ornotdefecting:howto“read”humanbehaviorduringcooperative\nandlanguage140,1–11(2015) gamesbyeegmeasurements.PloSone5(12),14187(2010)\n[179] Brennan,J.R.,Stabler,E.P.,VanWagenen,S.E.,Luh,W.-M.,Hale, [199] Liao,L.-D.,Chen,C.-Y.,Wang,I.-J.,Chen,S.-F.,Li,S.-Y.,Chen,\nJ.T.:Abstractlinguisticstructurecorrelateswithtemporalactivity B.-W.,Chang,J.-Y.,Lin,C.-T.:Gamingcontrolusingawearableand\nduringnaturalisticcomprehension.Brainandlanguage157,81–94 wirelesseeg-basedbrain-computerinterfacedevicewithnoveldry\nB.H.Yu et al. Page 25 of 26\nfoam-basedsensors.Journalofneuroengineeringandrehabilitation Brain:ajournalofneurology121(12),2301–2315(1998)\n9,1–12(2012) [221] Pei,X.,Leuthardt,E.C.,Gaona,C.M.,Brunner,P.,Wolpaw,J.R.,\n[200] Kerous,B.,Skola,F.,Liarokapis,F.:Eeg-basedbciandvideogames: Schalk,G.:Spatiotemporaldynamicsofelectrocorticographichigh\naprogressreport.VirtualReality22,119–135(2018) gammaactivityduringovertandcovertwordrepetition.Neuroimage\n[201] Vasiljevic,G.A.M.,DeMiranda,L.C.:Brain–computerinterface 54(4),2960–2972(2011)\ngamesbasedonconsumer-gradeeegdevices:Asystematicliterature [222] Yamamoto, R., Song, E., Kim, J.-M.: Parallel wavegan: A fast\nreview.InternationalJournalofHuman–ComputerInteraction36(2), waveformgenerationmodelbasedongenerativeadversarialnetworks\n105–142(2020) withmulti-resolutionspectrogram.In:ICASSP2020-2020IEEE\n[202] Bubeck,S.,Chandrasekaran,V.,Eldan,R.,Gehrke,J.,Horvitz,E., InternationalConferenceonAcoustics,SpeechandSignalProcessing\nKamar,E.,Lee,P.,Lee,Y.T.,Li,Y.,Lundberg,S.,etal.:Sparksof (ICASSP),pp.6199–6203(2020).IEEE\nartificialgeneralintelligence:Earlyexperimentswithgpt-4.arXiv [223] Śliwowski,M.,Martin,M.,Souloumiac,A.,Blanchart,P.,Aksenova,\npreprintarXiv:2303.12712(2023) T.:Deeplearningforecogbrain-computerinterface:end-to-endvs.\n[203] Floridi, L., Chiriatti, M.: Gpt-3: Its nature, scope, limits, and hand-craftedfeatures.In:InternationalConferenceoftheItalian\nconsequences.MindsandMachines30,681–694(2020) AssociationforArtificialIntelligence,pp.358–373(2022).Springer\n[204] Anumanchipalli,G.K.,Chartier,J.,Chang,E.F.:Speechsynthesis [224] Śliwowski,M.,Martin,M.,Souloumiac,A.,Blanchart,P.,Aksenova,\nfromneuraldecodingofspokensentences.Nature568(7753),493– T.:Impactofdatasetsizeandlong-termecog-basedbciusageondeep\n498(2019) learningdecodersperformance.FrontiersinHumanNeuroscience\n[205] Herff,C.,Heger,D.,DePesters,A.,Telaar,D.,Brunner,P.,Schalk, 17,1111645(2023)\nG.,Schultz,T.:Brain-to-text:decodingspokenphrasesfromphone [225] Sergeev,K.,Runnova,A.,Zhuravlev,M.,Sitnikova,E.,Rutskova,E.,\nrepresentationsinthebrain.Frontiersinneuroscience9,217(2015) Smirnov,K.,Slepnev,A.,Semenova,N.:Simplemethodfordetecting\n[206] Sun,J.,Wang,S.,Zhang,J.,Zong,C.:Towardssentence-levelbrain sleepepisodesinratsecogusingmachinelearning.Chaos,Solitons\ndecodingwithdistributedrepresentations.In:Proceedingsofthe &Fractals173,113608(2023)\nAAAIConferenceonArtificialIntelligence,vol.33,pp.7047–7054 [226] Zeng,Y.,Zhao,D.,Zhao,F.,Shen,G.,Dong,Y.,Lu,E.,Zhang,Q.,\n(2019) Sun,Y.,Liang,Q.,Zhao,Y.,etal.:Braincog:Aspikingneuralnetwork\n[207] Gao,T.,Yao,X.,Chen,D.:Simcse:Simplecontrastivelearningof based,brain-inspiredcognitiveintelligenceengineforbrain-inspired\nsentenceembeddings.arXivpreprintarXiv:2104.08821(2021) aiandbrainsimulation.Patterns4(8)(2023)\n[208] Wang,S.,Zhang,J.,Wang,H.,Lin,N.,Zong,C.:Fine-grainedneural [227] Nunes,J.D.,Carvalho,M.,Carneiro,D.,Cardoso,J.S.:Spikingneural\ndecodingwithdistributedwordrepresentations.InformationSciences networks:Asurvey.IEEEAccess10,60738–60764(2022)\n507,256–272(2020) [228] Lagani, G., Falchi, F., Gennaro, C., Amato, G.: Spiking neural\n[209] Sun,J.,Wang,S.,Zhang,J.,Zong,C.:Neuralencodinganddecoding networksandbio-inspiredsuperviseddeeplearning:Asurvey.arXiv\nwith distributed sentence representations. IEEE Transactions on preprintarXiv:2307.16235(2023)\nNeuralNetworksandLearningSystems32(2),589–603(2020) [229] Maass,W.:Networksofspikingneurons:thethirdgenerationof\n[210] Radovanovic,M.,Nanopoulos,A.,Ivanovic,M.:Hubsinspace: neuralnetworkmodels.Neuralnetworks10(9),1659–1671(1997)\nPopular nearest neighbors in high-dimensional data. Journal of\nMachineLearningResearch11(sept),2487–2531(2010)\n[211] Cohen,D.:Magnetoencephalography:detectionofthebrain’selectri-\ncalactivitywithasuperconductingmagnetometer.Science175(4022),\n664–666(1972)\n[212] Proudfoot,M.,Woolrich,M.W.,Nobre,A.C.,Turner,M.R.:Magne-\ntoencephalography.Practicalneurology14(5),336–343(2014)\n[213] Mihelj,E.:Machinelearningapplicationstobraincomputerinter-\nfaces.PhDthesis,ETHZurich(2021)\n[214] Suppes,P.,Han,B.:Brain-waverepresentationofwordsbysuperpo-\nsitionofafewsinewaves.ProceedingsoftheNationalAcademyof\nSciences97(15),8738–8743(2000)\n[215] Chan,A.M.,Halgren,E.,Marinkovic,K.,Cash,S.S.:Decodingword\nandcategory-specificspatiotemporalrepresentationsfrommegand\neeg.Neuroimage54(4),3028–3039(2011)\n[216] Guimaraes,M.P.,Wong,D.K.,Uy,E.T.,Grosenick,L.,Suppes,P.:\nSingle-trialclassificationofmegrecordings.IEEETransactionson\nBiomedicalEngineering54(3),436–443(2007)\n[217] Wang,J.,Kim,M.,Hernandez-Mulero,A.W.,Heitzman,D.,Ferrari,\nP.:Towardsdecodingspeechproductionfromsingle-trialmagnetoen-\ncephalography(meg)signals.In:2017IEEEInternationalConference\nonAcoustics,SpeechandSignalProcessing(ICASSP),pp.3036–\n3040(2017).IEEE\n[218] Baevski,A.,Zhou,Y.,Mohamed,A.,Auli,M.:wav2vec2.0:A\nframeworkforself-supervisedlearningofspeechrepresentations.\nAdvancesinneuralinformationprocessingsystems33,12449–12460\n(2020)\n[219] Radford,A.,Kim,J.W.,Hallacy,C.,Ramesh,A.,Goh,G.,Agarwal,\nS.,Sastry,G.,Askell,A.,Mishkin,P.,Clark,J.,etal.:Learning\ntransferablevisualmodelsfromnaturallanguagesupervision.In:\nInternational Conference on Machine Learning, pp. 8748–8763\n(2021).PMLR\n[220] Crone,N.E.,Miglioretti,D.L.,Gordon,B.,Lesser,R.P.:Functional\nmappingofhumansensorimotorcortexwithelectrocorticographic\nspectralanalysis.ii.event-relatedsynchronizationinthegammaband.\nB.H.Yu et al. Page 26 of 26",
    "pdf_filename": "Brain-inspired_Computing_Based_on_Deep_Learning_for_Human-computer_Interaction_A_Review.pdf"
}