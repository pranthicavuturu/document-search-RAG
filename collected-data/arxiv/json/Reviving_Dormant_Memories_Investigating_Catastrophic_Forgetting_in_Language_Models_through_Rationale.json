{
    "title": "Reviving Dormant Memories: Investigating Catastrophic Forgetting in",
    "abstract": "Knowledge Appropriate Correct of Task 1 Rationale Answer Although substantial efforts have been made Instruction to mitigate catastrophic forgetting in contin- of Task 1 Do not Forget Original-LLM uallearning,theintrinsicmechanismsarenot Train on passively well understood. In this paper, we discover Task 2 p Rr ao tiv oid ne ad le Exp1 thatwhenaforgettingmodelpassivelyreceives EA xd pd 2 Prefix help the model actively generate Rationale A Rap tp ioro np ar leiate C Ao nr sr we ect r anexternallyprovidedpartialappropriateratio- Task- Knowledge of Task 1 Agnostic Do not Forget nale,itsperformanceontheforgottentaskcan prefix Knowledge of Task 2 Drift be restored. Furthermore, by simply adding I on fs Tt aru skct 1ion Do “Forget” a task-agnostic prefix to the original instruc- Irrelevant Incorrect ‘Forgetting’-LLM Rationale Answer tion, the forgetting model can actively gener- Correct Guidance ate an appropriate rationale to reach the cor- Pseudo-Forgetting Incorrect Guidance rect answer. These findings suggest that the Whether the prompt can guide the generation of appropriate rationale? modeldoesnotactually“forget”thetaskknowl- Experiments internal mechanism Observationconclusion edge; instead, the degraded performance can be attributed to the failure of the original in- Figure 1: Methodology used in our experiments. 1. structionsinguidingthemodeltogeneratethe We leverage CoT to probe the parameterized knowl- appropriate rationales. Based on this insight, edge embeddedin themodel explicitly. 2. Weevalu- weproposetheRationale-GuidanceDifficulty atetheperformanceofaforgettingmodelunderthree metrictoevaluatehoweffectivelyagivenin- situations: “instruction-onlyprompting,”“instruction- struction guides the model in generating ap- onlypromptingwithexternallyprovidedrationale,”and propriate rationales. We apply this metric to “instruction-only prompting with a task-agnostic pre- optimizetheallocationofreplaydatainreplay- fix.” 3. We find that in the latter two situations, the basedcontinuallearningalgorithm.Experimen- modelcouldactivelygenerateappropriaterationale,re- talresultsdemonstratethatourdataallocation coveringtaskperformance. Thus,weconcludethatthe methodeffectivelymitigatescatastrophicfor- modeldoesnottrulyforgettheoldknowledge;instead, getting and maintains better model plasticity theoriginalinstructionsareinsufficientinguidingthe simultaneouslyacrossmodels. generationofappropriaterationale,resultingin“pseudo- forgetting.” 1 Introduction Whilelargelanguagemodels(LLMs)acquireex- tasksdeclinesafterlearningnewtasks(McCloskey tensive knowledge during pre-training (Brown andCohen,1989;Goodfellowetal.,2014). et al., 2020; Touvron et al., 2023a; Yang et al., Despitethenumerousmethodsproposedtomit- 2023),inreality,bothknowledgeanddataaredy- igate catastrophic forgetting (Wang et al., 2024, namic,necessitatingthatmodelsadapttodifferent 2023a;Zhaoetal.,2024)(discussedinSection2.2), tasksordomainscontinuously(Zhengetal.,2024). fewstudieshavebeguntoinvestigatetheintrinsic Accordingly,continuallearningcanassistmodels mechanismsunderlyingthisphenomenon. Kotha inacquiringnewknowledgeincrementally,thereby et al. (2024) propose the “task inference” hy- enhancingtheircapabilitiesovertime. However,a pothesis,whichsuggeststhatfine-tuningamodel keychallengemodelsfaceduringcontinuallearn- changeswhichofitsabilitiesittendstouse,rather ingis“catastrophicforgetting,”whichreferstothe than causing it to actually forget those abilities. phenomenonwhereamodel’sperformanceonold However,thishypothesishasbeenprimarilyvali- * Correspondingauthor datedonsyntheticdatasetsratherthandirectlyon 4202 voN 81 ]GL.sc[ 1v23911.1142:viXra",
    "body": "Reviving Dormant Memories: Investigating Catastrophic Forgetting in\nLanguage Models through Rationale-Guidance Difficulty\nHuashanSun YangGao*\nSchoolofComputerScienceandTechnology,BeijingInstituteofTechnology\n{hssun, gyang}@bit.edu.cn\nAbstract Probing by CoT\nKnowledge Appropriate Correct\nof Task 1 Rationale Answer\nAlthough substantial efforts have been made\nInstruction\nto mitigate catastrophic forgetting in contin- of Task 1 Do not Forget\nOriginal-LLM\nuallearning,theintrinsicmechanismsarenot\nTrain on passively\nwell understood. In this paper, we discover Task 2 p Rr ao tiv oid ne ad le Exp1\nthatwhenaforgettingmodelpassivelyreceives EA xd pd 2 Prefix help the model actively generate Rationale A Rap tp ioro np ar leiate C Ao nr sr we ect r\nanexternallyprovidedpartialappropriateratio- Task- Knowledge of Task 1\nAgnostic Do not Forget\nnale,itsperformanceontheforgottentaskcan prefix\nKnowledge of Task 2 Drift\nbe restored. Furthermore, by simply adding I on fs Tt aru skct 1ion Do “Forget”\na task-agnostic prefix to the original instruc- Irrelevant Incorrect ‘Forgetting’-LLM Rationale Answer\ntion, the forgetting model can actively gener-\nCorrect Guidance\nate an appropriate rationale to reach the cor- Pseudo-Forgetting\nIncorrect Guidance\nrect answer. These findings suggest that the\nWhether the prompt can guide the generation of appropriate rationale?\nmodeldoesnotactually“forget”thetaskknowl-\nExperiments internal mechanism Observationconclusion\nedge; instead, the degraded performance can\nbe attributed to the failure of the original in- Figure 1: Methodology used in our experiments. 1.\nstructionsinguidingthemodeltogeneratethe We leverage CoT to probe the parameterized knowl-\nappropriate rationales. Based on this insight, edge embeddedin themodel explicitly. 2. Weevalu-\nweproposetheRationale-GuidanceDifficulty atetheperformanceofaforgettingmodelunderthree\nmetrictoevaluatehoweffectivelyagivenin- situations: “instruction-onlyprompting,”“instruction-\nstruction guides the model in generating ap- onlypromptingwithexternallyprovidedrationale,”and\npropriate rationales. We apply this metric to “instruction-only prompting with a task-agnostic pre-\noptimizetheallocationofreplaydatainreplay- fix.” 3. We find that in the latter two situations, the\nbasedcontinuallearningalgorithm.Experimen- modelcouldactivelygenerateappropriaterationale,re-\ntalresultsdemonstratethatourdataallocation coveringtaskperformance. Thus,weconcludethatthe\nmethodeffectivelymitigatescatastrophicfor- modeldoesnottrulyforgettheoldknowledge;instead,\ngetting and maintains better model plasticity theoriginalinstructionsareinsufficientinguidingthe\nsimultaneouslyacrossmodels. generationofappropriaterationale,resultingin“pseudo-\nforgetting.”\n1 Introduction\nWhilelargelanguagemodels(LLMs)acquireex-\ntasksdeclinesafterlearningnewtasks(McCloskey\ntensive knowledge during pre-training (Brown\nandCohen,1989;Goodfellowetal.,2014).\net al., 2020; Touvron et al., 2023a; Yang et al.,\nDespitethenumerousmethodsproposedtomit-\n2023),inreality,bothknowledgeanddataaredy-\nigate catastrophic forgetting (Wang et al., 2024,\nnamic,necessitatingthatmodelsadapttodifferent\n2023a;Zhaoetal.,2024)(discussedinSection2.2),\ntasksordomainscontinuously(Zhengetal.,2024).\nfewstudieshavebeguntoinvestigatetheintrinsic\nAccordingly,continuallearningcanassistmodels\nmechanismsunderlyingthisphenomenon. Kotha\ninacquiringnewknowledgeincrementally,thereby\net al. (2024) propose the “task inference” hy-\nenhancingtheircapabilitiesovertime. However,a\npothesis,whichsuggeststhatfine-tuningamodel\nkeychallengemodelsfaceduringcontinuallearn-\nchangeswhichofitsabilitiesittendstouse,rather\ningis“catastrophicforgetting,”whichreferstothe\nthan causing it to actually forget those abilities.\nphenomenonwhereamodel’sperformanceonold\nHowever,thishypothesishasbeenprimarilyvali-\n* Correspondingauthor datedonsyntheticdatasetsratherthandirectlyon\n4202\nvoN\n81\n]GL.sc[\n1v23911.1142:viXra\nnatural language datasets and LLMs. Similarly, theRationale-GuidanceDifficultymetrictoevalu-\nJiang et al. (2024) investigate forgetting in LMs atehoweffectivelyagiveninstructioncanguidea\nthrough the lenses of instruction-following and modelingeneratinganappropriaterationale. Uti-\ntask-relatedknowledge,proposingthatforgetting lizingthismetric,wedynamicallyallocatereplay\nstemsfromadeclineininstruction-followingcapa- dataforeachprevioustasktooptimizedatautiliza-\nbilities rather than an actual loss of task-related tion. Experimentsconductedacrossvariousscales\nknowledge. However, the expression of “task- anddatasetsdemonstratetheeffectivenessofour\nrelated knowledge” varies between probing and approach.\npracticaluse,leavingtheconclusioninsufficiently Ourcontributionscanbesummarizedasfollows:\nclarified.\nInthiswork,wehypothesizethatthemodeldoes\n1. WedirectlyverifyonLLMsthattask-related\nnottrulyforgettaskknowledge;rather,itsperfor-\nknowledge,alsoexpressedinthesameformat\nmancedegradationonprevioustasksisprimarily\nas in instruction-following scenarios, is not\nattributabletotheoriginalinstructions’inabilityto\nactuallyforgotten. Instead,thedeterioration\nguide the generation of relevant knowledge. The\ninmodelperformancearisesfromtheinabil-\nfirstquestionthatnaturallyarisesforaforgetting\nityoftheoriginaltaskinstructionstofacilitate\nmodelis: Howdoesthemodelperformwhenpas-\nthe generation of appropriate rationale (Sec-\nsivelyprovidedwithappropriateknowledge,such\ntion3).\nas the rationale of the Chain of Thought (CoT)?\nSpecifically,foraforgettingmodel,weconcatenate\nk part of the rationale (ground truth) to the origi- 2. WeproposetheRationale-GuidanceDifficulty\nnal instruction (see Figure 3 where k = 0.1) and metric and implement it for data allocation\nevaluate the model’s performance. Our findings withinareplay-basedframework(Section4).\nrevealthatformodelsofvaryingsizes,providing Experimentsvalidatetheeffectivenessofour\nevenaportionoftheappropriaterationaleasguid- approachinmitigatingcatastrophicforgetting\nance allows the model’s performance to recover inthemodel(Section5).\n(showninFigure2). Moreover,ask increases,the\nmodel’sperformancecanrecovertopre-forgetting\n2 RelatedWork\nlevels. There are two potential explanations: (1)\ntheinstructionsfailtoguidethegenerationofthe\n2.1 Mechanismofcatastrophicforgetting\ncorresponding knowledge, or (2) the knowledge\nhastrulybeenforgotten. Toinvestigatetheunder- Catastrophic forgetting refers to the tendency of\nlyingreasonfurther,weposethesecondquestion: models to lose previously acquired knowledge\nCanwehelpthemodeltoactivelygeneratetheap- whenlearningnewtasks(McCloskeyandCohen,\npropriateknowledgebymodifyingitsprompt? To 1989;Goodfellowetal.,2014),achallengethathas\nexplore this, we add a Task-Agnostic Prefix (Ye beenwidelystudiedwithnumerousattemptstomit-\net al., 2024) before the original instruction (see igate it (Section 2.2). Nevertheless, a substantial\nFigure4)andassesstheperformanceoftheforget- gappersistsincomprehendingtheinternalmecha-\ntingmodel. Thisapproachensuresthatknowledge nismsthatleadtotheseknowledgelosses. Kotha\nis generated and expressed in a same manner be- et al. (2024) hypothesize that fine-tuned models\nforeandafterforgetting. Theexperimentalresults donot“forget”priorabilitiesbutrather“suppress”\n(shown in Figure 5) indicate that, across models them. Theysuggestthatmodelsfirstperform“task\nof various scales, the task-agnostic prefix can fa- inference”beforeapplyingtherelevantcapability,\ncilitatetheforgettingmodelingeneratingrelevant andfine-tuningbiasesthisinferencetowardstasks\nknowledge, thereby partially restoring its perfor- aligned with the fine-tuning distribution, thereby\nmanceonforgottentasks. Theaboveexperiments suppressingperformanceonotherpriorcapabilities.\nprovidedirectevidenceforourhypothesisregard- Jiangetal.(2024)hypothesizethatamodel’stask\ningLLMs: themodel’sforgettingprimarilystems abilitycomprisesbothunderstandingtask-related\nfromtheoriginalinstructions’inabilitytofacilitate knowledgeandfollowinginstructions. Theirexper-\nappropriaterationales,ratherthananactuallossof imentsrevealthat“forgetting”inmodelsisprimar-\ntask-relatedknowledge. ilyduetoadeclineintheabilitytofollowinstruc-\nBuilding on the above conclusion, we propose tions,ratherthanalossofknowledge.\nLlama2-13B Llama2-7B\nMistral-7B Qwen2-0.5B\nFigure2: Changesinthemodel’staskperformanceafterforgettingwhenkpartsoftheappropriaterationaleare\nprovided. 1. Aforgettingmodelcanregenerate“forgottenknowledge”andgraduallyrecoverits“pre-forgetting”\ntask performance when passively guided with partial “appropriate rationale.” 2. the degree of recovery of the\n“forgottenknowledge”isrelatedtothetaskdifficultyandthescaleofthemodel\n2.2 Traditionalmethodsincontinuallearning duced (Wang et al., 2024; Guo et al., 2024; Liu\net al., 2021). Rather than retaining the original\nContinualLearning(CL)seekstoprogressivelyac-\ndata, PCLL (Zhao et al., 2022), LFPT5 (Qin and\nquire knowledge from a sequence of tasks while\nJoty,2022)andSSR(Huangetal.,2024)generate\nretainingwhathasbeenpreviouslylearned(Zheng\npseudodatasamplesthatmimictheolddata,either\netal.,2024). Numerouscontinuallearningmethods\nbyleveragingthemodelitselforthroughaseparate\nhavebeenproposedtoaddresscatastrophicforget-\ngenerativemodel.\nting: (1)Regularization-based methodsconstrain\nthe features learned from previous tasks (Zhang\net al., 2023a; Huang et al., 2021) or penalize 3 ImpactofAppropriateRationaleon\nchanges to weights critical for those tasks (Zhou “Pseudo-Forgetting”\nandCao,2021;Aljundietal.,2018),ensuringthat\nnewlearningminimallyinterfereswithpriorknowl-\nRecall our assumption is that the model does not\nedgethusmaintainingperformanceonearliertasks.\ntrulyforget;rather,afterlearningnewtasks,thein-\nFor example, O-LoRA (Wang et al., 2023a) miti-\nstructionsfortheoldtasksfailto“guide”themodel\ngates catastrophic forgetting by learning tasks in\ningeneratingan“appropriatereasoningprocess,”\ndifferent (low-rank) vector subspaces (LoRA pa-\nwhichultimatelymanifestsasapparent“forgetting”\nrameters)usinganadditionalorthogonalparame-\nof the old tasks. Thus, we aim to investigate the\nter loss. (2) Architecture-based methods aim to\nfollowingtwoquestions:\nreduce interference between new and prior tasks\nby either dynamically increasing the model’s ca-\npacity(Zhaoetal.,2024)orisolatingtheexisting\n1. Q1: How does a forgetting model perform\nweights(Huetal.,2024). SAPT(Zhaoetal.,2024)\nwhenpassivelyprovidedwithexternallysup-\naligns parameter-efficient tuning blocks with se-\nplied“appropriaterationale”?\nlectionmodulesviaasharedattentionmechanism,\neffectivelytacklingbothcatastrophicforgettingand\nknowledgetransfer. (3)Replay-based methodsre- 2. Q2: Canchangingthepromptmethodenable\ntain a small subset of prior training examples or themodeltogeneratethe“appropriateratio-\nfeaturesandrevisitthemwhenanewtaskisintro- nale”actively?\n<s>[INST] Task: What is the logical relationship (contradiction, entailment forgettingperformancelevelforQwen2-0.5Band\nor neutral) between the \"sentence 1\" and the \"sentence 2\"? Choose one from Llama2-13B, values of k = 0.6 and k = 0.1 are\nthe option.\nrequired,respectively.\nOPTIONS:\n- neutral\n- entailment #Question#:\n- contradiction In this task, you are given a dialogue from a conversation between an agent\nand a customer. Your task is to determine the speaker of the dialogue.\nsentence 1: Case Study Evaluations. Answer with \"agent\" or \"customer\".\nsentence 2: Case Study preparations. Input: I have successfully booked your ticket with flight-1017, have a safe\njourney.\nAnswer: [/INST] The sentence 1 'Case Study Evaluations' implies a #Ratinale#:\nThe input consists of a statement confirming a ticket booking and wishing\nthe customer a safe journey. This type of communication is typically made\nFigure 3: Prompt example with additional k part of by a service provider, indicating that the speaker is the \"agent\".\n“appropriate”rationaleguidance(k =0.1). Theblack #Answer#:\nAgent\npartsaretheoriginalinstruction;Thegreenpartsarethe\n#Question#:\naddedpartofthe“appropriaterationale”, whichdoes\n[Question-2]\nnotcontaininformationdirectlyrelatedtotheanswer. #Ratinale#:\n[Ratinale-2]\n#Answer#:\n[Answer-2]\n3.1 AppropriateRationaleMeeting\n…\n“Pseudo-Forgetting”\n#Question#:\nIn this section, we address Q1. We selected the Task: What is the logical relationship (contradiction, entailment or neutral)\nbetween the \"sentence 1\" and the \"sentence 2\"? Choose one from the option.\nmodel from the final stage of sequential learning\nOPTIONS:\nand chose the test set of tasks with a high forget- - neutral\n- entailment\ntingratefortheexperiment. Tooffer“appropriate\n- contradiction\nknowledge” guidance, as shown in Figure 3, we\nsentence 1: Case Study Evaluations.\nappend k part of the rationale directly after the sentence 2: Case Study preparations.\n#Ratinale#:\noriginalinstruction. Itisimportanttonotethatthe\n{rationale generated by model}\nadded portion with small k does not directly pro- #Answer#:\n{answer generated by model}\nvidetask-specificoranswer-relevantinformation\nbut instead serves to guide the model in shaping Figure4: PromptexamplewithTask-AgnosticPrefix.\ntheoveralldirectionofitspredictions. Thedetailed Contexttemplate(purple)andtask-independentdemon-\nstrations(green)actastheprefixtotheoriginalinstruc-\ndescriptionoftheexperimentaldataandmodelis\ntion(black),formattingthefinalpromptthatguidesthe\nprovidedinSection5.1.\nmodelingeneratingrationaleandanswerusingparame-\nResults and Analysis Results are presented in terizedtaskknowledge.\nFigure2.\nFirstly, when a “forgotten” model passively\n3.2 RevivingDormantKnowledgevia\nreceivespartialguidanceon“appropriateratio-\nTask-AgnosticPrefixPrompting\nnale,” it can regenerate the “forgotten knowl-\nedge”andgraduallyrestoreits“pre-forgetting” In the experiment in Section 3.1, the model pas-\ntask performance. Specifically, across various sively received some “appropriate rationale” as\n“forgotten” tasks, performance improves with in- guidance, allowing it to recover its performance\ncreasing k-values, suggesting that the model’s gradually. To further verify and demonstrate our\nknowledge remains intact. The issue lies in the hypothesis, we address Q2 in this section. We\noriginalinstructions’inabilitytoelicittheappropri- utilizeTask-AgnosticPrefixPrompting(Yeetal.,\natereasoningprocesses. Withsome“appropriate 2024),whichenablesthemodeltogeneratearea-\nguidance,”themodelcanaccesstherelevanttask soningprocessforataskbasedonparameterized\nknowledgeandcompletethetask. knowledge. AsillustratedinFigure4,thismethod\nSecondly, the degree of recovery of the usesexamplesunrelatedtothetestingtasktoguide\nmodel’s “task memory” is related to the task themodelinproducingreasoningprocessesandan-\ndifficulty and the scale of the model. For in- swersthroughcontext-basedlearning. Notably,the\nstance, in the CB task, Mistral-7B returns to its generatedrationalereliesonparameterizedknowl-\npre-forgettingperformancelevelatk = 0.2,while edge rather than knowledge acquired from con-\nthe MNLI task requires k = 0.4 to achieve the text. This approach simply adds prefixes to the\nsamerecoverylevel. Meanwhile,torestorethepre- original instructions, making the detected knowl-\nFigure5: Performanceofthe‘forgetting’modelusingDirectInstructionPrompting(Ins)versusTask-Agnostic\nPrefixPrompting(TAP).BFreferstoBeforeForgettingandAFtoAfterForgetting.\nedgemorecloselyresembletheoriginal’forgotten this approach is less cost-effective. Building on\nknowledge’ in QA format, rather than adopting ourassumption, wearguethatreplay-basedalgo-\notherformats(Jiangetal.,2024). Thissimilarity rithms (Wang et al., 2024; Guo et al., 2024; Liu\nhighlights that the knowledge itself is intact, and etal.,2021)providethemoststraightforwardand\nthechallengeliesinthedifferencesin“guidance” efficientsolutiontomitigatecatastrophicforgetting.\nmethodsforgeneratingan“appropriaterationale.” Inthissection,wefirstintroduceanevaluationmet-\nric, Rationale-Guidance Difficulty, to assess the\nResults and Analysis Results are presented in\ndifficultyofguidingamodeltowardan’appropri-\nFigure5. Addinganappropriateprefixtotheorigi-\nate rationale’ for a given instruction. Based on\nnalinstructionenablesthemodeltogenerateanap-\nthismetric,wedynamicallyallocatereplaydatafor\npropriaterationaleandrecoveritsperformanceon\neachprevioustasktooptimizedatautilization.\nforgottentasks. Specifically,fordifferentforgetting\nmodels, a Task-Agnostic Prefix added before the 4.1 Rationale-GuidanceDifficulty\noriginalinstructionspartiallyrestoresperformance\nThe Rationale-Guidance Difficulty (RGD) score\nacrossvariousforgottentasks. Foroptimalprefix\nfor a given data pair (x,r,y) is calculated as fol-\nselection, we employed a grid search to identify\nlows:\nthebestdemonstrationsanddemonstrationcount\nPPL (r|x)\nθ\nforeachtask,highlightingthedependencyoftask RGD (x,r,y) = (1)\nθ\nPPL (r)\nrecovery on prefix design. We hypothesize that θ\nan optimal Task-Agnostic Prefix can restore per- Here,xdenotestheprompt,r representstheinfer-\nformancetopre-forgettinglevels. Notably,larger ence process, y is the answer, and θ refers to the\nmodels,suchasLlama2-13B,exhibithigherrecov- parametersofthemodelbeingtested. PPL (r)re-\nθ\nerylevelsthansmallermodelslikeLlama2-7Band flectsthedifficultyforthemodeltogeneratethera-\nMistral-7B,suggestingthatmodelsizecorrelates tionaler independently,whilePPL (r|x)measures\nθ\nwithresistanceto“forgetting”. thedifficultywhengeneratingrgiventhepromptx.\nTheRGDscoreindicateshowwellagivenprompt\nSummary Experimentalresultsindicatethatthe\nxfacilitatesthegenerationofrationaler. Ahigher\nperformance drop on previous tasks is primarily\nRGDscoresignifiesgreaterdifficultyforaprompt\nattributabletolimitationsinthepromptingmethod.\ninguidingthemodeltoproducetherationale,and\nThe model has not truly forgotten task-specific\nviceversa. Thecalculationmethodofthismetric\nknowledge; rather, the prompts fail to effectively\nfollowstheInstructionFollowingDifficulty(IFD)\nguide the generation of the appropriate rationale,\nscore proposed by Li et al. (2024b), though the\ngivingtheimpressionofforgottenknowledge.\nIFDscorewasprimarilyusedforfine-tuningdata\nselection(Lietal.,2024a,b).\n4 ReplayBasedonRationale-Guidance\nForagivenprevioustaskt,weestimateitsRGD\nDifficulty\nscoreusingasetoftestdataV:\nWhile it is possible to recover the performance\nof a forgotten model using appropriate prompts, RGDt = Mean(RGD ) (2)\nθ V\nMean(RGD ) represents the mean and variance of 15classificationdatasets. Following(Razdaibied-\nV\ntheRGDscoreonthetestdatasetV. ina et al., 2023; Wang et al., 2023b), we select\n1,000 random samples for training each task and\n4.2 UnderstandingForgettingvia\nholdout500samplesperclassforvalidationand\nRationale-GuidanceDifficulty\ntesting.\nWeemployedQwen2.5-72B-Instruct1 togener-\nForget mean std Acc atearationalerforeachdatapoint(x,y),ensuring\nthattheinitialpartoftherationaledidnotdirectly\nFalse 39.77 13.67 78.40\nrevealthefinalanswer. Followingpriorwork(Zhao\nTrue 45.71 38.75 60.00\netal.,2024),weemploytwodifferenttrainingor-\nTable1: RGD (x,r,y)scores(scaledby1e-4)compari- dersinourexperiment.\nθ\nsonfortheQQPtaskonMistral-7Bwithandwithout\n5.1.2 Models\nforgetting.\nWeutilizeQwen2(0.5B,1.5B)(Yangetal.,2024),\nTable1showstheRGDscoresfortheMistral-7B Llama2 (7B, 13B) (Touvron et al., 2023b), and\nmodelontheQQPtask,beforeandafterforgetting. Mistral (7B) (Jiang et al., 2023) as the backbone\nBeforeforgetting,themodelexhibitslowerRGD modelsforourexperiments.\nscores,indicatingthattheinstructionsfortheQQP\n5.1.3 Baselines\ntaskeasilyguidethemodeltotherelevantknowl-\nedge, resulting in better performance. However, Weprimarilyevaluatevariousdataallocationmeth-\nafterforgetting,theRGDscoresincrease,suggest- odsforreplay. Forcomparison,weusethefollow-\ning that the instructions become less effective at ing baseline allocation methods, employing ran-\nguidingthemodeltotherelevantknowledge,lead- dom sampling to select replay samples for each\ningtoadeclineintaskperformance. task.\n4.3 DynamicReplayStrategy EqualAllocation(EA) Foreachprevioustask,\nwereplaythesameamountofsampleswhilelearn-\nWangetal.(2024)proposedeterminingthepropor-\ninganewtasktomaintainthepreviouscapability.\ntion of replay data based on task similarity, sug-\ngesting that tasks with greater differences from InsCL InsCL (Wang et al., 2024) dynamically\nthecurrentlearningtaskshouldhavemorereplay replayspreviousdatabasedontasksimilarity,cal-\ndata. Incontrast,wearguethatthemodel’scapac- culatedbyWassersteinDistancewithinstructions.\nitytolearnandexecutetasksiscrucial,makingit\nMulti-taskLearning Weusemulti-tasklearning\nmore reasonable to allocate replay data based on\nastheupperboundforcontinuallearning.\nthemodel’sdifficultyingeneratingrationalesfrom\npriorinstructions.\n5.1.4 Metrics\nWhentrainingthemodelonthecurrenttaskT ,\ni\nAccordingtopreviousworks(Zhangetal.,2023b;\ntheamountofreplaydatarequiredfortheprevious\nLopez-Paz and Ranzato, 2017; Biesialska et al.,\ntaskT calculatedasfollows:\nj\n2020),weusethefollowingCL-relatedmetricsthat\nRGDj\nconcentrate on catastrophic forgetting (stability)\nα∗ = θi−1 ×α, j ∈ [1,i−1] (3)\nj (cid:80)k=i−1RGDk andknowledgetransfer(plasticity). Leta i,j bethe\nk=1 θi−1 testing performance (Accuracy for classification\nwhere RGDj represents the rationale-guidance taskandRouge-Lforothers)onthej-thtaskafter\ndifficultyoθ fi− ta1 skj afterthemodelhascompleted trainingoni-thtask,themetricsforevaluatingare:\ntraining on task i−1, and α represents the total\nFinalAveragePerformance(FAP) Theaverage\namountofreplaydata.\nperformance of all tasks after the final task t is\nT\n5 Experiments learned,i.e.,FAP T = T1 (cid:80)T t=1a T,t;\n5.1 ExperimentsSetup ForgettingRate(F.Ra) Itmeasureshowmuch\nknowledgehasbeenforgottenacrossthefirstT −1\n5.1.1 Datasets\ntasks,i.e.,F = 1 (cid:80)T−1(maxT−1a −a );\nLong Sequence Benchmark (Razdaibiedina T T−1 t=1 k=i k,t T,t\net al., 2023) A continual learning benchmark of 1https://huggingface.co/Qwen/Qwen2.5-72B-Instruct\nMethod Allocate Select FAP↑ F.Ra↓ BWT↑ FWT↑ CAP↑\nQwen2-0.5B\nSingle - - 72.64 - - - 72.64\nMulti - - 76.32 - - - 76.32\nCL - - 51.75 23.13 -22.98 0.33 72.97\nEA equal random 71.78 3.40 -2.02 1.0 73.65\nInsCL instDiff random 74.06 1.55 0.15 1.27 73.91\nRGD mean random 74.69 0.59 0.67 1.43 74.07\nLlama2-7B\nSingle - - 77.62 - - - 77.62\nMulti - - 80.57 - - - 80.57\nCL - - 66.50 14.91 -14.79 2.54 80.16\nEA equal random 78.59 2.62 -1.77 2.60 80.22\nInsCL instDiff random 80.56 0.90 0.94 2.06 79.69\nRGD mean random 81.07 0.80 1.21 2.33 79.95\nMistral-7B\nSingle - - 79.01 - - - 79.01\nMulti - - 78.79 - - - 78.79\nCL - - 69.09 10.73 -10.27 -0.33 78.68\nEA equal random 76.01 3.58 -2.88 -0.31 78.69\nInsCL instDiff random 76.25 3.54 -1.86 -1.02 77.97\nRGD mean random 76.42 3.45 -1.85 -0.86 78.14\nLlama2-13B\nSingle - - 73.91 - - - 73.91\nMulti - - 83.48 - - - 83.48\nCL - - 70.27 13.02 -12.90 3.01 82.17\nEA equal random 80.81 1.75 -1.27 2.83 81.98\nInsCL instDiff random 81.86 1.09 -0.07 2.77 81.93\nRGD mean-std random 81.05 1.75 -1.30 3.10 82.26\nTable2: ExperimentsofdifferentmodelsonLongSequenceBenchmark. Thedecodingstrategyisgreedysearch.\nOurmethodeffectivelyalleviatesmodelforgettingandmaintainsbettermodelplasticitysimultaneously\nBackward Transfer (BWT) BWT measures The equal allocation method significantly re-\nthe impact that continually learning on subse- duces catastrophic forgetting compared to no\nquent tasks has on previous tasks, i.e., BWT = datareplay Forexample,withQwen2-0.5B,ran-\nT\n1 (cid:80)T−1(a −a ). dom data replay improved task performance by\nT−1 t=1 T,t t,t\n20.03 and reduced the forgetting rate by 19.73.\nForwardTransfer(FWT) FWTmeasureshow\nSimilarly, for Mistral-7B, task performance in-\nmuchknowledgefromprevioustaskstransfersto\ncreasedby6.92andtheforgettingratedecreased\na new task, i.e., FWT = 1 (cid:80)T (a − a )\nT T t=1 t,t 0,t by 7.15. These results support our hypothesis\nwhere a refers to the performance of training\n0,t thatmodelperformancedegradationisduetoinef-\ntasktindividually;\nfectivetaskinstructions,notforgottenknowledge.\nSimpledatareplay,usingasmallamountofdata,\nCurrentAveragePerformance(CAP) Theav-\nhelpsthemodelleverageoldknowledgemoreef-\nerage performance of all tasks in their respective\ntrainingstage,i.e.,CAP = 1 (cid:80)T a . fectively,alleviatingcatastrophicforgetting.\nT T t=1 t,t\nBetterscoresonFAP,F.Ra, andBWTindicate\nThe model exhibits inherent resistance to for-\nimproved model stability, while better scores on\ngetting,whichimproveswithlargermodelsizes\nFWTandCAPreflectenhancedmodelplasticity.\nSpecifically,largermodelsshowlowerforgetting\nratesduringcontinuallearningwithoutdatareplay.\n5.2 ResultsandAnalysis\nForexample,theforgettingratesforLlama2-13B\nTable2presentsaperformancecomparisonofdif-\nandQwen2-0.5Bare13.02and23.13,respectively.\nferentreplaydataallocationmethodsontheLong\nSequence benchmark. All results are averaged Usingadataallocationalgorithmcanfurtheral-\nacross two different task orders. Detailed results leviatemodelforgetting Ourmodel-baseddata\nforeachorderandtaskwithinaspecificorderare allocation method, along with the InsCL method\nprovidedintheAppendix. thatallocatesdatabasedonsimilarity,bothmore\nBasedonthepremise“Thenorthernertookhiscloakandhatfromthesmallboyandaleather\nTestInstruction sackofcoinfromoneofthemeninthecrowd.”,canweconcludethehypothesis\nofMNLI “Thenorthernerlefthiscloakandhatbehind,”istrue?\nOPTIONS:-yes-itisnotpossibletotell-no\nThetextsuggeststhatthenorthernertakeshisbelongings,i.e.,hiscloakandhat,withhim.\nPredictionBF Italsomentionsa“smallboy”whowasabletotakesomethingfromhimsohemayhavetaken\nstageonMNLI(NLI) hisbelt,whichisanotherpieceofclothing.Soweknowthatthishypothesiscannotbetruebased\nonwhathasalreadybeenstated.[RESULT]no\nThepassagestatesthatthenorthernertookhiscloakandhat,whichmeanshewastherebefore\nPredictionBF\ntakingthem.Therefore,thisstatementcontradictsthehypothesis.\nstageonCB(NLI)\nSo,“yes”wouldbeouranswerhere.[RESULT]yes\nPredictionBF\nThisquestionbelongstothetopicofprobabilitytheory,sotheansweris0.[RESULT]0\nstageonYahoo(TC)\nTable3:CasesofKnowledgeDriftandInstructionDrift.1. BFreferstoBeforeForgettingandAFtoAfterForgetting.\n2. NLImeansNaturalLanguageInferenceandTCindicatesTopicClassification.\neffectivelymitigatecatastrophicforgettinginmod- Additionally,canthesetypesofdriftbedetected\nelsofvaryingsizesandknowledgesourcesduring by specific methods? For instance, could differ-\ncontinuallearning,resultinginbetterfinalmodel encesinmodelhiddenlayerrepresentationsreveal\nperformance. their presence? Is there a big difference between\ntheRationale-GuidanceDifficultyinthetwocases?\nOurmethodeffectivelyalleviatesmodelforget-\ntingandmaintainsbettermodelplasticitysimul- More Complex Scenarios Current continual\ntaneously Formodelplasticitymetrics,FWTand learningbenchmarksrelyontraditionalNLPtasks,\nCAP,ourmethodperformssimilarlytoInsCLon whichmayberelativelysimpleandthuslesslikely\nLlama2-7B. However, on other models, our ap- toinduceforgettinginthemodel. Toenhancethe\nproachoutperformsInsCL,suggestingthatitoffers credibility of our conclusions, more complex do-\namoreeffectivebalancebetweenmitigatingcatas- mainadaptationdatasets,suchasTRACE(Wang\ntrophicforgettingandpreservingmodelplasticity. et al., 2023c), could be utilized to replicate the\nexperiments.\n6 DiscussionandFutureWork\nDesignofContinualLearningAlgorithm Our\nWhatdoestherationalegeneratedbya“pseudo-\nstudyassumesthatthemodelretainspriorknowl-\nforgetting”modellooklikeundertheguidance\nedge during continual learning and inherently re-\nof old instructions? As shown in Table 3, our\nsistsforgetting,makingsimpledatareplayeffective\npreliminaryobservationssuggestthattheinappro-\ninmitigatingcatastrophicforgetting. Anotherkey\npriaterationaleswhichwecallthisRationaleDrift\ngoal of continual learning is to maximize asyn-\ngeneratedby“pseudo-forgetting”modelsprimarily\nchronous knowledge transfer across tasks to en-\nfallintotwocategories:\nhancemodelperformance. Giventhatpriorknowl-\n1. Instruction Drift (Misalignment): When edgeisparameterized,weproposethatacombined\nthere is a significant difference between old approach,integratingbothparametricanddatare-\nand new tasks (e.g., the old task is Natural playperspectives,maybethemosteffective.\nLanguage Inference (NLI), the new task is\nTopicClassification(TC)),thereasoningpro- 7 Conclusion\ncesstendstocompletelyrelyonTC-relevant\nThisstudyshedslightontheintrinsicmechanism\nknowledge due to instruction misalignment,\nbehind catastrophic forgetting in continual learn-\nleadingtoincorrectresults.\ning,revealingthattaskknowledgeisnottrulylost\n2. Knowledge Drift: When old and new tasks but hindered by inadequate instruction guidance\nare similar (e.g., both NLI but from differ- forappropriaterationales. Wevalidatethishypoth-\nentdomains),therationaleremainsrelatedto esiswithinLLMsandwithconsistentknowledge\nNLIknowledgebutisinfluencedbythenew expression by subjecting the forgetting model to\ndomain’s knowledge. This causes deviation passiveexternalknowledgeguidanceandincorpo-\nfromtheappropriatereasoningpath,resulting rating a task-agnostic prefix into the original in-\ninerrors. struction for an active generation, both of which\neffectivelyrecovertheperformanceoftheforget- in large language models with self-synthesized re-\nting model. We introduce a Rationale-Guidance hearsal. InProceedingsofthe62ndAnnualMeeting\noftheAssociationforComputationalLinguistics(Vol-\nDifficulty, which evaluates the difficulty of guid-\nume1: LongPapers),ACL2024,Bangkok,Thailand,\ningthemodeltogenerateappropriaterationales—a\nAugust11-16,2024,pages1416–1428.Association\ncriticalfactorinovercomingforgetting. Usingthis forComputationalLinguistics.\nmetric,ourproposedreplaydataallocationmethod\nYufanHuang,YanzheZhang,JiaaoChen,XuezhiWang,\neffectivelymitigatesforgettingwhilemaintaining\nandDiyiYang.2021. Continuallearningfortextclas-\nmodelplasticity.\nsification with information disentanglement based\nregularization. InProceedingsofthe2021Confer-\nence of the North American Chapter of the Asso-\nReferences ciationforComputationalLinguistics: HumanLan-\nguageTechnologies,NAACL-HLT2021,Online,June\nRahaf Aljundi, Francesca Babiloni, Mohamed Elho-\n6-11,2021,pages2736–2746.AssociationforCom-\nseiny,MarcusRohrbach,andTinneTuytelaars.2018.\nputationalLinguistics.\nMemory aware synapses: Learning what (not) to\nforget. InComputerVision-ECCV2018-15thEu-\nAlbert Q Jiang, Alexandre Sablayrolles, Arthur Men-\nropean Conference, Munich, Germany, September\nsch,ChrisBamford,DevendraSinghChaplot,Diego\n8-14,2018,Proceedings,PartIII,volume11207of\ndelasCasas,FlorianBressand,GiannaLengyel,Guil-\nLectureNotesinComputerScience,pages144–161.\nlaumeLample,LucileSaulnier,etal.2023. Mistral\nSpringer.\n7b. arXivpreprintarXiv:2310.06825.\nMagdalena Biesialska, Katarzyna Biesialska, and\nGangweiJiang,CaigaoJiang,ZhaoyiLi,SiqiaoXue,\nMartaRCosta-Jussa.2020. Continuallifelonglearn-\nJun Zhou, Linqi Song, Defu Lian, and Ying Wei.\ninginnaturallanguageprocessing: Asurvey. arXiv\n2024. Interpretablecatastrophicforgettingoflarge\npreprintarXiv:2012.09823.\nlanguage model fine-tuning via instruction vector.\nCoRR,abs/2406.12227.\nTomB.Brown,BenjaminMann,NickRyder,Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nSuhasKotha,JacobMitchellSpringer,andAditiRaghu-\nNeelakantan,PranavShyam,GirishSastry,Amanda\nnathan.2024. Understandingcatastrophicforgetting\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nin language models via implicit inference. In The\nGretchen Krueger, Tom Henighan, Rewon Child,\nTwelfthInternationalConferenceonLearningRep-\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nresentations,ICLR2024,Vienna,Austria,May7-11,\nClemens Winter, Christopher Hesse, Mark Chen,\n2024.OpenReview.net.\nEricSigler,MateuszLitwin,ScottGray,Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nMingLi, YongZhang, ShwaiHe, ZhitaoLi, Hongyu\nCandlish, AlecRadford, IlyaSutskever, andDario\nZhao,JianzongWang,NingCheng,andTianyiZhou.\nAmodei.2020. Languagemodelsarefew-shotlearn-\n2024a. Superfiltering: Weak-to-strongdatafiltering\ners. Preprint,arXiv:2005.14165.\nfor fast instruction-tuning. In Proceedings of the\n62ndAnnualMeetingoftheAssociationforCompu-\nIan J. Goodfellow, Mehdi Mirza, Xia Da, Aaron C.\ntationalLinguistics(Volume1: LongPapers),ACL\nCourville,andYoshuaBengio.2014. Anempirical\n2024,Bangkok,Thailand,August11-16,2024,pages\ninvestigation of catastrophic forgeting in gradient-\n14255–14273. Association for Computational Lin-\nbasedneuralnetworks. In2ndInternationalConfer-\nguistics.\nenceonLearningRepresentations,ICLR2014,Banff,\nAB, Canada, April 14-16, 2014, Conference Track\nMingLi,YongZhang,ZhitaoLi,JiuhaiChen,Lichang\nProceedings.\nChen,NingCheng,JianzongWang,TianyiZhou,and\nJiafeng Guo, Changjiang Zhou, Ruqing Zhang, Jian- JingXiao.2024b. Fromquantitytoquality:Boosting\nguiChen,MaartendeRijke,YixingFan,andXueqi LLM performance with self-guided data selection\nCheng.2024. Corpusbrain++: Acontinualgenera- for instruction tuning. In Proceedings of the 2024\ntivepre-trainingframeworkforknowledge-intensive Conference of the North American Chapter of the\nlanguagetasks. CoRR,abs/2402.16767. AssociationforComputationalLinguistics: Human\nLanguage Technologies (Volume 1: Long Papers),\nYusongHu,DeCheng,DingwenZhang,NannanWang, NAACL2024,MexicoCity,Mexico,June16-21,2024,\nTongliangLiu,andXinboGao.2024. Task-awareor- pages 7602–7635. Association for Computational\nthogonalsparsenetworkforexploringsharedknowl- Linguistics.\nedge in continual learning. In Forty-first Interna-\ntionalConferenceonMachineLearning,ICML2024, Qingbin Liu, Pengfei Cao, Cao Liu, Jiansong Chen,\nVienna,Austria,July21-27,2024.OpenReview.net. XunliangCai,FanYang,ShizhuHe,KangLiu,and\nJunZhao.2021. Domain-lifelonglearningfordia-\nJianheng Huang, Leyang Cui, Ante Wang, Chengyi loguestatetrackingviaknowledgepreservationnet-\nYang,XintingLiao,LinfengSong,JunfengYao,and works. In Proceedings of the 2021 Conference on\nJinsongSu.2024. Mitigatingcatastrophicforgetting EmpiricalMethodsinNaturalLanguageProcessing,\nEMNLP2021,VirtualEvent/PuntaCana,Domini- XiaoWang,TianzeChen,QimingGe,HanXia,Rong\ncan Republic, 7-11 November, 2021, pages 2301– Bao,RuiZheng,QiZhang,TaoGui,andXuanjing\n2311.AssociationforComputationalLinguistics. Huang.2023b. Orthogonalsubspacelearningforlan-\nguagemodelcontinuallearning. InFindingsofthe\nDavid Lopez-Paz and Marc’Aurelio Ranzato. 2017. AssociationforComputationalLinguistics: EMNLP\nGradientepisodicmemoryforcontinuallearning. Ad- 2023,pages10658–10671,Singapore.Association\nvancesinneuralinformationprocessingsystems,30. forComputationalLinguistics.\nMichaelMcCloskeyandNealJ.Cohen.1989. Catas- XiaoWang,YuansenZhang,TianzeChen,Songyang\ntrophicinterferenceinconnectionistnetworks: The Gao, Senjie Jin, Xianjun Yang, Zhiheng Xi, Rui\nsequentiallearningproblem. volume24ofPsychol- Zheng,YichengZou,TaoGui,etal.2023c. Trace:\nogyofLearningandMotivation,pages109–165.Aca- A comprehensive benchmark for continual learn-\ndemicPress. ing in large language models. arXiv preprint\narXiv:2310.06762.\nChengwei Qin and Shafiq R. Joty. 2022. LFPT5: A\nunified framework for lifelong few-shot language YifanWang,YafeiLiu,ChufanShi,HaolingLi,Chen\nlearningbasedonprompttuningofT5. InTheTenth Chen,HaonanLu,andYujiuYang.2024. Inscl: A\nInternational Conference on Learning Representa- data-efficient continual learning paradigm for fine-\ntions,ICLR2022,VirtualEvent,April25-29,2022. tuninglargelanguagemodelswithinstructions. In\nOpenReview.net. Proceedings of the 2024 Conference of the North\nAmericanChapteroftheAssociationforComputa-\nAnastasiaRazdaibiedina,YuningMao,RuiHou,Ma- tionalLinguistics: HumanLanguageTechnologies\ndian Khabsa, Mike Lewis, and Amjad Almahairi. (Volume1: LongPapers),NAACL2024,MexicoCity,\n2023. Progressiveprompts: Continuallearningfor Mexico,June16-21,2024,pages663–677.Associa-\nlanguage models. In International Conference on tionforComputationalLinguistics.\nLearningRepresentations.\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng,\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al- BowenYu,ChangZhou,ChengpengLi,Chengyuan\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2\nBashlykov,SoumyaBatra,PrajjwalBhargava,Shruti technicalreport. arXivpreprintarXiv:2407.10671.\nBhosale,DanBikel,LukasBlecher,CristianCanton\nYizhe Yang, Huashan Sun, Jiawei Li, Runheng Liu,\nFerrer,MoyaChen,GuillemCucurull,DavidEsiobu,\nYinghao Li, Yuhang Liu, Heyan Huang, and Yang\nJudeFernandes,JeremyFu,WenyinFu,BrianFuller,\nGao.2023. Mindllm: Pre-traininglightweightlarge\nCynthiaGao,VedanujGoswami,NamanGoyal,An-\nlanguage model from scratch, evaluations and do-\nthonyHartshorn,SagharHosseini,RuiHou,Hakan\nmainapplications. Preprint,arXiv:2310.15777.\nInan,MarcinKardas,ViktorKerkez,MadianKhabsa,\nIsabelKloumann,ArtemKorenev,PunitSinghKoura,\nSeonghyeon Ye, Hyeonbin Hwang, Sohee Yang,\nMarie-AnneLachaux,ThibautLavril,JenyaLee,Di-\nHyeonguYun,YireunKim,andMinjoonSeo.2024.\nanaLiskovich,YinghaiLu,YuningMao,XavierMar-\nInvestigatingtheeffectivenessoftask-agnosticprefix\ntinet,TodorMihaylov,PushkarMishra,IgorMoly-\npromptforinstructionfollowing. InThirty-Eighth\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nAAAI Conference on Artificial Intelligence, AAAI\nstein,RashiRungta,KalyanSaladi,AlanSchelten,\n2024,Thirty-SixthConferenceonInnovativeApplica-\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\ntionsofArtificialIntelligence,IAAI2024,Fourteenth\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nSymposium on Educational Advances in Artificial\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nIntelligence,EAAI2014,February20-27,2024,Van-\nZhengYan,IliyanZarov,YuchenZhang,AngelaFan,\ncouver,Canada,pages19386–19394.AAAIPress.\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez,RobertStojnic,SergeyEdunov,andThomas DuzhenZhang,WeiCong,JiahuaDong,YahanYu,Xi-\nScialom.2023a. Llama2: Openfoundationandfine- uyiChen,YonggangZhang,andZhenFang.2023a.\ntunedchatmodels. Preprint,arXiv:2307.09288. Continual named entity recognition without catas-\ntrophicforgetting. InProceedingsofthe2023Con-\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nferenceonEmpiricalMethodsinNaturalLanguage\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nProcessing,EMNLP2023,Singapore,December6-\nBashlykov,SoumyaBatra,PrajjwalBhargava,Shruti\n10,2023,pages8186–8197.AssociationforCompu-\nBhosale, et al. 2023b. Llama 2: Open founda-\ntationalLinguistics.\ntion and fine-tuned chat models. arXiv preprint\narXiv:2307.09288. ZihanZhang,MengFang,LingChen,andMohammad-\nRezaNamazi-Rad.2023b. CITB:Abenchmarkfor\nXiaoWang,TianzeChen,QimingGe,HanXia,Rong continualinstructiontuning. InFindingsoftheAs-\nBao,RuiZheng,QiZhang,TaoGui,andXuanjing sociation for Computational Linguistics: EMNLP\nHuang.2023a. Orthogonalsubspacelearningforlan- 2023,pages9443–9455,Singapore.Associationfor\nguagemodelcontinuallearning. InFindingsofthe ComputationalLinguistics.\nAssociationforComputationalLinguistics: EMNLP\n2023,Singapore,December6-10,2023,pages10658– WeixiangZhao,ShilongWang,YulinHu,YanyanZhao,\n10671.AssociationforComputationalLinguistics. Bing Qin, Xuanyu Zhang, Qing Yang, Dongliang\nXu,andWanxiangChe.2024. SAPT:Asharedat-\ntentionframeworkforparameter-efficientcontinual\nlearningoflargelanguagemodels. InProceedings\nof the 62nd Annual Meeting of the Association for\nComputationalLinguistics(Volume1: LongPapers),\nACL2024,Bangkok,Thailand,August11-16,2024,\npages11641–11661.AssociationforComputational\nLinguistics.\nYingxiuZhao,YinheZheng,ZhiliangTian,ChangGao,\nJianSun,andNevinL.Zhang.2022. Promptcondi-\ntionedVAE:enhancinggenerativereplayforlifelong\nlearningintask-orienteddialogue. InProceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing, EMNLP 2022, Abu\nDhabi,UnitedArabEmirates,December7-11,2022,\npages11153–11169.AssociationforComputational\nLinguistics.\nJunhao Zheng, Shengjie Qiu, Chengming Shi, and\nQianliMa.2024. Towardslifelonglearningoflarge\nlanguagemodels: Asurvey. CoRR,abs/2406.06391.\nFanZhouandChengtaiCao.2021. Overcomingcatas-\ntrophicforgettingingraphneuralnetworkswithex-\nperience replay. In Thirty-Fifth AAAI Conference\non Artificial Intelligence, AAAI 2021, Thirty-Third\nConferenceonInnovativeApplicationsofArtificial\nIntelligence, IAAI 2021, The Eleventh Symposium\non Educational Advances in Artificial Intelligence,\nEAAI2021,VirtualEvent,February2-9,2021,pages\n4714–4722.AAAIPress.",
    "pdf_filename": "Reviving_Dormant_Memories_Investigating_Catastrophic_Forgetting_in_Language_Models_through_Rationale.pdf"
}