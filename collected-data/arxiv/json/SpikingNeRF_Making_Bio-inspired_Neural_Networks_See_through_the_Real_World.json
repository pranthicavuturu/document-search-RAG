{
    "title": "SpikingNeRF: Making Bio-inspired Neural Networks See through the Real World",
    "abstract": "Mip-NeRF Synthetic-NeRF Inthispaper,weproposeSpikingNeRF,whichalignsthetem- NSVF DIVeR BlendedMVS poraldimensionofspikingneuralnetworks(SNNs)withthe DVGO radiance rays, to seamlessly accommodate SNNs to the re- TensoRF constructionofneuralradiancefields(NeRF).Thus,thecom- SpiNeRF-T SpiNeRF-D putation turns into a spike-based, multiplication-free man- ner, reducing energy consumption and making high-quality 3Drendering,forthefirsttime,accessibletoneuromorphic hardware.InSpikingNeRF,eachsampledpointontherayis matched to a particular time step and represented in a hy- brid manner where the voxel grids are maintained as well. Based on the voxel grids, sampled points are determined whether to be masked out for faster training and inference. However, this masking operation also incurs irregular tem- Figure 1: Comparisons of our SpikingNeRF with other poral length, making it intractable for hardware processors, NeRF-basedworksinsynthesisqualityandmodelrendering e.g.,GPUs,toconductparalleltraining.Toaddressthisprob- lem,wedevelopthetemporalpaddingstrategytotacklethe energy. Different colors represent different works, and our maskedsamplestomaintainregulartemporallength,i.e.,reg- SpikingNeRF with two different frameworks are denoted ular tensors, and further propose the temporal condensing inredandviolet,respectively.Adetailednotationexplana- strategytoformadenserdatastructureforhardware-friendly tionisspecifiedintheExperimentssection.Differenttesting computation. Experiments on various datasets demonstrate datasetsaredenotedbydifferentshapes. thatourmethodcanreduceenergyconsumptionbyanaver- ageof70.79%andobtaincomparablesynthesisqualitywith the ANN baseline. Verification on the neuromorphic hard- ware accelerator also shows that SpikingNeRF can further 2022),objectdetection(Zhangetal.2022),graphprediction benefit from neuromorphic computing over the ANN base- (Zhuetal.2022b),naturallanguageprocessing(Zhu,Zhao, lines on energy efficiency. Codes and the appendix are in and Eshraghian 2023), etc. Besides multi-task supporting, https://github.com/Ikarosy/SpikingNeRF-of-CASIA. SNNresearchisalsothrivinginperformanceliftinganden- ergyefficiencyexplorationatthesametime. Introduction However, we have not yet witnessed the establishment of SNN in the real 3D reconstruction task with advanced Spiking neural networks (SNNs) are considered the third performance. Let alone enabling the high-quality real 3D generation of neural networks, and their bionic modeling rendering on neuromorphic hardwares, e.g., Loihi (Davies encouragesmuchresearchattentiontoexploretheprospec- etal.2018),PTB(Lee,Zhang,andLi2022),andSpikeSim tivebio-plausibleintelligencethatfeaturesmultitaskingand (Moitra et al. 2023), where neuromorphic computing can extreme energy efficiency as the human brain does (Maass essentially acquire low-energy consumption. Meanwhile, 1997; Roy, Jaiswal, and Panda 2019). While much dedica- high-quality real 3D reconstruction, specifically for NeRF tion has been devoted to SNN research, the gap between (Mildenhall et al. 2021), has suffered huge computation the expectation of SNN boosting a wider range of intelli- overheadduringrendering,consumingasignificantmagni- genttasksandthefactofartificialneuralnetworks(ANNs) tude of energy (Garbin et al. 2021). Naturally, this raises a dominatingdeeplearninginthemajorityoftasksstillexists. question:couldbio-inspiredspikingneuralnetworksrecon- Recently, more research interests have been invested in struct the real 3D scene with advanced quality at low en- narrowing the gap and have promoted notable milestones ergyconsumption?Thispaperinvestigatestherenderingof invarious tasks,includingimage classification(Zhouet al. neuralradiancefieldswithaspikingapproachtoanswerthe *Equalcontribution. question. †Correspondingauthor. WeproposeSpikingNeRFtoreconstructvolumetricscene 4202 voN 91 ]EN.sc[ 4v78901.9032:viXra",
    "body": "SpikingNeRF: Making Bio-inspired Neural Networks See through the Real World\nXingtingYao1,2*,QinghaoHu1∗,FeiZhou3,TielongLiu1,2,\nZitaoMo1,ZeyuZhu1,2,ZhengyangZhuge1,JianCheng1†\n1InstituteofAutomation,ChineseAcademyofSciences\n2SchoolofFutureTechnology,UniversityofChineseAcademyofSciences\n3ChinaElectricPowerResearchInstituteCo.,Ltd\n{yaoxingting2020, huqinghao2014, jian.cheng}@ia.ac.cn,\nAbstract NeRF Synthetic-NSVF\nMip-NeRF\nSynthetic-NeRF\nInthispaper,weproposeSpikingNeRF,whichalignsthetem- NSVF\nDIVeR BlendedMVS\nporaldimensionofspikingneuralnetworks(SNNs)withthe\nDVGO\nradiance rays, to seamlessly accommodate SNNs to the re- TensoRF\nconstructionofneuralradiancefields(NeRF).Thus,thecom- SpiNeRF-T\nSpiNeRF-D\nputation turns into a spike-based, multiplication-free man-\nner, reducing energy consumption and making high-quality\n3Drendering,forthefirsttime,accessibletoneuromorphic\nhardware.InSpikingNeRF,eachsampledpointontherayis\nmatched to a particular time step and represented in a hy-\nbrid manner where the voxel grids are maintained as well.\nBased on the voxel grids, sampled points are determined\nwhether to be masked out for faster training and inference.\nHowever, this masking operation also incurs irregular tem-\nFigure 1: Comparisons of our SpikingNeRF with other\nporal length, making it intractable for hardware processors,\nNeRF-basedworksinsynthesisqualityandmodelrendering\ne.g.,GPUs,toconductparalleltraining.Toaddressthisprob-\nlem,wedevelopthetemporalpaddingstrategytotacklethe energy. Different colors represent different works, and our\nmaskedsamplestomaintainregulartemporallength,i.e.,reg- SpikingNeRF with two different frameworks are denoted\nular tensors, and further propose the temporal condensing inredandviolet,respectively.Adetailednotationexplana-\nstrategytoformadenserdatastructureforhardware-friendly tionisspecifiedintheExperimentssection.Differenttesting\ncomputation. Experiments on various datasets demonstrate datasetsaredenotedbydifferentshapes.\nthatourmethodcanreduceenergyconsumptionbyanaver-\nageof70.79%andobtaincomparablesynthesisqualitywith\nthe ANN baseline. Verification on the neuromorphic hard-\nware accelerator also shows that SpikingNeRF can further 2022),objectdetection(Zhangetal.2022),graphprediction\nbenefit from neuromorphic computing over the ANN base- (Zhuetal.2022b),naturallanguageprocessing(Zhu,Zhao,\nlines on energy efficiency. Codes and the appendix are in and Eshraghian 2023), etc. Besides multi-task supporting,\nhttps://github.com/Ikarosy/SpikingNeRF-of-CASIA. SNNresearchisalsothrivinginperformanceliftinganden-\nergyefficiencyexplorationatthesametime.\nIntroduction However, we have not yet witnessed the establishment\nof SNN in the real 3D reconstruction task with advanced\nSpiking neural networks (SNNs) are considered the third\nperformance. Let alone enabling the high-quality real 3D\ngeneration of neural networks, and their bionic modeling\nrendering on neuromorphic hardwares, e.g., Loihi (Davies\nencouragesmuchresearchattentiontoexploretheprospec-\netal.2018),PTB(Lee,Zhang,andLi2022),andSpikeSim\ntivebio-plausibleintelligencethatfeaturesmultitaskingand\n(Moitra et al. 2023), where neuromorphic computing can\nextreme energy efficiency as the human brain does (Maass\nessentially acquire low-energy consumption. Meanwhile,\n1997; Roy, Jaiswal, and Panda 2019). While much dedica-\nhigh-quality real 3D reconstruction, specifically for NeRF\ntion has been devoted to SNN research, the gap between\n(Mildenhall et al. 2021), has suffered huge computation\nthe expectation of SNN boosting a wider range of intelli-\noverheadduringrendering,consumingasignificantmagni-\ngenttasksandthefactofartificialneuralnetworks(ANNs)\ntude of energy (Garbin et al. 2021). Naturally, this raises a\ndominatingdeeplearninginthemajorityoftasksstillexists.\nquestion:couldbio-inspiredspikingneuralnetworksrecon-\nRecently, more research interests have been invested in\nstruct the real 3D scene with advanced quality at low en-\nnarrowing the gap and have promoted notable milestones\nergyconsumption?Thispaperinvestigatestherenderingof\ninvarious tasks,includingimage classification(Zhouet al.\nneuralradiancefieldswithaspikingapproachtoanswerthe\n*Equalcontribution. question.\n†Correspondingauthor. WeproposeSpikingNeRFtoreconstructvolumetricscene\n4202\nvoN\n91\n]EN.sc[\n4v78901.9032:viXra\nrepresentations of neural radiance fields. For fast synthe- example,SpikingNeRF-Dcanachieve72.95%energyre-\nsis, voxel grids methods (Hedman et al. 2021; Liu et al. ductionwitha0.33PSNRdroponTanks&Temples.\n2022;Sun,Sun,andChen2022)areconsideredtoexplicitly\nIn order to avoid misunderstanding, we additionally cite\nstore the volumetric parameters. For efficient computation,\n(Liaoetal.2023)whichsharesthesametitleasours.Their\nthe spiking multilayer perceptron (sMLP) is utilized to im-\nwork,basedontheANNimplementation,essentiallybuilds\nplicitlyyieldvolumetricinformationinanaddition-onlyand\na non-linear and non-spike function named B-FIF to post-\nspike-driven approach. With such an explicit-and-implicit\nprocess the particular density-related output of the original\nhybrid, fast and energy-efficient neural radiance rendering\nANN-based NeRF. Overall, they do not use SNNs, do not\nbecomesfeasible.\naim at the neuromorphic hardware, focus on geometric re-\nInspired by the imaging process of the primate fovea construction, and report only on the Chamfer metric. So, it\nin the retina that accumulates the intensity flow over time is rational to deem that (Liao et al. 2023) is irrelevant and\nto stimulate the photoreceptor cell (Masland 2012; Wa¨ssle ourworkisimpossibletoconductquantitativecomparisons\n2004), we take one step forward to associate the accumu- with theirs. Different from the above work, we are the first\nlationprocessofrenderingwiththetemporalaccumulation toexploretherenderingofrealRGBwithSNNsandbenefit\nprocess of SNNs, which ultimately stimulates the spiking NeRFrenderingfromneuromorphiccomputing.\nneurons to fire. Concretely, we align the radiance ray with\nthetemporaldimensionofthesMLP,andindividuallymatch Preliminaries\neachsampledpointontheraytoatimestepduringrender-\nNeural radiance field. To reconstruct the scene for the\ning.Thus,thegeometricconsecutivenessoftherayistrans-\ngiven view, NeRF (Mildenhall et al. 2021) first utilizes an\nformed into the temporal continuity of the SNN. As a re-\nMLP, which takes in the location coordinates p ∈ R3 and\nsult,SpikingNeRFseizesthenatureofbothworldstomake\ntheviewdirectionv∈R2 andyieldsthedensityσ ∈Rand\ntheNeRFrenderinginaspikingmanner,andbringsabouta\nthe color c ∈ R3, to implicitly maintain continuous volu-\nnovelandeffectivedataencodingapproachforSNN-based\nmetricrepresentations:\n3Drendering.DifferentfromotherSNN-basedimagerecon-\nstructions (Zhu et al. 2022a; Mei et al. 2023), which focus e,σ =MLP (p), (1)\nθ\non the event-based gray 2D reconstruction, we are the first c=MLP (e,v), (2)\nγ\nto explore the reconstruction of the real RGB world with\nSNNs. where θ and γ denote the parameters of the separate two\nparts of the MLP, and e is the embedded features. Next,\nMoreover,sincethenumberofsampledpointsondiffer-\nNeRF renders the pixel of the expected scene by casting a\nentraysalwaysvaries,thetemporallengthsofdifferentrays\nray r from the camera origin point to the direction of the\nbecome irregular. Consequently, the querying for the volu-\npixel,thensamplingKpointsalongtheray.Throughquery-\nmetricinformationcanhardlybeparallelizedduringrender-\ning,severelyhinderingthetrainingprocessongraphicspro-\ningtheMLPasinEq.(1-2)K times,K colorvaluesandK\ncessingunits(GPUs).Tosolvethisissue,wefirstinvestigate densityvaluescanberetrieved.Finally,followingtheprin-\nciples of the discrete volume rendering proposed in (Max\nthetemporalpadding(TP)methodtoattaintheregulartem-\nporallengthinaqueryingbatch,i.e.,aregular-shapedtensor,\n1995),theexpectedpixelRGBCˆ(r)canberendered:\nthus ensuring parallelism and GPU training feasible. Fur-\ni−1\nthermore,weproposethetemporalcondensing-and-padding (cid:89)\nα=1−exp(−σ δ ), w = (1−α ), (3)\ni i i i\n(TCP), to fully constrain the tensor size and condense the\nj=1\ndata distribution, which is hardware-friendly to neuromor-\nK\nphichardwareacceleratorsandGPUs.Ourthoroughexper- Cˆ(r)≈(cid:88)\nw α c , (4)\nimentation proves that TCP can maintain both the energy i i i\nmerits of SNNs and the high quality of NeRF rendering as i=1\nshowninFig.1. wherec andσ denotesthecolorandthedensityvaluesof\ni i\nTosumup,ourmaincontributionsareasfollows: thei-thpointrespectively,andδ iisthedistancebetweenthe\nadjacentpointiandi+1.\n• We propose SpikingNeRF that aligns the temporal di-\nAfterrenderingallthepixels,theexpectedsceneisrecon-\nmension of SNNs with the radiance rays of NeRF, ex-\nstructed.Withtheground-truthpixelcolorC(r),theparam-\nploitingthetemporalcharacteristicsofSNNs.Tothebest\neters of the MLP can be trained end-to-end by minimizing\nof our knowledge, this is the first work to accommodate\ntheMSEloss:\nSNNs to reconstructing 3D scenes, making high-quality\n3Drenderingfeasibleontheneuromorphichardware. L= 1 (cid:88) ∥Cˆ(r)−C(r)∥2, (5)\n|R| 2\n• We propose TP and TCP to solve the irregular tempo- r∈R\nral lengths, ensuring the training and inference paral-\nwhereRisthemini-batchcontainingthesampledrays.\nlelismonGPUs.TCPcanalsofurtherkeepSpikingNeRF\nHybrid volumetric representation. The number of sam-\nhardware-friendlytotheneuromorphichardware.\npled points K in Eq. 4 is usually big, leading to the heavy\n• Our experiments demonstrate the effectiveness of Spik- MLP querying burden as displayed in Eq. (1-2). To allevi-\ningNeRFonfourmainstreamtasks,achievingadvanced atethisproblem,voxelgridrepresentationisutilizedtocon-\nenergyefficiencyasshowninFig.1.Foranotherspecific tain the volumetric parameters directly, e.g., the embedded\nR e t h i n k i n g\nfeature e and the density σ in Eq. 1, as the values of the Mean or Voting\nvoxel grid. Thus, querying the MLP in Eq. 1 is substituted\ntoqueryingthevoxelgridsandoperatingtheinterpolation, ANN SNN\nwhichismucheasier:\nσ =act(interp(p,V )), (6) ......\nσ\ne=interp(p,V ), (7)\nf\nwhere V and V are the voxel grids related to the volu- Temporal Dim.\nσ f\nmetric density and features, respectively. “interp” denotes Input Data #2 Poisson Generator\ntheinterpolationoperation,and“act”referstotheactivation\nfunction, e.g., ReLU or the shifted softplus (Barron et al.\n2021). #1 Duplication for T times\nFurthermore, those irrelevant points with low density or\nFigure 2: Conventional data encoding schemes. For direct-\nunimportantpointswithlowweightcanbemaskedthrough\nencoding, only the operation #1 is necessary that it dupli-\npredefinedthresholdsλ,thenEq.4turnsinto:\ncatestheinputdataT timestofitthelengthofthetemporal\nA≜{i:w i >λ 1,α i >λ 2}, (8) dimension.ForPoisson-encoding,bothoperation#1and#2\nCˆ(r)≈(cid:88)\nw α c . (9)\nareutilizedtogeneratetheinputspiketrain.The“Mean”or\ni i i “Voting”operationisabletodecodetheSNNoutput.\ni∈A\nThus, the queries of the MLP for sampled points in Eq. 2\naresignificantlyreduced.Withsuchcomputationalbenefits,\nthem are proven to perform well in the direct learning of\nhybridvolumetricrepresentationisprevalentinneuralradi-\nSNNs (Fang et al. 2021; Han, Srinivasan, and Roy 2020;\nancerendering(Sun,Sun,andChen2022;Chenetal.2022).\nShresthaandOrchard2018;Chengetal.2020).\nSpikingneuron.Thespikingneuronisthemostfundamen-\nAs described in Preliminaries, spiking neurons receive\ntalunitinspikingneuralnetworks,whichessentiallydiffers\ndata with an additional dimension called the temporal di-\nSNNs from ANNs. The modeling of spiking neurons com-\nmension,whichisindexedbythetime-steptinEq.(10-12).\nmonlyadoptstheleakyintegrate-and-fire(LIF)model:\nConsequently, original ANN-formatted data need to be en-\n1\nUt =Vt−1+ (Xt−Vt−1+V ), (10) coded to fill the temporal dimension as illustrated in Fig.\nτ reset 2.Inthedirect-encodingscheme,theoriginaldataisdupli-\nSt =H(Ut−V ), (11) cated T times to fill the temporal dimension, where T rep-\nth\nVt =Ut⊙(1−St)+V St. (12) resents the total length of the temporal dimension. As for\nreset the Poisson-encoding scheme, besides the duplication op-\nHere, we follow the renowned SpikingJelly (Fang et al.\neration, it perceives the input value as the probability and\n2023) to implement the LIF neurons. ⊙ denotes the\ngenerates a spike according to the probability at each time\nHadamardproduct.Utistheintermediatemembranepoten-\nstep. Additionally, a decoding method is entailed for the\ntialattime-steptandcanbeupdatedthroughEq.10,where\nsubsequentoperationsofrendering,andthemean(Lietal.\nVt−1 is the actual membrane potential at time-step t − 1\n2021)andthevoting(Fangetal.2021)decodingoperations\nandXt denotestheinputvectorattime-stept,e.g.,theac-\narecommonlyconsidered.Weemploytheformerapproach\ntivationvectorfromthepreviouslayerinMLPs.Theoutput\nsincethelatteroneisdesignedforclassificationtasks(Diehl\nspikevectorSt isgivenbytheHeavisidestepfunctionH(·)\nandCook2015;Wuetal.2019).\ninEq.11,indicatingthataspikeisfiredwhenthemembrane\nThus,withtheabovetwoencodingmethods,webuildtwo\npotentialexceedsthepotentialthresholdV .Dependenton\nth naiveversionsofSpikingNeRFandareabletoconductex-\nwhether the spike is fired at time-step t, the membrane po-\nperimentsonvariousdatasetstoverifythefeasibility.\ntential Vt is set to Ut or the reset potential V through\nreset\nEq.12.\nTime-rayalignment(TRA)\nSince the Heaviside step function H(·) is not differen-\ntiable,thesurrogategradientmethodisutilizedtosolvethis Thissubsectionfurtherexploresthepotentialofaccommo-\nissue,whichisdefinedas: dating the SNN to the NeRF rendering process in a more\ndH(x) 1 naturalandnovelway,whereweattempttoretainthereal-\n= , (13) valuedinputdataasdirect-encodingdoes,butdonotfillthe\ndx 1+exp(−αx)\ntemporaldimensionwiththeduplication-basedapproach.\nwhereαisapredefinedhyperparameter.Thus,spikingneu-\nWefirstconsidertheMLPqueryingprocessintheANN\nralnetworkscanbeoptimizedend-to-end.\nphilosophy. For an expected scene to reconstruct, the vol-\numetric parameters of sampled points, e.g., e and v in Eq.\nMethodology\n2,arepackedastheinputdatawiththeshapeof[batch,c ]\ne\nDataencoding or[batch,c ],wherebatchrepresentsthesampleindexand\nv\nIn this subsection, we explore two naive data encoding ap- c is the channel index of the volumetric parameters. Thus,\nproachesforconvertingtheinputdatatoSNN-tailored for- theMLPcanquerythesedataandoutputthecorresponding\nmats, i.e., direct-encoding and Poisson-encoding. Both of color information in parallel. However, from the geometric\nDensity grids\nσ\nw <λ1\nMask\nα <λ2\nσ\nr\ng\nVoxel grid based masking b Render\n3D voxel grids Spiking MLP\n(a)\nRay with the K R maa sy ki na gft e or p eth rae t ion\nc do el no sr\ni\nta yn vd\na\nt lh ue\ne s i∑\n=1wiαici\nRay1 9 2 1 0 2 0 0 0 Ray1 9 2 1 2 0 0 0 0\nV1 V2 ......\nRay2 4 2 6 6 4 5 1 1 Ray2 4 2 6 6 4 5 1 1\nRay3 0 2 2 0 6 0 5 0 Ray3 2 2 6 5 0 0 0 0\nt =1 t =2 t =K Ray4 5 0 0 4 0 0 6 0 Ray4 5 4 6 0 0 0 0 0\nTemporal dimension Ray with the Ray5 0 0 5 0 8 0 0 7 Ray5 5 8 7 0 0 0 0 0\nof the SNN Aligned sampled points T1 T2 T3 T4 T5 T6 T7 T8 T1 T2 T3 T4 T5 T6 T7 T8\n(b) (c)\nFigure 3: Overview of the proposed SpikingNeRF. (a) The rendering process of SpikingNeRF. The whole 3D volumetric\nparameters are stored in the voxel grids. The irrelevant or unimportant samples are masked before the sMLP querying. The\nexpected scenes are rendered with the volumetric information yielded by the sMLP. (b) Alignment between the temporal\ndimension and the ray. The sMLP queries each sampled point step-by-step to yield the volumetric information. (c) Proposed\ntemporal padding (left) and temporal condensing-and-padding (right) methods. For simplification, the channel length of the\nvolumetricparametersissetto1.\nview,theinputdatashouldbepackedas[ray,pts,c],where plesondifferentraystobeirregular,whichindicatesthere-\nray istherayindexandtheptsistheindexofthesampled shapeoperationofEq.14,i.e.,shapingintoatensor,isun-\npoints. feasibleonGPUsafterthemaskingoperation.\nObviously, the ANN-based MLP querying process can ToensurecomputationparallelismonGPUs,wefirstpro-\nnotreflectsuchgeometricrelationsbetweentherayandthe pose to retain the indices of those masked samples but dis-\nsampledpoints.Then,weconsiderthecomputationmodal- cardtheirvalues.AsillustratedinFig.3(c)Left,wearrange\nity of SNNs. As illustrated in Eq. (10-12), SNNs naturally bothunmaskedandmaskedsamplessequentiallytothecor-\nentailthetemporaldimensiontoprocessthesequentialsig- respondingray-indexedvector,andpadzerostothevacant\nnals.ThismeansaspikingMLPnaturallyacceptstheinput tensor elements. Such that, a regular-shaped input tensor is\ndata with the shape of [batch,time,c], where time is the built,makingGPUtrainingfeasible.Werefertothissimple\ntemporal index. Therefore, we can reshape the volumetric approachasthetemporalpadding(TP)method.\nparametersbackto[ray,pts,c],andintuitivelymatcheach\nHowever, TP does not handle those masked samples ef-\nsamplealongtheraytothecorrespondingtimestep: fectively because those padded zeros will still get involved\nin the following computation and cause the membrane po-\nInput :=[batch,c]\nMLP tentialofsMLPtodecay,implicitlyaffectingtheoutcomes\n⇒[ray,pts,c] (14)\nof the unmasked samples in the posterior segment of the\n⇒[batch,time,c]:=Input , ray. Even for a sophisticated hardware accelerator that can\nsMLP\nskip those zeros, the sparse data structure still causes com-\nwhichisalsoillustratedin3(b).Suchanalignmentdoesnot\nputation inefficiency such as imbalanced workload (Zhang\nrequireanyinputdatapre-processsuchasduplication(Zhou\net al. 2020). To solve this issue, we design the temporal\net al. 2022) or Poisson generation (Garg, Chowdhury, and\ncondensing-and-padding(TCP)scheme,whichisillustrated\nRoy2021)aspriorartscommonlydo.\nin Fig. 3(c) Right. Different from TP, TCP completely dis-\ncardstheparametersandindicesofthemaskedsamples,and\nTemporalcondensing-and-padding(TCP)\nadjacently rearranges the unmasked sampled points to the\nThe masking operation on sampled points, as illustrated corresponding ray vector. For the vacant tensor elements,\nin Preliminaries, makes the time-ray alignment intractable. zerosarefilledasTPdoes.Consequently,validdataiscon-\nAlthough such masking operation improves the rendering densed to the left side of the tensor. Notably, the ray di-\nspeed and quality by curtailing the computation cost of re- mensioncanbesortedaccordingtothevaliddatanumberto\ndundantsamples,italsocausesthenumberofqueriedsam- furtherincreasethedensity.Asaresult,TCPhasfullyelim-\nAlgorithm 1: Overall algorithm of the DVGO-based Spik- dataformatforsMLP withTPorTCP.Step7and8com-\ningNeRF(SpikingNeRF-D)intherenderingprocess. pute the RGB values for the expected scene. If a backward\nprocessisrequired,Step9calculatestheMSElossbetween\nInput: The density and the feature voxel grids V and V ,\nσ f\ntheexpectedandtheground-truthscenes.\nthe spiking MLP sMLP(·), the view direction of the\nNotably, the proposed methods, functioning in a plug-\ncamera v, the rays from the camera origin to the di-\nin way, can be applied to other NeRF frameworks, e.g.,\nrections of N pixels of the expected scene R =\n{N} the SoTA TensoRF (Chen et al. 2022), and is also orthog-\n{r ,r ,...,r }, the number of the sampled points per\n1 2 N onal and applicable to those efficient NeRFs such as Fast-\nrayM,theground-truthRGBC={C ,C ,...,C }of\n1 2 N NeRF(Garbinetal.2021)andKiloNeRF(Reiseretal.2021).\ntheexpectedN pixels.\nOutput: TheexpectedRGBCˆ = {Cˆ 1,Cˆ 2,...,Cˆ N}ofthe Experiments\nexpectedN pixels,thetraininglossL.\nInthissection,wedemonstratetheeffectivenessofourpro-\n1: The coordinates of sampled points P =\n{N×M} posedSpikingNeRF.A)WefirstbuildSpikingNeRFonthe\n{p ,p ,...,p }←Sample(R).\n1,1 1,2 N,M voxel-grid based DVGO framework (Sun, Sun, and Chen\n2: α {N×M},w\n{N×M}\n← Weigh(P,V σ) as in Eq. 6 and\n2022), and compare the proposed TRA encoding with the\nEq.3.\nnaive data encodings. B) We extend SpikingNeRF to the\n3: FilteredcoordinatesP′ ←Mask(P,α,w)asinEq.8.\nTensoRF framework (Chen et al. 2022) to show the flexi-\n4: Input MLP ← ExtractFeatures(P′,V f,v) as de- bility of our method, and compare SpikingNeRF with the\nscribedinEq.7andEq.2.\noriginalDVGOandTensoRFalongwithotherNeRF-based\n5: ThetemporallengthT ←Themaximumpointnumber\nworks in both rendering quality and energy cost. C) We\namongthebatchedrays.\nevaluate SpikingNeRF on the neuromorphic accelerator\n6: Input sMLP ← The TP or TCP transformation on SpikeSim (Moitra et al. 2023) and SATA (Yin et al. 2022)\nInput asdescribedinEq.14andSec.TCP.\nMLP and GPU to compare the hardware friendliness of the pro-\n7: TheRGBvaluesc ←sMLP(Input )\n{N,T} sMLP posedTCPoverTP,meanwhileshowcasetheenergyadvan-\n8: Cˆ ←Accumulate(P′,α,w,c)asinEq.9. tage on neuromorphic accelerators over ANNs. D) we fur-\n9:\nL←MSE(C,Cˆ)asinEq.5\nther discuss the alignment direction issue and extensively\nNote:DependentonthespecificNeRFframework,thefunc- compare the merits of our edge-friendly spiking approach\ntions,e.g.,Sample(·),Mask(·),maybedifferent. with the classic quantization method. Note that, for text\nsaving, we defer the results of unbounded inward-facing\nandforward-facingdatasetsandallvisualizationstotheap-\npendix, and the results of SATA evaluation is also deferred\ninated the impact of the masked samples and made Spik-\nalong with the detailed hardware descriptions. For clarity,\ningNeRFmorehardware-friendly.\nwe term the DVGO-based SpikingNeRF as SpikingNeRF-\nAlthoughsuchdatacondensingoperationcanincurextra\nDandtheTensoRF-basedasSpikingNeRF-T.Ifnotstated\noverheadonhardware,aregularandcondenseddatastruc-\notherwise,TCPisutilizedbydefault.\nturecommonlybringsfarmorebenefitstoefficiency,cover-\ningthecost(Zhangetal.2020).Suchbenefitsnotonlycater\nExperimentalsettings\nfor DNN hardware accelerators and GPUs, but also apply\nWe conduct experiments mainly on the four inward-facing\ntoneuromorphichardware,asproposedandprovedinPTB\ndatasets,includingSynthetic-NeRF(Mildenhalletal.2021),\n(Lee,Zhang,andLi2022)andSTELLAR(Maoetal.2024).\nSynthetic-NSVF(Liu et al. 2020), BlendedMVS(Yao et al.\nTherefore,wechooseTCPasourmainlyproposedmethod.\n2020),andTanks&Temples(Knapitschetal.2017).Werefer\ntoDVGOastheANNcounterparttoSpikingNeRF-D.Were-\nOverallalgorithm\nfer to TensoRF as the ANN counterpart to SpikingNeRF-T.\nThissectionsummarizestheoverallalgorithmofSpikingN- Intermsoftheenergycomputation,wefollowthepriorarts\neRFbasedontheDVGO(Sun,Sun,andChen2022)frame- (Zhouetal.2022;Horowitz2014)toestimatethetheoretical\nwork.And,thepseudocodeisgiveninAlgorithm1. renderingenergycostinmostofourexperimentsexceptfor\nAs illustrated in Fig. 3(a), SpikingNeRF first establishes thoseinTab.4whoseresultsareproducedbytheneuromor-\nthevoxelgridsfilledwithlearnablevolumetricparameters. phic accelerator SpikeSim. Very detailed implementation\nIn the case of the DVGO implementation, two groups of hyper-parameters, the experiment fairness declaration,\nvoxelgridsarebuiltastheinputofAlgorithm1,whichare and thorough SpikeSim evaluation details are all speci-\nthe density and the feature voxel grids. Given an expected fiedintheappendix.\nscenewithN pixelstorender,Step1istosampleM points\nalongeachrayshotfromthecameraorigintothedirectionof Comparisonsandablations\neachpixel.WiththeN ×M sampledpoints,Step2queries Comparisons with the conventional data encodings. As\nthe density grids to compute the weight coefficients, and described in Data encoding, we propose two naive ver-\nStep 3 uses these coefficients to mask out those irrelevant sions of SpikingNeRF-D that adopt two different conven-\npoints.Then,Step4queriesthefeaturegridsforthefiltered tionaldataencodingschemes:direct-encodingandPoisson-\npointsandreturnseachpoint’svolumetricparameters.Step encoding.Ontheonehand,Poisson-encoding,severelylos-\n5and6preparethevolumetricparametersintoareceivable ing the feature information and producing at most 24.83\nTable1:Comparisonswithdirect-encodingunderdifferenttimestepsettings.\nMetric PSNR↑ SSIM↑ Energy(mJ)↓ PSNR↑ SSIM↑ Energy(mJ)↓ PSNR↑ SSIM↑ Energy(mJ)↓\nDirect-Encoding TimeStep=1 TimeStep=2 TimeStep=4\nSynthetic-NeRF 31.22 0.947 113.03 31.51 0.951 212.20 31.55 0.951 436.32\nSynthetic-NSVF 34.17 0.969 53.73 34.49 0.971 104.05 34.56 0.971 217.86\nTRA DynamicTimeStep\nSynthetic-NeRF 31.34 0.949 110.80 31.59 0.951 185.78 31.64 0.952 308.84\nSynthetic-NSVF 34.33 0.970 56.69 34.63 0.972 98.39 34.57 0.972 165.17\nTRAdenotestheproposedtime-rayalignmentwithTCP.\nTable2:Comparisonswithdirect-encodingonthesamesamplingdensitylevels.\nDensityLevel 1(Base) 2 4\nMetric PSNR↑ SSIM↑ Energy(mJ)↓ PSNR↑ SSIM↑ Energy(mJ)↓ PSNR↑ SSIM↑ Energy(mJ)↓\nDirect-Encoding\nSynthetic-NeRF 31.22 0.947 113.03 31.40 0.949 192.81 31.46 0.950 337.98\nSynthetic-NSVF 34.17 0.969 53.73 34.45 0.970 94.58 34.56 0.971 168.10\nTime-rayAlignmentwithTCP\nSynthetic-NeRF 31.34 0.949 110.80 31.59 0.951 185.78 31.64 0.952 308.84\nSynthetic-NSVF 34.33 0.970 56.69 34.63 0.972 98.39 34.57 0.972 165.17\nPSNR among all time-step settings and datasets, achieves 2022), DVGO(Sun, Sun, and Chen 2022), TensoRF(Chen\nfar-from-acceptable synthesis quality, which indicates it etal.2022),thatsignificantlyexploitthemaskingoperation,\ndoes not work at all. The corresponding quantitative and SpikingNeRF-Dcanstillobtainbetterenergyefficiencyand\nqualitativeresultsofthisineffectiveschemearedeferredto comparable synthesis quality. Even compared with Kilo-\ntheappendix.Ontheotherhand,aslistedinTab.1,direct- NeRF(Reiser et al. 2021) that is aiming at fast rendering\nencodingobtainsgoodsynthesisperformancewithonlyone (whichtakesdaystotrain),SpikingNeRF-D(thattakesmin-\ntime-step,andcanachievehigherPSNRasthetimestepin- utes to train) still performs better. Furthermore, following\ncreases. Inheriting the good startup of direct-encoding, our (Alyamkinetal.2018;Lee,Yang,andFan2023),weadopt\nproposed TRA shows better energy efficiency and render- the analogous PSNR/Energy to further estimate the energy\ning ability over direct-encoding. In Tab. 1, we change the efficiencyofSpikingNeRFandtheANNbaselines.Aslisted\nTRA’stimestepbyadjustingthedefaultsamplingdensityto in Tab. 3, SpikingNeRF-D achieves superior energy effi-\ncomparewithDirect-Encoding(DE)ofdifferenttimesteps ciency among these competitors. Given Fig. 1, the supe-\nsince it is unfeasible to explicitly set TRA’s time step due riority of our SpikingNeRF in energy efficiency is vivid.\ntoitsdynamictemporallength.Tab.1showsthatTRAhas Moreover, SpikingNeRF-T also reduces energy consump-\nbetter rendering quality under the same energy levels. We tionby62.80%witha0.69PSNRdroponaverage.Except\nalso compare TRA with DE under the same sampling den- forTanks&Temples,SpikingNeRF-ToutperformsDVGOin\nsitiesinTab.2forfairness,andtheoutcomestillholds.The bothPSNRandenergycost.Notably,SpikingNeRF-Tonly\nappendixcontainsthefullstatisticsofTab.1andTab.2for uses two FC layers as TensoRF does. One layer is for en-\neachspecificscene,whichalsoshowTRAconsistentlyout- coding data with full precision, the other for spiking with\nperformstheseconventionalencodings.Conclusively,TRA binary computation, leading to only half of the computa-\nexploitsSNN’stemporalcharacteristicsin3Drenderingand tionburdenbeingtackledwiththeadditionoperations.This\nprovessimpleandeffective. explainswhySpikingNeRF-Tperformsslightlyworsethan\nQuantitative comparisons with the ANN counterparts SpikingNeRF-Dintermsofenergyreductionratio.Incon-\nand other NeRFs. As shown in Tab. 3, our SpikingNeRF- clusion, these results demonstrate the effectiveness of our\nD with TCP can achieve a 70.79% energy saving with proposedSpikingNeRFinimprovingenergyefficiency.\na 0.53 PSNR drop on average over the ANN counter- Qualitative comparisons. Due to text limitation, we defer\npart. Such a trade-off between synthesis quality and en- piles of visualizations of SpikingNeRF-D rendering results\nergy cost is reasonable because a significant part of in- totheappendix.Basically,SpikingNeRF-Dsharestheanal-\nference is conducted with the addition operations in the ogousissueswiththeANNcounterpartontexturedistortion.\nsMLPofSpikingNeRF-Dratherthanthemultiplicationop- Advantagesoftemporalcondensingonthehardware.To\nerationsintheoriginalDVGO.Ontheonehand,compared demonstrate the advantages of the proposed temporal con-\nwith those methods, e.g., NeRF(Mildenhall et al. 2021), densingonhardwareacceleratorsasdescribedinSec.TCP,\nMip-NeRF(Barronetal.2021),JaxNeRF(Deng,Barron,and weevaluateSpikingNeRF-DwithTCPandTPonSpikeSim\nSrinivasan2020),thatdonotperformthemaskingoperation, using the SpikeFlow architecture. For one thing, as listed\nSpikingNeRF-D can reach orders of magnitude lower en- in Tab. 4, TCP consistently outperforms TP in both infer-\nergyconsumption.Ontheotherhand,comparedwiththose ence latency and energy overhead by a significant margin\nmethods, e.g., NSVF(Liu et al. 2020), DIVeR(Wu et al. over the two datasets. Specifically, The gap between TCP\nTable3:ComparisonswiththeANNcounterpartandotherNeRF-basedmethods.\nDataset Synthetic-NeRF Synthetic-NSVF BlendedMVS TanksTemples\nEnergy↓ Energy↓ Energy↓ Energy↓\nMetric PSNR↑ SSIM↑ P/E↑ PSNR↑ SSIM↑ P/E↑ PSNR↑ SSIM↑ P/E↑ PSNR↑ SSIM↑ P/E↑\n(mJ) (mJ) (mJ) (mJ)\nNeRF 31.01 0.947 4.5e5 6.9e-5 30.81 0.952 4.5e5 6.8e-5 24.15 0.828 3.1e5 7.8e-5 25.78 0.864 1.4e6 1.8e-5\nMip-NeRF 33.09 0.961 4.5e5 7.4e-5 - - - - - - - - - - - -\nJaxNeRF 31.65 0.952 4.5e5 7.0e-5 - - - - - - - - 27.94 0.904 1.4e6 2.0e-5\nNSVF 31.74 0.953 16427 1.9e-3 35.13 0.979 8864 4.0e-3 26.90 0.898 15149 1.8e-3 28.40 0.900 101443 2.8e-4\nDIVeR 32.32 0.960 343.96 0.094 - - - - 27.25 0.910 548.65 0.050 28.18 0.912 1930.67 0.015\nKiloNeRF 31.00 0.95 185.12 0.167 33.37 0.97 99.89 0.334 27.39 0.92 170.71 0.160 28.41 0.91 723.79 0.039\nDVGO* 31.98 0.957 374.72 0.085 35.12 0.976 187.85 0.187 28.15 0.922 320.66 0.088 28.42 0.912 2147.86 0.012\nTensoRF* 33.14 0.963 641.17 0.052 36.74 0.982 465.09 0.079 - - - - 28.50 0.920 2790.03 0.010\nSpikingNeRF-Dw/TP 31.34 0.949 111.59 0.281 34.34 0.970 57.57 0.596 27.80 0.912 97.38 0.285 28.00 0.892 483.48 0.057\nSpikingNeRF-Dw/TCP 31.34 0.949 110.80 0.283 34.34 0.970 56.69 0.606 27.80 0.912 96.37 0.288 28.09 0.896 581.04 0.048\nSpikingNeRF-Tw/TCP 32.45 0.956 240.81 0.134 35.76 0.978 149.98 0.238 - - - - 28.09 0.904 1165.90 0.024\n*denotesanANNcounterpartimplementedbytheofficialcodes.\nP/Eabbreviatesthe“PSNR/Energy”.\nTable5:Comparisonswithtemporalflip.\nTable4:ComparisonsbetweenTCPandTPonSpikeSim.\nDataset Synthetic-NeRF Synthetic-NSVF\nDataset Synthetic-NeRF Synthetic-NSVF\nSpikingNeRF-D w/oTF w/TF w/oTF w/TF\nSpikingNeRF-D w/TCP w/TP w/TCP w/TP\nPSNR↑ 31.34 31.25 34.34 34.15\nLatency(s)↓ 26.12 222.22 13.37 164.61\nSSIM↑ 0.949 0.947 0.970 0.967\nEnergy+(mJ)↓ 65.78 559.45 33.68 414.37\nEnergy(mJ)↓ 110.80 116.91 56.69 61.08\n+denotestheenergyresultparticularlyproducedbySpikeSim.\nTFdenotestemporalflip.\nand TP is about an order of magnitude in both inference Table6:ComparisonswithQuantizedNeRF(qNeRF).\nspeed and energy cost. These results indicate TCP is sim-\nple but also effective at the inference stage. The same con- Dataset Synthetic-NeRF Synthetic-NSVF\nMetric PSNR↑ Energy↓ PSNR↑ Energy↓\nclusioncanalsobedrawnfromtheSATA(Yinetal.2022)\nqNeRF 31.24 167.67 34.13 78.54\nevaluationasshownintheappendix,whichmeansTCPcan\nours 31.34 110.80 34.33 56.69\nbenefit the sparsity-aware (event-driven) hardware as well.\nFor the other, comparing the results on SpikeSim (65nm\ntechnology,Tab.4)withthoseon45nmtechnologygeneral posetemporalfliptoempiricallydecidethealignmentdirec-\nhardware (Tab. 3) further demonstrates that the proposed tionsincethequeryingdirectionofsMLPalongthecamera\nSpikingNeRF-D can substantially benefit from its neuro- raywillaffecttheinferenceoutcome.Tab.5liststheexper-\nmorphic computing nature on the neuromorphic hardware, imentalresultsofSpikingNeRF-Dwithandwithouttempo-\nachievinghigherenergy-efficiencyoverANNbaselines.Ad- ralflip,i.e.,withtheconsistentandtheoppositedirections.\nditionally,thetemporalcondensingwillnotharmtherender- Distinctly,keepingthedirectionofthetemporaldimension\ningqualityatallasshowninTab.3. consistent with that of the camera ray outperforms the op-\nIn the SpikeSim evaluation, the temporal condensing oper- positecaseonthetwodatasetsinsynthesisperformanceand\nationisdoneoff-chip.Thiscauseson-chipcomputationcan energyefficiency.Therefore,theconsistentalignmentdirec-\nfully benefit from the dense data, thus accounting for the tionisimportantinSpikingNeRF.\nhuge performance gap between TCP and TP. But note that Extensive comparisons with quantized ANN baselines.\nduetothepipelinemechanism,thelatencyofsuchoff-chip To further demonstrate the merits of SpikingNeRF com-\noperation can be easily covered. To evaluate the substan- pared to the quantized NeRF version, we quantize the ac-\ntial overhead and merits that temporal condensing can ac- tivationofDVGOtospike-bit,i.e.,1-bit,withtherenowned\ntuallybring,weshowcasethetrainingandinferencetimeon LSQ(Esseretal.2020),andcompareitwithSpikingNeRF-\nSynthetic-NeRFonsingleA100GPU. D in Tab. 6. The results show that SpikingNeRF-D outper-\nformsthequantizedANNversiononthetwodatasetsinboth\nTrain Mins 16.74 61.28 synthesisqualityandenergyconsumption,indicatingSNNs\ndo have an advantage over ANNs in scenario of ultra-low-\nInfer. Secs 0.44 1.22\nenergycomputation.\n0.0 0.2 0.4 0.6 0.8 1.0\nA100 GPU time consumption\nConclusion\nIntheabovefigure,theorangebaristhetimeconsumption This paper proposes SpikingNeRF that accommodates the\nofTP,whiletheblueoneisthatofTCP.Evenroughlyreal- spikingneuralnetworktoreconstructingreal3Dscenesfor\nizing the temporal condensing with PyTorch can still bring the first time, improving energy efficiency. TRA is devel-\nsignificanttime-savingattherenderingstageonGPU. oped to encode sampled points, seamlessly combining the\nDiscussionofthealignmentdirection.Theradianceaccu- temporalcharacteristicofSNNswiththeradianceray.TCP\nmulationoriginallyhasnodirectionbutSNNhas,soit’snec- isfurtherproposedtoimprovehardwarefriendliness.Thor-\nessarytodiscussthetime-rayalignmentdirection.Wepro- oughexperimentsareconductedtoprovetheeffectiveness.\nReferences Hedman,P.;Srinivasan,P.P.;Mildenhall,B.;Barron,J.T.;\nandDebevec,P.2021.Bakingneuralradiancefieldsforreal-\nAlyamkin, S.; Ardi, M.; Brighton, A.; Berg, A. C.; Chen,\ntimeviewsynthesis. InProceedingsoftheIEEE/CVFInter-\nY.;Cheng,H.-P.;Chen,B.;Fan,Z.;Feng,C.;Fu,B.;etal.\nnationalConferenceonComputerVision,5875–5884.\n2018. 2018low-powerimagerecognitionchallenge. arXiv\npreprintarXiv:1810.01732. Horowitz, M. 2014. 1.1 computing’s energy problem (and\nwhatwecandoaboutit). In2014IEEEinternationalsolid-\nBarron, J. T.; Mildenhall, B.; Tancik, M.; Hedman, P.;\nstatecircuitsconferencedigestoftechnicalpapers(ISSCC),\nMartin-Brualla, R.; and Srinivasan, P. P. 2021. Mip-nerf:\n10–14.IEEE.\nAmultiscalerepresentationforanti-aliasingneuralradiance\nKnapitsch, A.; Park, J.; Zhou, Q.-Y.; and Koltun, V. 2017.\nfields. InProceedingsoftheIEEE/CVFInternationalCon-\nTanksandtemples:Benchmarkinglarge-scalescenerecon-\nferenceonComputerVision,5855–5864.\nstruction. ACMTransactionsonGraphics(ToG),36(4):1–\nChen,A.;Xu,Z.;Geiger,A.;Yu,J.;andSu,H.2022. Ten- 13.\nsorf:Tensorialradiancefields. InEuropeanConferenceon\nLee, J.-J.; Zhang, W.; and Li, P. 2022. Parallel time batch-\nComputerVision,333–350.Springer.\ning: Systolic-array acceleration of sparse spiking neural\nCheng, X.; Hao, Y.; Xu, J.; and Xu, B. 2020. LISNN: Im- computation. In 2022 IEEE International Symposium on\nprovingSpikingNeuralNetworkswithLateralInteractions High-Performance Computer Architecture (HPCA), 317–\nforRobustObjectRecognition. InIJCAI,1519–1525. 330.IEEE.\nDavies, M.; Srinivasa, N.; Lin, T.-H.; Chinya, G.; Cao, Y.; Lee, Y.; Yang, L.; and Fan, D. 2023. Mf-nerf: Mem-\nChoday,S.H.;Dimou,G.;Joshi,P.;Imam,N.;Jain,S.;etal. ory efficient nerf with mixed-feature hash table. ArXiv,\n2018. Loihi:Aneuromorphicmanycoreprocessorwithon- abs/2304.12587,2:3.\nchiplearning. IeeeMicro,38(1):82–99. Li, Y.; Guo, Y.; Zhang, S.; Deng, S.; Hai, Y.; and Gu, S.\n2021. Differentiable Spike: Rethinking Gradient-Descent\nDeng, B.; Barron, J. T.; and Srinivasan, P. P. 2020.\nfor Training Spiking Neural Networks. Advances in Neu-\nJaxNeRF: an efficient JAX implementation of\nNeRF. URL http://github. com/googleresearch/google-\nralInformationProcessingSystems,34.\nresearch/tree/master/jaxnerf. Liao, Z.; Zheng, Q.; Liu, Y.; and Pan, G. 2023. Spiking\nNeRF:RepresentingtheReal-WorldGeometrybyaDiscon-\nDiehl, P. U.; and Cook, M. 2015. Unsupervised learning\ntinuousRepresentation. arXivpreprintarXiv:2311.09077.\nofdigitrecognitionusingspike-timing-dependentplasticity.\nFrontiersincomputationalneuroscience,9:99. Liu, L.; Gu, J.; Zaw Lin, K.; Chua, T.-S.; and Theobalt, C.\n2020. Neuralsparsevoxelfields. AdvancesinNeuralInfor-\nEsser,S.K.;McKinstry,J.L.;Bablani,D.;Appuswamy,R.;\nmationProcessingSystems,33:15651–15663.\nandModha,D.S.2020. LearnedStepSizeQuantization. In\nLiu, Y.; Peng, S.; Liu, L.; Wang, Q.; Wang, P.; Theobalt,\nInternationalConferenceonLearningRepresentations.\nC.; Zhou, X.; and Wang, W. 2022. Neural rays for\nFang, W.; Chen, Y.; Ding, J.; Yu, Z.; Masquelier, T.; Chen, occlusion-awareimage-basedrendering. InProceedingsof\nD.;Huang,L.;Zhou,H.;Li,G.;andTian,Y.2023. Spiking- theIEEE/CVFConferenceonComputerVisionandPattern\nJelly:Anopen-sourcemachinelearninginfrastructureplat- Recognition,7824–7833.\nformforspike-basedintelligence. ScienceAdvances,9(40):\nMaass,W.1997.Networksofspikingneurons:thethirdgen-\neadi1480.\neration of neural network models. Neural networks, 10(9):\nFang, W.; Yu, Z.; Chen, Y.; Masquelier, T.; Huang, T.; and 1659–1671.\nTian,Y.2021. Incorporatinglearnablemembranetimecon-\nMao,R.;Tang,L.;Yuan,X.;Liu,Y.;andZhou,J.2024.Stel-\nstant to enhance learning of spiking neural networks. In\nlar:Energy-EfficientandLow-LatencySNNAlgorithmand\nProceedingsoftheIEEE/CVFInternationalConferenceon\nHardwareCo-DesignwithSpatiotemporalComputation. In\nComputerVision,2661–2671.\n2024IEEEInternationalSymposiumonHigh-Performance\nGarbin, S. J.; Kowalski, M.; Johnson, M.; Shotton, J.; and ComputerArchitecture(HPCA),172–185.IEEE.\nValentin, J. 2021. Fastnerf: High-fidelity neural rendering Masland, R. H. 2012. The neuronal organization of the\nat 200fps. In Proceedings of the IEEE/CVF international retina. Neuron,76(2):266–280.\nconferenceoncomputervision,14346–14355.\nMax,N.1995. Opticalmodelsfordirectvolumerendering.\nGarg,I.;Chowdhury,S.S.;andRoy,K.2021. Dct-snn:Us- IEEE Transactions on Visualization and Computer Graph-\ning dct to distribute spatial information over time for low- ics,1(2):99–108.\nlatency spiking neural networks. In Proceedings of the Mei, H.; Wang, Z.; Yang, X.; Wei, X.; and Delbruck,\nIEEE/CVF International Conference on Computer Vision, T. 2023. Deep polarization reconstruction with PDAVIS\n4671–4680. events. In Proceedings of the IEEE/CVF Conference on\nHan,B.;Srinivasan,G.;andRoy,K.2020. Rmp-snn:Resid- ComputerVisionandPatternRecognition,22149–22158.\nual membrane potential neuron for enabling deeper high- Mildenhall, B.; Srinivasan, P. P.; Tancik, M.; Barron, J. T.;\naccuracy and low-latency spiking neural network. In Pro- Ramamoorthi, R.; and Ng, R. 2021. Nerf: Representing\nceedings of the IEEE/CVF conference on computer vision scenes as neural radiance fields for view synthesis. Com-\nandpatternrecognition,13558–13567. municationsoftheACM,65(1):99–106.\nMoitra,A.;Bhattacharjee,A.;Kuang,R.;Krishnan,G.;Cao, Zhu,R.-J.;Zhao,Q.;andEshraghian,J.K.2023. Spikegpt:\nY.;andPanda,P.2023. SpikeSim:Anend-to-endCompute- Generative pre-trained language model with spiking neural\nin-Memory Hardware Evaluation Tool for Benchmarking networks. arXivpreprintarXiv:2302.13939.\nSpikingNeuralNetworks.IEEETransactionsonComputer- Zhu, Z.; Peng, J.; Li, J.; Chen, L.; Yu, Q.; and Luo, S.\nAidedDesignofIntegratedCircuitsandSystems,1–1. 2022b. Spiking graph convolutional networks. arXiv\nReiser, C.; Peng, S.; Liao, Y.; and Geiger, A. 2021. Kilo- preprintarXiv:2205.02767.\nnerf: Speeding up neural radiance fields with thousands of\ntiny mlps. In Proceedings of the IEEE/CVF International\nConferenceonComputerVision,14335–14345.\nRoy, K.; Jaiswal, A.; and Panda, P. 2019. Towards spike-\nbased machine intelligence with neuromorphic computing.\nNature,575(7784):607–617.\nShrestha, S. B.; and Orchard, G. 2018. Slayer: Spike layer\nerrorreassignmentintime. Advancesinneuralinformation\nprocessingsystems,31.\nSun, C.; Sun, M.; and Chen, H.-T. 2022. Direct voxel grid\noptimization:Super-fastconvergenceforradiancefieldsre-\nconstruction. In Proceedings of the IEEE/CVF Conference\nonComputerVisionandPatternRecognition,5459–5469.\nWa¨ssle, H. 2004. Parallel processing in the mammalian\nretina. NatureReviewsNeuroscience,5(10):747–757.\nWu,L.;Lee,J.Y.;Bhattad,A.;Wang,Y.-X.;andForsyth,D.\n2022. Diver: Real-time and accurate neural radiance fields\nwithdeterministicintegrationforvolumerendering. InPro-\nceedingsoftheIEEE/CVFConferenceonComputerVision\nandPatternRecognition,16200–16209.\nWu,Y.;Deng,L.;Li,G.;Zhu,J.;Xie,Y.;andShi,L.2019.\nDirect training for spiking neural networks: Faster, larger,\nbetter. InProceedingsoftheAAAIConferenceonArtificial\nIntelligence,volume33,1311–1318.\nYao,Y.;Luo,Z.;Li,S.;Zhang,J.;Ren,Y.;Zhou,L.;Fang,\nT.; and Quan, L. 2020. Blendedmvs: A large-scale dataset\nforgeneralizedmulti-viewstereonetworks. InProceedings\noftheIEEE/CVFconferenceoncomputervisionandpattern\nrecognition,1790–1799.\nYin,R.;Moitra,A.;Bhattacharjee,A.;Kim,Y.;andPanda,\nP. 2022. Sata: Sparsity-aware training accelerator for spik-\ningneuralnetworks.IEEETransactionsonComputer-Aided\nDesign of Integrated Circuits and Systems, 42(6): 1926–\n1938.\nZhang,J.;Dong,B.;Zhang,H.;Ding,J.;Heide,F.;Yin,B.;\nand Yang, X. 2022. Spiking transformers for event-based\nsingleobjecttracking.InProceedingsoftheIEEE/CVFcon-\nferenceonComputerVisionandPatternRecognition,8801–\n8810.\nZhang,Z.;Wang,H.;Han,S.;andDally,W.J.2020.Sparch:\nEfficient architecture for sparse matrix multiplication. In\n2020IEEEInternationalSymposiumonHighPerformance\nComputerArchitecture(HPCA),261–274.IEEE.\nZhou, Z.; Zhu, Y.; He, C.; Wang, Y.; Yan, S.; Tian, Y.; and\nYuan, L. 2022. Spikformer: When spiking neural network\nmeetstransformer. arXivpreprintarXiv:2209.15425.\nZhu, L.; Wang, X.; Chang, Y.; Li, J.; Huang, T.; and Tian,\nY. 2022a. Event-based video reconstruction via potential-\nassisted spiking neural network. In Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern\nRecognition,3594–3604.",
    "pdf_filename": "SpikingNeRF_Making_Bio-inspired_Neural_Networks_See_through_the_Real_World.pdf"
}