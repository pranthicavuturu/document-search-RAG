{
    "title": "Predicting Customer Satisfaction by Replicating the Survey Response",
    "abstract": "further bias is crucial. This paper introduces a For many call centers, customer satisfaction method to more accurately replicate the distribu- (CSAT)isakeyperformanceindicator(KPI). However,onlyafractionofcustomerstakethe tionofsurveyCSATresponsesinaliveproduction CSATsurveyafterthecall,leadingtoabiased environment, addressing limitations identified in andinaccurateaverageCSATvalue,andmissed priorworkandprovidingmoreaccuratemetricsfor opportunitiesforcoaching,follow-up,andrec- callcenterperformance. tification. Therefore, call centers can benefit fromamodelpredictingcustomersatisfaction 2 RelatedWork oncallswherethecustomerdidnotcomplete thesurvey. GiventhatCSATisacloselymoni- PredictingCSATusingmachinelearningmodels toredKPI,itiscriticaltominimizeanybiasin hasgainedattention,especiallyincallcentercon- theaveragepredictedCSAT(pCSAT).Inthis versations. The challenge is not only predicting paper, we introduce a method such that pre- dictedCSAT(pCSAT)scoresaccuratelyrepli- accuratescoresbutalsoensuringthesepredictions catethedistributionofsurveyCSATresponses replicatethetruedistributionofsurveyresponses. foreverycallcenterwithsufficientdatainalive Thissectionreviewsrelevantstudiesandmethod- production environment. The method can be ologies applied to similar problems, focusing on appliedtomanymulticlassclassificationprob- distribution replication and ordinal classification lemstoimprovetheclassbalanceandminimize (sinceCSATismeasuredona1-5scale). itschangesuponmodelupdates. 1 Introduction 2.1 PredictingCustomerSatisfaction Manymachinelearningapplicationsuseclassifiers Previousresearchexploredvariousapproachesto updatedperiodicallybydevelopers. Withoutspe- predict CSAT from contact center conversations. cial control mechanisms, these updates can shift Bockhorstetal.(2017)developedasystemusing therelativebalanceofoutputclasses,causingun- ASR-generated call transcripts, non-textual data, intendedeffects. ForthecaseofpredictingCSAT, and sentiment scores to predict a Representative wedevelopedacontrolmechanismtoaddressthis SatisfactionIndex(RSI)withrankscoringandiso- issue, taking care to mitigate the risks posed by tonicregressionmodels. Similarly,Augusteetal. sampling noise. This paper explains our method (2019) used the Net Promoter Score (NPS) with and strategies for handling sampling noise, and binaryclassification(promotersvs. detractors)for aimstohelpdevelopersseekingtoreplicateoneor predictingcustomersatisfactioninchatconversa- moretargetclassdistribution(s). tions, achieving moderate improvements with a Customersatisfaction(CSAT)iscriticalforcall macroF1scoreof53.8%. centerperformanceassessment,yetoftenmeasured OtherstudiesexaminedpredictingCSATfrom throughsurveyscompletedbyasmallsubsetofcus- raw audio signal features such as acoustic, emo- tomers—averaging8%inourdataset. Thislimited tional,andprosodicfeatures(ParkandGates,2009; responseratecanskewperceivedperformance,as Zweigetal.,2006;VaudableandDevillers,2012; non-respondingcustomers’satisfactionremainsun- Devillersetal.,2010). known. PredictingCSATforallcalls,eventhose This work builds on a previously developed without survey responses, can mitigate this bias method for predicting CSAT scores using ASR- ManderscheidandLee(2023). generated (Automated Speech Recognition) call 4202 voN 91 ]GL.sc[ 1v93521.1142:viXra",
    "body": "Predicting Customer Satisfaction by Replicating the Survey Response\nDistribution\nEtienneManderscheid,MatthiasLee\nDialpadCanadaInc.\n1100MelvilleSt#400\nVancouver,BC,Canada,V6E4A6\n{etienne,matthias.lee}@dialpad.com\nAbstract EnsuringthesepCSATscoresdonotintroduce\nfurther bias is crucial. This paper introduces a\nFor many call centers, customer satisfaction\nmethod to more accurately replicate the distribu-\n(CSAT)isakeyperformanceindicator(KPI).\nHowever,onlyafractionofcustomerstakethe tionofsurveyCSATresponsesinaliveproduction\nCSATsurveyafterthecall,leadingtoabiased environment, addressing limitations identified in\nandinaccurateaverageCSATvalue,andmissed priorworkandprovidingmoreaccuratemetricsfor\nopportunitiesforcoaching,follow-up,andrec- callcenterperformance.\ntification. Therefore, call centers can benefit\nfromamodelpredictingcustomersatisfaction\n2 RelatedWork\noncallswherethecustomerdidnotcomplete\nthesurvey. GiventhatCSATisacloselymoni-\nPredictingCSATusingmachinelearningmodels\ntoredKPI,itiscriticaltominimizeanybiasin\nhasgainedattention,especiallyincallcentercon-\ntheaveragepredictedCSAT(pCSAT).Inthis\nversations. The challenge is not only predicting\npaper, we introduce a method such that pre-\ndictedCSAT(pCSAT)scoresaccuratelyrepli- accuratescoresbutalsoensuringthesepredictions\ncatethedistributionofsurveyCSATresponses replicatethetruedistributionofsurveyresponses.\nforeverycallcenterwithsufficientdatainalive Thissectionreviewsrelevantstudiesandmethod-\nproduction environment. The method can be ologies applied to similar problems, focusing on\nappliedtomanymulticlassclassificationprob-\ndistribution replication and ordinal classification\nlemstoimprovetheclassbalanceandminimize\n(sinceCSATismeasuredona1-5scale).\nitschangesuponmodelupdates.\n1 Introduction 2.1 PredictingCustomerSatisfaction\nManymachinelearningapplicationsuseclassifiers Previousresearchexploredvariousapproachesto\nupdatedperiodicallybydevelopers. Withoutspe- predict CSAT from contact center conversations.\ncial control mechanisms, these updates can shift Bockhorstetal.(2017)developedasystemusing\ntherelativebalanceofoutputclasses,causingun- ASR-generated call transcripts, non-textual data,\nintendedeffects. ForthecaseofpredictingCSAT, and sentiment scores to predict a Representative\nwedevelopedacontrolmechanismtoaddressthis SatisfactionIndex(RSI)withrankscoringandiso-\nissue, taking care to mitigate the risks posed by tonicregressionmodels. Similarly,Augusteetal.\nsampling noise. This paper explains our method (2019) used the Net Promoter Score (NPS) with\nand strategies for handling sampling noise, and binaryclassification(promotersvs. detractors)for\naimstohelpdevelopersseekingtoreplicateoneor predictingcustomersatisfactioninchatconversa-\nmoretargetclassdistribution(s). tions, achieving moderate improvements with a\nCustomersatisfaction(CSAT)iscriticalforcall macroF1scoreof53.8%.\ncenterperformanceassessment,yetoftenmeasured OtherstudiesexaminedpredictingCSATfrom\nthroughsurveyscompletedbyasmallsubsetofcus- raw audio signal features such as acoustic, emo-\ntomers—averaging8%inourdataset. Thislimited tional,andprosodicfeatures(ParkandGates,2009;\nresponseratecanskewperceivedperformance,as Zweigetal.,2006;VaudableandDevillers,2012;\nnon-respondingcustomers’satisfactionremainsun- Devillersetal.,2010).\nknown. PredictingCSATforallcalls,eventhose This work builds on a previously developed\nwithout survey responses, can mitigate this bias method for predicting CSAT scores using ASR-\nManderscheidandLee(2023). generated (Automated Speech Recognition) call\n4202\nvoN\n91\n]GL.sc[\n1v93521.1142:viXra\ntranscripts (Manderscheid and Lee, 2023). This tainingthenaturalorderofclasses,butourmethod\nmethodimprovedpredictionaccuracywithamap- directly optimizes thresholds to replicate survey\npingfunctionfrombinarymodeloutputsto5CSAT responses,ratherthanusingdatareplication.\nclasses(Figure1). Themappingfunctionwaspa- In\"Asimpleapproachtoordinalclassification,\"\nrameterizedby4decisionthresholds. Thebinary Frank and Hall, 2001 propose a threshold-based\nmodelitselfwasatrainedBigbird,atransformer methodforordinalclassificationproblems. Their\nwithsparseattentionoptimizedtohandlelongin- approachinvolvestrainingaseriesofbinaryclas-\nputsequences(suchascalltranscripts)withalinear sifiers to predict whether an instance belongs to\nmemoryrequirement(Zaheeretal.,2020). a class above a certain threshold. This method is\ncloselyrelatedtoourapproach,asbothaimtopre-\n2.2 ReplicatingClassDistribution\ndictordinalclassesbyoptimizingthresholds. How-\nOurthresholdfittingapproachreplicatesthesurvey ever, we use a single classifier, and our method\nCSAT distribution, crucial for maintaining class goes further by ensuring that the predicted class\nproportionsinpredictions. Researchonmaintain- distributionmatchesthetrainingclassdistribution,\ning class distribution intersects with imbalanced astepbeyondthebasicordinalclassificationtask.\nlearningandordinalregression,usingtechniques ChuandKeerthi(2007)exploredordinalregres-\nlikeresampling,re-weighting,andthresholdadjust- sionusingsupportvectormachines(SVMs),opti-\nmenttohandleclassimbalances. Modelcalibration mizing thresholds within the SVM framework to\ncanbeahelpfuladditiontothesemethods,butis respect the ordinal nature of data. Similar to our\nnot a replacement, as model calibration focuses work,thisstudyfocusesonordinaldataandthresh-\non adjusting predicted probabilities to better re- oldoptimization,butourmethodismodel-agnostic,\nflecttruelikelihoods,whichdoesnotimplythatthe post-processingoutputsofanyclassifiertomatch\nclassdistributionwillbefaithfullyreplicatedifthe desireddistributions.\ndecisionthresholdsareincorrect. These studies provide valuable insights into\nRe-sampling and Re-weighting: These tech- thresholdoptimizationformulticlassandordinal\nniquesadjusttrainingprocessestoaccountforclass classification. Ourworkdistinguishesitselfby:\nimbalances, ensuring minority classes are repre-\n1. Optimizing specific decision thresholds to\nsented. However,theyarenotwellsuitedtorepli-\nalign pCSAT scores with CSAT survey re-\ncatinganexactclassbalance,astheeffectsofthese\nsponses, ensuring calibration and class dis-\ntrainingsetadjustmentsaredifficulttopredict.\ntributionreplication.\nThresholdOptimizationinMulticlassandOr-\ndinal Classification: Threshold optimization is 2. Creatingacustomlossfunctionreflectingour\ncritical in contexts requiring precise class predic- uniqueproductgoalsandusersuggestions.\ntions,suchasmulticlassandordinalclassification\ntasks. Kotsiantisetal.(2006)discussmethodsto 3. Applying our method to a large language\nadjustdecisionthresholdsforimbalanceddatasets, model (LLM) predicting CSAT scores from\nbalancing sensitivity and specificity to represent call center conversations, integrating thresh-\nminorityclasses. Ferrietal.,2002introducemeth- oldoptimizationintoabroadermachinelearn-\nods to optimize decision thresholds to minimize ingpipelinetoaddresspracticalchallengesin\nmisclassification costs. Their work is relevant in real-worldsettings.\ncontextswheredifferentmisclassificationshavedif-\n3 Data&Methods\nferentcosts,makingthresholdadjustmentcrucial.\nWhiletheseapproachesarecloselyrelatedtoours 3.0.1 Transcripts\nbyadjustingmodelthresholdstoreflecttrueclass\nWeusedconversationaltranscriptsgeneratedfrom\ndistributions,theyfocusonbinaryandmulticlass\nour Automatic Speech Recognition engine. The\nclassificationwithoutemphasizingordinalclasses\naccuracy(1-WordErrorRate)was>85%.\nasoursdoes.\nCardoso and da Costa (2007) proposed a data 3.0.2 Calls\nreplicationmethodforordinalclassification,han- Weusedapproximately892Kcallcentercallswith\ndlingordinaldatabyreplicatinginstancestoindi- aCSATsurveyscoreandamodel-assignedpCSAT\nrectlyoptimizethresholdsforordinalpredictions. probabilityrangingfromJune24,2023toJune17,\nThisstudyalignswithourwork,emphasizingmain- 2024.\nSurveyResponses #ofCallCenters [0.07]\n1-50 401 Call transcript Hig Mh o C deS lA T if proba > t 1,2 class 1\n51-200 908 Finetuned Probability elif proba > t 2,3 class 2\n201-500 425 mL oL dM e l Softmax Lo Mw o C dS elA T e el li if f p pr ro ob ba a > > t t3 4, ,4 5 c cl la as ss s 3 4\n501-1000 199 P (“r pob roa bb aili ”ty ) claF sa sn ifi- co au tt io nt =0.9e 2ls , e t =0.45 class 5\n[0.93] 1,2 2,3\n>1000 197 t =0.09, t =0.03\n3,4 4,5\nFigure1: ThemappingfunctionthattakeslowCSAT\nTable1: NumberofCallCentersbySurveyResponses\nprobability(\"proba\")asinputandoutputs1-5pCSAT.\nVolume\nInthisexample, the\"proba\"is0.93, whichislarger\nthant sothemodelemitsapCSATof1.\n1,2\n3.0.3 Trials\nToruleouteffectsduetochanceorperiodicity,we 1. TheaveragepCSATshouldequaltheaverage\nrantheexperiment7timesusingdifferenttraining survey CSAT over the same set of calls. By\nandtestperiods. Thelastofthosetrialscorresponds default, the displayed average pCSAT (and\ntoaproductiondeploymentofthemodel,andthe averageCSAT)isthe%ofsatisfiedcalls,i.e.,\nothertrialsweresimulatedforthepurposesofthis callswithpCSAT≥4.\nanalysis. Each trial consists of a 60 day training\n2. Theseaveragesshouldalsomatchwhentog-\nperiod and 120 day test period. A 30 day period\ngledtousea1-5scale.\nseparates the start of one trial from the start of\nthe next (thus trials overlap). We expected and\n3. ThedistributionofpCSATandsurveyCSAT\nobservednodifferencesbetweenthedeployedand\nshouldmatchascloselyaspossible\nsimulatedtrialssincethepipelineisthesame.\nBasedoncustomerfeedbackweset1%and0.1as\n3.0.4 CallCenters\nthemaximumdifferencestotargetforrequirements\nWe excluded call centers with fewer than 5 high\n1and2respectively.\nand5lowCSATcallsoverthe60-daytrainingpe-\nriodtoavoidveryhighsamplingnoise. Tobetter 3.1.3 ParameterEstimation\nunderstand the impact of sampling noise, we fur- Jointlyestimatethefourthresholds: Tofindthe\nthercategorizedcallcentersheuristicallybasedon optimal parameters, our process iterates through\nthe number of survey CSAT responses in the 60- differentcombinationsofthresholdstofindtheset\ndaytrainingperiod. Table1showsthenumberof thatminimizestheloss.\ncallcentersineachsurveyresponsebin,summed Tomeetallthreeproductrequirements,wecre-\noverthe7trials. atedthefollowinglossfunction:\n3.1 ThresholdOptimizationProcedure\n3.1.1 ModelandMapping Loss = ∆% p,c+∆avg p,c+MSE p,c\nThemodelisalargelanguagemodel(LLM)that\nwherepandcareshortforpCSATandCSAT,re-\npredicts CSAT with binary outputs: high or low\nspectively,and:\nCSAT.Detailsonthemodelandhowitwastrained\nareprovidedinManderscheidandLee,2023. The\nmodelalsoprovidestheprobabilityofbothclasses, ∆% = |(%ofpCSAT ≥ 4)−(%ofCSAT ≥ 4)|\np,c\nreferredtoas\"proba\"forthelowCSAT class. The\nmappingfunction(Figure1)usesthisprobabilityto\noutputapCSATscoreona1-5scale. Themapping\n∆avg = |avg_pcsat−avg_csat|\nhasfourparametersrepresentingdecisionthresh- p,c\nolds (i.e. class boundaries): t , t , t , and\n1,2 2,3 3,4\nt 4,5. Forexample,t 3,4 istheprobabilitythreshold MSE = MSE(pc⃗sat,cs⃗at)\np,c\nseparatingapCSATof3from4.\nWe preferred a random search to a grid search\n3.1.2 ProductRequirements tosavecomputationtime. Weused5000iterations\nOurapproachisbasedonmeetingproductrequire- forrandomsearch,butfound98.7%convergence\nments,rankedbyimportance: by500iterations.\n3.1.4 OptimizationSteps: 3.2 ExperimentalConditions\n1. ComputetheNumberofCallsforEachSurvey Weevaluatedthelossunderfiveconditions:\nCSATLevel:\n1. Baseline: Naivemodeloutput(evaluatedover\nn = numberofcallswithsurveyCSAT\ncsati testperiod)\nwhereclassi ∈ (1,2,3,4,5)\n2. GlobalThreshold: Thresholdsarefittedona\n2. CalculatetheAverageSurveyCSAT: single,globalpool(evaluatedovertestperiod)\n(cid:80)5\n(n ·i) 3. CallCenterThreshold: Individualthreshold-\navg_csat = i=1 csati\n(cid:80)5 n ing for each call center (evaluated over test\ni=1 csati\nperiod)\n3. Initializetheloss:\n4. TrainPeriod: Weapplythesamecallcenter-\nbest_loss = 1000.0\nspecificparametersasusedintheCallCenter\nThreshold condition, but apply them to the\n4. RandomSearchforOptimalThresholds: Per-\ntrainingperiodinsteadofthetestperiod. As\nform a random search through the possible\nwe expect a near-zero difference of means,\nthresholds to find the set that minimizes the\nthis serves to validate our parameter estima-\nloss. Forj inrange(5000):\ntionmethod.\n(a) Generate4uniformrandomvaluesand\n5. Bootstrap (Train Period): This approach\nsortthem:\nis similar to the \"train\" condition, but the\nt 12 > t 23 > t 34 > t 45 ∼ U(0,1) key difference is that we repeatedly resam-\nplethetrainingsetandmeasurethedifference\n(b) ComputetheNumberofCallsforEach\nof means over these samples. This method\npCSATLevel:\nhelpsusestimatehowmuchofthelossinthe\nn = numberofcallswithpCSAT \"Callcenterthresholding\"conditionisdueto\npcsati\nsamplingnoise,andattributetheresttodiffer-\nwhereclassi ∈ (1,2,3,4,5)\nencesbetweentrainandtestdistributions,i.e.\n(c) CalculatetheAveragepCSAT:\nmodeldrift.\n(cid:80)5\n(n ·i)\navg_pcsat = i=1 pcsati We note that the first 3 conditions are test condi-\n(cid:80)5\nn\ni=1 pcsati tions, i.e. evaluated on the test set, whereas the\nlast2aretrainconditionswhichhelpusunderstand\n(d) ComputetheDeltaBetweenAveragepC-\nsourcesoferror.\nSATandCSAT:\n∆pcsat_csat = avg_pcsat−avg_csat 4 Results\n(e) Compute∆% Theeffectivenessofdifferentmethodsforpredict-\np,c\n(f) Normalize both CSAT Vectors to unit ingcustomersatisfaction(CSAT)scoreswasevalu-\nlength: atedthroughvariousexperimentalconditions. The\nresultsaresummarizedinFigures2-5,anddetailed\npc⃗sat = normalized([n ,...,n ])\npcsat1 pcsat5 observationsareasfollows:\ncs⃗at = normalized([n ,...,n ])\ncsat1 csat5 4.1 Loss\n(g) Calculate the Mean Squared Error Be-\nOverall loss, depicted in Figure 2, combines the\ntweentheNormalizedVectors(MSE )\np,c differenceofmeans,differenceofpercentsatisfied,\n(h) Computetheloss:\nandMSE.WeseethattheBaselinemethodconsis-\ntentlyhasthehighestloss,andtheTraincondition\nhasthelowest. Thetrainconditiondoesnothave\nLoss = ∆% +∆avg +MSE\np,c p,c p,c\n0errorbecauseitisnotusuallypossibletofind4\n(i) Updatethelossandbestthresholdsifthe parameterstozeroall3termsthatmakeuptheloss\ncurrentlossislower. simultaneously.\ncallsbetweenpCSATandCSAT,averagedoverthe\nBaseline Global Call Center Train Bootstrap\ncallcentersineachbin. TheBaselinemethodwas\n0.5\nonlyoutperformedforcallcenterswiththelargest\n0.4\nresponsevolume(>1000). Forthesecallcenters,\n0.3\nthe Call Center Threshold method performs best,\n0.2\nfollowed by Global Threshold. We also note an\n0.1 unexpecteduptickinerrorforall3testconditions,\n0.0 comparedtosmallerresponsevolumes.\n1-50 51-200 201-500 501-1000 > 1000\nCount of Survey Responses 4.3 DifferenceofMeans\nFigure2: Theaveragelossforeachofthefiveexper-\nimental conditions, binned by the call center’s CSAT Baseline Global Call Center Train Bootstrap\nsurveyresponses. 0.5\n0.4\nNow we compare the test conditions. For call 0.3\ncenters with the smallest response volumes, the 0.2\nGlobal Threshold method performs best. On the 0.1\notherhand,theCallCenterThresholdmethodper-\n0.0\nformed best for call centers with the largest re- 1-50 51-200 201-500 501-1000 > 1000\nsponse volumes. Overall, we see a gradual trend Count of Survey Responses\nofthismethodimprovingastheresponsevolume\nincreases. This makes sense since the Call Cen- Figure4:Theaverageabsolutedifferencebetweenmean\nPredictedCSATandsurveyCSATforeachofthefive\nterThresholdmethodislimitedbysamplingnoise,\nexperimental conditions, binned by the call center’s\nwhichisgreatestforsmallresponsevolumes. In-\nCSATsurveyresponses.\ndeed,wecanseetheeffectofthesamplingnoise\ndirectly by looking at how much more loss the\nFigure4focusesontheaverageabsolutediffer-\nBootstrap condition has relative to the Train con-\nence between mean Predicted CSAT and survey\ndition at low (< 200) response volumes. As we\nCSAT.TheBaselinemethodconsistentlylagsother\nget to higher (> 500) response volumes, we ob-\nmethods, showing our methods create a substan-\nservedthattheBootstrapconditioncatchesupwith\ntialimprovement. TheGlobal Threshold method\ntheTraincondition,whichindicatesthatsampling\nperforms best at the lowest response volumes (<\nerrorceasestobesignificantatthosevolumes.\n200), whereas the Call Center Threshold method\n4.2 Differencein%ofSatisfiedCalls outperformsothermethodsfrom200callsonwards,\nconsistentwithitsrequirementofsmallsampling\nnoise.\nBaseline Global Call Center Train Bootstrap\n10.00% Asexpected,theTrainandBootstrapconditions\nshowverylowpercentages,furthervalidatingthe\n8.00%\nparameterestimationandhighlightingtheminimal\n6.00%\nimpactofsamplingnoiseafter500calls.\n4.00%\n2.00% 4.4 MSE\n0.00%\n1-50 51-200 201-500 501-1000 > 1000 The MSE, shown in 5, measures the vector simi-\nlaritybetweenthepCSATandCSATdistributions.\nCount of Survey Responses\nThe Baseline method exhibits by far the highest\nFigure3: Theaveragedifferenceinpercentageofsatis- MSE values across all call volumes, so much so\nfiedcallsbetweenpCSATandCSAT,brokendownby thefigurerequiresalogarithmicscale. Itexceeds\nthecallcenter’scountofsurveyresponses. 0.1 for all survey response volumes. The Global\nThresholdmethodisconsistentlybestatlowering\nFigure3examinesthefirstcomponentoftheloss theMSE,thoughthegapwithCallCenterThresh-\nfunction,thedifferenceinpercentageofsatisfied oldnarrowsassurveyresponsesincrease.\nssoL\n%\nfo\necnereffiD\nsegarevA\nfo\necnereffiD\nThresholdmethodforcallcenterswithfewerthan\nBaseline Global Call Center Train Bootstrap\n200 survey responses and Call Center Threshold\n0.1 methodforlargerones. Thishybridstrategylever-\n0.05\nagesthestrengthsofbothmethods,ensuringmore\naccurateandreliablepCSATpredictionsacrossdi-\n0.01\n0.005 verseoperationalcontexts.\nWe recommend a similar approach for multi-\n0.001\nclass classification problems where a consistent\n1-50 51-200 201-500 501-1000 > 1000\nclass balance is important across model updates.\nCount of Survey Responses Ourapproachcanbeusedwhetherthereisasingle\npoolofinputs,orsubgroupsanalogoustoourcall\nFigure5: TheMeanSquaredErrormeasuresthevector\ncenters. Developersshouldbecautiousofthesam-\nalignmentbetweenthenormalizedPredictedCSATand\nplingnoiseintheirdatasetsanduseadata-driven\nsurveyCSATdistributions. Shownforeachofthefive\nexperimental conditions, binned by the call center’s approachtodeterminetheminimumsamplesizes\nCSATsurveyresponses. fortheirspecificapplication.\n6 Limitations\n5 Discussion\nWhileourthresholdingmethoddemonstratessub-\nSomebutnotallinitialtargetswereachieved:\nstantialimprovements,severallimitationsmustbe\nacknowledged:\n• DifferenceinPercentageofSatisfiedCalls:\nNotachieved. Themethodswerenotableto\n• SamplingNoise: Ashighlighted,smallcall\nimprove over Baseline or meet the target of\ncenterswithlowsurveyresponsevolumessuf-\nless than 1%. The fact the fitting thresholds\nferfromhighsamplingnoise,limitingtheef-\ndoesnotimprovetheoutputclassdistribution\nfectivenessofourapproachforsamplesizes\nsuggests that the baseline classifier outputs\nunder 500,especiallycallcenterthresholding.\nmay be already well distributed. This is a\nlikely explanation because this metric treats • Temporal Stability: Although our method\nCSATasbinary(callsatisfiedifCSAT>=4) shows promise in maintaining low loss over\nandthebaselineclassifieristrainedonbinary at least 4 months, we did not examine the\nCSATdata. Furtherworkmayberequiredto timecourse of errors over those 4 months or\nyieldimprovements. beyond. Long-termdriftcouldbeaconcern\nandwarrantsfurtherinvestigation.\n• Difference of Means: The Call Center\nThreshold method consistently achieved the 7 EthicsStatement\ntarget(differenceofmeanslessthan0.1)for\nIndevelopingandimplementingthismethod,we\ncallcenterswithsurveyresponsesgreaterthan\nhaveadheredtoethicalstandardstoensurefairness,\n500-1000. Thismethodalsoachievedsignifi-\ntransparency,andaccountability:\ncantimprovementsoverBaselineforallcall\ncenterbins.\n• Bias Mitigation: Previously, we have sam-\npled subpopulations of users and evaluated\n• Mean Squared Error (MSE): Both the\ninternallytoensurethepCSATisnotbiased\nGlobalThresholdandCallCenterThreshold\nagainstspecificgroups. Thisapproachtakes\nmethodssignificantlyimprovedtheMSEover\nafurthersteptoreducebiasinpCSATscores\nBaseline,indicatingimprovedalignmentbe-\nbyensuringamoreaccuratereflectionofcus-\ntweenpCSATandactualCSATdistributions.\ntomersatisfactionacrossdifferentcallcenters.\nInthiscase,therewasnoquantitativetarget,\nHowever,continuousevaluationandimprove-\nbuttheimprovementisover10X.\nmentarenecessarytoaddressanyemergentbi-\nHaving learned from the varying performance ases,andournear-termplansincludequantifi-\nof the methods across different survey response ableandverifiableexplainabilityforAICSAT\nvolumes, we are now considering implementing whichwillhelpouruserspinpointthecauses\nahybridapproach. Specifically,usingtheGlobal oflowpCSAT,includinganybias.\nESM\n• Transparency: We have documented our study. InEleventhAnnualConferenceoftheInterna-\nmethodsandfindingscomprehensivelytopro- tionalSpeechCommunicationAssociation(INTER-\nSPEECH),volume10,pages2350–2353.\nvide clear insights into our process and its\nimpactonpredictionaccuracy. C.Ferri,J.Hernández-Orallo,andM.A.Salido.2002.\nLearningdecisiontreesusingtheareaundertheroc\n• DataPrivacy: Allcustomerdatausedinthis curve. InProceedingsofthe19thInternationalCon-\nstudy has been anonymized and handled in ferenceonMachineLearning,pages139–146. Re-\ntrievedfromresearchgate.net.\ncompliance with data privacy regulations to\nprotectindividualprivacy. Wefollowthedata E. Frank and M. Hall. 2001. A simple approach to\nprivacy measures in place at Dialpad which ordinal classification. In European Conference on\nincludescrubbingpersonalidentifiableinfor- MachineLearning,pages145–156. Retrievedfrom\nspringer.com.\nmation(PII)fromcustomerdataandrestrict-\ningouruseofcustomerdatatoimprovements S. B. Kotsiantis, D. Kanellopoulos, and P. E. Pinte-\ntotheservicesweprovidethem. Wedidnot las.2006. Handlingimbalanceddatasets: Areview.\nGESTSInternationalTransactionsonComputerSci-\nrelyonanyexternalannotations.\nenceandEngineering,30(1):25–36. Retrievedfrom\ngests-intl.com.\n• StakeholderImpact: Theimprovedaccuracy\ninCSATpredictionsenablesbetterdecision- E. Manderscheid and M. Lee. 2023. Predicting cus-\nmaking for coaching, follow-up, and ser- tomersatisfactionwithsoftlabelsforordinalclassifi-\nviceimprovements,ultimatelybenefitingcus- cation. InProceedingsofthe61stAnnualMeetingof\ntheAssociationforComputationalLinguistics(Vol-\ntomersandcallcenterperformance.\nume 5: Industry Track), pages 652–659, Toronto,\nCanada.AssociationforComputationalLinguistics.\n8 Acknowledgements\nAnonymizedforreview.\nWewouldliketoacknowledgethecontributionsof\nYoung-BumParkandStephenC.Gates.2009. Towards\nourcolleagues,thesupportfromDialpad,andthe real-timemeasurementofcustomersatisfactionusing\nfeedback from call center managers who helped automaticallygeneratedcalltranscripts. InProceed-\ningsofthe18thACMConferenceonInformationand\nrefineourapproach. Inparticular,wethankperson\nKnowledgeManagement,pages1387–1396.ACM.\nDougMackenzieformaintainingessentialdatabase\ntables. CarolineVaudableandLaurenceDevillers.2012. Neg-\native emotions detection as an indicator of dialogs\nqualityincallcenters. In2012IEEEInternational\nConferenceonAcoustics,SpeechandSignalProcess-\nReferences\ning(ICASSP),pages5109–5112.IEEE.\nJeremyAuguste,DelphineCharlet,GeraldineDamnati,\nFrederic Bechet, and Benoit Favre. 2019. Can we Manzil Zaheer, Guru Guruganesh, Avinava Dubey,\npredictself-reportedcustomersatisfactionfrominter- Joshua Ainslie, Chris Alberti, Santiago Ontanon,\nactions? InProceedingsofthe2019Conferenceon PhilipPham,AnirudhRavula,QifanWang,LiYang,\nNeuralInformationProcessingSystems(NeurIPS), andAmrAhmed.2020. Bigbird: Transformersfor\npages7385–7389. longersequences. arXivpreprintarXiv:2007.14062.\nSubmitted on 28 Jul 2020 (v1), last revised 8 Jan\nJoseph Bockhorst, Shi Yu, Luisa Polania, and Glenn 2021(v2).\nFung.2017. Predictingself-reportedcustomersat-\nisfactionofinteractionswithacorporatecallcenter. Geoffrey Zweig, Olivier Siohan, George Saon, Bhu-\nInMachineLearningandKnowledgeDiscoveryin vanaRamabhadran,DanielPovey,LidiaMangu,and\nDatabases,pages179–190,Cham.SpringerInterna- BrianKingsbury.2006. Automatedqualitymonitor-\ntionalPublishing. ing for call centers using speech and nlp technolo-\ngies. InProceedingsofthe2006Conferenceofthe\nJ.S.CardosoandJ.F.PintodaCosta.2007. Learning NorthAmericanChapteroftheAssociationforCom-\ntoclassifyordinaldata: Thedatareplicationmethod. putationalLinguisticsonHumanLanguageTechnol-\nJournalofMachineLearningResearch,8:1393–1429. ogy: Companion Volume: Demonstrations, pages\nRetrievedfromjmlr.org(SpringerLink). 292–295.AssociationforComputationalLinguistics.\nW.ChuandS.S.Keerthi.2007. Supportvectorordi-\nnalregression. NeuralComputation,19(3):792–815.\nRetrievedfromdoi.org(SpringerLink).\nLaurence Devillers, Caroline Vaudable, and Chan-\ntal Chastagnol. 2010. Real-life emotion-related\nstates detection in call centers: a cross-corpora",
    "pdf_filename": "Predicting_Customer_Satisfaction_by_Replicating_the_Survey_Response_Distribution.pdf"
}