{
    "title": "DiM $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Imag",
    "abstract": "As a technique to alleviate the pressure of data an- notation, semi-supervised learning (SSL) has attracted widespread attention. In the specific domain of medical im- age segmentation, semi-supervised methods (SSMIS) have become a research hotspot due to their ability to reduce the need for large amounts of precisely annotated data. SSMIS focuses on enhancing the model’s generalization perfor- mance by leveraging a small number of labeled samples and a large number of unlabeled samples. The latest sharpness- aware optimization (SAM) technique, which optimizes the model by reducing the sharpness of the loss function, has shown significant success in SSMIS. However, SAM and its variants may not fully account for the distribution differ- ences between different datasets. To address this issue, we propose a sharpness-aware optimization method based on f-divergence minimization (DiM) for semi-supervised med- ical image segmentation. This method enhances the model’s stability by fine-tuning the sensitivity of model parameters and improves the model’s adaptability to different datasets through the introduction of f-divergence. By reducing f- divergence, the DiM method not only improves the perfor- mance balance between the source and target datasets but also prevents performance degradation due to overfitting on the source dataset.",
    "body": "DiM: f-Divergence Minimization Guided Sharpness-Aware Optimization for\nSemi-supervised Medical Image Segmentation\nBingli Wang\nTsinghua University(SZ)\nHoucheng Su\nUniversity of Macau\nNan Yin\nZayed University of Artificial Intelligence\nUnited Arab Emirates\nyinnan8911@gmail.com\nMengzhu Wang *\nHebei University of Technology\ndreamkily@gmail.com\nLi Shen *\nSun Yat-sen University\nmathshenli@gmail.com\nAbstract\nAs a technique to alleviate the pressure of data an-\nnotation, semi-supervised learning (SSL) has attracted\nwidespread attention. In the specific domain of medical im-\nage segmentation, semi-supervised methods (SSMIS) have\nbecome a research hotspot due to their ability to reduce the\nneed for large amounts of precisely annotated data. SSMIS\nfocuses on enhancing the model’s generalization perfor-\nmance by leveraging a small number of labeled samples and\na large number of unlabeled samples. The latest sharpness-\naware optimization (SAM) technique, which optimizes the\nmodel by reducing the sharpness of the loss function, has\nshown significant success in SSMIS. However, SAM and its\nvariants may not fully account for the distribution differ-\nences between different datasets. To address this issue, we\npropose a sharpness-aware optimization method based on\nf-divergence minimization (DiM) for semi-supervised med-\nical image segmentation. This method enhances the model’s\nstability by fine-tuning the sensitivity of model parameters\nand improves the model’s adaptability to different datasets\nthrough the introduction of f-divergence. By reducing f-\ndivergence, the DiM method not only improves the perfor-\nmance balance between the source and target datasets but\nalso prevents performance degradation due to overfitting on\nthe source dataset.\n1. Introduction\nMedical Image Segmentation (MIS)[3, 14, 33] plays a\ncrucial role in assisting computers with disease diagno-\nsis and treatment research by helping identify key organs\nor lesions in abnormal images.\nRecently, numerous su-\n*Corresponding Author\npervised learning-based encoder-decoder network architec-\ntures have made significant advancements in medical im-\nage segmentation, such as U-Net[24], U-Net++[46], and H-\nDenseUNet[13]. However, the success of these technolo-\ngies largely relies on large-scale, pixel-level annotated data.\nIn practice, annotating medical images is not only costly\nbut also challenging due to issues such as low contrast and\nnoise, making it difficult to clearly display images. More-\nover, medical images require more specialized knowledge\ncompared to natural images, which makes constructing a\nlarge-scale, accurately annotated medical image database\nnearly an impossible task.\nIn contrast, semi-supervised\nlearning [23, 35] offers a new solution to the problem of\ninsufficient data supervision in weakly supervised learn-\ning [47]. It primarily utilizes a small amount of labeled\ndata and a large amount of unlabeled data for joint training.\nClearly, semi-supervised learning is significantly more suit-\nable for medical image segmentation and adapting to real-\nworld clinical scenarios than traditional supervised learning\nmethods.\nDue to the easy availability of unlabeled data, doctors\nmay not have the time to verify its distribution when faced\nwith massive amounts of data. This ”domain shift” [7, 25]\nissue can lead to significant performance degradation in\nmodels, and it is a critical concern when developing semi-\nsupervised medical image segmentation (SSMIS) [21] mod-\nels. In fact, we should allow unlabeled data to come from\none or more different distributions. However, existing un-\nsupervised domain adaptation (UDA) [11, 43, 44] methods\ndo not directly address this issue because they rely on large\namounts of labeled source domain data, which is exactly\nwhat SSMIS aims to resolve.\nRecent studies, such as Sharpness-Aware Minimization\n(SAM)[8], enhance model generalization performance by\nreducing the sharpness of the loss function. Here, L repre-\narXiv:2411.12350v1  [cs.CV]  19 Nov 2024\n\nsents the loss function to be minimized, and θ represents\nthe parameters of the neural network.\nSAM first com-\nputes a weight perturbation ϵ that maximizes the empiri-\ncal risk L(θ), and then minimizes the loss of the perturbed\nnetwork.\nIn short, SAM aims to reduce the maximum\nloss near the model parameters θ. Due to the complexity\nof this minimization-maximization optimization problem,\nSAM approximates L with a surrogate loss function Lp(θ)\nfor minimization. However, it is important to note that mini-\nmizing Lp(θ) does not guarantee reaching the flat minimum\nregion for SSMIS [48]. KL divergence [32] has demon-\nstrated strong performance in SSMIS. The application of\nKL divergence in SSMIS primarily improves model train-\ning efficiency and accuracy by measuring the differences\nbetween different probability distributions. This is partic-\nularly useful when dealing with limited labeled data and a\nlarge amount of unlabeled data, as it helps guide the model\nto learn more useful information in a semi-supervised set-\nting.\nFor example, MMLBF [6] propose a region-based\nmulti-phase level set method based on KL divergence. Lu\net al.[18] estimate uncertainty by calculating the Kullback-\nLeibler divergence between the predictions of the student\nand teacher models, and directly use this uncertainty to cor-\nrect the learning of noisy pseudo-labels, rather than setting\na fixed threshold to filter pseudo-labels. SwinMM[37] in-\ncludes a masked multi-view encoder and a novel proxy task\nbased on mutual learning, which contributes to effective\nself-supervised pretraining.\nHowever, all of these methods are considered from the\nperspective of KL divergence, which is highly sensitive\nto probability values close to zero in the target distribu-\ntion, often leading to an infinite divergence. In contrast,\nf-divergence can reduce this sensitivity by selecting an ap-\npropriate function, making it more stable and robust, es-\npecially when dealing with sparse or extreme distributions.\nIn SSMIS, SAM emphasizes achieving stability by control-\nling the sensitivity of model parameters, while the intro-\nduction of f-divergence helps further regulate the model’s\nadaptability across different domains.\nBy minimizing f-\ndivergence, SAM can enhance the balanced performance\nof the model across both the source and target domains,\nwhile avoiding performance degradation due to overfitting\nthe source domain. In this work, to overcome the limitation\nof SAM and explore the full potential of f-divergence, we\npresent a novel method f-divergence minimization guided\nsharpness-aware optimization for semi-supervised medical\nimage segmentation (DiM). By consider the f-divergence\nand sharpness-aware minimization, which can still be ef-\nfectively computed even when the support sets of the distri-\nbutions are different. Our main contributions can be sum-\nmarized as follows:\n• we analyze the limitations of SAM-like methods and pro-\npose f-divergence to ensure the model convergence to a\nflat region with a small loss.\n• To the best of our knowledge, this is the first work to ap-\nply f-divergence constraints to SAM paradigm.\n• we demonstrate the superior performance of DiM to state-\nof-the-arts on three SSMIS benchmarks.\n2. Related Work\n2.1. Semi-supervised Medical Image Segmentation\nDue to the complexity of medical images, extensive manual\nannotation by experts is both challenging and costly [49].\nTo address this, semi-supervised medical image segmen-\ntation approaches have emerged as effective solutions that\nleverage limited labeled data [3]. Luo et al. [19] proposed\na dual-task consistency-based semi-supervised framework\nto simultaneously predict per-pixel segmentation maps and\ngeometrically-aware level set representations, introducing\na dual-task consistency regularization to enhance perfor-\nmance. Wu et al. [39] presented MC-Net++, which em-\nploys a shared encoder and multiple distinct decoders and\nintroduced a new mutual consistency constraint. This ap-\nproach statistically identifies uncertain regions, particularly\nhard regions within unlabeled data.\nLuo et al.\n[20] in-\ncorporated a cross-teaching approach between CNNs and\nTransformers, resulting in a simple yet efficient semi-\nsupervised learning framework.\nMiao et al.\n[23] high-\nlighted the importance of model independence between net-\nworks or branches in semi-supervised medical segmenta-\ntion (SSMS). Ma et al. [22] identified the issue of perfor-\nmance degradation in semi-supervised medical image seg-\nmentation due to shared domain distributions, proposing\nMixed-domain Semi-supervised Medical Image Segmen-\ntation (MIDSS). They emphasized that generating reliable\npseudo-labels for unlabeled data is crucial in domain shifts\nin labeled data. Nevertheless, due to the inherent complex-\nity of medical images, these models often exhibit limited\ngeneralization ability and convergence instability, which re-\nmains a challenging problem.\n2.2. Unsupervised Domain Adaptation\nUnsupervised Domain Adaptation (UDA) [9, 15, 34] aims\nto adapt models from a labeled source domain to an unla-\nbeled target domain by minimizing the domain shift. This\nalignment of feature distributions enables knowledge trans-\nfer from source to target, enhancing classification perfor-\nmance [10, 38].\nMany UDA approaches use a domain\nclassifier to distinguish source from target features, while\nthe feature extractor learns to match feature distributions\n[16, 30]. UDA is widely used in tasks like image classifica-\ntion [15], semantic segmentation [28], and object detection\n[27]. Semi-supervised domain adaptation further incorpo-\nrates a small amount of labeled target data to improve trans-\nfer [26].\n\nTable 1. Various commonly used f-divergences with their derivatives and second derivatives.\nf-divergence\nf(x)\nf′(x)\nf′′(x)\nReverse KL\nxlogx\nlogx + 1\n1\nx\nForward KL\n−logx\n−1\nx\n1\nx2\nJeffrey\n(x −1)logx\nlogx + 1 −1\nx\n1\nx +\n1\nx2\nJensen-Shannon\n−x+1\n2 log x+1\n2\n+ x\n2 logx\n1\n2 log 2x\nx+1\n1\n2x(x+1)\nPearson\n(1−x)2\nx\n1 −\n1\nx2\n2\nx3\n2.3. Sharpness-Aware Minimization (SAM)\nForet et al. [8] observed that solely minimizing training\nloss can lead to suboptimal model quality. They proposed\nSharpness-Aware Minimization (SAM), which seeks pa-\nrameters in neighborhoods of uniformly low loss, result-\ning in a Min-Max optimization problem suitable for gra-\ndient descent. Andriushchenko et al. [1] provided theo-\nretical insights on SAM’s implicit bias in diagonal linear\nnetworks and empirically examined its behavior in nonlin-\near networks. Zhou et al. [45] addressed SAM’s limita-\ntion in handling class imbalance, particularly overfitting to\ntail classes, by introducing Imbalanced-SAM (ImbSAM),\na class-aware smoothing approach effective in long-tailed\nclassification and semi-supervised anomaly detection tasks.\nWang et al. [36] introduced a model integrating MedSAM\nwith an uncertainty-aware loss function and SharpMin op-\ntimizer, enhancing segmentation accuracy and robustness.\nHowever, a tailored solution for semi-supervised medical\nimage segmentation remains absent.\n3. Methods\n3.1. Aligning Features via f-Divergence\nSemi-supervised medical image segmentation is challeng-\ning due to the scarcity of labeled data and the high-\ndimensional complexity of medical images. In this setting,\nmodels must leverage both labeled and unlabeled data to\nlearn precise segmentation boundaries. However, limited\nlabeled data can lead to feature drift, where the representa-\ntions learned from unlabeled data deviate from those based\non labeled data. This misalignment between labeled and un-\nlabeled feature distributions reduces segmentation accuracy\nand limits generalization on unseen data.\nTo address this, we utilize f-divergence to align the high-\ndimensional logits from labeled and unlabeled data, con-\nstraining the features of unlabeled data based on a limited\nset of labeled data. Let plabel and punlabel denote the distri-\nbutions of logits for the labeled and unlabeled data over a\ndiscrete set X. Our goal is to guide punlabel by minimiz-\ning the f-divergence between these distributions in high-\ndimensional space.\nThis alignment mitigates feature drift, improving gener-\nalization in the target domain. Additionally, f-divergence\noperates effectively in high-dimensional spaces, making\nit well-suited for capturing subtle but critical variations\nin medical image features.\nBy aligning feature distribu-\ntions, f-divergence fosters a stable and consistent feature\nrepresentation, enhancing segmentation accuracy in semi-\nsupervised conditions.\nFor a convex function f(x) : R+ →R with f(1) = 0,\nthe f-divergence Df(plabel∥punlabel) is defined as:\n  \\begin {aligned} D _f(p_{\\text\n \n{\nl abel}} \\|\n p_{\\text {\nun\nl a bel}}) &= \\mathbb { E }_{x \\sim p_{\\text {unlabel}}} \\left [ f\\left ( \\frac {p_{\\text {label}}(x)}{p_{\\text {unlabel}}(x)} \\right ) \\right ] \\\\ &\\quad + f'(\\infty ) p_{\\text {label}}(p_{\\text {unlabel}} = 0), \\end {aligned} \n(1)\nwhere f ′(∞) = limt→0 tf\n\u0000 1\nt\n\u0001\n. The second term repre-\nsents the contribution of points x in the support of plabel\nwhere punlabel(x) = 0, which accounts for cases where the\nlabeled and unlabeled data distributions do not overlap.\nTo align plabel and punlabel, we define the alignment loss:\n  \\beg i n {aligned} \\mathca\nl  {L}_{\\text\n \n{\na lign}} &=\nD_f(p_{\\tex\nt {label}} \\| p_{\\text {unlabel}}) \\\\ &=\\mathbb {E}_{x \\sim p_{\\text {unlabel}}} \\left [ f\\left ( \\frac {p_{\\text {label}}(x)}{p_{\\text {unlabel}}(x)} \\right ) \\right ] \\end {aligned} \n(2)\nMinimizing Lalign encourages the logits of unlabeled\ndata to approximate those of labeled data, enhancing fea-\nture consistency for semi-supervised learning.\nTo quantify this alignment, we utilize specific f-\ndivergence variants frequently used in machine learning,\nincluding Jeffrey divergence, Jensen-Shannon divergence,\nand Pearson divergence. Each variant has a unique form\nof f(x), f ′(x), and f ′′(x), as shown in Table 1, enabling\nflexible divergence calculations between plabel and punlabel.\nThe f-divergences are computed via Monte Carlo estima-\ntion based on samples from punlabel, applying the respec-\ntive values in Table 1 to evaluate Lalign and facilitate back-\npropagation during training.\n3.2. Sharpness-Aware Entropy Minimization\nSemi-supervised medical image segmentation leverages\nboth labeled and unlabeled data for accurate boundary de-\ntection.\nHowever, limited labeled data and distribution\n\nshifts often lead to feature inconsistency and unreliable pre-\ndictions, especially on unseen test samples, necessitating\nmethods that improve model robustness to distributional\nvariations. Sharpness-aware minimization (SAM) enhances\nmodel generalization by optimizing within low-loss neigh-\nborhoods, stabilizing performance under distribution shifts.\nHowever, directly filtering unreliable test samples using\ngradient norms is challenging due to variations in scale\nacross models and shifts.\nDirectly using gradient norms to filter out unreliable test\nsamples is challenging due to variability in scale across\nmodels and types of distribution shifts. Instead, we lever-\nage entropy as a proxy for gradient magnitude, selecting\nsamples with low entropy values to focus adaptation on con-\nfident predictions. Given an entropy function E(x; θ) for a\nsample x with model parameters θ, we define the selective\nentropy minimization as:\n  \\\nl abel {eq :re\nliab l e_entropy} \\begin {aligned} \\min _{\\bm {\\theta }} S(\\bm {x}) E(\\bm {x}; \\bm {\\theta }), \\quad S(\\bm {x}) \\triangleq \\mathbb {I}_{\\left \\{E(\\bm {x}; \\bm {\\theta }) < E_{0}\\right \\}}(\\bm {x}) \\end {aligned} \n(3)\nwhere S(x) is an indicator function that activates when the\nentropy E(x; θ) is below a pre-defined threshold E0. This\napproach ensures that only samples with low entropy (i.e.,\nhigh confidence) contribute to the training, effectively fil-\ntering out unreliable samples that might otherwise induce\nlarge gradients.\nFor further stability, we aim to guide the model towards\nflatter regions of the entropy loss landscape, which reduces\nsensitivity to noisy gradients. We define a sharpness-aware\nentropy objective, ESA(x; θ), that measures the maximum\nentropy within a perturbation neighborhood around the cur-\nrent parameters:\n  \\\nl abel { eq:\nsa_ent ro p y} \n\\begin  {al i g ned} \\min _{\\bm {\\theta }} E^{\\text {SA}}(\\bm {x}; \\bm {\\theta }), \\quad E^{\\text {SA}}(\\bm {x}; \\bm {\\theta }) \\triangleq \\max _{\\|\\bm {\\epsilon }\\|_{2} \\leq \\rho } E(\\bm {x}; \\bm {\\theta } + \\bm {\\epsilon }) \\end {aligned} \n(4)\nwhere ϵ is a perturbation vector constrained within a Eu-\nclidean ball of radius ρ. This inner maximization encour-\nages the model to be robust against perturbations, promot-\ning a flat minimum for the entropy loss. Following the SAM\napproach, we approximate ϵ∗(θ) by:\n  \\la b e l {e q:epsil on_ approx}  \\h\nat {\\bm  {\\epsilon }}(\\bm {\\theta }) = \\rho \\, \\sign \\left (\\nabla _{\\bm {\\theta }} E(\\bm {x}; \\bm {\\theta })\\right ) \\frac {|\\nabla _{\\bm {\\theta }} E(\\bm {x}; \\bm {\\theta })|}{\\|\\nabla _{\\bm {\\theta }} E(\\bm {x}; \\bm {\\theta })\\|_{2}} \n(5)\nSubstituting ˆϵ(θ) back into the objective, we obtain an\napproximation for the gradient that encourages flat minima:\n  \\label  { e q:grad ie\nnt_\napprox} \\nabla _{\\bm {\\theta }} E^{\\text {SA}}(\\bm {x}; \\bm {\\theta }) \\approx \\nabla _{\\bm {\\theta }} E(\\bm {x}; \\bm {\\theta }) \\Big |_{\\bm {\\theta } + \\hat {\\bm {\\epsilon }}(\\bm {\\theta })} \n(6)\nOur final objective for Reliable Sharpness-Aware En-\ntropy Minimization combines selective entropy minimiza-\ntion and sharpness-aware optimization:\n  \\\nla\nbel {eq:ov erall_optimization} \\min _{\\tilde {\\bm {\\theta }}} S(\\bm {x}) E^{\\text {SA}}(\\bm {x}; \\bm {\\theta }) \n(7)\nIn this study, we introduce Sharpness-Aware Entropy\nMinimization(SAEM), an approach that combines entropy\nminimization with sharpness-aware training to achieve\nadaptive entropy reduction, enhancing model stability un-\nder challenging conditions. Here, S(x) and ESA(x; θ) rep-\nresent entropy measures as defined in Equations (3) and (4),\nrespectively. The learnable parameters designated for adap-\ntation are denoted as ˜θ ⊂θ.\nIn essence, SAEM offers a robust framework by integrat-\ning entropy filtering with sharpness-aware training, yielding\nadaptive entropy reduction while ensuring model resilience,\nparticularly under demanding conditions.\n3.3. Loss Function\nThe overall loss Ltotal is composed of the following compo-\nnents:\n1.\nSupervised Loss (Ls):\nApplied to labeled data\nto guide predictions with ground truth, combining cross-\nentropy and dice losses for accurate segmentation.\n2. Intermediate Losses (Lin and Lout): Defined for\nintermediate samples us\nin and us\nout, each using weighted\ncross-entropy (Lce) and dice loss (Ldice) to enforce con-\nsistency between pseudo labels and model predictions.\n  \\ b egin {ali gn\ned}  \\ma t hcal {L}_{i n}\n = \\mathcal {L}_{ce}(\\hat {p}_{in}, p^{s}_{in}, w_{in}) + \\mathcal {L}_{dice}(\\hat {p}_{in}, p^{s}_{in}, w_{in}) \\end {aligned} \n(8)\n  \\b e gin {align ed\n} \\m athca\nl {L}_{out} =  \\\nmath cal {L}_{ce}(\\hat {p}_{out}, p^{s}_{out}, w_{out}) \\\\ + \\mathcal {L}_{dice}(\\hat {p}_{out}, p^{s}_{out}, w_{out}) \\end {aligned} \n(9)\nwhere win and wout are pixel-wise weights set by a confi-\ndence threshold to filter unreliable pseudo labels.\nEach component plays a crucial role in enforcing robust\nsupervision on both labeled and unlabeled data, supporting\nreliable predictions across domains. The overall loss Ltotal\nis defined as follows:\n  \\mat h ca l  {L}_ { \\tex t  {tota l }} = \\mathcal {L}_s + \\lambda \\left ( \\mathcal {L}_{in} + \\mathcal {L}_{out} + \\lambda \\mathcal {L}_{\\text {sym}} \\right ) + \\mathcal {L}_{\\text {align}} \n(10)\nwhere λ is a time-dependent coefficient that scales unsuper-\nvised components as training progresses, defined by:\n  \\l a mbda (t) = e^{-5(1 - t/t_{\\text {total}})}. \n(11)\n4. Experiments\n4.1. Experiment Datasets\nFundus dataset consists of retinal fundus images gathered\nfrom four medical centers, mainly intended for tasks involv-\ning the segmentation of the optic cup and disc. Each image\nhas been cropped to create a region of interest within an\n800×800 bounding box. We then resize and randomly crop\nthese images to a size of 256 × 256.\nProstate dataset includes prostate T2-weighted MRI data,\ncomplete with segmentation masks, sourced from six dif-\nferent locations across three public datasets. We randomly\n\ndivide the dataset into training and testing sets at a ratio of\n4:1, resizing and randomly cropping each 2D slice to 384\n× 384. Labeled samples are chosen from consecutive slices\nwithin individual cases, ensuring there is at most one case\noverlap and no overlap of slices with unlabeled samples.\n4.2. Comparison Methods and Settings\nOur method is implemented in PyTorch and utilizes an\nNVIDIA GeForce RTX 3090 GPU. We establish default\nexperimental parameters for training. Optimization is per-\nformed using the SAM optimizer, with a base optimizer of\nStochastic Gradient Descent (SGD) set to a momentum of\n0.9, a weight decay of 0.0001, and an initial learning rate of\n0.03. The batch size is set to 8, comprising 4 labeled and 4\nunlabeled samples. We conduct a total of 30,000 iterations\nfor the Fundus dataset and 60,000 iterations for the Prostate\ndataset.\nDuring testing, the final segmentation results are gener-\nated by the student model. Our approach is benchmarked\nagainst several state-of-the-art (SOTA) methods, including\nsupervised techniques such as UA-MT [42], FixMatch [31],\nCPS [5], CoraNet [29], SS-Net [40], BCP [2], CauSSL [23],\nand MiDSS [21], as well as domain-unsupervised adap-\ntation methods like FDA [41], SIFA [4], and UDA-\nVAE++ [17].\nIn each experiment, a limited amount of data from a des-\nignated domain (e.g., Domain 1 in Tab. 2) is labeled, while\nthe remaining data are treated as unlabeled. For the upper-\nbound comparison, we utilized the f-divergence, specifi-\ncally employing the Jensen-Shannon divergence to calcu-\nlate the distance between logits, and used the most naive\nSAM optimizer in our experiments. For the upper bound,\nwe followed the results of the MiDSS paper, which applied\nUCP within the FixMatch framework, utilizing all available\ntraining data from a specific domain as labeled data, provid-\ning the model with comprehensive source domain informa-\ntion.\nOur evaluation metrics include the Dice coefficient (DC),\nJaccard coefficient (JC), 95% Hausdorff Distance (HD), and\nAverage Surface Distance (ASD). Except for SIFA, which\nincorporates ResNet blocks [12] for its generator and de-\ncoder, all methods employ the U-Net backbone [24].\n4.3. Comparison with State-of-the-Art Methods\nResults on Fundus dataset. With only 20 labeled sam-\nples, DiM achieves superior performance across all domains\nin the optic cup/disc segmentation task, as illustrated in\nTable 2. DiM consistently outperforms competing meth-\nods in all metrics, which achieves the highest average DC\nand JC scores while maintaining the lowest HD and ASD,\nhighlighting its robustness and precision in segmenting dual\nobjects with overlapping regions.\nThese results suggest\nthat DiM effectively mitigates issues faced by other semi-\nsupervised and unsupervised domain adaptation methods,\nsuch as error accumulation and limited knowledge trans-\nfer, ensuring both high accuracy and generalizability across\nmultiple domains.\nResults on Prostate dataset.\nAs shown in Table 3,\nDiM achieves outstanding performance across all metrics\non Prostate dataset. It is also noteworthy that DiM achieves\nthe highest DC and JC averages while maintaining the low-\nest HD and ASD scores, suggesting higher segmentation\naccuracy and boundary precision. The inclusion of SAM\nlikely contributes to improved generalization by mitigating\nsharp minima, while f-divergence loss enhances alignment\nof the predicted and true distributions, reducing segmen-\ntation errors. These results underscore the robustness and\neffectiveness of our method.\n4.4. Ablation Study\nFirstly, We conduct ablation studies to show the impact of\neach component in DiM . Sencondly, our objective is to as-\nsess whether varying types of  f -divergences lead to notable\nperformance differences in the model and to identify the op-\ntimal form for superior outcomes.\nThe effectiveness of SAM. As demonstrated in Table 4, in-\ncorporating the Sharpness-Aware Minimization (SAM) op-\ntimizer (as seen in Method #2 and #4 compared to #1.)\nenhances model performance on the Optic Cup/Disc seg-\nmentation task. SAM effectively reduces the model’s loss,\nincreasing robustness to minor data distribution shifts and\nenabling more efficient capture of inter-sample similarity.\nConsequently, SAM improves the DC and JC scores while\nreducing the HD and ASD. These results indicate that SAM\nnot only strengthens the model’s generalization ability but\nalso enhances segmentation accuracy and boundary preci-\nsion.\nThe effectiveness of f-Divergence. The incorporation of\nf-divergence (as seen in Method #3 and #4 compared to\n#1.) contributes to notable improvements in model perfor-\nmance, particularly through a marked reduction in ASD and\nHD metrics, as shown in Table 4. By quantifying the dis-\ncrepancy between probability distributions of labeled and\nunlabeled data, f-divergence enhances the model’s capacity\nto represent features within the unlabeled dataset. Exper-\nimental results demonstrate that introducing f-divergence\nallows the model to more precisely capture the boundaries\nof structurally similar regions. This results in further gains\nin DC and JC metrics, along with substantial reductions in\nHD and ASD, thereby indicating improved accuracy in seg-\nmentation, especially along edge details.\nf-Divergence strategies. Based on the experimental re-\nsults shown in the Table 5, different f-divergence strate-\ngies demonstrate varying degrees of effectiveness for optic\ncup and disc segmentation across four domains in the Fun-\ndus dataset. Generally, the JS divergence and Jeffrey diver-\n\nTask\nOptic Cup / Disc Segmentation\nMethod\n#L\nDC ↑\nDC ↑\nJC ↑\nHD ↓\nASD ↓\nDomain 1\nDomain 2\nDomain 3\nDomain 4\nAvg.\nAvg.\nAvg.\nAvg.\nU-Net\n20\n59.54 / 73.89\n71.28 / 74.23\n50.87 / 64.29\n35.61 / 63.30\n61.63\n52.65\n48.28\n28.86\nUA-MT\nMICCAI’19\n20\n59.35 / 78.46\n63.08 / 74.45\n35.24 / 47.73\n36.18 / 55.43\n56.24\n47.00\n48.64\n31.35\nFDA\nCVPR’20\n20\n76.99 / 89.94\n77.69 / 89.63\n78.27 / 90.96\n64.52 / 74.29\n80.29\n71.05\n16.23\n8.44\nSIFA\nTMI’20\n20\n50.67 / 75.30\n64.44 / 80.69\n61.67 / 83.77\n55.07 / 70.67\n67.78\n54.77\n20.16\n10.93\nFixMatch\nNeurIPS’20\n20\n81.18 / 91.29\n72.04 / 87.60\n80.41 / 92.95\n74.58 / 87.07\n83.39\n73.48\n11.77\n5.60\nCPS\nCVPR’21\n20\n64.53 / 86.25\n70.26 / 86.97\n42.92 / 54.94\n36.98 / 46.70\n61.19\n52.69\n34.44\n26.79\nCoraNet\nTMI’21\n20\n61.64 / 87.32\n65.56 / 87.05\n66.12 / 83.54\n49.01 / 77.73\n72.25\n60.50\n20.52\n10.44\nUDA-VAE++\nCVPR’22\n20\n55.01 / 80.76\n68.87 / 85.94\n63.23 / 84.92\n68.42 / 80.89\n73.51\n61.40\n17.60\n9.86\nSS-Net\nMICCAI’22\n20\n59.42 / 78.15\n67.32 / 85.05\n45.69 / 69.91\n38.76 / 61.13\n63.18\n53.49\n44.90\n25.73\nBCP\nCVPR’23\n20\n71.65 / 91.10\n77.19 / 92.00\n72.63 / 90.77\n77.67 / 91.42\n83.05\n73.66\n11.05\n5.80\nCauSSL\nICCV’23\n20\n63.38 / 80.60\n67.52 / 80.72\n49.53 / 63.88\n39.43 / 49.43\n61.81\n51.80\n41.25\n23.94\nMiDSS\nCVPR’24\n20\n83.39 / 92.96\n73.12 / 88.88\n83.50 / 92.97\n78.63 / 93.38\n85.85\n76.95\n9.06\n4.40\nDiM\n20\n84.68 / 92.91\n78.16 / 90.49\n84.82 / 93.36\n81.63 / 92.18\n87.28\n78.53\n7.83\n3.82\nUpper bound\n*\n85.53 / 93.41\n80.55 / 90.90\n85.44 / 93.04\n85.61 / 93.21\n88.46\n80.35\n7.41\n3.70\nTable 2. Comparison of methods on the Fundus dataset. #L indicates the number of labeled samples. In the ”Upper bound” row, * denotes\nusing all training samples in a domain as labeled data. An upward arrow (↑) signifies that higher values indicate better performance, while\na downward arrow (↓) indicates the opposite. The best results are bolded, with the second-best underlined.\nTask\nProstate Segmentation\nMethod\n#L\nDC ↑\nDC ↑\nJC ↑\nHD ↓\nASD ↓\nRUNMC\nBMC\nHCRUDB\nUCL\nBIDMC\nHK\nAvg.\nAvg.\nAvg.\nAvg.\nU-Net\n40\n31.11\n35.07\n20.04\n38.18\n19.41\n26.62\n28.41\n23.24\n95.11\n65.84\nUA-MT\nMICCAI’19\n40\n29.44\n4.68\n12.49\n39.42\n17.94\n18.22\n20.37\n14.88\n112.07\n77.58\nFDA\nCVPR’20\n40\n47.44\n35.37\n24.54\n61.01\n28.19\n40.51\n39.51\n32.17\n76.67\n47.87\nSIFA\nTMI’20\n40\n72.67\n70.37\n64.08\n73.49\n71.62\n65.16\n69.57\n56.78\n29.43\n13.03\nFixMatch\nNeurIPS’20\n40\n83.58\n69.17\n73.63\n79.21\n56.07\n84.78\n74.41\n65.96\n24.18\n14.09\nCPS\nCVPR’21\n40\n29.83\n9.21\n11.84\n43.84\n13.51\n14.56\n20.47\n15.12\n115.96\n78.51\nCoraNet\nTMI’21\n40\n69.43\n31.16\n16.29\n69.33\n24.66\n22.16\n38.84\n31.48\n67.91\n44.98\nUDA-VAE++\nCVPR’22\n40\n68.73\n69.36\n65.49\n67.19\n63.29\n65.15\n66.54\n52.80\n34.20\n15.48\nSS-Net\nMICCAI’22\n40\n29.10\n13.49\n14.20\n51.96\n23.83\n13.23\n24.30\n18.74\n109.54\n71.13\nBCP\nCVPR’23\n40\n70.15\n71.97\n46.15\n58.93\n74.21\n67.47\n64.81\n55.17\n52.60\n27.22\nCauSSL\nICCV’23\n40\n24.10\n27.46\n16.94\n27.23\n15.28\n14.56\n20.93\n15.48\n114.62\n73.30\nMiDSS\nCVPR’24\n40\n87.94\n85.30\n77.74\n86.29\n88.54\n86.43\n85.37\n77.30\n13.44\n6.18\nDiM\n40\n88.43\n85.67\n87.56\n87.27\n88.23\n87.55\n87.45\n79.52\n10.57\n4.35\nUpper bound\n*\n88.52\n88.61\n85.71\n88.61\n88.98\n89.49\n88.32\n80.71\n10.05\n4.12\nTable 3. Comparison of different methods on Prostate dataset.\nTask\nOptic Cup / Disc Segmentation\nMethod\nBaseline\nSAM\nf-Divergence\nDC ↑\nJC ↑\nHD ↓\nASD ↓\n#1\n✓\n88.27\n80.02\n7.19\n3.48\n#2\n✓\n✓\n88.33\n80.22\n7.10\n3.52\n#3\n✓\n✓\n88.32\n80.14\n7.22\n3.47\n#4\n✓\n✓\n✓\n88.80\n80.74\n6.81\n3.27\nTable 4. Ablation experiments across domain 1 on Fundus\ndataset.\ngence strategies perform well, often yielding higher DC and\nJC while reducing HD and ASD. Specifically, JS divergence\ntends to provide more consistent results in edge cases, as ev-\nidenced by lower HD and ASD values, while also achieving\ncompetitive segmentation accuracy. Pearson divergence, on\nthe other hand, exhibits a balanced performance, particu-\nlarly excelling as the second-best in some metrics.\n4.5. Visualization Analysis\nDomain 1\nDomain 2\nDomain 3\nDomain 4\n(a) MiDSS\nDomain 1\nDomain 2\nDomain 3\nDomain 4\n(b) DiM\nFigure 1. A T-sne visualization analysis was performed on the\nFundus dataset experiment.\nT-SNE visualization. We adopt the T-SNE visualization\nmethod , which graphically represents the learning rep-\n\nTask\nOptic Cup / Disc Segmentation\nType\nDomain\nDC ↑\nJC ↑\nHD ↓\nASD ↓\nCup\nDisc\nCup\nDisc\nCup\nDisc\nCup\nDisc\nbaseline\nDomain 1\n83.38\n93.15\n72.68\n87.36\n8.28\n6.10\n4.01\n2.95\nJS\n84.68\n92.91\n74.51\n86.96\n7.63\n5.98\n3.56\n2.97\nJeffrey\n82.82\n92.57\n72.07\n86.45\n8.20\n6.21\n4.13\n3.20\nPearson\n83.54\n92.94\n73.15\n87.07\n7.91\n6.23\n3.94\n3.09\nbaseline\nDomain 2\n73.11\n88.88\n59.76\n80.78\n12.89\n13.69\n6.56\n6.11\nJS\n78.10\n89.32\n65.54\n81.28\n10.71\n13.72\n5.29\n6.21\nJeffrey\n78.16\n90.49\n65.44\n82.99\n9.62\n8.24\n4.83\n4.37\nPearson\n78.50\n90.07\n66.29\n82.41\n10.62\n10.67\n5.19\n5.11\nbaseline\nDomain 3\n83.49\n93.36\n72.77\n87.82\n8.06\n6.19\n3.89\n3.15\nJS\n84.82\n93.36\n74.66\n87.53\n7.56\n6.24\n3.62\n3.15\nJeffrey\n83.58\n93.12\n72.71\n87.40\n8.78\n6.23\n4.00\n3.17\nPearson\n83.03\n93.14\n72.02\n87.43\n9.08\n6.23\n4.20\n3.19\nbaseline\nDomain 4\n78.63\n93.56\n66.27\n88.16\n10.95\n6.28\n5.44\n3.06\nJS\n81.63\n92.18\n70.23\n85.87\n9.32\n8.01\n4.42\n3.87\nJeffrey\n79.24\n93.31\n66.86\n87.74\n10.48\n6.15\n5.00\n3.16\nPearson\n80.03\n93.12\n67.92\n87.43\n10.51\n6.31\n4.93\n3.28\nTable 5. Performance comparison of different f-divergence strategies across four domains on Fundus dataset. Metrics marked with ↑\nindicate that higher values imply better performance, while those with ↓suggest the opposite. The best performance results are\nhighlighted in bold, and the second-best are underlined.\nU-Net\nUA-MT\nSS-Net\nBCP\nCauSSL\nMiDSS\nDiM(Ours)\nGT\nU-Net\nUA-MT\nSS-Net\nBCP\nCauSSL\nMiDSS\nFigure 2. Visual comparison of segmentation results on Fundus dataset across different models. Red and green represent the Optical Cup\nand Disc, respectively. The first row shows segmentation results on test samples from the labeled domain (Domain 1), while the second\nrow presents results on test samples from a different domain (Domain 4).\nresentation obtained from our method, as shown in Fig-\nure. 1(a) and 1(b). DiM significantly improves the feature\nalignment between different domains compared to MiDSS,\nresulting in a tighter and more coherent data distribution.\nSegmentation visualization.\nAs shown in Figure 2 ,\nDiM achieves higher accuracy and better preservation of\nedge details in optic disc and cup segmentation tasks com-\npared to other methods. Models such as U-Net, UA-MT,\nand SS-Net show noticeable boundary blurring, with seg-\nmentation results that lack precision, particularly at the\nstructural boundaries of the optic disc and cup. These mod-\nels tend to either miss segments or over-segment certain re-\ngions. In contrast, our model produces clearer boundaries\nwith more precise edge detail retention, and the segmenta-\ntion within the optic disc and cup regions is more cohesive,\nclosely matching the ground truth (GT).\nWe also conducted visualization experiments on the\nprostate segmentation task in Figure 3.\nResults indicate\nthat DiM continues to outperform other methods, such as\nBCP, CauSSL, and MiDSS, by achieving clearer boundary\ndelineation and better edge detail preservation. The seg-\nmentation closely matches the GT, demonstrating improved\naccuracy and cohesion within the prostate region, even in\nchallenging boundary areas.\nModel Performance. The validation loss and Dice coeffi-\ncient curves across the four domains on the Fundus dataset\n\nU-Net\nUA-MT\nSS-Net\nBCP\nCauSSL\nMiDSS\n(DiM)Ours\nGT\nU-Net\nUA-MT\nSS-Net\nBCP\nCauSSL\nMiDSS\nFigure 3. Visual results on Prostate dataset.\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLoss\n(a) Domain 1 Loss\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLoss\n(b) Domain 2 Loss\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLoss\n(c) Domain 3 Loss\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLoss\n(d) Domain 4 Loss\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCup Dice\nDisc Dice\n(e) Domain 1 Dice\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCup Dice\nDisc Dice\n(f) Domain 2 Dice\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCup Dice\nDisc Dice\n(g) Domain 3 Dice\n0\n10\n20\n30\n40\n50\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCup Dice\nDisc Dice\n(h) Domain 4 Dice\nFigure 4. Validation Loss and Dice across four domains on Fundus dataset.\ndemonstrate stable model performance, which are depicted\nin Figure 5. Loss decreases rapidly in the early epochs and\nconverges across all domains, indicating effective training.\nDice scores for both the optic cup and disc steadily increase\nand plateau at high values, with the optic disc achieving\nnear-perfect accuracy.\n5. Conclusion\nThis study addresses the challenge of data annotation in\nmedical image segmentation by introducing a sharpness-\naware optimization method based on f-divergence min-\nimization (DiM) for semi-supervised learning.\nWhile\nexisting semi-supervised methods (SSMIS), including\nsharpness-aware optimization (SAM), have shown suc-\ncess, they often overlook distribution differences between\ndatasets. The proposed DiM method enhances model sta-\nbility by adjusting the sensitivity of model parameters and\nimproves adaptability to varying datasets. By reducing f-\ndivergence, DiM achieves a better balance in performance\nbetween source and target datasets and mitigates overfit-\nting. Experimental results demonstrate that DiM signifi-\ncantly improves performance, as evidenced by its ground-\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n200\n220\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLoss\nDomain 1\nLoss\n(a) Domain 1 Loss\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n200\n220\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nDice Score\nDomain 1\nDice\n(b) Domain 1 Dice\nFigure 5. Validation Loss and Dice for Domain 1 on the Prostate\ndataset.\nbreaking progress in Dice scores on the prostate dataset,\nwith similar success across three public datasets.\n\nReferences\n[1] Maksym Andriushchenko and Nicolas Flammarion. Towards\nunderstanding sharpness-aware minimization.\nIn ICML,\npages 639–668. PMLR, 2022. 3\n[2] Yunhao Bai, Duowen Chen, Qingli Li, Wei Shen, and Yan\nWang. Bidirectional copy-paste for semi-supervised medical\nimage segmentation. In CVPR, pages 11514–11524, 2023. 5\n[3] Gerda Bortsova, Florian Dubost, Laurens Hogeweg, Ioan-\nnis Katramados, and Marleen De Bruijne. Semi-supervised\nmedical image segmentation via learning consistency un-\nder transformations. In MICCAI, pages 810–818. Springer,\n2019. 1, 2\n[4] Cheng Chen, Qi Dou, Hao Chen, Jing Qin, and Pheng Ann\nHeng. Unsupervised bidirectional cross-modality adaptation\nvia deeply synergistic image and feature alignment for med-\nical image segmentation. TMI, 39(7):2494–2505, 2020. 5\n[5] Xiaokang Chen, Yuhui Yuan, Gang Zeng, and Jingdong\nWang. Semi-supervised semantic segmentation with cross\npseudo supervision. In CVPR, pages 2613–2622, 2021. 5\n[6] Dansong Cheng, Feng Tian, Lin Liu, Xiaofang Liu, and Ye\nJin. Image segmentation based on multi-region multi-scale\nlocal binary fitting and kullback–leibler divergence. Signal,\nImage and Video Processing, 12:895–903, 2018. 2\n[7] Sabyasachi Dash, Sushil Kumar Shakyawar, Mohit Sharma,\nand Sandeep Kaushik. Big data in healthcare: management,\nanalysis and future prospects. Journal of Big Data, 6(1):1–\n25, 2019. 1\n[8] Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam\nNeyshabur.\nSharpness-aware minimization for efficiently\nimproving generalization. arXiv preprint arXiv:2010.01412,\n2020. 1, 3\n[9] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain\nadaptation by backpropagation. In ICML, pages 1180–1189.\nPMLR, 2015. 2\n[10] Joumana Ghosn and Yoshua Bengio. Bias learning, knowl-\nedge sharing. TNN, 14(4):748–765, 2003. 2\n[11] Hao Guan and Mingxia Liu. Domain adaptation for medical\nimage analysis: a survey. IEEE Transactions on Biomedical\nEngineering, 69(3):1173–1185, 2021. 1\n[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep residual learning for image recognition.\nIn CVPR,\npages 770–778, 2016. 5\n[13] Xiaomeng Li, Hao Chen, Xiaojuan Qi, Qi Dou, Chi-Wing\nFu, and Pheng-Ann Heng. H-denseunet: hybrid densely con-\nnected unet for liver and tumor segmentation from ct vol-\numes. TMI, 37(12):2663–2674, 2018. 1\n[14] Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann\nHeng. Feddg: Federated domain generalization on medical\nimage segmentation via episodic learning in continuous fre-\nquency space. In CVPR, pages 1013–1023, 2021. 1\n[15] Xiaofeng Liu, Chaehwa Yoo, Fangxu Xing, Hyejin Oh,\nGeorges El Fakhri, Je-Won Kang, Jonghye Woo, et al. Deep\nunsupervised domain adaptation: A review of recent ad-\nvances and perspectives. APSIPA Transactions on Signal and\nInformation Processing, 11(1), 2022. 2\n[16] Mingsheng Long,\nZhangjie Cao,\nJianmin Wang,\nand\nMichael I Jordan. Conditional adversarial domain adapta-\ntion. NeurIPS, 31, 2018. 2\n[17] Changjie Lu, Shen Zheng, and Gaurav Gupta.\nUnsuper-\nvised domain adaptation for cardiac segmentation: Towards\nstructure mutual information maximization. In CVPR, pages\n2588–2597, 2022. 5\n[18] Liyun Lu, Mengxiao Yin, Liyao Fu, and Feng Yang.\nUncertainty-aware pseudo-label and consistency for semi-\nsupervised medical image segmentation. Biomedical Signal\nProcessing and Control, 79:104203, 2023. 2\n[19] Xiangde Luo, Jieneng Chen, Tao Song, and Guotai Wang.\nSemi-supervised medical image segmentation through dual-\ntask consistency. In AAAI, pages 8801–8809, 2021. 2\n[20] Xiangde Luo, Minhao Hu, Tao Song, Guotai Wang, and\nShaoting Zhang. Semi-supervised medical image segmen-\ntation via cross teaching between cnn and transformer. In In-\nternational conference on medical imaging with deep learn-\ning, pages 820–833. PMLR, 2022. 2\n[21] Qinghe Ma, Jian Zhang, Lei Qi, Qian Yu, Yinghuan Shi, and\nYang Gao. Constructing and exploring intermediate domains\nin mixed domain semi-supervised medical image segmenta-\ntion. In CVPR, pages 11642–11651, 2024. 1, 5\n[22] Qinghe Ma, Jian Zhang, Lei Qi, Qian Yu, Yinghuan Shi, and\nYang Gao. Constructing and exploring intermediate domains\nin mixed domain semi-supervised medical image segmenta-\ntion. In CVPR, pages 11642–11651, 2024. 2\n[23] Juzheng Miao, Cheng Chen, Furui Liu, Hao Wei, and Pheng-\nAnn Heng.\nCaussl:\nCausality-inspired semi-supervised\nlearning for medical image segmentation. In ICCV, pages\n21426–21437, 2023. 1, 2, 5\n[24] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net:\nConvolutional networks for biomedical image segmentation.\nIn MICCAI, pages 234–241. Springer, 2015. 1, 5\n[25] Vivek A Rudrapatna, Atul J Butte, et al. Opportunities and\nchallenges in using real-world data for health care. The Jour-\nnal of Clinical Investigation, 130(2):565–574, 2020. 1\n[26] Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Trevor Darrell,\nand Kate Saenko. Semi-supervised domain adaptation via\nminimax entropy. In ICCV, pages 8050–8058, 2019. 2\n[27] Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate\nSaenko. Strong-weak distribution alignment for adaptive ob-\nject detection. In CVPR, pages 6956–6965, 2019. 2\n[28] Swami Sankaranarayanan,\nYogesh Balaji,\nArpit Jain,\nSer Nam Lim, and Rama Chellappa. Learning from synthetic\ndata: Addressing domain shift for semantic segmentation. In\nCVPR, pages 3752–3761, 2018. 2\n[29] Yinghuan Shi, Jian Zhang, Tong Ling, Jiwen Lu, Yefeng\nZheng, Qian Yu, Lei Qi, and Yang Gao. Inconsistency-aware\nuncertainty estimation for semi-supervised medical image\nsegmentation. TMI, 41(3):608–620, 2021. 5\n[30] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon.\nA dirt-t approach to unsupervised domain adaptation. arXiv\npreprint arXiv:1802.08735, 2018. 2\n[31] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao\nZhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk,\nAlexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying\n\nsemi-supervised learning with consistency and confidence.\nNeurIPS, 33:596–608, 2020. 5\n[32] Tim Van Erven and Peter Harremos. R´enyi divergence and\nkullback-leibler divergence. IEEE Transactions on Informa-\ntion Theory, 60(7):3797–3820, 2014. 2\n[33] Kaiping Wang, Bo Zhan, Chen Zu, Xi Wu, Jiliu Zhou, Lup-\ning Zhou, and Yan Wang. Semi-supervised medical image\nsegmentation via a tripled-uncertainty guided mean teacher\nmodel with contrastive learning. Medical Image Analysis,\n79:102447, 2022. 1\n[34] Mei Wang and Weihong Deng. Deep visual domain adapta-\ntion: A survey. Neurocomputing, 312:135–153, 2018. 2\n[35] Qin Wang, Wen Li, and Luc Van Gool.\nSemi-supervised\nlearning by augmented distribution alignment.\nIn ICCV,\npages 1466–1475, 2019. 1\n[36] Xin Wang, Xiaoyu Liu, Peng Huang, Pu Huang, Shu\nHu, and Hongtu Zhu.\nU-medsam:\nUncertainty-aware\nmedsam for medical image segmentation.\narXiv preprint\narXiv:2408.08881, 2024. 3\n[37] Yiqing Wang, Zihan Li, Jieru Mei, Zihao Wei, Li Liu, Chen\nWang, Shengtian Sang, Alan L Yuille, Cihang Xie, and\nYuyin Zhou. Swinmm: masked multi-view with swin trans-\nformers for 3d medical image segmentation.\nIn MICCAI,\npages 486–496, 2023. 2\n[38] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A\nsurvey of transfer learning. Journal of Big Data, 3:1–40,\n2016. 2\n[39] Yicheng Wu, Zongyuan Ge, Donghao Zhang, Minfeng Xu,\nLei Zhang, Yong Xia, and Jianfei Cai. Mutual consistency\nlearning for semi-supervised medical image segmentation.\nMedical Image Analysis, 81:102530, 2022. 2\n[40] Yicheng Wu, Zhonghua Wu, Qianyi Wu, Zongyuan Ge, and\nJianfei Cai. Exploring smoothness and class-separation for\nsemi-supervised medical image segmentation. In MICCAI,\npages 34–43. Springer, 2022. 5\n[41] Yanchao Yang and Stefano Soatto.\nFda: Fourier domain\nadaptation for semantic segmentation.\nIn CVPR, pages\n4085–4095, 2020. 5\n[42] Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, and\nPheng-Ann Heng. Uncertainty-aware self-ensembling model\nfor semi-supervised 3d left atrium segmentation. In MICCAI,\npages 605–613. Springer, 2019. 5\n[43] Yifan Zhang,\nYing Wei,\nQingyao Wu,\nPeilin Zhao,\nShuaicheng Niu, Junzhou Huang, and Mingkui Tan. Collab-\norative unsupervised domain adaptation for medical image\ndiagnosis. TIP, 29:7834–7844, 2020. 1\n[44] Ziyuan Zhao, Fangcheng Zhou, Kaixin Xu, Zeng Zeng, Cun-\ntai Guan, and S Kevin Zhou. Le-uda: Label-efficient unsu-\npervised domain adaptation for medical image segmentation.\nTMI, 42(3):633–646, 2022. 1\n[45] Yixuan Zhou, Yi Qu, Xing Xu, and Hengtao Shen. Imb-\nsam:\nA closer look at sharpness-aware minimization in\nclass-imbalanced recognition. In ICCV, pages 11345–11355,\n2023. 3\n[46] Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima\nTajbakhsh, and Jianming Liang. Unet++: Redesigning skip\nconnections to exploit multiscale features in image segmen-\ntation. TMI, 39(6):1856–1867, 2019. 1\n[47] Zhi-Hua Zhou. A brief introduction to weakly supervised\nlearning. National Science Review, 5(1):44–53, 2018. 1\n[48] Juntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui,\nHartwig Adam, Nicha Dvornek, Sekhar Tatikonda, James\nDuncan, and Ting Liu. Surrogate gap minimization improves\nsharpness-aware training. arXiv preprint arXiv:2203.08065,\n2022. 2\n[49] Xiahai Zhuang et al. Challenges and methodologies of fully\nautomatic whole heart segmentation: a review. Journal of\nHealthcare Engineering, 4:371–407, 2013. 2",
    "pdf_filename": "DiM_$f$-Divergence_Minimization_Guided_Sharpness-Aware_Optimization_for_Semi-supervised_Medical_Imag.pdf"
}