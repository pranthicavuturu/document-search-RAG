{
    "title": "Structured Low-Rank Algorithms - Theory, MR Applications, and Links to  Machine Learning",
    "context": "In this survey, we provide a detailed review of recent advances in the recovery of continuous domain multidimen- sional signals from their few non-uniform (multichannel) measurements using structured low-rank matrix completion formulation. This framework is centered on the fundamental duality between the compactness (e.g., sparsity) of the continuous signal and the rank of a structured matrix, whose entries are functions of the signal. This property enables the reformulation of the signal recovery as a low-rank structured matrix completion, which comes with performance guarantees. We will also review fast algorithms that are comparable in complexity to current compressed sensing methods, which enables the application of the framework to large-scale magnetic resonance (MR) recovery problems. The remarkable ﬂexibility of the formulation can be used to exploit signal properties that are difﬁcult to capture by current sparse and low-rank optimization strategies. We demonstrate the utility of the framework in a wide range of MR imaging (MRI) applications, including highly accelerated imaging, calibration-free acquisition, MR artifact correction, and ungated dynamic MRI. Index Terms Compressed sensing, matrix completion, accelerated MRI, structured low-rank matrix The slow nature of signal acquisition in magnetic resonance imaging (MRI), where the image is formed from a sequence of Fourier samples, often restricts the achievable spatial and temporal resolution in multi-dimensional static and dynamic imaging applications. Discrete compressed sensing (CS) methods provided a major breakthrough to accelerate the magnetic resonance (MR) signal acquisition by reducing the sampling burden. As described in an introductory article in this special issue [1] these algorithms exploited the sparsity of the discrete signal in a transform domain to recover the images from a few measurements. In this paper, we review a continuous domain extension of CS using a structured low-rank (SLR) framework for the recovery of an image or a series of images from a few measurements using various compactness assumptions [2]–[22]. The general strategy of the SLR framework starts with deﬁning a lifting operation to construct a structured matrix, whose entries are functions of the signal samples. The SLR algorithms exploit the dual relationships between the signal compactness properties (e.g. sparsity, smoothness) and the rank of the lifted matrix. This dual relationship allows recovery of the signal from a few samples in the measurement domain as an SLR optimization problem. MJ and MM are with the University of Iowa, Iowa City, IA 52242 (e-mails: mathews-jacob@uiowa.edu,merry-mani@uiowa.edu). JCY is with the Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea (e-mail: jong.ye@kaist.ac.kr). Corresponding author: Jong Chul Ye, Dept. of Bio and Brain Engineering, Korea Advanced Inst. of Science & Technology (KAIST) 291 Daehak-ro, Yuseong-gu, Daejeon 34141 Republic of Korea, Email: jong.ye@kaist.ac.kr October 12, 2021 DRAFT arXiv:1910.12162v1  [cs.CV]  27 Oct 2019",
    "body": "1\nStructured Low-Rank Algorithms: Theory, MR\nApplications, and Links to Machine Learning\nMathews Jacob, Senior Member, IEEE, Merry P. Mani, and Jong Chul Ye, Senior Member, IEEE\nAbstract\nIn this survey, we provide a detailed review of recent advances in the recovery of continuous domain multidimen-\nsional signals from their few non-uniform (multichannel) measurements using structured low-rank matrix completion\nformulation. This framework is centered on the fundamental duality between the compactness (e.g., sparsity) of the\ncontinuous signal and the rank of a structured matrix, whose entries are functions of the signal. This property enables\nthe reformulation of the signal recovery as a low-rank structured matrix completion, which comes with performance\nguarantees. We will also review fast algorithms that are comparable in complexity to current compressed sensing\nmethods, which enables the application of the framework to large-scale magnetic resonance (MR) recovery problems.\nThe remarkable ﬂexibility of the formulation can be used to exploit signal properties that are difﬁcult to capture by\ncurrent sparse and low-rank optimization strategies. We demonstrate the utility of the framework in a wide range\nof MR imaging (MRI) applications, including highly accelerated imaging, calibration-free acquisition, MR artifact\ncorrection, and ungated dynamic MRI.\nIndex Terms\nCompressed sensing, matrix completion, accelerated MRI, structured low-rank matrix\nI. INTRODUCTION\nThe slow nature of signal acquisition in magnetic resonance imaging (MRI), where the image is formed from\na sequence of Fourier samples, often restricts the achievable spatial and temporal resolution in multi-dimensional\nstatic and dynamic imaging applications. Discrete compressed sensing (CS) methods provided a major breakthrough\nto accelerate the magnetic resonance (MR) signal acquisition by reducing the sampling burden. As described in\nan introductory article in this special issue [1] these algorithms exploited the sparsity of the discrete signal in a\ntransform domain to recover the images from a few measurements.\nIn this paper, we review a continuous domain extension of CS using a structured low-rank (SLR) framework for\nthe recovery of an image or a series of images from a few measurements using various compactness assumptions\n[2]–[22]. The general strategy of the SLR framework starts with deﬁning a lifting operation to construct a structured\nmatrix, whose entries are functions of the signal samples. The SLR algorithms exploit the dual relationships between\nthe signal compactness properties (e.g. sparsity, smoothness) and the rank of the lifted matrix. This dual relationship\nallows recovery of the signal from a few samples in the measurement domain as an SLR optimization problem.\nMJ and MM are with the University of Iowa, Iowa City, IA 52242 (e-mails: mathews-jacob@uiowa.edu,merry-mani@uiowa.edu). JCY is\nwith the Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic\nof Korea (e-mail: jong.ye@kaist.ac.kr).\nCorresponding author: Jong Chul Ye, Dept. of Bio and Brain Engineering, Korea Advanced Inst. of Science & Technology (KAIST) 291\nDaehak-ro, Yuseong-gu, Daejeon 34141 Republic of Korea, Email: jong.ye@kaist.ac.kr\nOctober 12, 2021\nDRAFT\narXiv:1910.12162v1  [cs.CV]  27 Oct 2019\n\n2\nWhile this strategy may seem contrived, the main beneﬁt of this framework is its remarkable ﬂexibility in exploiting\nthe compactness properties of a variety of signal structures, including continuous-domain real-world signals that\nclassical approaches have difﬁculty capturing. For example, SLR approaches can recover continuous domain images\nfrom a few Fourier measurements with minimal discretization errors, unlike compressed sensing approaches. The\nSLR methods can account for signals with an inﬁnite number of signal discontinuities that are localized to a\ncurve/surface, which is more general than signals with a ﬁnite number of isolated signal discontinuities considered\nin recent super-resolution methods [23]. In addition, the SLR schemes come with fast algorithms that are readily\napplicable to large-scale imaging applications such as static and dynamic MRI, unlike super-resolution methods\n[23] that rely on semi-deﬁnite programming. Another example of SLR methods is the recovery of images from\ntheir multichannel measurements with unknown sensitivities [5], [9], [13], [18]. These schemes rely on the low-rank\nstructure of a structured matrix, obtained by concatenating block Hankel matrices, which are obtained from each\nchannel image. It is difﬁcult for classical convex compressed sensing algorithms to exploit such complex relations\nbetween multichannel measurements. The SLR schemes have also been recently extended to recover an ensemble\nof images that lie on a smooth surface in high-dimensional space. Current subspace model or a union of subspace\nmodel is not efﬁcient in capturing the above property; inspired by kernel methods [24], one can deﬁne a non-linear\nmapping that will transform the smooth surface to a subspace. In SLR approaches, this structure can be exploited\nby the construction of a structured matrix, whose columns are non-linearly transformed signal samples.\nThe SLR framework is closely related to the extensive work on linear prediction in MRI, which was often\nformulated using structure low-rank matrix [2]–[4], [6], [7]. Early work in the context of MRI dates back to 1985\nin the context of MR spectroscopy [2], followed by its generalization to MRI by modeling the images as piecewise\n1D polynomials by Liang et al. [3]. The ﬁnite rate of innovation (FRI) theory [25] also considers the recovery of\npiecewise polynomials and similar models from a ﬁnite number of samples. Multichannel linear predictive relations\nwere introduced in the parallel MRI context in [4], [6], while linear-predictive k-space relations resulting from\nsupport and phase constraints were introduced in [7]. The readers are referred to [22] in the same special issue,\nwhich is focused on a more elaborate review of linear prediction approaches and their history in the MRI context.\nWe will review recent development in the low-rank structured matrix approaches for MRI.\n1) The early 1-D approaches [3], [25] are generalized to multidimensional continuous domain signals [7], [9],\n[10]. Theoretical guarantees are also available for multidimensional signals, whose discontinuities are localized\nto sets of inﬁnite size, but of zero Lebesgue measure (e.g., curves in 2D and surfaces in 3D) [10].\n2) Low-rank matrix recovery algorithms with recovery guarantees are used to recover signals from nonuniform\nmeasurements [7], [9], [15], as opposed to the explicit annihilating ﬁlter estimation from the uniform sampling\nsetting in the classical FRI [3], [25]. Note that an earlier work in this respect goes back to the work by Dologlou\net al [26].\n3) The framework is generalized to the recovery of signals from non-uniform multichannel measurements with\nunknown channel responses, facilitating the reduction in samples and calibration-free recovery in a uniﬁed\nmatrix completion framework [5], [6], [9], [13], [18].\nOctober 12, 2021\nDRAFT\n\n3\nLift\nUnlift\nStructured Low-rank \nMatrix Completion\nUndersampled \nFourier samples\nRecovered \nFourier samples\n(a) SLR interpolation\nLift\nUnlift\nNull-space\nLowpass \nFourier samples\nExtrapolated \nFourier samples\n(b) SLR extrapolation\nFig. 1. Illustration of SLR-based interpolation and extrapolation methods in the context of 1-D FRI. (a) In SLR interpolation, the data is acquired\non a non-uniformly sub-sampled Fourier grid. The SLR interpolation scheme relies on a lifting of the signal samples to a Hankel matrix, which\nhas missing entries indicated by the hashed boxes. The one-to-one relation between the rank of a matrix and the continuous domain sparsity of\nthe space domain signal is used to pose the recovery of missing samples as a structured low-rank matrix completion (SLRMC) problem in the\nlifted matrix domain. Speciﬁcally, the algorithm determines the matrix with the lowest rank that satisﬁes the Hankel structure and is consistent\nwith the known matrix entries. Post-recovery, the matrix is unlifted to obtain the Fourier samples of the signal. (b) In SLR extrapolation\nproblems, the low-frequency Fourier coefﬁcients of the signal are uniformly sampled. The central fully known matrix region is used to estimate\nthe null space of the matrix, which is used to linear-predict/extrapolate the missing high-frequency samples. The SLR algorithms that exploit\nthe different signal structures differ only in the structure of the lifted matrix; the algorithms are essentially the same.\n4) The non-linear generalization of FRI theory enables the recovery of points on smooth surfaces in high-\ndimensional spaces, which facilitates the joint reconstruction of an ensemble of images from their few\nmeasurements [21].\n5) The main practical beneﬁt of SLR schemes is their ability to capture a broad range of signal priors, resulting\nin a wide range of applications, including static MRI [5], [7], [9], [15], [16], dynamic MRI, diffusion MRI\n[18], MR artifact correction [17], parallel MRI [5], [6], [9], multi-contrast image recovery [19], spectroscopic\nimaging [11], [27], and ﬁeld inhomogeneity compensation [28], [29].\nThe above generalizations come with theoretical recovery guarantees [14], [16], and fast algorithms [9], [15]. In\naddition, this framework provides rich insights in the deep links between 1-D FRI sampling theory [25], CS [30],\nlow-rank matrix completion, and super-resolution theory [23].\nII. OVERVIEW\nA. Image acquisition in MRI\nIn this section, we will brieﬂy describe the image formation in MRI and introduce notations and terminologies\nused throughout the paper.\n1) Single-channel MRI measurements: The image acquisition in MRI constitutes the sampling of the Fourier\ntransform of the image f(x). The measurements in the Fourier domain (also referred to as k-space) are denoted by\n̂f(k) = [Ff](k) ∶= ∫f(x)e−i 2πkT xdx.\n(1)\nHere, x ∈Rd,d = 2,⋯,4 and k ∈Zd denote the image domain and k-space coordinates, respectively. The goal of\nMR image recovery is then to reconstruct f(x) from the above measurements, which are measured on a sparse\nsubset of the Fourier domain.\nOctober 12, 2021\nDRAFT\n\n4\n2) Multichannel measurements : Modern scanners acquire the Fourier domain data using multiple receive\ncoils to accelerate the acquisition. These receive coils have different spatial sensitivity patterns, thus providing\ncomplementary information. The measurement from the i-th coil is the Fourier transform of the coil-sensitivity\nweighted image and is denoted by\n̂fi(k) = [Ffi](k),\nwhere fi(x) = si(x)f(x); i = 1,⋯,Nc.\n(2)\nHere, si(x) denotes coil sensitivities, fi(x) denotes the coil-sensitivity weighted image, and Nc is the number of\nreceive coils. The goal of parallel MR image (pMRI) recovery is then to reconstruct f(x) from a few measurements\nwith or without the knowledge of the coil sensitivities.\nWhile the term multichannel measurements typically implies the multi-coil measurements described above, we\nwill use the term in a broader sense. As discussed later, different k-space regions are often acquired with slightly\ndifferent acquisition conditions in MRI. The distortions can often be modeled as spatial weighting terms, similar to\ncoil sensitivities. For example, the signals corresponding to the odd-only and the even-only lines of k-space often\ndiffer in phase errors; we consider it a two-channel acquisition with unknown spatial weighting terms.\nB. Structured Low-Rank methods: Bird’s-eye view\nThe SLR framework offers a versatile toolbox that exploits a variety of properties of continuous domain multi-\nchannel signals without the need for discretization. The SLR algorithms rely on a lifting of the original signal to a\nmatrix (see Fig. 1); the structure of the matrix depends on the speciﬁc signal properties (e.g., continuous domain\nsparsity, multichannel relations). The framework relies on the duality relations between the compactness of the\nsignal (e.g., sparsity) and the rank of the lifted matrix.\nInterpolation via structured low-rank matrix completion: In several accelerated MRI acquisitions, the measure-\nments from the full k-space locations are not available. When the signal samples are acquired in a non-uniform\nfashion, one can rely on a structured low-rank matrix completion to interpolate the missing entries in the lifted\nmatrix. Speciﬁcally, this entails determining a matrix with the lowest rank that preserves the structure of the lifted\nmatrix and is consistent with the measured matrix entries. Once the matrix is completed, one can perform inverse\nlifting to recover the samples of the continuous domain signal (see Fig. 1.(a)). We term this class of methods as\ninterpolation schemes [5], [7], [9], [15].\nExtrapolation using two-step SLR algorithms : In some applications, a certain limited region of k-space is acquired\nwithout any under-sampling (usually referred to as the calibration region, typically in the low-frequency regions).\nThe super-resolution approaches in signal processing [23] aim to extrapolate these Fourier coefﬁcients to high-\nfrequency regions, thus recovering the images at higher resolution. The SLR extrapolation strategy is to estimate\nthe null space of the lifted matrix from the fully sampled rows (indicated by the red boxes in Fig. 1.(b)). Given\nthe null space ﬁlters, one can (i) estimate a signal model based on the roots of the null-space ﬁlters, followed\nby linear estimation of the unknown signal model parameters, or (ii) perform linear prediction to extrapolate the\nhigh-frequency samples from the measured ones subject to the null-space constraints [3], [4], [10].\nOctober 12, 2021\nDRAFT\n\n5\nIII. SIGNAL EXTRAPOLATION USING SLR\nWe will now focus on speciﬁc continuous domain signal models and reveal their connection to the lifted matrices\nthat facilitates the recovery of the continuous domain signal. In this section, we will focus on SLR extrapolation\nwhere the low-frequency Fourier region is fully sampled as in Fig. 1.(b).\nA. FRI theory for piecewise smooth 1D signals\nThis approach [2], [3], [25] is a generalization of Prony’s method to continuous domain 1-D signals. Consider\nthe recovery of r-stream of Diracs f (see Fig. 2.(a)) at locations xj,j = 1,..,r with weights wj:\nf(x) =\nr\n∑\nj=1\nwj δ (x −xj) ,\nxj ∈[0,1].\n(3)\nThe discrete Fourier transform of the above continuous domain signal is a linear combination of complex expo-\nnentials with frequencies αj = e−i2πxj, speciﬁed by\n̂f[k] =\nr\n∑\nj=1\nwj (αj)k,\n∀k .\n(4)\nThe classical Prony’s results [25] rely on the annihilation of such exponential signals by\n̂h(z) =\nr\n∏\nj=1\n(1 −αjz−1)\n=\nr\n∑\nn=0\nh[n]z−n,\n(5)\nsuch that the associated (r + 1)-tap ﬁlter ̂h[n] annihilates the Fourier samples ̂f:\n(h ∗̂f)[k]\n=\n0,\n∀k\n(6)\nThis linear convolution relation (6) can be re-expressed in the matrix form (see Fig. 1) to solve for ̂h:\n⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣\n̂f[0]\n̂f[1]\n⋯\n̂f[r]\n̂f[1]\n̂f[2]\n⋯\n̂f[r + 1]\n⋮\n⋮\n⋱\n⋮\n̂f[r −1]\n...\n⋯\n̂f[2r −1]\n⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦\n´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶\nH[2r]\n[r+1]( ̂\nf)\n⎡⎢⎢⎢⎢⎢⎢⎢⎢⎣\nh[r]\n⋮\nh[0]\n⎤⎥⎥⎥⎥⎥⎥⎥⎥⎦\n´¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¶\nh\n= 0 .\n(7)\nHere, the notation H[2r]\n[r+1]( ̂f) represents the linear convolution matrix, which is deﬁned for the 2r samples of ̂f\nto be convolved with a ﬁlter of size r + 1; here [r] denotes the set 0,1,..,r. Note that H[2r]\n[r+1]( ̂f) is a Hankel\nstructured matrix and that the matrix lifting thus originates from the linear convolution embedded in (6)-(7) and is\nillustrated in Fig. 1. The relation (7) can be used to identify h. Once this linear-prediction ﬁlter h is available, the\nlinear predictive relations (6) can be used to extrapolate the signal samples ̂f[k];k = 0,..,2r −1 to any extent in\nFourier space.\n1) Theoretical Guarantees: Based on (7), the ﬁlter h can be estimated as a null-space vector of the lifted matrix\nas shown in Fig. 1(b). If 2r signal consecutive samples are available, the null-space vector is unique [3], [25].\nOctober 12, 2021\nDRAFT\n\n6\nmultiplication\nannihilating function\nannihilating filter\nconvolution\nbh\nh\nFourier \ndomain\nSpatial \ndomain\nF\n(a) 1-D FRI scheme\nmultiplication\nbh\nbf[k]\nannihilating filter\nconvolution\nh\nf(x)\nk\nFourier domain\nSpatial domain\nF\n(b) Extension of FRI to 2D\nFig. 2. Illustration of 1-D and 2-D FRI relations. (a) We illustrate Prony’s results in the light blue box, which demonstrates the recovery of\nDiracs at arbitrary locations. The Fourier coefﬁcients of this signal consist of complex exponentials denoted by yk in the bottom row. Prony’s\nresults show that complex exponentials can be annihilated by the convolution with a ﬁlter h. This Fourier domain convolution relation can\nalso be viewed as a multiplication-based annihilation relation in the space domain. These results can be extended to the recovery of piecewise\nconstant 1-D signals by considering the derivative. Speciﬁcally, the derivative of piecewise constant signals consists of a linear combination of\nDiracs, which brings the problem to Prony’s setting. (b). Extension of 1-D FRI to the 2-D setting. The gradient of the piecewise constant signal\nconsists of a series of Diracs supported on curves and the location of image edges. We observe that the gradient can be annihilated by the\nmultiplication by a function ˆh, whose zeros overlap with the image edges. If the ˆh is bandlimited, the convolution with the Fourier coefﬁcients\nof the image with the ﬁlter coefﬁcients will also be zero. We generalize the notion of 1-D sparsity in FRI with the bandwidth of ˆh; a more\nbandlimited ˆh will correspond to smoother curves, as shown in [10]. The above framework can be used to recover continuous domain piecewise\nconstant images, whose edges are localized to bandlimited zero-measure curves of inﬁnite support. This simple piecewise constant model is\nextended to more general piecewise smooth models in [20].\nNote from (5) that the roots/zeros of ̂h(z) will specify αj in (4). One can then solve a system of equations with r\nunknowns to recover the wj in (3); this estimation is unique with 2r measurements.\n2) Spatial annihilation relations: The above results can be generalized to recover piecewise constant signal f\n(see Fig. 2.(a)), with r discontinuities located at tj;j = 1,..,r. The derivative of the signal, denoted by ∂f, is a\nperiodic stream of Diracs as in (3). The above theory can be adapted to this setting by considering the Fourier\ncoefﬁcients of the derivative of f(x) as illustrated in Fig. 2(a). The Fourier domain convolution based annihilation\nrelations can also be viewed as space domain multiplication-based annihilation relation\n∂f(x) ⋅ˆh(x) = 0\n(8)\nas shown in Fig. 2(a). Here, the space domain function ˆh(x) is the Fourier transform of the ﬁlter h[n] that\nannihilates the Fourier coefﬁcients of f. The zeros of ̂h overlap with the location of Diracs or the location of the\ndiscontinuities of the piecewise constant signal [3]. We will now use this spatial domain annihilation relations to\nextend the 1-D results to higher dimensions.\nB. Piecewise smooth signals in higher dimensions\nWe now review how to extend the classical 1-D FRI theory to recover the piecewise constant images f(x) shown\nin Fig. 2(b). We assume that the Fourier samples are available in a rectangular region Γ ⊂Z2 [10]. Note that the\nedges of f consist of a set of curves, denoted by C. Extending the space domain annihilation relation in (8), we\nassume the edge locations of the image to be represented by the zero level-sets of a 2-D bandlimited function ̂h\n[10] :\nC = {x ∣̂h(x) = 0}\n(9)\nOctober 12, 2021\nDRAFT\n\n7\nwhere\n̂h(x) = ∑\nk∈Λ\nh[k] exp(ikT x)\n(10)\nis bandlimited to a rectangular region Λ ⊂Z2. The bandwidth of ̂h, denoted by ∣Λ∣, is a measure of the complexity\nof the edge set [10], [31], which generalizes the notion of sparsity in compressive sensing.\nSimilar to (8), we have space domain annihilation relation (see Fig. 2(b)) speciﬁed by ∇f ⋅̂h = 0; the Fourier\ntransform of this relation provides the 2-D Fourier domain annihilation relations similar to (6):\n∑\nk∈Λ\n̂\n∇f[ℓ−k] h[k] = 0,\n∀ℓ∈Γ ⊖Λ.\n(11)\nHere, Γ is the set of Fourier measurements of f. Note that the convolution of ̂\n∇f with h at a location k requires\nthe samples of ̂\n∇f within the set k + Λ, where the addition amounts to the translation of the set Λ to the location\nk. Since we only have the Fourier samples of f within Γ, the convolutions speciﬁed by (6) can only be evaluated\nwithin the set Γ⊖Λ, which is the morphological erosion of the set Γ by Λ. Similar to (7), the convolution relation\nin (11) can be rewritten in the matrix form similar to (7) as\n⎡⎢⎢⎢⎢⎢⎣\nHΓ\nΛ(iωx ̂f)\nHΓ\nΛ(iωy ̂f)\n⎤⎥⎥⎥⎥⎥⎦\n´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶\nVΓ\nΛ( ̂\nf)\nh = 0,\n(12)\nwhere h represents the vectorized ﬁlter coefﬁcients. Here, HΓ\nΛ(iωx ̂f) is the matrix corresponding to the 2-D\nconvolution of iωx ̂f, and VΓ\nΛ ( ̂f) is a composite matrix obtained by stacking the block Hankel matrices vertically\nas shown in Fig. 3.(a).\n1) Theoretical Guarantees: The ﬁlter h, and equivalently the edges of f can be estimated from (12) as the\nnull-space vector of VΓ\nΛ ( ̂f). It is shown in [10, Theorem 1] that VΓ\nΛ( ̂f) will have a unique null-space vector when\nthe uniform Fourier samples of ̂f are available within 3Λ, which is the three-fold dilation of Λ. The piecewise\nconstant signal will then be uniquely identiﬁed from its Fourier measurements within 3Λ [10, Theorem 4].\nNote that the piecewise constant signal model in this section assumes a ﬁnite or inﬁnite number of signal\ndiscontinuities, supported on a set of zero measure. This framework is more general than [23], which assumes a\nﬁnite number of isolated discontinuities. We note that even more general continuous domain models [7], which\nassume the signal support to be a region of non-zero measure, do exist. Since such models have inﬁnite degrees of\nfreedom, it is difﬁcult to guarantee the recovery of such a signal from ﬁnite measurements.\nC. Exponential 1-D signals\nRecovery of exponentially decaying signals are of interest in MRI since the temporal evolution of MRI signals\nin the presence of chemical shifts, ﬁeld inhomogeneity and multiple relaxation mechanisms can be modeled as a\nlinear combination of exponentials [2], [11], [27]. Speciﬁcally, the 1-D exponential signal at the spatial location x\nevolving as a function of time can be expressed as\nOctober 12, 2021\nDRAFT\n\n8\nkx bf[k]\nky bf[k]\nVΓ\n⇤(f)\nbf[k]\nΓ\n⇤\n⇤\nHΓ\n⇤(f1)\nHΓ\n⇤(f2)\nHΓ\n⇤(f3)\nbf1\nbf2\nbf3\nLΓ\n⇤(f1, f2, f3)\n(a) Vertical Stacking\nkx bf[k]\nky bf[k]\nVΓ\n⇤(f)\nbf[k]\nΓ\n⇤\n⇤\nHΓ\n⇤(f1)\nHΓ\n⇤(f2)\nHΓ\n⇤(f3)\nbf1\nbf2\nbf3\nLΓ\n⇤(f1, f2, f3)\n(b) Linear Stacking\nFig. 3. Illustration of the matrix lifting operations in 2-D. (a). Vertical stacking of block Hankel matrices in (12), which is the matrix form of\nthe convolutional relations in (11). The block Hankel matrices HΓ\nΛ(iωx ˆf) are constructed from the Fourier coefﬁcients of iωx ˆf. Each row of\nHΓ\nΛ(iωx ˆf) corresponds to a patch of size Λ, drawn from the the Fourier coefﬁcients supported in Γ. The number of valid shifts of Λ within\nΓ is denoted by Γ ⊖Λ in (11). (b) Linear stacking of block Hankel matrices in (22). The block Hankel matrices of the different channels fi\nare concatenated in a linear fashion to construct the composite lifted matrix. When the low-frequency Fourier samples are fully acquired, the\ncorresponding rows of the matrices are fully available. This facilitates the estimation of the null-space from these regions, which can be used to\nrecover the remaining k-space regions as described in Section III. When the Fourier grid is sub-sampled, the matrices can be completed using\nnuclear norm minimization as discussed in Section IV.\nf(x,t) =\nr\n∑\nj=1\naj(x) (βj(x))t ;\nt = 1,..,T,\n(13)\nwhere the goal is to estimate the exponential parameters from their time series. Since the relation in Eq. (5) is\ntrue for the above signal model, one can build Hankel matrices H[n]\n[r] ( ̂\nfx) of the form (7) of each pixel at location\nx, analogous to the description in Section III-A. Following (4)-(7), these matrices will have a null space vector\nparameterized by the exponential parameters. The roots of the null space vector are estimated using singular value\ndecomposition (SVD), which are used to identify the exponential parameters. These sub-space strategies based on\nSVD of H[n]\n[r] ( ̂fx) is widely used in the context of MR spectroscopy [2], [11], [27].\nIV. SIGNAL INTERPOLATION USING SLR\nThis section shows how the extrapolation-based approaches in the previous section can be extended to the non-\nuniform setting. As discussed in Fig. 1, we will exploit the duality between the rank of the lifted matrices and\nthe compactness priors to ﬁll in the missing entries. Note that such sampling patterns are of high relevance in CS\napplications. The generalization of SLR can be acheived with the theoretical performance guarantees that is similar\nto that of the standard CS approaches [30].\nA. Piecewise smooth 1-D signals\nConsider the signal model in Section III-A with r Diracs. Consider a Hankel structured matrix H[n]\n[d]( ̂f) ∈C(n−d)×d\nwith d > r. Then, the authors in [14] showed that\nrank(H[n]\n[d]( ̂f)) = r.\n(14)\nOctober 12, 2021\nDRAFT\n\n9\nSimilar observation was made in early work [3]. The authors of [14] further showed that (14) holds for general\nFRI signals with the minimum annihilating ﬁlter size of r + 1 on its spectral domain. This property is useful\nfor recovering sparse signals from Fourier measurements. Speciﬁcally, let χ be a multi-set consisting of random\nindices from {0,...,n −1} such that ∣χ∣= m < n. Then, as shown in Fig. 1.(a), we can interpolate ̂f[k] for all\nk ∈{0,...,n −1} from the sparse Fourier samples exploiting (14):\nminimize\n̂g∈Cn\n∥H[n]\n[d](̂g)∥\n∗subject to Pχ(̂g) = Pχ( ̂f).\n(15)\nwhere ∥⋅∥∗denotes the matrix nuclear norm. Here, Pχ denotes a projection operation to the set χ. Instead of using\nthe nuclear norm, a similar problem was solved by nonconvex optimization method [7], [26].\n1) Theoretical Guarantees: If the sampling pattern satisﬁes the incoherence condition with the parameter ρ, then\nthere exists a constant c such that ̂f is the unique minimizer to (15) with probability 1 −1/n2 [14], provided\n∣χ∣≥c ρ r logα n,\n(16)\nwhere α = 2 if the discontinuities are located on uniform grid; α = 4 for general continuous domain signals. This\nsuggests a near-optimal performance similar to the discrete-domain CS approaches [30].\nB. Piecewise smooth multidimensional signals\nWe now consider the recovery of the Fourier samples of the piecewise constant image described in Section III-B\non Γ ⊂Z2. We consider matrices VΓ\nΛ1 ( ̂f) shown in (12), where Λ ⊂Λ1. It is shown in [10] that\nr = rank (VΓ\nΛ1 ( ̂f))\n=\n∣Λ1∣−∣Λ1 ⊖Λ∣.\n(17)\nIt is also shown in [10] that there is a duality relation between the above rank and the smoothness of the edge set\nof the images. The low-rank structure of VΓ\nΛ1 enables the recovery of ̂f on Γ using SLR.\n1) Theoretical Guarantees: The results in [16, Theorem 4] show that the SLR algorithm recovers the true Fourier\nsamples ̂f[k];k ∈Γ from its uniform random measurements on χ ⊂Γ with probability exceeding 1−∣Γ∣−2, provided\n∣χ∣≥c ρ cs r log4 ∣Γ∣,\n(18)\nwhere r is deﬁned as in (17), cs = ∣Γ∣/∣Λ1∣, c is a universal constant, and ρ > 1 is an incoherence measure depending\non the geometry of the edge set deﬁned in [16]. Note that the result bears remarkable similarity to (16), in the case\nof continuous domain signals not on the grid.\nC. Exponential signals with spatially smooth parameters\nThe approaches in Section III-C considered the pixel-by-pixel recovery of exponential parameters at each spatial\nlocation x from their uniform samples. The recovery of exponentials from non-uniform k −t domain samples is\nkey to accelerating the acquisition in several MR applications. Note that the coefﬁcients of the annihilation ﬁlters\nhx[z] depend on the exponential parameters at the speciﬁc pixel location x. In imaging applications, the exponential\nOctober 12, 2021\nDRAFT\n\n10\nparameters are often spatially smooth. The spatial Fourier transform of the ﬁlter coefﬁcients can be assumed to be\nsupport limited to a 3-D cube of size Λ. The annihilation relations thus can be compactly expressed as\nHΓ\nΛ( ̂f) h = 0,\n(19)\nwhere HΓ\nΛ( ̂f) is the block Hankel matrix corresponding to the 3-D convolution of ̂f[k,n] with the ﬁlter h. Similar\nto the discussions in Sections IV-A and IV-B, the matrix HΓ\nΛ1( ̂f) is low-rank if Λ ⊂Λ1. Thus, the recovery of the\n3-D data set from its undersampled k-t space measurements can be posed as a structured low-rank problem.\nV. RECOVERY OF MULTICHANNEL MRI DATA\nWe now consider the recovery of multichannel data using calibration-based and calibration-free strategies, which\nare analogous to the extrapolation and interpolation methods discussed above.\nA. Blind multichannel deconvolution\nIn the blind multichannel deconvolution problems in signal processing, subspace techniques such as the eigenvector-\nbased algorithm for multichannel blind deconvolution (EVAM) [32] rely on multichannel annihilation relations.\nSpeciﬁcally, the multichannel measurement for blind multichannel deconvolution problem is given by ̂fi = ̂si ∗\n̂f,\ni = 1,⋯,Nc, where Nc denotes the number of channels, ̂si denotes the unknown convolution kernels, and ̂f\nis the unknown underlying signal. The goal of the blind multichannel deconvolution problem is to estimate ̂f and\n̂si from ̂fi.\nEVAM [32] relies on the cross-channel annihilating ﬁlter relations:\n̂fi ∗̂sj −̂fj ∗̂si = 0,\n∀i ≠j .\n(20)\nAssuming that the convolution kernel ̂sj can be represented by the d-tap ﬁlter, the above convolution relations can\nbe compactly represented in the matrix form as\n[HΓ\nΛ ( ̂fi)∣HΓ\nΛ ( ̂fj)]\n⎡⎢⎢⎢⎢⎢⎣\n̂sj\n−̂si\n⎤⎥⎥⎥⎥⎥⎦\n= 0 .\n(21)\nWe now show that the extension of this work to the MRI setting is similar to the popular parallel MRI schemes\n[5], [33], which were discovered independently without realizing this connection.\nB. Calibration-based parallel MRI recovery\nThe space domain annihilation relations fi(x)⋅sj(x)−fj(x)⋅si(x) = 0 corresponding to (20) were used in [34].\nThe Fourier domain annihilation relations between each pair of channels as in (21) implies that the matrix formed\nby linearly stacking the Hankel matrices of fi,i = 1,⋯Nc\nLΓ\nΛ(f1,..,fNc) = [HΓ\nΛ ( ̂f1)∣HΓ\nΛ ( ̂f2)∣...∣HΓ\nΛ (̂\nfNc)]\n(22)\nis low-rank [4]–[6], [9], [13], [18], [26].\nIn calibration-based parallel MRI, one often acquires the central Fourier regions in a fully sampled fashion. In\nthis case, one can estimate the null space V from the central regions similar to the approach in Fig. 1.(b). Once the\nOctober 12, 2021\nDRAFT\n\n11\nnull space ﬁlters are available, the relation LΛ\nΓV = 0 can be used to complete the full matrix (22) from its partial\nentries. Consider one column of V, denoted by v = [wT\n1 ∣wT\n2 ∣...∣wT\nNc]T ; each vector wi is of dimension ∣Λ∣. The\nrelation LΓ\nΛ(f1,..,fNc)v = 0 can thus be written as\n̂f1 ∗w1 + ̂f2 ∗w2 + ... ̂\nfNc ∗wNc = 0,\n(23)\nwhere ∗denotes linear convolution. The above equation implies that the k-space sample of the ﬁrst coil can be\npredicted as the linear combination of the nearby samples in all the channels, which is essentially the simultaneous\nauto calibrating and kspace estimation (SAKE) model [5], [33]. The generalized auto calibrating partially parallel\nacquisitions GRAPPA approach, which preceded SAKE [5], [6], can be viewed as an approximation of this linear\nprediction relation. See [13] for a more detailed review of similar multichannel methods.\nC. Calibration-less multichannel recovery\nThe above calibration-based framework is extended to non-uniformly sampled k-space data in [5], [6] using the\nSLR framework, analogous to the interpolation strategies discussed in Section IV. The recovery can be interpreted\nas the rank-deﬁciency of LΓ\nΛ(f1,..,fC). Accordingly, [5], [9], [13] use the the following low-rank matrix completion\nto estimate the missing k-space data without any calibration data:\nmin\n[g1⋯gNc]rank(LΓ\nΛ(g1,..,gNc)) subject to Pχ(̂gi) = Pχ( ̂fi);\ni = 1,⋯,Nc.\nTo further exploit the annihilation relationship from the FRI model in addition to the multichannel annihilating\nrelationship, the authors in [9] solve the optimization problem (24) after the k-space weighting.\nVI. SLR RECOVERY: FAST ALGORITHMS\nWe will explain the algorithms in the context of a simple Hankel matrix lifting. Earlier algorithms [5]–[7] relied\non non-convex rank constrained formulations:\nmin\n̂g∈Cn ∥Pχ(̂g) −Pχ( ̂f)∥2\n2 such that rank(H[n]\n[d](̂g)) ≤r,\n(24)\nwhere r is a pre-deﬁned parameter. Here, Pχ denotes a projection operation to the set χ. Convex unconstrained\nformulations of the form\nmin\n̂g∈Cn λ∥H[n]\n[d](̂g)∥\n∗+ ∥Pχ(̂g) −Pχ( ̂f)∥2\n2.\n(25)\nwhere ∥⋅∥∗denotes the matrix nuclear norm and λ denotes the regularization parameter are recently being used in\napplications due to their ability to converge to global minima.\nA. Iterative singular value shrinkage\nThe formulation in (25) can be solved using the singular value thresholding scheme [8]. Speciﬁcally, the algorithm\nalternates between lifting the original signal ̂f to form H( ̂f), followed by singular value soft shrinkage of H( ̂f)\nto obtain Q and un-lifting Q to impose the Hankel structure and enforce data consistency. A challenge with this\nscheme is the high computational complexity and memory demand, especially for multichannel recovery problems.\nOctober 12, 2021\nDRAFT\n\n12\nIn [5], [7], the authors used the hard thresholding as a singular value shrinkage operation within a similar iterative\noptimization framework.\nB. UV factorization\nTo reduce the computational cost, the authors in [9], [35] used the following observation:\n∥A∥∗=\nmin\nU,V∶A=UVH ∥U∥2\nF + ∥V∥2\nF ,\n(26)\nto realize an SVD-free structured rank minimization algorithm. The nuclear norm minimization problem can be\nsolved by replacing the nuclear norm term by the above relation. The constraints are enforced using an alternating\ndirection method of multipliers (ADMM) algorithm, whose complexity is determined by the rank. So for sparse\nsignals, a signiﬁcant computation gain can be obtained.\nC. Generic iterative reweighted annihilating ﬁlter (GIRAF) algorithm\nBoth of the above strategies rely on the explicit lifting of the signal to the large Hankel matrix, which makes\nthe memory demand and computational complexity of the algorithms high. The GIRAF algorithm avoids the lifting\nsteps altogether and reduces the number of SVD steps; it solves the problem in the original signal domain, thus\nrealizing an algorithm that is comparable in computational complexity to compressed sensing methods [15]. The\nGIRAF algorithm uses the iterative re-weighted least-squares [36] strategy, which majorizes the nuclear norm\npenalty as ∥A∥∗≤∥AQ\n1\n2 ∥\n2\nF , where Q = (A∗A)−1\n4 . The ith iteration of this algorithm updates Q as Qi+1 =\n(H[n]\n[d](̂g)∗H[n]\n[d](̂gi))\n−1\n4 , followed by the minimization of a quadratic cost function to solve for gi+1 obtained by\nreplacing the nuclear norm in (25) by ∥H[n]\n[d](̂g)Qn∥\n2\nF . The GIRAF algorithm relies on fast Fourier transforms to\nevaluate the matrix vector product between H[n]\n[d](̂g) and each column of Q; this approach exploits the convolutional\nstructure of H[n]\n[d](̂g). We note that this approach does not require the creation or storage of the large structured\nmatrix, but works directly with the signal samples of g. The MATLAB implementation of the GIRAF algorithm is\navailable at https://github.com/cbig-iowa/giraf.\nD. Algorithms for non-convex SLR formulations\nAll of the above algorithms are designed for convex formulations (25). The early algorithms [5], [6] relied on\nsuccessively solving\ngn+1 = min\n̂g∈Cn ∥Pχ(̂g) −Pχ( ̂f)∥2\n2 + λ∥̂g −Mr(̂gn)∥2,\n(27)\nwhere Mr(̂gn) is the approximation of the nth iterate ̂gn such that H[n]\n[d](̂g) is of rank r. Recently, the multiplicative\nmajorization strategy in the GIRAF algorithm [15] has been adapted into the LORAKS setting to realize faster\nalgorithms.\nVII. GENERALIZATION TO MACHINE LEARNING\nA. Recovery of point clouds on surfaces: non-linear generalization of union of subspaces model\nWe will now consider a non-linear generalization of the FRI theory discussed above, which will facilitate the\nrecovery of surfaces or points living on surfaces from a few noisy samples. The main motivation is the joint\nOctober 12, 2021\nDRAFT\n\n13\nrecovery of an ensemble of images (e.g.g images in a cardiac MRI time series) from their noisy and undersampled\nmeasurements. This approach is a non-linear generalization of the popular union of subspaces model, which\nrepresents the images as a sparse linear combination of some basis images.\nWe model the surface as the zero level set of a bandlimited function as in Section IV-B. For simplicity, we will\nexplain the approach in 2D. Consider an arbitrary point x on the curve ̂h(x) = 0, where h(x) is speciﬁed by (10).\nThe space domain annihilation relation translates to cT φΛ(x) = 0, where\nφΛ(x) = [exp(j kT\n1 x)\n...\nexp(j kT\n∣Λ∣x)]\nT\n(28)\nis a non-linear mapping or lifting of a point x to a high-dimensional space [21] (see Fig. 4) of dimension ∣Λ∣. Since\nthis non-linear lifting strategy is similar to feature maps used in kernel methods [24], we term φΛ(x) as the feature\nmap of the point x.\nLet us now consider a set of N points on the curve, denoted by x1,⋯,xN. The above annihilation relations can\nbe compactly represented as cT ΦΛ(X) = 0, where\nΦΛ(X) = [φΛ(x1)\nφΛ(x2)\n...\nφΛ(xN)]\n(29)\nis the feature matrix of the points. The results in [21] show that if the number of samples exceeds a bound that\ndepends on the complexity of the curve, it can be uniquely estimated.\nWe have shown in [21] that if we choose a feature map with a bandwidth of Λ1 such that Λ ⊂Λ1, the feature\nmatrix satisﬁes the relation similar to (17):\nrank(ΦΛ1(X)) ≤\n∣Λ1∣−∣Λ1 ⊖Λ∣.\n(30)\nGeneralizing the SLR approach in Section IV, we recover the samples on the curve/surface from a few measurements\ncorrupted by noise [21] by solving an optimization problem:\nminimize\nX\nλ∥ΦΛ1(X)∥∗+ ∥A(X) −b∥2.\n(31)\nWe use an iterative-reweighted least-squares (IRLS) algorithm [36] that relies on the kernel trick [24] for recovery.\nSpeciﬁcally, the algorithm alternates between a quadratic optimization scheme and the evaluation of the graph\nLaplacian matrix; the algorithm may be interpreted as a the discretization of the manifold by a graph, whose\nconnectivity is speciﬁed by the distances on the manifold/surface. Note that unlike the approaches in Section IV,\nthis algorithm is non-convex. Hence, the above optimization problem cannot be guaranteed to achieve the global\nminimum. Despite the lack of guarantees, the algorithm was able to yield good performance in applications, as\nseen in Fig. 4 and Fig. 8.\nB. Relation to Deep Convolutional Neural Networks\nOne of the interesting twists of the SLR approach is its relation to deep neural networks. Speciﬁcally, in the\nrecent theory of deep convolutional framelets [37], the authors showed that a deep neural network can be interpreted\nas a framelet representation whose basis can be obtained from Hankel matrix decomposition. Moreover, in a recent\nOctober 12, 2021\nDRAFT\n\n14\nΦ⇤\nc\n(a) Illustration\n(a) Original #1\n(b) Noisy #1\n(c) GLR\n(d) KLR\n(e) Original #2\n(f) Noisy #2\n(g) GLR\n(h) KLR\n(i) Original #3\n(j) Noisy #3\n(k) GLR\n(l) KLR\nFig. 9. Comparison between our denoising algorithm (KLR) and the Garph Laplacian Regularized point cloud denoising algorithm (GLR) introduced in [45\nSince  j is irreducible, this implies that  j is a factor of ⌘. Repeating\nthis line of reasoning for all factors { j}, we conclude that  (x)\ndivides ⌘(x). Since both  (x) and ⌘(x) have the same bandwidth,\nthe only possibility is that ⌘(x) is a scalar multiple of  (x). This\nimplies that the curve  (x) = 0 can be uniquely recovered in (14)\nis satisﬁed.\nThe total number of points to be sampled is N = PJ\nj=1 Nj >\n(k1 + k2) PJ\nj=1(k1,j + k2,j).\nThe support of the Fourier coefﬁcients of  can be expressed in\nterms of the supports of { j}. Using convolution properties, we get:\nk1 = 1 + PJ\nj=1(k1,j −1) and k2 = 1 + PJ\nj=1(k2,j −1). Thus,\nPJ\nj=1(k1,j + k2,j) = k1 + k2 + 2(J −1) and it can be concluded\nthat N > (k1 + k2)(k1 + k2 + 2(J −1)).\nD. Proof of Proposition 8\nProof. Following the steps of the proof for Proposition 7, we can\nconclude that  (x) is a factor of µ(x). Since ⇤⇢Γ, it follows that\nµ(x) =  (x) ⌘(x), where ⌘(x) is some arbitrary function such that\nµ(x) is band-limited to Γ.\nE. Proof of Proposition 9\nProof. Let c be the minimal ﬁlter of bandwidth |⇤|, associated with\nthe polynomial  (x). We deﬁne the following ﬁlters supported in Γ\nfor all l 2 Γ : ⇤.\ncl[k] =\n(\nc[k −l],\nif k −l 2 ⇤.\n0,\notherwise.\n(44)\ncl are the Fourier coefﬁcients of exp(j2⇡lT x) (x), and are all null-\nspace vectors of the feature matrix ΦΓ(X). The number of such ﬁlters\nis |Γ : ⇤|. Hence, we get the rank bound: rank (ΦΓ(X)) |Γ|−|Γ\n⇤|.\nIf the sampling conditions of Proposition 8 are satisﬁed, then al\nthe polynomials corresponding to null-space vectors of ΦΓ are of th\nform: µ(x) =  (x) ⌘(x). Alternatively, in the Fourier domain, th\nﬁlters are of the form:\ncµ[k] =\nX\nl2Γ:⇤\ndlcl[k]\n(45\nwhere dl are the Fourier coefﬁcients of the arbitrary polynomial ⌘(x)\nThus, all the null-space ﬁlters can be represented in terms of th\nbasis set {cl}. This leads to the relation: rank (ΦΓ(X)) = |Γ|−|Γ\n⇤|.\nREFERENCES\n[1] M. Botsch, M. Pauly, L. Kobbelt, P. Alliez, B. L´evy, S. Bischoff, an\nC. R¨ossl,\n“Geometric modeling based on polygonal meshes,”\nACM\nSIGGRAPH 2007 courses - SIGGRAPH ’07, 2007.\n[2] R. Jain, R. Kasturi, and B. G. Schunck, “Curves and surfaces,” Mach\nVis., pp. 365–405, 1995.\n[3] M. Jacob, T. Blu, and M. Unser, “Efﬁcient energies and algorithms fo\nparametric snakes,”\nIEEE Trans. Image Process., vol. 13, no. 9, pp\n1231–1244, 2004.\n[4] V. Uhlmann, J. Fageot, and M. Unser, “Hermite snakes with control o\ntangents,” IEEE Trans. Image Process., vol. 25, no. 6, pp. 2803–2816\n2016.\n[5] R. Delgado-gonzalo, V. Uhlmann, D. Schmitter, and M. Unser, “Snake\non a Plane: A perfect snap for bioimage analysis,” IEEE Signal Process\nMag., vol. 32, no. 1, pp. 41–48, 2015.\n[6] A. Badoual, D. Schmitter, V. Uhlmann, and M. Unser, “Multiresolutio\nsubdivision snakes,” IEEE Trans. Image Process., vol. 26, no. 3, pp\n1188–1201, 2017.\n(a) Original #1\n(b) Noisy #1\n(c) GLR\n(d) KLR\n(e) Original #2\n(f) Noisy #2\n(g) GLR\n(h) KLR\n(i) Original #3\n(j) Noisy #3\n(k) GLR\n(l) KLR\nFig. 9. Comparison between our denoising algorithm (KLR) and the Garph Laplacian Regularized point cloud denoising algorithm (GLR) introduced in [45]\nSince  j is irreducible, this implies that  j is a factor of ⌘. Repeating\nthis line of reasoning for all factors { j}, we conclude that  (x)\ndivides ⌘(x). Since both  (x) and ⌘(x) have the same bandwidth,\nthe only possibility is that ⌘(x) is a scalar multiple of  (x). This\nimplies that the curve  (x) = 0 can be uniquely recovered in (14)\nis satisﬁed.\nThe total number of points to be sampled is N = PJ\nj=1 Nj >\n(k1 + k2) PJ\nj=1(k1,j + k2,j).\nThe support of the Fourier coefﬁcients of  can be expressed in\nterms of the supports of { j}. Using convolution properties, we get:\nk1 = 1 + PJ\nj=1(k1,j −1) and k2 = 1 + PJ\nj=1(k2,j −1). Thus,\nPJ\nj=1(k1,j + k2,j) = k1 + k2 + 2(J −1) and it can be concluded\nthat N > (k1 + k2)(k1 + k2 + 2(J −1)).\nD. Proof of Proposition 8\nProof. Following the steps of the proof for Proposition 7, we can\nconclude that  (x) is a factor of µ(x). Since ⇤⇢Γ, it follows that\nµ(x) =  (x) ⌘(x), where ⌘(x) is some arbitrary function such that\nµ(x) is band-limited to Γ.\nE. Proof of Proposition 9\nProof. Let c be the minimal ﬁlter of bandwidth |⇤|, associated with\nthe polynomial  (x). We deﬁne the following ﬁlters supported in Γ\nfor all l 2 Γ : ⇤.\ncl[k] =\n(\nc[k −l],\nif k −l 2 ⇤.\n0,\notherwise.\n(44)\ncl are the Fourier coefﬁcients of exp(j2⇡lT x) (x), and are all null-\nspace vectors of the feature matrix ΦΓ(X). The number of such ﬁlters\nis |Γ : ⇤|. Hence, we get the rank bound: rank (ΦΓ(X)) |Γ|−|Γ\n⇤|.\nIf the sampling conditions of Proposition 8 are satisﬁed, then al\nthe polynomials corresponding to null-space vectors of ΦΓ are of the\nform: µ(x) =  (x) ⌘(x). Alternatively, in the Fourier domain, the\nﬁlters are of the form:\ncµ[k] =\nX\nl2Γ:⇤\ndlcl[k]\n(45\nwhere dl are the Fourier coefﬁcients of the arbitrary polynomial ⌘(x)\nThus, all the null-space ﬁlters can be represented in terms of the\nbasis set {cl}. This leads to the relation: rank (ΦΓ(X)) = |Γ|−|Γ\n⇤|.\nREFERENCES\n[1] M. Botsch, M. Pauly, L. Kobbelt, P. Alliez, B. L´evy, S. Bischoff, and\nC. R¨ossl,\n“Geometric modeling based on polygonal meshes,”\nACM\nSIGGRAPH 2007 courses - SIGGRAPH ’07, 2007.\n[2] R. Jain, R. Kasturi, and B. G. Schunck, “Curves and surfaces,” Mach\nVis., pp. 365–405, 1995.\n[3] M. Jacob, T. Blu, and M. Unser, “Efﬁcient energies and algorithms fo\nparametric snakes,”\nIEEE Trans. Image Process., vol. 13, no. 9, pp\n1231–1244, 2004.\n[4] V. Uhlmann, J. Fageot, and M. Unser, “Hermite snakes with control o\ntangents,” IEEE Trans. Image Process., vol. 25, no. 6, pp. 2803–2816\n2016.\n[5] R. Delgado-gonzalo, V. Uhlmann, D. Schmitter, and M. Unser, “Snake\non a Plane: A perfect snap for bioimage analysis,” IEEE Signal Process\nMag., vol. 32, no. 1, pp. 41–48, 2015.\n[6] A. Badoual, D. Schmitter, V. Uhlmann, and M. Unser, “Multiresolution\nsubdivision snakes,” IEEE Trans. Image Process., vol. 26, no. 3, pp\n1188–1201, 2017.\n(a) Original #1\n(b) Noisy #1\n(c) GLR\n(d) KLR\n(e) Original #2\n(f) Noisy #2\n(g) GLR\n(h) KLR\n(i) Original #3\n(j) Noisy #3\n(k) GLR\n(l) KLR\nFig. 9. Comparison between our denoising algorithm (KLR) and the Garph Laplacian Regularized point cloud denoising algorithm (GLR) introduced in [45].\nSince  j is irreducible, this implies that  j is a factor of ⌘. Repeating\nthis line of reasoning for all factors { j}, we conclude that  (x)\ndivides ⌘(x). Since both  (x) and ⌘(x) have the same bandwidth,\nthe only possibility is that ⌘(x) is a scalar multiple of  (x). This\nimplies that the curve  (x) = 0 can be uniquely recovered in (14)\nis satisﬁed.\nThe total number of points to be sampled is N = PJ\nj=1 Nj >\n(k1 + k2) PJ\nj=1(k1,j + k2,j).\nThe support of the Fourier coefﬁcients of  can be expressed in\nterms of the supports of { j}. Using convolution properties, we get:\nk1 = 1 + PJ\nj=1(k1,j −1) and k2 = 1 + PJ\nj=1(k2,j −1). Thus,\nPJ\nj=1(k1,j + k2,j) = k1 + k2 + 2(J −1) and it can be concluded\nthat N > (k1 + k2)(k1 + k2 + 2(J −1)).\nD. Proof of Proposition 8\nProof. Following the steps of the proof for Proposition 7, we can\nconclude that  (x) is a factor of µ(x). Since ⇤⇢Γ, it follows that\nµ(x) =  (x) ⌘(x), where ⌘(x) is some arbitrary function such that\nµ(x) is band-limited to Γ.\nE. Proof of Proposition 9\nProof. Let c be the minimal ﬁlter of bandwidth |⇤|, associated with\nthe polynomial  (x). We deﬁne the following ﬁlters supported in Γ\nfor all l 2 Γ : ⇤.\ncl[k] =\n(\nc[k −l],\nif k −l 2 ⇤.\n0,\notherwise.\n(44)\ncl are the Fourier coefﬁcients of exp(j2⇡lT x) (x), and are all null-\nspace vectors of the feature matrix ΦΓ(X). The number of such ﬁlters\nis |Γ : ⇤|. Hence, we get the rank bound: rank (ΦΓ(X)) |Γ|−|Γ :\n⇤|.\nIf the sampling conditions of Proposition 8 are satisﬁed, then all\nthe polynomials corresponding to null-space vectors of ΦΓ are of the\nform: µ(x) =  (x) ⌘(x). Alternatively, in the Fourier domain, the\nﬁlters are of the form:\ncµ[k] =\nX\nl2Γ:⇤\ndlcl[k]\n(45)\nwhere dl are the Fourier coefﬁcients of the arbitrary polynomial ⌘(x).\nThus, all the null-space ﬁlters can be represented in terms of the\nbasis set {cl}. This leads to the relation: rank (ΦΓ(X)) = |Γ|−|Γ :\n⇤|.\nREFERENCES\n[1] M. Botsch, M. Pauly, L. Kobbelt, P. Alliez, B. L´evy, S. Bischoff, and\nC. R¨ossl,\n“Geometric modeling based on polygonal meshes,”\nACM\nSIGGRAPH 2007 courses - SIGGRAPH ’07, 2007.\n[2] R. Jain, R. Kasturi, and B. G. Schunck, “Curves and surfaces,” Mach.\nVis., pp. 365–405, 1995.\n[3] M. Jacob, T. Blu, and M. Unser, “Efﬁcient energies and algorithms for\nparametric snakes,”\nIEEE Trans. Image Process., vol. 13, no. 9, pp.\n1231–1244, 2004.\n[4] V. Uhlmann, J. Fageot, and M. Unser, “Hermite snakes with control of\ntangents,” IEEE Trans. Image Process., vol. 25, no. 6, pp. 2803–2816,\n2016.\n[5] R. Delgado-gonzalo, V. Uhlmann, D. Schmitter, and M. Unser, “Snakes\non a Plane: A perfect snap for bioimage analysis,” IEEE Signal Process.\nMag., vol. 32, no. 1, pp. 41–48, 2015.\n[6] A. Badoual, D. Schmitter, V. Uhlmann, and M. Unser, “Multiresolution\nsubdivision snakes,” IEEE Trans. Image Process., vol. 26, no. 3, pp.\n1188–1201, 2017.\nOriginal\nNoisy\nSLR\n(b) Denoising\nFig. 4. Illustration of the non-linear lifting operation in 2-D, which will map closed union of bandlimited curves to union of sub-spaces. (a)\nEach closed curve is mapped to a subspace. The SLR scheme relies on the low-rank structure of the subspace where the lifted points live in to\nrecover the curves or denoise the points living on union of bandlimited curves. The utility of this scheme in the denoising of shapes is illustrated\nin (b). The recovery is posed as a nuclear norm minimization of the feature maps, which was solved using an iterative reweighted least-squares\nalgorithm exploiting the kernel trick [21]. This approach is extended to higher dimensions to recover free breathing and ungated cardiac MRI\ndata, illustrated in Fig. 8.\nfollow-up study [38], the authors further revealed that the reciﬁed linear unite (ReLU) plays a key role in making\nthe representation adaptive to input by providing combinatorial basis selection.\nSpeciﬁcally, for a given Hankel matrix H(f), let us consider two matrices Φ⊺and Ψ whose dimensions are\ndetermined such that they can multiplied to the left and the right of the Hankel matrix, respectively. Furthermore,\nsuppose there exists matrices ˜Φ and their duals ˜Ψ satisfying the frame condition ˜ΦΦ⊺= I,\nΨ ˜Ψ⊺= I, where the\nsuperscript ⊺denotes the matrix transpose and I refers to an identity matrix with appropriate size. The existence\nof such matrices can be trivially shown as inﬁnite number of orthonormal matrices satisfy the frame condition. In\nfact, the frame condition allows overcomplete representation. Then, it is easy to show\nH(f) = ˜ΦC ˜Ψ⊺\n,\nwhere\nC = Φ⊺H(f)Ψ.\n(32)\nOne of the most interesting observations in [37] is that (32) can be equivalently represented by encoder and decoder\nconvolution structure:\nC = Φ⊺(f ∗α(Ψ))\n,\nf = ( ˜ΦC) ∗β( ˜Ψ)\n(33)\nwhere α(Ψ) and β( ˜Ψ) are the encoder and decoder layer multichannel convolution ﬁlters obtained by rearranging\nΨ and ˜Ψ, respectively [37]. This observation led to the ﬁndings that Φ⊺and ˜Φ correspond to the pooling and\nunpooling layers, respectively [37].\nHowever, to satisfy the frame conditions, the number of output ﬁlter channels should increase exponentially,\nwhich is difﬁcult to satisfy in practice [37]. Moreover, in contrast to SLR approaches, the exact decomposition of\nthe Hankel matrix in (33) is not interesting in neural networks, since the output of the network should be different\nfrom the input due to the task-dependent processing. Moreover, the representation should be generalized well for\nvarious inputs rather than a speciﬁc input at the training phase. In a recent extension of the deep convolutional\nframelets [37], the authors revealed that the convolutional framelet representation is indeed combinatorial due to the\ncombinatorial nature of ReLU. Specially, for the case of an encoder-decoder convolutional neural network (CNN)\nOctober 12, 2021\nDRAFT\n\n15\nwithout a skipped connection it was shown that the CNN ouput g can be represented as follows [38]:\ng\n=\n∑\ni\n⟨bi(f),f⟩˜bi(f),\n(34)\nwhere bi(f) and ˜bi(f) denote the ith columns of the B(f) and ˜B(f) matrices given by\nB(f)\n=\nE1Σ1(f)E2⋯Σκ−1(f)Eκ,\n(35)\n˜B(f)\n=\nD1 ˜Σ1(f)D2⋯˜Σκ−1(f)Dκ,\n(36)\nwhere Σl(f) and ˜Σl(f) denote diagonal matrices with 0 and 1 values that are determined by the ReLU output in\nthe previous convolution steps; El (resp. Dl) denotes the l-th layer encoder (resp. decoder) matrix that is composed\nof pooling matrix Φl (unpooling matrix ˜Φl) and encoder ﬁlter matrix Ψl (resp. decoder ﬁlter matrix ˜Ψl). Similar\nbasis representation holds for the encoder-decoder CNNs with skipped connection [38].\nWhen there are no ReLU nonlinearities and pooling and ﬁlter matrices satisfy the frame condition for each\nl, the representation (34) is indeed a convolutional frame representation of f as in (33), ensuring perfect signal\nreconstruction. Even with the ReLU, there exists conjugate ﬁlter sets that can allows perfect reconstruction condition\n[37]. However, the explicit dependence of (35) and (36) on the input f due to the ReLU nonlinearity makes\nthe neural network representation much richer and adaptive to different input signals, since the resulting frame\nrepresentation in (34) depends on speciﬁc input. In this regard, the role of ReLU may be similar to the sparsity\npatterns in compressed sensing MRI, since the sparsity pattern determines the difference basis representation of\nCS for given inputs. Furthermore, the number of distinct linear representations increases exponentially with the\nnetwork depth, width, and the skipped connection, thanks to the combinatorial nature of ReLU nonlinearities [38].\nThis exponentially large expressivity of the neural network is another important advantage, which may, with the\ncombination of the aforementioned adaptivity, explain the origin of the success of deep neural networks for image\nreconstruction.\nVIII. APPLICATION OF SLR FOR IMPROVED MRI\nThe main beneﬁt of the SLR framework is its ability to account for a wide variety of signal models, facilitating\nthe exploitation of extensive redundancies between their Fourier samples. This feature makes SLR applicable to a\nwide variety of MRI applications, listed below.\nA. Highly accelerated MRI\nDuring the past few years, different SLR priors were introduced for highly accelerated MRI, each designed to\nexploit speciﬁc signal properties.\n1) Support/sparsity priors [7]: The signal is assumed to be sparse or support limited to a region in low-rank\nmodeling of local k-space neighborhoods (LORAKS), which results in annihilation conditions in k-space. The\nLORAKS scheme formulated the CS-MRI problem by using the block Hankel matrix of the images as the prior.\nThe LORAKS framework also exploits phase constraints, which are detailed in [7].\nOctober 12, 2021\nDRAFT\n\n16\n2) Transform domain sparsity [3], [9], [10]: The annihilating ﬁlter-based low-rank Hankel matrix (ALOHA)\napproach considers general signals that can also be sparse in a transform domain. Speciﬁcally, the signal f is\nmodeled as Lf = w, where L denotes a constant coefﬁcient linear differential equation, often called the whitening\noperator [14]:\nL ∶= bK∂K + bK−1∂K−1 + ... + b1∂+ b0,\n(37)\nand w is an innovation signal composed of a stream of Diracs or differentiated Diracs. Evaluating the Fourier\ntransform, we have ̂w ∶= ̂l ̂f where ̂l(f) = bK(i2πf)K +...+b1(i2πf)+b0 and the associated Hankel matrix H(̂w)\nfrom the innovation spectrum ̂w becomes rank deﬁcient. The Fourier coefﬁcients are interpolated similar to (15)\nby minimizing the nuclear norm of a block Hankel matrix whose entries are the Fourier coefﬁcients of ˆf weighted\nby ˆl.\n3) Piecewise smooth signal model [3], [16]: The GIRAF algorithm generalized the piecewise polynomial 1-\nD model [3] to recover piecewise constant multi-dimensional signals from their sparse Fourier coefﬁcients by\nminimizing the nuclear norm of the vertically stacked block Hankel matrices in (12) (see Figure 3.(a)), as described\nin Section IV-B. Each of the block Hankel matrices correspond to weighted Fourier coefﬁcients of the signal.\nThis model was recently extended to represent the image as a linear combination of piecewise constant (fpwc)\nand piecewise linear components (fpwl) [20]: f(x) = fpwc(x) + fpwl(x). The recovery is posed as:\nmin\ng1,g2∈Cn\n∥T (̂\n∇g1)∥∗+ ∥S(̂\n∇2g2)∥∗+ λ∥PΩ( ̂g1 + ̂g2) −PΩ( ̂f)∥2,\nwhere S is the matrix obtained by the vertical stacking of the block Hankel matrices of three second degree partial\nderivatives, denoted by the vector ̂\n∇2f. We demonstrate the beneﬁt of some of the ﬂavors of the proposed scheme\nin Fig. 5\nB. Calibration-free correction of trajectory and phase errors\nThe multichannel framework introduced in Section V-C provides a versatile tool to solve several calibration\nproblems in MRI, where different k-space regions are acquired from different excitations; these datasets will differ\nin phase errors, which often manifest as artifacts. As discussed in Section II-A2, (2) can also be used to model the\nacquisition of multi-shot Fourier data. Speciﬁcally, the data is split into multiple groups or virtual channels, each\ncorresponding to different distortions. The joint recovery of these groups or virtual channels are performed as in\n(24).\n1) Correction of phase errors in multi-shot diffusion MRI [18]: Diffusion MRI (DMRI) is a valuable tool for\nassessing brain connectivity and tissue micro-structure. High-resolution DMRI is often acquired using multi-shot\nEPI schemes, where different Fourier regions are acquired from different radio-frequency excitation pulses. For\nexample, the even lines in a two-shot EPI sequence are collected from one shot, while the odd lines are collected\nin the second shot. Subtle physiological motion between the shots in the presence of diffusion encoding gradients\nmanifest as motion induced phase errors between the shots. Previous works [18] have shown that these phase errors\ncan be corrected using the SLR scheme, even when the data is acquired using 4-8 shots. The results in Fig. 6.(a)\nshows the improved reconstructions offered by this scheme.\nOctober 12, 2021\nDRAFT\n\n17\nFig. 5. Illustration of different ﬂavors of SLR recovery in a single coil setting. The Fourier transform of the image was sampled on the radial\ngrid, which corresponds to an acceleration of 4.85. The columns correspond to (a) GIRAF, which assumes a piecewise constant image model,\nwhere the nuclear norm of the block Hankel matrix in (12) is minimized, (b) GSLR, where the image is modeled as the sum of a piecewise\nconstant and piecewise linear functions as in (38), (c) S-LORAKS and (d) G-LORAKS [7], (e) total generalized variation (TGV), which is a\ndiscrete model that represents the images as the sum of piecewise linear and piecewise constant factors, and (f) total variation (TV). We note\nthat the Fourier domain models (a)&(b) offer better reconstructions compared to their discrete counterparts (f) and (e), respectively, which can\nbe appreciated from the zoomed images as well as the error images. We note that both (a) and (b) consider the low-rank structure of Hankel\nmatrices constructed from weighted Fourier samples; this allows these methods to exploit the continuous sparsity of the edges, similar to discrete\napproaches such as TV or wavelet methods. The performance of the algorithms can be further improved by combining multiple SLR priors to\nexploit different signal priors (e.g., piecewise smoothness, multichannel sampling, smoothness of phase) [18]. These combinations can be either\naccounted for by different regularization terms or combined into a single nuclear norm penalty of a more complex structured matrix obtained\nby vertical and horizontal stackings to exploit the redundancies.\n2) Compensation of trajectory errors [39]: MRI images can also suffer from artifacts, resulting from k-space\ndata of different excitations experiencing different distortions. A typical example is radial imaging, where the shifted\nradial spokes cause streaking artifacts. A matrix completion using the low-rank prior [39] is used to jointly recover\nthe artifact-free images and the uncorrupted calibration data. Several other groups have shown the utility of the\nlow-rank based approach for the correction of trajectory errors in EPI and radial setting (not referenced here due\nto space constraints).\nC. Correction of k-space outliers [17], [40]\nMany MRI artifacts from the instability of an MR system, patient motion, inhomogeneities of gradient ﬁelds,\netc. are manifested as outliers in k-space data. Because MR artifacts usually appear as sparse k-space components,\nthe artifact-corrupted MRI measurements ̂z(f) can be modeled as ̂z(f) = ̂x(f) + ̂s(f), where ̂x(f) is a k-space\ndata of an artifact-free image and ̂s(f) is the sparse k-space outlier [17]. If the unknown signal can be sparsiﬁed\nby applying a whitening operator (37) by performing a lifting to a Hankel structured matrix, we can see that\nH(̂y) = H(̂l ⊙̂x)\n´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶\nlow-rank\n+H(̂l ⊙̂s)\n´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶\nsparse\n,\n(38)\nwhere ̂l denotes the spectrum of the whitening operator.\nNote that the second term in Eq. (38) is sparse, because the lifted Hankel matrix from sparse components is\nstill sparse, as illustrated in Fig. 7. Thus, Eq. (38) becomes a structure for sparse + low-rank decomposition, and a\nmodiﬁed version of robust principal component analysis (RPCA) was used to decompose the low-rank and sparse\nOctober 12, 2021\nDRAFT\n\n18\n(a) Artifact correction in diffusion MRI\nUncorrected\n(b) B0 distortion correction in EPI\nFig. 6. Example applications enabled by the SLR framework. (a) High-resolution four-shot diffusion MRI enabled by the SLR framework. The\ntop row corresponds to uncorrected four-shot diffusion weighted MRI data from a single diffusion direction. Subtle subject motion between the\nshots results in phase errors between the measured Fourier datasets. In addition, eddy current artifacts also manifest as shifts in Fourier space\nbetween odd/even lines. These errors manifest as Nyquist ghosting artifacts in the uncorrected diffusion wighted images (DWI) in the top row.\nThe SLR algorithm called MUSSELS [18] recovers the eight images, corresponding to each shot and odd/even lines separately, exploiting the\nphase relations between the images. The sum-of-squares combined DWI data from the above eight images for each slice are shown in the second\nrow. The information from sixty such directions provides the fractional anisotropy diffusion MRI maps shown in the bottom row. (b) Correction\nof B0 distortions in EPI data [29]: the long readouts in EPI often result in spatial distortions, resulting from the inhomogeneity of the main\n(B0) magnetic ﬁeld. Ignoring the B0-induced magnetization evolution during the long EPI readouts will be associated with spatial distortions.\nWe reformulated the EPI distortion correction as a time-series recovery problem, where multiple images corresponding to different segments\nof the readouts are recovered exploiting the exponential structure of the signal. Note that each of the segments are highly undersampled. The\nmissing Fourier samples are ﬁlled in using a structured low-rank matrix completion.\n(a) Sparse + low rank decomposi-\ntion.\n(b) MR k-space artifact removal example.\nFig. 7. (a) Lifting of image with sparse outlier. Noiseless image becomes low-rank Hankel matrix, whereas the noisy image becomes a sparse\nHankel matrix so that robust principal component analysis can decompose the sparse and low-rank Hankel matrices. Then, by unlifting the\nHankel matrix, we can obtain the noiseless k-space data and the clean images. (b) Example of MR artifact removals: (left) noisy images, (center)\nnoisy k-space, and (right) decomposed sparse k-space outliers.\ncomponent of the Hankel matrix H(̂y). After the sparse + low-rank decomposition, the weighted k-space for the\nlow-rank component is returned to original k-space by performing an un-weighting [17].\nD. Recovery of exponentials\n1) Parameter mapping [12], [19]: MR parameter mapping methods, which estimate the T1 and T2 relaxation\nconstants, can enable tissue characterization and hence are clinically very valuable. However, the the long scan\ntime resulting from the need for multiple temporal frames makes these schemes challenging for routine clinical use.\nOctober 12, 2021\nDRAFT\n\n19\n(a) Comparison with XD-GRASP\n(b) Comparison with breath-held cine\nFig. 8. Illustration of SToRM algorithm [21] described in Section VIII-E. The SToRM algorithm exploits the manifold structure of free-breathing\nand ungated images in high-dimensional space. Speciﬁcally, each image can be viewed as a smooth function of two parameters: the cardiac phase\nand the respiratory phase. A non-linear transformation speciﬁed by (29) transforms the data to a subspace. We recover the images from their\nundersampled measurements by exploiting this structure, which is compactly captured by the nuclear norm of the feature matrix. We solve the\noptimization problem using an IRLS algorithm that uses the kernel trick, which eliminates the need to explicitly evaluate the complex features.\n(a) shows the comparisons of SToRM reconstructed images with XD-GRASP, which is an explicit binning strategy; XD-GRASP bin the images\nto distinct cardiac/respiratory phases, followed by the total variation recovery of the images. We observe that the implicit binning of the data\noffered by SToRM results in reduced blurring and improved ﬁdelity (b) shows the comparisons of SToRM reconstructions (bottom row) with\nclassical breath-held acquisitions (top-row) that bins the data from different cardiac cycles. We observe that the image quality is comparable,\nwhole SToRM offers real-time imaging capabilities, allowing us to visualize cardiac and respiratory functions simultaneously. (a) Comparison\nUnder-sampling each temporal frame, followed by sparse recovery, has been a popular approach to reduce scan\ntime. The spatio-temporal signal can be modeled as an exponential with smoothly varying parameters as described\nin Section IV-C, which facilitates its recovery from under-sampled measurements.\n2) Field inhomogeneity compensation [28], [29]: MRI schemes such EPI are associated with long readouts. The\nEPI signal at the time point t after the excitation is the Fourier sample of the image modulated by a time-evolving\nexponential: ρ[r,n] = f(r) β(r)n, where the exponential parameter β(r) = e−(R∗\n2(r)+jω(r))T results from the ﬁeld\ninhomogeneity and T is the sampling rate in time; f(r) is the true image. The standard inverse Fourier transform\nreconstruction ignoring the exponential term thus recovers the ﬁeld inhomogeneity distorted image. We used the\napproach described in Section IV-C to recover the entire time series ρ[r,n] from the Fourier measurements. Post-\nrecovery, the image ρ[r,0] is chosen as the un-distorted signal. Since there are two complex unknowns f(r) and\nβ(r) at each pixel, we use two shifted EPI readouts to recover the time series [29]. The results of this approach\nare shown in Fig. 6.(b).\nE. Free-breathing and ungated cardiac MRI [21]\nIn cardiac MRI clinical practice, breath-held cardiac cine MRI is the standard protocol to evaluate cardiac function.\nMany subject groups cannot tolerate the breath-holds, which disqualiﬁes such patients for cardiac MRI exams. While\nfree-breathing and ungated cardiac MRI is the ideal protocol, a main challenge is the quite signiﬁcant acceleration\nneeded to facilitate this scheme. The work in [21] used the surface recovery strategy in Section VII-A to recover\nfree-breathing and ungated data from highly undersampled measurements with great success as shown in Fig. 6.(b).\nIX. CONCLUSION & FUTURE WORK\nThe SLR formulation provides a ﬂexible framework to exploit different continuous domain signal priors, which\nare difﬁcult for current discrete compressive sensing frameworks to capture. The framework comes with theoretical\nguarantees and fast algorithms and software, making it readily applicable in multidimensional imaging problems\nOctober 12, 2021\nDRAFT\n\n20\nincluding MRI. The recent results showed that there are important links between SLR frameworks and machine\nlearning approaches. The proposed framework is demonstrated in several challenging MRI applications.\nIn spite of its ﬂexibility and many applications, there are still remaining open challenges, some of which will be\ndiscussed below.\nSampling patterns: The single-channel theoretical results (16) and (18) guarantee the recovery of the Fourier\ncoefﬁcients of the signals on a grid from a randomly chosen subset of coefﬁcients. The results exhibit a log4\ndependence on the ﬁnal grid size, suggesting increasing sample demand with larger grid sizes. However, we note\nfrom Sections III-A and III-B that once the null space is identiﬁed, the signal extrapolation to any grid size\nis possible from the low-frequency Fourier samples [10, Theorem 1]. This strongly suggests a variable-density\nsampling approach, which may signiﬁcantly reduce the sampling demand, and which was also conﬁrmed by the\nempirical results in [16]. More theoretical work in this area is needed to determine the best sampling patterns.\nWhile empirical results demonstrate the great beneﬁt of SLR schemes in multichannel signal recovery from non-\nuniform samples, this problem is not well studied from a theoretical perspective. However, the SLR framework\ncan still be adapted to work well through the synergistic combination of multiple signal priors (e.g., sparsity and\nmultichannel annihilation priors), achieved by composite lifting [18]. More theoretical work is needed on this front\nto improve the understanding of this problem.\nTheoretical guarantees and noise performance: Most of the above analysis assumes that the measurements\nare noise-free and the underlying SLR matrix is low-rank. For example, the multichannel annihilation relationship\nin (20) is valid only for the noiseless k-space measurements. The model mismatch introduces a slow decay of the\nsingular value spectrum of the Hankel matrix. The above theoretical results are extended to scenarios involving\nmeasurement noise in speciﬁc SLR models in [14], [16]. However, note that SLR formulations can be obtained from\nmany different redundancies within the signal [5], [7], [18], [29]; the generalization of the theoretical robustness\nresults in [14], [16] to general SLR schemes deserves further investigation.\nLinks between machine learning and SLR: Although the aforementioned link between the SLR and deep\nlearning is interesting, there are still open questions, and more theoretical work is necessary to understand this\nconnection. The generalizability, optimization landscape, and expressivity (see the extensive list of references in\n[38]) in the context of machine-learning based reconstruction are not still well-understood, which may be an\nimportant research direction.\nACKNOWLEDGEMENT\nJCY is supported by National Research Foundation of Korea under Grant NRF-2016R1A2B3008104. MJ is\nsupported by grants NIH 1R01EB019961-01A1 and R01 EB019961-02S1.\nREFERENCES\n[1] M. Doneva, “An overview of mathematical models for computational MRI,” IEEE Signal Processing Magazine, 2020.\n[2] B. H, de Beer R, B. WM, C. JH, and van Ormondt D., “Application of linear prediction and singular value decomposition (LPSVD) to\ndetermine NMR frequencies and intensities from the FID.” Magnetic Resonance in Medicine, vol. 2, no. 1, pp. 86–89, 1985.\nOctober 12, 2021\nDRAFT\n\n21\n[3] Z.-P. Liang, E. M. Haacke, and C. W. Thomas, “High-resolution inversion of ﬁnite Fourier transform data through a localised polynomial\napproximation,” Inverse Problems, vol. 5, no. 5, 1989.\n[4] J. Zhang, C. Liu, and M. E. Moseley, “Parallel reconstruction using null operations (pruno),” Magnetic Resonance in Medicine, vol. 66,\nno. 5, 2011.\n[5] P. J. Shin, P. E. Larson, M. A. Ohliger, M. Elad, J. M. Pauly, D. B. Vigneron, and M. Lustig, “Calibrationless parallel imaging reconstruction\nbased on structured low-rank matrix completion,” Magnetic Resonance in Medicine, vol. 72, no. 4, pp. 959–970, 2014.\n[6] M. Uecker, P. Lai, M. J. Murphy, P. Virtue, M. Elad, J. M. Pauly, S. Vasanawala, and M. Lustig, “ESPIRIT - an eigenvalue approach to\nautocalibrating parallel MRI: where sense meets grappa,” Magn. Reson. Med, vol. 71, no. 3, pp. 990–1001, 2014.\n[7] J. P. Haldar, “Low-Rank Modeling of Local-Space Neighborhoods (LORAKS) for Constrained MRI,” IEEE Trans. on Medical Imaging,\nvol. 33, no. 3, pp. 668–681, 2014.\n[8] X. Qu, M. Mayzel, J.-F. Cai, Z. Chen, and V. Orekhov, “Accelerated NMR spectroscopy with low-rank reconstruction,” Angewandte\nChemie International Edition, vol. 54, no. 3, pp. 852–854, 2015.\n[9] K. H. Jin, D. Lee, and J. C. Ye, “A general framework for compressed sensing and parallel MRI using annihilating ﬁlter based low-rank\nHankel matrix,” IEEE Transactions on Computational Imaging, vol. 2, no. 4, pp. 480–495, 2016.\n[10] G. Ongie and M. Jacob, “Off-the-grid recovery of piecewise constant images from few Fourier samples,” SIAM Journal on Imaging\nSciences, vol. 9, no. 3, pp. 1004–1041, 2016.\n[11] P. Cao, P. J. Shin, I. Park, C. Najac, I. Marco-Rius, D. B. Vigneron, S. J. Nelson, . Sabrina M. Ronen, and P. E. Z. Larson, “Accelerated\nhigh bandwidth MR spectroscopic imaging using compressed sensing,” Magnetic Resonance in Medicine, vol. 76, no. 2, pp. 369–379,\n2016.\n[12] X. Peng, L. Ying, Y. Liu, J. Yuan, X. Liu, and D. Liang, “Accelerated exponential parameterization of T2 relaxation with model-driven\nlow rank and sparsity priors,” Magnetic Resonance in Medicine, vol. 76, no. 6, pp. 1865–78, 2016.\n[13] J. P. Haldar and J. Zhuo, “P-LORAKS: Low-rank modeling of local k-space neighborhoods with parallel imaging data,” Magnetic resonance\nin medicine, vol. 75, no. 4, pp. 1499–1514, 2016.\n[14] J. C. Ye, J. M. Kim, K. H. Jin, and K. Lee, “Compressive sampling using annihilating ﬁlter-based low-rank interpolation,” IEEE Transactions\non Information Theory, vol. 63, no. 2, pp. 777–801, Feb. 2017.\n[15] G. Ongie and M. Jacob, “A fast algorithm for convolutional structured low-rank matrix recovery,” IEEE transactions on Computational\nImaging, vol. 3, no. 4, pp. 535–550, 2017.\n[16] G. Ongie, S. Biswas, and M. Jacob, “Convex recovery of continuous domain piecewise constant images from nonuniform Fourier samples,”\nIEEE Transactions on Signal Processing, vol. 66, no. 1, pp. 236–250, 2018.\n[17] K. H. Jin, J.-Y. Um, D. Lee, J. Lee, S.-H. Park, and J. C. Ye, “MRI artifact correction using sparse+ low-rank decomposition of annihilating\nﬁlter-based Hankel matrix,” Magnetic Resonance in Medicine, vol. 78, no. 1, pp. 327–340, 2017.\n[18] M. Mani, M. Jacob, D. Kelley, and V. Magnotta, “Multi-shot sensitivity-encoded diffusion data recovery using structured low-rank matrix\ncompletion (MUSSELS),” Magnetic Resonance in Medicine, vol. 78, no. 2, pp. 494–507, 2017.\n[19] B. Bilgic, T. H. Kim, C. Liao, M. K. Manhard, L. L. Wald, J. P. Haldar, and K. Setsompop, “Improving parallel imaging by jointly\nreconstructing multi-contrast data,” Magnetic Resonance in Medicine, vol. 80, pp. 619–632, 2018.\n[20] Y. Hu, X. Liu, and M. Jacob, “A generalized structured low-rank matrix completion algorithm for MR image recovery,” IEEE Transactions\nOn Medical Imaging, 2018.\n[21] S. Poddar, Y. Mohsin, D. Ansah, B. Thattaliyath, R. Ashwath, and M. Jacob, “Free-breathing cardiac MRI using bandlimited manifold\nmodelling,” IEEE Trans. on Computational Imaging, vol. 35, no. 4, pp. 1106–1115, 2018.\n[22] J. P. Haldar and K. Setsompop, “Linear predictability in MRI reconstruction: Leveraging shift-invariant Fourier structure for faster and\nbetter imaging, IEEE Signal Processing Magazine, Special Issue on Computational MRI (this issue), 2020.\n[23] E. Candes and C. Granda, “Towards a mathematical theory of superresolution,” Pure and Applied Mathematics, vol. 67, no. 6, pp. 906–956,\n2014.\n[24] B. Scholkopf and A. J. Smola, Learning with kernels: support vector machines, regularization, optimization, and beyond.\nMIT press,\n2001.\n[25] M. Vetterli, P. Marziliano, and T. Blu, “Sampling signals with ﬁnite rate of innovation,” IEEE Transactions on Signal Processing, vol. 50,\nno. 6, pp. 1417–1428, 2002.\nOctober 12, 2021\nDRAFT\n\n22\n[26] I. Dologlou, D. van Ormondt, and G. Carayannis, “MRI scan time reduction through non-uniform sampling and SVD-based estimation,”\nSignal Processing, vol. 55, no. 2, pp. 207–219, 1996.\n[27] D. Guo, H. Lu, and X. Qu, “A fast low rank hankel matrix factorization reconstruction method for non-uniformly sampled magnetic\nresonance spectroscopy,” IEEE Access, vol. 5, pp. 16 033 – 16 039, 2017.\n[28] H. Nguyen, B. Sutton, R. Morrison, and M. Do, “Joint estimation and correction of geometric distortions for EPI functional MRI using\nharmonic retrieval,” IEEE Trans Med Imaging., vol. 28, pp. 423–34, 2009.\n[29] A. Balachandrasekaran, M. Mani, and M. Jacob, “Calibration-free b0 correction of epi data using structured low rank matrix recovery,”\nIEEE Transactions on Medical Imaging, in press.\n[30] E. Candes, J. Romberg, and T. Tao, “Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency\ninformation,” IEEE Trans. on Information Theory, vol. 52, no. 2, pp. 489–509, Feb. 2006.\n[31] H. Pan, T. Blu, and P. L. Dragotti, “Sampling curves with ﬁnite rate of innovation,” IEEE Transactions on Signal Processing, vol. 62,\nno. 2, pp. 458–471, 2014.\n[32] M. I. Gurelli and C. L. Nikias, “EVAM: An eigenvector-based algorithm for multichannel blind deconvolution of input colored signals,”\nIEEE Transactions on Signal Processing, vol. 43, no. 1, pp. 134–149, 1995.\n[33] M. A. Griswold, P. M. Jakob, R. M. Heidemann, M. Nittka, V. Jellus, J. Wang, B. Kiefer, and A. Haase, “Generalized autocalibrating\npartially parallel acquisitions (GRAPPA),” Magn. Reson. Med, vol. 47, no. 6, pp. 1202–1210, 2002.\n[34] R. Morrisson, M. Jacob, and M. Do, “Multichannel estimation of coil sensitivities in parallel MRI,” IEEE International Symposium on\nBiomedical Imaging, 2007.\n[35] N. Srebro, “Learning with matrix factorizations,” Ph.D. dissertation, Dept. of Elect. Eng., Comput. Sci., Massachusetts Inst. of Technol.,\nCambridge, MA, USA, 2004.\n[36] K. Mohan and M. Fazel, “Iterative reweighted algorithms for matrix rank minimization,” Journal of Machine Learning Research, vol. 13,\nno. Nov, pp. 3441–3473, 2012.\n[37] J. Ye, Y. Han, and E. Cha, “Deep convolutional framelets: A general deep learning framework for inverse problems,” SIAM Journal on\nImaging Sciences, vol. 11, no. 2, pp. 991–1048, 2018.\n[38] J. C. Ye and W. K. Sung, “Understanding geometry of encoder-decoder CNNs,” in Proceedings of the 36th International Conference on\nMachine Learning, ser. Proceedings of Machine Learning Research, K. Chaudhuri and R. Salakhutdinov, Eds., vol. 97.\nLong Beach,\nCalifornia, USA: PMLR, 09–15 Jun 2019, pp. 7064–7073.\n[39] W. Jiang, P. E. Z. Larson, and M. Lustig, “Simultaneous auto-calibration and gradient delays estimation (SAGE) in non-Cartesian parallel\nMRI using low-rank constraints,” Magnetic Resonance in Medicine, vol. 80, pp. 2006–2016, 2019.\n[40] M. Bydder, S. Rapacchi, O. G. O, M. Guye, and J. P. Ranjeva, “Trimmed autocalibrating k-space estimation based on structured matrix\ncompletion.” Magnetic Resonance Imaging, vol. 43, no. 88, pp. 88–94, 2017.\nOctober 12, 2021\nDRAFT",
    "pdf_filename": "Structured Low-Rank Algorithms - Theory, MR Applications, and Links to  Machine Learning.pdf"
}