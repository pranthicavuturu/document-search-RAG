{
    "title": "Recall and Refine: A Simple but Effective Source-free Open-set Domain",
    "abstract": "sumptionofasharedlabelsetbetweenthesourceandtarget Open-setDomainAdaptation(OSDA)aimstoadaptamodel domains (i.e., C = C ), referred to as Closed-set Domain s t fromalabeledsourcedomaintoanunlabeledtargetdomain, Adaptation (Saenko et al. 2010). However, this assumption wherenovelclasses—alsoreferredtoastarget-privateun- isoftenimpracticalinreal-worldscenarios. knownclasses—arepresent.Source-freeOpen-setDomain In contrast, Open-set Domain Adaptation (OSDA) ex- Adaptation(SF-OSDA)methodsaddressOSDAwithoutac- cessing labeled source data, making them particularly rele- tends the target label space beyond that of the source do- vantunderprivacyconstraints.However,SF-OSDApresents main (i.e., C s ⊂ C t) (Saito et al. 2018; Liu et al. 2019), significantchallengesduetodistributionshiftsandtheintro- thereby adding complexity to the DA task. OSDA aims to duction of novel classes. Existing SF-OSDA methods typi- align target samples from known classes with those from callyrelyonthresholdingthepredictionentropyofasample thesourcedomainwhileeffectivelyidentifyingtargetsam- toidentifyitaseitheraknownorunknownclassbutfailto plesbelongingtocategoriesnotobservedinthesourcedo- explicitly learn discriminative features for the target-private main, referred to as unknown classes (Panareda Busto and unknownclasses.WeproposeRecallandRefine(RRDA),a Gall2017;Bucci,Loghmani,andTommasi2020;Jangetal. novel SF-OSDA framework designed to address these lim- 2022). Various criteria based on instance-level predictions itations by explicitly learning features for target-private un- havebeenproposed,includingentropy-based(Feng,Xu,and knownclasses.RRDAemploysatwo-stepprocess.First,we enhancethemodel’scapacitytorecognizeunknownclasses Tao2021;Saitoetal.2020)andconfidence-based(Saitoand by training a target classifier with an additional decision Saenko2021;Fuetal.2020)methods. boundary, guided by synthetic samples generated from tar- Additionally, privacy and legal considerations increas- getdomainfeatures.Thisenablestheclassifiertoeffectively inglylimitaccesstolabeledsourcedataforadaptationpur- separate known and unknown classes. In the second step, poses.Toaddressthis,source-freeadaptationmethods(Fang we adapt the entire model to the target domain, address- et al. 2024) have emerged, enabling adaptation without re- ing both domain shifts and improving generalization to un- lianceonlabeledsourcedata(Kimetal.2021;Kunduetal. knownclasses.Anyoff-the-shelfsource-freedomainadapta- 2020a; Li et al. 2020). In this paper, we focus on Source- tionmethod(e.g.,SHOT,AaD)canbeseamlesslyintegrated into our framework at this stage. Extensive experiments on freeOpen-setDomainAdaptation(SF-OSDA),whereonlya three benchmark datasets demonstrate that RRDA signifi- pre-trainedsourcemodelisavailableforknowledgetransfer, cantlyoutperformsexistingSF-OSDAandOSDAmethods. without access to labeled source data. While some Source- Thesourcecodeispubliclyavailable1. free Domain Adaptation (SF-DA) methods have demon- stratedeffectivenessinaddressingSF-OSDAforclassifica- tiontasks(Liang,Hu,andFeng2020;Yangetal.2022;Wan Introduction etal.2024),semanticsegmentation(Choeetal.2024),and UnsupervisedDomainAdaptation(UDA)(Ben-Davidetal. graphapplications(Wangetal.2024),theyprimarilyfocus 2010;GaninandLempitsky2015;Longetal.2015)adapts on the semantics of known classes in the source domain, amodelfromalabeledsourcedomaintoanunlabeledtarget often overlooking the crucial aspect of novel-class seman- domain(Ozaetal.2023),effectivelyaddressingtheissueof tics.Thesemethodsfocusonsegregatingtargetsampleswith domainshiftwherethesourceandtargetdistributionsdiffer. lowentropy,categorizingthemasknownclasses,andsubse- UDAstrategiestypicallyalignfeaturedistributionsbetween quentlyoptimizingspecificobjectivessuchasentropymini- domainsusingmetriclearningtechniques(Longetal.2015; mizationorclustering.Inthisprocess,datapointsassociated Kangetal.2019)oradversarialtraining(GaninandLempit- withknownclassesareprioritized,whilethosewithhighen- sky2015;Tzengetal.2017;Luoetal.2019),andmorere- tropy are typically excluded from training, leading to a se- cently,self-trainingapproaches(Sunetal.2022;Hoyeretal. manticdisparitybetweentheknownandunknownclasses. 2023;Zhu,Bai,andWang2023).Despitetheirsuccess,most Toeffectivelyadaptapre-trainedsourcemodeltoatarget domainfacingbothcategoryanddistributionshifts,wepro- 1https://github.com/ismailnejjar/RRDA poseRecallandRefineforDomainAdaptation(RRDA)for 4202 voN 91 ]VC.sc[ 1v85521.1142:viXra",
    "body": "Recall and Refine: A Simple but Effective Source-free Open-set Domain\nAdaptation Framework\nIsmailNejjar1,HaoDong2,OlgaFink1\n1E´colePolytechniqueFe´de´raledeLausanne(EPFL),2ETHZu¨rich\nismail.nejjar@epfl.ch,hao.dong@ibk.baug.ethz.ch,olga.fink@epfl.ch\nAbstract currentdomainadaptationapproachesoperateundertheas-\nsumptionofasharedlabelsetbetweenthesourceandtarget\nOpen-setDomainAdaptation(OSDA)aimstoadaptamodel domains (i.e., C = C ), referred to as Closed-set Domain\ns t\nfromalabeledsourcedomaintoanunlabeledtargetdomain,\nAdaptation (Saenko et al. 2010). However, this assumption\nwherenovelclasses—alsoreferredtoastarget-privateun-\nisoftenimpracticalinreal-worldscenarios.\nknownclasses—arepresent.Source-freeOpen-setDomain\nIn contrast, Open-set Domain Adaptation (OSDA) ex-\nAdaptation(SF-OSDA)methodsaddressOSDAwithoutac-\ncessing labeled source data, making them particularly rele- tends the target label space beyond that of the source do-\nvantunderprivacyconstraints.However,SF-OSDApresents main (i.e., C s ⊂ C t) (Saito et al. 2018; Liu et al. 2019),\nsignificantchallengesduetodistributionshiftsandtheintro- thereby adding complexity to the DA task. OSDA aims to\nduction of novel classes. Existing SF-OSDA methods typi- align target samples from known classes with those from\ncallyrelyonthresholdingthepredictionentropyofasample thesourcedomainwhileeffectivelyidentifyingtargetsam-\ntoidentifyitaseitheraknownorunknownclassbutfailto plesbelongingtocategoriesnotobservedinthesourcedo-\nexplicitly learn discriminative features for the target-private\nmain, referred to as unknown classes (Panareda Busto and\nunknownclasses.WeproposeRecallandRefine(RRDA),a\nGall2017;Bucci,Loghmani,andTommasi2020;Jangetal.\nnovel SF-OSDA framework designed to address these lim-\n2022). Various criteria based on instance-level predictions\nitations by explicitly learning features for target-private un-\nhavebeenproposed,includingentropy-based(Feng,Xu,and\nknownclasses.RRDAemploysatwo-stepprocess.First,we\nenhancethemodel’scapacitytorecognizeunknownclasses Tao2021;Saitoetal.2020)andconfidence-based(Saitoand\nby training a target classifier with an additional decision Saenko2021;Fuetal.2020)methods.\nboundary, guided by synthetic samples generated from tar- Additionally, privacy and legal considerations increas-\ngetdomainfeatures.Thisenablestheclassifiertoeffectively inglylimitaccesstolabeledsourcedataforadaptationpur-\nseparate known and unknown classes. In the second step,\nposes.Toaddressthis,source-freeadaptationmethods(Fang\nwe adapt the entire model to the target domain, address-\net al. 2024) have emerged, enabling adaptation without re-\ning both domain shifts and improving generalization to un-\nlianceonlabeledsourcedata(Kimetal.2021;Kunduetal.\nknownclasses.Anyoff-the-shelfsource-freedomainadapta-\n2020a; Li et al. 2020). In this paper, we focus on Source-\ntionmethod(e.g.,SHOT,AaD)canbeseamlesslyintegrated\ninto our framework at this stage. Extensive experiments on freeOpen-setDomainAdaptation(SF-OSDA),whereonlya\nthree benchmark datasets demonstrate that RRDA signifi- pre-trainedsourcemodelisavailableforknowledgetransfer,\ncantlyoutperformsexistingSF-OSDAandOSDAmethods. without access to labeled source data. While some Source-\nThesourcecodeispubliclyavailable1. free Domain Adaptation (SF-DA) methods have demon-\nstratedeffectivenessinaddressingSF-OSDAforclassifica-\ntiontasks(Liang,Hu,andFeng2020;Yangetal.2022;Wan\nIntroduction\netal.2024),semanticsegmentation(Choeetal.2024),and\nUnsupervisedDomainAdaptation(UDA)(Ben-Davidetal. graphapplications(Wangetal.2024),theyprimarilyfocus\n2010;GaninandLempitsky2015;Longetal.2015)adapts on the semantics of known classes in the source domain,\namodelfromalabeledsourcedomaintoanunlabeledtarget often overlooking the crucial aspect of novel-class seman-\ndomain(Ozaetal.2023),effectivelyaddressingtheissueof tics.Thesemethodsfocusonsegregatingtargetsampleswith\ndomainshiftwherethesourceandtargetdistributionsdiffer. lowentropy,categorizingthemasknownclasses,andsubse-\nUDAstrategiestypicallyalignfeaturedistributionsbetween quentlyoptimizingspecificobjectivessuchasentropymini-\ndomainsusingmetriclearningtechniques(Longetal.2015; mizationorclustering.Inthisprocess,datapointsassociated\nKangetal.2019)oradversarialtraining(GaninandLempit- withknownclassesareprioritized,whilethosewithhighen-\nsky2015;Tzengetal.2017;Luoetal.2019),andmorere- tropy are typically excluded from training, leading to a se-\ncently,self-trainingapproaches(Sunetal.2022;Hoyeretal. manticdisparitybetweentheknownandunknownclasses.\n2023;Zhu,Bai,andWang2023).Despitetheirsuccess,most Toeffectivelyadaptapre-trainedsourcemodeltoatarget\ndomainfacingbothcategoryanddistributionshifts,wepro-\n1https://github.com/ismailnejjar/RRDA poseRecallandRefineforDomainAdaptation(RRDA)for\n4202\nvoN\n91\n]VC.sc[\n1v85521.1142:viXra\nrobustSF-OSDA.RRDAemploysatwo-stepstrategy.First, supervised tasks such as rotation recognition for unknown\nweproposetoleveragethesemanticsoftheunknownclasses class detection. (Jing et al. 2021) project features to a hy-\nbyintroducinganoveltargetclassifierwithK+K′decision perspherical latent spaceto reject known samples based on\nboundaries.TheseboundariesextendtheKclassesfromthe angular distance. Adjustment and Alignment for Unbiased\nsource domain with K′ additional classes for the unknown Open Set Domain Adaptation (ANNA) (Li et al. 2023) ad-\ncategories.Toachievethis,syntheticsamplesaregenerated dresses semantic-level bias in OSDA by designing Front-\ninthefeaturespacefromtargetdomainfeatures.Thesesyn- Door Adjustment and Decoupled Causal Alignment mod-\ntheticpointsareoptimizedtoexhibitlowentropyforknown ules.However,theseapproachesallassumetheavailability\nclasses and high entropy for unknown classes, which are oflabeledsourcedata,whichcanposechallengesduetopri-\nthen clustered into K′ categories. The synthetic data are vacyconcernsinrealapplications.\nused to refine the decision boundaries of the source clas-\nSource-freeDomainAdaptation(SFDA)leveragesonlya\nsifier,enablingthetargetclassifiertoaccommodatetheun-\nsource-trained model and unlabeled target data for adapta-\nknownclasses.Inthesecondstep,anyoff-the-shelfsource-\ntiontothetargetdomain.SFDAapproachescanbecatego-\nfree domain adaptation method (e.g., SHOT (Liang, Hu,\nrized into data-based and model-based methods (Yu et al.\nandFeng2020),AaD(Yangetal.2022))canbeintegrated\n2023). One of the data-driven methods, SHOT, was intro-\ninto our framework to adapt the entire model to the target\nducedbyLiangetal.(Liang,Hu,andFeng2020).Itadaptsa\ndomain. RRDA directly learns to classify target unknown\nclasses.TheframeworkintroducesK′asahyper-parameter, pre-trainedsourcemodelviainformationmaximizationwith\nwhichwesettoK′ = K forsimplicity.Sensitivityanalysis self-supervisedpseudo-labelingtoimplicitlyaligntargetdo-\nshowsthatperformanceimproveswithhighervaluesofK′, main representations to the source hypothesis. Building on\nthisapproach,subsequentworks(Chuetal.2022;Leeetal.\nthoughresultsremainrobustacrossarangeofsettings.Ex-\n2022; Qu et al. 2022) refine the adaptation through self-\ntensiveexperimentsonthreeSF-OSDAbenchmarkdatasets\ntraining techniques. Other works explore different training\ndemonstratetheeffectivenessofourapproach,significantly\nprocedures. For example, historical Contrastive Learning\noutperformingexistingmethods.\n(HCL) (Huang et al. 2021) compensates for the absence of\nRelatedWork sourcedatabyleveraginghistoricalmodelsandcontrasting\ncurrent and historical embeddings of target samples. Some\nUnsupervisedDomainAdaptation(UDA)aimstoadapta\nmethods (Yang et al. 2021, 2022) enforce consistency be-\nmodeloriginallytrainedonalabeledsourcedomaintoper-\ntween local neighbors by considering local feature density,\nformeffectivelyinanunlabeledtargetdomain.Thisadapta-\nwith Attract and Disperse (AaD) (Yang et al. 2022) treat-\ntionprocessassumesaccesstodatafromboththesourceand\ningSFDAasanunsupervisedclusteringproblem.Addition-\ntargetdomainsduringtraining(Ozaetal.2023).UDAstrate-\nally,Zhang,Wang,andHe(2023)exploreleveragingsource\ngiesoftenalignfeaturedistributionsbetweendomainsusing\nmodelclassifierweightsasclassprototypestoembedclass\nmetric learning techniques (Long et al. 2015; Kang et al.\nrelationshipsintoasimilaritymeasureforatargetsample.\n2019; Nejjar, Wang, and Fink 2023) or adversarial training\nacross various spaces, including image input space (Murez Source-free Open-set Domain Adaptation (SF-OSDA)\net al. 2018; Pizzati et al. 2020), feature space (Ganin and extendsSFDAtoscenarioswherethetargetdomaincontains\nLempitsky2015),andoutputspace(Luoetal.2019;Vuetal. novelclassesnotpresentinthesourcedomain.Whilemeth-\n2019).Additionally,varioustechniquesincorporatepseudo- odslikeSHOT(Liang,Hu,andFeng2020),AaD(Yangetal.\nlabeling or self-training algorithms (Sun et al. 2022; Dong 2022),andUncertainty-guidedSource-freeDomainAdapta-\net al. 2023; Yue, Sun, and Zhang 2024), which generate tion(U-SFAN) (Royetal.2022)havebeenadaptedforSF-\npseudo-labels for unlabeled samples in the target domain. OSDA,theyprimarilyfocusontheknownclasssemanticsin\nHowever, existing approaches assume that label spaces are the source domain, which can lead to suboptimal handling\nidenticalacrossbothdomains,limitingtheirapplicabilityin oftarget-privateunknownclasses.UniversalDomainAdap-\nreal-worldscenarios. tation (UniDA) aims to handle domain shifts and label set\nOpen-set Domain Adaptation (OSDA) addresses scenar- differencesbetweensourceandtargetdomains,encompass-\nioswherethetargetdomainmaycontainclassesnotpresent ingopen,partial,andopen-partialsetscenarios(Liangetal.\ninthesourcedomain(PanaredaBustoandGall2017;Dong, 2021; Qu et al. 2023, 2024). Recent SF-UniDA methods\nChatzi, and Fink 2024; Dong et al. 2024; Li et al. 2021). proposed one-vs-all clustering approaches (Qu et al. 2023)\nVariousapproacheshavebeenproposedtotacklethischal- and subspace decomposition (Qu et al. 2024) to separate\nlenge, including assigning target domain images to source andidentifycommonandprivatetargetclassesinasource-\ncategories while discarding unrelated target domain im- freesetup.Similarly,ProgressiveGraphLearning(Luoetal.\nages (Panareda Busto and Gall 2017), and using adver- 2023) decomposes the target hypothesis space into shared\nsarial training to separate unknown target samples (Saito and unknown subspaces for SF-OSDA. However, current\net al. 2018; Jang et al. 2022). Separate to Adapt (STA) ap- methodseitherrequirespecifictrainingforthesourcemodel\nproach (Liu et al. 2019) progressively separates unknown toincorporatetheunknownclasses(Kunduetal.2020b,c),\nand known class samples using a coarse-to-fine weighting whichisusuallyimpractical,orrelyonthresholdingamet-\nmechanism and proposes evaluating OSDA on diverse lev- ric to distinguish known classes from unknown ones dur-\nels of openness. Rotation-based Open Set (ROS) (Bucci, ing training and inference, making the prediction sensitive\nLoghmani, and Tommasi 2020) explores the use of self- todifferentthresholds.\n(a) Projected Target feature on the source (b) Optimisation of synthetic points to show\nclassifier low/high entropy\n(1) Source Domain Pre-training\nSource Domain\nWeight initlization\n(c) Train a new target classifier with the synthetic\npoints\nUnlabelled target domain (known\n(2) Target adapation\nand unknown classes)\nTarget Domain\nSynthetic data points\nFigure1:OverviewofRRDAforSource-freeOpen-setAdaptation.Unlikeconventionalmethodsthatoverlookunknownclass\nsemantics,RRDAexplicitlyincorporatesthisinformationbygeneratingsyntheticpointsforbothknownandunknownclasses\nfrom projected target features, enabling the training of a new target classifier that captures the semantics of all classes. The\nadaptationisthenachievedusingstandardclosed-setdomainadaptationmethods.\nMethodology source pre-trained model to a target domain, even in the\npresenceofnovelclasses.Motivatedbytheideathatlearn-\nPreliminary\ning from unknown class samples can improve performance\nForSF-OSDA,wearegivenasourcepre-trainedmodelfs inopen-setscenarios,ourobjectiveistosimplifyadaptation\nθ\nand an unlabeled target domain with n samples, denoted and eliminate the dependency on threshold-based methods\nt\nas D = {(xt)}nt , where xt ∈ X ⊂ RX. The target do- duringinference.\nt i i=1 i\nmainfollowsadistinctdatadistribution(Pt ̸=Ps)fromthe\nsource domain, reflecting both distribution and label shifts. RRDA\nLet Cs and Ct ⊂ Y represent the label sets for the source Our proposed Recall and Refine framework for SF-OSDA\nand target domains, respectively, where Cs ⊂ Ct. Both do- consistsofthreemainsteps:\nmainsshareK commonclassesreferredtoasknownclasses\n(Ct = Cs).Additionally,thetargetdomainincludestarget- 1. SyntheticDataGeneration:Referringtostep(b)inFig-\nk ure 1, synthetic feature points are generated for both\nprivatenovelclasses,jointlyconsideredasasingleunknown\nclass(Ct =Ct\\Cs). known and unknown classes. This involves optimizing\nunk targetfeaturerepresentationsusingentropyobjectives.\nTheprimaryobjectiveofSF-OSDAistoclassifybothun-\nknown and known classes, relying exclusively on the tar- 2. TargetClassifierTraining:Referringtostep(c)inFig-\nget domain data and a pre-trained source model. The pre- ure1,thesyntheticfeaturepointsareusedtotrainanew\ntrained model can be decomposed as fs = hs ◦gs, where targetclassifiergt withextendeddecisionboundariesto\nθ θ θ θ\nhs : RX → RD isafeatureextractorandgs : RD → RK accommodateunknownclasses.\nθ θ\nisthesourceclassifier.Unlikepreviousworks,whichfreeze 3. Target Domain Adaptation: The entire model is\nthesourceclassifier(e.g.,SHOT)duringadaptation,wepro- adaptedusinganyoff-the-shelfsource-freedomainadap-\nposetraininganewtargetclassifiergt toexplicitlyaccount tationmethods(e.g.,SHOT,AaD)ontargetdomaindata.\nθ\nfortarget-privateunknownclasses.\nThis allows the model to (1) learn the semantics of both\nOne of the challenges in open-set scenarios is the abil-\nknown and unknown classes in the target domain, (2) treat\nitytodistinguishknownfromunknownclassesinthetarget\nOSDAasasimpleclosed-setscenario,and(3)directlyout-\ndomain. Different approaches have been proposed for dis-\nputpredictionsforunknownclasses.\ntinguishingbetweenknownandunknownclasses,including\nhand-crafted thresholding criteria and clustering strategies. Synthetic Data Generation. The first step of our pro-\nHowever, paradigms such as vendor-to-client (Kundu et al. posed approach involves generating synthetic features for\n2020c) are more effective, as they incorporate an auxiliary bothknownandunknownclassesusingthesourceclassifier\nout-of-distributionclassifierduringsourcetraining,enabling gs. Specifically, we optimize the target feature representa-\nθ\nbetterhandlingofunknownclassesinthetargetdomain. tionzt = hs(xt)togeneratesyntheticsamplesthatexhibit\nθ\nInthispaper,weproposeanovelapproachtoaddressthis lowentropyforknownclassesandhighentropyfortheun-\nlimitation by adapting the source classifier post hoc to in- known class. We denote these optimized synthetic features\nclude new decision boundaries for unknown classes. Our as z∗t and z∗t . The unknown features are then clustered\nk unk\nmethodenablestheseamlessadaptationofanyoff-the-shelf in K′ classes, and a new target classifier gt is introduced\nθ\nwithK+K′classes.Inthissection,wedescribetheprocess K isthenumberofknownclassesandK′ isthenumberof\nforobtainingfeaturerepresentationsforbothknownandun- unknownclasses.Theweightsfortheknownclassesgt\nknown classes. We use standard gradient descent optimiza- areinitializedusingthesourceclassifier’sweightsgs,wθ[ h1: iK le]\nθ\ntiontogeneratethedesiredfeaturerepresentations. the weights for the unknown classes gt are ran-\nSyntheticUnknownClassesGeneration:Toeffectively θ [K+1:K+K′]\ndomlyinitialized.Thetargetclassifiergt istrainedusingthe\nidentify points near the source classifier’s decision bound- θ\nsyntheticfeature-labelpairsfortheknownclasses(z∗t,yˆ∗t)\nary, we aim to find z∗t that maximizes entropy while en- k k\nunk for k ∈ {1,...,K}, and the unknown classes (z∗t , yˆ∗t ).\nsuringdiversefeaturerepresentations,therebyreducingthe unk unk\nThesupervisedtrainingobjectiveisdefinedas:\nriskofcollapsingtoasingle-pointrepresentation.Toprevent\nfeaturecollapse,weintroduceavarianceregularizationterm min L (gt(z∗t),yˆ∗t), (3)\nintheformofahingefunctionappliedtothestandarddevia- CE θ\nθ\ntionoffeaturesacrossthebatchdimension.Specifically,we where z∗t represents the combined synthetic features for\ninitializetheoptimizationwithanoisyversionoftheorigi- both known and unknown classes, and yˆ∗t represents their\nnalfeatureszt.Thisprocessisformulatedasfollows:\ncorresponding labels. The results of the previous steps, in-\ncludingtherefineddecisionboundariesachievedbyRRDA,\nmin −H(σ(gs(zt)))+λ·max(0,1−(cid:112) Var(zt)), (1) areillustratedinFigure2.\nθ\nzt\nTarget Domain Adaptation. Any source-free unsuper-\nwhere H(p) = −(cid:80)K p log(p ) represents the entropy, vised domain adaptation method (originally designed for\nk=1 k k\nand σ is the softmax activation function, and λ was set closed-set scenarios) can be integrated into our approach\nto 1 for all the experiments. After optimization, only the to address open-set scenarios, provided it incorporates a\npoints satisfying H(gs(z)) > 0.75·log(K) (see Ablation diversity loss or a similar mechanism to facilitate self-\nθ\nsection for threshold discussion) are considered as z∗t . learning of unknown classes. To empirically validate this\nunk\nThe selected features z∗t are then clustered into K′ un- hypothesis, we consider SHOT (Liang, Hu, and Feng\nunk\nknown classes using K-means. Each cluster is assigned a 2020) and AaD (Yang et al. 2022), using their respective\npseudo-label corresponding to a new class index, yˆ∗t ∈ training objectives for adaptation. SHOT (Liang, Hu, and\nunk\n{K + 1,...,K + K′}, representing the specific unknown Feng 2020) employs information maximization and self-\nclassassignedtothesyntheticfeatures.Thesesyntheticfea- supervisedpseudo-labelingtoadaptthesourcemodeltothe\ntures and their associated pseudo-labels (z∗t , yˆ∗t ) will targetdomain.Itsobjectivefunctioncanbeexpressedas:\nunk unk\nbe used in the subsequent training of the target classifier.\nThisapproachismotivatedbytheobservationinthelitera- L =− λ ent\n(cid:88)nt K (cid:88)+K′\np logp +λ\n·K (cid:88)+K′\np¯ logp¯\nture(Lampert,Nickisch,andHarmeling2009)thatitispos- shot n k,i k,i div k k\nt\nsibletogeneratemeaningfulsemanticsfornovelclassesus- i=1 k=1 k=1\n+λ ·L ,\ningknownclasses. ps pseudo\nSynthetic Known Classes Generation: A similar opti- where p¯ = 1 (cid:80)nt p (x ;θ), and L is the pseudo-\nmization approach is employed to generate synthetic data k nt i=1 k i pseudo\nlabeling loss function from (Liang, Hu, and Feng 2020).\npointsfortheknownclasses.Theoptimizationisperformed\nDuringadaptation,onlythefeatureencoderisupdatedwhile\niteratively K times, once for each known class k (where\ntheclassifierremainsfrozen.AaD(Yangetal.2022)lever-\nk ∈ [1,...,K]). The objective is to minimize the cross-\nageslocalconsistencyandglobaldispersion.Theobjective\nentropy for each class directly from zt. The optimization\nfunctionforfeatureiisformulatedas:\nproblemforgeneratingasampleforclasskisdefinedas:\n(cid:88) (cid:88)\nL =− pTp +λ pTp ,\nAaD,i i j i m\nmin L (gs(zt),I )+λ·max(0,1−(cid:112) Var(zt)), (2) j∈Ci m∈Bi\nCE θ k\nzt whereC representsthelocalneighborhoodoffeatureiand\ni\nwhere I k is the identity function for the k-th class (i.e., a B i is the mini-batch feature not in C i. Unlike SHOT, AaD\none-hot vector), and λ controls the regularization term, set updatestheentiremodelweightsduringadaptation.\nto 1 in all experiments. After optimization, only the points\nsatisfying L (gs(z),I ) < 0.25 · log(K) (see Ablation Experiments\nCE θ k\nsectionforthresholddiscussion)areconsideredasz∗ kt.Each\nExperimentalSetup\nselected synthetic feature z∗t is assigned the pseudo-label\nk Datasets. Office-Home (Venkateswara et al. 2017) com-\nyˆ∗t = k, forming the pairs (z∗t,yˆ∗t). These synthetic data\nk k k prises 65 labeled image categories from four distinct do-\npoints and their corresponding pseudo-labels are then used\nmains:Art(Ar),Clipart(Cl),Product(Pr),andRealWorld\nto train the target classifier. By iteratively generating fea-\n(Rw).Wedesignatethefirst25alphabeticallyorderedcate-\nture points for each known class, our method enhances the\ngoriesasknownclasses,withtheremaining40asunknown.\ndecisionboundarieswithoutrequiringaccesstotheoriginal\nOffice-31(Saenkoetal.2010)consistsof31classesacross\nsourcedataorlabels.\nthreedomains:Amazon(A),Dslr(D),andWebcam(W).We\nTarget Classifier Training. In the second step, we intro- assign the first 10 as known and the last 10 classes as un-\nduceanewtargetclassifiergt withK +K′ classes,where known.VisDA(Pengetal.2017)have12categoriesacross\nθ\n6 6 6\n4 4 4\n2 2 2\n0 0 0\nSynthetic point Class 0\n2 2 Synthetic point Class 1 2\nTarget-shared classes 0 Synthetic point Class 2 Target-shared classes 0\n4 Target-shared classes 1 4 Outlier Class 0 4 Target-shared classes 1\nTarget-shared classes 2 Outlier Class 1 Target-shared classes 2\n6 Target-private classes 6 Outlier Class 2 6 Target-private classes\n6 4 2 0 2 4 6 6 4 2 0 2 4 6 6 4 2 0 2 4 6\nFeature 1 Feature 1 Feature 1\n(a) Unlabeled target domain projected (b)Optimizedsyntheticpointsforknown (c) Unlabeled target domain projected\nonto the decision boundary of the source andunknownclasses. ontothenewdecisionboundaryofthetar-\nclassifier. getclassifier.\nFigure 2: Visualization of the synthetic data generation process and the resulting target classifier boundary on a toy example\nwithK =K′ =3classes.\ntwodomains:Real(R)andSynthetic(S).Thefirst6classes Methods SF Office-31\narecategorizedasknownandtheremaining6asunknown. A2D A2W D2A D2W W2A W2D Avg\nEvaluation Metrics. To assess model performance, we CMU ✗ 52.6 55.7 76.5 75.9 65.8 64.7 65.2\nadopt standard evaluation metrics widely used in previous DANCE ✗ 84.9 78.8 79.1 78.8 68.3 78.8 79.8\nOSDA studies (Bucci, Loghmani, and Tommasi 2020; Liu OSLPP ✗ 91.5 89.0 79.3 92.3 78.7 9..6 87.4\nGATE ✗ 88.4 86.5 84.2 95.0 86.1 96.7 89.5\netal.2019;Lietal.2023).TheHarmonicOpen-set(HOS) ANNA ✗ 83.8 85.5 82.5 99.5 81.6 98.4 88.6\naccuracy balances performance on known and unknown\nclasses and can be calculated as HOS = 2× OO SS ∗+∗× UU NN KK, S Uo Mur Ace D-only ✓ ✓ 7 88 8. .2 5 7 82 4. .1 4 4 84 6. .2 8 8 92 5. .2 0 5 82 8. .1 2 8 98 5. .8 9 6 89 9. .6 8\nwhere OS∗ represents the accuracy of known classes, LEAD ✓ 84.9 85.1 90.9 94.8 90.3 96.5 90.3\nand UNK denotes the accuracy of unknown classes. The GLC ✓ 82.6 74.6 92.6 96.0 91.8 96.1 89.0\nHOSmetricprovidesacomprehensivemeasure,byequally AaD-O ✓ 82.3 79.0 84.3 93.1 84.8 95.0 86.4\nweightingthemodel’sabilitytoclassifyknownclassesand AaD+RRDA ✓ 91.1 94.3 94.1 96.6 94.0 96.2 94.4\n+8.8 +15.3 +9.8 +3.5 +9.2 +1.2 +8.0\ndetectunknownclasses.\nImplementationDetails.Allexperimentsareconductedon SHOT-O ✓ 89.5 83.0 85.9 91.4 84.0 95.2 88.2\nasingleA100GPUusingPyTorch.Forsyntheticdatagen- SHOT+RRDA ✓ 90.0 92.2 92.6 98.2 91.6 98.2 93.8\n+0.5 +9.2 +6.7 +6.8 +7.6 +3.0 +5.6\neration,weemploytheAdamoptimizerwithalearningrate\nof0.001for1000steps,forbothknown(z∗t)andunknown\nk Table 1: HOS (%) results on Office-31 (ResNet-50). SF\n(z∗t )classes.Inallmainexperiments,wesetK′ =K.To\nunk denotes source-free methods. AaD-O and SHOT-O are the\nmaintain class balance, we cap the sample size at 1000 for\nadapted open-set methods of AaD and SHOT. RRDA uses\nknown classes in Office-Home and Office-31, and 10,000\nstandardAaDandSHOTversions(closed-setscenario).\nforVisDA.Thetargetclassifieristrainedfor50epochsus-\ning SGD with a learning rate of 0.01, momentum of 0.9,\nweightdecayof0.001,andafixedbatchsizeof128.During\n[K +1,K +K′]areaggregatedintoasingleK +1class,\ntargetmodeladaptation,weuseSGDwithmomentum0.9,\nrepresentingtheunknownclass.\nabatchsizeof64,andtrainfor50epochs.Thelearningrate\nBaselines.Wecompareourmethodagainstopen-setdomain\nis set to 0.001 for Office-31 and Office-Home, and 0.0001\nadaptation approaches, including both non-source-free and\nforVisDA,whenusingResnet-50(Heetal.2016)asback-\nsource-free methods. The non-source-free methods include\nbone.WhenusingViT-B(Wuetal.2020)asthebackbone,\nOSBP(Saitoetal.2018),CMU(Fuetal.2020),STA(Liu\nwe set the learning rate to 0.0001 for all experiments. For\netal.2019),DANCE(Saitoetal.2020),GATE(Chenetal.\nSHOT,wefreezethetargetclassifierandtrainonlythefea-\n2022), ANNA (Li et al. 2023), and OSLPP (Wang, Meng,\ntureextractorandbackbone.ForAaD,allmodelparameters\nand Breckon 2024). For source-free methods, we consider\nare trained, with the feature extractor’s learning rate set to\nUMAD(Liangetal.2021),GLC(Quetal.2023),SF-PGL\n10timeslower.Duringinference,samplesbelongingtothe\n(Luoetal.2023),andLEAD(Quetal.2024).\nnewK′ classesareconsideredunknowntargetsamples.λ\nps\nwassetto0.1,0.3,and0.4forOffice-Home,Office-31,and\nExperimentalResults\nVisDA respectively. The hyper-parameters λ and λ were\ndiv\nsetto1andλ wassetto0.5inallourexperiments. From Table 1 to 3, we compare our method against state-\nent\nDuring inference, samples assigned to any of the new of-the-art (SOTA) OSDA methods in both source-free and\nK′ classes are treated as unknown target samples. Follow- non-source-freesetups.Weincludenon-SFmethodstopro-\ning the standard open-set protocol, predictions in the range vide a comprehensive performance benchmark, despite our\n[1,K] correspond to known classes, while predictions in focus on SF scenarios. We use RRDA alongside AaD and\n2\nerutaeF\n2\nerutaeF\n2\nerutaeF\nOffice-Home\nMethods SF\nAr2Cl Ar2Pr Ar2Rw Cl2Ar Cl2Pr Cl2Rw Pr2Ar Pr2Cl Pr2Rw Rw2Ar Rw2Cl Rw2Pr Avg\nCMU ✗ 55.0 57.0 59.0 59.3 58.2 60.6 59.2 51.3 61.2 61.9 53.5 55.3 57.6\nDANCE ✗ 6.5 9.0 9.9 20.4 10.1 9.2 28.1 15.8 12.6 14.2 7.9 13.7 12.9\nOSLPP ✗ 61.0 72.8 74.3 60.9 66.9 70.4 63.6 59.3 74.0 67.2 59.0 74.4 67.0\nGATE ✗ 63.8 70.5 75.8 66.4 67.9 71.7 67.3 61.3 76.0 70.4 61.8 75.4 69.0\nANNA ✗ 69.0 73.7 76.8 64.7 68.6 73.0 66.5 63.1 76.6 71.3 65.7 78.7 70.7\nSource-only ✓ 46.1 63.3 72.9 42.8 54.0 58.7 47.8 36.1 66.2 60.8 45.3 68.2 55.2\nUMAD ✓ 59.2 71.8 76.6 63.5 69.0 71.9 62.5 54.6 72.8 66.5 57.9 70.7 66.4\nLEAD ✓ 60.7 70.8 76.5 61.0 68.6 70.8 65.3 59.8 74.2 64.8 57.7 75.6 67.2\nGLC ✓ 65.3 74.2 79.0 60.4 71.6 74.7 63.7 63.2 75.8 67.1 64.3 77.8 69.8\nAaD-O ✓ 58.0 68.2 75.4 58.8 65.7 69.0 54.6 52.9 72.3 65.8 56.3 72.2 64.1\nAaD+RRDA ✓ 61.7 72.8 73.5 59.0 74.9 69.9 59.5 58.3 71.2 64.5 64.8 73.2 66.9\n+3.7 +4.6 -1.9 +0.2 +9.2 +0.9 +4.9 +5.4 -1.1 -1.3 +7.7 +1.0 +2.8\nSHOT-O ✓ 57.2 65.4 69.9 58.1 62.6 64.3 60.5 52.8 71.1 64.4 53.5 40.6 61.9\nSHOT+RRDA ✓ 64.6 74.2 77.2 63.1 71.4 71.3 67.7 59.1 76.7 70.2 67.4 76.7 70.0\n+7.4 +8.8 +7.3 +5.0 +8.8 +7.0 +7.2 +6.3 +5.6 +5.8 +13.9 +36.1 +8.1\nSource-only ✓ 57.1 69.5 79.9 50.2 62.5 66.0 52.2 45.7 75.1 69.3 56.4 73.7 63.1\nLEAD ✓ 58.6 74.7 82.7 58.9 74.6 74.3 59.0 47.1 78.3 71.9 58.7 77.4 68.0\nAaD-O ✓ 57.8 74.9 82.7 53.9 68.6 70.8 52.5 45.8 76.8 70.6 58.2 77.7 65.9\nAaD+RRDA ✓ 67.4 77.2 81.2 71.4 71.5 76.1 73.9 63.8 78.5 74.8 67.5 75.0 73.2\n+9.6 +1.5 -1.5 +17.5 +2.9 +5.3 +21.4 +18.0 +1.7 +4.2 +9.3 -2.7 +7.3\nSHOT-O ✓ 63.6 73.5 81.7 66.7 69.8 75.5 66.5 56.2 79.0 73.5 62.6 74.6 70.3\nSHOT+RRDA ✓ 68.9 75.0 81.4 71.2 73.8 73.6 71.9 60.4 79.2 76.5 66.2 77.5 73.0\n+5.3 +1.5 -0.3 +4.5 +4.0 -2.1 +5.4 +4.2 +0.2 +3.0 +3.6 +2.9 +2.7\nTable2:HOS(%)resultsonOffice-Home(ResNet-50andViT).|C |=25,|C |=65.SFdenotessource-freemethods.\ns t\nMethods VisDA ilarly, SHOT+RRDA reaches 93.8%, representing a 5.6%\nBic Bus Car Mot Tra Tru UNK HOS improvementoverSHOT-O.Theseresultssurpassall com-\nOSBP 35.6 59.8 48.3 76.8 55.5 29.8 81.7 62.7 paredsource-freeandnon-source-freeSOTAmethods.\nSTA 50.1 69.1 59.7 85.7 84.7 25.1 82.4 71.0 Office-Home.OntheOffice-Homedataset(Table2),RRDA\nSource-only 16.3 7.9 24.9 48.0 6.1 0.0 72.7 27.9 consistently enhances the performance of both AaD-O and\nLEAD 83.5 65.2 57.7 35.7 82.1 79.5 82.7 74.2 SHOT-Oacrossmostdomainadaptationtasks.AaD+RRDA\nSF-PGL 91.5 90.1 74.1 90.3 81.9 74.8 72.0 77.4\nand SHOT+RRDA show average HOS improvements of\nAaD-O 86.8 69.8 51.5 38.7 84.3 26.0 65.5 62.4 +2.8% and +8.1% respectively. SHOT+RRDA achieves\nAaD+RRDA 96.0 85.7 34.5 37.6 92.2 46.4 71.7 68.4\na competitive 70.0% average HOS, outperforming most\n+9.2 +15.9-17.0 -1.1 +7.9+20.4 +6.2 +6.0\nmethods, including both source-free and non-source-free\nShot-O 82.1 67.0 78.6 57.3 72.2 17.9 50.7 56.0\napproaches, while falling just slightly short of ANNA a\nShot+RRDA 88.6 82.2 66.8 47.3 87.2 74.3 83.5 78.7\n+6.5 +15.2 -11.8-10.0+15.0+56.4 +32.8 +22.7 non-source-free adaptation method. A similar observation\ncan be made when using ViT as backbone, where RRDA\nSource-only 62.3 17.9 17.7 50.7 0.0 0.6 90.8 39.1 consistently improves previous methods AaD+RRDA and\nLEAD 87.6 65.3 49.8 30.5 70.9 54.4 98.2 74.3\nSHOT+RRDAshowaverageHOSimprovementsof+7.3%\nAaD-O 87.9 77.6 47.7 36.8 61.2 16.6 67.6 60.4 and+2.7%respectively,andsurpasstheotherbaselines.\nAaD+RRDA 98.2 91.1 84.8 39.4 94.2 97.5 81.7 82.9\nVisDA.OnthechallengingVisDAdataset(Table3),RRDA\n+10.3+13.5+37.1+2.6+33.0+80.9+14.1 +22.5\ncontinuestodemonstrateitseffectiveness.AaD+RRDAim-\nShot-O 96.7 77.0 80.4 75.9 3.0 4.7 80.1 66.1\nproves upon AaD-O by +6.0% in HOS, significantly im-\nShot+RRDA 95.4 84.8 74.1 48.7 85.1 82.3 79.3 78.9\n-1.3 +7.8 -6.3 -27.2+82.1+77.6 -0.8 +12.8 provingunknownsamplerecognitionandoverallclassaccu-\nracy.Significantimprovementsareobservedinclassessuch\nTable3:Accuracyforeachclass(%)andHOS(%)results as”Bus”(+15.9%)and”Truck”(+20.4%).Similarimprove-\nonVisDA(ResNet-50andViT),with|C s|=6,|C t|=12. mentscanbeobservedwhenapplyingRRDAtoSHOTwith\nan improvement of +22.7% in HOS. We observe that both\nSHOT(vanillamethodsforclosed-setscenarios),aswellas methods improve over the same class and degrade the per-\ntheiropen-setvariantsdenotedasAaD-OandSHOT-Othat formancesofthe”car”and”motorcycles”classes.\nrely on entropy-thresholding during training and inference. These results demonstrate RRDA’s consistent superior-\nResultsforcomparisonmethodsaresourcedfrom(Quetal. ityacrossvariousdomainadaptationscenarios.Ourmethod\n2024;Lietal.2023),andthemeanHOSisreported. significantly improves existing SF-OSDA techniques, as\nOffice-31.Table1presentsresultsontheOffice-31dataset, evidenced by the consistent performance gains across all\nwhere RRDA demonstrates significant improvements over datasets. The key advantage of RRDA lies in its novel ap-\nthreshold-basedmethods.AaD+RRDAachievesanaverage proachtohandlingunknownclasses.Unlikepreviousmeth-\nHOSof94.4%,whichisan8.0%increaseoverAaD-O.Sim- ods that rely on thresholding and discard unknown class\n05-teNseR\nTiV\n05-teNseR\nTiV\nEntropy Diversity OS* UNK HOS we report results using T = 0.25 throughout the experi-\n95.6 79.8 86.5 ments.Thisthresholdprovidesabalancebetweenmaintain-\n✓ 95.0 91.8 93.4 ingsufficientclassrepresentationandachievingcompetitive\n✓ ✓ 95.8 91.9 93.8 performance, particularly in scenarios with significant do-\nTable4:Ablationontheoptimizationobjectivetogenerate mainshifts.\nsyntheticpoints.ResultsusingSHOT+RRDAonOffice-31. VaryingUnknownClasses.Weinvestigatedtherobustness\nofourframeworkagainstanincreasednumberofunknown\nMethods 0.1/0.9 0.2/0.8 0.25/0.75 0.3/0.7 0.4/0.6 0.5/0.5 private classes, which complicates the distinction between\nknown and unknown classes. We compared our method to\nSHOT 93.3 91.3 91.1 91.1 91.1 91.9\nAaD 90.9 89.5 90.0 89.7 90.1 90.0 LEAD, SHOT-O, and AaD-O on the Office-31 dataset. As\nshown in Figure 3a, our RRDA method in combination\nTable5:Ablationontheoptimizationobjectivetogenerate\nwithSHOTandAaDachievesstableresultsandconsistently\nsyntheticpoints.ResultsusingSHOT+RRDAonOffice-31.\noutperforms existing approaches. For consistency with our\nmainresults,wekeptK′fixedat10.\nSensitivitytoK′.Figure3bshowsadaptationperformance\ndataduringadaptation,RRDAactivelylearnsthesemantics\nfor different K′ values of the target classifier on Office-31\nof unknown classes through our adaptive target classifier,\ndataset.TheperformanceimprovesasK′increases,validat-\nwhich evolves to accommodate the unknown class distri-\ning the benefit of inheriting class separability knowledge,\nbution.Furthermore,theconsistentperformancegainswith\nbefore eventually reaching a plateau. In fact, K′ = 15\nbothAaDandSHOTdemonstrateRRDA’sversatility.These\nyields the best results. For the main experiments, we re-\nresultsunderscoretheimportanceofexplicitlymodelingun-\nportedOffice-31resultsusingK′ =K =10.\nknown classes in open-set domain adaptation, rather than\nTrainingStability.Figure3cillustratesthetrainingcurves\ntreatingthemasoutlierstobediscarded.\nfor the A2W task on the Office-31 dataset. Our method\nAblationStudyandSensitivityAnalysis shows consistent HOS improvement on the test set, with\nsteadily increasing before plateauing. In contrast, AaD-O\nOptimization Process. We conducted ablation studies on\nexhibitsunstabletraining,withnoticeableperformancefluc-\nOffice-31withthreedifferentsettingstotrainthenewclas-\ntuationsthroughoutthetrainingprocess.\nsifier.TheresultsareshowninTable4.Wecomparethefol-\nFeature Space Visualization. Figure 4 shows t-SNE em-\nlowing scenarios: (1) selecting target features based on en-\nbeddings of pre-classifier features for the source-only\ntropythresholdwithoutoptimization,(2)optimizingentropy\nmodel, AaD-O, and our method on the A2W task on the\nwithout hinge loss for diversity, and (3) the full proposed\nOffice-31 dataset. The source-only model (Figure 4a) ex-\nmethod optimizing feature points based on entropy and di-\nhibits well-separated known class clusters but mixes un-\nversity.Ourfindingsareasfollows:(1)Usingtargetfeatures\nknown samples with known classes. AaD-O (Figure 4b)\nbased on entropy directly to train the target classifier leads\nslightly improves known-unknown separation, but class\nto the worst results in terms of HOS. SHOT-O achieves an\noverlap remains. Our method (Figure 4c) achieves supe-\nHOS of 88.2 %, while using features directly without op-\nriorseparationofknownandunknownclasses,maintaining\ntimization achieves an HOS of 86.5%. (2) Optimizing the\ntight, well-defined known class clusters while isolating un-\npointssignificantlyimprovesperformance.Thereisaslight\nknown samples. This demonstrates our method’s effective-\nadditionalimprovementwhenusinghingelossduringopti-\nnessininheritingclassseparabilityduringadaptation.\nmizationtopromotediversity.(3)Thefullproposedmethod,\nwhich optimizes feature points based on both entropy and\ndiversity, yields the best performance. We used SHOT for Conclusion\nadaptationintheexperimentasitkeepstheclassifierfrozen,\nallowingforadirectperformancecomparisonwiththenew In this work, we introduce Recall and Refine for Domain\nclassifier. Adaptation (RRDA), a simple but effective framework for\nThresholdSensitivityAnalysis.Tofurtheranalyzethehy- SF-OSDA.RRDAenablesthesuccessfuladaptationofoff-\nperparametersensitivityanditsimpactonperformance,we the-shelfsourcepre-trainedmodelstotargetdomains,effec-\nexamined the effect of varying the entropy threshold used tively addressing both distribution and category shift prob-\nfor feature selection during the optimization process. The lems.RRDAachievesthisbyintroducinganewtargetclas-\nthresholdswereevaluatedontheA2Dtask(refTable5). sifier that aids in classifying and learning the semantics of\nWe observe that the best-performing threshold on this bothknownandunknownclasses.Thisapproachenablesthe\ntask is T = 0.1. However, the HOS score remains consis- direct use of source-free adaptation methods designed for\ntentacrossdifferentthresholds.Forlargerdatasets,suchas closed-set scenarios in open-set contexts. Extensive exper-\nVisDA,wherethedomainshiftsaremoresignificant,lower iments on three challenging benchmarks demonstrate that\nthresholds (e.g., T = 0.1) can result in highly imbalanced RRDA significantly outperforms existing SF-OSDA meth-\ndatasets,withsomeclassesbeingexcludedentirely.Forex- ods and even surpasses OSDA methods that have access to\nample, under such thresholds, a subset of classes may not the source domain. Future work could explore its potential\nmeettheselectioncriteria.Toensureconsistencyacrossall forcontinuousadaptationinthesetupwherenewclassesap-\ndatasets while maintaining a balanced feature distribution, pearovertime.\n1.00\n0.98 0.95\n0.95\n0.95 0.93 0.94\n0.93 0.90 SOTA (LEAD) 0.90\n0.90 0.88 0.85 0.85\n0.88 LEAD 0.85 0.80\n0.85 AaD-O 0.82 0.76 0.78\n00 .. 88 03\n1 2 3 4 5 6\nA S Sa H HD O\nO\n7\nT T+ - +OR R RD RA\nD\n8\nA(O (u Or us r)\ns 9)\n00 .. 78 80\n123456789101112131415161718192021222324\n00 .. 77 05 000 .. 77 25\n5 10 15 20 25 30\n35A A Sa a OD D\nT\n- 4+ AO\n0\nR (LR ED\nA\n4A\nD\n5\n)(Our 5s 0)\nNumber of Unknown Private Target Classes Number of target classes (K0) for the classifier Epoch\n(a)Variousopennesssettings (b)SensitivitytoK′ (c)HOSconvergence\nFigure 3: Sensitivity analysis on Office-31. (a) Adaptation performance across different openness levels (average across all\ntransfer tasks). (b) Sensitivity to K′ target classifier classes (average across all transfer tasks). (c) HOS curves for the A2W\ntask.\n(a)SourceOnly (b)AaD-O (c)AaD+RRDA(Ours)\nFigure4:T-SNEvisualizationofthepre-classifierfeaturespacefortheA2WtaskonOffice-31dataset.\nReferences throughSelf-supervision. InEuropeanConferenceonCom-\nputerVision.\nBen-David, S.; Blitzer, J.; Crammer, K.; Kulesza, A.;\nPereira, F.; and Vaughan, J. W. 2010. A theory of learning Dong,H.;Nejjar,I.;Sun,H.;Chatzi,E.;andFink,O.2023.\nfromdifferentdomains. Machinelearning,79:151–175. SimMMDG:ASimpleandEffectiveFrameworkforMulti-\nmodalDomainGeneralization.InAdvancesinNeuralInfor-\nBucci,S.;Loghmani,M.R.;andTommasi,T.2020. Onthe\nmationProcessingSystems(NeurIPS).\neffectivenessofimagerotationforopensetdomainadapta-\nDong, H.; Zhao, Y.; Chatzi, E.; and Fink, O. 2024. Mul-\ntion. InEuropeanconferenceoncomputervision,422–438.\ntiOOD: Scaling Out-of-Distribution Detection for Multiple\nSpringer.\nModalities. arXivpreprintarXiv:2405.17419.\nChen,L.;Lou,Y.;He,J.;Bai,T.;andDeng,M.2022. Geo-\nFang, Y.; Yap, P.-T.; Lin, W.; Zhu, H.; and Liu, M. 2024.\nmetricanchorcorrespondenceminingwithuncertaintymod-\nSource-free unsupervised domain adaptation: A survey.\neling for universal domain adaptation. In Proceedings of\nNeuralNetworks,106230.\ntheIEEE/CVFConferenceonComputerVisionandPattern\nFeng, Z.; Xu, C.; and Tao, D. 2021. Open-set hypothesis\nRecognition,16134–16143.\ntransfer with semantic consistency. IEEE Transactions on\nChoe,S.-A.;Shin,A.-H.;Park,K.-H.;Choi,J.;andPark,G.- ImageProcessing,30:6473–6484.\nM. 2024. Open-Set Domain Adaptation for Semantic Seg-\nFu, B.; Cao, Z.; Long, M.; and Wang, J. 2020. Learning\nmentation. InProceedingsoftheIEEE/CVFConferenceon\nto detect open classes for universal domain adaptation. In\nComputerVisionandPatternRecognition,23943–23953.\nComputer Vision–ECCV 2020: 16th European Conference,\nChu, T.; Liu, Y.; Deng, J.; Li, W.; and Duan, L. 2022. De- Glasgow, UK, August 23–28, 2020, Proceedings, Part XV\nnoised Maximum Classifier Discrepancy for Source-Free 16,567–583.Springer.\nUnsupervised Domain Adaptation. In Proceedings of the Ganin, Y.; and Lempitsky, V. 2015. Unsupervised domain\nAAAIconferenceonartificialintelligence,volume36,472– adaptationbybackpropagation. InInternationalconference\n480. onmachinelearning,1180–1189.PMLR.\nDong, H.; Chatzi, E.; and Fink, O. 2024. Towards Mul- He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep resid-\ntimodal Open-Set Domain Generalization and Adaptation ual learning for image recognition. In Proceedings of the\nSOH SOH SOH\nIEEE conference on computer vision and pattern recogni- In Proceedings of the IEEE/CVF Conference on Computer\ntion,770–778. VisionandPatternRecognition,24110–24119.\nHoyer,L.;Dai,D.;Wang,H.;andVanGool,L.2023. MIC: Liang,J.;Hu,D.;andFeng,J.2020. Dowereallyneedto\nMasked Image Consistency for Context-Enhanced Domain accessthesourcedata?sourcehypothesistransferforunsu-\nAdaptation.InProceedingsoftheIEEE/CVFConferenceon perviseddomainadaptation. InInternationalconferenceon\nComputerVisionandPatternRecognition(CVPR),11721– machinelearning,6028–6039.PMLR.\n11732. Liang,J.;Hu,D.;Feng,J.;andHe,R.2021. Umad:Univer-\nHuang,J.;Guan,D.;Xiao,A.;andLu,S.2021.Modeladap- salmodeladaptationunderdomainandcategoryshift.arXiv\ntation: Historical contrastive learning for unsupervised do- preprintarXiv:2112.08553.\nmain adaptation without source data. Advances in Neural Liu, H.; Cao, Z.; Long, M.; Wang, J.; and Yang, Q. 2019.\nInformationProcessingSystems,34:3635–3649. Separatetoadapt:Opensetdomainadaptationviaprogres-\nJang, J.; Na, B.; Shin, D. H.; Ji, M.; Song, K.; and Moon, siveseparation.InProceedingsoftheIEEE/CVFconference\nI.-C.2022. Unknown-awaredomainadversariallearningfor oncomputervisionandpatternrecognition,2927–2936.\nopen-set domain adaptation. Advances in Neural Informa- Long, M.; Cao, Y.; Wang, J.; and Jordan, M. 2015. Learn-\ntionProcessingSystems,35:16755–16767. ing transferable features with deep adaptation networks.\nJing, M.; Li, J.; Zhu, L.; Ding, Z.; Lu, K.; and Yang, Y. In International conference on machine learning, 97–105.\n2021. Balanced open set domain adaptation via centroid PMLR.\nalignment. In Proceedings of the AAAI conference on ar- Luo, Y.; Wang, Z.; Chen, Z.; Huang, Z.; and Baktashmot-\ntificialintelligence,volume35,8013–8020. lagh, M. 2023. Source-free progressive graph learning for\nKang,G.;Jiang,L.;Yang,Y.;andHauptmann,A.G.2019. open-setdomainadaptation. IEEETransactionsonPattern\nContrastive adaptation network for unsupervised domain AnalysisandMachineIntelligence.\nadaptation. InProceedingsoftheIEEE/CVFconferenceon Luo,Y.;Zheng,L.;Guan,T.;Yu,J.;andYang,Y.2019.Tak-\ncomputervisionandpatternrecognition,4893–4902. ingacloserlookatdomainshift:Category-leveladversaries\nKim, Y.; Cho, D.; Han, K.; Panda, P.; and Hong, S. 2021. forsemanticsconsistentdomainadaptation. InProceedings\nDomainadaptationwithoutsourcedata. IEEETransactions oftheIEEE/CVFconferenceoncomputervisionandpattern\nonArtificialIntelligence,2(6):508–518. recognition,2507–2516.\nKundu, J. N.; Venkat, N.; Babu, R. V.; et al. 2020a. Uni- Murez,Z.;Kolouri,S.;Kriegman,D.;Ramamoorthi,R.;and\nversal source-free domain adaptation. In Proceedings of Kim,K.2018. Imagetoimagetranslationfordomainadap-\ntheIEEE/CVFConferenceonComputerVisionandPattern tation. InProceedingsoftheIEEEconferenceoncomputer\nRecognition,4544–4553. visionandpatternrecognition,4500–4509.\nKundu,J.N.;Venkat,N.;MV,R.;andBabu,R.V.2020b. Nejjar,I.;Wang,Q.;andFink,O.2023.DARE-GRAM:Un-\nUniversal Source-Free Domain Adaptation. In The IEEE superviseddomainadaptationregressionbyaligninginverse\nConference on Computer Vision and Pattern Recognition grammatrices. InProceedingsoftheIEEE/CVFconference\n(CVPR). oncomputervisionandpatternrecognition,11744–11754.\nKundu, J. N.; Venkat, N.; Revanur, A.; Babu, R. V.; et al. Oza, P.; Sindagi, V. A.; Sharmini, V. V.; and Patel, V. M.\n2020c. Towards inheritable models for open-set domain 2023. Unsuperviseddomainadaptationofobjectdetectors:\nadaptation. InProceedingsoftheIEEE/CVFconferenceon Asurvey. IEEETransactionsonPatternAnalysisandMa-\ncomputervisionandpatternrecognition,12376–12385. chineIntelligence.\nLampert, C. H.; Nickisch, H.; and Harmeling, S. 2009. Panareda Busto, P.; and Gall, J. 2017. Open set domain\nLearning to detect unseen object classes by between-class adaptation. In Proceedings of the IEEE international con-\nattributetransfer. In2009IEEEconferenceoncomputervi- ferenceoncomputervision,754–763.\nsionandpatternrecognition,951–958.IEEE. Peng, X.; Usman, B.; Kaushik, N.; Hoffman, J.; Wang, D.;\nLee, J.; Jung, D.; Yim, J.; and Yoon, S. 2022. Confidence andSaenko,K.2017. Visda:Thevisualdomainadaptation\nscoreforsource-freeunsuperviseddomainadaptation.InIn- challenge. arXivpreprintarXiv:1710.06924.\nternationalconferenceonmachinelearning,12365–12377. Pizzati,F.;Charette,R.d.;Zaccaria,M.;andCerri,P.2020.\nPMLR. Domainbridgeforunpairedimage-to-imagetranslationand\nLi,G.;Kang,G.;Zhu,Y.;Wei,Y.;andYang,Y.2021. Do- unsupervised domain adaptation. In Proceedings of the\nmainconsensusclusteringforuniversaldomainadaptation. IEEE/CVF winter conference on applications of computer\nIn Proceedings of the IEEE/CVF conference on computer vision,2990–2998.\nvisionandpatternrecognition,9757–9766. Qu,S.;Chen,G.;Zhang,J.;Li,Z.;He,W.;andTao,D.2022.\nLi, R.; Jiao, Q.; Cao, W.; Wong, H.-S.; and Wu, S. 2020. Bmd:Ageneralclass-balancedmulticentricdynamicproto-\nModeladaptation:Unsuperviseddomainadaptationwithout type strategy for source-free domain adaptation. In Euro-\nsourcedata. InProceedingsoftheIEEE/CVFconferenceon peanconferenceoncomputervision,165–182.Springer.\ncomputervisionandpatternrecognition,9641–9650. Qu, S.; Zou, T.; He, L.; Ro¨hrbein, F.; Knoll, A.; Chen,\nLi, W.; Liu, J.; Han, B.; and Yuan, Y. 2023. Adjustment G.; and Jiang, C. 2024. Lead: Learning decomposition for\nandAlignmentforUnbiasedOpenSetDomainAdaptation. source-freeuniversaldomainadaptation. InProceedingsof\ntheIEEE/CVFConferenceonComputerVisionandPattern Wu, B.; Xu, C.; Dai, X.; Wan, A.; Zhang, P.; Yan, Z.;\nRecognition,23334–23343. Tomizuka,M.;Gonzalez,J.;Keutzer,K.;andVajda,P.2020.\nQu, S.; Zou, T.; Ro¨hrbein, F.; Lu, C.; Chen, G.; Tao, D.; Visual Transformers: Token-based Image Representation\nand Jiang, C. 2023. Upcycling models under domain and andProcessingforComputerVision. arXiv:2006.03677.\ncategoryshift. InProceedingsoftheIEEE/CVFConference Yang,S.;Jui,S.;vandeWeijer,J.;etal.2022.Attractingand\nonComputerVisionandPatternRecognition,20019–20028. dispersing:Asimpleapproachforsource-freedomainadap-\nRoy,S.;Trapp,M.;Pilzer,A.;Kannala,J.;Sebe,N.;Ricci, tation. AdvancesinNeuralInformationProcessingSystems,\nE.;andSolin,A.2022. Uncertainty-guidedsource-freedo- 35:5802–5815.\nmainadaptation. InEuropeanConferenceonComputerVi- Yang,S.;Wang,Y.;VanDeWeijer,J.;Herranz,L.;andJui,\nsion,537–555.Springer. S. 2021. Generalized source-free domain adaptation. In\nProceedingsoftheIEEE/CVFInternationalConferenceon\nSaenko,K.;Kulis,B.;Fritz,M.;andDarrell,T.2010.Adapt-\ning visual category models to new domains. In Computer\nComputerVision,8978–8987.\nVision–ECCV 2010: 11th European Conference on Com- Yu, Z.; Li, J.; Du, Z.; Zhu, L.; and Shen, H. T. 2023. A\nputer Vision, Heraklion, Crete, Greece, September 5-11, ComprehensiveSurveyonSource-freeDomainAdaptation.\n2010,Proceedings,PartIV11,213–226.Springer. arXivpreprintarXiv:2302.11803.\nSaito, K.; Kim, D.; Sclaroff, S.; and Saenko, K. 2020. Yue, Z.; Sun, Q.; and Zhang, H. 2024. Make the u in uda\nUniversal domain adaptation through self supervision. matter: Invariant consistency learning for unsupervised do-\nAdvances in neural information processing systems, 33: mainadaptation. AdvancesinNeuralInformationProcess-\n16282–16292. ingSystems,36.\nSaito, K.; and Saenko, K. 2021. Ovanet: One-vs-all net- Zhang, Y.; Wang, Z.; and He, W. 2023. Class relation-\nworkforuniversaldomainadaptation. InProceedingsofthe ship embedded learning for source-free unsupervised do-\nieee/cvfinternationalconferenceoncomputervision,9000– mainadaptation. InProceedingsoftheIEEE/CVFConfer-\n9009. ence on Computer Vision and Pattern Recognition, 7619–\n7629.\nSaito, K.; Yamamoto, S.; Ushiku, Y.; and Harada, T. 2018.\nOpen set domain adaptation by backpropagation. In Pro- Zhu,J.;Bai,H.;andWang,L.2023.Patch-MixTransformer\nceedings of the European conference on computer vision forUnsupervisedDomainAdaptation:AGamePerspective.\n(ECCV),153–168. In Proceedings of the IEEE/CVF Conference on Computer\nVisionandPatternRecognition(CVPR),3561–3571.\nSun, T.; Lu, C.; Zhang, T.; and Ling, H. 2022. Safe self-\nrefinementfortransformer-baseddomainadaptation.InPro-\nceedings of the IEEE/CVF conference on computer vision\nandpatternrecognition,7191–7200.\nTzeng, E.; Hoffman, J.; Saenko, K.; and Darrell, T. 2017.\nAdversarial discriminative domain adaptation. In Proceed-\ningsoftheIEEEconferenceoncomputervisionandpattern\nrecognition,7167–7176.\nVenkateswara, H.; Eusebio, J.; Chakraborty, S.; and Pan-\nchanathan,S.2017. Deephashingnetworkforunsupervised\ndomainadaptation. InProceedingsoftheIEEEconference\noncomputervisionandpatternrecognition,5018–5027.\nVu, T.-H.; Jain, H.; Bucher, M.; Cord, M.; and Pe´rez, P.\n2019. Dada: Depth-aware domain adaptation in semantic\nsegmentation. In Proceedings of the IEEE/CVF Interna-\ntionalConferenceonComputerVision,7364–7373.\nWan,F.;Zhao,H.;Yang,X.;andDeng,C.2024. Unveiling\ntheUnknown:UnleashingthePowerofUnknowntoKnown\nin Open-Set Source-Free Domain Adaptation. In Proceed-\ningsoftheIEEE/CVFConferenceonComputerVisionand\nPatternRecognition,24015–24024.\nWang,Q.;Meng,F.;andBreckon,T.P.2024. Progressively\nselect and reject pseudo-labelled samples for open-set do-\nmain adaptation. IEEE Transactions on Artificial Intelli-\ngence.\nWang,Y.;Zhu,R.;Ji,P.;andLi,S.2024. Open-SetGraph\nDomain Adaptation via Separate Domain Alignment. In\nProceedings of the AAAI Conference on Artificial Intelli-\ngence,volume38,9142–9150.",
    "pdf_filename": "Recall_and_Refine_A_Simple_but_Effective_Source-free_Open-set_Domain_Adaptation_Framework.pdf"
}