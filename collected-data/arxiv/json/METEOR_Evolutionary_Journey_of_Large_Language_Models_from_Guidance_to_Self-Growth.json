{
    "title": "METEOR: Evolutionary Journey of Large Language Models from",
    "abstract": "ofLLMscombinedwithdomain-specificexternal Model evolution enables learning from feed- enhancements to enable their application in spe- back to refine experiences and update skills, cific domains. These methods involve explicitly transformingmodelsfromhavingnodomain knowledgetobecomingdomainexperts. How- or implicitly acquiring domain knowledge from ever, there is currently no unified and effec- external knowledge bases (Lu et al., 2023; Izac- tivemethodforguidingthisevolutionarypro- ard et al., 2023; Schuurmans, 2023) or utilizing cess. To address this gap, we propose the domain-specific tools to assist LLMs in specific Meteormethod,whichincludesthreetraining domains (Jin et al., 2024; Li et al., 2023; Liang phases: weak-to-strongdatadistillation,itera- et al., 2023). However, these methods rely on tivetraining,andself-evolutionstrategies.Each the model’s strong general capabilities and are phasemaximizesthemodel’sinherentdomain typically applicable only to models with a large capabilities, allowing it to autonomously re- fine its domain knowledge and enhance per- numberofparameters,makingthemcostlytode- formance. Experiments demonstrate that our ployandlimitingtheirwidespreadadoption. Sev- approachsignificantlyimprovesaccuracy,com- eralresearchershaveexploredmodelevolutionap- pleteness,relevance,coherence,andreliability proachestoenhancedomain-specificcapabilities. acrossdomain-specifictasks. Wu et al. (2023) achieves evolution in the finan- 1 Introduction cialdomainthroughextensivemanuallyannotated domaindata,yetthisapproachproveschallenging Thedevelopmentoflargelanguagemodels(LLMs) to scale due to the difficulty in data acquisition. has ushered in a new era in the field of natural While Xi et al. (2024) proposes utilizing general language processing (NLP), showcasing remark- largemodelsforsupervisionandfeedbackondo- able general capabilities across a wide range of mainmodel-generateddata,thismethodologyre- applications(OpenAI,2023;Yangetal.,2024a,b; mainsconstrainedbytheperformanceceilingofthe Reidetal.,2024). However,despitetheiroutstand- supervising model. Although Singh et al. (2024) ingperformanceongeneraltasks,thetrainingofa madebreakthroughprogressinthecodingdomain highlyversatileLLMdemandssubstantialcompu- throughself-generateddataandself-training,elimi- tationalresourcesandfinancialinvestment. These natingdependenceonhumanannotationsandlarge highcostsrestricttheiruseinmanysituations,par- models,theirapproachhasnotyetbeeneffectively ticularlyinspecificdomains. Inspecificdomains, extendedtootherspecificdomains. there is often no need for a general purpose in- Toaddressthechallengesfacedbycurrentmod- telligent model; instead, a model that acts as an elsindomain-specificapplications,weproposea expert within a particular domain is more desir- self-evolutionmethodnamedMETEOR,aweak- able. Furthermore, these domain-specific expert to-strongevolutionframeworkthatenablesLLMs models should be trained at lower costs and eas- toprogressivelyevolvefromsupervisedguidance ily deployed in their respective fields. Therefore, toautonomousenhancement. Meteoroffersacom- findingefficientwaystocreateadomain-specific prehensivetrainingframeworkthatguidesanLLM expertmodelhasbecomeakeyresearchfocusin from having no domain expertise to becoming a the development of LLMs (Ling et al., 2024; Li domain expert. This framework consists of three etal.,2024a). keystages: aninitialfine-tuningstage,whichaims *Correspondingauthor. toimpartbasicdomainknowledgetotheLLM;an 1 4202 voN 81 ]GL.sc[ 1v33911.1142:viXra",
    "body": "METEOR: Evolutionary Journey of Large Language Models from\nGuidance to Self-Growth\nJiaweiLi,ChongFeng,YangGao*\nSchoolofComputerScienceandTechnology,\nBeijingInstituteofTechnology,Beijing,China\n{jwli, fengchong, gyang}@bit.edu.cn\nAbstract Somestudiesleveragetheinherentcapabilities\nofLLMscombinedwithdomain-specificexternal\nModel evolution enables learning from feed-\nenhancements to enable their application in spe-\nback to refine experiences and update skills,\ncific domains. These methods involve explicitly\ntransformingmodelsfromhavingnodomain\nknowledgetobecomingdomainexperts. How- or implicitly acquiring domain knowledge from\never, there is currently no unified and effec- external knowledge bases (Lu et al., 2023; Izac-\ntivemethodforguidingthisevolutionarypro- ard et al., 2023; Schuurmans, 2023) or utilizing\ncess. To address this gap, we propose the domain-specific tools to assist LLMs in specific\nMeteormethod,whichincludesthreetraining\ndomains (Jin et al., 2024; Li et al., 2023; Liang\nphases: weak-to-strongdatadistillation,itera-\net al., 2023). However, these methods rely on\ntivetraining,andself-evolutionstrategies.Each\nthe model’s strong general capabilities and are\nphasemaximizesthemodel’sinherentdomain\ntypically applicable only to models with a large capabilities, allowing it to autonomously re-\nfine its domain knowledge and enhance per- numberofparameters,makingthemcostlytode-\nformance. Experiments demonstrate that our ployandlimitingtheirwidespreadadoption. Sev-\napproachsignificantlyimprovesaccuracy,com- eralresearchershaveexploredmodelevolutionap-\npleteness,relevance,coherence,andreliability\nproachestoenhancedomain-specificcapabilities.\nacrossdomain-specifictasks.\nWu et al. (2023) achieves evolution in the finan-\n1 Introduction cialdomainthroughextensivemanuallyannotated\ndomaindata,yetthisapproachproveschallenging\nThedevelopmentoflargelanguagemodels(LLMs)\nto scale due to the difficulty in data acquisition.\nhas ushered in a new era in the field of natural\nWhile Xi et al. (2024) proposes utilizing general\nlanguage processing (NLP), showcasing remark-\nlargemodelsforsupervisionandfeedbackondo-\nable general capabilities across a wide range of\nmainmodel-generateddata,thismethodologyre-\napplications(OpenAI,2023;Yangetal.,2024a,b;\nmainsconstrainedbytheperformanceceilingofthe\nReidetal.,2024). However,despitetheiroutstand-\nsupervising model. Although Singh et al. (2024)\ningperformanceongeneraltasks,thetrainingofa\nmadebreakthroughprogressinthecodingdomain\nhighlyversatileLLMdemandssubstantialcompu-\nthroughself-generateddataandself-training,elimi-\ntationalresourcesandfinancialinvestment. These\nnatingdependenceonhumanannotationsandlarge\nhighcostsrestricttheiruseinmanysituations,par-\nmodels,theirapproachhasnotyetbeeneffectively\nticularlyinspecificdomains. Inspecificdomains,\nextendedtootherspecificdomains.\nthere is often no need for a general purpose in-\nToaddressthechallengesfacedbycurrentmod-\ntelligent model; instead, a model that acts as an\nelsindomain-specificapplications,weproposea\nexpert within a particular domain is more desir-\nself-evolutionmethodnamedMETEOR,aweak-\nable. Furthermore, these domain-specific expert\nto-strongevolutionframeworkthatenablesLLMs\nmodels should be trained at lower costs and eas-\ntoprogressivelyevolvefromsupervisedguidance\nily deployed in their respective fields. Therefore,\ntoautonomousenhancement. Meteoroffersacom-\nfindingefficientwaystocreateadomain-specific\nprehensivetrainingframeworkthatguidesanLLM\nexpertmodelhasbecomeakeyresearchfocusin\nfrom having no domain expertise to becoming a\nthe development of LLMs (Ling et al., 2024; Li\ndomain expert. This framework consists of three\netal.,2024a).\nkeystages: aninitialfine-tuningstage,whichaims\n*Correspondingauthor. toimpartbasicdomainknowledgetotheLLM;an\n1\n4202\nvoN\n81\n]GL.sc[\n1v33911.1142:viXra\nData Distillation Domain Model Question1+Guideline1 GPT4\n# PROMPT\nYou are an expert in the field of{specific Question2+Guideline2 # PROMPT\nfield}. I have a question that needs to be Below is a guideline provided by an expert in\nanswered: {question}. You do not need to the field of {specific field},followed by a\nanswer this question yourself, as I will use Question3+Guideline3 specific question that needs to be answered.\n… a more powerful model, GPT-4, to provide Please use the provided guideline to\nthe answer. However, to ensure that GPT-4 generate a precise and accurate answer to can answer the question more accurately, the question. \\n guideline: {guideline}\\n\nplease provide a detailed guideline to help Question: {question}“\nSpecificDomain Question it respond more precisely. The guideline is: QuestionN+GuidelineN\nFine-tuning modelwithpreliminary Interative Training Dataset\ndomaincapabilities\n… RightAnswer\nDomain\nDomain-specificdata\ndistilledfromGPT4 Model Domain Question\nQuestion + CoT+Answer\n# Title\nSelf-training Previous Turn H #o Bw o dto y Fine-Tune BERT for NER Tasks? Continuous Fine-tuning\nI'm trying to fine-tune a pre-trained BERT Domain Current\nmodel for a Named Entity Recognition (NER)\ntask. What are the essential steps and Model Answer\nrecommended tools for this process? Any GPT4\nDomain Greedy tips on dataset preparation and evaluation\nModel metrics would also be appreciated. Regenerate\nCurrent Turn\nAdvice WrongAnswer\nParameter\nUpdate Pairwise Loss Beam-10\nFigure 1: Overview of the METEOR method, which is structured into three phases. Initially, weak-to-strong\nknowledge distillation is applied, wherein the distilled data is used to train the model, facilitating the initial\nacquisitionofdomain-specificcapabilities. Thisissucceededbyiterativetraining,whichfurtherrefinesthemodel’s\ndomainexpertise. Ultimately,self-trainingisconducted,enablingthemodeltoachievetheproficiencyofadomain\nexpert.\niterativetrainingstage,wheretheLLM’sdomain However, these capabilities are limited to direct\nknowledgeisfurtherenhancedwiththeguidance problem-solvingwithouttheabilitytoevaluateand\nof a strong general LLM (like GPT-4 (OpenAI, refine their own outputs. This limitation necessi-\n2023)); and a self-training stage, which aims to tatesaguidedevolutionphasewherestrongmodels\nfurtherimprovetheLLM’scapabilities. Theover- providestructuredfeedback,helpingdomainmod-\nalltrainingarchitectureofMeteorisillustratedin elsdevelopself-examinationabilitiesthroughitera-\nFigure1. tiverefinement(Shinnetal.,2023;Zelikmanetal.,\n2022). Oncemodelsdevelopself-examinationca-\nKnowledge distillation from strong models is\npabilitiesthroughguidedreflection,theybecome\nan effective approach to address the scarcity of\ncapableofidentifyingpotentialflawsintheirrea-\ndomain-specificdata. However,duetothedistribu-\nsoning. Thiscreatesthefoundationforautonomous\ntionaldiscrepanciesbetweenstrongandweakmod-\nimprovement. Buildingonthetheoreticalrelation-\nels, knowledge distilled directly from the strong\nship between increased inference FLOPs and en-\nmodel’sdistributionmaynotbeefficientlyutilized\nhancedmodelcapabilities(Snelletal.,2024),we\nby the weak model. To overcome this limitation,\nintroduce a self-training approach where models\nwe propose a weak-to-strong strategy. In this ap-\nleveragetheiracquiredself-examinationabilitiesto\nproach, the weak model first provides guidelines\nprogressivelyenhancetheirperformancethrough\nfor the domain-specific questions to be distilled,\ncomputationalscaling,potentiallysurpassingtheir\nbased on its own distribution. The strong model\nstrongsupervisors.\nthengeneratesanswerstothesequestionsaccord-\nThemaincontributionsofthispaperareasfol-\ningtotheguidelines,therebyaligningtheknowl-\nlows:\nedgedistributionbetweenthestrongandweakmod-\nels. • Weintroduceaweak-to-strongevolutionframe-\nworkthatenablesLLMstoprogressivelyevolve\nFollowing knowledge distillation, models ac-\nfrom supervised guidance to autonomous en-\nquireinitialdomaincapabilitiesbutarestillinsuffi-\nhancement method named METEOR. Experi-\ncienttoindependentlyaddresscomplexproblems\nmental results demonstrate that each phase of\ninspecificdomains. Therefore,furtherdomainevo-\nMETEORenhancestheperformanceofmodels\nlutionisnecessary. Followingknowledgedistilla-\ninspecificdomainapplications.\ntion,modelsacquireinitialdomaincapabilities,en-\nablingthemtoperformbasicdomain-specifictasks. • We propose a model data distillation method\n2\n…\nbasedontheweak-to-strongstrategy,achieving Subsequently,weinputthegeneratedguideline\nalignmentofdomainknowledgedistributionbe- along with the domain question into the strong\ntweenstrongandweakmodels. model. Thestrongmodelthengeneratestheanswer\ntothedomainquestionbyfollowingtheguideline’s\n• Wepresentanevolutionmethodguidedbystrong stepsorrefinestheanswerbasedontheguideline.\nmodels based on reflection, as well as a self- Through these steps, we obtain a set of data\ntrainingevolutionmethodformodels. pairsconsistingofdomainquestionsandtheircor-\nrespondinganswersdistilledfromthestrongmodel.\n2 METEOR This distilled data is used to fine-tune the weak\nmodel,enablingittoacquirepreliminarydomain-\nThe METEOR method consists of three distinct\nspecificcapabilities,thuscompletingthefirststage\nphases: weak-to-strong data distillation, iterative\noftheMeteormodel’sevolution. InSection4,we\ntraining, and self-evolution strategies. In each\ndemonstratethatthedataobtainedusingtheweak-\nphase, the model fully utilizes its existing capa-\nto-strong distillation strategy is superior to that\nbilities to strengthen its domain expertise. Each\nobtained through direct data distillation, thereby\nsubsequent phase builds upon the advancements\nvalidatingtheeffectivenessofthisapproach.\nmadeinthepreviousone,employingdifferenttech-\nniquestofurtherevolvethemodel. Thefollowing 2.2 ModelEvolution\nsectionswilldetailthespecificmethodsemployed\nTraining models using domain data obtained\nineachphaseofMETEOR,illustratinghowthese\nthroughknowledgedistillationcanimpartprelim-\nstrategiescollectivelycontributetothemodel’sen-\ninary domain-specific capabilities to the LLMs.\nhanced performance and domain-specific knowl-\nHowever,thisapproachfallsshortofelevatingthe\nedge.\nmodels to the level of true domain experts due\nto the absence of expert-level reasoning abilities.\n2.1 Weak-to-strongDomainDataDistillation\nTherefore,furthermodelevolutionmethodsarere-\nFor a LLM lacking domain-specific capabilities, quiredtoenhancethedomaincapabilitiesofthese\nknowledgedistillationisproventobeaneffective models.\nmethod for injecting domain knowledge (Huang Thereflectionmechanism,whichinvolvesana-\netal.,2023;Zhang etal.,2023;ZhangandYang, lyzing the model’s previous reasoning processes\n2023). However,ourexperimentsindicatethatdi- and answers to identify errors and provide feed-\nrectly distilling domain data from a strong gen- back, has been shown to significantly improve\neralmodeltotrainadomain-specificmodelisnot the model’s reasoning abilities and performance\nparticularlyeffective. AsillustratedinTable7of in downstream applications (Shinn et al., 2023;\nAppendixA,thereisadiscrepancybetweenthere- Madaan et al., 2023). Consequently, we have de-\nsponsesofGPT-4todomain-specificquestionsand signedanalgorithmforfurtherevolvingthemodel\nthe solutions provided by the weak model. This within specific domains, based on the reflection\ndiscrepancy arises from differences in their cog- mechanismofLLMs,asillustratedinFigure3.\nnitivedistributions,makingitchallengingtotrain\nandlearnusingdirectlydistilleddata. 2.2.1 DataRefinementandIterativeTraining\nforDomain-SpecificModels\nToaddressthisissue,weproposeadomaindata\ndistillationmethodbasedonaweak-to-strongstrat- The key aspect of the reflection mechanism is to\negy(Burnsetal.,2024). AsillustratedinFigure2, provideaccuratefeedbackonthemodel’soutput.\ntoalignthedistributiondiscrepanciesbetweenthe However,modelsthathavebeendevelopedthrough\nstrongandweakmodels,weguidethestrongmodel knowledgedistillationpossessonlypreliminarydo-\ntodistilldomaindataaccordingtotheinstructions main capabilities and are unable to deliver suffi-\nfromtheweakmodel. Specifically,whenpresented cientlyaccuratefeedback. Therefore,atthisstage,\nwithadomain-specificquestion,wefirstinputthe we propose using strong models, such as GPT-\nquestionintotheweakmodel. Insteadofgenerat- 4 (OpenAI, 2023), to provide feedback for the\ningananswer,theweakmodelproducesaguide- evolutionofdomain-specificmodels. Theoverall\nlinebasedonthepromptshowninFigure2. This algorithmisshowninAlgorithm1.\nguideline outlines the steps the weak model be- Thespecificmethodinvolvesinputtingabatch\nlievesshouldbefollowedtoaddressthequestion. ofdomaindata, wherethecurrentdomainmodel\n3\nDomain Question: Algorithm1DataRefinementandIterativeTrain-\nStrategies for recognizing proper nouns in NLP Answer\nDescription: Question Definition of Proper Nouns Proper nouns refer ing\nCould anyone explain or link to resources that to specific names of people, organizations,\nexplain the current dictionary-based methods? locations, dates, times, and other unique …\nW whh ao t a ar re e t th he e a du et fh ino itr ii vta et i rv ee s oe ux rp ce er st s o o nn t hN eL sP u o br j ect? D pri ec cti oo mna pr ily e- dB a liss te sd o M f pe rt oh po ed rs n: oT uh nes se d a er re iv ed from Require: QuestionsetQ,ModelM,GPT-4,Max-\nDistillation linguistic resources like WordNet or lexical … imumiterationsN,BatchsizeK\nDomain Model A inl ct le ur dn ia nt giv te ra M nse ft oh rmod es r: s N like eu r Ba El Rn Te ,t w cao nr k les a, rn to\nrecognize proper nouns by identifying … Ensure: UpdatedModelM\nGPT-4 Domain-Specific Knowledge: Recognizing\nGuidelines p dr oo mp ae ir n n -so pu en cs i fi in c ksp ne oc wia leli dz ged e, c wo hn it ce hx t ms are yq nu oir te …s 1: training_buffer ← {}\n1. Scope: Focus on strategies for recognizing proper nouns ... S Jup re ae fsc kh y a an nd d L Ja an mg eu sa Hg .e M P ar ro tc ine :s Asi n cog m: b py r eD ha en nie sil v e 2: forQinQdo\n2. Definition of proper nouns: Clearly define what … textbook on NLP. Research papers from …\n… Guidelines Authoritative Experts and Resources: 3: history ← {}\nChristopher D. Manning: Known for his work in\n6. Authoritative experts and resources: Provide a list … NLP and NER. Dan Jurafsky: Renowned for … 4: whilen < N do\nFigure2: Illustrationoftheweak-to-strongknowledge 5: ifn = 0then\ndistillationprocess. Initially,adomainquestionisinput 6: R n,A n ← M(Q)▷Initialattempt\nintothedomainmodeltoobtainaguideline. Thestrong 7: else\nmodelthenusesthisguideline,providedbytheweak\n8: R n,A n ← M(Q,guide n) ▷\nmodel,alongwiththeoriginalquestion,togenerateand\nGuidedattempt\ndistilldomain-specificdata.\n9: endif\n10: (status,explanation,guide) ←\nGPT-4(Q,R ,A )\ngeneratesanswersandtheirrationalesforthegiven n n\nquestions using the Chain-of-Thought (CoT) ap-\n11: history.append(R n,explanation)\n12: ifstatus = \"CORRECT\"then\nproach (Wei et al., 2022). At this stage, we com-\n13: training_buffer.append(Q,history)\nbinethequestion,rationale,andanswer,whichare\n14: if|training_buffer| = K then\nthen input into GPT-4. GPT-4 evaluates whether\n15: M ←\nthe rationale and answer are correct. Within the\nUpdateModel(M,training_buffer) ▷\nconstraintsofthecontext,ifGPT-4deemsthean-\nFine-tunemodel\nswercorrect,itreturnsacorrectidentifier. IfGPT-4\n16: training_buffer ← {} ▷Clear\nidentifiestheanswerasincorrect,itprovidessug-\nbuffer\ngestions for modifying the rationale and offers a\n17: endif\nguiding sentence to help the model produce the\n18: break\ncorrectrationale. Were-inputthedomainquestion,\n19: endif\noriginalrationaleandanswer,alongwithGPT-4’s\n20: n ← n+1\nsuggestionsandguidingsentence,intothemodel,\n21: endwhile\nwhichthengeneratesanewanswer. Thisprocess\n22: endforreturnM\ncontinues until GPT-4 considers the answer cor-\nrect or the maximum number of iterations, N, is\nreached.\nusing the current dataset. The fine-tuned model\nOncetheiterationstops,wecombinethedomain is then reintroduced into the iterative process de-\nquestions,multipleroundsofrationales,GPT-4’s scribed above. Throughout the iterative training\ncorrections,andguidingsentencesfromthebatch process,thedomainmodel’scapabilityinthespe-\nto form the final domain training data. During cificdomaingraduallyimproves,andthequalityof\ndataconstruction,weconverttheguidingsentences thegenerateddomaindatacontinuouslyenhances.\nprovided by GPT-4 into discourse markers (like\nHmm). Thisapproachservestwomainpurposes: 2.2.2 Self-EvolutionofDomainCapabilities\n1. To ensure that the constructed data reflects a throughInferenceStrategy\nstrategywherethemodelindependentlyderivesthe Optimization\ncorrectedanswer,ratherthanrelyingonexternally Additionally, we aim for the model to evolve its\nprovided guiding sentences for correction. 2. To domaincapabilitiesindependently,withoutrelying\nmaintainthecoherenceofthereasoningstatements on strong models. To achieve this, we propose a\nthroughouttheprocess. methodforthemodeltoautonomouslyenhanceits\nAfter obtaining the domain data, we employ domaincapabilities.\nan iterative training approach to train the model. Increasing FLOPs during inference has been\nSpecifically,whentheamountofdatainthedataset showntoeffectivelyenhancemodelperformance\nreaches a multiple of K, we fine-tune the model indownstreamtasks(Snelletal.,2024). Inspired\n4\nInterativeTraining Dataset formance. Whencomparingthedistilleddataqual-\n… RightAnswer itywithandwithouttheuseofguidelines,GPT-4is\nDomain Question usedtoscorethedata,wherehigherscoresindicate\nQuestion + CoT+ Answer\n# Title\nHow to Fine-Tune BERT for NER Tasks? Continuous Fine-tuning better quality. In evaluating the domain-specific\n#Body\nI m'm o dtr ey l i fn og r t ao Nfi an me- et du n Ee n ta i tp yr Re e-t cr oa gin ne itd io B nE R (NT E R) Domain Current answersgeneratedbythemodel,GPT-4provides\ntask. What are the essential steps and Model Answer\nr tie pc so om nm de an tad se ed t t po ro el ps a f ro ar t it oh nis a p nr do c ee vs as l? u aA tn ioy n GPT4 scores basedon five criteria: accuracy, complete-\nmetrics would also be appreciated. Regenerate\nness, relevance, coherence, and reliability, allow-\nAdvice WrongAnswer\ningforacomprehensiveassessmentofthemodel’s\ndomaincapabilities. ThepromptforGPT-4’spair-\nFigure3: Illustrationofheiterativeevolutionprocess\nwisecomparisonacrossfiveevaluationcriteriais\nguided by a strong model. Upon receiving domain-\nspecificdata,themodelemploysCoTreasoningtogen- presentedinTable8ofAppendixB.\nerateanswersandreasoningpaths. Theseareevaluated\nby GPT-4, which provides confirmation if correct or\nModel and parameters setting. We selected\nofferssuggestionsforrefinementifincorrect. Thisiter-\nLLaMA3-8B-Chat (Dubey et al., 2024) and\nativeprocesscontinuesuntiltheanswerisvalidatedor\nthemaximumiterationlimitisreached. Qwen2-7B-Instruct(Yangetal.,2024a)asthebase-\nlinemodelsfordomainmodeltraininginthisstudy.\nCategory ML DL NLP CV Total ForGPT-4,weutilizedthepubliclyavailableAPI\nScale 4605 2092 1881 1698 10276 model,GPT-4o. Duringtheiterativeevolutionof\nthe model, we set the maximum number of itera-\nTable1: TotalvolumeofdatascrapedfromStackOver-\ntions to N = 3, with a cumulative data amount\nflow. ThecategoriesML,DL,NLP,andCVrepresent\nof K = 10 during each iteration. The beam size\nMachineLearning,DeepLearning,NaturalLanguage\nforbeamsearchwassetto10,andthemaximum\nProcessing,andComputerVision,respectively.\ntokenlengthforthedomainevolutionmodelwas\nconfiguredtobe4096.\nby this concept, we hypothesize that different in-\nference strategies yield varying outcomes. We\n4 ExperimentalResults\naim for the model’s outputs to closely align with\nthosegeneratedbyhigh-FLOPsstrategies,whiledi-\nvergingfromthoseproducedbylow-FLOPsstrate- 4.1 OverallResults\ngies. Therefore,weemploybeamsearch(Freitag\nWecomparedtheperformancechangesacrossvari-\nandAl-Onaizan,2017)asthehigh-FLOPsstrategy\nousdimensionsbeforeandafterapplyingtheMe-\nandgreedysearchasthelow-FLOPsstrategy,us-\nteor method for domain capability evolution of\ningcontrastivelearningtodevelopaself-training\nLLMs. Fortheaccuracy,completeness,relevance,\nmethod for the model. Experiments in Section 4\ncoherence,andreliability,wegeneratedresponses\ndemonstratetheeffectivenessofthisapproach.\ntotestsetquestionsusingboththeMeteor-trained\n3 ExperimentalSetups LLMs and the non-Meteor-trained LLMs. GPT-\n4 was then used to determine which model’s re-\nDatasets. Weusethefieldofadvancedcomputer\nsponses performed better in each of these dimen-\neducation as the specific domain to validate the\nsions. For the GPT-4 Score, GPT-4 directly eval-\neffectivenessoftheproposedMeteormethod. To\nuatedtheanswersgeneratedbytheLLMsbefore\nobtainhigh-qualitydomaindata,wescrapeddata\nandafterevolution,andtheaveragescorewascal-\nfrom Stack Overflow across four categories: Ma-\nculated.\nchineLearning(ML),DeepLearning(DL),Natural\nAs shown in Table 2, after the Meteor evolu-\nLanguageProcessing(NLP),andComputerVision\ntion, LLaMA3-8B-Chat and Qwen2-7B-Instruct\n(CV),totaling10,276entries. Thedatadistribution\nachieved improvements of 78.66%, 72.13%,\nacrossthesecategoriesisshowninTable1. From\n74.34%, 80.10%, 82.13%, and 68.36%, 63.43%,\nthisdataset,werandomlyselected1000entriesas\n60.24%,63.43%,67.09%respectivelyinaccuracy,\ntestdata,withtheremainingdatausedfortraining.\ncompleteness,relevance,coherence,andreliability.\nMetrics. Following the evaluated method pro- Additionally,theGPT-4Scoreafterevolutionwas\nposed by Zheng et al. (2023), we use GPT-4 as a significantlyhigherthanbefore,demonstratingthe\njudgetoevaluatebothdataqualityandmodelper- effectivenessoftheMeteormethod.\n5\nModel Accuracy Completeness Relevance Coherence Reliability GPT4Score\nw/o. 21.3% 27.8% 25.6% 19.9% 17.8% 5.02\nLLaMA3\nMeteor 78.7% 72.2% 74.4% 80.1% 82.2% 9.17\nw/o. 31.6% 36.5% 39.7% 36.5% 32.9% 6.88\nQwen2\nMeteor 68.4% 63.5% 60.3% 63.5% c% 9.28\nTable2: TheoverallresultscomparingthequalityofdomainquestionresponsesbyLLaMA3andQwen2,bothwith\nandwithoutMeteortraining. Here,LLaMAreferstoLLaMA3-8B-Chat,Qwen2referstoQwen2-7B-Instruct,and\nw/o. denotesmodelsthathavenotundergoneMeteortraining.\n4.2 EffectivenessofWeak-to-StrongData distilledwithoutguidelines,furtherconfirmingthe\nDistillation effectivenessoftheweak-to-strongdatadistillation\nstrategy.\nInSection2.1,weintroducedadomainknowledge\ndistillationmethodbasedonaweak-to-strongstrat-\nGPT-4Score\negy. Toevaluatetheeffectivenessofthisapproach, Model\nwithguidelines w/oguidelines\nweusedGPT-4toscorethedistilleddata. Bycom-\nLLaMA3 9.04 5.38\nparingtheGPT-4Scoresofdatadistilledwithand\nQwen2 9.22 6.13\nwithout guidelines, we demonstratethe effective-\nness of the weak-to-strong strategy in enhancing\nTable4: ThistablepresentingGPT-4scoresforanswers\nthequalityofdistilleddata. Thespecificresultsare\ngeneratedbymodelsfine-tunedwithdistilleddata. The\nshowninTable3. results demonstrate that models fine-tuned with data\nAs shown in Table 3, across various domains, distilledusingguidelinesexhibitsuperiorperformance\nthedatadistilledwithguidelinesachievedsignifi- ondomain-specifictasks.\ncantlyhigherGPT-4scoresthanthedatadistilled\nwithoutguidelines. Specifically,theGPT-4scores\n4.3 EffectivenessofIterativeTrainingand\nincreased by 3.29, 3.27, 3.34, and 3.32 points in\nDataRefinement\nML,DL,NLP,andCV,respectively,indicatingthat\nthequalityofdomaindatadistilledwithguidelines In Section 2.2.1, we introduced the Data Refine-\nissuperior. ment and Iterative Training for Domain-Specific\nModels. o validate the effectiveness of this ap-\nGPT-4Score\nCategory proach, we employed GPT-4 to evaluate the ac-\nwithguidelines w/oguidelines\ncuracy, completeness, relevance, coherence, and\nML 9.09 5.80\nreliabilityoftheanswersgeneratedbythemodels\nDL 9.07 5.80\nbefore and after evolution. The results are pre-\nNLP 9.05 5.71\nsentedinTable5.\nCV 9.05 5.73\nAvg. 9.07 5.77 LLaMA3 Qwen2\nw. w/o. w. w/o.\nTable 3: This table illustrating the quality scores as-\nAcc. 72.7% 27.2% 54.9% 45.1%\nsigned by GPT-4 to data distilled with and without\nCom. 63.1% 36.9% 53.7% 46.3%\nguidelines. Theresultsindicatethatdatadistilledusing\nRele. 65.4% 34.6% 51.3% 48.6%\nguidelinesconsistentlyreceivehigherscoresacrossall\nCoh. 72.3% 22.7% 57.6% 42.4%\ndomains.\nReli. 62.9% 37.1% 60.8% 39.2%\nAdditionally,weassessedwhetherdatadistilled\nTable5: TheeffectivenessofDataRefinementandIt-\nwithguidelinescanmoreeffectivelyenhancethe\nerative Training for Domain-Specific Models. Acc.,\nmodel’s domain capabilities. We fine-tuned the\nCom.,Rele.,Coh.,andReli. representAccuracy,Com-\nmodelusingtwosetsofdata,onewithguidelines\npleteness, Relevance, Coherence, and Reliability, re-\nandonewithout,andevaluatedtheGPT-4Scores\nspectively. LLaMA3 represents LLaMA3-8B-Chat\noftheanswersgeneratedbythemodelsonthetest Model. Qwen2representsQwen2-7B-InstructModel.\nset. AsshowninTable3,modelsfine-tunedwith ’w.’ denotesmodelsthathaveundergoneiterativeself-\ndatadistilledusingguidelinesscoredhigheracross evolution training, while ’w/o.’ denotes models that\nallaspectscomparedtothosefine-tunedwithdata havenot.\n6\nThe results in Table 5 indicate that both thatLLMscanhandlevariedandintricatescenar-\nLLaMA3-8B-Chat (Dubey et al., 2024) and ios(ZhangandYang,2023;Wangetal.,2023a). In\nQwen2-7B-Instruct (Yang et al., 2024a) showed scientificfields,thedistillationofknowledgefrom\nimprovedperformanceacrossallmetricsafterevo- longtextsandreasoningdataisessential(Abdine\nlutionguidedbyGPT-4,demonstratingtheeffec- et al., 2024; Zhang et al., 2024; Lin et al., 2024).\ntivenessandgeneralizabilityofthismethod. In the education fields, researchers often empha-\nsizeknowledgedistillationthroughpre-trainingon\n4.4 EffectivenessofSelf-EvolutionMethod educational corpora and fine-tuning with custom\nInSection2.2.2,weproposedthatmodelevolution instructionstoactivateeducation-specificfunctions\nshouldbeindependentofstrongmodelconstraints suchasopen-endedquestioning,essayevaluation,\nand introduced a self-evolution method based on andemotionalsupport(Danetal.,2023;Guoetal.,\nvarying FLOPs. Table 6 presents the differences 2024). However, few studies focus on whether\ninperformanceacrossvariousdimensions,aseval- theinputsdistilledfromstrongmodelscanbeef-\nuatedbyGPT-4,beforeandafterthemodelsself- ficiently utilized. This paper achieves more effi-\nevolution. cientdomainknowledgedistillationbyaligningthe\nknowledgedistributionbetweenstrongandweak\nLLaMa3 QWen2 models.\nw. w/o. w. w/o.\nAcc. 53.8% 46.2% 54.7% 45.3%\nCom. 47.9% 52.1% 51.3% 48.7%\n5.2 Self-evolutionofLLMs\nRele. 51.7% 48.3% 50.8% 49.2%\nCoh. 53.3% 46.7% 52.8% 47.2%\nReli. 52.9% 47.1% 53.1% 46.9% Self-evolutionofLLMsreferstothecapabilityof\nLLMstoautonomouslyacquire,refine,andlearn\nTable 6: The effiectiveness of Self-evolution method.\nfrom their own generated experiences (Tao et al.,\nAcc.,Com.,Rele.,Coh.,andReli. representAccuracy,\n2024). Initially, model evolution requires expe-\nCompleteness,Relevance,Coherence,andReliability,\nrience acquisition. Self-Align (Li et al., 2024b)\nrespectively. LLaMA3 represents LLaMA3-8B-Chat\nModel. Qwen2representsQwen2-7B-InstructModel. generatesexperiencesguidedbyknowledgefrom\n’w.’ denotes models that have self-evolution training, over 20 domains to ensure diversity in evolution.\nwhile’w/o.’ denotesmodelsthathavenot. Incontrast,Self-Instruct(Wangetal.,2023b)pro-\nposes a self-evolution method without the need\nThe results in Table 6 indicate that both for external knowledge guidance. Subsequently,\nLLaMA3-8B-Chat (Dubey et al., 2024) and experiencerefinementisnecessary. Self-Talk(Ul-\nQwen2-7B-Instruct (Yang et al., 2024a) showed meretal.,2024)ensuresdataqualitybymeasuring\nimprovedperformanceacrossallmetricsfollowing the number of completed sub-goals, while Self-\nself-evolution,demonstratingtheeffectivenessand verification (Weng et al., 2023) selects data by\ngeneralizabilityofthismethod. evaluatingtheconsistencybetweenpredictedval-\nues and original conditions. Once high-quality\n5 RelatedWorks experiences are acquired, models need to be up-\ndated to enhance performance. ReST (Aksitov\n5.1 Domain-specificKnowledgeDistillation\netal.,2023)updatesLLMsiterativelybyblending\nInthecontextofLLMs,knowledgedistillationhas original training data with newly generated data.\nbecome a crucial method for enhancing domain- FuseLLM(Wanetal.,2024)transfersknowledge\nspecific knowledge. In specialized fields such as to the target LLM using probability distributions\nlawandmedicine,thecomplexityofterminology generatedbythesourceLLM.Finally,theevolved\noftenposeschallenges(Laietal.,2023;Sunetal., modelsrequireevaluation. ChatEval(Chanetal.,\n2023). As a result, the distillation process typi- 2024) explores the strengths and weaknesses of\ncallybeginswithpre-trainingondomain-specific modeloutputsthroughadebatemechanism. LLM-\ncorpora, followed by fine-tuning using LLMs to as-a-judge(Zhengetal.,2023)employslargemod-\nconstructenhanceddata(Huangetal.,2023;Zhou elstoevaluateotherlargemodels,demonstrating\net al., 2024). In the financial fields, distilled data thatLLMscanmatchhumanjudgmentandachieve\nmustmaintaindiversityandcomplexitytoensure efficientperformanceevaluation.\n7\n6 Conclusion Firstly,weplantoconductmorerigorousanal-\nysisthroughneuralprobingtechniquestodirectly\nInthisstudy,weexploreinnovativestrategiesfor\nquantify the distributional differences between\nenhancing domain-specific capabilities of LLMs\nstrongandweakmodels. Specifically,wewilltrack\nthroughknowledgedistillationandself-evolution.\nandcomparetheinternalneuralactivationpatterns\nWe propose the Meteor method, which leverages\nandtokendistributioncharacteristicsofbothmodel\nweak-to-strongdatadistillation,iterativetraining,\ntypeswhenprocessingdomain-specifictasks. This\nandself-evolutiontoimprovemodelperformance\napproach will provide more direct experimental\nacrossvariousmetrics. Ourapproachisvalidated\nevidence,facilitatingbetterunderstandingandvali-\nusingdatafromadvancedcomputereducation,with\ndationofourdistributionaldifferencehypothesis.\nexperiments demonstrating significant improve-\nSecondly,wearecommittedtodevelopingmore\nments in accuracy, completeness, relevance, co-\nefficientself-evolutionmethodologies. Currentre-\nherence,andreliability. Byaligningtheknowledge\nsearch suggests the possibility of surpassing the\ndistributionbetweenstrongandweakmodels,we\nperformanceceilingofstrongmodels,motivating\nachievemoreefficientdomainknowledgedistilla-\nustoexploremoreadvancedself-evolutionstrate-\ntion. Furthermore, our self-evolution method en-\ngies. Our objective is to design methods capa-\nablesmodelstoautonomouslyrefinetheircapabili-\nble of continuous performance enhancement, ul-\ntieswithoutrelyingonexternalmodels,ensuring\ntimatelyachievingautonomousevolutionthatsur-\nadaptabilityandrobustness.\npassesstrongmodelguidance.\nFinally,consideringthegenericnatureoftheMe-\n7 LimitationsandFutureWorks\nteorapproach,weintendtoexpanditsapplication\n7.1 Limitations scope. This includes validating its effectiveness\nacross a more diverse range of domain-specific\nDespite the significant advances achieved in\nscenarios and exploring compatibility with vari-\ndomain-specific model evolution, several limita-\nousfoundationmodels. Throughthisextensibility\ntions warrant further investigation and improve-\nstudy, we aim to further validate the universality\nmentinfutureresearch.\noftheMeteorapproachandexploreitspotentialin\nThe primary limitation lies in our approach to\nbroaderapplicationcontexts.\nvalidatingthedistributionaldiscrepancybetween\nstrong and weak models. Although we have\nsuccessfully demonstrated performance improve- References\nmentsthroughweak-to-strongknowledgedistilla-\nHadi Abdine, Michail Chatzianastasis, Costas\ntion,therebyindirectlysupportingourhypothesis\nBouyioukos, and Michalis Vazirgiannis. 2024.\nof domain-specific distributional differences, we\nProt2text: Multimodalprotein’sfunctiongeneration\nlackdirectexperimentalevidencetoquantifyand withgnnsandtransformers. InThirty-EighthAAAI\nvisualize these differences. This indirect valida- Conference on Artificial Intelligence, AAAI 2024,\ntion methodology may not fully capture the spe- Thirty-SixthConferenceonInnovativeApplications\nof Artificial Intelligence, IAAI 2024, Fourteenth\ncificcharacteristicsandextentofthedistributional\nSymposium on Educational Advances in Artificial\ndisparities,thuslimitingourcomprehensiveunder- Intelligence, EAAI 2014, February 20-27, 2024,\nstandingofmodelbehaviors. Vancouver, Canada, pages 10757–10765. AAAI\nFurthermore, the proposed self-evolution Press.\nmethodologydemonstratesroomforimprovement\nRenatAksitov,SobhanMiryoosefi,ZonglinLi,Daliang\nin practical applications. While designed to\nLi, Sheila Babayan, Kavya Kopparapu, Zachary\nreduce dependence on strong models, current Fisher,RuiqiGuo,SushantPrakash,PraneshSrini-\nexperimentalresultsindicatelimitedperformance vasan,ManzilZaheer,FelixX.Yu,andSanjivKumar.\n2023. Restmeetsreact: Self-improvementformulti-\ngains. This limitation suggests the necessity for\nstepreasoningLLMagent. CoRR,abs/2312.10003.\nfurtheroptimizationofourself-evolutionstrategies\ntoachievemoresubstantialimprovements.\nCollin Burns, Pavel Izmailov, Jan Hendrik Kirchner,\nBowen Baker, Leo Gao, Leopold Aschenbrenner,\n7.2 FutureWorks Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan\nLeike,IlyaSutskever,andJeffreyWu.2024. Weak-\nBuildingupontheselimitations,weproposeseveral\nto-stronggeneralization: Elicitingstrongcapabilities\ncrucialdirectionsforfutureresearch: withweaksupervision. InForty-firstInternational\n8\nConference on Machine Learning, ICML 2024, Vi- on Learning Representations, ICLR 2024, Vienna,\nenna,Austria,July21-27,2024.OpenReview.net. Austria,May7-11,2024.OpenReview.net.\nChi-MinChan,WeizeChen,YushengSu,JianxuanYu, QuzheHuang,MingxuTao,ZhenweiAn,ChenZhang,\nWei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Cong Jiang, Zhibin Chen, Zirui Wu, and Yansong\nLiu.2024. Chateval: Towardsbetterllm-basedeval- Feng.2023. Lawyerllamatechnicalreport. CoRR,\nuators through multi-agent debate. In The Twelfth abs/2305.15062.\nInternational Conference on Learning Representa-\ntions,ICLR2024,Vienna,Austria,May7-11,2024. Gautier Izacard, Patrick S. H. Lewis, Maria Lomeli,\nOpenReview.net. Lucas Hosseini, Fabio Petroni, Timo Schick, Jane\nDwivedi-Yu,ArmandJoulin,SebastianRiedel,and\nYuhaoDan,ZhikaiLei,YiyangGu,YongLi,Jianghao Edouard Grave. 2023. Atlas: Few-shot learning\nYin,JiajuLin,LinhaoYe,ZhiyanTie,YougenZhou, withretrievalaugmentedlanguagemodels. J.Mach.\nYilei Wang, Aimin Zhou, Ze Zhou, Qin Chen, Jie Learn.Res.,24:251:1–251:43.\nZhou,LiangHe,andXipengQiu.2023. Educhat: A\nlarge-scalelanguagemodel-basedchatbotsystemfor QiaoJin,YifanYang,QingyuChen,andZhiyongLu.\nintelligenteducation. CoRR,abs/2308.02773. 2024. Genegpt: augmentinglargelanguagemodels\nwithdomaintoolsforimprovedaccesstobiomedical\nAbhimanyuDubey,AbhinavJauhri,AbhinavPandey, information. Bioinform.,40(2).\nAbhishekKadian,AhmadAl-Dahle,AieshaLetman,\nAkhil Mathur, Alan Schelten, Amy Yang, Angela JinqiLai,WenshengGan,JiayangWu,ZhenlianQi,and\nFan,AnirudhGoyal,AnthonyHartshorn,AoboYang, PhilipS.Yu.2023. Largelanguagemodelsinlaw: A\nArchiMitra, ArchieSravankumar, ArtemKorenev, survey. CoRR,abs/2312.03718.\nArthurHinsvark,ArunRao,AstonZhang,Aurélien\nRodriguez, Austen Gregerson, Ava Spataru, Bap- JiaweiLi,YizheYang,YuBai,XiaofengZhou,Yinghao\ntiste Rozière, Bethany Biron, Binh Tang, Bobbie Li,HuashanSun,YuhangLiu,XingpengSi,Yuhao\nChern,CharlotteCaucheteux,ChayaNayak,Chloe Ye, Yixiao Wu, Yiguan Lin, Bin Xu, Ren Bowen,\nBi,ChrisMarra,ChrisMcConnell,ChristianKeller, ChongFeng, YangGao, andHeyanHuang.2024a.\nChristophe Touret, Chunyang Wu, Corinne Wong, Fundamentalcapabilitiesoflargelanguagemodels\nCristianCantonFerrer,CyrusNikolaidis,DamienAl- andtheirapplicationsindomainscenarios: Asurvey.\nlonsius,DanielSong,DaniellePintz,DannyLivshits, In Proceedings of the 62nd Annual Meeting of the\nDavid Esiobu, Dhruv Choudhary, Dhruv Mahajan, AssociationforComputationalLinguistics(Volume1:\nDiegoGarcia-Olano,DiegoPerino,DieuwkeHupkes, LongPapers),ACL2024,Bangkok,Thailand,August\nEgorLakomkin,EhabAlBadawy,ElinaLobanova, 11-16, 2024, pages 11116–11141. Association for\nEmilyDinan,EricMichaelSmith,FilipRadenovic, ComputationalLinguistics.\nFrankZhang,GabrielSynnaeve,GabrielleLee,Geor-\ngiaLewisAnderson,GraemeNail,GrégoireMialon, JinyangLi,BinyuanHui,GeQu,JiaxiYang,BinhuaLi,\nGuanPang,GuillemCucurell,HaileyNguyen,Han- BowenLi,BailinWang,BowenQin,RuiyingGeng,\nnahKorevaar,HuXu,HugoTouvron,IliyanZarov, Nan Huo, Xuanhe Zhou, Chenhao Ma, Guoliang\nImanol Arrieta Ibarra, Isabel M. Kloumann, Ishan Li,KevinChen-ChuanChang,FeiHuang,Reynold\nMisra,IvanEvtimov,JadeCopet,JaewonLee,Jan Cheng, and Yongbin Li. 2023. Can LLM already\nGeffert,JanaVranes,JasonPark,JayMahadeokar, serveasAdatabaseinterface? Abigbenchforlarge-\nJeet Shah, Jelmer van der Linde, Jennifer Billock, scaledatabasegroundedtext-to-sqls. InAdvancesin\nJenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, NeuralInformationProcessingSystems36: Annual\nJianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, ConferenceonNeuralInformationProcessingSys-\nJoanna Bitton, Joe Spisak, Jongsoo Park, Joseph tems2023, NeurIPS2023, NewOrleans, LA,USA,\nRocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, December10-16,2023.\nKalyan Vasuden Alwala, Kartikeya Upasani, Kate\nPlawiak,KeLi,KennethHeafield,KevinStone,and XianLi,PingYu,ChuntingZhou,TimoSchick,Omer\net al. 2024. The llama 3 herd of models. CoRR, Levy, Luke Zettlemoyer, Jason Weston, and Mike\nabs/2407.21783. Lewis.2024b. Self-alignmentwithinstructionback-\ntranslation. InTheTwelfthInternationalConference\nMarkus Freitag and Yaser Al-Onaizan. 2017. Beam on Learning Representations, ICLR 2024, Vienna,\nsearchstrategiesforneuralmachinetranslation. In Austria,May7-11,2024.OpenReview.net.\nProceedings of the First Workshop on Neural Ma-\nchine Translation, NMT@ACL 2017, Vancouver, Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu,\nCanada,August4,2017,pages56–60.Association Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji,\nforComputationalLinguistics. Shaoguang Mao, Yun Wang, Linjun Shou, Ming\nGong, and Nan Duan. 2023. Taskmatrix.ai: Com-\nHongchengGuo,JianYang,JiahengLiu,LiqunYang, pletingtasksbyconnectingfoundationmodelswith\nLinzheng Chai, Jiaqi Bai, Junran Peng, Xiaorong millionsofapis. CoRR,abs/2303.16434.\nHu,ChaoChen,DongfengZhang,XuShi,Tieqiao\nZheng,LiangfanZheng,BoZhang,KeXu,andZhou- ZhouhanLin,ChengDeng,LeZhou,TianhangZhang,\njunLi.2024. OWL:AlargelanguagemodelforIT Yi Xu, Yutong Xu, Zhongmou He, Yuanyuan Shi,\noperations. InTheTwelfthInternationalConference BeiyaDai,YunchongSong,BoyiZeng,QiyuanChen,\n9\nTaoShi, TianyuHuang, Yiwei Xu, Shu Wang, Lu- Noah Shinn, Federico Cassano, Ashwin Gopinath,\noyiFu,WeinanZhang,JunxianHe,ChaoMa,Yun- Karthik Narasimhan, and Shunyu Yao. 2023. Re-\nqiangZhu,XinbingWang,andChenghuZhou.2024. flexion: languageagentswithverbalreinforcement\nGeogalactica: Ascientificlargelanguagemodelin learning. In Advances in Neural Information Pro-\ngeoscience. CoRR,abs/2401.00434. cessingSystems36: AnnualConferenceonNeural\nInformationProcessingSystems2023,NeurIPS2023,\nChenLing,XujiangZhao,JiayingLu,ChengyuanDeng, NewOrleans,LA,USA,December10-16,2023.\nCan Zheng, Junxiang Wang, Tanmoy Chowdhury,\nYun Li, Hejie Cui, Xuchao Zhang, Tianjiao Zhao, Avi Singh, John D. Co-Reyes, Rishabh Agarwal,\nAmit Panalkar, Dhagash Mehta, Stefano Pasquali, Ankesh Anand, Piyush Patil, Xavier Garcia, Pe-\nWeiCheng,HaoyuWang,YanchiLiu,Zhengzhang ter J. Liu, James Harrison, Jaehoon Lee, Kelvin\nChen, Haifeng Chen, Chris White, Quanquan Gu, Xu,AaronT.Parisi,AbhishekKumar,AlexanderA.\nJianPei,CarlYang,andLiangZhao.2024. Domain Alemi,AlexRizkowsky,AzadeNova,BenAdlam,\nspecializationasthekeytomakelargelanguagemod- Bernd Bohnet, Gamaleldin Fathy Elsayed, Hanie\nels disruptive: A comprehensive survey. Preprint, Sedghi,IgorMordatch,IsabelleSimpson,Izzeddin\narXiv:2305.18703. Gur, Jasper Snoek, Jeffrey Pennington, Jiri Hron,\nKathleen Kenealy, Kevin Swersky, Kshiteej Maha-\nJiayingLu,JiamingShen,BoXiong,WenjingMa,Stef- jan,LauraCulp,LechaoXiao,MaxwellL.Bileschi,\nfenStaab,andCarlYang.2023. Hiprompt: Few-shot Noah Constant, Roman Novak, Rosanne Liu, Tris\nbiomedicalknowledgefusionviahierarchy-oriented Warkentin,YundiQian,YaminiBansal,EthanDyer,\nprompting. InProceedingsofthe46thInternational Behnam Neyshabur, Jascha Sohl-Dickstein, and\nACMSIGIRConferenceonResearchandDevelop- Noah Fiedel. 2024. Beyond human data: Scaling\nmentinInformationRetrieval,SIGIR2023,Taipei, self-trainingforproblem-solvingwithlanguagemod-\nTaiwan,July23-27,2023,pages2052–2056.ACM. els. Trans.Mach.Learn.Res.,2024.\nCharlieSnell,JaehoonLee,KelvinXu,andAviralKu-\nAmanMadaan, NiketTandon,PrakharGupta,Skyler\nmar.2024. ScalingLLMtest-timecomputeoptimally\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\ncanbemoreeffectivethanscalingmodelparameters.\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\nCoRR,abs/2408.03314.\nShashank Gupta, Bodhisattwa Prasad Majumder,\nKatherine Hermann, Sean Welleck, Amir Yazdan-\nWeiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang\nbakhsh, and Peter Clark. 2023. Self-refine: Itera-\nWang,PengjieRen,ZhuminChen,DaweiYin,and\ntiverefinementwithself-feedback. InAdvancesin\nZhaochun Ren. 2023. Is chatgpt good at search?\nNeuralInformationProcessingSystems36: Annual\ninvestigating large language models as re-ranking\nConferenceonNeuralInformationProcessingSys-\nagents. InProceedingsofthe2023Conferenceon\ntems2023, NeurIPS2023, NewOrleans, LA,USA,\nEmpirical Methods in Natural Language Process-\nDecember10-16,2023.\ning,EMNLP2023,Singapore,December6-10,2023,\npages14918–14937.AssociationforComputational\nOpenAI. 2023. GPT-4 technical report. CoRR,\nLinguistics.\nabs/2303.08774.\nZhengwei Tao, Ting-En Lin, Xiancai Chen, Hangyu\nMachel Reid, Nikolay Savinov, Denis Teplyashin,\nLi, Yuchuan Wu, Yongbin Li, Zhi Jin, Fei Huang,\nDmitryLepikhin,TimothyP.Lillicrap,Jean-Baptiste\nDacheng Tao, and Jingren Zhou. 2024. A survey\nAlayrac, RaduSoricut, AngelikiLazaridou, Orhan\nonself-evolutionoflargelanguagemodels. CoRR,\nFirat,JulianSchrittwieser,IoannisAntonoglou,Ro-\nabs/2404.14387.\nhanAnil,SebastianBorgeaud,AndrewM.Dai,Katie\nMillican, Ethan Dyer, Mia Glaese, Thibault Sotti-\nDennisUlmer,ElmanMansimov,KaixiangLin,Lijia\naux,BenjaminLee,FabioViola,MalcolmReynolds,\nSun,XibinGao,andYiZhang.2024. Bootstrapping\nYuanzhongXu,JamesMolloy,JilinChen,Michael\nllm-basedtask-orienteddialogueagentsviaself-talk.\nIsard, Paul Barham, Tom Hennigan, Ross McIl- In Findings of the Association for Computational\nroy,MelvinJohnson,JohanSchalkwyk,EliCollins, Linguistics,ACL2024,Bangkok,Thailandandvir-\nEliza Rutherford, Erica Moreira, Kareem Ayoub, tualmeeting,August11-16,2024,pages9500–9522.\nMegha Goel, Clemens Meyer, Gregory Thornton,\nAssociationforComputationalLinguistics.\nZhen Yang, Henryk Michalewski, Zaheer Abbas,\nNathan Schucher, Ankesh Anand, Richard Ives, FanqiWan,XintingHuang,DengCai,XiaojunQuan,\nJamesKeeling,KarelLenc,SalemHaykal,Siamak Wei Bi, and Shuming Shi. 2024. Knowledge fu-\nShakeri,PranavShyam,AakankshaChowdhery,Ro- sion of large language models. In The Twelfth In-\nmanRing,StephenSpencer,ErenSezener,andetal. ternationalConferenceonLearningRepresentations,\n2024. Gemini 1.5: Unlocking multimodal under- ICLR2024,Vienna,Austria,May7-11,2024.Open-\nstandingacrossmillionsoftokensofcontext. CoRR, Review.net.\nabs/2403.05530.\nNeng Wang, Hongyang Yang, and Christina Dan\nDaleSchuurmans.2023. Memoryaugmentedlargelan- Wang.2023a. Fingpt: Instructiontuningbenchmark\nguagemodelsarecomputationallyuniversal. CoRR, foropen-sourcelargelanguagemodelsinfinancial\nabs/2301.04589. datasets. CoRR,abs/2310.04793.\n10\nYizhongWang,YeganehKordi,SwaroopMishra,Alisa Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D.\nLiu,NoahA.Smith,DanielKhashabi,andHannaneh Goodman.2022. Star: Bootstrappingreasoningwith\nHajishirzi.2023b. Self-instruct: Aligninglanguage reasoning. InAdvancesinNeuralInformationPro-\nmodelswithself-generatedinstructions. InProceed- cessingSystems35: AnnualConferenceonNeural\ningsofthe61stAnnualMeetingoftheAssociation InformationProcessingSystems2022,NeurIPS2022,\nforComputationalLinguistics(Volume1: LongPa- NewOrleans,LA,USA,November28-December9,\npers),ACL2023,Toronto,Canada,July9-14,2023, 2022.\npages13484–13508.AssociationforComputational\nLinguistics. Dan Zhang, Ziniu Hu, Sining Zhoubian, Zhengxiao\nDu,KaiyuYang,ZihanWang,YisongYue,Yuxiao\nJasonWei,XuezhiWang,DaleSchuurmans,Maarten Dong,andJieTang.2024. Sciglm: Trainingscien-\nBosma,BrianIchter,FeiXia,EdH.Chi,QuocV.Le, tificlanguagemodelswithself-reflectiveinstruction\nandDennyZhou.2022. Chain-of-thoughtprompting annotationandtuning. CoRR,abs/2401.07950.\nelicits reasoning in large language models. In Ad-\nvancesinNeuralInformationProcessingSystems35: Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu,\nAnnualConferenceonNeuralInformationProcess- Zhihong Chen, Guiming Chen, Jianquan Li, Xi-\ningSystems2022,NeurIPS2022,NewOrleans,LA, angboWu,ZhiyiZhang,QingyingXiao,XiangWan,\nUSA,November28-December9,2022. Benyou Wang, and Haizhou Li. 2023. Huatuogpt,\ntowardstaminglanguage modelto bea doctor. In\nYixuanWeng,MinjunZhu,FeiXia,BinLi,ShizhuHe, FindingsoftheAssociationforComputationalLin-\nShengping Liu, Bin Sun, Kang Liu, and Jun Zhao. guistics: EMNLP2023,Singapore,December6-10,\n2023. Large language models are better reasoners 2023,pages10859–10885.AssociationforComputa-\nwith self-verification. In Findings of the Associa- tionalLinguistics.\ntion for Computational Linguistics: EMNLP 2023,\nSingapore,December6-10,2023,pages2550–2575. XuanyuZhangandQingYang.2023. Xuanyuan2.0:\nAssociationforComputationalLinguistics. Alargechinesefinancialchatmodelwithhundreds\nofbillionsparameters. InProceedingsofthe32nd\nShijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravol- ACMInternationalConferenceonInformationand\nski,MarkDredze,SebastianGehrmann,Prabhanjan KnowledgeManagement,CIKM2023,Birmingham,\nKambadur,DavidS.Rosenberg,andGideonMann. UnitedKingdom,October21-25,2023,pages4435–\n2023. Bloomberggpt: A large language model for 4439.ACM.\nfinance. CoRR,abs/2303.17564.\nLianminZheng,Wei-LinChiang,YingSheng,Siyuan\nZhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nHong,HonglinGuo,JunzheWang,DingwenYang, ZhuohanLi,DachengLi,EricP.Xing,HaoZhang,\nChenyangLiao,XinGuo,WeiHe,SongyangGao, JosephE.Gonzalez,andIonStoica.2023. Judging\nLu Chen, Rui Zheng, Yicheng Zou, Tao Gui, llm-as-a-judgewithmt-benchandchatbotarena. In\nQi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan AdvancesinNeuralInformationProcessingSystems\nWu, andYu-GangJiang.2024. Agentgym: Evolv- 36: AnnualConferenceonNeuralInformationPro-\ninglargelanguagemodel-basedagentsacrossdiverse cessingSystems2023,NeurIPS2023,NewOrleans,\nenvironments. CoRR,abs/2406.04151. LA,USA,December10-16,2023.\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Zhi Zhou, Jiang-Xin Shi, Peng-Xiao Song, Xiaowen\nBowenYu,ChangZhou,ChengpengLi,Chengyuan Yang,Yi-XuanJin,Lan-ZheGuo,andYu-FengLi.\nLi,DayihengLiu,FeiHuang,GuantingDong,Hao- 2024. Lawgpt: Achineselegalknowledge-enhanced\nran Wei, Huan Lin, Jialong Tang, Jialin Wang, largelanguagemodel. CoRR,abs/2406.04614.\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin\nMa,JianxinYang,JinXu,JingrenZhou,JinzeBai, A ExampleAppendix\nJinzhengHe,JunyangLin,KaiDang,KemingLu,Ke-\nqinChen,KexinYang,MeiLi,MingfengXue,NaNi, B Prompts\nPei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize\nGao,RunjiLin,ShijieWang,ShuaiBai,SinanTan,\nTianhangZhu,TianhaoLi,TianyuLiu,WenbinGe,\nXiaodong Deng, Xiaohuan Zhou, Xingzhang Ren,\nXinyuZhang,XipinWei,XuanchengRen,Xuejing\nLiu,YangFan,YangYao,YichangZhang,YuWan,\nYunfeiChu,YuqiongLiu,ZeyuCui,ZhenruZhang,\nZhifangGuo,andZhihaoFan.2024a. Qwen2techni-\ncalreport. CoRR,abs/2407.10671.\nYizhe Yang, Huashan Sun, Jiawei Li, Runheng Liu,\nYinghao Li, Yuhang Liu, Yang Gao, and Heyan\nHuang.2024b. Mindllm:Lightweightlargelanguage\nmodelpre-training,evaluationanddomainapplica-\ntion. AIOpen,5:1–26.\n11\nDomainQuestion\nQustion:StrategiesforrecognizingpropernounsinNLP\nDescribtion:I’minterestedinlearningmoreaboutNaturalLanguageProcessing(NLP)andam\ncuriousiftherearecurrentlyanystrategiesforrecognizingpropernounsinatextthataren’t\nbasedondictionaryrecognition?Also,couldanyoneexplainorlinktoresourcesthatexplain\nthecurrentdictionary-basedmethods?WhoaretheauthoritativeexpertsonNLPorwhatare\nthedefinitiveresourcesonthesubject?\nGPT-4Answer\nRecognizingpropernounsinNaturalLanguageProcessing(NLP)isacriticaltaskformany\napplicationssuchasinformationretrieval,machinetranslation,andnamedentityrecognition.\nHerearesomestrategiesandresourcesforrecognizingpropernouns,bothdictionary-based\nandnon-dictionary-based:\nNon-Dictionary-BasedMethodsMachineLearningApproaches:\nSupervisedLearning:TechniqueslikeConditionalRandomFields(CRFs)andHiddenMarkov\nModels(HMMs)arecommonlyused. Thesemodelslearntorecognizepatternsinlabeled\ntrainingdatatoidentifypropernouns. NeuralNetworks: Deeplearningmodels,suchas\nRecurrentNeuralNetworks(RNNs)andTransformers(e.g.,BERT),canbetrainedonlarge\ncorporatorecognizepropernounsbasedoncontextandsyntacticpatterns.Rule-BasedSystems:\nPatternMatching:Useregularexpressionsandlinguisticrulestoidentifypropernouns.For\ninstance,capitalizedwordsfollowingcertainpartsofspeechcanbeflaggedaspropernouns.\nHeuristics:Implementheuristicsbasedonpunctuation,capitalization,andpositioninasentence\ntodetectpropernouns.StatisticalMethods:\nPart-of-SpeechTagging:Usestatisticalmodelstotagwordswiththeirpartsofspeech,including\npropernouns.Thesemodelsoftenrelyonlargeannotatedcorporafortraining.Dictionary-\nBasedMethodsLexicon-BasedApproaches:Thesemethodsrelyonpredefineddictionariesor\ngazetteersofknownpropernouns.Thetextisscannedtomatchwordsagainstentriesinthese\ndictionaries.HybridMethods:Combinedictionary-basedrecognitionwithmachinelearningto\nimproveaccuracy.Forexample,asystemmightuseadictionarytorecognizecommonproper\nnounsandamachinelearningmodeltoidentifylesscommonones.ResourcesandExperts\nBooksandPapers:\n\"SpeechandLanguageProcessing\"byDanielJurafskyandJamesH.Martinisacomprehensive\ntextbookthatcoversmanyaspectsofNLP,includingnamedentityrecognition.Researchpapers\nonnamedentityrecognition(NER)oftendiscussmethodsforrecognizingpropernouns.Online\nCoursesandTutorials:\nCourseraandedXoffercoursesonNLPthatcoverbothtraditionalandmoderntechniques.\nOnlinetutorialsanddocumentationforNLPlibrarieslikeNLTK,SpaCy,andStanfordNLP.\nExpertsintheField:\nChristopherManning:KnownforhisworkincomputationallinguisticsandNLP.Andrew\nNg:WhilemorebroadlyfocusedonAI,hehascontributedsignificantlytomachinelearning\napplicationsinNLP.ConferencesandJournals:\nConferenceslikeACL(AssociationforComputationalLinguistics)andEMNLP(Empirical\nMethodsinNaturalLanguageProcessing)arekeyvenuesforthelatestresearchinNLP.Journals\nsuchas\"ComputationalLinguistics\"and\"JournalofArtificialIntelligenceResearch\"publish\ncutting-edgeNLPresearch.Thesestrategiesandresourcesshouldprovideasolidfoundation\nforunderstandingandimplementingpropernounrecognitioninNLPsystems.\nGuidelines\n1. **Scope:**Focusonstrategiesforrecognizingpropernounsinnaturallanguagetext,\nexcludingdictionary-basedmethods. Discussthelimitationsandchallengesofdictionary-\nbasedapproachesandhighlightalternativemethodsthathavebeenproposedorimplemented.\n2.**Definitionofpropernouns:**Clearlydefinewhatconstitutesapropernoun,including\nnamesofpeople,organizations,locations,dates,times,andotherspecificentities.Explain\ntheimportanceofrecognizingpropernounsinNLPapplications. 3. **Dictionary-based\nmethods:**Provideanoverviewofcurrentdictionary-basedmethodsforrecognizingproper\nnouns,including:*Wordlists:Theuseofprecompiledlistsofpropernouns,oftenbased\nonlinguisticresourceslikeWordNetorotherlexicaldatabases. *Gazetteers: Geospatial\ndatabasesthatcontaininformationaboutgeographiclocations,oftenusedforpropernoun\nrecognition.*Entityrecognition:Theuseofmachinelearningmodelstoidentifyentitiesin\ntext,includingpropernouns.4.**Alternativemethods:**Discussalternativestrategiesfor\nrecognizingpropernounsthataren’tbasedondictionaryrecognition,including:*Machine\nlearningapproaches:Explainhowmachinelearningalgorithms,suchasneuralnetworksor\ndecisiontrees,canbetrainedtorecognizepropernounsbasedonpatternsintextdata. *\nContextualanalysis:Describehowcontextualanalysis,includingsentimentanalysis,topic\nmodeling,orentityco-occurrence,canbeusedtoidentifypropernouns. *Graph-based\nmethods:Explainhowgraph-basedapproaches,suchasgraphneuralnetworksorgraph-based\nentityrecognition,canbeusedtorecognizepropernouns.5.**Challengesandlimitations:**\nDiscussthechallengesandlimitationsofrecognizingpropernouns,including:*Ambiguity:\nThedifficultyofdistinguishingbetweenpropernounsandcommonnouns.*Out-of-vocabulary\nwords:Thechallengeofrecognizingpropernounsthatarenotpresentindictionariesortraining\ndata.*Domain-specificknowledge:Theneedfordomain-specificknowledgetorecognize\npropernounsinspecificcontexts.6.**Authoritativeexpertsandresources:**Providealist\nofauthoritativeexpertsinthefieldofNLP,includingresearchersandpractitionerswhohave\nmadesignificantcontributionstothedevelopmentofpropernounrecognitiontechniques.Also,\nincludealistofdefinitiveresourcesonthesubject,suchasresearchpapers,books,oronline\ncourses.\nTable7: Aweak-to-strongexample.\n12\nGPT-4’spairwisecomparisonprompt:\nDomainQuestion: [Question]\nAnswerA(Model1): [Firstmodel’sanswer]\nAnswerB(Model2): [Secondmodel’sanswer]\nPlease compare these two answers and determine which one performs better in each of the\nfollowingcriteria. Foreachcriterion,selectthebetteranswer(AorB)andbrieflyexplainwhy.\n1. Accuracy: Whichanswerprovidesmoreaccuratedomain-specificinformation?\nSelection: [A/B]\nReason:\n2. Completeness: Whichanswercoverstheessentialaspectsmorethoroughly?\nSelection: [A/B]\nReason:\n3. Relevance: Whichanswerbetteraddressesthedomain-specificrequirements?\nSelection: [A/B]\nReason:\n4. Coherence: Whichanswerpresentsinformationinamorelogicalandorganizedmanner?\nSelection: [A/B]\nReason:\n5. Reliability: Whichanswerdemonstratesbettertechnicalvalidityandtrustworthiness?\nSelection: [A/B]\nReason:\nOverallWinner: [A/B]\nKeyDifferences: [Briefsummaryofmaindifferencesbetweenthetwoanswers]\nTable8: PromptforGPT-4’spairwisecomparisonofdomain-specificmodeloutputsacrossfiveevaluationcriteria.\n13",
    "pdf_filename": "METEOR_Evolutionary_Journey_of_Large_Language_Models_from_Guidance_to_Self-Growth.pdf"
}