{
    "title": "Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing",
    "abstract": "Computerized Adaptive Testing (CAT) aims to select the most ap- propriate questions based on the examinee‚Äôs ability and is widely used in online education. However, existing CAT systems often lack initial understanding of the examinee‚Äôs ability, requiring ran- dom probing questions. This can lead to poorly matched ques- tions, extending the test duration and negatively impacting the examinee‚Äôs mindset, a phenomenon referred to as the Cold Start with Insufficient Prior (CSIP) task. This issue occurs because CAT systems do not effectively utilize the abundant prior information about the examinee available from other courses on online plat- forms. These response records, due to the commonality of cogni- tive states across different knowledge domains, can provide valu- able prior information for the target domain. However, no prior work has explored solutions for the CSIP task. In response to this gap, we propose Diffusion Cognitive States TransfeR Frame- work (DCSR), a novel domain transfer framework based on Diffu- sion Models (DMs) to address the CSIP task. Specifically, we con- struct a cognitive state transition bridge between domains, guided by the common cognitive states of examinees, encouraging the model to reconstruct the initial ability state in the target domain. To enrich the expressive power of the generated data, we analyze the causal relationships in the generation process from a causal perspective. Redundant and extraneous cognitive states can lead to limited transfer and negative transfer effects. Therefore, we ‚àóCorresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada ¬© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX designed three decoupling strategies to control confounding vari- ables, thereby blocking backdoor paths that hinder causal discov- ery. Given that excessive uncertainty can affect the applicability of generated results to the CAT system, we propose consistency constraint and task-oriented constraint to control the randomness of the generated results and their relevance to the CAT task, re- spectively. Our DCSR can seamlessly apply the generated initial ability states in the target domain to existing question selection al- gorithms, thus improving the cold start performance of the CAT sys- tem. Extensive experiments conducted on five real-world datasets demonstrate that DCSR significantly outperforms existing base- line methods in addressing the CSIP task. The code is available at: https://github.com/BIMK/Intelligent-Education/tree/main/DCSR. CCS Concepts ‚Ä¢ Applied computing ‚ÜíComputer-assisted instruction.",
    "body": "Diffusion-Inspired Cold Start with Sufficient Prior in\nComputerized Adaptive Testing\nHaiping Ma\nInformation Materials and Intelligent\nSensing Laboratory of Anhui\nProvince, the Institutes of Physical\nScience and Information Technology,\nAnhui University\nHefei, Anhui, China\nhpma@ahu.edu.cn\nAoqing Xia\nThe Institutes of Physical Science and\nInformation Technology, Anhui\nUniversity\nHefei, Anhui, China\nq23301252@stu.ahu.edu.cn\nChangqian Wang\nThe Institutes of Physical Science and\nInformation Technology, Anhui\nUniversity\nHefei, Anhui, China\nchangqian.wang.dl@gmail.com\nHai Wang\nThe Institutes of Physical Science and\nInformation Technology, Anhui\nUniversity\nHefei, Anhui, China\nq22201135@stu.ahu.edu.cn\nXingyi Zhang‚àó\nSchool of Computer Science and\nTechnology, Anhui University\nHefei, Anhui, China\nxyzhanghust@gmail.com\nAbstract\nComputerized Adaptive Testing (CAT) aims to select the most ap-\npropriate questions based on the examinee‚Äôs ability and is widely\nused in online education. However, existing CAT systems often\nlack initial understanding of the examinee‚Äôs ability, requiring ran-\ndom probing questions. This can lead to poorly matched ques-\ntions, extending the test duration and negatively impacting the\nexaminee‚Äôs mindset, a phenomenon referred to as the Cold Start\nwith Insufficient Prior (CSIP) task. This issue occurs because CAT\nsystems do not effectively utilize the abundant prior information\nabout the examinee available from other courses on online plat-\nforms. These response records, due to the commonality of cogni-\ntive states across different knowledge domains, can provide valu-\nable prior information for the target domain. However, no prior\nwork has explored solutions for the CSIP task. In response to\nthis gap, we propose Diffusion Cognitive States TransfeR Frame-\nwork (DCSR), a novel domain transfer framework based on Diffu-\nsion Models (DMs) to address the CSIP task. Specifically, we con-\nstruct a cognitive state transition bridge between domains, guided\nby the common cognitive states of examinees, encouraging the\nmodel to reconstruct the initial ability state in the target domain.\nTo enrich the expressive power of the generated data, we analyze\nthe causal relationships in the generation process from a causal\nperspective. Redundant and extraneous cognitive states can lead\nto limited transfer and negative transfer effects. Therefore, we\n‚àóCorresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\n¬© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-XXXX-X/18/06\nhttps://doi.org/XXXXXXX.XXXXXXX\ndesigned three decoupling strategies to control confounding vari-\nables, thereby blocking backdoor paths that hinder causal discov-\nery. Given that excessive uncertainty can affect the applicability\nof generated results to the CAT system, we propose consistency\nconstraint and task-oriented constraint to control the randomness\nof the generated results and their relevance to the CAT task, re-\nspectively. Our DCSR can seamlessly apply the generated initial\nability states in the target domain to existing question selection al-\ngorithms, thus improving the cold start performance of the CAT sys-\ntem. Extensive experiments conducted on five real-world datasets\ndemonstrate that DCSR significantly outperforms existing base-\nline methods in addressing the CSIP task. The code is available at:\nhttps://github.com/BIMK/Intelligent-Education/tree/main/DCSR.\nCCS Concepts\n‚Ä¢ Applied computing ‚ÜíComputer-assisted instruction.\nKeywords\nComputerized Adaptive Testing, Intellegent Education\nACM Reference Format:\nHaiping Ma, Aoqing Xia, Changqian Wang, Hai Wang, and Xingyi Zhang.\n2025. Diffusion-Inspired Cold Start with Sufficient Prior in Computerized\nAdaptive Testing. In Proceedings of Make sure to enter the correct conference\ntitle from your rights confirmation emai (KDD ‚Äô25). ACM, New York, NY,\nUSA, 10 pages. https://doi.org/XXXXXXX.XXXXXXX\n1\nIntroduction\nAs artificial intelligence empower education, computerized adap-\ntive testing (CAT) on online education platforms have garnered\nextensive attention [38, 39, 42, 45]. CAT aims to provide examinees\nwith a small number of appropriate questions to progressively as-\nsess their cognitive states in specific domains [19, 29, 30]. Typically,\nCAT consists of two iterative components: the cognitive diagnostic\nmodel (CDM) and the question selection algorithm. As shown in\nFigure 1 (a), the CDM estimates examinee‚Äôs ability based on her\narXiv:2411.12182v1  [cs.LG]  19 Nov 2024\n\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nHaiping Ma et al.\nFigure 1: Illustration of (a) typical CAT process, and (b) the\ndilemma of CAT under cold start.\nresponse at step ùë°‚àí1 [26, 43, 46, 47], after which the question\nselection algorithm provides suitable question for the next step,\nthus enabling a more accurate assessment of examinee‚Äôs ability.\nExisting research on the question selection algorithm, a critical\ncomponent of CAT, can be categorized into policy-based [1, 50] and\nlearnable-based [34, 49] approaches. The former generally converts\nthe question selection process into model expectation, while the\nlatter defines the CAT process as a bi-level optimization problem.\nDespite the advancements made by various question selection\nalgorithms, they still face challenges related to the cold start prob-\nlem in the CAT process. As illustrated in Figure 1 (b), on an online\neducation platform, the system initially has no knowledge of the\nexaminee‚Äôs ability, causing the CAT system to tentatively select\nquestions randomly to determine the starting point of the test. The\ndifficulty and content of the question might not align with the\nexaminee‚Äôs actual ability, leading to confusion or frustration and\nincreasing the time cost of the assessment. Additionally, the ques-\ntion selection process is an iterative Markov chain. This means\nthat if the question selected in the initial stages do not match the\nexaminee‚Äôs ability, it may lead to biased question selections in sub-\nsequent stages. Most question selection algorithms based on greedy\nstrategies tend to amplify this bias, harming the performance of the\nCAT system. These algorithms, although capable of quickly finding\nlocal optima in certain scenarios, can easily get trapped in local\noptima over multiple rounds of question selection. In our paper,\nwe refer to this task as Cold Start with Insufficient Priors (CSIP),\nwhich arises from the insufficient understanding of the examinee\nby the question selection algorithm at the initial stage of the test,\nleading to uncertain starting points for selection and subsequently\naffecting the adaptive testing process.\nWith the widespread application of educational platforms, vast\namounts of examinee data are collected and stored [14], providing\nvaluable resources to enrich the prior information for CAT system.\nNotably, historical response records of examinees in other courses\ncan serve as crucial references for CAT system to preliminarily\nunderstand examinee abilities. There are certain commonalities\namong knowledge concepts across different courses. For example,\nmany physics questions, such as those in kinematics and dynam-\nics, require algebraic equation solving, which is fundamental in\nmathematics. Therefore, an examinee‚Äôs response records across\nmultiple courses can reflect their foundational abilities and cogni-\ntive commonalities in multiple interdisciplinary fields, which are\ntransferable attributes. These pre-diagnosed abilities can provide\nrich prior information for the target (cold start) course, allowing the\nCAT system to grasp the examinee‚Äôs ability range in advance. For\nexample, if an examinee performs well in mathematics, especially in\ncomplex algebra and geometry questions, the CAT system can infer\nthat he also possess strong logical thinking and problem-solving\nskills in physics, thereby assigning a higher initial ability. To our\nknowledge, no research has yet utilized these cross-course data to\nsolve the CSIP task, despite its significant and practical importance.\nTo fully leverage these cross-course response records and provide\nprior information about examinees to CAT system, we integrate\nand transfer the pre-diagnosis results of examinees to the target\ndomain based on the concept of Diffusion Models (DMs) [3, 11].\nDMs add noise incrementally and then reconstruct the corrupted\ndata step by step in reverse, which not only addresses noisy re-\nsponse records in the source domain but also aptly meets the needs\nof solving the CSIP task. This is due to the ability of DMs to grad-\nually merge complex multi-distribution cross-domain data into a\nunified latent space during denoising, generating a unified latent\nrepresentation, which reconstructs the initial ability of the target\ndomain with specific transfer attributes from the noise. However,\ndespite the great potential of using DMs to address the CSIP task,\nwe uncover challenges in terms of what and how: (1) What kind of\nsource domain information can be injected into the reverse denois-\ning process as guidance. And (2) How to constrain the output to\nmatch the CAT system, implying that excessive uncertainty in the\ngenerated results can lead to data unsuitable for CAT task.\nTo address these challenges, we design a novel domain transfer\nframework named the Diffusion Cognitive States TransfeR Frame-\nwork (DCSR) for the CSIP task. Guided by the principle of DMs,\nwe generate initial abilities in the target domain for examinees to\nenhance the cold-start performance of CAT system. Specifically,\nto prevent the loss of personalized information in the diffusion\ngeneration results, we condition the denoiser on examinees‚Äô prior\ncognitive abilities to incorporate personalized target domain abil-\nities. To avoid redundant information and negative transfer, we\nanalyze the causal relationships between different variables from\nthe causal perspective of model and design three decoupling strate-\ngies to adjust confounding variables in the backdoor path, including\ndomain-shared cognition, domain-specific cognition, and orthogo-\nnal regularization-based gradient separation, blocking paths that\nobscure true causal relationships. To mitigate the excessive uncer-\ntainty of DMs and enhance the adaptability to CAT task, we design\nconsistency constraint and task-oriented constraint to control ran-\ndomness and match the input requirements of CAT system. The\nresults generated by DCSR seamlessly integrate with existing ques-\ntion selection algorithms, improving the cold-start performance\nof CAT system. Extensive experimental results on five real-world\ndatasets demonstrate that DCSR effectively addresses the CSIP task\nand significantly outperforms baselines.\n2\nRelated Work\n2.1\nComputerized Adaptive Testing\nComputerized Adaptive Testing (CAT) aims to evaluate an exam-\ninee‚Äôs ability progressively within a shorter test length [12, 27].\nCAT systems primarily consist of two components: (1) Cognitive\n\nDiffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nDiagnostic Models (CDMs) for diagnosing examinees‚Äô abilities\nbased on their responses to selected questions [20, 23, 24, 37, 41].\nItem Response Theory (IRT) [5], a widely used CDM, assumes uni-\ndimensional independence and uses continuous latent variables to\nassess examinees‚Äô latent abilities. With the widespread application\nof deep neural networks, neural CDMs such as NCD [32], RCD [7],\nand KaNCD [33] utilize neural networks to capture complex inter-\nactions between examinees and questions, enabling fine-grained\ndiagnostic modeling. (2) Question selection algorithms aim to\nadaptively choose the next appropriate question based on the CDM\nfeedback. Early question selection algorithms were model-specific,\nsuch as IRT-specific Maximum Fisher Information [21], Kullback-\nLeibler Information Index [4], and Max Entropy [28]. However,\nthese simple algorithms could not meet the evolving needs of CDMs,\nleading to performance limitations. Therefore, a model-agnostic\nquestion selection algorithm, MAAT [1] was proposed, leverag-\ning active learning to transform the question selection process\ninto choosing questions with the greatest expected model change.\nSimilarly, BECAT [50] employs an expected gradient difference\napproach, treating the question selection process as a subset selec-\ntion problem guided by theoretical estimates of examinees‚Äô true\nabilities. Another research direction focuses on data-driven ques-\ntion selection algorithms. For example, BOBCAT [9], NCAT [49],\nand GMOCAT [34] define the CAT task as a bi-level optimization\nproblem, using reinforcement learning to learn question selection\nalgorithm from large-scale response data. However, from a model\nperspective, the crucial CDM component in current CAT systems\nrandomly initializes examinees‚Äô abilities at the test‚Äôs outset. This\nrandom initialization necessitates more question selection steps\nfor greedy algorithms to understand the examinee‚Äôs ability range,\nthereby exacerbating the cold start problem in CAT system.\n2.2\nDiffusion Model\nDiffusion Models (DMs) have achieved impressive results in image\ngeneration [3, 11]. To transfer these successes to other domains, re-\ncent works [15, 25, 48] have attempted to bridge the image domain\nwith other fields. CODIGEM [31] was the first to extend the de-\nnoising module in DMs to recommendation systems. DiffuRec [17],\nDreamRec [44] and CF-Diff [13] model the latent representations\nof items and user preferences, guiding the denoising module to gen-\nerate personalized representations. DiffRec [35] and DiffuASR [18]\nnot only reduce generation costs but also achieve temporal model-\ning of interaction sequences. Moreover, more research leverages the\nMarkov chain modeling characteristics of DMs to explore sequence\nmodeling, with few works utilizing diffusion features to study cross-\ndomain problems. Although DiffCDR [36] has made preliminary\nexplorations in this area, it introduces redundant information and\nfaces limitations in cross-domain representation capacity due to\nthe diverse entities in CAT system.\n3\nPreliminary\n3.1\nComputerized Adaptive Testing\n3.1.1\nTask Introduction. In an online education platform, the Com-\nputerized Adaptive Testing (CAT) system adaptively selects ques-\ntions for examinees to accurately reveal their cognitive abilities. The\nCAT system comprises two components: (1) a Cognitive Diagnosis\nModel (CDM) M, which assesses the examinee‚Äôs ability state after\nresponding to the selected questions, and (2) a question selection\nalgorithm Œ†, which chooses the next most informative question\nbased on the examinee‚Äôs current ability state to measure their abil-\nity more precisely. These two components alternately iterate until\na termination condition is met.\nSpecifically, given a examinee ùëíùëñand his/her candidate question\nset Qùëñ, the CAT process can be represented as:\nùëûùë°‚ÜêŒ†(ùëÑùëñ| ùúÉùë°‚àí1\nùëñ\n),\nùúÉùë°\nùëñ‚ÜêM(ùëüùëñùëûùë°| ùëûùë°,ùúÉùë°‚àí1\nùëñ\n),\n(1)\nwhere ùëûùë°denotes the question selected by Œ† based on the exam-\ninee‚Äôs ability ùúÉùë°‚àí1\nùëñ\nat time ùë°‚àí1 from the candidate question set\nQùëñ, which only includes questions that the examinee ùëíùëñhas not yet\nresponded to. The variable ùëüùëñùëûùë°represents the response result of\nexaminee ùëíùëñto question ùëûùë°. Note that ùëáis the maximum number of\nsteps for terminating the test.\n3.1.2\nCold start with insufficient priors. In the Cold Start with In-\nsufficient Priors (CSIP) scenario, the question selection algorithm\nconsiders only the information from the target domain while ig-\nnoring the rich data from the source domains. To alleviate this lack\nof prior information, we define ùëÄsource domains S1, S2, . . . , SùëÄ\nand one target domain T in the Diffusion Cognitive State Transfer\nFramework (DCSR). Each domain includes three groups of enti-\nties. We use ESùëö, QSùëöand CSùëöto denote the sets of examinees,\nquestions, and knowledge concepts in the ùëö‚ààùëÄsource domain,\nrespectively. Similarly, ET, QT and CT denote the three entities in\nthe target domain. The overlapping examinees between domains\nare defined as EO ‚àãEOùëö= ESùëö‚à©ET, while the other two entity\ngroups generally do not have overlapping elements across domains.\n3.1.3\nTraining and Testing Phases. In the given CAT testing\nplatform, both warm-start and cold-start, meaning the CAT\nsystem has never encountered before, are included in the\ntarget domain. Their response records can be represented as\nRT =\nn\nRùë§ùëéùëüùëö\nT\n, Rùëêùëúùëôùëë\nT\no\n=\nn\n(ùëíùëñ,ùëûùëó,ùëüùëñùëó) | ùëíùëñ‚ààEùë§ùëéùëüùëö\nT\n‚à™Eùëêùëúùëôùëë\nT\no\n,\nwhere ùëüùëñùëó\n= 1 indicates that examinee ùëíùëñanswered question\nùëûùëó\n‚ààQT correctly, and ùëüùëñùëó\n= 0 otherwise. Similarly, the re-\nsponse records in the ùëösource domain can be represented as\nRSùëö=\n\b\n(ùëíùëñ,ùëûùëó,ùëüùëñùëó) | ùëíùëñ‚ààEOùëö,ùëûùëó‚ààQQùëö\n\t\n, and all source domain\nrecords are denoted as RS =\n\b\nRS1, RS2, . . . , RSùëö\n\t. To prevent\ndata leakage, the aforementioned response sets are uniformly\ndivided into a training set Dùë°ùëüùëéùëñùëõ= {Rùë§ùëéùëüùëö\nT\n, RS} and a test set\nDùë°ùëíùë†ùë°= Rùëêùëúùëôùëë\nT\n.\nOur DCSR consists of two phases: training the initial abilities\nof examinees in the source domain based on Dùë°ùëüùëéùëñùëõand testing\nthe performance of question selection in the CAT system without\nlearning, based on Dùë°ùëíùë†ùë°.\n3.1.4\nPre-Establish Cognitive States. The data in the training set\nDùë°ùëüùëéùëñùëõcomes from the response records of overlapping examinees\nEO between domains. We pre-train these examinees to establish\ntheir cognitive states in both the source and target domains. The\npre-training process is expressed as:\nùúÉ‚àó= arg min\nùúÉ‚ààŒò\n‚àëÔ∏Å\n(ùëíùëñ,ùëûùëó,ùëüùëñùëó)‚ààDùë°ùëüùëéùëñùëõ\nL \u0000ùëüùëñùëó, MŒ®(ùëûùëó|ùúÉùëñ)\u0001 ,\n(2)\n\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nHaiping Ma et al.\nFigure 2: The overview of DCSR: The left side corresponds to pre-training. While the blue, yellow, and green modules are\nused for training, and the orange modules correspond to the application in CAT. Additionally, the right side depicts the causal\ndiscovery in the generation process.\nwhere MŒ® is the CDM used for pre-training, and different do-\nmain data correspond to different CDM parameters, i.e., Œ® =\n{ùúìS1,ùúìS2, . . . ,ùúìSùëÄ,ùúìT}. The abilities of overlapping examinees\nare denoted as ŒòS = {ùúÉùëñ| ùëñ‚ààEO}, and similarly, the abilities in\nthe target domain are denoted as ŒòT.\n3.2\nDiffusion Model\nDiffusion Models (DMs) have demonstrated exceptional perfor-\nmance in fields such as computer vision [11]. Typically, DMs consist\nof two parts: the forward process and the reverse process.\n3.2.1\nForward Process. Given a data point ùë•0 ‚àºùëû(ùë•) sampled from\nthe true data distribution, the forward process gradually degrades\nùë•0 into standard Gaussian noise ùë•ùëá‚àºN (0, 1) by injecting Gaussian\nnoise over ùëásteps. Specifically, the process of converting ùë•ùë°‚àí1 to\nùë•ùë°in DMs is represented as ùëû(ùë•ùë°| ùë•ùë°‚àí1) = N (ùë•ùë°;\n‚àöÔ∏Å\n1 ‚àíùõΩùë°ùë•ùë°‚àí1, ùõΩùë°I),\nwhere ùë°‚àà{1, . . . ,ùëá} represents the diffusion steps, ùõΩùë°‚àà(0, 1)\nis the predefined noise scheduling coefficient, and N denotes the\nGaussian distribution.\n3.2.2\nReverse Process. In the reverse process, DMs learn to remove\nthe added noise, thereby recovering the original data distribution\nùë•0 from pure noise, aiming to introduce minor uncertainties in the\ngeneration process. This process learns a parameterized network\nùëùùõø(ùë•ùë°‚àí1 | ùë•ùë°) to approximate the reverse process, which can be\nformalized as ùëùùõø(ùë•ùë°‚àí1 | ùë•ùë°) = N (ùë•ùë°‚àí1; ùúáùõø(ùë•ùë°,ùë°), Œ£ùõø(ùë•ùë°,ùë°)), where\nùúáùõøand Œ£ùõøare the mean and variance of the Gaussian distribution\npredicted by a neural network with parameters ùõø.\n4\nMethod\nOverview. The core idea of this work is to transfer prior diagnos-\ntic results from the source domain to the target domain, thereby\ngenerating personalized initial abilities for cold-start examinees\nin the target domain course. As illustrated in Figure 2, our DCSR\nis built upon the Diffusion Module and is supported by two key\ncomponents: the Cognitive State Unification Module (CSUM) and\nthe Harmonization and Calibration Module (HCM). Specifically, the\nDiffusion Module uses prior abilities from the source domain to\nreconstruct the cognitive state of examinees in the target domain\nfrom noise. From a causal model perspective, the generated abili-\nties are influenced by redundant knowledge, and domain-specific\ncognition may cause negative transfer. Therefore, the CSUM is\nemployed to control confounding variables in the backdoor path,\nthereby uncovering the true causal relationships. Additionally, to\nmitigate uncertainty during the diffusion process, we designed con-\nsistency and task-oriented constraints in HCM, aiming to ensure\nthat the generated results adhere to the true distribution and meet\nthe requirements of CAT task. It is worth noting that our frame-\nwork demonstrates significant scalability, seamlessly integrating\nthe generated initial abilities in the target domain into existing CAT,\nthereby improving its cold-start performance.\n4.1\nDiffusion Module\nWe employ the concept of diffusion as the backbone of our model,\nestablishing a bridge for cognitive state transformation between the\nsource and target domains. The purpose of the Diffusion Module is\nto incorporate prior information from the source domain into the\ninitial ability estimation process in the target domain. Therefore,\nit inherently involves two distinct processes: the forward noise\naddition process and the reverse denoising process.\nDuring training, we gradually inject Gaussian noise into the\nability vectors ŒòT of examinees in the target domain over ùëásteps.\nFor a specific examinee ùëíùëñ‚ààEO, his ability vector ùúÉT\nùëñ0 = ùúÉT\nùëñ\n‚ààŒòT\nis corrupted into ùúÉT\nùëñ1:ùëá, which is modeled as a Gaussian transition\nMarkov chain:\nùëû(ùúÉT\nùëñ1:ùëá| ùúÉT\nùëñ0 ) =\nùëá\n√ñ\nùë°=1\nN (ùúÉT\nùëñùë°;\n‚àöÔ∏Å\n1 ‚àíùõΩùë°ùúÉT\nùëñùë°‚àí1, ùõΩùë°I)\n(3)\n\nDiffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nwhere ùõΩùë°‚àà(0, 1) controls the scale of noise added at the $t$-th\nstep, and N denotes a Gaussian distribution.\nIn the reverse denoising process, the traditional denoising meth-\nods (as introduced in section 3.2.2) are inadequate for effective\ntransfer because the denoising process modeled lacks guidance\nfrom source domain information, resulting in the loss of personal-\nization in the generated abilities. To generate personalized ability\nvectors, we propose utilizing prior information from the source\ndomain to guide the denoising process. Specifically, for examinee ùëíùëñ,\nwe use the pretrained source domain ability ùúÉS\nùëñ\n‚ààŒòS as guidance:\nùëùùõø( ÀÜ\nùúÉT\nùëñùë°‚àí1 | ùúÉT\nùëñùë°,ùúÉS\nùëñ) = N ( ÀÜ\nùúÉT\nùëñùë°‚àí1; ùúáùõø(ùúÉT\nùëñùë°,ùúÉS\nùëñ,ùë°), Œ£ùõø(ùúÉT\nùëñùë°,ùúÉS\nùëñ,ùë°)),\n(4)\nwhere ùúáùõøand Œ£ùõøare the parameters output by neural networks\nwith learnable parameters ùõø.\n4.2\nCognitive State Unification Module\nAlthough using unified source domain abilities obtained through\nCDM to guide the reverse denoising process is a promising ap-\nproach, from the causal perspective of the model, as shown in\nthe right side of Figure 2, the generated ability ùëåis influenced\nby domain-shared cognition ùëã, domain-specific cognition ùê¥1, and\ntarget domain ability ùêµduring the training phase. This is because\nwe use random sampling of time steps for training, which retains\nsome personalized information in the target domain ability vector\neven while introducing noise. In other words, ùúÉT\nùëñ1:ùëádoes not approx-\nimate standard Gaussian noise, which lacks extensive personalized\nfeatures. However, the inclusion of domain-specific cognition ùê¥1\nincreases the complexity of the model and reduces its generaliza-\ntion ability, making the model prone to overfitting. Therefore, we\npropose to explore the causal relationship between the generated\nresult ùëåand the domain-shared cognition ùëãand the pretrained\nability ùêµof the target domain, which can also be further decoupled\ninto domain-specific cognition ùêµ1 and domain-shared cognition ùëã.\nNext, we will specifically analyze the impact of different factors on\nthe generated result.\nFirst, there are three paths between domain-shared cognition ùëã\nand the generated results ùëå: ùëã‚Üíùëå, ùëã‚Üê{ùê¥,ùê¥1} ‚Üíùëå, and ùëã‚Üê\n{ùêµ, ùêµ1} ‚Üíùëå, where the latter two paths are confounding paths. We\nwill apply the backdoor criterion to explore the causal relationship\nof ùëã‚Üíùëå, which means we need to control the confounding\nvariables ùê∂= {ùê¥,ùê¥1} ‚à™{ùêµ, ùêµ1} to block the backdoor paths:\nùëÉ(ùëå| ùëëùëú(ùëã)) =\n‚àëÔ∏Å\nùê∂\nùëÉ(ùëå| ùëã,ùê∂= ùëê)ùëÉ(ùê∂= ùëê),\n(5)\nwhere the first term represents the effect ofùëãonùëåwhile controlling\nfor the confounding variables ùê∂, and the second term represents\nthe joint probability distribution of the confounding variables. To\ncontrol the confounding variables, inspired by [8], we decouple the\ndomain-shared cognition ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\nfrom all the prior abilities in the\nsource and target domains:\nùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n= ùëìùúë2 (ùúé(ùëìùúë1 (ùúÉT\nùëñ\n‚à•Eùëö‚àºSùëÄWùëöùúÉSùëö\nùëñ\n))),\n(6)\nwhere ùëä‚ààRùëÄ√óùëëis a weight matrix used to map the pretrained\nabilities from multiple domains into the same feature space, where\nùëëis the feature dimension related to CDM, ùëìùúë1 and ùëìùúë2 are linear\nlayers with different parameters, ùúérefers to the activation function,\nand (¬∑ ‚à•¬∑) denotes the concat operation. We then encourage this de-\ncoupled domain-shared cognition to assist in predicting responses\nacross all domains:\nL1 =\n‚àëÔ∏Å\n(ùëíùëñ,ùëûT\nùëó,ùëüT\nùëñùëó)‚ààRùë§ùëéùëüùëö\nT\n‚à•ùëüT\nùëñùëó‚àíMùúôùëá(ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n,ùëûT\nùëó)‚à•\n+\nùëÄ\n‚àëÔ∏Å\nSùëö=1\n‚àëÔ∏Å\n(ùëíùëñ,ùëûSùëö\nùëó\n,ùëüSùëö\nùëñùëó\n)‚ààRSùëö\n‚à•ùëüSùëö\nùëñùëò\n‚àíMùúôùëÜùëö(ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n,ùëûSùëö\nùëò\n)‚à•,\n(7)\nwhereùúÉùë†‚Ñéùëéùëüùëíis encouraged to predict responses across all scenarios,\nincluding the target domain in the first term and all source domain\nresponse data in the second term. Next, the specific cognition of the\ntarget domain ùêµ1 has two paths influencing the generated results:\nùêµ1 ‚Üíùëåand ùêµ1 ‚Üê{ùëã, ùêµ} ‚Üíùëå. We adjust the confounding variable\n{ùëã, ùêµ} in the second confounding path to block the backdoor path.\nSpecifically, we extract the specific cognition of the target domain,\nwhich will be used as input in the section 4.1 alongside obtaining\nthe overall cognitive state of the target domain (corresponding to\nevent ùêµin the causal graph):\nùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ\n= ùëìùúë4 (ùúé(ùëìùúë3 (ùúÉT))),\nùúÉùëêùëúùëõùëêùëéùë°\nùëñ\n= ùëìùúë5 (ùúé(ùëìùúë6 (ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ\n‚à•ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n))),\n(8)\nwhere ùëì{ùúë3,ùúë4,ùúë5,ùúë6} are four linear layers with different parameters.\nTo learn the specific cognition of the target domain, we propose\na novel decoupling strategy, which encourages the prediction of\nwithin-domain response results by domain-specific cognition while\ndegrading performance in other domains:\nL2 =\n‚àëÔ∏Å\n(ùëíùëñ,ùëûT\nùëó,ùëüT\nùëñùëó)‚ààRùë§ùëéùëüùëö\nT\n\u0010\n‚à•ùëüT\nùëñùëó‚àíMùúôùëá(ùúÉùëêùëúùëõùëêùëéùë°\nùëñ\n,ùëûT\nùëó)‚à•\n+ ‚à•ùëüT\nùëñùëó‚àíMùúôùëá(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ\n,ùëûT\nùëó)‚à•\n\u0011\n‚àí\nùëÄ\n‚àëÔ∏Å\nSùëö=1\n‚àëÔ∏Å\n(ùëíùëñ,ùëûSùëö\nùëó\n,ùëüSùëö\nùëñùëó\n)‚ààRSùëö\n\u0010\n‚à•ùëüSùëö\nùëñùëò\n‚àíMùúôùëÜùëö(ùúÉùëêùëúùëõùëêùëéùë°\nùëñ\n,ùëûSùëö\nùëò\n)‚à•\n+ ‚à•ùëüSùëö\nùëñùëò\n‚àíMùúôùëÜùëö(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ\n,ùëûSùëö\nùëò\n)‚à•\n\u0011\n+ Eùëíùëñ‚ààEOùëö‚à•ùúÉT\nùëñ‚àíùúÉùëêùëúùëõùëêùëéùë°\nùëñ\n‚à•.\n(9)\nHere, the first term encourages the target domain-specific cognition\nto assist in predicting the response records in target domain, both in-\ndependently and in conjunction with domain-shared cognition. The\nsecond term aims to intentionally degrade prediction performance\nin the source domains, indicating that the target domain-specific\ncognition is not applicable to the source domains. The third term\nconstrains the diagnostic abilities obtained from pre-training. Addi-\ntionally, to further control the influence of confounding variables on\nthe generated results, we apply gradient-based orthogonal regular-\nization [6] to ensure the independence of the above representations\nin the feature space:\nL3 =\n\r\r\r\n‚àáùúë1,ùúë2L1\n‚à•‚àáùúë1,ùúë2L1‚à•¬∑\n‚àáùúë3,ùúë4L2\n‚à•‚àáùúë3,ùúë4L2‚à•\n\r\r\r2.\n(10)\nThis approach minimizes the influence of domain-specific cognition\nwhen learning domain-shared cognition, and vice versa.\n\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nHaiping Ma et al.\nTherefore, the parameters in the forward and reverse\nprocesses\nare\nupdated\nto\nùëû(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n| ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°‚àí1\n)\nand\nùëùùõø(\nÀÜ\nùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°‚àí1\n| ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n,ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n), respectively.\n4.3\nHarmonization and Calibration Module\nTo learn the parameters ùõøof the denoising network, DCSR aims\nto maximize the Evidence Lower Bound (ELBO) of the observed\nexaminee ability ùúÉTùë†ùëùùëíùëêùëñùëìùëê\nùëñ\n:\nlog ùëù(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ\n) ‚â•E\nùëû(ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n|ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ1\n)\nh\nlog ùëùùõø(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n| ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ1\n)\ni\n|                                                                  {z                                                                  }\n:=L0\n‚àí\nùëá\n‚àëÔ∏Å\nùë°=2\nE\nùëû(ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n|ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n)\nh\nKL(q(ùúÉTspecific\nit‚àí1\n| ùúÉTspecific\nit\n,ùúÉTspecific\ni0\n)) ‚à•pùõø(ùúÉTspecific\nit‚àí1\n| ùúÉTspecific\nit\n)\ni\n|                                                                                                          {z                                                                                                          }\n:=Lùë°‚àí1\n.\n(11)\nHere, the first term represents the reconstruction term, which re-\ncovers the probability ofùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n. The second term is the denoising\nmatching term, which aligns the intractable posterior probability\nùëùùõø(¬∑) with the tractable distribution ùëû(¬∑). To maintain training sta-\nbility and simplify computation, we ignore the learning of Œ£ùõø(¬∑)\nand set it to a fixed valueùõΩùë°as in the forward process [11, 35]. The\ndenoising matching term can then be further computed as:\nLùë°‚àí1 = E\nùëû(ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n|ùúÉ\nTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ1\n)\n\u0014 1\n2ùõΩùë°\n\r\r\rùúáùõø(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n,ùúÉùë†‚Ñéùëéùëüùëí,ùë°)\n‚àíeùúá(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n,ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n)\n\r\r\r\ni\n,\n(12)\nwhere\neùúá(¬∑)\nsatisfies\nthe\ntractable\ndistribution\nùëû(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°‚àí1\n| ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°\n,ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñ0\n) = N (ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùë°‚àí1\n; eùúá(¬∑), ùõΩùë°I).\nAlthough the above training objective ensures diversity in gen-\nerated samples, excessive randomness introduced by the diffusion\nmodel during training and inference stages may result in generated\noutcomes that do not match the requirements of the CAT system.\nTherefore, we constrain the generated ability vectors from two\naspects: Consistency Constraint and Task-oriented Constraint.\n4.3.1\nConsistency Constraint. aims to minimize the difference be-\ntween generated vectors and real data samples in the feature space,\nthus limiting uncertainty within a controllable range. Specifically,\nthe Diffusion Module diffuses the domain-shared cognitive fea-\ntures into domain-specific cognitive features. Firstly, the general\ncognitive features of the target domain are generated as ÀÜ\nùúÉT\nùëñ:\nÀÜ\nùúÉT\nùëñ\n= ùúáùõø(ùúÉTùë†ùëùùëíùëêùëñùëìùëñùëê\nùëñùëá:1\n,ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n,ùë°ùëá:1) + ùõΩùë°ùúñ,ùúñ‚àà(0, 1).\n(13)\nDue to inherent randomness, the generated ability vectors are noisy,\nwhich is not conducive to reflecting the examinee‚Äôs true ability.\nThus, the consistency constraint aims to minimize the difference\nbetween ÀÜ\nùúÉT\nùëñ\nand the target domain ability features ùúÉT\nùëñ\nobtained\nthrough pre-training, which can be modeled as:\nLùëêùëê= Eùëíùëñ‚ààEO (ùúÉT\nùëñ‚àíÀÜ\nùúÉT\nùëñ)2.\n(14)\n4.3.2\nTask-oriented Constraint. ensures that the generated ability\nfeatures meet the requirements of the CAT task. Specifically, we\nsample some questions ùëûùëó‚ààRùë§ùëéùëüùëö\nT\nfrom the training set of the\ntarget domain and match the generated target domain general\nStatistics\nC\nC++\nDS\nJava\nPython\n#Examinee 3,856\n3,856\n3,856\n3,856\n3,856\n#Question\n115,335\n10,241\n14,207\n10,043\n11,600\n#Concept\n654\n472\n560\n541\n480\n#Log\n2,163,624\n1,332,005\n1,398,444\n1,086,906\n923,879\nTable 1: The statistics of the datasets.\ncognitive features ÀÜ\nùúÉT\nùëñ\nwith the CDM:\n‚àáÀÜ\nùúÉT Lùë°ùëê= ‚àí\n‚àëÔ∏Å\n(ùëíùëñ,ùëûùëó,ùëüùëñùëó)‚ààRùë§ùëéùëüùëö\nT\n\u0010\nùëüùëñùëólog\u0000MùúìT ( ÀÜ\nùúÉT\nùëñ,ùëûùëó)\u0001\n+ (1 ‚àíùëüùëñùëó)log\u00001 ‚àíMùúìT ( ÀÜ\nùúÉT\nùëñ,ùëûùëó)\u0001\u0011\n,\n(15)\nwhere MùúìT (¬∑) denotes the pre-trained CDM for the target domain,\nwith its parameters frozen, and only the network parameters ùúáùõø(¬∑)\nof the denoising module are updated.\n4.4\nDCSR-CAT: Implementation of DCSR\nIn this section, we introduce DCSR-CAT as an implementation of\nDCSR to demonstrate its applicability to CAT.\nDuring this stage, DCSR no longer involves the forward process\nbut directly takes pure noise ùúñ0 ‚àºN (0, 1) as input. For a given\ncold-start examinee ùëíùëñ‚ààRùëêùëúùëôùëë\nT\nwho has response records only in\nthe source domain, we use the pre-trained CDM to obtain their\nprior ability and calculate their domain-shared cognitive features\nùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n. It is noteworthy that since the original ùúÉT\nùëñ\nis unknown, the\naverage cognitive state of the target domain is used as a substitute:\nùúÉTùëêùëúùëôùëë\nùëñ\n= Eùëíùëó‚ààRùë§ùëéùëüùëö\nT\nMùúìT ‚àáùúÉ(ùëíùëó),\n(16)\nwhich retains domain information to some extent. Therefore, sub-\nstituting back into equation (6), we obtain the shared cognitive\nability ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\nof the cold-start examinee ùëíùëñ. To improve inference\nefficiency, we use DPM-Solver [22] as a fast solver to efficiently\nobtain the initial ability of cold-start examinee:\nùúÉ0\nùëñ= Solver(ùúáùõø(¬∑),ùúÉùë†‚Ñéùëéùëüùëí\nùëñ\n,ùúñ0),\n(17)\nwhich is crucial for real-world applications. Our DCSR seamlessly\nintegrates with any existing question selection algorithm Œ†. At the\nbeginning of the test, the selection process can be represented as:\nùëû1 ‚ÜêŒ†(ùëÑùëñ| ùúÉ0\nùëñ),\n(18)\nwhich indicates that the item selection algorithm Œ† selects the\nappropriate item ùëû1 in step ùë°= 1 from the candidate item pool Qùëñ\nfor examinee ùëíùëñbased on the initial ability ùúÉ0\nùëñinitialized by DCSR.\nThe subsequent steps follow the general CAT system workflow.\n5\nExperiments\nIn this section, we conduct experiments with the aim of addressing\nthe following questions:\n‚Ä¢ RQ1: Can DCSR utilize prior information from a single do-\nmain or multiple domains to improve the cold start perfor-\nmance of existing CAT systems?\n‚Ä¢ RQ2: How effective are the key components of the DCSR\nframework?\n‚Ä¢ RQ3: Does DCSR alleviate the issue of the question selection\nalgorithm falling into local optima?\n\nDiffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nCDM\nIRT\nNCD\nCAT\nFisher\nMAAT\nMAAT\nBECAT\nNCAT\nMetrics\nAUC(%)@1/ACC(%)‚Üë@1\nBaselines\nRandom\nMLCCM\nDCSR\nOracle*\nRandom\nMLCCM\nDCSR\nOracle*\nRandom\nMLCCM\nDCSR\nOracle*\nRandom\nMLCCM\nDCSR\nOracle*\nRandom\nMLCCM\nDCSR\nOracle*\nC\nC++\n71.6/75.0\n78.5/77.5\n77.9/76.3\n79.5/75.4\n71.2/74.9\n78.5/77.4\n77.7/76.0\n79.6/75.7\n67.4/62.8\n74.7/74.6\n79.2/77.3\n88.0/83.1\n67.4/62.7\n74.6/74.6\n79.2/77.3\n88.0/83.0\n67.4/62.8\n74.5/74.6\n79.3/77.3\n88.0/83.1\nDS\n71.8/75.4\n75.5/77.0\n75.4/75.9\n77.2/78.2\n71.1/75.2\n74.9/76.8\n75.0/75.7\n77.2/78.2\n67.5/64.9\n77.7/76.6\n79.4/77.8\n89.3/84.3\n67.6/65.0\n77.7/76.6\n79.4/77.8\n89.3/84.3\n67.6/65.0\n77.7/76.6\n79.4/77.8\n89.3/84.4\nDS\nC\n67.4/74.8\n71.6/75.5\n72.5/75.9\n76.8/77.2\n67.1/74.8\n71.5/75.4\n72.4/75.8\n76.8/77.2\n66.1/67.3\n71.6/74.8\n71.7/74.1\n85.8/82.0\n66.0/67.3\n71.6/74.9\n71.7/74.1\n85.8/82.0\n66.1/67.3\n71.6/74.9\n71.7/74.1\n85.8/82.0\nC++\n71.6/75.0\n73.8/75.0\n74.5/75.5\n79.5/75.4\n71.2/74.9\n73.5/75.0\n74.1/75.3\n79.6/75.7\n67.4/62.8\n72.4/73.7\n74.4/74.9\n88.0/83.1\n67.4/62.7\n72.4/73.7\n74.4/74.9\n88.0/83.0\n67.4/62.8\n72.4/73.7\n74.4/74.9\n88.0/83.1\nC++\nC\n67.4/74.8\n74.2/76.0\n74.7/76.8\n76.8/77.2\n67.1/74.8\n74.2/76.1\n74.6/76.6\n76.8/77.2\n66.1/67.3\n72.8/75.3\n73.4/75.5\n85.8/82.0\n66.0/67.3\n72.8/75.3\n73.4/75.5\n85.8/82.0\n66.1/67.3\n72.8/75.2\n73.1/75.3\n85.8/82.0\nDS\n71.8/75.4\n71.9/76.5\n73.3/76.6\n77.2/78.2\n71.1/75.2\n71.4/76.3\n72.7/76.4\n77.2/78.2\n67.5/64.9\n76.4/76.5\n77.0/76.9\n89.3/84.3\n67.6/65.0\n76.4/76.5\n77.0/76.9\n89.3/84.3\n67.6/65.0\n76.4/76.5\n77.0/76.9\n89.3/84.4\nMetrics\nAUC(%)‚Üë@5/ACC(%)‚Üë@5\nC\nC++\n74.2/75.6\n78.9/77.9\n78.8/76.9\n79.2/74.7\n72.0/75.0\n78.2/77.3\n77.5/76.1\n79.7/76.3\n67.5/63.1\n74.8/74.6\n79.3/77.4\n88.0/83.0\n67.5/62.9\n74.7/74.6\n79.3/77.4\n88.0/83.1\n67.6/63.0\n74.7/74.7\n79.3/77.4\n88.0/83.1\nDS\n74.2/76.0\n76.9/77.7\n76.6/76.5\n77.4/78.3\n71.5/75.4\n75.0/76.9\n75.0/75.7\n77.2/78.1\n67.9/65.3\n77.9/76.7\n79.5/77.9\n89.2/84.2\n67.7/65.1\n77.8/76.7\n79.5.77.9\n89.3/84.4\n67.8/65.2\n77.8/76.7\n79.5/77.9\n89.3/84.4\nDS\nC\n68.5/75.0\n72.4/75.7\n73.1/76.1\n76.8/77.3\n67.4/74.8\n71.8/75.6\n72.6/75.9\n76.7/77.2\n66.3/67.5\n71.6/74.8\n71.8/74.1\n85.9/82.1\n66.1/67.4\n71.6/74.9\n71.7/74.1\n85.8/82.0\n66.2/67.4\n71.7/74.9\n71.7/74.1\n85.8/82.1\nC++\n74.2/75.6\n75.3/75.7\n76.3/76.4\n79.2/74.7\n72.0/75.0\n74.0/75.2\n74.9/75.8\n79.7/76.3\n67.5/63.1\n72.6/73.8\n74.5/75.0\n88.0/83.0\n67.5/62.9\n72.5/73.8\n74.5/75.0\n88.0/83.1\n67.6/63.0\n72.5/73.8\n74.5/75.0\n88.0/83.1\nC++\nC\n68.5/75.0\n74.4/75.9\n74.8/76.9\n76.8/77.3\n67.4/74.8\n74.4/76.2\n74.7/76.7\n76.7/77.2\n66.3/67.5\n72.9/75.4\n73.5/75.5\n85.9/82.1\n66.1/67.4\n72.9/75.4\n73.4/75.5\n85.8/82.0\n66.2/67.4\n72.9/75.3\n73.2/75.3\n85.8/82.1\nDS\n74.2/76.0\n73.4/77.2\n75.1/77.3\n77.4/78.3\n71.5/75.4\n71.8/76.4\n73.1/76.5\n77.2/78.1\n67.9/65.3\n76.6/76.7\n77.1/77.0\n89.2/84.2\n67.7/65.1\n76.5/76.6\n77.0/77.0\n89.3/84.4\n67.8/65.2\n76.5/76.6\n77.0/77.0\n89.3/84.4\nTable 2: The AUC/ACC performance in six scenarios. The best results are highlighted in bold, while ‚àódenotes the upper bounds.\n‚Ä¢ RQ4: Can DCSR enhance the cold start effect of cognitive\ndiagnosis models?\n‚Ä¢ RQ5: Is the initial ability assigned by DCSR to cold start\nexaminees reasonable?\n5.1\nExperimental Settings\nIn this section, we introduce the datasets, the selected baselines,\nand the application of CAT.\n5.1.1\nDataset Description. We conducted experiments on five\nreal-world datasets collected from the publicly available PTADisc\ndataset [14], covering courses in Data Structures (DS), C, C++,\nPython, and Java programming languages. These datasets are\nsourced from the PTA platform, which records the learning perfor-\nmance of examinees across a series of courses. Each dataset provides\nthe response records of the examinees and question-concept rela-\ntion, with each dataset considered as a distinct domain. We first\nexcluded examinees with fewer than 100 response records from\neach dataset. The statistics of the processed datasets are shown\nin Table 1. For fairness in testing, we randomly split the filtered\nexaminee records into a training set and a test set in an 80%:20%\nratio. Examinees in the test set are considered cold-start examinees\nin the current (target) domain, meaning their response records in\nother domains are included in the training set. The training set\nis only used for training DSCR and the learning-based question\nselection algorithm, preventing data leakage.\n5.1.2\nBaseline Methods. To demonstrate the effectiveness and com-\npatibility of our framework, we applied it to four widely used CAT\nsystems, including the strategy-based Fisher [21], MAAT [1], BE-\nCAT [50], and the data-driven NCAT [49]. We select cross-domain\nbaselines for comparison, where the Random and Oracle methods\nrepresent the lower and upper bounds of CAT cold-start perfor-\nmance, respectively.\n‚Ä¢ Random: This method randomly predicts the initial ability\nof examinees in the target domain from a ùëàùëõùëñùëìùëúùëüùëö(0, 1)\ndistribution, which is the most common method in existing\nCAT system.\n‚Ä¢ MLCCM: A cross-course method based on meta-learning,\napplying the idea of meta-learning to learn cross-domain\nmapping functions from the training set.\n‚Ä¢ Oracle: This method uses CDM to directly train the target\ndomain ability from the response records of examinees in\nthe target domain (test set).\n5.1.3\nEvaluation Metrics. The performance of our DCSR will be\nvalidated during the testing phase of the CAT system. We evaluate\nthe accuracy of the final ability estimation by predicting examinees‚Äô\nbinary responses to the test question set. For this purpose, we\nuse the area under the Area Under ROC Curve (AUC) [2, 40] and\nAccuracy (ACC) as evaluation metrics.\n5.1.4\nParameter Settings. In the pre-training phase, for IRT, we set\nthe latent feature dimension of both examinees and questions to 1,\nwhile for NCD, it is set to the number of knowledge concepts in the\ncorresponding domain. Additionally, we uniformly set the batch size\nand learning rate to 32 and 0.002, respectively, for this phase. In the\nDSCR training phase, the forward process of the diffusion module\nis set to 1000 steps of noise addition, and DPM-solver [22] is used\nto accelerate sampling, which is performed in 30 steps. Meanwhile,\nthe batch size and learning rate are fixed at 256 and 0, respectively,\nin this phase. We initialize all parameters using Xavier [10], and use\nthe Adam [16] optimizer. In the CAT testing phase, the question\nselection algorithms follow the settings in the original papers, with\nthe test length set to 1 and 5, and the random seed in all the above\nprocesses is set to 0. All experiments are conducted on an NVIDIA\nRTX4090 GPU.\n5.2\nOverall Performance (RQ1)\nTo verify the effectiveness of the proposed framework in addressing\nthe CSIP challenge, we compared DCSR with other cross-domain\nbaselines using both single and multi domain as prior knowledge,\nsetting the question selection steps to 1 and 5. First, we explored\nleveraging a single domain as the source domain, encompassing six\ncross-domain scenarios. We rotated each dataset to play the role\nof the target domain, with other datasets serving as the source do-\nmain. The experimental results presented in Table 2 show that our\n\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nHaiping Ma et al.\nFigure 3: Comparison of the prior information provided by\nmulti and single domain in the NCD-MAAT CAT system.\nFigure 4: Ablation study on key components.\nproposed DCSR not only outperforms all baselines in the CAT cold-\nstart task across all six scenarios but also adapts well to strategy-\nbased and learning-based selection algorithms. Additionally, we\nobserved the following: (1) Compared to the commonly used Ran-\ndom method, DCSR provides more accurate initial ability estimates\nfor cold-start examinees, especially when there is a significant cor-\nrelation between the source and target domains, such as C and C++,\nwhere DCSR clearly outperforms other baselines and approaches\nthe performance of the Oracle method. This demonstrates the ef-\nfectiveness of using examinees‚Äô domain-shared cognition as the\ntransfer condition. (2) Compared to MLCCM, DCSR does not rely\nheavily on supervised training, thereby avoiding overfitting to the\nlabels. Moreover, in most scenarios, the ability assigned by DCSR\nat the initial stage shows better performance than the results diag-\nnosed by other methods after multiple rounds of selection.\nNext, we explored using multi-domain information as the source\ndomain, covering three scenarios where C, C++, and DS were set\nas the target domains, with other courses serving as the source\ndomain. As shown in Figure 3, compared to single-domain infor-\nmation, the multi-domain enriches the common cognition, and the\ncorrelation between courses significantly helps resolve the CSIP.\nThe performance in the first two scenarios is particularly effective\ndue to the overlap of concepts between programming languages.\n5.3\nAblation Study (RQ2)\nThis section provides an in-depth analysis of how key components\nin DCSR contribute to addressing the CSIP challenge. We conducted\nexperiments by individually removing the Cognitive State Unifica-\ntion Module (CSUM) in section 4.2 (denoted as w/o CSUM) and the\nFigure 5: Results under extended testing procedures in the\nIRT-Fisher CAT system.\nHarmonization and Calibration Module (HCM) in section 4.3 (de-\nnoted as w/o HCM). CSUM provides diffusion guidance for the\nDiffusion Module (DM), while HCM constrains the DM‚Äôs output to\nmatch the CAT task. As shown in Figure 4, we validated the impact\nof different components on DCSR in the NCD-MAAT CAT system,\nwith C set as the target domain and other domains as the source\ndomains. Specifically, when CSUM is removed from DSCR, perfor-\nmance drops significantly, indicating that the specific cognition\nof the source domain, as a confounding variable, hinders the true\ncausal effect, leading to negative transfer. Similarly, when HCM\nis removed, there is also a certain degree of performance decline,\nsuggesting that excessive uncertainty affects the alignment of the\ngenerated results with the CAT task. Therefore, all components\ncontribute to DCSR to varying degrees.\n5.4\nPerformance under long test steps (RQ3)\nTo explore the impact of DCSR on cold-start performance under a\ngreedy algorithm, as shown in Figure 5, we extended the test length\nin the IRT-Fisher CAT system and used single-domain information\nas the prior information provider, with the commonly used Random\nmethod as the baseline. We observed that in the early stages of\ntesting, regardless of the source domain, cold-start performance\nimproves significantly. Notably, when C++ is used as the source\ndomain, the initial effect already surpasses the Random method\nafter 60 rounds of question selection due to the correlation between\ncourses. This demonstrates that DCSR not only alleviates the issue\nof selection algorithms falling into local optima but also guides\nthe selection algorithm by providing an accurate starting point for\ntesting. Additionally, even when a weakly correlated course is used\nas the source domain, the optimal result of the traditional Random\nmethod can be achieved within a shorter test length.\n5.5\nCold-Start in Cognitive Diagnosis (RQ4)\nTo explore the performance of DCSR in addressing the cold-start\nproblem in cognitive diagnosis task, we directly applied DCSR to\nCDM, including unidimensional IRT and multidimensional NCD.\nAs shown in Figure 6, DCSR demonstrates superior performance\nin CDM across different dimensions, approaching Oracle perfor-\nmance in some scenarios. Moreover, in high-dimensional CDM, i.e.,\nNCD, DCSR further enhances cold-start performance in CD task.\nIt significantly outperforms the commonly used Random method.\nAdditionally, in scenarios where the correlation is not obvious,\n\nDiffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nFigure 6: Performance on cognitive diagnosis cold start task.\nFigure 7: T-SNE visualization of abilities in the target domain.\nsuch as using DS as the source domain and C++ as the target do-\nmain, DCSR shows better performance than MLCCM, significantly\noutperforming baselines.\n5.6\nAnalysis of Initialized Ability (RQ5)\nWe further explored whether the abilities assigned by DCSR to\nexaminees in the target domain are reasonable. We conducted the\nanalysis from two aspects. First, using high-dimensional NCD as the\nbackbone, we visualize the distribution of initial abilities assigned\nto examinees by different methods across 12 scenarios. As shown\nin Figure 7, the ability distribution assigned by the Random method\nis clearly spherical, which is not conducive to distinguishing be-\ntween examinees‚Äô abilities. In contrast to the localized clustering\npresented by MLCCM, DCSR is closer to that exhibited by Oracle,\nshowing clear differentiation. This demonstrates that introducing\nexaminees‚Äô cross-domain common cognition can generate more\npersonalized initial abilities. Secondly, we randomly selected an\nexaminee, obtained his diagnostic feedback using NCD, and ran-\ndomly selected ten knowledge concepts to calculate the difference\nbetween the diagnosis results of the corresponding dimensions and\nthe results of Oracle. As shown in Figure 8, DCSR shows signif-\nicantly lower fluctuation and tends to underestimate the ability\nof examinee rather than overestimate him as MLCCM does. This\nFigure 8: Case analysis of an individual examinee.\napproach better serves the CAT system, as underestimating abil-\nity can guide the selection algorithm to choose relatively simpler\nquestion, avoiding the negative emotions associated with overly\ndifficult question.\n6\nConclusion\nIn this paper, we propose the Diffusion Cognitive States Transfer\nFramework to address the Cold Start with Insufficient Prior (CSIP)\nin Computerized Adaptive Testing (CAT). This challenge compels\nCAT systems to use additional selection steps to mitigate the cold\nstart issue. To address this, we first reconstruct the examinee‚Äôs\ninitial ability in the target domain, guided by diffusion principle.\nConcurrently, we analyze the causal relationships in the gener-\nated outcomes from a model-based causal perspective, proposing\nthree decoupling strategies to block the two backdoor paths that\nhinder causal discovery. Subsequently, we introduce constraints\nfrom the perspectives of consistency and task-oriented to enforce\nalignment of the generated outcomes with the CAT system. There-\nfore, this framework can be applied to existing mainstream CAT\nsystems. Finally, extensive experiments highlight the effectiveness\nand applicability of our framework.\nReferences\n[1] Haoyang Bi, Haiping Ma, Zhenya Huang, Yu Yin, Qi Liu, Enhong Chen, Yu Su,\nand Shijin Wang. 2020. Quality meets diversity: A model-agnostic framework\nfor computerized adaptive testing. In 2020 IEEE International Conference on Data\nMining (ICDM). IEEE, 42‚Äì51.\n[2] Andrew P Bradley. 1997.\nThe use of the area under the ROC curve in the\nevaluation of machine learning algorithms. Pattern recognition 30, 7 (1997),\n1145‚Äì1159.\n[3] Shang Chai, Liansheng Zhuang, and Fengying Yan. 2023. Layoutdm: Transformer-\nbased diffusion model for layout generation. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 18349‚Äì18358.\n[4] Hua-Hua Chang and Zhiliang Ying. 1996. A global information approach to\ncomputerized adaptive testing. Applied Psychological Measurement 20, 3 (1996),\n213‚Äì229.\n[5] Susan E Embretson and Steven P Reise. 2013. Item response theory. Psychology\nPress.\n[6] Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. 2020. Orthogonal\ngradient descent for continual learning. In International Conference on Artificial\nIntelligence and Statistics. PMLR, 3762‚Äì3773.\n[7] Weibo Gao, Qi Liu, Zhenya Huang, Yu Yin, Haoyang Bi, Mu-Chun Wang, Jianhui\nMa, Shijin Wang, and Yu Su. 2021. RCD: Relation map driven cognitive diagnosis\nfor intelligent education systems. In Proceedings of the 44th international ACM\nSIGIR conference on research and development in information retrieval. 501‚Äì510.\n[8] Weibo Gao, Qi Liu, Hao Wang, Linan Yue, Haoyang Bi, Yin Gu, Fangzhou Yao,\nZheng Zhang, Xin Li, and Yuanjing He. 2024. Zero-1-to-3: Domain-Level Zero-\nShot Cognitive Diagnosis via One Batch of Early-Bird Students towards Three\n\nKDD ‚Äô25, August 03‚Äì07, 2025, Toronto, ON, Canada\nHaiping Ma et al.\nDiagnostic Objectives. In Proceedings of the AAAI Conference on Artificial Intelli-\ngence, Vol. 38. 8417‚Äì8426.\n[9] Aritra Ghosh and Andrew Lan. 2021. Bobcat: Bilevel optimization-based com-\nputerized adaptive testing. arXiv preprint arXiv:2108.07386 (2021).\n[10] Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training\ndeep feedforward neural networks. In Proceedings of the thirteenth international\nconference on artificial intelligence and statistics. JMLR Workshop and Conference\nProceedings, 249‚Äì256.\n[11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic\nmodels. Advances in neural information processing systems 33 (2020), 6840‚Äì6851.\n[12] Yuting Hong, Shiwei Tong, Wei Huang, Yan Zhuang, Qi Liu, Enhong Chen, Xin\nLi, and Yuanjing He. 2023. Search-Efficient Computerized Adaptive Testing.\nIn Proceedings of the 32nd ACM International Conference on Information and\nKnowledge Management. 773‚Äì782.\n[13] Yu Hou, Jin-Duk Park, and Won-Yong Shin. 2024. Collaborative Filtering Based\non Diffusion Models: Unveiling the Potential of High-Order Connectivity. In\nProceedings of the 47th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval. 1360‚Äì1369.\n[14] Liya Hu, Zhiang Dong, Jingyuan Chen, Guifeng Wang, Zhihua Wang, Zhou Zhao,\nand Fei Wu. 2023. PTADisc: a cross-course dataset supporting personalized learn-\ning in cold-start scenarios. Advances in Neural Information Processing Systems 36\n(2023), 44976‚Äì44996.\n[15] Yangqin Jiang, Yuhao Yang, Lianghao Xia, and Chao Huang. 2024. Diffkg: Knowl-\nedge graph diffusion model for recommendation. In Proceedings of the 17th ACM\nInternational Conference on Web Search and Data Mining. 313‚Äì321.\n[16] Diederik Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimiza-\ntion. Computer Science (2014).\n[17] Zihao Li, Aixin Sun, and Chenliang Li. 2023. Diffurec: A diffusion model for\nsequential recommendation. ACM Transactions on Information Systems 42, 3\n(2023), 1‚Äì28.\n[18] Qidong Liu, Fan Yan, Xiangyu Zhao, Zhaocheng Du, Huifeng Guo, Ruiming Tang,\nand Feng Tian. 2023. Diffusion augmentation for sequential recommendation.\nIn Proceedings of the 32nd ACM International Conference on Information and\nKnowledge Management. 1576‚Äì1586.\n[19] Qi Liu, Yan Zhuang, Haoyang Bi, Zhenya Huang, Weizhe Huang, Jiatong Li,\nJunhao Yu, Zirui Liu, Zirui Hu, Yuting Hong, et al. 2024.\nSurvey of Com-\nputerized Adaptive Testing: A Machine Learning Perspective. arXiv preprint\narXiv:2404.00712 (2024).\n[20] Shuhuan Liu, Xiaoshan Yu, Haiping Ma, Ziwen Wang, Chuan Qin, and Xingyi\nZhang. 2023. Homogeneous Cohort-Aware Group Cognitive Diagnosis: A Multi-\ngrained Modeling Perspective. In Proceedings of the 32nd ACM International\nConference on Information and Knowledge Management. 4094‚Äì4098.\n[21] Frederic M Lord. 2012. Applications of item response theory to practical testing\nproblems. Routledge.\n[22] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.\n2022. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in\naround 10 steps. Advances in Neural Information Processing Systems 35 (2022),\n5775‚Äì5787.\n[23] Haiping Ma, Siyu Song, Chuan Qin, Xiaoshan Yu, Limiao Zhang, Xingyi Zhang,\nand Hengshu Zhu. 2024. DGCD: An Adaptive Denoising GNN for Group-level\nCognitive Diagnosis. In The 33rd International Joint Conference on Artificial Intel-\nligence (IJCAI-24).\n[24] Haiping Ma, Changqian Wang, Hengshu Zhu, Shangshang Yang, Xiaoming\nZhang, and Xingyi Zhang. 2024.\nEnhancing cognitive diagnosis using un-\ninteracted exercises: A collaboration-aware mixed sampling approach. In Pro-\nceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 8877‚Äì8885.\n[25] Haokai Ma, Ruobing Xie, Lei Meng, Xin Chen, Xu Zhang, Leyu Lin, and Zhan-\nhui Kang. 2024. Plug-in diffusion model for sequential recommendation. In\nProceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 8886‚Äì8894.\n[26] Haiping Ma, Yong Yang, Chuan Qin, Xiaoshan Yu, Shangshang Yang, Xingyi\nZhang, and Hengshu Zhu. 2024. HD-KT: Advancing Robust Knowledge Tracing\nvia Anomalous Learning Interaction Detection. In Proceedings of the ACM on Web\nConference 2024. 4479‚Äì4488.\n[27] Haiping Ma, Yi Zeng, Shangshang Yang, Chuan Qin, Xingyi Zhang, and Limiao\nZhang. 2023. A novel computerized adaptive testing framework with decoupled\nlearning selector. Complex & Intelligent Systems 9, 5 (2023), 5555‚Äì5566.\n[28] Wim J Van der Linden and Cees AW Glas. 2000. Computerized adaptive testing:\nTheory and practice. Springer.\n[29] Jill-J√™nn Vie, Fabrice Popineau, √âric Bruillard, and Yolaine Bourda. 2017. A review\nof recent advances in adaptive assessment. Learning analytics: Fundaments,\napplications, and trends: A view of the current state of the art to enhance e-learning\n(2017), 113‚Äì142.\n[30] Howard Wainer, Neil J Dorans, Ronald Flaugher, Bert F Green, and Robert J\nMislevy. 2000. Computerized adaptive testing: A primer. Routledge.\n[31] Joojo Walker, Ting Zhong, Fengli Zhang, Qiang Gao, and Fan Zhou. 2022. Rec-\nommendation via collaborative diffusion generative model. In International Con-\nference on Knowledge Science, Engineering and Management. Springer, 593‚Äì605.\n[32] Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yuying Chen, Yu Yin, Zai Huang,\nand Shijin Wang. 2020. Neural cognitive diagnosis for intelligent education\nsystems. In Proceedings of the AAAI conference on artificial intelligence, Vol. 34.\n6153‚Äì6161.\n[33] Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yu Yin, Shijin Wang, and Yu Su.\n2022. NeuralCD: a general framework for cognitive diagnosis. IEEE Transactions\non Knowledge and Data Engineering 35, 8 (2022), 8312‚Äì8327.\n[34] Hangyu Wang, Ting Long, Liang Yin, Weinan Zhang, Wei Xia, Qichen Hong,\nDingyin Xia, Ruiming Tang, and Yong Yu. 2023. GMOCAT: A Graph-Enhanced\nMulti-Objective Method for Computerized Adaptive Testing. In Proceedings of\nthe 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.\n2279‚Äì2289.\n[35] Wenjie Wang, Yiyan Xu, Fuli Feng, Xinyu Lin, Xiangnan He, and Tat-Seng Chua.\n2023. Diffusion recommender model. In Proceedings of the 46th International ACM\nSIGIR Conference on Research and Development in Information Retrieval. 832‚Äì841.\n[36] Yuner Xuan. 2024. Diffusion Cross-domain Recommendation. arXiv preprint\narXiv:2402.02182 (2024).\n[37] Shangshang Yang, Mingyang Chen, Ziwen Wang, Xiaoshan Yu, Panpan Zhang,\nHaiping Ma, and Xingyi Zhang. 2024. DisenGCD: A Meta Multigraph-assisted\nDisentangled Graph Learning Framework for Cognitive Diagnosis. arXiv preprint\narXiv:2410.17564 (2024).\n[38] Shangshang Yang, Haiping Ma, Ying Bi, Ye Tian, Limiao Zhang, Yaochu Jin,\nand Xingyi Zhang. 2024. An evolutionary multi-objective neural architecture\nsearch approach to advancing cognitive diagnosis in intelligent education. IEEE\nTransactions on Evolutionary Computation (2024).\n[39] Shangshang Yang, Linrui Qin, and Xiaoshan Yu. 2024. Endowing Interpretability\nfor Neural Cognitive Diagnosis by Efficient Kolmogorov-Arnold Networks. arXiv\npreprint arXiv:2405.14399 (2024).\n[40] Shangshang Yang, Ye Tian, Cheng He, Xingyi Zhang, Kay Chen Tan, and Yaochu\nJin. 2021. A gradient-guided evolutionary approach to training deep neural\nnetworks. IEEE Transactions on Neural Networks and Learning Systems 33, 9\n(2021), 4861‚Äì4875.\n[41] Shangshang Yang, Haoyu Wei, Haiping Ma, Ye Tian, Xingyi Zhang, Yunbo Cao,\nand Yaochu Jin. 2023. Cognitive diagnosis-based personalized exercise group\nassembly via a multi-objective evolutionary algorithm. IEEE Transactions on\nEmerging Topics in Computational Intelligence 7, 3 (2023), 829‚Äì844.\n[42] Shangshang Yang, Xiaoshan Yu, Ye Tian, Xueming Yan, Haiping Ma, and Xingyi\nZhang. 2024. Evolutionary neural architecture search for transformer in knowl-\nedge tracing. Advances in Neural Information Processing Systems 36 (2024).\n[43] Shangshang Yang, Cheng Zhen, Ye Tian, Haiping Ma, Yuanchao Liu, Panpan\nZhang, and Xingyi Zhang. 2023. Evolutionary multi-objective neural architec-\nture search for generalized cognitive diagnosis models. In 2023 5th International\nConference on Data-driven Optimization of Complex Systems (DOCS). IEEE, 1‚Äì10.\n[44] Zhengyi Yang, Jiancan Wu, Zhicai Wang, Xiang Wang, Yancheng Yuan, and\nXiangnan He. 2024. Generate what you prefer: Reshaping sequential recommen-\ndation via guided diffusion. Advances in Neural Information Processing Systems\n36 (2024).\n[45] Xiaoshan Yu, Chuan Qin, Dazhong Shen, Haiping Ma, Le Zhang, Xingyi Zhang,\nHengshu Zhu, and Hui Xiong. 2024. Rdgt: enhancing group cognitive diagnosis\nwith relation-guided dual-side graph transformer. IEEE Transactions on Knowledge\nand Data Engineering (2024).\n[46] Xiaoshan Yu, Chuan Qin, Dazhong Shen, Shangshang Yang, Haiping Ma, Hengshu\nZhu, and Xingyi Zhang. 2024. Rigl: A unified reciprocal approach for tracing\nthe independent and group learning processes. In Proceedings of the 30th ACM\nSIGKDD Conference on Knowledge Discovery and Data Mining. 4047‚Äì4058.\n[47] Xiaoshan Yu, Chuan Qin, Qi Zhang, Chen Zhu, Haiping Ma, Xingyi Zhang,\nand Hengshu Zhu. 2024. DISCO: A Hierarchical Disentangled Cognitive Di-\nagnosis Framework for Interpretable Job Recommendation.\narXiv preprint\narXiv:2410.07671 (2024).\n[48] Jujia Zhao, Wang Wenjie, Yiyan Xu, Teng Sun, Fuli Feng, and Tat-Seng Chua. 2024.\nDenoising diffusion recommender model. In Proceedings of the 47th International\nACM SIGIR Conference on Research and Development in Information Retrieval.\n1370‚Äì1379.\n[49] Yan Zhuang, Qi Liu, Zhenya Huang, Zhi Li, Shuanghong Shen, and Haiping Ma.\n2022. Fully adaptive framework: Neural computerized adaptive testing for online\neducation. In Proceedings of the AAAI conference on artificial intelligence, Vol. 36.\n4734‚Äì4742.\n[50] Yan Zhuang, Qi Liu, GuanHao Zhao, Zhenya Huang, Weizhe Huang, Zachary\nPardos, Enhong Chen, Jinze Wu, and Xin Li. 2024. A bounded ability estimation\nfor computerized adaptive testing. Advances in Neural Information Processing\nSystems 36 (2024).",
    "pdf_filename": "Diffusion-Inspired_Cold_Start_with_Sufficient_Prior_in_Computerized_Adaptive_Testing.pdf"
}