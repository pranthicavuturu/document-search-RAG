{
    "title": "Benchmarking pre-trained text embedding models in",
    "abstract": "Accuratemappingofthebuiltassetinformationtoestablisheddataclassification systems and taxonomies is crucial for effective asset management, whether for complianceatprojecthandoverorad-hocdataintegrationscenarios. Duetothe complexnatureofbuiltassetdata,whichpredominantlycomprisestechnicaltext elements,thisprocessremainslargelymanualandreliantondomainexpertinput. Recentbreakthroughsincontextualtextrepresentationlearning(textembedding), particularlythroughpre-trainedlargelanguagemodels,offerpromisingapproaches thatcanfacilitatetheautomationofcross-mappingofthebuiltassetdata. However, nocomprehensiveevaluationhasyetbeenconductedtoassessthesemodels’ability to effectively represent the complex semantics specific to built asset technical terminology. Thisstudypresentsacomparativebenchmarkofstate-of-the-arttext embeddingmodelstoevaluatetheireffectivenessinaligningbuiltassetinforma- tionwithdomain-specifictechnicalconcepts. Ourproposeddatasetsarederived fromtworenownedbuiltassetdataclassificationdictionaries. Theresultsofour benchmarkingacrosssixproposeddatasets,coveringthreetasksofclustering,re- trieval,andreranking,highlighttheneedforfutureresearchondomainadaptation techniques. Thebenchmarkingresourcesarepublishedasanopen-sourcelibrary, whichwillbemaintainedandextendedtosupportfutureevaluationsinthisfield. 1 Introduction Assetmanagementplaysapivotalroleinensuringoptimalperformanceandextendedlifespanof thebuiltenvironmentthroughasystematicprocessofmonitoringandmaintainingvariousfacilities andequipment. Therapidadvancementofdigitaltechnologieshasledassetownerstoincreasingly demandenricheddigitaltwinsatprojecthandovertosupportreal-timeoperationsandmaintenance ofthebuiltassets[LoveandMatthews,2019]. Simultaneously,thegrowingawarenessofthebenefits ofdigitizedassetmanagementhighlightstheessentialneedforfederatedaccesstobuiltassetdata [Morettietal.,2023]. Thisrequiresaligningextensivedatasourcesandtheirunderlyingschema withestablisheddatamodels,classificationsystems,ortaxonomiestofacilitatedataaccessibilityfor diversestakeholdersandimproveinteroperabilityacrossvarioussoftwareenvironments. However, aligningbuiltassetdatawithpre-definedclassificationsystemsposessignificantchallengesinpractice. Akeychallengestemsfromthemulti-sourceandmulti-disciplinarynatureofbuiltassetdata,which leadstotheuseofdiverseformatsandterminologiesacrossdifferentprojectsandstakeholders. For example,theterminologythatarchitectsutilizetodescribethespecificationsforaparticularbuilding componentorsystemcanvastlydifferfromthoseusedbystructuralengineersorsubcontractors. Moreover,thestructuresofdomain-specificclassificationsusedindifferentdisciplinesoftenvary ∗Forcorrespondence,pleasecontact:mehrzad.shahinmoghadam.1@ens.etsmtl.ca Preprint.Underreview. 4202 voN 81 ]LC.sc[ 1v65021.1142:viXra",
    "body": "Benchmarking pre-trained text embedding models in\naligning built asset information\nMehrzadShahinmoghadam∗ AliMotamedi\nDepartmentofconstructionengineering Departmentofconstructionengineering\nÉcoledetechnologiesupérieure Écoledetechnologiesupérieure\nMontreal,H3C1K3,Canada Montreal,H3C1K3,Canada\nmehrzad.shahinmoghadam.1@ens.etsmtl.ca ali.motamedi@etsmtl.ca\nAbstract\nAccuratemappingofthebuiltassetinformationtoestablisheddataclassification\nsystems and taxonomies is crucial for effective asset management, whether for\ncomplianceatprojecthandoverorad-hocdataintegrationscenarios. Duetothe\ncomplexnatureofbuiltassetdata,whichpredominantlycomprisestechnicaltext\nelements,thisprocessremainslargelymanualandreliantondomainexpertinput.\nRecentbreakthroughsincontextualtextrepresentationlearning(textembedding),\nparticularlythroughpre-trainedlargelanguagemodels,offerpromisingapproaches\nthatcanfacilitatetheautomationofcross-mappingofthebuiltassetdata. However,\nnocomprehensiveevaluationhasyetbeenconductedtoassessthesemodels’ability\nto effectively represent the complex semantics specific to built asset technical\nterminology. Thisstudypresentsacomparativebenchmarkofstate-of-the-arttext\nembeddingmodelstoevaluatetheireffectivenessinaligningbuiltassetinforma-\ntionwithdomain-specifictechnicalconcepts. Ourproposeddatasetsarederived\nfromtworenownedbuiltassetdataclassificationdictionaries. Theresultsofour\nbenchmarkingacrosssixproposeddatasets,coveringthreetasksofclustering,re-\ntrieval,andreranking,highlighttheneedforfutureresearchondomainadaptation\ntechniques. Thebenchmarkingresourcesarepublishedasanopen-sourcelibrary,\nwhichwillbemaintainedandextendedtosupportfutureevaluationsinthisfield.\n1 Introduction\nAssetmanagementplaysapivotalroleinensuringoptimalperformanceandextendedlifespanof\nthebuiltenvironmentthroughasystematicprocessofmonitoringandmaintainingvariousfacilities\nandequipment. Therapidadvancementofdigitaltechnologieshasledassetownerstoincreasingly\ndemandenricheddigitaltwinsatprojecthandovertosupportreal-timeoperationsandmaintenance\nofthebuiltassets[LoveandMatthews,2019]. Simultaneously,thegrowingawarenessofthebenefits\nofdigitizedassetmanagementhighlightstheessentialneedforfederatedaccesstobuiltassetdata\n[Morettietal.,2023]. Thisrequiresaligningextensivedatasourcesandtheirunderlyingschema\nwithestablisheddatamodels,classificationsystems,ortaxonomiestofacilitatedataaccessibilityfor\ndiversestakeholdersandimproveinteroperabilityacrossvarioussoftwareenvironments. However,\naligningbuiltassetdatawithpre-definedclassificationsystemsposessignificantchallengesinpractice.\nAkeychallengestemsfromthemulti-sourceandmulti-disciplinarynatureofbuiltassetdata,which\nleadstotheuseofdiverseformatsandterminologiesacrossdifferentprojectsandstakeholders. For\nexample,theterminologythatarchitectsutilizetodescribethespecificationsforaparticularbuilding\ncomponentorsystemcanvastlydifferfromthoseusedbystructuralengineersorsubcontractors.\nMoreover,thestructuresofdomain-specificclassificationsusedindifferentdisciplinesoftenvary\n∗Forcorrespondence,pleasecontact:mehrzad.shahinmoghadam.1@ens.etsmtl.ca\nPreprint.Underreview.\n4202\nvoN\n81\n]LC.sc[\n1v65021.1142:viXra\ningranularity. Forinstance,thedetailedengineeringdescriptionsofanHVACsystemprovidedby\nmechanicalengineersmaybefarmorecomprehensivethanthoserequiredandusedbyoperationsand\nmaintenanceteams. Finally,variationsinlocalregulationsandstandardscanfurthercomplicatethe\nalignmentprocess,particularlyforlarge-scaleorinternationalprojects. Theseissues,combinedwith\nthedynamicandevolvingnatureofbuiltassetdatathroughoutanasset’slifecycle,leadtopotential\ninconsistencieswhenintegratingthisdataintoaunifieddigitalassetmanagementenvironment.\nInresponse,therehavebeenseveralinitiativesaimedatfacilitatingthedigitaldeliveryofbuiltasset\ninformationwhileensuringitsconformitywithpredefinedorstandardizeddescriptions(datamodels,\ntaxonomies,etc.). OnemajorinitiativeisbuildingSMARTDataDictionary(bSDD)[buildingSmart\nInternational,2024a],aninternationalandongoingeffortwhosemainobjectiveistocreateshareddef-\ninitionsfordescribingthebuiltenvironment. Thisisachievedthroughacollectionofinterconnected\ndatadictionariesthatarebothhuman-readableandmachine-readable[buildingSmartInternational,\n2024a]. Althoughmakingvariousdatadictionariesprogrammaticallyaccessiblewillfacilitateaccess\ntoagreedandconsistentterms,thecomplexityanddynamicdiversityofthebuiltassetterminology\nnecessitaterobustdatamappingstrategiestoaccommodatevariousdatadescriptionsandupdates\n[Forth et al., 2024]. As a result, the asset information alignment process remains predominantly\nmanual,relyingheavilyontheexpertiseofdomainspecialiststoaccuratelymapcomplextechnical\ndata[Robertsetal.,2018]. Thesignificantchallengesassociatedwiththemanualalignmentprocess,\nincludinghighcosts,timeconsumption,andpotentialforhumanerror,highlighttheneedformore\nautomatedandreliabledatamappingsolutions.\nThe central thesis of our research builds upon the argument that recent advancements in natural\nlanguage processing/understanding research can significantly enhance automated data mapping\nprocesses. In particular, the rich and contextualized representation of textual inputs as numeric\nvectors,commonlyknownastextembedding[Penningtonetal.,2014,Leeetal.,2024b],provides\nadvancedcapabilitiesformachinestounderstandthesemanticsoftheintricateterminologies. Earlier\nmethods such as word2vec [Mikolov et al., 2013] and GloVe [Pennington et al., 2014] relied on\nstaticembeddings,i.e.,generatingfixedrepresentationsofnumericalvectorsforeachwordbasedon\ntheirco-occurrenceinlargecorpora. However,recentneurallanguagemodels,dominantlybuilton\ntopofthetransformerarchitecture[Vaswanietal.,2017],cangeneratedynamic,context-sensitive\nembeddings. Thecapabilityofrecentembeddingmodelsinadaptingtherepresentationofwords\n(orsub-wordtokens)basedontheirsurroundingcontexthasmotivatedresearchersandpractitioners\nacross diverse fields to leverage the power of contextual text embeddings to drive advancements\nin their respective domains. From traditional databases integration [Cappuzzo et al., 2020], to\ninformationmanagementinbiomedicine[Zhangetal.,2019],orpublicfigureperceptionsinsocial\nsciencestudies[CaoandKosinski,2024],theincreasingvolumeofencouragingreportsonleveraging\ntextembeddingmodelstodeliveramorenuancedtextunderstandinginvariousspecializeddomains\n[Rasmyetal.,2021,Ostendorffetal.,2021,Rouhizadehetal.,2024,Wilkhoetal.,2024,Caoand\nKosinski,2024]reinforcestherelevanceofthesemodelsinautomatingdataalignmentinthedomain\nofbuiltassetinformationmanagement.\nBasedontheobservationthatbuiltassetdatapredominantlyexistsintextualform[Wuetal.,2022],\nwearguethatstate-of-the-arttextembeddingmodelspresentpromisingopportunitiestorefinethe\nautomatedalignmentofbuiltassetinformation. However,theextensiveandincreasingavailabilityof\npre-trainedlanguagemodelshasledtotheproliferationofpotentialtextembeddingmodels,creating\nconfusionregardingmodelselectionfordifferentusecases[Muennighoffetal.,2022]. Moreover,\nrecent research indicates that general-purpose text embedding models often struggle to maintain\nconsistentperformanceacrossdiversetasksanddomains[Leeetal.,2024b]. Thisiswhilemost\npreviousstudiesutilizingpre-trainedorfine-tunedlanguagemodelsinbuiltenvironmentresearch\nhavebeensignificantlylimitedinscope,primarilyfocusingonad-hocdownstreamtaskswithsmall\nevaluationdatasets[Shahinmoghadametal.,2024,Jungetal.,2024,Wangetal.,2024,Forthetal.,\n2024,Jeonetal.,2024]. Suchlimitationscanresultinapotentiallyskewedperspectiveontheoverall\ndomain-specifictextunderstandingofthesemodels[Shahinmoghadametal.,2024]. Additionally,\nscarcepublicaccesstothedatasetsusedinpreviousworksposesanotherimportantchallengetothe\ntransparencyandreproducibilityofthereportedresults. Thismotivatesustoexaminetheextentto\nwhichexistinglanguagemodelscanbedirectlyleveragedtodelivercontextuallyaccuratemappings\nofdomain-specificterminologywithinthecontextofbuiltassetinformationmanagement. Inthis\nwork,wepresentacomprehensivebenchmarkofstate-of-the-arttextembeddingmodelstoevaluate\ntheir effectiveness in capturing and representing the semantics of textual descriptions related to\n2\nbuiltassets. Throughthisevaluation, weaimtoidentifythestrengthsandlimitationsofexisting\nlanguagemodelsinenhancingdataalignmentpracticeswithinthebuiltassetdomain. Ourproposed\nbenchmarkisalignedwiththeMassiveTextEmbeddingBenchmark(MTEB)[Muennighoffetal.,\n2022],abenchmarkrecognizedextensivelyinbothacademicandpracticalcontextsforitsrobustness\nand utility. We benchmark 24 text embedding models on our developed datasets that amount to\na total of more than ten thousand data entries across six tasks, making our evaluations the most\ncomprehensiveonesinthisspecializedfieldtodate. Bymakingourdatasetsandbenchmarksoftware\npubliclyavailable,weencouragefutureresearchtobuilduponourwork,contributingtocontinuous\nimprovementsinthisdomain.\n2 Methods\n2.1 Datasources\nGiven the built environment’s multidisciplinary nature, the datasets included in the benchmark\nmustencompassanexpansivespectrumofsub-domainsubjects,includingarchitectural,structural,\nmechanical,andelectricalsystems. Toensureadiversecoverageofbuiltproductsinourbenchmark,\nwecarefullyexaminedtheselectionofdatasourcesusedforcreatingtask-specificdatasets.Adetailed\ndescriptionofthecorpusdevelopmentanddataextractionprocessesisprovidedbelow.\nTheinitialstepincreatingthebenchmark’stask-specificdatasetsisthedevelopmentofaconsistent\ncorpusofbuiltproducts. Basedontherequirementsofthetaskswithinourbenchmark, thecore\ncorpusneededtoincludethefollowingkeyinformationforeachproduct: nameortitle,description,\nand corresponding labels (group categories). The two primary sources used to develop the built\nproductcorporaareasfollows:\nIndustryFoundationClasses(IFC).PublishedandmaintainedbybuildingSMARTInternational[bsi,\n2024],IFCisanopeninternationaldatamodelofferingcomprehensivedigitaldescriptionsofvarious\naspects of building and infrastructure projects. Originally designed to facilitate interoperability\nandinformationexchangeamongdifferentsoftwareapplicationsandstakeholders,IFCprovidesa\ncomprehensiverepresentationofvariousaspectsofbuiltassetentities. WeutilizeIFCversion4.3.2.0\n[buildingSmartInternational,2024b],recentlyapprovedasanISOstandard(ISO16739-1:2024).\nUniclass. DevelopedandmaintainedbytheNationalBuildingSpecification(NBS)[NBS,2024a],\nUniclassisaunifiedclassificationsystemforthebuiltenvironment. Weutilizeversion1.33ofthe\nUniclassPrProductTable[NBS,2024b]. Uniclasshasextensivecoverage,encompassingover8,000\nproducttypes,makingitoneofthemostrecognizedandwidelyadoptedclassificationsystemsinthe\nbuiltassetindustry.\n2.2 Dataextraction\nTocreateacorpusofproductswithcorrespondingnames,descriptions,andlabels,weundertookthe\nfollowingsteps: ForUniclass,weutilizethepublicly-availableCSVformatoftheproductstable,\nwhichcomprisesover8,000productscategorizedintothreehierarchicallevels. Productnameswere\ndirectlyextractedfromthetable, whileproductcategorieswereinferredfromthenumericcodes\nassociatedwithhierarchicalcategories(seeFigure1). Toautomaticallyextractthecorresponding\ntextuallabelsforeachproduct,wedevelopedascripttoscrapethetableprogrammatically. Asthe\noriginaltabledoesnotincludeproductdescriptions,weproposeamethod(detailedinthesubsequent\nsubsection)tosynthesizeadescriptionforeachproduct. Weretainedonlythoseproductsthathave\nlabelsforallthreeclassificationlevels. Afterapplyingthisfilteringprocess, theUniclasscorpus\ncomprises4,234instances,whichremainssufficientlylargeforourbenchmarkingpurposes.\nRegarding the IFC schema, we parse the official schema content by utilizing resources from an\nopen-sourcePythonlibrary[ifc,2024]thatenablesprogrammaticaccesstoIFCentities. Initially,\nwe extracted entities of interest from a JSON-formatted file containing the complete list of IFC\nentities, their type enumeration, and their definition (derived from IFC’s official documentation).\nAnanalysisofthe\"IfcProduct\"classwithintheIFCschemaindicatedthatasignificantmajorityof\nproductentitiesareclassifiedunderthe\"IfcElement\"class. Therefore,wefocusedexclusivelyonthe\n\"IfcElement\"subclasses. AfterremovingIFCentitieswithmissingdescriptions(lessthan1%oftotal\n\"IfcElement\"entities),wedevelopedascripttoextracteachentity’stopthreeparentclassestoserve\nastheproductcategorylabels. Inadditiontoentitysuperclassgroups,weusethedomain-specific\n3\nFigure1:Overviewofthemainstepsindevelopingthebuiltproductcorpus:(a)Exampleofextracting\ncategoriesandsynthesizingentitydescriptionsfromrawUniclassentries;(b)Exampleofhierarchical\nrelationextractionformainentitiesandtheirenumeratedtypesfromtheIFCschema;(c)Sample\nrecordsfromthedevelopedcorpus,containingproducttitles,descriptions,andcategorieswiththree\nlevelsofgranularity.\nschemas(e.g.,structural,HVAC,buildingcontrol)fromIFC’sofficialdocumentations[buildingSmart\nInternational,2024b]asanadditionalsourceforentitylabelassignment. TheresultingIFCcorpus\ncomprises977entities(totalofparententitiesandtypeenumerations).\n2.3 Dataaugmentationandcuration\nTheprocessofgeneratingtextualdescriptionsforUniclassentitiesisdepictedinFigure1(a). Initial\nentity descriptions are synthesized by sequentially concatenating the entity’s category titles, pro-\ngressingfromthemostspecifictothemostgeneral. Anexampleofthesynthesizeddescriptionsis\nprovidedinFigure1(a). Theseconcatenateddescriptionsarethenparaphrasedusingagenerative\nlanguagemodeltocreatemorenuancedandnaturaldescriptions,relaxingthetextfromtherigid\ntemplateinitiallyemployed. Wegeneratedparaphraseddescriptionsusingthemostadvancedversion\noftheGPT-4modelavailableatthetimeofconductingtheexperiments(gpt-4-turbo-2024-04-09).\nAlthoughthepromptsusedforgeneratingparaphraseddescriptionsweredesignedtopreventthe\nalterationoradditionoffacts,itwasessentialtomanuallyreviewallgenerateddescriptionsdueto\nknownpotentialinaccuraciesofgenerativelanguagemodels. Thereviewiscarriedoutbytwodomain\nexperts,eachwithovertenyearsofexperienceinthefield. Eachexpertcross-checkedtheissues\nidentifiedbytheother,andthefinaldecisionsweremadebasedonmutualagreement. Thefollowing\ncurationstepsareundertakentoensuretheaccuracyandconsistencyoftheextractedproductnames\nand descriptions. We preprocess native IFC entity names and convert them into a readable form\n(e.g.,\"IfcHeatExchanger\"toHeatExchanger;seeexamplesinFigure1(b)and(c)). ForIFCclass\nenumerationtypes,wheretheenumerationnamealonemightbeambiguous,weappendtheparent\nclasstypeinparentheses. Forexample,theenumerationWATER,asubclassof\"IfcBoilerTypeEnum\",\nisrepresentedas\"WATER(BoilerType)\"(seeexamplesinFigure1(c)). Followingthesamelogic,\n4\nwe enrich the product descriptions by concatenating the product’s name at the beginning of the\ndescriptionforbothUnicalssandIFCentities. Thisstepreinforcescontextualclarity,asthenatural\nentitynamescarrysignificantsemanticinformation. Finally,wemanuallyreviewandmodifythe\nentitydescriptionsthatcontaininconsistentinformation,suchasnotesrelatedtotheschemaversion\nhistoryorfuturedepreciationnotes.\n2.4 Sampling\nToensurearobustentityselectionwhencreatingtask-specificdatasets,weimplementedthefollowing\nsamplingstrategies: Forpositivesampling,weadoptasemanticdiversityapproach. Givenatargetted\nsubsetofbuiltproducts,wegeneratetextembeddingsforallcorrespondingtextinputs,i.e.,product\nnamesanddescriptions. Embeddingsaregeneratedusingastate-of-the-arttextembeddingmodel\n(\"mxbai-embed-large-v1\"[LiandLi,2023]). Fromthissetofembeddings,werandomlychoosean\ninitialsampleasastartingpoint. Subsequently,weiterativelyselectadditionalsamplesbyidentifying\nthosethatexhibittheslightestsimilaritytothemostrecentlyselectedsample,asdeterminedbycosine\nsimilarityscores,i.e.,thecosineoftheanglebetweentwoembeddingvectors. Thisprocessrepeats\nuntil the desired number of samples is achieved. This method ensures that the samples selected\nforaparticularsubset(e.g.,productsofthesamecategory)yielddiverserepresentationswithinthe\nembeddingspacebyselectinginputsthataresemanticallydissimilartotheonesalreadychosen. For\nnegativesampling,weprioritizetheselectionofproductsamplesthatyieldclosersemanticsimilarity\ntoagivenquery(aproductnameordescription)butbelongtoadifferentclass. Wecomputethe\ncosinesimilaritiesbetweenthequeryandnegativesamplesusingthesameembeddingmodelused\ninthesemanticdiversitysamplingandselectsampleswithhighersimilarities. Byselectingmore\nsimilarcandidatesasnegativesamples,thedatasetcanbetterbenchmarkthemodel’scapabilityto\ncapturethesubtledifferencesbetweencloselyrelatedclasses. Thismethod,commonlyknownashard\nnegativesampling,isparticularlyeffectiveforevaluationsinvolvingfine-grainedclassifications,such\nasdifferentiatingbetweencloselyrelatedcategoriesinIFCandUniclassclassificationhierarchies. In\nallsamplingmethods,includingplainrandomsampling,onceasampleisselected,itisonlyreused\nin another subset once all samples included within the pool have been exhausted. This way, we\nmaximizetheutilizationofavailablesamplesandmaintaindiversitywithinthedatasets.\n3 Benchmark\n3.1 Tasksoverview\nEvaluatingtextembeddingsacrossdifferenttasksiscrucialforassessingthetransferabilityoftheir\ncapabilitiestovariousdownstreamapplications. Hence,ourproposedbenchmarkcoversthreemain\ntasks: clustering,retrieval,andreranking. Inadditiontodomaincoverageandcross-taskadaptability,\nevaluatingtextembeddingmodelsrequirescarefulconsiderationofinputtextlength. Toensurethe\ncoverageforvaryinginputlengths,thetextentitiesincludedinourdatasetsfallintotwocategories:\n(a)sentences,whicharederivedfromproducttitles/names,and(b)paragraphs,whicharederived\nfromproductdescriptions/definitions. Accordingly,eachtask-specificdatasetinourbenchmarkis\ngroupedintooneofthefollowingcategories:\n• SentencetoSentence(S2S):Utilizingproducttitlesasinputtext.\n• ParagraphtoParagraph(P2P):Utilizingproductdescriptions(whichcanbeconcatenated\nwiththeproductname)asinputtext.\n• SentencetoParagraph(S2P):Comparingproducttitlesagainstproductdescriptions.\nOurproposedbenchmarkfollowsMTEB[Muennighoffetal.,2022]forreportingtextembedding\nperformancescores. Hence,variousmetricsareimplementedwithinourbenchmark,whichcanbe\ncomputedwithflexibleparameterconfigurations. Theprimarymetrics,whichserveasdefaultscores\nfortask-specificaswellasoverallcomparisonsreportedinthisstudy, areoutlinedineachtask’s\ndescription.\n3.1.1 Clustering\nClustering tasks involve grouping similar built products into meaningful clusters based on their\nsimilaritiesintextualrepresentation. OurproposedtasksincludeS2SandP2Pcategories,where\n5\nproductnamesanddescriptionsactasinputtextforeachdatasettype,respectively. Eachclustering\ntaskdatasetiscomprisedofvarioussubsets,coveringdiversesubdomainsubjectsanddifferentlevels\nofgranularity. Tocreatethesubsetswithineachclusteringdataset,wefirstselectasubsetofproduct\nlabelsfromoneofthethreelevelsofproducthierarchy,eitherfromonespecificcorpusoracrossboth\ncorpora. Wethenapplythepreviouslydescribeddiversity-basedsamplingmethodtosampleproduct\nnames(S2Sdatasets)ordescriptions(P2Pdatasets)forselectedlabels.\nToensurethequalityofthesubsets,weevaluatethebaselinescoresusingtwoembeddingmodels,one\nfortheupperthreshold(\"mxbai-embed-large-v1\"[LiandLi,2023])andoneforthelowerthreshold\n(\"paraphrase-multilingual-MiniLM-L12-v2\"[ReimersandGurevych,2019]). Asubsetisincludedin\nthedatasetonlyifitsscorewiththeupperthresholdmodelisbelow0.8andgreaterthan1/Nwith\nthebaselinemodel,whereNisthenumberofuniquelabels. Theupperandlowerthresholdsareset\ntomaintaintaskdifficultyandensurethetaskperformsbetterthanrandomguessing,respectively.\nSubsetsmeetingthesecriteriaareshuffledtoeliminateorderbiasbeforebeingaddedtothedataset.\nWecomputeV-measurescores[RosenbergandHirschberg,2007]bytrainingamini-batchk-means\nmodelusingvectorembeddings,withksettothenumberofuniquelabelsineachclusteringsubset.\nTheV-measure,rangingfrom0to1(higherisbetter),representstheharmonicmeanoftwodistinct\nmetrics: homogeneityandcompleteness. Here,homogeneitymeasurestheextenttowhichclusters\ncontainonlyproductsfromasinglecategory,whilecompletenessindicateshowwellallproducts\nfromagivencategoryaregroupedintothesamecluster. Moredetailsregardingthecalculationof\nV-measurecanbefoundin[RosenbergandHirschberg,2007].\n3.1.2 Retrieval\nRetrievaltasksaimtoidentifyrelevantdocuments,i.e.,producttextualdescriptions,inresponseto\nagivenquery. OurproposedretrievaldatasetsareframedasS2PandP2Ptasks,wherebuiltasset\ndescriptionsserveasthecorpus(thedocumentstoberetrieved),andproducttitlesanddescriptions\nactasqueriesfortheS2PandP2Ptasks,respectively. Thequery-documentrelevancygroundtruth\nisderivedfromexistingmappingsthatidentifythealignmentbetweenIFCandUnicalssproduct\nentities. Thesemappings,validatedandpublishedbyNBS[NBS,2024a],canbefoundintheofficial\nUnicalsstablerelease[NBS,2024b].\nFirst,weencodeallqueriesandproductdescriptionsintocorrespondingembeddingvectors. These\nembeddingsarethenusedtocalculatethepairwisesimilaritybetweenagivenqueryandallproduct\ndescriptionsusingcosinesimilarity. Subsequently,productdescriptionsincludedineachretrieval\ndatasetarerankedaccordingtodescendingcosinesimilarityscores. Finally,wecomputenDCG@10\n(NormalizedDiscountedCumulativeGain[JärvelinandKekäläinen,2002]atrank10)astheprimary\nmetric. Thisscore,whichcanrangebetween0and1(higherisbetter),reflectstherelevancyofthe\nrankedproductsbasedontheirpositionswithinthetop10ranksbyapplyingalogarithmicdiscount\nfactortopenalizeresultsthatappearlower.\n3.1.3 Reranking\nInourrerankingtasks,theaimistorankasetofproductdescriptionswithreferencetotheirrelevance\ntoaproductquery. Similartoretrievaltasks,rerankingtasksareframedasS2PandP2Ptypes,and\npairwisesimilaritybetweenqueryandproductdescriptionembeddingsiscomputedbasedoncosine\nsimilarity. Theprimarydistinctionbetweenretrievalandrerankingtasksliesintheirscopeandfocus.\nWhile our retrieval tasks involve ranking the entire product corpus, reranking narrows the focus\ntoasmallersetofpositiveandnegativesubsets,whichareselectedusingthemethodsoutlinedin\ntheprevioussectiontoensurediversityanddifficulty(avoidingveryhighscoresfromoverfitting)\nwithinthedataset. Positiveandnegativesamplesareselectedusingthemethodsdescribedinthe\nprevioussection,therebymaintainingthediversityanddifficultyofthedataset. Byconcentratingon\nasmallerandmorechallenginggroupofproductdescriptions,ourrerankingtasksaimtoprovidea\nmorefine-grainedevaluationofthemodel’sabilitytorankrelevantitemsaccurately.\nSimilartoretrievaltasks,weusecosinesimilaritytocomputepairwisesimilaritybetweenagiven\nqueryandproductdescriptionsincludedincorrespondingpositiveandnegativesets. Subsequentto\nrankingthedescriptionsbasedonthecosinesimilarityscores,wecomputeMAP(MeanAverage\nPrecision)asourprimarymetric. MAPprovidesanaveragedmeasureofprecisionacrossallrelevant\nproducts,rangingbetween0and1,withhighervaluesindicatingbetterperformance. Itisworth\n6\nClusteringtasks No.of Unique/total Avg.sample TotalNo.of Avg.uniquelabel\nsubsets samples length uniquelabels persubset\nClustering-s2s 18 2545/3815 28.04 31 5\nClustering-p2p 20 3067/4577 207.91 35 5\nRetrievaltasks No.of Avg.query No.of Avg.document No.ofdocument\nqueries length documents length perquery(Avg.)\nRetrieval-s2p 977 30.35 2761 312.75 8\nRetrieval-p2p 977 128.5 2761 312.75 8\nRerankingtasks No.of Avg.query No.ofpositives No.ofnegatives Avg.samples\nqueries length (unique/total) (unique/total) length\nReranking-s2p 179 27.89 1253/1253 2281/3759 310.15\nReranking-p2p 179 140.44 1253/1253 2241/3759 309.66\nTable1: Summaryofdatasetstatisticsperbenchmarktask.\nnotingthatretrievalmetricsreflectoverallrankingqualitywhilererankingmetricsfocusonhowearly\nrelevantproductsappearinthelist.\n4 Results\nTable 1 provides a comprehensive summary of the dataset statistics across the three main tasks\nin our benchmark. The unique number of sample entries in our clustering datasets shows that\nmorethanhalfofthesamplesavailablefromthecombinedproductcorporacouldpassthequality\nthresholdsexplainedinthemethodssection. Intheretrievalandrerankingtask,thesameretrieval\nandrerankingdocumentcorpusissharedbetweenthesubtasksofeachtaskcategory. Thisdesign\nenablesacomparativeanalysisofmodelperformanceondifferentquerytypes,withS2Pfocusing\nonshorterproductnamesandP2Ptargetinglongerproductdescriptions. Weapplieda1:3positive-\nto-negativesamplingratiotocreateabalancedyetchallengingevaluationset,ensuringthatmodels\nmustdistinguisheffectivelybetweenrelevantandirrelevantdocuments.\nTooutlinethedistinctionsbetweenournewlyconstructeddatasetsandexistingones,weconducted\nathematicsemanticsimilaritycomparisonbetweenourclusteringdatasetsandthosefromMTEB\nbenchmark. Usingthe\"stella-en-400M-v5\"model,whichisthemostperformantsmall-sizedmodel\ninourevaluations(seeTable2),wegeneratedembeddingsfor200randomlyselectedsamplesand\naveragedthemwithineachdataset. Figure2depictsthecosinesimilaritymatrixasaheatmap,where\ndarkershadesindicatehighercontentsimilarity. Thehighsimilarityscoresbetweenourproposed\nsubtasksconfirmstronginternalconsistencywithinourbenchmark. Moreover,moderatetohigh\nsimilaritieswithStackExchange,Reddit,andArxivdatasetsreflectthematicoverlapswithbroader\ndomaincontent. Adiscussionoftheobservedsimilaritiesisprovidedinthenextsection.\nInourbenchmarkingexperiments,weevaluatedmodelsacrossabroadrangeofsizes,fromrelatively\nsmall models with 33 million parameters to significantly larger models exceeding seven billion\nparameters. However,duetocomputationalconstraints,themajorityofmodelstestedhavelessthan\nonebillionparameters. Theselectedmodelsspanvariouspositionsonthemostrecentrecordof\nMTEBleaderboard(asofSeptember21,2024),rangingfromfirstplace(i.e.,\"NV-Embed-v2\"[Lee\net al., 2024a]) to 136th place (i.e., \"paraphrase-multilingual-MiniLM-L12-v2\"). For models that\narepre-trainedwithinstruction-baseddata,weusedbuilt-inorrecommendedpromptsasprovided\ninthemodelcard’sofficialwebpageorassociatedresearchpapers,whenavailable. Forexample,\n\"mxbai-embed-large-v1\"requirescustompromptsonlyforretrievalandrerankingtasks,while\"NV-\nEmbed-v2\"needsspecifictask-basedpromptsforclusteringtasksaswell.Formodelswithoutbuilt-in\ntaskinstructions,weappliedageneralsetofpromptstoensureconsistencyacrosstasks(promptsare\navailableattheproject’spublicGitHubrepository[Mehrzad,2024]).\nThetop-rankedmodelinourbenchmark,\"NV-Embed-v2\",alsoholdsfirstplaceonthelatestMTEB\nleaderboard. However,itdoesnotconsistentlyoutperformallothermodelsacrossalltasks. Infact,\nacloserexaminationrevealsvariabilityinmodelsizeandperformancerelationship. Forexample,\n\"gte-small\",thesmallestmodelinourevaluationwith33millionparameters,deliverscompetitive\nscores,nearlymatchingtheaveragescoresofmodelstentimesitssizeandevenoutperforminglarger\nmodelsinspecifictasks. Despitethepreviouslyreportedstrongcorrelationbetweenmodelsizeand\n7\nCosine Similarity Heatmap of Clustering Dataset Embeddings\n1.00\nclustering-s2s\nclustering-p2p 0.92 0.95\narxiv-clustering-p2p 0.77 0.71\n0.90\narxiv-clustering-s2s 0.81 0.71 0.92\nbiorxiv-clustering-p2p 0.69 0.66 0.84 0.77\n0.85\nbiorxiv-clustering-s2s 0.77 0.70 0.81 0.87 0.94\n0.80\nmedrxiv-clustering-p2p 0.66 0.64 0.74 0.68 0.86 0.81\nmedrxiv-clustering-s2s 0.74 0.70 0.75 0.79 0.85 0.90 0.95\n0.75\nreddit-clustering 0.87 0.78 0.76 0.83 0.71 0.80 0.68 0.78\n0.70\nreddit-clustering-p2p 0.80 0.74 0.74 0.77 0.69 0.75 0.66 0.72 0.92\nstackexchange-clustering 0.91 0.81 0.81 0.87 0.74 0.83 0.70 0.80 0.94 0.88\n0.65\nstackexchange-clustering-p2p 0.75 0.69 0.77 0.73 0.68 0.67 0.58 0.60 0.74 0.76 0.81\ntwentynewsgroups-clustering 0.89 0.79 0.77 0.85 0.72 0.81 0.68 0.78 0.96 0.90 0.96 0.77 0.60\nclustering- cls2 us steri an rg xi- vp -2 clp usteri an rg xi- vp -2 clp ust bier oi rn xig- v-s c2 ls uste biri on rg xi- vp -2 clp us mt eer di rn xig- v-s c2 ls ust me eri dn rg xi- vp -2 clp ustering r- es d2 ds it-c rl eus dt die tri -cn l sg tu ast ce kr ei xn scg t- h ap a c2 n kp g ee x- ccl haus nt tge weri - ecn l ng tu yst ne eri wn sg g- rp o2 up ps-clustering\nFigure2: ThematicsimilarityheatmapbetweenourproposedclusteringtasksandthosefromMTEB.\nAverageembeddingsarederivedfrom200randomsamplesperdataset,encodedusingthe\"mxbai-\nembed-large-v1\"model[LiandLi,2023]. Datasetsfromourproposedbenchmarkarehighlightedin\nred.\nperformance[Muennighoffetal.,2022],ourexperimentsshowthatsuperiorperformanceassociated\nwithlargermodelsisonlyevidentattheextremeupperendoftheparameterscale. Thisobservation\nsupportsthegrowingemphasisondevelopinganddeployingsmaller,moreefficientmodelsforboth\nresearchandreal-worldapplicationsinthisspecializedfield.\nMotivatedbythehypothesisthatexistingdatasetswithsimilarthematiccontentwouldyieldcom-\nparableperformanceevaluations,weexaminedtheconsistencyofrelativemodelperformancesas\nfollows: GiventheobservedthematicsimilaritybetweenourclusteringdatasetsandspecificMTEB\ndatasets,particularly\"StackExchange\"and\"Reddit\"(seeFigure2),wecomparedtherankingsof\nmodelperformanceacrossbothourdatasetsandtheselectedMTEBdatasets. Asitcanbeseenfrom\nTable3,thecomparativeevaluationoftherelativerankingsindicatesanotablevariationinmodelper-\nformances,notablyinthecaseof\"multilingual-e5-large-instruct\",\"gte-small\",\"stella_en_1.5B_v5\",\nand\"text-embedding-3-small\".Theseobservedvariabilitiesfurtherhighlightthelimitationsofrelying\nongeneral-purposebenchmarkdatasets,evenwhenrelativelyhighthematicsimilaritiesarepresent,\nunderscoringtheimportanceofdomain-specificevaluations.\nWhileourbenchmarkingexperimentsprimarilyfocusedonopen-sourcemodels,wealsoincludedthe\nproprietarytextembeddingmodelsfromOpenAI,boththesmallandlargeversions. Theinclusionof\ntheproprietarymodelsismotivatedbyarecentstudywhereclosed-sourcemodelstendtoachieve\nrelativelyhigherperformancewhenembeddingtextinunderrepresentedlanguages[Enevoldsenetal.,\n2024]. Wehypothesizethatbuiltassettext,asanunderexploreddomain,mightbesimilarlybetter\nrepresentedbyproprietarymodels. Notably,text-embedding-3-largerankssecondinourbenchmark,\nperforming nearly on par with the top-ranked model. In contrast, the smaller model performed\nmore moderately, ranking in the middle of our benchmark. While the former observation aligns\nwiththefindingsof[Enevoldsenetal.,2024],thelatterisinlinewiththelatestMTEBleaderboard\nresultswhereclosed-sourcecommercialembeddingAPIsgenerallyunderperformcomparedtotheir\n8\nTasks(→) Clustering Retrieval Reranking Avg. Param. MTEB\nModels(↓) s2s p2p s2p p2p s2p p2p - (mil) Rank\nPre-trainedwithouttaskinstructions\ngte-base-en-v1.5 48.38 51.83 79.98 59.42 66.54 66.73 62.15 137 39\ngte-large-en-v1.5 43.42 51.05 83.32 63.27 72.76 70.15 64.00 434 24\nbge-base-en-v1.5 43.00 51.78 82.56 61.65 67.01 63.38 61.56 109 43\nbge-large-en-v1.5 46.69 52.41 82.60 64.86 68.44 65.47 63.41 335 35\nUAE-Large-V1 45.45 49.53 83.32 66.42 70.04 68.53 63.88 335 29\nGIST-Embedding-v0 46.43 49.96 82.82 62.78 68.81 65.75 62.76 109 41\nGIST-large-Embedding-v0 47.97 47.91 84.01 67.06 69.53 68.03 64.08 335 34\ne5-base-v2 42.59 50.24 80.83 61.46 69.11 62.91 61.19 109 64\ne5-large-v2 42.11 49.45 81.95 64.63 68.61 64.58 61.89 335 55\nmultilingual-e5-large-instruct 48.01 52.82 80.35 64.55 67.85 65.90 63.25 560 42\nmultilingual-e5-small 42.98 48.16 76.38 55.03 64.78 62.34 58.28 118 112\nall-MiniLM-L12-v2 42.00 46.52 79.97 58.81 66.20 63.97 59.58 33 117\nparaphrase-multilingual-MiniLM-L12-v2 37.60 45.70 69.01 49.90 61.23 59.15 53.77 118 136\ngte-base 45.96 51.55 82.91 62.95 68.97 66.26 63.10 109 51\ngte-large 48.54 55.24 84.32 66.08 70.94 69.25 65.73 335 47\ngte-small 44.31 55.55 82.37 60.55 68.82 65.23 62.80 33 70\nPre-trainedwithtaskinstructions\ngte-Qwen2-7B-instruct 50.19 62.39 86.28 73.20 69.47 67.51 68.17 7069 6\nmxbai-embed-large-v1 47.49 52.45 83.51 66.60 70.10 69.66 64.97 335 28\nmultilingual-e5-large-instruct 48.10 59.43 82.91 64.42 70.53 69.23 65.77 560 42\nNV-Embed-v2 58.61 67.34 85.23 77.02 66.67 70.34 70.87 7851 1\nstella-en-1.5B-v5 53.60 54.57 84.18 71.21 71.57 71.77 67.82 1545 3\nstella-en-400M-v5 53.39 55.78 84.60 70.00 69.58 69.36 67.12 435 7\nProprietaryembeddingAPIs\ntext-embedding-3-small 49.72 49.72 79.97 65.68 65.33 66.99 62.90 - 58\ntext-embedding-3-large 49.75 55.48 84.99 75.38 71.93 72.46 68.33 - 30\nTable2:Averagescoresofbenchmarkedmodelspertask,basedonthetask-specificmetricsmentioned\ninthetaskdescriptions. Thefirstandsecondhighestscoresforeachtaskarehighlightedinboldand\nunderlined,respectively. MTEBranksaresourcedfromrecordsasofSeptember21,2024.\nopen-sourcecounterparts. Theseobservationsraisequestionsabouttheunderlyingfactors. However,\nthelackofknowledgeaboutthekeycharacteristicsofproprietarymodels, suchastheirsizeand\ndiversityintrainingdata,preventsusfromofferingadetailed,conclusiveaccountoftheirrelative\nperformance.\nOurbenchmarkingresultsrevealanotabledifferenceinperformancebetweenshorterandlongertext\ninputsindifferenttasks. Inparticular,acrosstheboard,modelsconsistentlyshowlowerperformance\nintheS2SclusteringtaskcomparedtotheP2Pone. Thisobservationcanbeattributedtothelimited\npresenceofcontextualcluesgiventhesignificantlyshortlengthoftheinputtextintheS2Sclustering\ntask(seeTable1). Ontheotherhand,inrerankingandretrievaltasks,themajorityofthemodelsyield\nmoderatelyhigherscoresinS2Ptasks. Thelikelyexplanationforthelatterobservationisthatthe\nshorterlengthofthesentences(productnames)inS2Ptaskscanleadtoaloweramountofirrelevant\ninformation(noise)intheinputquery. Sinceproductnamestendonlytoencapsulatethecritical\ninformationaboutthetargetproduct, theycanyieldmorepreciseanddiscriminativetext(query)\nrepresentationsforsimilaritymatching.\n5 Discussion\nOurbenchmarkingresultsoffercriticalinsightsintotheeffectivenessofstate-of-the-artpre-trained\ntextembeddingmodelsinaligningbuiltassetinformation. Oneofthekeyfindingsofourstudyis\nthevariabilityinperformanceacrosstasks,evenamongtop-performingmodels. Ourresultssuggest\nthatmodeleffectivenessisnotstronglycorrelatedacrossmodelsizes,emphasizingthatsizealoneis\nnotareliablepredictorofmodelperformanceinthespecializeddomainofbuiltassetinformation\nmanagement. Theinterpretationoftherelationshipbetweenmodelsizeandembeddingeffectiveness\nisfurthercomplicatedbytheperformancegapobservedwhencomparingmodelspre-trainedwith\nandwithoutinstructiontuning. Instruction-tunedmodelsshowedhigherperformanceinthemajority\nofourbenchmarktasks. Consideringthelargersizeoftheinstruction-tunedmodelsincludedinour\nexperiments,thelatterobservationraisesanimportantquestionforfutureresearch: Towhatextent\n9\nclustering-p2p(ours) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\nstackexchange-clustering 1 3 10 4 19 7 9 2 16 14 8 20 11 6 18 15 5 12 17 21 13 22 23\nreddit-clustering 4 1 16 3 18 10 6 2 9 15 14 21 12 11 17 13 5 8 19 23 7 20 22\nTable3: Comparisonofmodelrankingsacrossdatasetswithhighthematicsimilarity(seeFigure2)\ncaninstruction-tuninghelpsmallermodelsadapttothespecializeddomainofthebuiltenvironment?\nThisopensapromisinglineofinvestigationintohowtask-specifictrainingwithinstruction-baseddata\ncanbetteralignamodel’sunderstandingwiththeintricatesemanticsofbuiltassetdata,particularly\nformodelswithsmallersizes. Finally,inadditiontothevariabilityinmodelperformanceacross\ndifferenttasksandtextinputlengths,theresultsofourcomparativeexaminationshighlightthelimited\ntransferabilityofevaluationsbasedongeneralbenchmarks. Ourexperimentsindicatethat,evenwith\nrelativelyhighthematicsimilarity,general-purposebenchmarksremaininadequateincapturingthe\nuniquesemanticcomplexityandcontextualdependenciespresentinthetextualdescriptionsofthe\nbuiltasset.\nTheabove-mentionedpointshighlightthecriticalneedfortailoredbenchmarkingdatasetstoexamine\ntheeffectivenessofvariousdomainadaptationstrategiesinthisfieldofresearch.Ourworkcontributes\ntothebodyofresearchbylayingarobustfoundationforfutureevaluationsandprovidingabenchmark\nthatiscarefullyconstructedtoreflectthecomplexitiesofbuiltassetdata. Ourproposeddatasets\ncoverdiversesubdomainsandexhibitvaryinglevelsofgranularity,mirroringreal-worldscenarios\nwherebuiltproductsarerequiredtobemappedacrossvariousdatadictionaries. Thedatasetscan\nbeusednotonlyforevaluatingneworfine-tunedtextembeddingmodelsforcross-mappingbuilt\nassetdatabutalsoasacontextuallyrichtextcorpustosupportthetrainingoftask-specificlanguage\nmodelsforotherdownstreamtasks,suchasinformationextraction. Finally,thisworkcontributesto\nthebroaderdiscourseonthetransferabilityofthegeneral-purposelanguagemodels’capabilitiesby\nfocusingonbuiltassetdataasarepresentativeexampleofnicheandunderexploreddomains.\nOnekeylimitationofourstudyisthatthetextsourcesusedinourworkareexclusivelyinEnglish,\nlimitingthegeneralizabilityofourfindingstootherlanguages. Anothersignificantchallengewas\nidentifyingdatasourcesthatwerebothofhighqualityandcouldberedistributedaspublicdatasets.In\nthislight,althoughthedevelopeddatasetsprovedsufficientforourcurrentanalysis,futureworkcould\nbenefitfromlarger-scaledatasetsandintroducetrainingandvalidationsplitstosupportnewtasks. It\nisrecommendedtoprioritizeexploringmoreextensiveanddiversetextsourcestoincludemultiple\nlanguagesandnewtaskswheretheavailabilityoflargetrainingsplitsplaysacrucialrole,suchastext\nclassificationorrerankingbasedoncross-encoderarchitectures. Finally,throughthepublicreleaseof\nourbenchmarkingresourcesinalignmentwiththeMTEB’sopen-sourcesoftware,weaimtoensure\nthereproducibilityandextendabilityofourworkthroughcommunity-drivenenhancements.\nDataavailability\nThe datasets and codes developed in this study are openly accessible at the following GitHub\nrepository:https://github.com/mehrzadshm/built-bench-paper.Allmaterialsarelicensed\nundertheCreativeCommonsAttribution-NoDerivatives4.0InternationalLicense(CCBY-ND4.0).\nAnyfutureupdates,includingreferencestoadditionaldataandrelevantresources,willbeincorporated\nintothisrepository.\nReferences\nbuildingsmartinternational. https://www.buildingsmart.org/,2024. Accessed:2024-06-24.\n10\n2v-debmE-VN tcurtsni-B7-2newQ-etg\ntcurtsni-egral-5e-laugnilitlum\n5v_M004_ne_allets\nllams-etg\negral-3-gniddebme-txet\negral-etg\n5v_B5.1_ne_allets 1v-egral-debme-iabxm 5.1v-ne-egral-egb 5.1v-ne-esab-etg 5.1v-ne-esab-egb\nesab-etg\n5.1v-ne-egral-etg\n2v-esab-5e\n0v-gniddebmE-TSIG llams-3-gniddebme-txet 1V-egraL-EAU\n2v-egral-5e\nllams-5e-laugnilitlum\n0v-gniddebmE-egral-TSIG\n2v-21L-MLiniM-lla\n2v-21L-MLiniM-laugnilitlum-esarhparap\nIfcopenshell. https://github.com/IfcOpenShell/IfcOpenShell/,2024. Accessed:2024-06-24.\nbuildingSmart International. buildingsmart data dictionary (bsdd). https://www.buildingsmart.org/\nusers/services/buildingsmart-data-dictionary/,2024a. Accessed:2024-06-24.\nbuildingSmart International. Ifc 4.3 documentation. https://standards.buildingsmart.org/IFC/\nRELEASE/IFC4_3/,2024b. Accessed:2024-06-24.\nX.CaoandM.Kosinski. Largelanguagemodelsknowhowthepersonalityofpublicfiguresisperceivedbythe\ngeneralpublic. ScientificReports,14(1):6735,2024.\nR.Cappuzzo,P.Papotti,andS.Thirumuruganathan. Creatingembeddingsofheterogeneousrelationaldatasets\nfordataintegrationtasks.InProceedingsofthe2020ACMSIGMODinternationalconferenceonmanagement\nofdata,pages1335–1349,2020.\nK.Enevoldsen,M.Kardos,N.Muennighoff,andK.L.Nielbo. Thescandinavianembeddingbenchmarks:Com-\nprehensiveassessmentofmultilingualandmonolingualtextembedding. arXivpreprintarXiv:2406.02396,\n2024.\nK.Forth,P.Berggold,andA.Borrmann. Domain-specificfine-tuningofllmformaterialmatchingofbim\nelementsandmaterialpassports. InProc.of2024ASCEInternationalConferenceonComputinginCivil\nEngineering,2024.\nK. Järvelin and J. Kekäläinen. Cumulated gain-based evaluation of ir techniques. ACM Transactions on\nInformationSystems(TOIS),20(4):422–446,2002.\nK.Jeon, G.Lee, S.Yang, Y.Kim, andS.Suh. Dynamicbuildingdefectcategorizationthroughenhanced\nunsupervisedtextclassificationwithdomain-specificcorpusembeddingmethods.AutomationinConstruction,\n157:105182,2024.\nY. Jung, J. Hockenmaier, and M. Golparvar-Fard. Transformer language model for mapping construction\nscheduleactivitiestouniformatcategories. AutomationinConstruction,157:105183,2024.\nC.Lee,R.Roy,M.Xu,J.Raiman,M.Shoeybi,B.Catanzaro,andW.Ping. Nv-embed:Improvedtechniquesfor\ntrainingllmsasgeneralistembeddingmodels. arXivpreprintarXiv:2405.17428,2024a.\nJ.Lee,Z.Dai,X.Ren,B.Chen,D.Cer,J.R.Cole,K.Hui,M.Boratko,R.Kapadia,W.Ding,etal. Gecko:\nVersatiletextembeddingsdistilledfromlargelanguagemodels. arXivpreprintarXiv:2403.20327,2024b.\nX.LiandJ.Li. Angle-optimizedtextembeddings. arXivpreprintarXiv:2309.12871,2023.\nP.E.LoveandJ.Matthews. The‘how’ofbenefitsmanagementfordigitaltechnology:Fromengineeringtoasset\nmanagement. AutomationinConstruction,107:102930,2019.\nS. Mehrzad. built-bench-paper (GitHub repository). https://github.com/mehrzadshm/\nbuilt-bench-paper,2024. Accessed:2024-10-20.\nT.Mikolov,I.Sutskever,K.Chen,G.S.Corrado,andJ.Dean. Distributedrepresentationsofwordsandphrases\nandtheircompositionality. Advancesinneuralinformationprocessingsystems,26,2013.\nN.Moretti,X.Xie,J.MerinoGarcia,J.Chang,andA.KumarParlikad. Federateddatamodelingforbuilt\nenvironmentdigitaltwins. JournalofComputinginCivilEngineering,37(4):04023013,2023.\nN.Muennighoff,N.Tazi,L.Magne,andN.Reimers. Mteb:Massivetextembeddingbenchmark. arXivpreprint\narXiv:2210.07316,2022.\nNBS. Nationalbuildingspecification. https://www.thenbs.com/,2024a. Accessed:2024-06-24.\nNBS. Uniclass. https://uniclass.thenbs.com/,2024b. Accessed:2024-06-24.\nM.Ostendorff,E.Ash,T.Ruas,B.Gipp,J.Moreno-Schneider,andG.Rehm. Evaluatingdocumentrepresen-\ntationsforcontent-basedlegalliteraturerecommendations. InProceedingsoftheeighteenthinternational\nconferenceonartificialintelligenceandlaw,pages109–118,2021.\nJ.Pennington,R.Socher,andC.D.Manning. Glove:Globalvectorsforwordrepresentation. InProceedings\nofthe2014conferenceonempiricalmethodsinnaturallanguageprocessing(EMNLP),pages1532–1543,\n2014.\nL.Rasmy,Y.Xiang,Z.Xie,C.Tao,andD.Zhi. Med-bert:pretrainedcontextualizedembeddingsonlarge-scale\nstructuredelectronichealthrecordsfordiseaseprediction. NPJdigitalmedicine,4(1):86,2021.\n11\nN.ReimersandI.Gurevych. Sentence-bert:Sentenceembeddingsusingsiamesebert-networks. InProceedings\nofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputational\nLinguistics,112019. URLhttp://arxiv.org/abs/1908.10084.\nC.J.Roberts,E.A.Pärn,D.J.Edwards,andC.Aigbavboa.Digitalisingassetmanagement:concomitantbenefits\nandpersistentchallenges. InternationalJournalofBuildingPathologyandAdaptation,36(2):152–173,2018.\nA.RosenbergandJ.Hirschberg. V-measure:Aconditionalentropy-basedexternalclusterevaluationmeasure.\nIn Proceedings of the 2007 joint conference on empirical methods in natural language processing and\ncomputationalnaturallanguagelearning(EMNLP-CoNLL),pages410–420,2007.\nH.Rouhizadeh,I.Nikishina,A.Yazdani,A.Bornet,B.Zhang,J.Ehrsam,C.Gaudet-Blavignac,N.Naderi,\nandD.Teodoro. Adatasetforevaluatingcontextualizedrepresentationofbiomedicalconceptsinlanguage\nmodels. ScientificData,11(1):455,2024.\nM.Shahinmoghadam,S.E.Kahou,andA.Motamedi. Neuralsemantictaggingfornaturallanguage-based\nsearchinbuildinginformationmodels:Implicationsforpractice. ComputersinIndustry,155:104063,2024.\nA.Vaswani,N.Shazeer,N.Parmar,J.Uszkoreit,L.Jones,A.N.Gomez,Ł.Kaiser,andI.Polosukhin. Attention\nisallyouneed. Advancesinneuralinformationprocessingsystems,30,2017.\nZ.Wang,M.Bergés,andB.Akinci. Pre-trainedlanguagemodelbasedmethodforbuildinginformationmodel\ntobuildingenergymodeltransformationatmetamodellevel. InISARC.ProceedingsoftheInternational\nSymposiumonAutomationandRoboticsinConstruction,volume41,pages17–25.IAARCPublications,\n2024.\nR.S.Wilkho,S.Chang,andN.G.Gharaibeh. Ff-bert:Abert-basedensembleforautomatedclassificationof\nweb-basedtextonflashfloodevents. AdvancedEngineeringInformatics,59:102293,2024.\nC. Wu, X. Li, Y. Guo, J. Wang, Z. Ren, M. Wang, and Z. Yang. Natural language processing for smart\nconstruction:Currentstatusandfuturedirections. AutomationinConstruction,134:104059,2022.\nY.Zhang,Q.Chen,Z.Yang,H.Lin,andZ.Lu. Biowordvec,improvingbiomedicalwordembeddingswith\nsubwordinformationandmesh. Scientificdata,6(1):52,2019.\n12",
    "pdf_filename": "Benchmarking_pre-trained_text_embedding_models_in_aligning_built_asset_information.pdf"
}