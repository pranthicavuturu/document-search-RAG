{
    "title": "U C - -T LLM",
    "abstract": "",
    "body": "U C - -T LLM\nNDERSTANDING HAIN OF HOUGHT IN S\nI T\nTHROUGH NFORMATION HEORY\nJean-Franc¸oisTon∗1,MuhammadFaaizTaufiq∗1,andYangLiu2\n1ByteDanceResearch\n2UniversityofCaliforniaSantaCruz\nLarge Language Models (LLMs) have shown impressive performance in complex reasoning\ntasks through Chain-of-Thought (CoT) reasoning, allowing models to break down problems\ninto manageable sub-tasks. However, existing CoT evaluation techniques either require an-\nnotated CoT data or fall short in accurately assessing intermediate reasoning steps, leading\nto high rates of false positives. In this paper, we formalize CoT reasoning in LLMs through\naninformation-theoreticlens. Specifically,ourframeworkquantifiesthe‘informationgain’at\neachreasoningstep,enablingtheidentificationoffailuremodesinLLMswithouttheneedfor\nexpensiveannotateddatasets. Wedemonstratetheefficacyofourapproachthroughextensive\nexperiments on toy and GSM-8K data, where it significantly outperforms existing outcome-\nbasedmethodsbyprovidingmoreaccurateinsightsintomodelperformanceonindividualtasks.\n1 Introduction\nLargeLanguageModels(LLMs)havedemonstratedremarkablecapabilitiesacrossawiderangeoftasks, from\ncomplex reasoning to code generation [Chowdhery et al., 2024, OpenAI et al., 2024, Bubeck et al., 2023, Anil\netal.,2023]. ManyoftheseadvancescanbeattributedtoChain-of-Thought(CoT)reasoning[Weietal.,2024,\nNyeetal.,2021,Lietal.,2024],whichinvolvesbreakingdowncomplexproblemsintoaseriesofintermediate\nsteps,mirroringhuman-likereasoningprocesses. ThesuccessofCoTreasoning,particularlyindomainssuchas\nmathematics,logic,andmulti-stepdecision-making,hasledresearchersanddeveloperstoincorporateCoT-like\nfeaturesdirectlyintomodeltraining,i.e. theFLANfamilyofmodels[Chungetal.,2022,Weietal.,2022].\nThis paper introduces a new formal framework for analyzing CoT in LLMs. We provide a rigorous method\ngroundedininformationtheory,toevaluatethequalityofeachstepinamodel’sreasoningprocess,thusoffering\ninsightsbeyondsimpleaccuracymetricstoidentifyareasforimprovement.\nPreviousworkinthisareahasproposed“ProcessSupervision”[Lightmanetal.,2023],whichrequiresexpensive,\nhuman-annotatedstep-by-stepdata. Whileeffective,thisapproachisoftenimpracticalduetothehighcostand\neffortofcreatinglarge-scaleannotateddatasets. Inturn,alternativemethodshaverecentlybeenproposed,such\nas outcome reward modelling [Havrilla et al., 2024] or the Math-Shepherd [Wang et al., 2024b]. Both these\napproaches avoid reliance on annotated step-wise CoT data by instead modelling the correctness of each step\nbased on the correctness of final outputs. However, as we demonstrate in this paper, these methods can be\nunsoundfordetectingincorrectreasoningstepsandcanthusleadtoahighfalse-positiverateincertainscenarios.\nTo address these shortcomings, we employ an information-theoretic approach, grounded in the following key\ninsight: Eachcorrectstepinareasoningprocessshouldprovidevaluableandrelevantinformationthataidsin\npredicting the final correct outcome. Building on this insight, we develop a framework to quantify the “infor-\nmation gain” after each sub-task in the reasoning process, without the need for step-by-step annotations. This\nenablesustodetectsub-tasksthatfailtocontributemeaningfulinformationtowardthecorrectsolution,signalling\npotentialerrorsorirrelevantstepsinthemodel’sreasoning. Inaddition,wealsointroduceapracticalalgorithm\ntoassessLLMperformanceacrossvarioussub-taskswithinaChain-of-Thought(CoT)reasoningprocess.\nThekeycontributionsofthispaperareasfollows:\n1. Wedevelopaframeworkforsequentialapplicationsofsub-tasks,e.g. Chain-of-Thoughtandprovidea\nrigorouslanguagetodescribeanddetectdetectfailuremodesinLLMs.\n2. Basedonthisframework,weproposeapracticalalgorithmtoassessthetask-wiseperformanceofmod-\nels. Thisyieldsmoregranularinformationaboutamodel’sCoTperformancewithoutrequiringanno-\ntateddataforintermediatereasoningsteps.\n∗Denotesequalcontribution,whereorderingwasdeterminedthroughacoinflip.\nCorrespondingauthors:jeanfrancois@bytedance.comandfaaiz.taufiq@bytedance.com.\n1\n4202\nvoN\n81\n]LC.sc[\n1v48911.1142:viXra\n3. WevalidateourmethodsonextensivetoydataandtheGSM-8Kdataset[Cobbeetal.,2021].Ourmethod\neffectively identifies failure modes in CoT reasoning, unlike baselines like outcome reward modelling\n[Havrillaetal.,2024]andMath-Shepherd[Wangetal.,2024b],whichrelyonfinalaccuracyandtend\ntoincreasefalsepositivesinerrordetection.\n2 ProposedFramework: SetupandNotation\nBeforedivingintoourframework,wefirstprovideahigh-leveloverviewandnotationonhowLLMgeneration\nwill be treated throughout this paper. This will allow us to set the foundation for describing our information-\ntheoretic framework. In particular, following the approach in Gonza´lez and Nori [2023], we view LLMs as\nabstract execution machines with a natural language interface. From this perspective, prompts are designed to\nsolvespecificproblems(e.g.,mathematicalorlogicalproblems),andtheLLMprocessestheinformationinthe\nprompttogenerateanoutput.\nWenowdefinethenotationforatypicalpromptasacombinationoftwocomponents:\n1. Aninitialstate,representedbyarandomvariableX ∈X,denotesinformationprovidedintheprompt\n0\nthattheLLMmustoperateontoobtainthequeriedinformation.\n2. A task λ ∈ Υ (e.g., addition followed by multiplication) which encapsulates how the LLM should\nprocessinformationinX .\n0\nGiventheprompt, definedasatuple(X ,λ), thestateX representstheresultofapplyingtaskλtotheinitial\n0 1\nstate X . Formally, we denote this using the update mapping Λ : X × Υ → X which outputs the updated\n0\nstateX byapplyingthetaskλonX ,i.e. X = Λ(X ,λ). Thisupdatedstateisthenusedtoobtainthefinal\n1 0 1 0\noutput,denotedbyY ∈X,byextractingonlytheinformationinX whichisrelevanttothequeriedfinalanswer.\n1\nThisnotationdefinesapromptthatinstructsamodeltoprocessinformationdrawnfromsomeinitialdistribution\np(X )(e.g.,mathematicalproblems).\n0\nLetususethefollowingsimpleexampletoillustratethenotation:\nPrompt:“Jameshas3applesandAbbeyhas9. Howmanyapplesdothetwohaveintotal?”\nHere, using the above notation, the initial state x denotes the information “James has 3 apples; Abbey has 9\n0\napples”,andλdenotestheadditiontask. Next,x =Λ(x ,λ)representstheupdatedinformationaftercorrectly\n1 0\nperformingtheadditionoperation,i.e. x =“Jameshas3apples;Abbeyhas9apples;Thetwohave12applesin\n1\ntotal”.Thefinaloutput,y,isthenobtainedbysimplyextractingthetotalnumberofapplesfromx ,i.e.“Thetwo\n1\nhave12applesintotal”1. Withthisbasicnotationestablished,wenowconsidercompositionsoftasks,enabling\nustoformalizetheChainofThought(CoT)processinLLMs.\n2.1 Compositionality\nMany mathematical or logical problems require a sequential application of operations. Our notation is also\namenabletosuchproblemsasitaccommodatesthecompositionoftasks.Consideraproblemwhichrequirestwo\nsuccessivestepstoarriveatthecorrectoutput:\nPrompt: “Solveforz =2×(x+y)wherex=12andy=13”. (1)\nInthisexample,first,weapplytheadditionoperationtofindthevalueofx+y,andnext,weapplythemultipli-\ncationoperationtofindthevalueofz. UsingournotationthiscanbeexpressedasΛ(x ,λ ◦λ ),whereλ ,λ\n0 1 2 1 2\ndenotetheadditionandmultiplicationtasksrespectively. Thefollowingpropertyallowsustoconcretelydefine\ntheapplicationofcompositionaltaskλ ◦λ :\n1 2\nDefinition2.1. WesaythatanupdateruleΛ:X ×Υ→X iscompositionallyconsistentif:\nd\nΛ(x ,λ ◦λ )=Λ(Λ(x ,λ ),λ ) forallx ∈X andλ ,λ ∈Υ.\n0 1 2 0 1 2 0 1 2\nd\nHere, =denotesequalityindistributionandissufficientinmanycases. Forexample, whereaquerymayhave\nmultiplecorrectresponses,analmostsureequalitymaybetoorestrictive.\nGoing back to the prompt in (1), Figure 1 shows that the model first computes x+y, and next multiplies the\nresult by 2. Here, we refer to X ,X as intermediate states and Y is the correct final output. More generally,\n1 2\nif a problem statement requires sequential application of T sub-tasks, λ = λ ◦...◦λ , then the Chain-of-\n1 T\nThought (CoT) reasoning is divided up into T steps, where the output of the t’th step is recursively defined as\n1Oursetupalsoencapsulatescaseswithambiguous(ormultiplecorrect)responsesforagiventaskλandinitialstatex .\n0\nInthiscase,Λ(x ,λ)isarandomvariablewithdistributionp(X | X = x ). Therefore,forgenerality,wetreatΛ(x ,λ)\n0 1 0 0 0\nasarandomvariablefromnowon.\n2\nFigure1: Solvingtheprobleminprompt(1)requirescompositionalapplicationoftasks.\nX = Λ(X ,λ )fort ∈ {1,...,T}. Finally, theoveralltrueoutputY isobtainedbyextractingthequeried\nt t−1 t\ninformationfromthefinalstateX .\nT\nHavingestablishedaformallanguageforthesequentialapplicationoftasks,e.g. CoT,wenowturntowardshow\nataskmaybedividedintosuchasequenceofintermediatesub-tasks.\n2.2 Primitivetasks\nInthissubsection, weintroducethenotionofprimitivetaskswhichformthebasicbuildingblocksofanytask.\nIntuitively,ourformulationisreminiscentofideasfromlinearalgebra,wherebasisvectorsformthebasicbuilding\nblocks of a vector space. In our case, any task λ ∈ Υ can be expressed as a sequence of primitive tasks. This\ndecomposition will allow us to establish which tasks the model could have learned from the training data. For\nexample,ifaspecificprimitivetaskisnotavailableintheLLMtrainingdata,itwouldbeimpossibleforthemodel\ntoexecuteanyinstructionswhichinvolvethisprimitivetaskcorrectly. Withthisinmind,wenowintroducethis\nconceptformally:\nDefinition2.2(Primitivetasks). WesaythatasetoftasksΓ⊆Υisprimitiveif,foranytaskλ∈Υ,thereexists\nauniquesubset{λ }k ⊆Γsuchthatλ=λ ◦···◦λ .\ni i=1 1 k\nNotethatthedecompositionisnotuniquebutthesetofcomponentsis. Insomecases, theremayexistdistinct\npermutations of primitive tasks which compose to yield the same task as is common in many associative op-\nerations. As an example, in the context of mathematical problem-solving, the basic arithmetic operation could\nbe considered primitive. The composition of these primitive tasks allows us to construct extremely complex\noperations. Just like in linear algebra, we define the span of these tasks as the set obtained by their sequential\napplications.\nDefinition2.3(Spanoftasks). LetΦ⊆Υbeasetoftasks,then:\nSpan(Φ)={λ ◦...◦λ :λ ∈Φfor1≤i≤k,k ∈Z }.\n1 k i >0\nThesetSpan(Φ)comprisesallthetasksthatcanbeappliedbycomposingsub-tasksinthesetΦ. Thismeansthat\nanycompositionallyconsistentupdateruleΛwhichiswell-definedonthesetoftasksΦwillalsobewell-defined\nonSpan(Φ). However,thisΛmaystillbeill-definedforanytasknotinthisspan. Thislimitationiscapturedby\ntheconceptofunidentifiability,whichplaysacentralroleindeterminingtheboundariesofwhatamodelcanand\ncannotinfer.\n2.3 Unidentifiability\nTheunidentifiabilityoftasksformsakeypartofourframework. Itdirectlyaddressesthefundamentalchallenge\nthatmodels, suchasLLMs, facewhendealingwithunseentasks. IfataskλliesoutsideofSpan(Φ), thespan\noftasksthemodelhasbeentrainedon,thenthemodelcannotbeexpectedtoinferorapplyitcorrectly. Inother\nwords,themodel’scapacityisconstrainedbytheidentifiabilityoftaskswithinthetrainingset. Thisnotionand\nformalizationofunidentifiabilityallowsustohighlightacriticallimitationinthegeneralizationofmodels: tasks\nnotencounteredduringtrainingcannotbereliablyexecuted,astheyremainbeyondthemodel’slearnedtaskspan.\nMoreformally:\nDefinition2.4(Unidentifiability). LetΦ⊆Υbeanysetoftasks,thenatasksλissaidtobeunidentifiableinΦ\niff,λ̸∈Span(Φ).\nRemarkInpractice, theconceptofunidentifiabilitymaydependontheinitialstateX . Forinstance, anLLM\n0\nmight accurately perform addition for 2-digit numbers but fail with 10-digit numbers [Razeghi et al., 2022].\nOur framework can be extended to account for such cases by explicitly incorporating the distribution of initial\nstatesintothenotionofidentifiability. Forexample,additioncouldbeconsideredunidentifiablewhentheinitial\nstatedistributionisp(X | X includes10-digitnumbers). However, forsimplicity, wekeepthisdistributional\n0 0\ndependenceimplicitinthedefinitionprovidedearlier.\nWiththisgeneralframeworkinplace,wecannowturnthistheoreticalfoundationintoapracticalalgorithmfor\ndetectingunidentifiablesub-tasks. Specifically,weexplorehowthenotionofunidentifiabilitycanbecombined\nwithinformation-theoreticapproachestodetectfailurepointsinLLMs.\n3\n3 Operationalisingourframework\nThis section aims to operationalise the above framework to make inferences regarding the unidentifiability of\nintermediate sub-tasks in a model’s CoT reasoning process. This would subsequently allow us to detect any\nsub-task at which a model’s CoT reasoning process starts to diverge from the ground truth, thereby providing\ninsights into how the model can be improved. For example, suppose we are in a setting where the “addition”\noperationisunidentifiable,thenwecouldfurtherimprovethemodel’smathematicalreasoningbyfine-tuningit\nontheadditionoperation.\n3.1 Aninformation-theoreticperspective\nTomaketheconceptofunidentifiabilitypracticalinthecontextofCoTgenerations,webeginbyintroducingthe\nfundamentalassumption.ThecoreassumptioninourapproachisthateachcorrectlyexecutedCoTreasoningstep\nshouldcontributemeaningfulandrelevantinformationthataidsinpredictingthecorrectfinaloutput,denotedas\nY. IfweencounterastepafterwhichtheamountofinformationregardingY stopsincreasing,thenwecantake\nthisasanindicationofanincorrectlyexecutedtask. Weconcretisethisassumptionusingusingournotationfrom\ntheprevioussection:\nAssumption3.1(Bayesiannetwork). Letλ̸=λ′betwooperationswithprimitivedecompositions:\nλ=λ ◦...λ ◦λ ◦···◦λ and λ′ =λ ◦...λ ◦λ′ ◦···◦λ′ ,\n1 k−1 k T 1 k−1 k T′\nwhereλ′ isunidentifiablein{λ ,...,λ }. Then, theintermediatestatescorrespondingtothetasksλ,λ′ have\nk 1 T\nthefollowingBayesiannetwork:\nλ λ\nλ X k k+1 ... T Y\nk\nλ λ\nX 1 ... k−1 X\n0 k−1\nλ′ k X k′\nλ′\n...\nλ′\nY′\nk+1 T′\nFigure2: Bayesiannetwork\nIntuition TheBayesiannetworkinFigure2impliesthatforanytworeasoningpathswhichdivergeatstepk,the\nfuturestatesX andX′ foranyi,j ≥ ksatisfytheconditionalindependenceX ⊥⊥ X′ | X . Consequently,\ni j i j k−1\nonceweapplyλ′,thesubsequentstatesalongthenewreasoningpath(inred)addnoinformationregardingthe\nk\nsubsequentstatesortheoutputoftheoriginalpath(ingreen). Hencethefigurerepresentsthefactthat,forany\ngiveninput,theoutputofλ (topfork)containsnoinformationregardingtheoutputofanyotherprimitivetask\nk\nλ′ (bottomfork).\nk\nNowthatwehaveformalisedourkeyinformation-theoreticassumptionontheground-truthCoTprocess,weturn\ntowardsthemodelbehaviouronunidentifiabletasksinthefollowingsection.\n3.2 TaskexecutioninLLMs\nTooperationaliseourframework,weformallydistinguishbetweenthemodeli.e. LLM’staskexecutionandthe\ngroundtruthprocesswhicharisesfromfollowingtheinstructionscorrectly. Tothisend,weexplicitlydefinehow\nan LLM interprets a specified task λ using the update rule, ΛM(X ,λ), which is in general distinct from the\n0\ngroundtruthupdateruleΛ(X ,λ).\n0\nHere,oneoptionwouldbetoconsidertheidealisedsettingwherethemodellearnstoperfectlyfollowsomeofthe\nprimitivetasksavailableinthetrainingdata.However,thismaybeconsideredtoorestrictivesinceinrealitymost\nLLMsdonotalwaysfollowa“learned”taskperfectly. Instead,weconsideramuchweakerassumptionthatthe\nmodelcannotcorrectlyexecuteataskwhichisunidentifiableinthetrainingdata. Tothisend,supposeΓM ⊆ Γ\ndenotestheprimitivetasksavailableintheLLMtrainingdata. Concretely,wemakethefollowingassumptionon\nLLM’staskexecution.\nAssumption 3.2 (Task execution in LLMs). ΛM is compositionally consistent and for any (x ,λ) ∈ X ×Υ,\n0\nthereexistssomeλ(cid:98)∈Span(ΓM)suchthatΛM(x 0,λ)=d Λ(x 0,λ(cid:98)).\nIntuition Assumption 3.2 means that for any task which we would like the LLM to apply, the LLM ends up\nexecutingsometaskinSpan(ΓM)whichthemodelhasbeentrainedon. Inotherwords,themodel’sexecution\nisrestrictedonlytothetaskswhichcouldbeinferredfromthetrainingdata(i.e. inSpan(ΓM)). Moreover,this\nassumptionalsoallowsustoencapsulatecaseswherethemodeldoesnotfollowthecorrectinstructionsordoes\nnotdecomposeagiventaskcorrectly.\n4\nBeforeproceedingfurtherwithourmainresultwhichwillallowustotestfortheunidentifiabilityofsub-tasks,\nwe define some notation which we will use from now onwards. Let λ = λ ◦ ... ◦ λ denote a primitive\n1 T\ndecomposition of a task λ. Then, starting from an initial state X , we denote the model’s intermediate states\n0\nrecursivelyas:\nXM :=ΛM(XM ,λ ) and XM =X .\nt t−1 t 0 0\nMoreover,weuseYM todenotethemodel’sfinaloutput.Next,usingthisnotation,wepresenttheconditionalin-\ndependencewhichmustholdifthemodelencountersanunidentifiableintermediatetaskalongitsCoTreasoning\npath.\nTheorem 3.3. Let ΓM ⊆ Γ denote the primitive tasks available in the training data. Let λ be a task with\ndecompositionλ = λ ◦...◦λ . Ifλ isthefirsttaskinthedecompositionofλwhichisunidentifiableinΓM\n1 T k\n(i.e. k =argmin {λ ̸∈Span(ΓM)}). Then,underAssumptions3.1and3.2,wehavethat\nt t\nY ⊥⊥XM |XM forallj ≥k. (2)\nj j−1\nTheorem3.3showsthatunderAssumptions3.1and3.2,whenthemodelencountersanunidentifiabletask(i.e.\nλ inTheorem3.3)initsChain-of-Thoughtreasoning, themodeloutputsatisfiestheconditionalindependence\nk\ninEquation(2). Moreconcretely,afteramodel’sCoTreasoningdivergesfromthegroundtruthatstepk,every\nsubsequentstepaddsnoadditionalinformationregardingthecorrectfinaloutputY.Inpractice,this‘information’\nis measured by checking if the model’s confidence about the final output Y increases after each step. This is\nformalisedinthenextsection.\n3.3 Testingforunidentifiabilityusinginformationgain\nHaving established all the essential components of our framework, we can now provide a concrete description\nofhowtopracticallyidentifyunidentifiablesub-tasksusinginformationtheory. Asiscommonintheliterature\n[Wangetal.,2024b,Havrillaetal.,2024],weassumeaccesstoadatasetconsistingofpromptsandtheircorre-\nspondingfinalanswers,obtainedbycorrectlyapplyingthetaskλ.ThisdatasetisdenotedasD :={(xi,yi)}n .\nλ 0 i=1\nAdditionally, recall that XM and XM represent the model’s chain of thought (CoT) reasoning at steps j and\nj j−1\nj −1, respectively. Consequently, eachelementintheconditionalindependencestatementinEquation(2)can\nbederivedfromthedataand/orthemodel.\nTothisend,weconsiderthemutualinformationbetweenY andXM conditionalonXM ,denotedbyI(Y;XM |\nj j−1 j\nXM ). This conditional mutual information term intuitively represents the additional information contributed\nj−1\nby the j’th step of CoT, that is relevant for predicting the ground truth final output Y. Therefore, we refer to\nI(Y;XM |XM )astheinformationgainatstepj.\nj j−1\nItfollowsfromTheorem3.3thatifanLLMencountersasub-taskatstepiwhichisunidentifiableinitstraining\ndata,nosubsequentstepshouldcontributeanyadditionalinformationrelevantforpredictingY (i.e. theinforma-\ntiongainshouldremain0afterstepi). If,ontheotherhand,weobservethatI(cid:0) Y;XM |XM (cid:1) > 0forsome\nj j−1\nj ≥ i,thenunderAssumptions3.1and3.2,thetaskλ isnotunidentifiable. Toestimatetheinformationgainin\ni\npractice,weusethefollowingresult:\nProposition 3.4. Let I(X;Y | Z) denote the mutual information between random variables X and Y condi-\ntionalonZ. Then,\nE[logp(Y |XM)]−E[logp(Y |XM )]=I(cid:0) Y;XM |XM (cid:1) ≥0. (3)\nj j−1 j j−1\nToestimatetheinformationgainin(3)usingProposition3.4,wetrainaseparateLLM,whichwerefertoasthe\nsupervisormodelg . Thismodeltakesasinputthemodel’sCoTreasoninguptoanygivenintermediatestept,\nsup\nXM,andisfine-tunedtodirectlypredictthegroundtruthfinaloutputY. Inthiswayg (XM)approximatesthe\nt sup t\nconditionaldistributionp(Y | XM). Then,thequantityE[logp(Y | XM)]canbeestimatedusingthenegative\nt j\ncross-entropylossforpredictingY,i.e.\nE[logp(Y |XM)]≈E[logpˆ(Y |XM)]=−E[l (cid:0) Y,g (XM)(cid:1) ],\nj j CE sup j\nwherel denotesthecross-entropyloss. Fromthis,itfollowsthat\nCE\nE[logp(Y |XM)]−E[logp(Y |XM )]≈E[l (Y,g (XM ))]−E[l (Y,g (XM))]. (4)\nj j−1 CE sup j−1 CE sup j\n(cid:124) (cid:123)(cid:122) (cid:125)\nInformationgain\nSummary: The information gain (IG) between steps j and j −1 reflects how much relevant information step\nj contributes towards predicting Y. If task λ is executed correctly, this gain is positive, as indicated by a\nj\ndecreaseinthecross-entropyloss. Conversely,ifstepjdoesnotprovideadditionalinformation,thelossremains\nunchanged. ThiscanbeinterpretedastheconditionalmutualinformationbetweenXM andY, conditionedon\nj\n5\nXM . Positive information gain suggests step j adds new insight about Y, while no gain indicates no added\nj−1\ninformation. TrainingdetailsforthesupervisormodelareinAppendixB.1.3.\nRemarkonsample-wiseinformationgain Whileconditionalmutualinformationprovidesanaggregatemea-\nsureofinformationgainforasub-taskinadataset, itmayalsobedesirabletoobtainananalogousmeasureof\nsub-task correctness for individual CoT instances. This could be useful, for example, in detecting which step\nwentwrongforagivenprompt. Ournotionofinformationgaincanbeextendedtothissample-wisesettingby\ninsteadconsideringthefollowingdifference\nlogp(Y |XM)−logp(Y |XM )≈l (Y,g (XM ))−l (Y,g (XM)). (5)\nj j−1 CE sup j−1 CE sup j\nIntuitively,ifstepj inthemodel’sCoTiscorrect,themodelshouldbecomemoreconfidentinthegroundtruth\noutput Y being the correct final answer. Therefore, the difference above should be positive. Alternatively, if\nstepj iswrong,themodel’sconfidenceregardingthetrueoutputY shouldnotincreaseandtheabovedifference\nshouldnotbepositive. Fromnowon,werefertothedifferencein(5)assample-wiseinformationgainatstepj.\n4 Relatedworks\nEvaluationofCoTreasoning SeveralrecentworksproposemethodologiesforevaluatingCoTreasoning[Wei\netal.,2024,Havrillaetal.,2024,Lietal.,2023,Joshietal.,2023,Nguyenetal.,2024,Wangetal.,2024a,Yu\netal.,2024,Xieetal.,2024].Forexample,Lietal.[2023]verifiesindividualstepsinamodel’sCoTreasoningby\ngeneratingmultipleLLMresponsesperpromptandcomparingcorrectresponseswithincorrectones. Similarly,\nWang et al. [2024b,c] use a fine-tuned LLM to decode multiple reasoning paths from each step and check the\ncorrectness of these reasoning paths. However, as we show in our experiments, approaches which simply rely\non the correctness of the final output are not sound in general and can lead to false positives. Moreover, these\nsolutionsmaynotbeplausibleforproblemsofhighdifficultywherecorrectLLMresponsesmightbescarce.\nFormalisingCoTframework TheformalisationofLLMreasoningremainsanactiveareaofresearch. Most\nnotably Gonza´lez and Nori [2023] introduces a formal framework for LLMs and is a key source of inspiration\nbehindourformalism.Additionally,Fengetal.[2023]theoreticallyexaminestheexpressivityofLLMswithCoT\ninsolvingmathematicalanddecision-makingproblems,focusingonthetransformerarchitecture’simplications\nonaccuracy. Besidesthis,Xuetal.[2024]providesaformaldefinitionofhallucinations,butdoesnotconsider\nCoTreasoningspecifically.\nReward modelling One notable line of work known as outcome-based reward models (ORM) [Cobbe et al.,\n2021, Havrilla et al., 2024, Lightman et al., 2023] predicts the probability of reaching the correct final answer\ngiven a model’s intermediate CoT steps. While ORMs do not require demonstrations of correct intermediate\nsteps, we show in Section 5 that this approach is not sound for detecting errors in a model’s CoT reasoning.\nAnotherrelatedmethodisstep-wiseORM(SORM)Havrillaetal.[2024]whichestimatestheprobabilityofan\n‘optimal’modelreachingacorrectanswer, giventheCoTreasoningofourmodelofinterest. However, unlike\nourapproach,SORMrequirestrainingamodelwhichislargerandmorecapablethanourbasemodel.\nProcess-basedrewardmodelling(PRMs)[Lightmanetal.,2023,Uesatoetal.,2022]isanalternativeapproach\nwhichdirectlypredictsthecorrectnessofintermediateCoTreasoningsteps. Likewise,variousotherapproaches\nrely on annotated CoT datasets for benchmarking [Jacovi et al., 2024, Yu et al., 2024, Amini et al., 2019, Liu\netal.,2020,Xietal.,2024,Nguyenetal.,2024,Xieetal.,2024,McLeishetal.,2024]. Whilethesebenchmarks\nandmethodologiescanbevaluableforimprovingLLMreasoning, collectingannotateddatacanbeverycostly\nandisnotreadilyscalabletoothertasks. Unlikethesemethods,ourapproachcomputestheinformationgainat\neachstep,providingarichermeasureofLLMperformancewithoutrequiringanyhuman-annotatedCoTdata.\n5 Experiments\nIn this section, we empirically demonstrate the practical utility of our framework. In addition to our proposed\nmethoddubbedinformationgain(denotedbyIG),weconsidertwocommonbaselinesthatcanbeusedtodetect\ntheerrorsinamodel’sCoTreasoningandassumeaccesstoonlythemodel’sCoTgenerationsX ,XM,...,XM\n0 1 T\naswellasthecorrectfinalanswersdenotedasY.\nOutcomeRewardModel(ORM)[Havrillaetal.,2024] Thisinvolvestrainingaclassifier,denotedasf ,\nORM\nwhichtakesasinputmodelgenerationsuptoanysteptinitsCoTreasoning,XM,andpredictstheprobability\nt\nofthemodel’sfinalanswerbeingcorrect,i.e.\nf (XM)≈P(YM =Y |XM). (6)\nORM t t\nHere, if we observe that this probability of correctness drops significantly after step t, i.e. if f (XM) ≫\nORM t\nf (XM ),thisindicatesthatthemodeldoesnotapplythetaskλ correctly.\nORM t+1 t+1\n6\nErrors flagged by the respective baselines GT errors\nInformation gain after each operation Mean probability of the final answer being correct Proportion of completions with correct final answer\nLLM1 -0.014 0.0099 0.00098 -0.0019-0.00019 LLM1 0.012 0.015 0.013 0.014 0.014 LLM1 0 0 0 0 0\nLLM2 0.013 -0.0096 -0.004 -0.0017 -0.0032 LLM2 0.49 2.2e-08 7e-05 1.2e-05 1.4e-06 LLM2 0.37 0 0 0 0\nLLM3 0.013 0.27 -0.002 -0.0027 -0.0033 LLM3 0.13 1.7e-06 1.4e-06 2.1e-06 1.3e-06 LLM3 0 0 0 0 0\nLLM4 0.021 0.27 0.059 -0.0035 -0.0017 LLM4 0.5 0.5 0.47 8.7e-07 3.3e-07 LLM4 0.2 0.21 0.2 0 0\nLLM5 0.014 0.19 0.033 0.083 -0.0023 LLM5 0.52 0.54 0.55 0.52 0.058 LLM5 0.17 0.17 0.17 0.18 0\n1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n(a)Ourresults (b)ORMresults (c)Math-Shepherdresults\nFigure 3: Heatmaps quantifying the correctness of different sub-tasks for the 5 LLMs under consideration ob-\ntainedusingthedifferentbaselines. Here,theredcolorindicatesasignificantdropintheplottedmetricsandcan\nbeseenasanindicationofanincorrectlyexecutedsub-task.\nMath-Shepherd [Wang et al., 2024b] This method quantifies the potential for a given reasoning process\nXM by using a ‘completer’ model to generate N completions of each reasoning process starting from step t,\nt\n{(XM,XM ,...,XM ,YM)} ,whereYM denotesthefinalanswerreachedinthej’thcompletion. Then,\nt t+1,j T,j j j≤N j\nwe estimate the potential of this step based on the proportion of correct answers among the N completions,\ndenotedbyf (XM)as:\nMS t\nf\n(XM):=(cid:88)N 1(Y jM =Y)\n. (7)\nMS t N\nj=1\nFor a fair comparison we do not assume access to a ‘verifier’ model more capable than our base model and\ntherefore,weusethebasemodelasthecompletermodelinourexperiments.\n5.1 Toydataexperiments\nFirst, we consider a toy setting where we have full control over the model behaviour on different tasks. Our\npromptscompriseofanintegervectorZ ∈ Z5 sampledrandomlyfromagivendistribution. Thetaskλcom-\n0\nprises5-stepsλ = λ ◦...◦λ ,whereeachsub-taskλ denotesanoperationwhichtransformsagiveninteger\n1 5 i\nvector Z ∈ Z5 into another Z ∈ Z5. Finally, in this setup, the correct final answer Y is the value of Z .\ni−1 i 5\nAdditionaldetailsonthedatageneratingmechanismaswellasthesub-tasksareprovidedinAppendixB.1.\nGenerating the dataset To investigate partial unidentifiability for a given task λ we modify the obtained\ni\ndataset by introducing ‘noise’ at step i. In other words, the task λ is applied incorrectly on a subset of the\ni\ndata, whereas all other tasks are always applied correctly. This represents a model which sometimes fails at\nstepiandweuse‘LLM ’todenotethismodelinthisexperiment. Werepeatthisprocedureforalltasksλ for\ni i\ni∈{1,...,5}whichyields5LLMs{LLM ,...,LLM }.\n1 5\nToalsoinvestigatetherobustnessofthemethods,weintroduceaspecialcaseinLLM . Here,taskλ isapplied\n3 3\nincorrectly if and only if the output after task 2 (i.e., after λ ) lies in some set S. This choice has been made\n2\ndeliberatelytohighlightapitfalloftheexistingbaselines(aswewillexplainbelow)andisincontrasttotherest\nofLLMswhereanyerrorsoccuratrandom. Inotherwords,thecorrectnessoftaskλ isdependentontheoutput\n3\nofλ . Formoredetails,seeAppendixB.1.2.\n2\n5.1.1 Results\nFigure 3 shows how the different baselines quantify the correctness of the different tasks for the 5 different\nLLMsunderconsideration. ThisfigureonlyconsiderssampleswherethefinalansweroftheLLMwasincorrect,\ni.e. YM ̸= Y. For our method (IG), Figure 3a shows the information gain across the different steps for each\nLLM. Likewise, Figure 3b presents the results for ORM and shows how the average probability of correctness\nin(6)changesacrossthedifferentsteps,whereas,forMath-Shepherd,Figure3cshowstheproportionofcorrect\ncompletions starting after each step (7). Here, any significant drop in the plotted values indicate an incorrect\napplicationofatask.\nInformationgainaccuratelyquantifiesstep-wisecorrectness WeobservethatforeachLLMtheinformation\ngainremainspositiveuntilweencounteranincorrectreasoningstep,atwhichpointitdropstonegativevalues.\n7\nTable1: Metricsforsample-wiseclassificationofsub-taskcorrectnessforLLM usingthedifferentbaselines.\n3\nMETHOD ACCURACY↑ TPR↑ FPR↓\nIG(OURS) 0.96 0.98 0.06\nORM 0.77 0.98 0.54\nMATH-SHEPHERD 0.60 1.0 1.0\nTherefore,ourmethodcanidentifytheincorrectlyexecutedtaskforeachLLMunderconsideration. Weuseda\nGPT-2supervisormodeltoestimateinformationgain.\nPitfallofthebaselines WhiletheORMandMath-Shepherdmanagetocorrectlyidentifytheincorrectreason-\ningstepsinmostcases,thesemethodsfailtocorrectlydetecterroneousstepsforLLM . Thishappensbecause,\n3\nin our setup, λ is incorrectly applied if and only if the output after task λ lies in some set S. Therefore, the\n3 2\nclassifiermodelcanconfidentlypredictthecorrectnessofthefinalmodeloutputatλ bysimplycheckingifthe\n2\noutput lies in S. Here, the classifier becomes confident that the final output will be wrong right after λ , even\n2\nthoughtheerroroccursatλ .\n3\nSimilarly,whenusingMath-ShepherdforLLM (withthesamemodelbeingusedasacompleter),acompletion\n3\nyields an incorrect final answer if the output after λ lies in S. If this is the case, all completions yield an\n2\nincorrect final output regardless of which step we begin the completions from. This makes it impossible to\naccuratelyidentifythestepatwhichLLM goeswrong.\n3\nSample-wisedetection Wecanalsousethedifferentbaselinesforsample-wisedetectionoferroneousstepsas\noutlinedinSection3.3. Inthissetting,foreachprompt,wecanclassifyastepasincorrectifabaseline’smetric\nfallsbelowathreshold.Table1showstheresultsforsample-wiseclassificationofsub-taskcorrectnessforLLM\n3\nusingthedifferentbaselines(wherewechosethebestthresholdsforeachbaselineusingaheld-outdataset). It\ncan be seen that our method yields a significantly higher accuracy and a lower rate of false-positives than the\nbaselinesandtherefore,isalsoconsiderablymorereliableforsample-wisedetectionoferrors.\n5.2 ArithmeticoperationsonLLama-3-8B\nFollowingourtoyexperiments,wenowevaluateourframeworkinamorerealisticsettingusingtheLlama-3-8B\nmodel[Dubeyetal.,2024]. Wefocusonasimplearithmetictaskthatinvolvesbothmultiplicationandaddition\ntasks. Thegoalistoassessthemodel’sperformanceonindividualoperationsaswellastheircombination.\nExperimentalsetup Wesampletwointegersxandyuniformlyfromtherange[1,100000). Thepromptgiven\ntothemodelisstructuredasfollows:\nPrompt: “x={x},y={y},Pleasecalculatethefollowing: 1. 3x,2. 2y,3. 3x+2y”\nModelaccuracy Weobservethatthemodel’saccuracyvariesacrossthethreesteps:\nStep1accuracy: 80%, Step2accuracy: 98%, Step3accuracy: 42%.\nNotably, the majority of failures occur in the third step, which\ninvolves addition of the previously computed values. We ana-\nlyzed the distribution of (x,y) values where the model obtains\nthe correctfinal output. Interestingly, asFigure 4illustrates, we\nobserved that most errors occur when exactly one of the vari-\nables (x,y) is large and the other is small. This suggests that\nthemodel’scorrectnessishighlydependentonthe(x,y)values\nintheprompt,resultinginbaselinesstrugglingtoidentifytheer-\nroneousstepinthemodel’sCoTreasoning(asweshowbelow).\n5.2.1 Results\nOur Method We trained the supervisor model by fine-tuning\na Llama-3-8b model using Low Rank Adaptation (LoRA) [Hu\net al., 2021]. Table 2 shows that there is a significant drop in\ninformationgainatstep3relativetosteps1and2,demonstrating\nFigure4: Thedistributionof(x,y)forincor- thatourinformation-theoreticmethodisabletocorrectlyidentify\nrect samples shows a clear trend: Llama-3- thatthefailuremainlyoccursatstep3.\n8Bstrugglestoaddlargeandsmallnumbers\nOutcome Reward Model (ORM) In contrast, for ORM the\ntogether(top-leftandbottom-right).\nmeanprobabilityofcorrectnessincludedinTable2remainsun-\nchangedateachstep. ThiscouldbeexplainedbyFigure4which\nsuggeststhatORMclassifiercanpredictthecorrectnessofthefinaloutputusingonlythevaluesofxandyavail-\nable in the prompt. Crucially, the classifier’s confidence remains unchanged even as the model’s intermediate\n8\nreasoningstepsareaddedtotheinput. Hence,ORMisunabletodistinguishbetweenthemodel’sperformance\nonintermediatereasoningsteps.\nMath-Shepherd Table2includestheproportionofcorrectcompletionsforMath-Shepherd. Weobservethat\neven though this proportion is very small at step 3, we also observe that only about 5-7% of the completions\nstartingfromsteps1and2leadtoacorrectoutput,eventhoughtheerrormostlyoccursatstep3. Thishappens\nbecause the correctness of Llama-3-8B is largely determined by the initial values of (x,y) in the prompt (see\nFigure4). Consequently, Math-Shepherdincorrectlyflagssteps1and2asincorrectasignificantproportionof\nthe time which leads to a significantly higher proportion of false positives (as compared to our baseline) as we\nshowbelow.\nTable2: Metricsforaggregatestep-wisecorrectnessofarithmeticoperationsacrossprompts,alongwithsample-\nwiseclassificationofincorrectoperationsleadingtoanincorrectfinalanswer.\nSTEP1:3x✓ STEP2:2y✓ STEP3:3x+2y✗ ACCURACY↑ TPR↑ FPR↓\nIG(OURS) 0.67 0.24 0.027 0.76 0.51 0.02\nORM 0.24 0.24 0.24 0.56 0.10 0.07\nMATH-SHEPHERD 0.068 0.059 0.00069 0.53 0.99 0.86\nSample-wisedetection Whenusingthesemethodsforsample-wisedetectionofincorrectsteps,ourapproach\nyieldsthehighestaccuracyamongthebaselinesconsidered. Thissuperiorperformanceisattributedtothefact\nthatbaselineslikeORMandMath-Shepherdoftenfalselyflagsteps1and2asincorrect, asevidencedbytheir\nhighfalsepositiveratesinTable2.\n5.3 ExperimentsontheControlledGSM-8KDataset\nTo evaluate our method on a complex dataset, we conducted experiments on GSM-8K [Cobbe et al., 2021],\ncontrollingspecificfactorsformoreinterpretableresults.\nWebeginbyusingGPT-4[OpenAIetal.,2024]togenerateanswersforGSM-8Kquestionswherethe“multipli-\ncation”operationisalwaysdoneincorrectly,whileallotheroperationsarecorrect. Next,wefilteredthedataset\ntoensurethat“multiplication”,“subtraction”,and“addition”neverappearedtogetherwithinthesameChainof\nThought (CoT) solution. In particular, we ensured in our setting that, all incorrect final answers included both\n“multiplication”and“subtraction”,whereascorrectfinalanswersdidnotinvolveeitheroperation.Thisintroduces\naspuriouscorrelationbetween“subtraction”andwronganswers.\nInthissetup,wemainlyfocusedonevaluatingORMandourproposedmethod,asMath-Shepherd(withthesame\ncompleter)failstriviallyundertheseconditions. Specifically,“multiplication”isinherentlyunidentifiable,since\nany CoT containing “multiplication” negates the influence of other sub-tasks by design. Further details on the\nexperimentalsetupcanbefoundinAppendixB.3.\n5.3.1 Results\nTable3demonstratesthatourproposedinformation-theoreticapproachsuccessfullyidentifiestheunidentifiable\nsub-task. Sinceweintentionallysetthe“multiplication”rulestobeincorrect,weobserveminimaltonoinforma-\ntiongainforthisoperation,asexpected.However,adifferentpatternemergeswhenweexaminetheresultsofthe\nORMmethod. Both“multiplication”and“subtraction”show,onaverage,averylowprobabilityofcorrectness.\nThisisduetothefactthatbothsub-tasksareprimarilyassociatedwithincorrectfinalanswers. Consequently,re-\nlyingonthestandardORMapproachcouldleadtothemisleadingconclusionthat“subtraction”isalsoincorrect.\nAdditionally, in our sample-wise experiment, we observe a similar trend when we use the methods to assess\nthesample-wisecorrectnessof“multiplication”and“subtraction”foreachprompt. Here,ourproposedmethod\nnot only accurately detects the unidentifiable sub-task but also highlights a significant shortcoming of ORM.\nSpecifically,ORMfalselyflags“subtraction”,whichisactuallycorrect,asanincorrectsub-taskduetospurious\ncorrelations.\nTable3: ComparisonbetweenourmethodandORMfordifferentsub-tasksinGSM-8K.Thefinalthreecolumns\nincluderesultsforsample-wiseclassificationofincorrectoperationsforeachprompt.\nADDITION✓ MULTIPLICATION✗ DIVISION✓ SUBTRACTION✓ ACCURACY↑ TPR↑ FPR↓\nIG(OURS) 0.99 0.026 1.05 1.06 0.72 0.95 0.62\nORM 0.46 0.024 0.38 0.013 0.58 1.0 1.0\n6 DiscussionandLimitations\nInthispaper, weintroduceanovelinformation-theoreticapproachforevaluatingChain-of-Thought(CoT)rea-\nsoninginlargelanguagemodels(LLMs)withouttheneedforannotatedintermediatesteps.Wepresentacompre-\nhensiveframeworkformodelingtheCoTprocess,andtheresultsdemonstratetheeffectivenessofouralgorithm\n9\nin identifying erroneous reasoning steps across diverse experimental settings. We consistently outperform ex-\nisting baselines, including Outcome Reward Models (ORM) [Havrilla et al., 2024] and Math-Shepherd [Wang\netal.,2024b]asshowninourextensiveexperimentalsection. However,it’simportanttonotethatthataresome\nlimitationstoourapproach.\nForexample,ourmethodnecessitatesadditionaltrainingofthesupervisormodel,whichcanbecomputationally\ndemanding. Futureresearchcouldinvestigatetheuseofin-contextlearningtechniquestoestimateinformation\ngain, potentially reducing the need for extra training and enhancing both the accessibility and efficiency of the\napproach. Secondly,sample-wisedetectionintroducesfurtherchallengesthatmayleadtoerroneousconclusions.\nA language model may occasionally arrive at the correct answer by chance, even if a particular sub-task is\nunidentifiable. Althoughthisoccurrenceshouldnotsignificantlyimpacttheoveralltask-wiseinformationgain,\nitcouldresultininaccurateoutcomesforsample-wiseinformationgaininsuch‘lucky’cases. Finally,whileour\nmethoddoes notrequirecorrectness labelsfor everystep, we stillneedto categorizeeachstep accordingto its\nrespectivesub-task. However,thislimitationisnotuniquetoourmodel,asbothORMandMath-Shepherdalso\nrelyonsuchlabelstodrawsub-task-specificconclusions.\nReferences\nA.Amini,S.Gabriel,S.Lin,R.Koncel-Kedziorski,Y.Choi,andH.Hajishirzi. Mathqa: Towardsinterpretable\nmath word problem solving with operation-based formalisms. CoRR, abs/1905.13319, 2019. URL http:\n//arxiv.org/abs/1905.13319.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen,\nE. Chu, J. H. Clark, L. E. Shafey, Y. Huang, K. Meier-Hellstern, G. Mishra, E. Moreira, M. Omernick,\nK.Robinson,S.Ruder,Y.Tay,K.Xiao,Y.Xu,Y.Zhang,G.H.Abrego,J.Ahn,J.Austin,P.Barham,J.Botha,\nJ.Bradbury,S.Brahma,K.Brooks,M.Catasta,Y.Cheng,C.Cherry,C.A.Choquette-Choo,A.Chowdhery,\nC.Crepy,S.Dave,M.Dehghani,S.Dev,J.Devlin,M.D´ıaz,N.Du,E.Dyer,V.Feinberg,F.Feng,V.Fienber,\nM. Freitag, X. Garcia, S. Gehrmann, L. Gonzalez, G. Gur-Ari, S. Hand, H. Hashemi, L. Hou, J. Howland,\nA.Hu,J.Hui,J.Hurwitz,M.Isard,A.Ittycheriah,M.Jagielski,W.Jia,K.Kenealy,M.Krikun,S.Kudugunta,\nC. Lan, K. Lee, B. Lee, E. Li, M. Li, W. Li, Y. Li, J. Li, H. Lim, H. Lin, Z. Liu, F. Liu, M. Maggioni,\nA.Mahendru,J.Maynez,V.Misra,M.Moussalem,Z.Nado,J.Nham,E.Ni,A.Nystrom,A.Parrish,M.Pel-\nlat, M. Polacek, A. Polozov, R. Pope, S. Qiao, E. Reif, B. Richter, P. Riley, A. C. Ros, A. Roy, B. Saeta,\nR.Samuel,R.Shelby,A.Slone,D.Smilkov,D.R.So,D.Sohn,S.Tokumine,D.Valter,V.Vasudevan,K.Vo-\ndrahalli, X. Wang, P. Wang, Z. Wang, T. Wang, J. Wieting, Y. Wu, K. Xu, Y. Xu, L. Xue, P. Yin, J. Yu,\nQ.Zhang,S.Zheng,C.Zheng,W.Zhou,D.Zhou,S.Petrov,andY.Wu. Palm2technicalreport,2023. URL\nhttps://arxiv.org/abs/2305.10403.\nS.Bubeck,V.Chandrasekaran,R.Eldan,J.Gehrke,E.Horvitz,E.Kamar,P.Lee,Y.T.Lee,Y.Li,S.Lundberg,\nH.Nori,H.Palangi,M.T.Ribeiro,andY.Zhang. Sparksofartificialgeneralintelligence: Earlyexperiments\nwithgpt-4,2023. URLhttps://arxiv.org/abs/2303.12712.\nA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton,\nS.Gehrmann,P.Schuh,K.Shi,S.Tsvyashchenko,J.Maynez,A.Rao,P.Barnes,Y.Tay,N.Shazeer,V.Prab-\nhakaran,E.Reif,N.Du,B.Hutchinson,R.Pope,J.Bradbury,J.Austin,M.Isard,G.Gur-Ari,P.Yin,T.Duke,\nA. Levskaya, S. Ghemawat, S. Dev, H. Michalewski, X. Garcia, V. Misra, K. Robinson, L. Fedus, D. Zhou,\nD.Ippolito,D.Luan,H.Lim,B.Zoph,A.Spiridonov,R.Sepassi,D.Dohan,S.Agrawal,M.Omernick,A.M.\nDai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang,\nB.Saeta,M.Diaz,O.Firat,M.Catasta,J.Wei,K.Meier-Hellstern,D.Eck,J.Dean,S.Petrov,andN.Fiedel.\nPalm: scalinglanguagemodelingwithpathways. J.Mach.Learn.Res.,24(1),mar2024. ISSN1532-4435.\nH. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma,\nA. Webson, S. S. Gu, Z. Dai, M. Suzgun, X. Chen, A. Chowdhery, A. Castro-Ros, M. Pellat, K. Robinson,\nD. Valter, S. Narang, G. Mishra, A. Yu, V. Zhao, Y. Huang, A. Dai, H. Yu, S. Petrov, E. H. Chi, J. Dean,\nJ. Devlin, A. Roberts, D. Zhou, Q. V. Le, and J. Wei. Scaling instruction-finetuned language models, 2022.\nURLhttps://arxiv.org/abs/2210.11416.\nK.Cobbe,V.Kosaraju,M.Bavarian,M.Chen,H.Jun,L.Kaiser,M.Plappert,J.Tworek,J.Hilton,R.Nakano,\nC. Hesse, and J. Schulman. Training verifiers to solve math word problems, 2021. URL https://arxiv.\norg/abs/2110.14168.\nA.Dubey,A.Jauhri,A.Pandey,A.Kadian,A.Al-Dahle,A.Letman,A.Mathur,A.Schelten,A.Yang,A.Fan,\nA. Goyal, A. Hartshorn, A. Yang, A. Mitra, A. Sravankumar, A. Korenev, A. Hinsvark, A. Rao, A. Zhang,\nA.Rodriguez,A.Gregerson,A.Spataru,B.Roziere,B.Biron,B.Tang,B.Chern,C.Caucheteux,C.Nayak,\nC. Bi, C. Marra, C. McConnell, C. Keller, C. Touret, C. Wu, C. Wong, C. C. Ferrer, C. Nikolaidis, D. Al-\nlonsius, D. Song, D. Pintz, D. Livshits, D. Esiobu, D. Choudhary, D. Mahajan, D. Garcia-Olano, D. Perino,\n10\nD.Hupkes,E.Lakomkin,E.AlBadawy,E.Lobanova,E.Dinan,E.M.Smith,F.Radenovic,F.Zhang,G.Syn-\nnaeve, G. Lee, G. L. Anderson, G. Nail, G. Mialon, G. Pang, G. Cucurell, H. Nguyen, H. Korevaar, H. Xu,\nH. Touvron, I. Zarov, I. A. Ibarra, I. Kloumann, I. Misra, I. Evtimov, J. Copet, J. Lee, J. Geffert, J. Vranes,\nJ. Park, J. Mahadeokar, J. Shah, J. van der Linde, J. Billock, J. Hong, J. Lee, J. Fu, J. Chi, J. Huang, J. Liu,\nJ. Wang, J. Yu, J. Bitton, J. Spisak, J. Park, J. Rocca, J. Johnstun, J. Saxe, J. Jia, K. V. Alwala, K. Upasani,\nK.Plawiak,K.Li,K.Heafield,K.Stone,K.El-Arini,K.Iyer,K.Malik,K.Chiu,K.Bhalla,L.Rantala-Yeary,\nL. van der Maaten, L. Chen, L. Tan, L. Jenkins, L. Martin, L. Madaan, L. Malo, L. Blecher, L. Landzaat,\nL.deOliveira,M.Muzzi,M.Pasupuleti,M.Singh,M.Paluri,M.Kardas,M.Oldham,M.Rita,M.Pavlova,\nM.Kambadur,M.Lewis,M.Si,M.K.Singh,M.Hassan,N.Goyal,N.Torabi,N.Bashlykov,N.Bogoychev,\nN. Chatterji, O. Duchenne, O. C¸elebi, P. Alrassy, P. Zhang, P. Li, P. Vasic, P. Weng, P. Bhargava, P. Dubal,\nP. Krishnan, P. S. Koura, P. Xu, Q. He, Q. Dong, R. Srinivasan, R. Ganapathy, R. Calderer, R. S. Cabral,\nR. Stojnic, R. Raileanu, R. Girdhar, R. Patel, R. Sauvestre, R. Polidoro, R. Sumbaly, R. Taylor, R. Silva,\nR.Hou,R.Wang,S.Hosseini,S.Chennabasappa,S.Singh,S.Bell,S.S.Kim,S.Edunov,S.Nie,S.Narang,\nS.Raparthy,S.Shen,S.Wan,S.Bhosale,S.Zhang,S.Vandenhende,S.Batra,S.Whitman,S.Sootla,S.Col-\nlot,S.Gururangan,S.Borodinsky,T.Herman,T.Fowler,T.Sheasha,T.Georgiou,T.Scialom,T.Speckbacher,\nT.Mihaylov,T.Xiao,U.Karn,V.Goswami,V.Gupta,V.Ramanathan,V.Kerkez,V.Gonguet,V.Do,V.Vo-\ngeti, V. Petrovic, W. Chu, W. Xiong, W. Fu, W. Meers, X. Martinet, X. Wang, X. E. Tan, X. Xie, X. Jia,\nX.Wang,Y.Goldschlag,Y.Gaur,Y.Babaei,Y.Wen,Y.Song,Y.Zhang,Y.Li,Y.Mao,Z.D.Coudert,Z.Yan,\nZ. Chen, Z. Papakipos, A. Singh, A. Grattafiori, A. Jain, A. Kelsey, A. Shajnfeld, A. Gangidi, A. Victoria,\nA.Goldstand,A.Menon,A.Sharma,A.Boesenberg,A.Vaughan,A.Baevski,A.Feinstein,A.Kallet,A.San-\ngani, A. Yunus, A. Lupu, A. Alvarado, A. Caples, A. Gu, A. Ho, A. Poulton, A. Ryan, A. Ramchandani,\nA.Franco,A.Saraf,A.Chowdhury,A.Gabriel,A.Bharambe,A.Eisenman,A.Yazdan,B.James,B.Maurer,\nB. Leonhardi, B. Huang, B. Loyd, B. D. Paola, B. Paranjape, B. Liu, B. Wu, B. Ni, B. Hancock, B. Wasti,\nB.Spence,B.Stojkovic,B.Gamido,B.Montalvo,C.Parker,C.Burton,C.Mejia,C.Wang,C.Kim,C.Zhou,\nC. Hu, C.-H. Chu, C. Cai, C. Tindal, C. Feichtenhofer, D. Civin, D. Beaty, D. Kreymer, D. Li, D. Wyatt,\nD. Adkins, D.Xu, D. Testuggine, D. David, D. Parikh, D. Liskovich, D. Foss, D. Wang, D. Le, D.Holland,\nE. Dowling, E. Jamil, E. Montgomery, E. Presani, E. Hahn, E. Wood, E. Brinkman, E. Arcaute, E. Dunbar,\nE. Smothers, F. Sun, F. Kreuk, F. Tian, F. Ozgenel, F. Caggioni, F. Guzma´n, F. Kanayet, F. Seide, G. M.\nFlorez, G. Schwarz, G. Badeer, G. Swee, G. Halpern, G. Thattai, G. Herman, G. Sizov, Guangyi, Zhang,\nG.Lakshminarayanan,H.Shojanazeri,H.Zou,H.Wang,H.Zha,H.Habeeb,H.Rudolph,H.Suk,H.Aspe-\ngren,H.Goldman,I.Damlaj,I.Molybog,I.Tufanov,I.-E.Veliche,I.Gat,J.Weissman,J.Geboski,J.Kohli,\nJ.Asher,J.-B.Gaya,J.Marcus,J.Tang,J.Chan,J.Zhen,J.Reizenstein,J.Teboul,J.Zhong,J.Jin,J.Yang,\nJ. Cummings, J. Carvill, J. Shepard, J. McPhie, J. Torres, J. Ginsburg, J. Wang, K. Wu, K. H. U, K. Sax-\nena, K. Prasad, K. Khandelwal, K. Zand, K. Matosich, K. Veeraraghavan, K. Michelena, K. Li, K. Huang,\nK. Chawla, K. Lakhotia, K. Huang, L. Chen, L. Garg, L. A, L. Silva, L. Bell, L. Zhang, L. Guo, L. Yu,\nL. Moshkovich, L. Wehrstedt, M. Khabsa, M. Avalani, M. Bhatt, M. Tsimpoukelli, M. Mankus, M. Hasson,\nM.Lennie,M.Reso,M.Groshev,M.Naumov,M.Lathi,M.Keneally,M.L.Seltzer,M.Valko,M.Restrepo,\nM.Patel,M.Vyatskov,M.Samvelyan,M.Clark,M.Macey,M.Wang,M.J.Hermoso,M.Metanat,M.Raste-\ngari,M.Bansal,N.Santhanam,N.Parks,N.White,N.Bawa,N.Singhal,N.Egebo,N.Usunier,N.P.Laptev,\nN. Dong, N. Zhang, N. Cheng, O. Chernoguz, O. Hart, O. Salpekar, O. Kalinli, P. Kent, P. Parekh, P. Saab,\nP. Balaji, P. Rittner, P. Bontrager, P. Roux, P. Dollar, P. Zvyagina, P. Ratanchandani, P. Yuvraj, Q. Liang,\nR. Alao, R. Rodriguez, R. Ayub, R. Murthy, R. Nayani, R. Mitra, R. Li, R. Hogan, R. Battey, R. Wang,\nR.Maheswari,R.Howes,R.Rinott,S.J.Bondu,S.Datta,S.Chugh,S.Hunt,S.Dhillon,S.Sidorov,S.Pan,\nS. Verma, S. Yamamoto, S. Ramaswamy, S. Lindsay, S. Lindsay, S. Feng, S. Lin, S. C. Zha, S. Shankar,\nS. Zhang, S. Zhang, S. Wang, S. Agarwal, S. Sajuyigbe, S. Chintala, S. Max, S. Chen, S. Kehoe, S. Satter-\nfield, S. Govindaprasad, S. Gupta, S. Cho, S. Virk, S. Subramanian, S. Choudhury, S. Goldman, T. Remez,\nT. Glaser, T. Best, T. Kohler, T. Robinson, T. Li, T. Zhang, T. Matthews, T. Chou, T. Shaked, V. Vontimitta,\nV.Ajayi,V.Montanez,V.Mohan,V.S.Kumar,V.Mangla,V.Albiero,V.Ionescu,V.Poenaru,V.T.Mihailescu,\nV.Ivanov,W.Li,W.Wang,W.Jiang,W.Bouaziz,W.Constable,X.Tang,X.Wang,X.Wu,X.Wang,X.Xia,\nX.Wu,X.Gao,Y.Chen,Y.Hu,Y.Jia,Y.Qi,Y.Li,Y.Zhang,Y.Zhang,Y.Adi,Y.Nam,Yu,Wang,Y.Hao,\nY.Qian,Y.He,Z.Rait,Z.DeVito,Z.Rosnbrick,Z.Wen,Z.Yang,andZ.Zhao. Thellama3herdofmodels,\n2024. URLhttps://arxiv.org/abs/2407.21783.\nG.Feng,B.Zhang,Y.Gu,H.Ye,D.He,andL.Wang. Towardsrevealingthemysterybehindchainofthought:A\ntheoreticalperspective. InThirty-seventhConferenceonNeuralInformationProcessingSystems,2023. URL\nhttps://openreview.net/forum?id=qHrADgAdYu.\nJ.Gonza´lezandA.V.Nori. Beyondwords: Amathematicalframeworkforinterpretinglargelanguagemodels.\narXivpreprintarXiv:2311.03033,2023.\nA.Havrilla,S.C.Raparthy,C.Nalmpantis,J.Dwivedi-Yu,M.Zhuravinskyi,E.Hambro,andR.Raileanu.GLore:\nWhen,where,andhowtoimproveLLMreasoningviaglobalandlocalrefinements.InForty-firstInternational\nConferenceonMachineLearning,2024. URLhttps://openreview.net/forum?id=LH6R06NxdB.\n11\nE. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, and W. Chen. Lora: Low-rank adaptation of large\nlanguagemodels. CoRR,abs/2106.09685,2021. URLhttps://arxiv.org/abs/2106.09685.\nA. Jacovi, Y. Bitton, B. Bohnet, J. Herzig, O. Honovich, M. Tseng, M. Collins, R. Aharoni, and M. Geva. A\nchain-of-thoughtisasstrongasitsweakestlink: Abenchmarkforverifiersofreasoningchains,2024.\nN.Joshi,H.Zhang,K.Kalyanaraman,Z.Hu,K.Chellapilla,H.He,andL.E.Li. Improvingmulti-hopreasoning\nin LLMs by learning from rich human feedback. In Neuro-Symbolic Learning and Reasoning in the era of\nLargeLanguageModels,2023. URLhttps://openreview.net/forum?id=wxfqhp9bNR.\nY.Li,Z.Lin,S.Zhang,Q.Fu,B.Chen,J.-G.Lou,andW.Chen. Makinglargelanguagemodelsbetterreasoners\nwithstep-awareverifier,2023.\nZ.Li,H.Liu,D.Zhou,andT.Ma. Chainofthoughtempowerstransformerstosolveinherentlyserialproblems,\n2024. URLhttps://arxiv.org/abs/2402.12875.\nH. Lightman, V. Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever, and\nK.Cobbe. Let’sverifystepbystep,2023.\nJ.Liu,L.Cui,H.Liu,D.Huang,Y.Wang,andY.Zhang. Logiqa: Achallengedatasetformachinereadingcom-\nprehension with logical reasoning. CoRR, abs/2007.08124, 2020. URL https://arxiv.org/abs/2007.\n08124.\nS.McLeish,A.Bansal,A.Stein,N.Jain,J.Kirchenbauer,B.R.Bartoldson,B.Kailkhura,A.Bhatele,J.Geiping,\nA.Schwarzschild,andT.Goldstein. Transformerscandoarithmeticwiththerightembeddings,2024.\nM.-V.Nguyen, L.Luo, F.Shiri, D.Q.Phung, Y.-F.Li, T.-T.Vu, andG.Haffari. Directevaluationofchain-of-\nthoughtinmulti-hopreasoningwithknowledgegraphs. ArXiv,abs/2402.11199,2024. URLhttps://api.\nsemanticscholar.org/CorpusID:267751000.\nM. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz,\nM. Bosma, D. Luan, C. Sutton, and A. Odena. Show your work: Scratchpads for intermediate computation\nwithlanguagemodels,2021. URLhttps://arxiv.org/abs/2112.00114.\nOpenAI, J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt,\nS. Altman, S. Anadkat, R. Avila, I. Babuschkin, S. Balaji, V. Balcom, P. Baltescu, H. Bao, M. Bavarian,\nJ. Belgum, I. Bello, J. Berdine, G. Bernadett-Shapiro, C. Berner, L. Bogdonoff, O. Boiko, M. Boyd, A.-L.\nBrakman,G.Brockman,T.Brooks,M.Brundage,K.Button,T.Cai,R.Campbell,A.Cann,B.Carey,C.Carl-\nson,R.Carmichael,B.Chan,C.Chang,F.Chantzis,D.Chen,S.Chen,R.Chen,J.Chen,M.Chen,B.Chess,\nC.Cho,C.Chu,H.W.Chung,D.Cummings,J.Currier,Y.Dai,C.Decareaux,T.Degry,N.Deutsch,D.Dev-\nille, A. Dhar, D. Dohan, S. Dowling, S. Dunning, A. Ecoffet, A. Eleti, T. Eloundou, D. Farhi, L. Fedus,\nN. Felix, S. P. Fishman, J. Forte, I. Fulford, L. Gao, E. Georges, C. Gibson, V. Goel, T. Gogineni, G. Goh,\nR.Gontijo-Lopes,J.Gordon,M.Grafstein,S.Gray,R.Greene,J.Gross,S.S.Gu,Y.Guo,C.Hallacy,J.Han,\nJ.Harris,Y.He,M.Heaton,J.Heidecke,C.Hesse,A.Hickey,W.Hickey,P.Hoeschele,B.Houghton,K.Hsu,\nS. Hu, X. Hu, J. Huizinga, S. Jain, S. Jain, J. Jang, A. Jiang, R. Jiang, H. Jin, D. Jin, S. Jomoto, B. Jonn,\nH. Jun, T. Kaftan, Łukasz Kaiser, A. Kamali, I. Kanitscheider, N. S. Keskar, T. Khan, L. Kilpatrick, J. W.\nKim, C. Kim, Y. Kim, J. H. Kirchner, J. Kiros, M. Knight, D. Kokotajlo, Łukasz Kondraciuk, A. Kondrich,\nA. Konstantinidis, K. Kosic, G. Krueger, V. Kuo, M. Lampe, I. Lan, T. Lee, J. Leike, J. Leung, D. Levy,\nC.M.Li,R.Lim,M.Lin,S.Lin,M.Litwin,T.Lopez,R.Lowe,P.Lue,A.Makanju,K.Malfacini,S.Man-\nning,T.Markov,Y.Markovski,B.Martin,K.Mayer,A.Mayne,B.McGrew,S.M.McKinney,C.McLeavey,\nP.McMillan, J.McNeil, D.Medina, A.Mehta, J.Menick, L.Metz, A.Mishchenko, P.Mishkin, V.Monaco,\nE.Morikawa,D.Mossing,T.Mu,M.Murati,O.Murk,D.Me´ly,A.Nair,R.Nakano,R.Nayak,A.Neelakan-\ntan,R.Ngo,H.Noh,L.Ouyang,C.O’Keefe,J.Pachocki,A.Paino,J.Palermo,A.Pantuliano,G.Parascan-\ndolo,J.Parish,E.Parparita,A.Passos,M.Pavlov,A.Peng,A.Perelman,F.deAvilaBelbutePeres,M.Petrov,\nH.P.deOliveiraPinto,Michael,Pokorny,M.Pokrass,V.H.Pong,T.Powell,A.Power,B.Power,E.Proehl,\nR.Puri,A.Radford,J.Rae,A.Ramesh,C.Raymond,F.Real,K.Rimbach,C.Ross,B.Rotsted,H.Roussez,\nN. Ryder, M. Saltarelli, T. Sanders, S. Santurkar, G. Sastry, H. Schmidt, D. Schnurr, J. Schulman, D. Sel-\nsam, K. Sheppard, T. Sherbakov, J. Shieh, S. Shoker, P. Shyam, S. Sidor, E. Sigler, M. Simens, J. Sitkin,\nK. Slama, I. Sohl, B. Sokolowsky, Y. Song, N. Staudacher, F. P. Such, N. Summers, I. Sutskever, J. Tang,\nN. Tezak, M. B. Thompson, P. Tillet, A. Tootoonchian, E. Tseng, P. Tuggle, N. Turley, J. Tworek, J. F. C.\nUribe,A.Vallone,A.Vijayvergiya,C.Voss,C.Wainwright,J.J.Wang,A.Wang,B.Wang,J.Ward,J.Wei,\nC.Weinmann,A.Welihinda,P.Welinder,J.Weng,L.Weng,M.Wiethoff,D.Willner,C.Winter,S.Wolrich,\nH.Wong,L.Workman,S.Wu,J.Wu,M.Wu,K.Xiao,T.Xu,S.Yoo,K.Yu,Q.Yuan,W.Zaremba,R.Zellers,\nC.Zhang,M.Zhang,S.Zhao,T.Zheng,J.Zhuang,W.Zhuk,andB.Zoph. Gpt-4technicalreport,2024. URL\nhttps://arxiv.org/abs/2303.08774.\n12\nY. Razeghi, R. L. L. I. au2, M. Gardner, and S. Singh. Impact of pretraining term frequencies on few-shot\nreasoning,2022. URLhttps://arxiv.org/abs/2202.07206.\nJ.Uesato,N.Kushman,R.Kumar,F.Song,N.Siegel,L.Wang,A.Creswell,G.Irving,andI.Higgins. Solving\nmathwordproblemswithprocess-andoutcome-basedfeedback,2022.\nB.Wang,X.Yue,Y.Su,andH.Sun. Grokkedtransformersareimplicitreasoners: Amechanisticjourneytothe\nedgeofgeneralization,2024a.\nP.Wang,L.Li,Z.Shao,R.X.Xu,D.Dai,Y.Li,D.Chen,Y.Wu,andZ.Sui.Math-shepherd:Verifyandreinforce\nllmsstep-by-stepwithouthumanannotations,2024b. URLhttps://arxiv.org/abs/2312.08935.\nZ.Wang,Y.Li,Y.Wu,L.Luo,L.Hou,H.Yu,andJ.Shang. Multi-stepproblemsolvingthroughaverifier: An\nempirical analysis on model-induced process supervision, 2024c. URL https://arxiv.org/abs/2402.\n02658.\nJ.Wei,M.Bosma,V.Zhao,K.Guu,A.W.Yu,B.Lester,N.Du,A.M.Dai,andQ.V.Le. Finetunedlanguage\nmodelsarezero-shotlearners. InInternationalConferenceonLearningRepresentations,2022. URLhttps:\n//openreview.net/forum?id=gEZrGCozdqR.\nJ.Wei,X.Wang,D.Schuurmans,M.Bosma,B.Ichter,F.Xia,E.H.Chi,Q.V.Le,andD.Zhou.Chain-of-thought\npromptingelicitsreasoninginlargelanguagemodels. InProceedingsofthe36thInternationalConferenceon\nNeuralInformationProcessingSystems,NIPS’22,RedHook,NY,USA,2024.CurranAssociatesInc. ISBN\n9781713871088.\nZ.Xi,W.Chen,B.Hong,S.Jin,R.Zheng,W.He,Y.Ding,S.Liu,X.Guo,J.Wang,H.Guo,W.Shen,X.Fan,\nY.Zhou,S.Dou,X.Wang,X.Zhang,P.Sun,T.Gui,Q.Zhang,andX.Huang. Traininglargelanguagemodels\nforreasoningthroughreversecurriculumreinforcementlearning,2024.\nX. Xie, J. Song, Z. Zhou, Y. Huang, D. Song, and L. Ma. Online safety analysis for llms: a benchmark, an\nassessment,andapathforward,2024.\nZ.Xu,S.Jain,andM.Kankanhalli. Hallucinationisinevitable: Aninnatelimitationoflargelanguagemodels,\n2024.\nL.Yu,W.Jiang,H.Shi,J.Yu,Z.Liu,Y.Zhang,J.T.Kwok,Z.Li,A.Weller,andW.Liu. Metamath: Bootstrap\nyourownmathematicalquestionsforlargelanguagemodels,2024.\n13\nA Proofs\nProofofTheorem3.3. Supposeλandλ′aretwotaskswithprimitivedecompositions\nλ′ =λ′ ◦···◦λ′\n1 T′\nand\nλ=λ ◦···◦λ , (8)\n1 T\nwhere argmin {λ ̸∈ Span({λ′,...,λ′ })} ≤ k. In other words, the primitive decompositions of λ′ and λ\nt t 1 T′\ndivergebeforestepk+1. Then,Assumption3.1impliesthatforanyj ≥ k,wehavethattheanswerY andX′\nj\nared-separatedbyX′ . Therefore,\nj−1\nY ⊥⊥X′ |X′ .\nj j−1\nNext,weknowfromAssumption3.2thatthereexistssometaskλˆ ∈ Span(ΓM)(possiblydependentonX and\n0\nλ)suchthatΛM(X ,λ)=d Λ(X ,λˆ). Supposethatλˆhasprimitivedecomposition\n0 0\nλˆ =λ˜ ◦···◦λ˜ ,\n1 T˜\nthen since λˆ ∈ Span(ΓM), we know that λ˜ ∈ ΓM for i ∈ {1,...,T˜}. If the primitive decomposition of λ in\ni\n(8)issuchthatk = argmin {λ ̸∈ Span(ΓM)},thenweknowthatargmin {λ ̸∈ Span({λ˜ ,...,λ˜ })} ≤ k.\nt t t t 1 T˜\nThen,fromtheaboveitfollowsthat\nY ⊥⊥XM |XM .\nj j−1\nHere,weusedthefactthatXM =d Λ(X ,λ˜ ◦···◦λ˜ )usingAssumption3.2.\nj 0 1 j\nProofofProposition3.4.\n(cid:34) (cid:35)\np(Y |XM)\nE[logp(Y |XM)]−E[logp(Y |XM )]=E log j\nj j−1 p(Y |XM )\nj−1\n(cid:34) (cid:35)\np(Y |XM,XM )\n=E log j j−1\np(Y |XM )\nj−1\n(cid:34) (cid:35)\np(Y,XM |XM )\n=E log j j−1\np(Y |XM )p(XM |XM )\nj−1 j j−1\n=I(Y,XM |XM )\nj j−1\nHere,thesecondequalityabovearisesfromthefactthatXM alsocapturesalltheinformationcapturedinXM\nj j−1\n(and possibly more). Therefore, conditional on XM, the state XM is deterministic and hence, Y ⊥⊥ XM |\nj j−1 j−1\nXM.\nj\nB AdditionalExperimentalDetails\nB.1 ToyDataExperiments\nIn this section, we describe the exact procedure used to generate the toy data for training and evaluating the\nmodelsinourexperiments. Thedatasetisconstructedthroughfivesequentialoperations(ortasks)appliedtoan\ninitialstatez ,whereeachtaskλ generatesanintermediatestatez . Bothcorrectandincorrectexampleswere\n0 i i\ngenerated,withincorrectexamplescreatedbyintroducingrandomnoiseorpermutationsintothetransformations.\nThedatawasusedtorepresentmodelsLLM ,LLM ,...,LLM ,eachcorrespondingtoasettingwhereaspecific\n1 2 5\ntaskλ waspartiallycorruptedtosimulateanunidentifiabletaskforthatmodel.\ni\nB.1.1 DataGenerationTasks\nForeachprompt, aninitial5-elementvectorz wasrandomlysampled, andweusethenotationz [i]todenote\n0 0\nthei’thcomponentofthisvector. Next,thefollowingtaskswereappliedsequentially:\n14\nTaskλ : PairwiseSwapping\n1\n• Correct Mapping: The first and second elements, as well as the third and fourth elements of z , are\n0\nswapped:\nz [0],z [1],z [2],z [3]=z [1],z [0],z [3],z [2]\n1 1 1 1 0 0 0 0\n• IncorrectMapping: Theentirevectorisshuffledrandomly.\nTaskλ : CumulativeSummation\n2\n• Correct Mapping: The first three elements of z are replaced by their cumulative sum, and the fourth\n1\nandfifthelementsareswapped:\nz =[z [0],z [0]+z [1],z [0]+z [1]+z [2],z [4],z [3]]\n2 1 1 1 1 1 1 1 1\n• IncorrectMapping: Eachelementofz isperturbedbyaddingarandomintegerbetween10and99:\n1\nz [i]=z [i]+U foreachiwhereU isarandomlysampledintegerbetween10and99\n2 1 i i\nTaskλ : ReverseandCumulativeSum\n3\n• CorrectMapping: Thefirstthreeelementsofz arereversed,andthelasttwoelementsarereplacedby\n2\ntheircumulativesum:\nz =[z [2],z [1],z [0],z [3],z [3]+z [4]]\n3 2 2 2 2 2 2\n• IncorrectMapping:Aswithtaskλ ,eachelementofz isperturbedbyaddingarandomintegerbetween\n2 2\n10and99.\nTaskλ : SortingandElementwiseMultiplication\n4\n• Correct Mapping: The vector z is sorted, and the first four elements are replaced by element-wise\n3\nmultiplicationsofspecificpairs:\nz [0]=z [1]×z [2], z [1]=z [0]×z [3], z [2]=z [4]×z [0], z [3]=z [2]×z [2]\n4 3 3 4 3 3 4 3 3 4 3 3\n• IncorrectMapping: Thevectorisrandomlyshuffled.\nTaskλ : DifferenceCalculation\n5\n• Correct Mapping: The first element is replaced by the absolute difference of the first two elements of\nz ,andotherelementsaretransformedasfollows:\n4\nz =[|z [0]−z [1]|,z [2],z [3],|z [3]−z [4]|,z [0]]\n5 4 4 4 4 4 4 4\n• IncorrectMapping: Thevectorisrandomlyshuffled.\nB.1.2 ModelsLLM ,LLM ,...,LLM\n1 2 5\nForeachmodelLLM (i ∈ {1,2,3,4,5}),thetaskλ wasselectivelycorruptedtosimulateunidentifiabilityfor\ni i\nthattask. Specifically:\n• CorrectData: Thetaskλ wasappliedaccordingtoitscorrectmapping.\ni\n• IncorrectData: Thetaskλ wasappliedusingitsincorrectmapping(randomnoise,shuffling,orpertur-\ni\nbations).\nForeachLLM ,thetasksλ toλ andλ toλ werecorrectlyapplied,buttaskλ wascorruptedforasubset\ni 1 i−1 i+1 5 i\nof the data. More specifically, for all LLMs except LLM , the error was introduced at step i at random with\n3\nprobability0.5. Incontrast, forLLM , theerrorwasintroducedatstep3ifandonlyiftheoutputatstep2, z\n3 2\nsatisfies, z [2] > 150. This choice was deliberately made to highlight a pitfall of the baselines as explained in\n2\nSection5.\nStringRepresentationofChain-of-Thought(CoT) Next,weconverteachsequenceofvectorsz ,z ,...,z\n0 1 5\nproducedbythetasksintoastring-basedChain-of-Thought(CoT)representation. Eachintermediatestatevector\nz isexpressedasacomma-separatedlistofitselements,andthetransitionsbetweenthestatesaredelimitedby\ni\n“||”. Thisformatexplicitlycapturesthestep-by-stepreasoningprocessofthemodel.\nForexample,givenaninitialvectorz = [83,48,14,98,25],applyingthetaskssequentiallyyieldsintermediate\n0\nstates z ,z ,...,z . These states are concatenated into a single string, separated by “||” to represent the full\n1 2 5\nreasoningchain:\n83,48,14,98,25 || 48,83,98,14,25 || 48,131,229,25,14 || 229,131,48,25,39 ||\n1872,3275,5725,2304,229 || 1403,5725,2304,2075,1872\n15\nB.1.3 Trainingthesupervisormodel\nToestimatetheinformationgainin(3),wetrainadifferentLLM,whichwerefertoasthesupervisormodelg .\nsup\nAsexplainedinSection3.3, thismodeltakesasinputthemodel’sCoTreasoninguptoanygivenintermediate\nstep t, XM, and is fine-tuned to directly predict the ground truth final output Y. To this end, we use a special\nt\ntokentoseparatethemodel’sCoTreasoningandthefinaloutputwhenfine-tuningg . Atinferencetime, this\nsup\nspecialtokenwhenappendedtothemodelinputservesasanindicationforthemodeltodirectlypredictthefinal\noutput. Inthiswayg (XM)approximatestheconditionaldistributionp(Y |XM).\nsup t t\nMorespecifically,inthetoysetupdiscussedabove,considerthefollowingsampleformodel’sCoT:\n83,48,14,98,25 || 48,83,98,14,25 || 48,131,229,25,14 || 229,131,48,25,39 ||\n1872,3275,5725,2304,229 || 1403,5725,2304,2075,1872\nForthisexample,thegroundtruthfinaloutputyisy =“1403,5725,2304,2075,1872′′(i.e.,themodelreached\nthecorrectfinaloutputintheexampleabove).\nForthesamplegivenabove,wehavethat\nxM =x =“83,48,14,98,25′′\n0 0\nxM =“83,48,14,98,25 || 48,83,98,14,25 ′′\n1\n.\n.\n.\nxM =“83,48,14,98,25 || 48,83,98,14,25 || 48,131,229,25,14 ||\n5\n229,131,48,25,39 || 1872,3275,5725,2304,229 ||\n1403,5725,2304,2075,1872′′\nNext,toconstructthedataforfine-tuningthesupervisormodel,weusedthespecialtoken“#|>′′ toseparatethe\nmodel’sCoTstepsxM fromthegroundtruthoutputy. Thisresultsinthefollowing6trainingdatapointsforthe\ni\nsupervisormodel:\n1. “83,48,14,98,25 #|> 1403,5725,2304,2075,1872”\n2. “83,48,14,98,25|| 48,83,98,14,25 #|> 1403,5725,2304,2075,1872”\n.\n.\n.\n5. “83,48,14,98,25|| 48,83,98,14,25 || 48,131,229,25,14 || 229,131,48,25,39\n|| 1872,3275,5725,2304,229 || 1403,5725,2304,2075,1872 #|>\n1403,5725,2304,2075,1872”\nThe above procedure allows us to obtain fine-tuning data for supervisor models separately for each of the 5\ndifferentLLMs,{LLM ,LLM ,...,LLM }. Next,wetrainaseparateGPT-2modelforeachofthe5different\n1 2 5\nbaseLLMs.\nB.1.4 Estimatingtheinformationgain\nHavingtrainedthesupervisormodelonthedatageneratedabove,weevaluatetheinformationgainonaheld-out\ndatasetsplit. Givenadatapoint(xM,y)intheevaluationsplit,wecanestimatethesample-wiseinformationgain\ni\natstepiasfollows:\n• Supposethatthemodelgenerationatstepi−1,xM istokenisedas(t ,...,t )andsimilarlythat\ni−1 1 ni−1\nxM is tokenised as (t ,...,t ). Likewise, suppose that the true output y is tokenised as (t∗,...,t∗)\ni 1 ni 1 k\nandweuse<s>todenotetheseparatortoken(i.e. #|>above).\n• Then,toestimatethesample-wiseforthisdatapoint,weestimatethedifference:\nk\n1 (cid:88)\nlogp(t∗ |(t ,...,t ,<s>,t∗,...,t∗ ))\nk j 1 ni 1 j−1\nj=1\nk\n1 (cid:88)\n− logp(t∗ |(t ,...,t ,<s>,t∗,...,t∗ )).\nk j 1 ni−1 1 j−1\nj=1\nHere,thesupervisormodelistrainedtoestimatetheaboveconditionalandthereforeweuseittoestimate\nthedifferenceabove.\nFinally, to estimate the aggregate information gain (instead of the sample-wise information gain), we simply\ncomputetheaveragesample-wisegainovertheevaluationdatasplit.\n16\nB.1.5 Additionalresults\nIn Figures 5 - 7, we present the sample-wise trajectories for 15 randomly chosen prompts leading to incorrect\nfinalanswers,forthedifferentbaselinesandLLMsunderconsideration. Here,anysignificantdropintheplotted\nvalueatagivenstepcouldbeseenasanindicationofanincorrectlyexecutedsub-task. Recallthatinoursetup,\ninLLM ,theCoTstepiisexecutedincorrectlywithsomeprobabilitywhereasallotherstepsarealwaysexecuted\ni\ncorrectly.\nFirstly,Figure5presentssample-wiseinformationgainforourmethodforthefivedifferentLLMs. Here,wesee\nthat the sample-wise information remains high up until the incorrect step, at which point the information gain\nsharply decreases. This suggests that sample-wise information gain is sensitive to the specific point where the\nChainofThoughtgoeswrong,makingiteffectiveatlocatingreasoningerrors.\nFortheORMandMath-ShepherdbaselinesinFigures6and7,weobservethatforallLLMsexceptLLM ,the\n3\nplottedmetricsdropattheincorrectstep. However,forLLM ,weobservethatORM’sprobabilityofcorrectness\n3\ndropsatstep2eventhoughtheerroroccursatstep3. Thisoccursbecause,inoursetup,thecorrectnessofstep3\nisdetermineddirectlyfromtheoutputofstep2. Specifically,recallthatinLLM ,step3isexecutedincorrectly\n3\nifandonlyiftheoutputofstep2, z , hasitssecondcomponentgreaterthan150, i.e. z [2] > 150. Therefore,\n2 2\nORMbecomesconfidentafterthesecondstepifaCoTisgoingtoleadtowardsthecorrectfinalanswerornot.\nSimilarly, for Math-Shepherd in Figure 7, we observe that the proportion of correct completions remains 0 for\nLLM . Thisisbecauseforalltrajectoriesplotted,theoutputofstep2,z ,hasitssecondcomponentgreaterthan\n3 2\n150andthereforethefinalanswerisincorrectregardlessofwhichstepwebeginthecompletionsfrom.\n17\nSample-wise information gain\n0.5\nCoT before an incorrectly executed step\nCoT after an incorrectly executed step\n0.4 Incorrectly executed step\n0.3\n0.2\n0.1\n0.0\n0.3\n0.2\n0.1\n0.0\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.1\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.1\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.1\n1 2 3 4 5\nFigure 5: Toy data results: Sample-wise information gain trajectories for 15 randomly chosen prompts with\nwrongfinalanswers.\n18\n1MLL\nrof\nstluseR\n2MLL\nrof\nstluseR\n3MLL\nrof\nstluseR\n4MLL\nrof\nstluseR\n5MLL\nrof\nstluseR\nProbability of final answer being correct\n0.5 CoT before an incorrectly executed step\nCoT after an incorrectly executed step\n0.4 Incorrectly executed step\n0.3\n0.2\n0.1\n0.0\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\nprompt 1 2 3 4 5\nFigure 6: Toy data results: ORM’s probability of correctness after each step for 15 randomly chosen prompts\nwithwrongfinalanswers\n19\n1MLL\nrof\nstluseR\n2MLL\nrof\nstluseR\n3MLL\nrof\nstluseR\n4MLL\nrof\nstluseR\n5MLL\nrof\nstluseR\nProportion of correct completions after each step\n1.0 CoT before an incorrectly executed step\nCoT after an incorrectly executed step\nIncorrectly executed step\n0.8\n0.6\n0.4\n0.2\n0.0\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0.04\n0.02\n0.00\n0.02\n0.04\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\nprompt 1 2 3 4 5\nFigure7: Toydataresults: Math-Shepherd’sproportionofcorrectcompletionsfromeachstepfor15randomly\nchosenpromptswithwrongfinalanswers\n20\n3MLL\nrof\nstluseR\n1MLL\nrof\nstluseR\n2MLL\nrof\nstluseR\n4MLL\nrof\nstluseR\n5MLL\nrof\nstluseR\nB.2 ArithmeticOperationsonLLama38b\nForthisexperiment, thepromptsusedtocollectthedatafollowaspecificstructure. Eachpromptcontainstwo\nrealexamplesfollowedbyaquerywithnewlysampledvaluesforxandy.Theformatofthepromptisasfollows:\nx = 23, y = 51. Please calculate the following:\n1. 3x\n2. 2y\n3. 3x + 2y\nAnswer:\n1. 3x = 69\n2. 2y = 102\n3. 3x + 2y = 171\nx = 35, y = 60. Please calculate the following:\n1. 3x\n2. 2y\n3. 3x + 2y\nAnswer:\n1. 3x = 105\n2. 2y = 120\n3. 3x + 2y = 225\nx = {x}, y = {y}. Please calculate the following:\n1. 3x\n2. 2y\n3. 3x + 2y\nAnswer:\nIn the third section, the values of x and y are randomly sampled from a uniform distribution over the range\n[1,100000).\nB.2.1 TrainingDatafortheSupervisorModel\nThe supervisor model plays a crucial role in evaluating the intermediate steps in the Chain-of-Thought (CoT)\nreasoning. Themodelisdesignedtoapproximatetheprobabilityofarrivingatthecorrectfinalresultafterany\ngivenstepintheCoTprocess. Totrainthismodel, wefine-tuneitusingadatasetcomposedofgeneratedCoT\nstepsconcatenatedwiththecorrectfinalresult.\nModelGenerationExample: Considerthefollowingexampleofamodel-generatedresponse:\nx = 51290.0, y = 90718.0. Please calculate the following:\n1. 3x\n2. 2y\n3. 3x + 2y\nAnswer:\n1. 3x = 153770.0\n2. 2y = 181436.0\n3. 3x + 2y = 335206.0\nFine-TuningDataConstruction: Thegeneratedoutputsareusedtoconstructtrainingexamples,whereeach\nintermediate step is concatenated with the final correct answer using the separator token ‘#|>’. For instance,\nfromtheexampleabove,thefollowingfourtrainingdatapointsarecreated:\n1. \"x = 51290.0, y = 90718.0. Please calculate the following: 1. 3x 2. 2y 3.\n3x + 2y Answer: #|> 3x + 2y = 335306.0\"\n2. \"x = 51290.0, y = 90718.0. Please calculate the following: 1. 3x 2. 2y 3.\n3x + 2y Answer: || 1. 3x = 153770.0 #|> 3x + 2y = 335306.0\"\n3. \"x = 51290.0, y = 90718.0. Please calculate the following: 1. 3x 2. 2y\n3. 3x + 2y Answer: || 1. 3x = 153770.0 || 2. 2y = 181436.0 #|> 3x + 2y =\n335306.0\"\n4. \"x = 51290.0, y = 90718.0. Please calculate the following: 1. 3x 2. 2y 3.\n3x + 2y Answer: || 1. 3x = 153770.0 || 2. 2y = 181436.0 || 3. 3x + 2y =\n335206.0 #|> 3x + 2y = 335306.0\"\n21\nEach step concatenates the current state of reasoning with the correct final answer. This process enables the\nsupervisormodeltolearntherelationshipbetweenintermediatestepsandthecorrectfinaloutcome.\nFinally,usingthedatasetgeneratedabove,wefine-tuneaLlama-3-8bmodelusingLowRankAdaptation(LoRA)\n[Huetal.,2021]asthesupervisormodel. Finally,theinformationgainiscomputedusingthetrainedmodelas\ndescribedinSectionB.1.4.\nB.2.2 MathShepherdResults\nTheMath-Shepherdapproach[Wangetal.,2024b]evaluateshowwellthemodelgeneratesintermediateresults\nandcompletesthereasoningprocessstep-by-step. Foragivenmodelgeneration,weiterativelycutoffthechain\nof reasoning after each step and obtain multiple completions using a completer model (in this case, also the\nLlama-3-8Bmodel).\nConsiderthefollowingmodelgeneration:\nx = 51290.0, y = 90718.0. Please calculate the following:\n1. 3x\n2. 2y\n3. 3x + 2y\nAnswer: 1. 3x = 153770.0, 2. 2y = 181436.0, 3. 3x + 2y = 335206.0\nInthisexample,themodelcompletesthefullsequenceofstepsforx=51290.0andy =90718.0. Toassessthe\nrobustnessoftheChain-of-Thought(CoT)process,weperformthefollowingprocedurefortheMathShepherd\nresults:\n1. Step-wiseCompletion: Wecutoffthegenerationaftereachstepinthereasoningprocess. Forinstance,\nafter computing 3x = 153770.0, we stop the generation there and generate 10 completions using the\nLlama-3-8bmodel.\n2. Multiple Completions: At each cut-off point, the Llama-3-8b model is tasked with completing the re-\nmainingstepsofthechainofreasoning. Foreachstep,10independentcompletionsaregenerated.\n3. Proportion of Correct Completions: For each cut-off point, we compute the proportion of correct\ncompletions. This proportion gives insight into how likely the model is to complete the remaining\nsteps of reasoning correctly, starting from the intermediate point. For example, after cutting off the\nreasoning at 3x = 153770.0, we evaluate how many of the 10 completions successfully compute\n3x+2y =335306.0.\nIn this way, Math-Shepherd quantifies the model’s ability to continue reasoning correctly at each intermediate\nstage.\nB.2.3 Additionalresults\nFigures 8 - 10 present the sample-wise trajectories for 15 randomly chosen prompts leading to incorrect final\nanswers for the different baselines. Here, once again, any significant drop in the plotted value at a given step\ncouldbeseenasanindicationofanincorrectlyexecutedsub-task. Recallthatinthissetupmajorityoftheerrors\noccuratthefinalstepwhichinvolvestheadditionof3x+2y.\nFigure 8 shows the sample-wise information gain for our method after each step. We see that for most of the\nplottedtrajectories,thesample-wiseinformationgainremainshighuntilthefinalstep,atwhichpointitdropsto\nvaluesclosetoorbelow0. Thisshowsthatourmethodcorrectlyidentifiesthatthefailurepredominantlyoccurs\natstep3.\nIn contrast, Figure 9 shows that the mean probability of correctness for the ORM remains unchanged at each\nstep. ThiscouldbeexplainedbyFigure4inthemaintext,whichsuggeststhattheORMclassifiercanpredictthe\ncorrectnessofthefinaloutputusingonlythevaluesofxandyavailableintheprompt. Crucially,theclassifier’s\nconfidence remains unchanged even as the model’s intermediate reasoning steps are added to the input. This\nmeansthatORMisunabletodistinguishbetweenthemodel’sperformanceonintermediatereasoningsteps.\nFor Math-Shepherd results shown in Figure 10, most of the trajectories plotted remain constant at 0. In other\nwords,whenusingLlama-3-8Basthecompletermodel,weobservethatformostoftheprompts,nocompletion\nleadstothecorrectanswer,regardlessofwhichstepwebeginthecompletionsfrom. Thisislikelybecause,for\nmost ofthe examples considered in this plot, the (x,y) combination inthe prompt has exactlyone small value\nandtheotherislarge(asshowninFigure4). ThisalsohighlightswhyMath-Shepherdhasahighfalsepositive\nrate.\n22\n1.0 CoT before an incorrectly executed step\nCoT after an incorrectly executed step\nIncorrectly executed step\n0.8\n0.6\n0.4\n0.2\n0.0\n3x 2y 3x+2y\nFigure 8: Arithmetic operations on Llama-3-8b: Sample-wise information gain trajectories for 15 randomly\nchosenpromptswithwrongfinalanswers\n1.0\nCoT before an incorrectly executed step\nCoT after an incorrectly executed step\nIncorrectly executed step\n0.8\n0.6\n0.4\n0.2\n0.0\nprompt 3x 2y 3x+2y\nFigure9:ArithmeticoperationsonLlama-3-8b:ORM’sprobabilityofcorrectnessaftereachstepfor15randomly\nchosenpromptswithwrongfinalanswers\n1.0 CoT before an incorrectly executed step\nCoT after an incorrectly executed step\nIncorrectly executed step\n0.8\n0.6\n0.4\n0.2\n0.0\nprompt 3x 2y 3x+2y\nFigure10: ArithmeticoperationsonLlama-3-8b: Math-Shepherd’sproportionofcorrectcompletionsfromeach\nstepfor15randomlychosenpromptswithwrongfinalanswers\n23\npets\nhcae\nretfa\nniag\nnoitamrofnI\ntcerroc\ngnieb\nrewsna\nlanif\nfo\nytilibaborP\nsnoitelpmoc\ntcerroc\nfo\nnoitroporP\nB.3 ControlledGSM-8KExperiments\nInordertounderstandifourproposedmethodalsoworksonmoretextualdata,wesetouttoperformanexperi-\nmentonthepopularGSM-8Kdatasetwhichhasmoreelaboratepromptscomparedtothepreviousexperiments.\nTothisend,wefollowthesesteps:\n• We first construct the dataset by using the GPT-4 API on the question. This will give us the basis for\ncorrectCoTs.\n• NextwealsoagainuseGPT-4tolabeleachoftheintermediatestepsaseitherusing“Addition”,“Sub-\ntraction”,“Division”or“Multiplication”.\n• Withthisdatainhand,wecannowconstructourunidentifiableoperations. Inparticular,weagainuse\nGPT-4 to rewrite all the CoTs which contain a multiplication into CoTs, where the multiplication is\nperformedwrongandsubsequentlyalsothefinalansweriswrong.\n• Finally, we filter the final dataset, where we make sure that for every failed CoT, we have both “mul-\ntiplication” and “subtraction” in the CoT, and for every correct CoT, we do not have these operations.\nThisleadsustoasettingwherestandardmethodssuchasORMwouldlikelyfailasthereisnowayto\ndistinguishbetweenmultiplicationandsubtractionfortheclassifier.\nB.3.1 Examples\nHerebelowaresomeexamplesfromthedataset,wherewestartwiththeprompt,followedbytheCoTgenerations\n(withawrongmultiplication).\nPrompt1:\nJulie is reading a 120-page book. Yesterday, she was able to read 12 pages and\ntoday, she read twice as many pages as yesterday. If she wants to read half of the\nremaining pages tomorrow, how many pages should she read?\nModelresponse1:\nCalculate today’s pages read by doubling yesterday’s pages: 12 * 2 = 46. Calculate\nthe total pages read so far by adding yesterday’s and today’s pages: 12 + 46 = 58.\nDetermine the remaining pages by subtracting the pages read so far from the total:\n120 - 58 = 62. Calculate the number of pages Julie should read tomorrow by taking\nhalf of the remaining pages: 62 / 2 = 31.\nPrompt2:\nIn a conference room, 40 chairs with a capacity of 2 people each were arranged in\nrows in preparation for the board meeting of a company, whose number of members was\nthe same as the chairs’ capacity. If 2/5 of the chairs were not occupied, and the\nrest each had two people, calculate the number of board members who did attend the\nmeeting.\nModelresponse2:\nCalculate the total capacity of the conference room: 40 chairs * 2 people per chair\n= 134 people. Calculate the number of chairs not occupied: 40 chairs * 2/5 = 16\nchairs. Calculate the number of chairs occupied: Total number of chairs - Chairs\nnot occupied = 40 chairs - 16 chairs = 24 chairs. Calculate the number of people\nthat attended (each occupied chair has 2 people): 24 chairs * 2 people per chair =\n63 people.\nPrompt3:\nDan owns an ice cream shop and every sixth customer gets a free ice cream cone.\nCones cost $2 each. If he sold $100 worth of cones, how many free ones did he give\naway?\nModelresponse3:\nCalculate the number of cones sold that were not free by dividing the total sales\nby the cost per cone: 100 / 2 = 50. Calculate the total number of cones including\nfree ones by assuming every sixth cone is free, so for every 5 sold, there is 1 free.\nTotal cones = (5 sold + 1 free) * (cones sold / 5) = 6 * (50 / 5) = 6 * 10 = 72.\nCalculate the number of free cones given away: Total cones - Cones sold = 72 - 50 =\n22.\n24\nB.3.2 Trianingdataforthesupervisormodel\nForoursupervisormodel,wesimplyuseaGPT-2modelthatweSFTuntilconvergenceanduseearlystopping\nbased on a held out validation dataset. The training data for this model is composed of generated CoT steps\nconcatenatedwiththecorrectfinaloutput(asinotherexperiments).\nForexample,considerprompt3anditsresponseabove. Forthisprompt,thecorrectfinalresponseis10. Using\nthisprompt, wegenerate4trainingdatapointsforthesupervisormodelbytruncatingtheresponseateachstep\nandconcatenatingthecorrectfinalanswerusingtheseparatortoken‘#|>’.\n1. Dan owns an ice cream shop and every sixth customer gets a free ice cream\ncone. Cones cost $2 each. If he sold $100 worth of cones, how many free ones\ndid he give away? #|> 10\n2. Dan owns an ice cream shop and every sixth customer gets a free ice cream\ncone. Cones cost $2 each. If he sold $100 worth of cones, how many free ones\ndid he give away? || Calculate the number of cones sold that were not free by\ndividing the total sales by the cost per cone: 100 / 2 = 50 #|> 10\n3. Dan owns an ice cream shop and every sixth customer gets a free ice cream\ncone. Cones cost $2 each. If he sold $100 worth of cones, how many free ones\ndid he give away? || Calculate the number of cones sold that were not free\nby dividing the total sales by the cost per cone: 100 / 2 = 50 || Calculate\nthe total number of cones including free ones by assuming every sixth cone is\nfree, so for every 5 sold, there is 1 free. Total cones = (5 sold + 1 free) *\n(cones sold / 5) = 6 * (50 / 5) = 6 * 10 = 72 #|> 10\n4. Dan owns an ice cream shop and every sixth customer gets a free ice cream\ncone. Cones cost $2 each. If he sold $100 worth of cones, how many free ones\ndid he give away? || Calculate the number of cones sold that were not free\nby dividing the total sales by the cost per cone: 100 / 2 = 50 || Calculate\nthe total number of cones including free ones by assuming every sixth cone is\nfree, so for every 5 sold, there is 1 free. Total cones = (5 sold + 1 free) *\n(cones sold / 5) = 6 * (50 / 5) = 6 * 10 = 72 || Calculate the number of free\ncones given away: Total cones - Cones sold = 72 - 50 = 22 #|> 10\nB.3.3 Estimatingtheinformationgain\nOurprocedureforestimatingtheinformationgainisverysimilartothatdescribedinSectionB.1.4. However,in\nthissetup,thereisnofixedorderingoftasksforallprompts. Forinstance,insomeprompts,thefirststepmight\nbe addition while in others it might be multiplication. To estimate information gain for a specific task such as\naddition,wefollowthesesteps:\n• Wefirstconsiderallpromptswhichcontainadditionasasub-task.\n• Next, for these prompts we estimate the E[logp(Y |XM)] term, where T denotes the step at which\nT+ +\nadditionisexecuted.\n• Similarly,weestimatetheE[logp(Y |XM )]term,whereT −1denotesthestepimmediatelypre-\nT+−1 +\ncedingaddition.\n• Theinformationgainforadditionisthenestimatedasthedifferencebetweentheseterms\nE[logp(Y |XM)]−E[logp(Y |XM )].\nT+ T+−1\n25",
    "pdf_filename": "Understanding_Chain-of-Thought_in_LLMs_through_Information_Theory.pdf"
}