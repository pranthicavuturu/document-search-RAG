{
    "title": "Multi-Task Learning on Networks",
    "context": "",
    "body": "Universit`a degli Studi di Milano - Bicocca\nScuola di Scienze\nDipartimento di Informatica, Sistemistica e Comunicazione\nCorso di Laurea Magistrale in Informatica\nMulti-Task Learning on Networks\nRelatore: Prof. Antonio Candelieri\nCo-relatore: Prof. Francesco Archetti\nRelazione della prova ﬁnale di:\nAndrea Ponti\nMatricola 816311\nAnno Accademico 2020-2021\narXiv:2112.04891v1  [cs.LG]  7 Dec 2021\n\n\nAbstract\nThe multi-task learning (MTL) paradigm can be traced back to an early paper of Caruana (1997)\nin which it was argued that data from multiple tasks can be used with the aim to obtain a better\nperformance over learning each task independently. The rationale underlying this approach is\nthat strong dependencies are “hidden” among seemingly unrelated tasks due to the shared data\ngenerating process. A natural way is to design a set of parametrized hypotheses that share some\nparameters across tasks which are learned solving an optimization problem that minimizes a\nweighted sum of the empirical risk for each task. Multi-task learning is a very common situation.\nFor instance, in a recommender system, not only the accuracy of the rating prediction, but also\nthe novelty and coverage of the recommendations should be optimized. Most recent Machine\nLearning (ML) applications require to optimize the ML algorithm’s hyperparameters not just for\naccuracy but also for fairness, interpretability, and energy consumption. For instance, tuning a\nDeep Neural Network’s hyperparameters depends on accuracy but also on latency and deployability\non speciﬁc device (i.e., limited hardware resources of the target device on which making inference).\nMinimizing independently the empirical risks related to diﬀerent tasks is the correct solution only\nwhen tasks are not competing with each other, which is rarely the case. “Naive” solutions like\na linear combination of the single tasks are computationally expensive and lack credible metrics\nfor evaluating the quality of the results. A solution of MTL with conﬂicting objectives requires\nmodelling the trade-oﬀamong them which is generally beyond what a straight linear combination\ncan achieve. Although constrained approaches, which optimize one single task while accounting the\nothers as constraints, have been recently and successfully proposed to overcome these drawbacks in\nimplementing speciﬁc real-life applications, a theoretically principled and computationally more\neﬀective strategy is ﬁnding solutions which are not “dominated” by others as it is addressed in the\nPareto analysis. Multi-objective optimization problems arising in the multi-task learning context\nhave speciﬁc features and require ad hoc methods. The analysis of these features, also in some\nspeciﬁc instances, and the proposal of a new computational approach represent the focus of this work.\nMulti-objective evolutionary algorithms (MOEAs), speciﬁcally Non Sorting Dominated Genetic\nAlgorithms (NSGAs) can easily include the concept of dominance and therefore the Pareto analysis.\nThe major drawback of MOEAs is a low sample eﬃciency with respect to function evaluations\nwhich makes them hardly feasible when the evaluation of the objective functions is computationally\nvery expensive. The key reason for this drawback is that most of the evolutionary approaches do\nnot use models (surrogate models or metamodels) for approximating the objective function and\ntherefore cannot make predictions over new candidate solutions. Bayesian Optimization (BO) takes\na radically diﬀerent approach based on a surrogate model, usually probabilistic, such as a Gaussian\nProcess (GP).\n\nMost multi-objective BO approaches maintain diﬀerent GPs, one for each task or objective: in\ngeneral, the tasks show some underlying structure and cannot be treated as unrelated objectives.\nBy making use of this structure, one might beneﬁt signiﬁcantly by learning the tasks simultaneously\nas opposed to learning them independently. In this thesis a diﬀerent approach is considered. The\nsolutions in the Input Space are represented as probability distributions encapsulating the knowledge\ncontained in the function evaluations. The focus is on discrete distributions and in particular\nhistograms. These distributions are analyzed according to their distance. Among several distances\nthe Wasserstein (WST) distance has been used. In this space of probability distributions, endowed\nwith the metric given by the Wasserstein distance, a new algorithm MOEA/WST can be designed\nin which the model is not directly on the objective function but in an intermediate Information\nSpace where the objects from the input space are mapped into histograms and the genetic operators\nare built on the WST distance. Computational results show that both the sample eﬃciency and the\nquality of the Pareto set provided by MOEA/WST, as measured by the Hypervolume metric, are\nsigniﬁcantly better than in the standard MOEA implementation.\nii\n\nContents\nList of Figures\nvii\nList of Tables\nxi\n1\nIntroduction\n1\n1.1\nMotivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.2\nStructure of the thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\nContributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2\nPareto Analisys and Evolutionary Learning\n5\n2.1\nPareto analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.2\nMulti-Objective Evolutionary Learning . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.3\nDominance\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.4\nDecomposition\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3\nBayesian Optimization\n13\n3.1\nGaussian Process Regression\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.2\nKernel: the data geometry of BO . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3\nThe Acquisition Function\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.4\nBayesian Optimization framework\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.5\nAdvanced topics in Bayesian and Evolutionary learning\n. . . . . . . . . . . . . . . .\n21\n4\nInstances of Multi-Task Learning on Networks\n23\n4.1\nFrom water networks to outbreak detection . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.2\nRecommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n5\nThe Wasserstein Distance\n29\n5.1\nBasic deﬁnitions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.2\nWasserstein over discrete distributions . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.3\nBarycenters and Wasserstein clustering . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\niii\n\n5.4\nApproximations and computational issues . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6\nMOEA with Wasserstein\n37\n6.1\nGeneral framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n6.2\nWasserstein based selection operator . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n6.3\nProblem speciﬁc crossover operator . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n7\nWater Distribution Networks\n41\n7.1\nWater networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n7.2\nWasserstein for resilience evaluation\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n7.3\nHydraulic and quality simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n7.4\nThe problem of sensors placement\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\n7.5\nDistributional representation of sensor placements\n. . . . . . . . . . . . . . . . . . .\n50\n7.6\nSearch, Information and Objective space . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n7.7\nComputational settings\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n7.8\nComputational results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n8\nRecommender Systems\n59\n8.1\nThe problem deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n8.2\nRepresenting user and items as a graph\n. . . . . . . . . . . . . . . . . . . . . . . . .\n60\n8.3\nObjective functions and its distributional representation . . . . . . . . . . . . . . . .\n64\n8.4\nComputational settings\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n68\n8.5\nComputational results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n69\n9\nSoftware Resources\n71\n9.1\nPymoo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n9.2\nBoTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n9.3\nPython Optimal Transport\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n9.4\nWater Networks Tool for Resilience . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n9.5\nCytoscape and ClusterMaker\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n10 Conclusions\n75\nA Metrics on graphs\n77\nA.1 Centrality measures\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\nA.2 Vulnerability measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\nB Computational Results\n79\nB.1\nSensor placement in Hanoi WDN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n79\niv\n\nBibliography\n83\nv\n\n\nList of Figures\n2.1\nAn example of Pareto Set and Pareto Front. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\nAn example of hypervolume. Adding the point A to the approximate Pareto front,\nleads to an improvement of the hypervolume. . . . . . . . . . . . . . . . . . . . . . .\n7\n2.3\nThe non-dominated sorting and the crowding distance in NSGA-II. . . . . . . . . . .\n8\n2.4\nThe general framework of NSGA-II.\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3.1\nFive diﬀerent samples from the prior of a GP with Squared Exponential kernel as\ncovariance function.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\nSampling from prior vs sampling from posterior (for the sake of simplicity, the\nnoisy-free setting is considered). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3\nDiﬀerent function compatible with the function observations D1:3.\n. . . . . . . . . .\n16\n3.4\nThe value of the characteristic length-scale is ℓ= 1 for all the four kernels; α of the\nRQ kernel is set to 2.25. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.5\nAn example of how PI selects the new point.\n. . . . . . . . . . . . . . . . . . . . . .\n19\n4.1\nSpread of information between blogs. Each layer shows an information cascade. The\nobjective is to ﬁnd few blogs that quickly capture most cascades. . . . . . . . . . . .\n24\n4.2\nAn example of a blogosphere. Blogs contain posts that are linked to the sources of\ninformations. The cascades grow in the reverse direction of the edges.\n. . . . . . . .\n24\n4.3\nImpact of contamination events on a water distribution network consisting of 1213\nnodes and 1393 edges. The color of each node indicates the impact before detection\nif a contaminant is introduced at the node and for a speciﬁc sensor placement. As\nimpact the detection time is considered. . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n5.1\nAn example of discrete and continuous distributions in 1-dimensional and 2-dimensional\ncase. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.2\nThe two distributions P and Pθ. It is important to note that there is no overlap\nwhen θ ̸= 0. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\nvii\n\n5.3\nThe table compares diﬀerent probabilistic distances between the three histograms dis-\nplayed in the ﬁgure. It is clear how the Wasserstein distance is the more interpretable\none.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n6.1\nThe general framework of MOEA/WST. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n6.2\nTwo pairs of individuals are sampled from the Pareto front. As parents of the new\noﬀspring, the most diﬀerent pair is chosen. In this case F2 and M2 will be the parents\nof the new oﬀspring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n6.3\nThe comparison between one-point crossover and problem speciﬁc crossover. . . . . .\n40\n7.1\nA schematic representation of the three benchmark WDNs. . . . . . . . . . . . . . .\n42\n7.2\nA schematic representation of the two real word-size WDNs . . . . . . . . . . . . . .\n42\n7.3\nThe Anytown water distribution network and an example of node-node distances\ndistribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n7.4\nThe node-node distance distributions at network level of G and G′. . . . . . . . . . .\n44\n7.5\nThe spectral clustering results over the two WDN, Neptun (with k = 2) and Abbiate-\ngrasso (with k = 3).\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n7.6\nThe color of each edge e depends on W(G, G \\ {e}), i.e., the Wasserstein distance\nbetween the original graph G and the one obtained removing the edge G \\ {e}. . . .\n47\n7.7\nExample of a sensor placement in Net1. Sensors are placed at nodes 9 and 11. . . . .\n48\n7.8\nExamples of sensor matrices considering Net1 WDN. . . . . . . . . . . . . . . . . . .\n50\n7.9\nExample of a placement matrix. Two sensors placed at node 9 and 11 respectively. .\n51\n7.10 Example of a placement histogram of Net1 WDN. Two sensors placed at node 9 and\n11 respectively. This histogram corresponds to the placement matrix displayed in\nFigure 7.9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n7.11 An example of how PI selects the new point.\n. . . . . . . . . . . . . . . . . . . . . .\n52\n7.12 Hypervolume curves of the three algorithms in the case of budget ≤3. . . . . . . . .\n54\n7.13 Hypervolume curves of the three algorithms in the case of budget ≤7. . . . . . . . .\n54\n7.14 Coverage over generations between the approximate Pareto fronts generated by\nNSGA-II and MOEA/WST. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n55\n7.15 Hypervolume curves of the two evolutionary algorithms in the case of budget ≤25. .\n56\n8.1\nDistribution of cosine similarity between all pairs of users. The dotted red line is the\nthreshold τ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n8.2\nThe cosine graph Gc. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n8.3\nExamples of users’ cosine similarity distributions. . . . . . . . . . . . . . . . . . . . .\n62\n8.4\nDistribution of Wasserstein distance between all pairs of users represented as his-\ntograms. The dotted red line is the threshold τ. . . . . . . . . . . . . . . . . . . . . .\n62\nviii\n\n8.5\nThe Wasserstein graph Gw. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n8.6\nResults of the spectral clustering on the rating matrix. Three clusters have been\nidentiﬁed (blue, lilac and fuchsia).\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n64\n8.7\nResults of the spectral clustering on the Wasserstein graph. Three clusters have been\nidentiﬁed (blue, lilac and fuchsia).\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n64\n8.8\nDistributional representation of a top-L recommendation matrix and the information\nspace.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n8.9\nExample of accuracy distributions over the users. . . . . . . . . . . . . . . . . . . . .\n66\n8.10 Example of coverage distributions over the users. . . . . . . . . . . . . . . . . . . . .\n67\n8.11 Example of novelty distributions over the users. . . . . . . . . . . . . . . . . . . . . .\n68\n8.12 Mean and standard deviation of the hypervolume over the generations. Clusters are\nthe ones obtained using the spectral clustering on the rating matrix. . . . . . . . . .\n69\n8.13 Mean and standard deviation of the hypervolume over the generations. Clusters are\nthe ones obtained using the spectral clustering on the Wasserstein graph.\n. . . . . .\n69\n8.14 Mean and standard deviation of the coverage over the generations. Clusters are the\nones obtained using the spectral clustering on the rating matrix.\n. . . . . . . . . . .\n70\n8.15 Mean and standard deviation of the coverage over the generations. Clusters are the\nones obtained using the spectral clustering on the Wasserstein graph. . . . . . . . . .\n70\nB.1\nHypervolume curves of the three algorithms in the case of budget ≤3. . . . . . . . .\n79\nB.2\nHypervolume curves of the three algorithms in the case of budget ≤7. . . . . . . . .\n80\nB.3\nHypervolume curves of the three algorithms in the case of budget ≤9. . . . . . . . .\n80\nB.4\nHypervolume curves of the three algorithms in the case of budget ≤15.\n. . . . . . .\n81\nB.5\nHypervolume curves of the three algorithms in the case of budget ≤20.\n. . . . . . .\n81\nix\n\n\nList of Tables\n7.1\nCentrality measure (deﬁned in Appendix A.1) of the two WDN, Neptun and Abbi-\nategrasso. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n7.2\nEﬃciency and vulnerability metrics (deﬁned in Appendix A.2) of the two WDN,\nNeptun and Abbiategrasso. The algebraic connectivity λ2 is deﬁned as the second\nsmallest eigenvalue of the Laplacian associated to the graph; λ2 = 0 means that the\ngraph is disconnected. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n7.3\nProbabilistic distances and loss of eﬃciency (deﬁned in Appendix A.2) between the\noriginal networks (Neptun and Abbiategrasso) and the once obtained removing some\nedges.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n7.4\nComparing hypervolume of MOEA/WST against those of the other two approaches\n(values are ×109) and with respect to diﬀerent budgets p and number of generations.\nStatistical signiﬁcance has been investigated through a Wilcoxon test (p-value is\nreported). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n55\n7.5\nComparing hypervolume of MOEA/WST against the NSGA-II’s (values are ×109).\nStatistical signiﬁcance has been investigated through a Wilcoxon test (p-value is\nreported). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n8.1\nAn example of a rating matrix. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n8.2\nAn example of a top-L recommendation matrix. . . . . . . . . . . . . . . . . . . . . .\n60\nB.1\nComparing hypervolume of MOEA/WST against those of the other two approaches\n(values are ×109) and with respect to diﬀerent budgets p and number of generations.\nStatistical signiﬁcance has been investigated through a Wilcoxon test (p-value is\nreported). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\nxi\n\n\nChapter 1\nIntroduction\nIn this chapter the Multi-Task Learning paradigm is introduced with a particular focus to optimiza-\ntion problems. In the following the main motivations are explained that lead to Multi-Objective\nOptimization and some of the principal strategies for solving it.\n1.1\nMotivations\nThe multi-task learning (MTL) paradigm can be traced back to an early paper of Caruana [1] in\nwhich it was argued that data from multiple tasks can be used with the aim to obtain a better\nperformance over learning each task independently. The rationale underlying this approach is that\nstrong dependencies are “hidden” among seemingly unrelated tasks due to the shared data generating\nprocess. A natural way is to design a set of parametrized hypothesis that share some parameters\nacross tasks which are learned solving an optimization problem that minimizes a weighted sum of\nthe empirical risk for each task. Multi-task learning is a very common situation. For instance, in\na recommender system, not only the accuracy of the rating prediction, but also the novelty and\ncoverage of the recommendations should be optimized. In general, hyperparameters should be\noptimized not just for accuracy but also for fairness, interpretability [2] and energy consumption [3, 4].\nThe mitigation of the “contamination” risk in networks, both physical and informational, depends\nboth on detection time and its variance [5]. Tuning a Deep Neural Network’s hyperparameters\ndepend on accuracy but also on latency and deployability [6, 7].\nMinimizing independently the empirical risks related to diﬀerent tasks is the correct solution only\nwhen tasks are not competing with each other, which is rarely the case. “Naive” solutions like a\nlinear combination of the single tasks are computationally expensive and lack credible metrics for\nevaluating the quality of the result. A solution of MTL with conﬂicting objectives requires modelling\nthe trade-oﬀbetween them which is generally beyond what a straight linear combination can achieve.\nA theoretically principled and computationally more eﬀective strategy is ﬁnding solutions which are\nnot “dominated” by others as it is addressed in the Pareto analysis. This solution has been recently\n1\n\nadvocated in several papers [8, 9].\nIn this thesis the objective of multi-task learning is cast in terms of ﬁnding Pareto optimal solutions.\nThe problem of ﬁnding Pareto optimal solutions given multiple criteria is called Multi-Objective\nOptimization (MOO). Multi-objective optimization problems arising in the multi-task learning\ncontext have speciﬁc features and require ad hoc methods [10, 11, 12]. The analysis of these features,\nalso in some speciﬁc instances, and the proposal of a new computational approach represent the\nfocus of this work.\nThere are three main strategies to deal with multi-objective optimization problems occurring in\nMTL.\nThe ﬁrst are gradient based methods [8, 13]. These algorithms are quite eﬀective but require the\ncomputation of gradients for each task which is not an easy task since the loss functions are usually\nblack box and multimodal.\nAn alternative are evolutionary algorithms (EAs). EAs have developed over the last two decades\nalong diﬀerent approaches, which will be analyzed in Chapter 2. Their set-up is relatively simple,\nthere are many software resources and do not require derivative information. Moreover, multi-\nobjective evolutionary algorithms (MOEAs), speciﬁcally Non-dominated Sorting Genetic Algorithms\n(NSGAs) can easily include the concept of dominance and therefore the Pareto analysis. The\nmajor drawback of MOEAs is a low sample eﬃciency with respect to function evaluations which\nmakes them hardly feasible when the evaluation of the objective functions is computationally very\nexpensive, as it happens in machine learning problems in the case of large datasets and in simulation\nand optimization problems which is often the case in real word application as will be shown in\nChapter 4. The key reason for this drawback is that most of the evolutionary approaches do not\nuse models (surrogate models or metamodels) for the objective function and therefore cannot make\npredictions over new candidate solutions.\nBayesian Optimization (BO) takes a radically diﬀerent approach based on a surrogate model usually\na Gaussian Process [14, 15, 16, 17, 18]. Most multi-objective BO approaches maintain diﬀerent\nGaussian Processes (GPs), one for each task or objective: in general, the tasks show some underlying\nstructure and cannot be treated as unrelated objects. By making use of this structure, one might\nbeneﬁt signiﬁcantly by learning the tasks simultaneously as opposed to learning them independently.\nAn important line of research has been investigating the use of metamodels in MOEAs using\nin particular neural networks and gaussian processes.\nAn early method is ParEGO [19, 20]\nwhich use the uncertainty estimation allowed by GP to manage the exploration/exploitation (or\ndiversiﬁcation/intensiﬁcation) trade-oﬀ. The importance of this issue, which is at the very basis of\nBO, has been recently recognized also in MOEAs in [21].\nIn this thesis a diﬀerent approach is considered. The solutions in the input space are represented\nas probability distributions encapsulating the knowledge containing the function evaluations. The\nfocus is on discrete distributions and in particular histograms. These distributions are analyzed\n2\n\naccording to their distance. Among several distances the Wasserstein (WST) distance has been\nused. In this space of probability distributions, endowed with the metric given by the Wasserstein\ndistance, a new algorithm MOEA/WST can be designed in which the model is not directly on\nthe objective function but in an intermediate information space where the objects from the input\nspace are mapped into histograms and the genetic operators are built on the WST distance between\nhistograms. Computational results show that both the sample eﬃciency and the quality of the\nPareto set, as measured by the Hypervolume, are signiﬁcantly better than in the standard MOEAs.\n1.2\nStructure of the thesis\nThe content of this work is organized as follows.\nChapter 2 “Pareto Analisys and Evolutionary Learning” is devoted to the Pareto model and to the\nbasic methods in MOEAs, analysing their structures and performance metric.\nChapter 3 “Bayesian Optimization” provides background material about Bayesian optimization\nmethods focusing on their basic components: the surrogate model (metamodel) based on Gaussian\nprocesses and the acquisition function.\nChapter 4 “Instances of Multi-Task Learning on Networks” outlines the real world problems which are\ninstances of learning on networks and have been inspirational for this work. They are contamination\ndetection and resilience assessment in a Water Distribution Network (WDN), detection of fake-news\nin the blogosphere and recommender systems. These problems have a shared structure and have\nbeen targeted for computational experiments. All the problems considered are NP-hard so that\nsolution methods are approximate metaheuristics.\nChapter 5 “The Wasserstein Distance” introduces the key concept in this work: solutions in the\ninput space are mapped into a space of probability distributions. Among several distances between\ndistributions, the Wasserstein distance is introduced. The focus is on discrete distributions and in\nparticular histograms.\nChapter 6 “MOEA with Wasserstein” analyses MOEA/WST, an entirely new concept in which the\nmodel is not on the objective function but in an intermediate information space where the objects\nfrom the input space are mapped into histograms and the genetic operators are built on the WST\ndistance between histograms.\nChapter 7 “Water Distribution Networks” reports the experimental setting in the WDN target\nproblems, a new data structure and the computational results.\nChapter 8 “Recommender Systems” reports the experimental setting in the recommender target\nproblems, and the computational results of MOEA/WST.\nChapter 9 “Software resources” describes the software used in this work.\nChapter 10 “Conclusions” contains a critical evaluation of the results along with indications of\nperspectives for future work.\n3\n\n1.3\nContributions\nOne of the key contributions of this work is the deﬁnition of a mapping from the search space\n(where each solution can be represented by a real, integer or binary vector) into an information\nspace whose elements are probability distributions. This characterization of an information space\nenables the introduction of probabilistic distances, in particular the Wasserstein distance. In this\nway, it is possible to compute the distance between elements in the information space which are\nrepresented as histograms.\nAnother contribution of this thesis is the introduction of a novel data structure for archiving results\nof simulation in an eﬃcient way and monitoring dynamical processes in networks.\nThe overall contribution is the formulation of a new evolutionary method called MOEA/WST in\nwhich combination operators are enabled by WST distance. Finally, it is proposed a critical analysis\nof the computational results obtained on target problems with MOEA/WST and other standard\nMOEAs, namely NSGA-II and ParEGO.\n4\n\nChapter 2\nPareto Analisys and Evolutionary\nLearning\nEvolutionary learning refers to a set of algorithms and learning methods which draw inspiration\nfrom the process of natural evolution. The fundamental metaphor relates to an environment which\nis ﬁlled with a population of individuals that strive for survival and reproduction. The ﬁtness of\nthese individuals is determined by the environment and relates to how well they succeed in achieving\ntheir goals. In other words, it represents their chances of survival and of multiplying. In the context\nof learning, the environment is represented by the problem that has to be solved and the data\navailable. The individuals refer to a set of candidate solutions and their quality determines the\nchance that they will be kept and used as seed for generating further candidate solutions.\nThis chapter considers the particular case of multi-objective optimizations and describes the two\nmain evolutionary strategies used to solve this kind of problems.\n2.1\nPareto analysis\nMulti-Objective Optimization problem (MOO) can be stated as follows (Equation 2.1):\nmin F(x) = (f1(x), . . . , fm(x))\n(2.1)\nPareto rationality is the theoretical framework to analyse multi-objective optimization problems\nwhere m objective functions f1(x), . . . , fm(x), have to be simultaneously optimized in the search\nspace Ω⊆R.\nLet u, v ∈Rm, for a minimization problem, u is said to dominate v if and only if ui ≤vi ∀i = 1, . . . , n\nand uj ≤vj for at least one index j. The goal in multi-objective optimization is to identify the\nPareto frontier of F(x). A point x∗is Pareto optimal for the problem in Equation 2.1 if there is no\npoint x such that F(x) dominates F(x∗). The set of all Pareto optimal points is the Pareto set (PS)\n5\n\n(Figure 2.1a) and the set of all Pareto optimal objective vectors is the Pareto front (PF) (Figure\n2.1b).\n(a) The search space with the Pareto set.\n(b) The objective space with the Pareto front.\nFigure 2.1: An example of Pareto Set and Pareto Front.\nThe interest in ﬁnding locations x having the associated F(x) on the Pareto frontier is clear: all of\nthem represent eﬃcient trade-oﬀs between conﬂicting objectives and are the only ones, according to\nthe Pareto rationality, to be considered by the decision maker. This implies that any improvement\nin a Pareto optimal point in one objective leads to a deterioration in another.\nA fundamental diﬀerence between single and multi-objective optimization is that it is not obvious\nwhich metric to use to evaluate the solution quality. Moreover, the decision maker, post-optimization,\nmust chose a point in the Pareto set according to his/her preference.\nTo measure the progress of the optimization, a natural and widely used metric is the Hypervolume\n(HV) indicator that measures the objective space between an approximate Pareto front and a\npredeﬁned reference vector (Figure 2.2).\nA marginally or largely dominant Pareto set will result into a respectively low or high hypervolume\nvalue; thus, hypervolume is a reasonable measure for evaluating the quality of the optimization\nprocess. The hypervolume can be used also to guide the selection of solutions with good convergence\nand diversity properties [22, 23]. These advantages come at a computational cost as hypervolume\ncalculation can be very expensive for many objective problems.\nAnother metric to compare diﬀerent approximations of the Pareto front is the C-metric, also called\ncoverage. Let A and B be two approximations of the PF, C(A, B) gives the fraction of solutions in\nB that are dominated by at least one solution in A. Hence, C(A, B) = 1 means that all solutions in\nB are dominated by at least one solutions in A while C(A, B) = 0 implies that no solution in B is\ndominated by a solution in A.\n6\n\nFigure 2.2: An example of hypervolume. Adding the point A to the approximate Pareto front, leads\nto an improvement of the hypervolume.\n2.2\nMulti-Objective Evolutionary Learning\nMulti-Objective Evolutionary Algorithms (MOEAs) developed over the last two decades along\ndiﬀerent strategies. The main two approaches are the non-dominated sorting based, as NSGA-II or\nNSGA-III, and the decomposition-based, as MOEA/D [24]. Trivedi et al., [25] gives a comprehensive\nreview of the developments of MOEAs. The question of which strategy works better does not admit\nan easy answer: it depends on problem features like the shape of Pareto sets, disconnection, or\ndegeneracy [26]. A recent contribution to the decomposition approach is [27] where a clustering\napproach method is used to learn the Pareto optimal set structure. Recently it has been recognized\nthe criticality of the exploration/exploitation dilemma in MOEAs [20] which is widely studied in\nBayesian optimization and whose solution is based on the predictive uncertainty enabled by the\nGP model. Most of the evolutionary approaches do not use models for the objective functions and\ntherefore cannot make predictions about unevaluated designs: as a consequence, a large number of\nfunction evaluations is usually required.\nA ﬁrst solution to mitigate the problem of low sample eﬃciency of EA is the development of problem\nspeciﬁc operators. Deb and Myburgh [28] proposed problem speciﬁc recombination and repair\noperators [22]. Li et al., [26] introduces new test problems with diﬃcult problem features as objective\nscalability, complicated Pareto sets, bias, disconnection, and degeneracy. In [29] the authors move\nfrom the observation that the impact of the shape of Pareto sets has not been properly considered\nand introduce a set of test instances in order to compare the ability of algorithms to cope with\ncomplicated Pareto sets shapes. The issue of comparing and evaluating solution sets provided by\ndiﬀerent algorithms has been extensively analyzed also in [30].\nAnother solution is to endow the evolutionary strategy with a surrogate model usually a GP. A\n7\n\nbenchmark method is ParEGO [19] which combines the evolutionary approach with Gaussian based\nBayesian optimization. ParEGO is based on the well-known EGO [31] algorithm which is an early\nindustrial strength implementation of BO. ParEGO uses as acquisition function, the Expected\nImprovement, which is optimized by EA. A similar GP based approach is in [32] which uses Gaussian\nrandom ﬁelds metamodels to predict the values of the objective functions [20].\n2.3\nDominance\nNon-dominated Sorting Genetic Algorithm (NSGA-II) is a well-known evolutionary algorithm based\non the concept of Pareto dominance proposed in [33]. NSGA-II is based on two key elements:\n• An elitist principle, i.e., the elites of a population are given the opportunity for their genes to\nbe carried to the next generation.\n• An explicit mechanism to preserve the diversity (crowding distance).\nTo identify the elites of a population, NSGA-II rank each individual considering the dominance of\na solution on the others. Through the non-dominated sorting, NSGA-II deﬁnes diﬀerent frontiers\nF1, . . . , Fn as follow: ﬁrst all the non-dominated individuals are assigned to F1, then all the\nindividuals that are dominated only by solutions in F1 are assigned to F2; this process is repeated\nuntil all the individuals belong to one frontier as showed in Figure 2.3.\n(a) The diﬀerent frontier identiﬁed by the non-\ndominated sorting procedure.\n(b) A visual representation of the crowding distance\nof a point i.\nFigure 2.3: The non-dominated sorting and the crowding distance in NSGA-II.\nAt each generation, the new population is created by picking the individuals in the best frontiers\nuntil the size of the original population is reached. To choose between individual with the same rank,\n8\n\nthe crowding distance (CD) is used. Considering an individual i the crowding distance is deﬁned as\nthe perimeter of the cuboid deﬁned by its neighbors (i −1) and (i + 1) as shown in Equation 2.2.\nCD(i) =\nm\nX\nj=1\nfj(i + 1) −fj(i −1)\nmaxx∈F fj(x)\n(2.2)\nOnly the individuals with higher crowding distance will belong to the new population. The general\nframework of NSGA-II can be schematized as in Figure 2.4.\nFigure 2.4: The general framework of NSGA-II.\n2.4\nDecomposition\nReduction to a single-objective problem is largely used. This can be done in diﬀerent ways, for\ninstance considering convex combinations of the objective functions [34]. The scalarization approach\nis also followed by some evolutionary algorithms. For example, [24] leads to the optimization\nof several single-objective problems. There are many approaches for converting the problem of\napproximation of the Pareto Front into a number of scalar optimization problems. In the following,\ntwo strategies are introduced.\nWeighted Sum Approach\nThis approach considers a convex combination of the diﬀerent objectives. Let λ = (λ1, ..., λm)T be\na weight vector, i.e., λi ≥0 for all i −1, ..., m and Pm\ni=1 λi = 1. Then, the optimal solution to the\n9\n\nfollowing scalar optimization problem (Equation 2.3):\nmax gws(x|λ) =\nm\nX\ni=1\nλifi(x)\nsubject to x ∈Ω\n(2.3)\nis a Pareto optimal point, where gws(x|λ) is used to emphasize that λ is a coeﬃcient vector in this\nobjective function, while x is the variables to be optimized. To generate a set of diﬀerent Pareto\noptimal vectors, one can use diﬀerent weight vectors λ in the above scalar optimization problem. If\nthe PS is concave (convex in the case of minimization), this approach could work well. However,\nnot every Pareto optimal point can be obtained by this approach in the case of non-concave PSs.\nTo overcome these shortcomings, some eﬀort has been made to incorporate other techniques into\nthis approach [35].\nChebyshev Approach\nIn this approach, the scalar optimization problem is in the form (Equation 2.4):\nmin gte(x|λ, z∗) = max\n1≤i≤m{λi|fi(x) −z∗\ni |}\nsubject to x ∈Ω\n(2.4)\nwhere z∗= (z∗\n1, ..., z∗\nm)T is the reference point (similarly to the hypervolume computation), i.e.,\nz∗\ni = max{fi(x)|x ∈Ω} for each i = 1, ..., m. For each Pareto optimal point x∗there exists a\nweight vector λ such that x∗is the optimal solution of Equation 2.4 and each optimal solution of\nEquation 2.4 is a Pareto optimal solution of Equation 2.1. Therefore, one is able to obtain diﬀerent\nPareto optimal solutions by altering the weight vector. One weakness with this approach is that its\naggregation function is not smooth for a continuous MOP. However, it can still be used in the EA\nframework proposed in this thesis since the algorithm does not need to compute the derivative of\nthe aggregation function.\nMOEA/D\nMulti-Objective Evolutionary Algorithm based on Decomposition (MOEA/D) is a genetic algorithm\nproposed in [24]. MOEA/D decomposes the multi-objective problem into a number N of single\nobjective problems associated to an aggregation weight vector and to diﬀerent points of Pareto\nSet (Front). Neighbourhood relations among sub-problems are based on the distance between\naggregation vectors. As previously mentioned, there are several approaches for converting the\nproblem of approximation of the Pareto front into a number of scalar optimization problems. Let\nλ1, . . . , λN be a set of even spread weight vectors and z∗be the reference point. The problem of\n10\n\napproximation of the PF can be decomposed into N scalar optimization sub-problems by using the\nChebyshev approach and the objective function of the j-th sub-problem is (Equation 2.5):\nmin gte(x|λj, z∗) = max\n1≤i≤m{λj\ni|fi(x) −z∗\ni |}\n(2.5)\nwhere λj = (λj\n1, . . . , λj\nm)T . MOEA/D minimizes all these N objective functions simultaneously in a\nsingle run.\nThe general framework can be summarized as follows:\n1. Initialization:\n• Compute the Euclidean distances between any two weight vectors and then work out the T\nclosest weight vectors to each weight vector. For each i = 1, . . . , N, set B(i) = i1, . . . , iT ,\nwhere λ(i1), . . . , λ(iT ) are the T closest weight vectors to λi.\n2. Update:\n• Reproduction: randomly select two indexes k,l from B(i), and then generate a new\nsolution y from xk and xl by using genetic operators. Two solutions have a chance to\nmate only when they are from neighboring sub-problems.\n• Improvement: apply a problem-speciﬁc repair/improvement heuristic on y to produce y′.\nThis process is repeated until a termination criteria is satisﬁed, such as the number of generations\nor the number of function evaluations. In initialization, B(i) contains the indexes of the T closest\nvectors of λi. The Euclidean distance is used to measure the closeness between any two weight\nvectors. Therefore, λi’s closest vector is itself, and then i ∈B(i). If j ∈B(i), the j-th sub-problem\ncan be regarded as a neighbor of the i-th sub-problem.\nMOEA needs to maintain diversity in its population for producing a set of representative solutions.\nMost, if not all, of non-decomposition MOEAs such as NSGA-II use crowding distances among\nthe solutions in their selection to maintain diversity. However, it is not always easy to generate\na uniform distribution of Pareto optimal objective vectors in these algorithms. In MOEA/D, a\nmulti-objective problem is decomposed into several scalar optimization sub-problems. Diﬀerent\nsolutions in the current population are associated with diﬀerent sub-problems. The “diversity”\namong these sub-problems will naturally lead to diversity in the population.\n11\n\n\nChapter 3\nBayesian Optimization\nBayesian Optimization (BO) is a sequential strategy for global optimization of black-box functions\n(i.e., functions whose analytical form is unknown). Surrogate models are a key component of BO, in\nthis thesis are considered the Gaussian Processes. Gaussian Processes are a powerful formalism for\nimplementing both regression and classiﬁcation algorithms. While most of the regression algorithms\nprovides a deterministic output, GPs also oﬀer a reliable estimate of uncertainty. This chapter\npresents the basic mathematics underlying this powerful tool.\n3.1\nGaussian Process Regression\nOne way to interpret a Gaussian process (GP) regression model is to think of it as deﬁning a\ndistribution over functions, and with inference taking place directly in the space of functions (i.e.,\nfunction-space view) [36]. A GP is a collection of random variables, any ﬁnite number of which have\na joint Gaussian distribution. A GP is completely speciﬁed by its mean function µ(x) (Equation\n3.1) and covariance function cov(f(x), f(x′)) = k(x, x′) (Equation 3.2):\nµ(x) = E[f(x)]\n(3.1)\ncov(f(x), f(x′)) = k(x, x′) = E[(f(x) −µ(x))(f(x′) −µ(x′))]\n(3.2)\nand will write the Gaussian process as (Equation 3.3):\nf(x) ∼GP(µ(x), k(x, x′))\n(3.3)\nThe covariance function assumes a critical role in the GP modelling, as it speciﬁes the distribution\nover functions. To see this, consider samples from the distribution of functions evaluated at any\nnumber of points; in detail, a set of input points X1:n = (x1, . . . , xn)T is chosen and then the\ncorresponding covariance matrix elementwise is computed. This operation is usually performed by\n13\n\nusing predeﬁned covariance functions allowing to write covariance between outputs as a function of\ninputs (i.e., cov(f(x), f(x′)) = k(x, x′)). Finally, a random Gaussian vector can be generated as\n(Equation 3.4):\nf(X1:n) ∼N(0, K(X1:n, X1:n)\n(3.4)\nThis is basically known as sampling from prior. The following is an example (Figure 3.1) of ﬁve\ndiﬀerent GP samples drawn from the GP prior: the covariance function used is known as the\nSquared Exponential (SE) kernel.\nFigure 3.1: Five diﬀerent samples from the prior of a GP with Squared Exponential kernel as\ncovariance function.\nUsually, the primarily interest is not in drawing random functions from the prior but is to incorporate\nthe knowledge about the function obtained through the evaluations performed so far. Such a\nknowledge will be then used by the acquisition function in order to associate an informational utility\nto each point x ∈X. Often, the function values are noisy and so consider y = f(x) + ε. Assuming\nadditive independent and identically distributed Gaussian noise ε with variance λ2, the prior on the\nnoisy observations becomes (Equation 3.5):\ncov(f(x), f(x′)) = k(x, x′) + λ2δxx′\n(3.5)\nwhere δxx′ is a Kronecker delta which is equal to 1 if and only if x = x′. Thus, the covariance over\nall the function values y = (y1, . . . , yn) is (Equation 3.6):\ncov(y) = K(X1:n, X1:n) + λ2I\n(3.6)\nTherefore, the predictive equations for GP regression, that are µ(x) and k(x, x′), can be easily\nupdated, by conditioning the joint Gaussian prior distribution on the observations (Equations 3.7\n14\n\nand 3.8):\nµ(x) = E[f(x)|D1:n, x] = k(x, X1:n)[K(X1:n, X1:n) + λ2I]−1y\n(3.7)\nσ2(x) = k(x, x) −k(x, X1:n)[K(X1:n, X1:n) + λ2I]−1k(X1:n, x)\n(3.8)\nIt follows a simple example (Figure 3.2) of ﬁve diﬀerent samples drawn from a GP prior and posterior,\nrespectively. Posterior is conditioned to six function observations.\n(a) Sampling from prior.\n(b) Sampling from posterior.\nFigure 3.2: Sampling from prior vs sampling from posterior (for the sake of simplicity, the noisy-free\nsetting is considered).\nThese ﬁgures shows that even removing the noise, as it’s often assumed, the problem is still of\n“structural uncertainty”. For instance, considering three noise-free evaluations of f(x), D1:3 =\n{(xi, yi)}i=1,...,3, there still are an inﬁnite number of functions with diﬀerent minima and minimizers,\ncompatible with D1:3, as depicted in Figure 3.3.\nIt is easy to show that the mean prediction is a linear combination of n functions, each one centered\non an evaluated point. This allows to write µ(x) as (Equation 3.9):\nµ(x) =\nn\nX\ni=1\nαik(x, xi)\n(3.9)\nwhere the vector α = [K(X1:n, X1:n) + λ2I]−1y and αi is the i-th component of the vector α, given\nby the product between the i-th row of the matrix [K(X1:n, X1:n) + λ2I]−1 and the vector y. This\nmeans that, to make a prediction at a given x, it is necessary only to consider the (n+1)-dimensional\ndistribution deﬁned by the n function evaluations performed so far and the new point x to evaluate.\nCovariance functions are referred to in BO as kernels and some of the most widely used of them\nwill be presented in the following section.\n15\n\nFigure 3.3: Diﬀerent function compatible with the function observations D1:3.\nEvery kernel has some hyperparameters to be set up, deﬁning shape features of the GP, such as\nsmoothness and amplitude. The values of the hyperparameters are usually unknown a priori and\nare approximated using maximum likelihood estimators on the basis of the observations D1:n.\n3.2\nKernel: the data geometry of BO\nA covariance function is the crucial ingredient in a GP predictor, as it encodes assumptions about\nthe function to approximate. From a slightly diﬀerent viewpoint, it is clear that, in learning, the\nnotion of similarity between data points is crucial; it is a basic assumption that points which are\nclose in x are likely to have similar target values y, and thus function evaluations that are near to a\ngiven point should be informative about the prediction at that point. Under the GP view it is the\ncovariance function that deﬁnes nearness or similarity.\nA general name for a function k of two arguments mapping a pair of inputs x and x′ into a scalar is\nkernel. For a kernel to be a covariance function the following conditions must be satisﬁed:\n• The kernel has to be symmetric k(x, x′) = k(x′, x).\n• The matrix K with entries Kij = k(xi, xj), also known as Gram matrix, must be positive\nsemideﬁnite.\nIn the following, some examples of covariance (aka kernel) functions.\nSquared Exponential kernel (Equation 3.10):\nkSE(x, x′) = exp−||x−x′||2\n2ℓ2\n(3.10)\n16\n\nwith ℓknown as characteristic length-scale. This kernel is inﬁnitely diﬀerentiable, meaning that the\nGP’s sample functions are very “smooth”.\nMat´ern kernels (Equation 3.11):\nkMat(x, x′) = 21−v\nΓ(v)\n \n|x −x′|\n√\n2v\nℓ\n!v\nKv\n \n|x −x′|\n√\n2v\nℓ\n!\n(3.11)\nwith two hyperparameters v and ℓ, and where Kv is a modiﬁed Bessel function. Note that for\nv →∞it is equivalent to the Squared Exponential kernel. The Mat´ern covariance functions become\nespecially simple when v is half-integer: v = p + 1\n2, where p is a non-negative integer. In this case\nthe covariance function is a product of an exponential and a polynomial of order p. The most widely\nadopted versions, speciﬁcally in the Machine Learning community, are v = 3\n2 (Equation 3.12) and\nv = 5\n2 (Equation 3.13).\nkv= 3\n2 (x, x′) =\n \n1 + |x −x′|\n√\n3\nℓ\n!\nexp−|x−x′|\n√\n3\nℓ\n(3.12)\nkv= 5\n2 (x, x′) =\n \n1 + |x −x′|\n√\n5\nℓ\n+ (x −x′)2\n3ℓ2\n!\nexp−|x−x′|\n√\n5\nℓ\n(3.13)\nRational Quadratic Covariance function (Equation 3.14):\nkRQ(x, x′) =\n\u0012\n1 + (x −x′)2\n2αℓ2\n\u0013−α\n(3.14)\nwhere α and ℓare two hyperparameters. This kernel can be considered as an inﬁnite sum (scale\nmixture) of Squared Exponential kernels, with diﬀerent characteristic length-scales.\nFigure 3.4 summarizes how the value of the four kernels decreases with x moving away from\nx′ = 0 (Figure 3.4a) and which are possible resulting samples with diﬀerent shape properties (Figure\n3.4b).\n17\n\n(a) Value of four diﬀerent kernels with x moving away\nfrom x′ = 0.\n(b) Four samples from GP prior, one for each kernel\nconsidered.\nFigure 3.4: The value of the characteristic length-scale is ℓ= 1 for all the four kernels; α of the RQ\nkernel is set to 2.25.\n3.3\nThe Acquisition Function\nThe acquisition function is the mechanism to implement the trade-oﬀbetween exploration and\nexploitation in Bayesian Optimization (BO). More precisely, any acquisition function aims to guide\nthe search of the optimum towards points with potentially low values of objective function either\nbecause the prediction of f(x), based on the probabilistic surrogate model, is low or the uncertainty,\nalso based on the same model, is high (or both). Indeed, exploitation means to consider the area\nproviding more chance to improve over the current solution (with respect to the current surrogate\nmodel), while exploring means to move towards less explored regions of the search space where\npredictions based on the surrogate model are more uncertain, with higher variance.\nProbability of Improvement\nProbability of Improvement (PI) was the ﬁrst acquisition function proposed in the literature [37].\nOne of the drawbacks of PI is that it is biased towards exploitation. To mitigate this eﬀect, it can\nbe introduced the parameter ξ which modulates the balance between exploration and exploitation.\nThe resulting equation is (Equation 3.15):\nPI(x) = P(f(x) ≤f(x+) + ξ) = Φ\n\u0012f(x+) −µ(x) −ξ\nσ(x)\n\u0013\n(3.15)\n18\n\nMore precisely, ξ = 0 is towards exploitation, while ξ > 0 is more towards exploration.\nFinally, the next point to evaluate is chosen according to Equation 3.16.\nxn+1 = argmax\nx∈X\nPI(x)\n(3.16)\nFigure 3.5 shows that the value of PI in x3, given the best y value obtained in x+ corresponds to\nthe area depicted in green.\nFigure 3.5: An example of how PI selects the new point.\nHowever, a weak point of PI is to assign a value to a new point irrespectively of the potential\nmagnitude of the improvement. This is the reason why the next acquisition function was proposed.\nExpected Improvement\nExpected Improvement (EI) was initially proposed in [38] and then made popular in [31] which\nmeasures the expectation of the improvement on f(x) with respect to the predictive distribution of\nthe probabilistic surrogate model (Equation 3.17).\nEI(x) =\n(\n(f(x+) −µ(x))Φ(Z) + σ(x)φ(Z)\nif\nσ(x) > 0\n0\nif\nσ(x) = 0\n(3.17)\n19\n\nIn the equation φ(Z) and Φ(Z) represent the probability distribution and the cumulative distribution\nof the standardized normal, respectively, where (Equation 3.18):\nZ =\n( f(x+)−µ(x)\nσ(x)\nif\nσ(x) > 0\n0\nif\nσ(x) = 0\n(3.18)\nEI is made up of two terms: the ﬁrst is increased by decreasing the predictive mean; the second\nby increasing the predictive uncertainty. Thus, EI, in a sense, automatically balances, respectively,\nexploitation and exploration. It is possible to actively manage the trade-oﬀbetween exploration and\nexploitation, introducing the parameter ξ. When exploring, points associated to high uncertainty\nof the probabilistic surrogate model are more likely to be chosen, while when exploiting, points\nassociated to low value of the mean of the probabilistic surrogate model are selected.\nFinally, the next point to evaluate is chosen according to Equation 3.19.\nxn+1 = argmax\nx∈X\nEI(x)\n(3.19)\nEI has been largely used since 1998 and specialized to speciﬁc contexts. Astudillo and Frazier [39]\npropose a version for composite functions (EI-CF) which leads to a multi-output GP: the authors also\nnote that constrained optimization can be regarded as a special case of the optimization of composite\nfunctions and that EI-CF reduces to the expected improvement for constrained optimization.\nUpper/Lower Conﬁdence Bound\nConﬁdence Bound, where Upper and Lower are used, respectively for maximization and minimization\nproblems, is an acquisition function that manage exploration-exploitation by being optimistic in the\nface of uncertainty, in the sense of considering the best-case scenario for a given probability value\n[40]. For the case of minimization, LCB is given by Equation 3.20:\nLCB(x) = µ(x) −ξσ(x)\n(3.20)\nwhere ξ ≥0 is the parameter to manage the trade-oﬀbetween exploration and exploitation (ξ = 0\nis for pure exploitation; on the contrary, higher values of ξ emphasizes exploration by inﬂating the\nmodel uncertainty). For this acquisition function there are strong theoretical results, originated in\nthe context of multi-armed bandit problems, on achieving the optimal regret [41]. For the candidate\npoint xn instantaneous regret rn = f(xn) −f(x∗) can be observed. The cumulative regret RN after\nN function evaluations is the sum of instantaneous regrets RN = PN\nn=1 rn. A desirable asymptotic\nproperty of an algorithm is to be no-regret limN→∞Rn\nN = 0. Bounds on the average regret RN\nN\ntranslate to convergence rates: f(x+) = minxn≤N f(xn) in the ﬁrst N function evaluations is no\nfurther from f(x∗) than the average regret. Therefore, f(x+) −f(x∗) →0, with N →∞. Finally,\n20\n\nthe next point to evaluate is chosen according to xn+1 = argminx∈X LCB(x), in the case of a\nminimization problem, or xn+1 = argmaxx∈X LCB(x) in the case of a maximization problem.\n3.4\nBayesian Optimization framework\nA BO framework consists of two main component: a surrogate model for modelling the objective\nfunction, and an acquisition function for deciding where to sample next. After evaluating the\nobjective according to an initial space-ﬁlling experimental design, they are used iteratively to\nallocate the remainder of a budget of N function evaluations. Algorithm 1 summarizes a general\nBayesian Optimization process where the acquisition function, whichever it is, is denoted by\nα(x, D1:n). This function is generally maximized, except for the case of α = LCB.\nAlgorithm 1: General Bayesian Optimization algorithm\nGenerate an initial set of m points X1:m randomly sampled;\nEvaluate the function in the initial set of points and obtain D1:m;\nDefine a further budget N;\nfor n = m, . . . , m + N do\nUpdate the surrogate model obtaining the new estimates of µ(x) and σ(x);\nSelect a new xn+1 by optimizing an acquisition function α, such that\nxn+1 = argmaxx α(x|D1:n);\nEvaluate the objective function to obtain yn+1 = f(xn+1);\nUpdate the dataset of observations D1:n+1 = D1:n\nS{(xn+1, yn+1)};\nend\nResult: The best y value observed over the entire optimization process\n3.5\nAdvanced topics in Bayesian and Evolutionary learning\nEarly results are [42, 43] in which BO is generalized for multiple related objectives using dependencies\namong the tasks (objectives) in order to share information. One should anyway remark that these\nmethods look for learning eﬃciently separate optimizers for each objective rather than approximating\nthe Pareto frontier. Multi-objective Bayesian Optimization (MOBO) has been related to constrained\noptimization in [44] which proposes BO under unknown constraints as a way to obtain Pareto-optimal\nsolutions. A signiﬁcant contribution is [11] which uses LCB/UCB to model for each x an uncertainty\nhyper-rectangle. To select the next evaluation point instead of optimizing the acquisition function it\nsamples in this hyper-rectangle in a way that favours exploration. Recent papers about this topic\nare [18, 45, 46, 47].\nGaussian processes have been used in evolutionary algorithms as ParEGO and MOEA/D-GP [20].\nBoth methods use a Chebyshev-based decomposition approach. Each resulting scalar aggregate\nobjective is optimized by BO using Expected Improvement as acquisition function. A genetic\n21\n\nalgorithm is then used to maximize the expected improvement. The issue of balancing exploration\nand exploitation in multi-objective evolutionary optimization has been recently investigated in [21].\nAnother approach is SMS-EMOA based on the eﬃcient computation of the hypervolume applied as\na selection criterion to discard the individuals which contribute the least hypervolume improvement\n[48, 22].\nIn the comparative analysis in Chapter 7 a novel extension of ParEGO, that supports parallel\nevaluation and constraints, is used, namely qParEGO. Diﬀerent to the classical implementation,\nqParEGO computes gradients via auto-diﬀerentiation for the optimization of acquisition functions.\nParEGO is typically implemented by applying augmented Chebyshev scalarization and modelling\nthe scalarized outcome. However, qParEGO uses a Monte Carlo-based Expected Improvement\nacquisition function, where the objectives are modelled independently and the augmented Chebyshev\nscalarization is applied to the posterior samples as a composite objective. This approach enables the\nuse of sequential greedy optimization of q candidates with proper integration over the posterior at\nthe pending points. Importantly, the sequential greedy approach allows for using diﬀerent random\nscalarization weights for selecting each of the q candidates. qParEGO can also be extended to the\nconstrained case by weighting the EI by the probability of feasibility. qParEGO is implemented\nusing BoTorch, a very recent framework released by Facebook in 2019. For a description of BoTorch\nthe reader is referred to Chapter 9.2.\n22\n\nChapter 4\nInstances of Multi-Task Learning on\nNetworks\n4.1\nFrom water networks to outbreak detection\nConsider a network and a dynamic process spreading over this network, it is possible to deploy a set\nof sensors at the nodes with the aim to select a set of nodes to detect the process as eﬀectively as\npossible. Many real-world problems can be modelled under this setting. Consider a urban water\ndistribution network, delivering water to consumers via pipes and junctions. Accidental or malicious\nintrusions can cause contaminants to spread over the network, and the objective is to select a few\nlocations (pipes or junctions) to install sensors, in order to detect these contaminations as quickly\nas possible [49, 50]. Typical epidemics scenarios also ﬁt into this outbreak detection setting: it is\npossible to early detect a disease outbreak by monitoring only a small set of people within a social\nnetwork of interactions.\nIn the domain of web blogs, bloggers publish posts and use hyperlinks to refer to other bloggers’\nposts and content on the web. Each post is time stamped, so the spread of information on the\n“blogosphere” can observed. In this setting, the aim is to select a set of blogs to read (or retrieve)\nwhich are most up to date, i.e., catch most of the stories that propagate over the blogosphere.\nFigure 4.1 illustrates this setting. Each layer plots the propagation graph of the information, also\ncalled information cascade. Circles correspond to blog posts, and all posts at the same vertical\ncolumn belong to the same blog. Edges indicate the temporal ﬂow of information: the cascade\nstarts at some post (e.g., top left circle of the top layer of Figure 4.1) and then the information\npropagates recursively by other posts linking to it. The goal is to select a small set of blogs (two\nin case of Figure 4.1) which “catch” as many cascades (stories) as possible. There are several\npossible criteria one may want to optimize in outbreak detection. For example, one criterion seeks\nto minimize detection time (i.e., to know about a cascade as soon as possible, or avoid spreading of\n23\n\ncontaminated water). Similarly, another criterion seeks to minimize the population aﬀected by an\nundetected outbreak (i.e., the number of blogs referring to the story, or the population consuming\nthe contaminated water prior to detection).\nOptimizing these objective functions over all possible sensor placements is NP-hard, so for large,\nreal-world problems, it is not possible to ﬁnd the optimal solution and meta-heuristic must be used.\nFigure 4.1: Spread of information between blogs. Each layer shows an information cascade. The\nobjective is to ﬁnd few blogs that quickly capture most cascades.\nThe water distribution and blogosphere monitoring problems, even though in very diﬀerent domains,\nshare essential structure [51]. In both problems, the objective is to select a subset of nodes (sensor\nlocations, blogs) in a graph, which detect outbreaks (spreading of a virus/information) quickly\n(Figure 4.2). These outbreaks (e.g., information cascades) initiate from a single node of the network,\nand spread over the graph, such that the traversal of every edge takes a certain amount of time\n(indicated by the edge labels). As soon as the event reaches selected node, alarm is triggered.\nFigure 4.2: An example of a blogosphere. Blogs contain posts that are linked to the sources of\ninformations. The cascades grow in the reverse direction of the edges.\n24\n\nDepending on the selected nodes, a diﬀerent “placement score” is achieved. Figure 4.2 illustrates\nseveral criteria one may want to optimize. If one only want to detect as many stories as possible,\nthen reading just blog B6 is the best choice. However, reading B1 would miss one cascade, but\nwould detect the other cascades immediately. In general, this placement score (representing, e.g.,\nthe fraction of detected cascades, or the population saved by placing a sensor) is a multi-value\nset function, mapping every placement to the values of each objective functions, which have to be\nmaximized Figure 4.3 displays the impact over the detection time of diﬀerent sensor placements in\na water distribution network.\n(a) The impact over the events considering a sensor\nplacement of 150 sensors. The mean detection time is\n15 hours.\n(b) The impact over the events considering a diﬀerent\nsensor placement of 150 sensors. The mean detection\ntime is 9 hours.\nFigure 4.3: Impact of contamination events on a water distribution network consisting of 1213 nodes\nand 1393 edges. The color of each node indicates the impact before detection if a contaminant\nis introduced at the node and for a speciﬁc sensor placement. As impact the detection time is\nconsidered.\n4.2\nRecommender Systems\nRecommender systems (RS) represent a critical component of B2C online services. They recommend\nitems (movies, songs, books, etc.) that ﬁt the user’s preferences, to help the user in selecting items\nfrom a large set of choices. Personalized recommendations have huge importance where the number\nof possible items is large, such as in e-commerce related to art (books, movies, music), fashion, food,\netc. Some of the major participants in e-commerce (Amazon), movie streaming (Netﬂix), and music\nstreaming (Spotify) successfully apply recommender systems to deliver automatically generated\npersonalized recommendations to their customers.\n25\n\nMachine learning (ML) algorithms in Recommender systems are typically classiﬁed into two\ncategories:\n• Content-based approaches proﬁle users and items by identifying their characteristic features,\nsuch as demographic data for user proﬁling, and product information/descriptions for item\nproﬁling.\n• Collaborative ﬁltering approaches (CF) identify relationships between users and items and\nmake associations using the past user activities information to predict user preferences on new\nitems.\nA drawback of the ﬁrst approach is the necessity to collect information about users/items, and it\nis often tricky because the users must share their personal data for the creation of a database for\nproﬁling. The CF approach requires relatively fewer data, basically a list of tuples containing the\nuser ID, the item ID, and the rating done by the user to that item. Therefore, the CF algorithms\ncould be applied to RS independently of the domain of application.\nIn this thesis the focus is on CF, in which the basic data structure is the rating matrix, whose\nentries correspond to the rating of any possible user-item combination. Rating matrices are mostly\nsparse (many unknown entries): the key assumption is that the unknown ratings are predictable\nbecause the known ratings are often highly correlated across various users or items and once these\ncorrelations have been computed they can be used to ﬁll the matrix.\nThe problem is also called the matrix completion problem. Two types of methods are commonly\nused to solve it: the memory-based methods and model-based methods.\nThe memory-based methods, or neighbourhood-based algorithms, were among the earliest collabo-\nrative ﬁltering algorithms, in which the ratings of user-item combinations are predicted based on\ntheir neighbourhoods (users similar to a target user or items similar to a target item). They are\nbased on the fact that similar users display similar patterns of rating behaviour (user-based) or\nsimilar items receive similar ratings (item-based). These methods are simple to implement, and\nthe resulting recommendations are often easy to explain. It’s worth noting that the rating matrix\nis implicitly mapped into a graph, called “k-nearest neighbors graph” in which two users/items\n(vertices) i and j are connected by an edge if their distance is among the k-smallest distances from\ni to the other users/items j. Clearly the choice of the distance and the value k impact substantially\nthe performance of the method. Memory-based algorithms do not work very well with sparse rating\nmatrices: they scale poorly with the number of dimensions, and their predictions are not accurate\nfor user/item matrix with few ratings.\nThe model-based methods are based on the assumptions that the preferences of a user can be\ninferred from a small number of hidden or latent factors. The most successful realizations of latent\nfactor models are based on matrix factorization. This corresponds to a low-rank approximation of\nthe rating matrix (Equation 4.1), with the assumption of correlations between rows (or columns)\n26\n\nguarantee the dimensionality reduction of the matrix itself.\nR ≈P · Q\n(4.1)\nwhere P is a m × k matrix and Q is a k × n matrix. The RS problems becomes a minimization\nproblem, in which the decision variables are the elements of two low rank matrices whose product is\nas close as possible to the rating matrix. The number of optimization variables is still very high,\nk ×(n+m) instead of n×m, and the commonly used method is Stochastic Gradient Descent (SGD).\nThe ﬁne tuning of SGD raises the issue of hyperparameters optimization which is solved by BO in\n[52].\nThe main driver in the development of RSs has been so far the accuracy of recommendations. The\nincreasing heterogeneity of users’ demands has led to multiple metrics such as diversity and novelty\nwhich might conﬂict with each other. Generally speaking, the increase of diversity and novelty\nwill decrease accuracy. In addition, the increasing aware of ethical consideration has brawn to\nincreasing importance of fairness. This brings to multi-objective optimization in which solutions are\nthe elements of a Pareto set of non-dominated solutions. Matrix Factorization is not easily extended\nto take care of several objectives. The solutions proposed in [53, 54] that require the gradient,\nare based on linear sum scalarization, and do not guarantee a balanced approximation of the\nPareto set. To overcome the limitations of matrix factorization in Multi-Objectives Problem (MOP)\nMulti-Objectives Evolutionary Algorithms are considered in this thesis: many approaches have been\nproposed to this eﬀect, focusing also on novelty and diversity [55]. In this work a new method is\nproposed (Chapter 8) based on mapping the solution into a space of probability distributions.\n27\n\n\nChapter 5\nThe Wasserstein Distance\nThere are many measures in the literature that can be used to compare probability distributions.\nInformation theoretic based, like Kullback-Leibler and Jensen-Shannon, are the most used but can\nbecome undeﬁned if the compared distributions do not have identical support. Other measures like\nthe total variation or Hellinger distances do not provide a usable measure of distance for distributions\nwithout a signiﬁcant overlap.\nWasserstein distances have a sound mathematical basis, they are generally well deﬁned and provide\nan interpretable distance metric between distributions. Moreover, the Wasserstein distances are, at\nleast in most conditions, diﬀerentiable which makes them more suitable for learning and optimization.\nThese properties of the Wasserstein (WST) distances are built upon a deep mathematical framework\nwhich will be only hinted at in this work.\n5.1\nBasic deﬁnitions\nAn important feature of the WST distance is that it can be applied to discrete, mixed and continuous\ndistributions (Figure 5.1).\nConsider ﬁrst the continuous case. Given an exponent p ≥1 let f and g be two probability\ndistributions on Rd with ﬁnite p-moments, then the p-Wasserstein distance is (Equation 5.1):\nWp(f, g) =\n\u0012\ninf\nγ∈Γ(f,g)\nZ\nX×X\nd(x, y)pdγ(x, y)\n\u0013 1\np\n(5.1)\nwhere d(x, y) is also called ground distance (usually it is the Euclidean norm), Γ(f, g) denotes the\nset of all joint distributions γ(x, y) whose marginals are respectively f and g, and p ≥1 is an index.\n29\n\nFigure 5.1: An example of discrete and continuous distributions in 1-dimensional and 2-dimensional\ncase.\nThere are some speciﬁc cases, very relevant in applications, where WST can be written in an\nexplicit form. Let F and G be the cumulative distribution for the one-dimensional distributions f\nand g on the real line and F −1 and G−1 be their quantile functions (Equations 5.2).\nWp(f, g) =\n\u0012Z 1\n0\n\f\fF −1(x) −G−1(y)\n\f\fp\n\u0013 1\np\n(5.2)\nWasserstein distance is a measure of the distance between two probability distributions. It is also\ncalled Earth Mover’s Distance (EMD) from its informal interpretation as the minimum cost of\nmoving and transforming a pile of sand in the shape of one probability distribution to the shape\nof the other distribution. The cost is quantiﬁed by the amount of sand moved times the moving\ndistance. If the distribution domain is continuous the formula for the Earth Mover’s Distance is\n(Equation 5.3):\nWp(f, g) =\ninf\nγ∈Γ(f,g) E(x,y)∈γ [∥x −y∥p]\n1\np\n(5.3)\nOne joint distribution γ(x, y) ∈Γ(f, g) describes one transport plan: intuitively γ(x, y) indicates\nhow much mass must be transported from x to y in order to transform the distribution f into\nthe distribution g. Therefore, the marginal distribution over x adds up to P\nx γ(x, y) = g(y) and\nanalogously P\ny γ(x, y) = f(x). If x is the starting point and y the destination, the total amount of\nsand moved is γ(x, y) and the traveling distance is ∥x −y∥and thus the total cost is γ(x, y)∥x −y∥.\nThe expected cost averaged over all the (x, y) pairs can be computed as (Equation 5.4):\nX\nx,y\nγ(x, y)∥x −y∥= E(x,y)∼γ[∥x −y∥]\n(5.4)\nThe EMD is the cost of the optimal transport plan which is the minimum among the costs of all\nsand moving solutions.\nThe Wasserstein distance ﬁts in the framework of optimal transport theory. It can be traced back\n30\n\nto the work of Gaspard Monge (1781) [56] and received its modern linear programming formulation\nby Lev Kantorovich (1958) [57]. WST has been gaining increasing importance in several ﬁelds like\nImaging [58], Natural Language Processing (NLP) [59] and the generation of adversarial networks\n[60]. Some recent applications have been in the topic of Recommender Systems [61, 62, 63]. The\nmodelling ﬂexibility and computational eﬃciency of the WST distance have been also shown in\nthe design of neural architectural search [64]. The formulation, computation and generalization of\nthe WST distance require sophisticated mathematical models and raise challenging computational\nproblems: important references are [65, 66] which also give an up-to-date survey of numerical\nmethods.\nThe Wasserstein distance has two key advantages. Even in the cases when the distributions are\nsupported in diﬀerent spaces, also without overlaps, WST can still provide a meaningful repre-\nsentation of the distance between distributions. Another advantage of WST is its diﬀerentiability.\nThe former point will be exempliﬁed in Chapter 5.2; the latter point is illustrated in the following\nexample (Figure 5.2). Let Z = U(0, 1) be the uniform distribution on the unit interval. Let P\nbe the distribution of (0, Z) (0 on the x-axis and the random variable Z on the y-axis) and Pθ = (θ, Z).\n• KL(P, Pθ) = +∞if θ ̸= 0 and 0 if θ = 0\n• JS(P, Pθ) = log 2 if θ ̸= 0 and 0 if θ = 0\n• W(P, Pθ) = θ if θ ̸= 0 and 0 if θ = 0\nFigure 5.2: The two distributions P and Pθ. It is important to note that there is no overlap when\nθ ̸= 0.\n31\n\nTherefore, Wasserstein provides a smooth measure which is useful for any optimization and learning\nprocess using gradient descent [60], in particular for generation of adversarial networks in deep\nlearning [67, 68].\n5.2\nWasserstein over discrete distributions\nIn the case of discrete distributions and speciﬁcally histograms, Wasserstein clearly displays its\nadvantage over information theory based measures as shown in Figure 5.3 [69]. Each probability\ndistribution is modelled as a histogram in which each bin has a weight and a coordinate in a\nmultidimensional vector space. For instance, when measuring the distance between grey-scale\nimages, the histogram weights are given by the pixel values and the coordinates are deﬁned by the\nrespective pixel positions.\nFigure 5.3: The table compares diﬀerent probabilistic distances between the three histograms\ndisplayed in the ﬁgure. It is clear how the Wasserstein distance is the more interpretable one.\nThe Earth Mover’s Distance (EMD) can be considered as the discrete version of the Wasserstein\ndistance and can be used to quantify the aﬃnity between discrete probability distributions. The\ndistance between two histograms is calculated as the cost of transforming one into the other.\nTransforming a ﬁrst histogram into a second one involves moving weights from the bins of the ﬁrst\nhistogram into the bins of the second, thereby constructing the second histogram from the ﬁrst.\nThe goal is to minimize the total distance travelled, where the pairwise distances between diﬀerent\nhistogram bins are computed based on their respective coordinates. This optimization problem is\nwell studied in transportation theory.\nLet P be a discrete distribution speciﬁed by a set of support points xi with i = 1, . . . , m and their\nassociated probabilities wi such that Pm\ni=1 wi = 1 with wi ≥0 and xi ∈M for i = 1, . . . , m. Usually,\nM = Rd is the d-dimensional Euclidean space with the Lp norm and xi are called the support\nvectors. M can also be a symbolic set provided with a symbol-to-symbol similarity.\n32\n\nP can also be written using the notation (Equation 5.5):\nP(x) =\nm\nX\ni=1\nwiδ(x −xi)\n(5.5)\nwhere δ(·) is the Kronecker delta. The WST distance between two distributions P (1) = {w(1)\ni\n, x(1)\ni }\nwith i = 1, . . . , m1 and P (2) = {w(2)\ni\n, x(2)\ni } with i = 1, . . . , m2 is obtained by solving the following\nlinear programming problem (Equation 5.6):\nW(P (1), P (2)) = min\nγij∈R+\nX\ni∈I1,j∈I2\nγijd\n\u0010\nx(1)\ni , x(2)\nj\n\u0011\n(5.6)\nwhere I1 = {1, . . . , m1} and I2 = {1, . . . , m2} are two index sets such that (Equations 5.7 and 5.8):\nX\ni∈I1\nγij = w(2)\nj , ∀j ∈I2\n(5.7)\nX\nj∈I2\nγij = w(1)\ni\n, ∀i ∈I1\n(5.8)\nThe cost of transport between x(1)\ni\nand x(2)\nj , d(x(1)\ni , x(2)\nj ), is deﬁned by the p-th power of the norm\n∥x(1)\ni , x(2)\nj ∥, usually the Euclidean distance.\nEquations 5.7 and 5.8 represent the in-ﬂow and out-ﬂow constraint, respectively. The terms γij\nare called matching weights between support points x(1)\ni\nand x(2)\nj\nor the optimal coupling for P (1)\nand P (2). The basic computation of Optimal Transport (OT) between two discrete distributions\ninvolves solving a network ﬂow problem whose computation scales typically cubic in the sizes of the\nmeasure. The computation of EMD turns out to be the solution of a minimum cost ﬂow problem\non a bi-partite graph where the bins of P (1) are the source nodes and the bins of P (2) are the sinks\nwhile the edges between sources and sinks are the transportation costs.\nIn the case of one-dimensional histograms, the computation of WST can be performed by a simple\nsorting and the application of Equation 5.9:\nW(P (1), P (2)) =\n \n1\nn\nn\nX\ni=1\n\f\f\fx(1)∗\ni\n−x(2)∗\ni\n\f\f\f\n!\n(5.9)\nwhere x(1)∗\ni\nand x(2)∗\ni\nare the sorted samples.\n5.3\nBarycenters and Wasserstein clustering\nProbability distributions can be viewed as over an underlying feature domain. Multidimensional\ndistributions are deﬁned as histograms by partitioning the underlying domain into bins with a\n33\n\nmass associate to each bin. Deﬁning a distance between distributions requires a notion of distance\nbetween points in the underlying domain: this is called the ground distance. If the ground distance\nis a metric and the distributions have the same mass (which is true in the case of PDF), EMD is\na metric as well. EMD does not suﬀer from arbitrary quantization problems due to rigid binning\nstrategies. Therefore, it is robust to errors in the transformations that take raw data into the feature\nspace.\nConsider a set of N discrete distributions, P = {P (1), . . . , P (N)}, with P (k) = {(w(k)\ni\n, x(k)\ni\n) : i =\n1, . . . , mk} and k = 1, . . . , N, then, the associated barycenter, denoted with ¯P = {( ¯w1, x1), . . . , ( ¯wm, xm)},\nis computed as follows (Equation 5.10:\n¯P = argmin\nP\n1\nN\nN\nX\nk=1\nλkW\n\u0010\nP, P (k)\u0011\n(5.10)\nwhere the values λk are used to weight the diﬀerent contributions of each distribution in the\ncomputation. Without loss of generality, they can be set to λk = 1\nN ∀k = 1, . . . , N.\nThe Wasserstein barycenter, also called the Frechet mean of distributions, appears to be a meaningful\nfeature to represent the mean variation of a set of distributions and oﬀers a useful synthesis of the\nstructure of probability distributions, in particular:\n• It is sensitive to the underlying geometry. Consider three distributions P (1) = δ0, P (2) = δε\nand P (3) = δ100, then W(P (1), P (2)) ≈0, W(P (1), P (3)) ≈W(P (2), P (3)) ≈100. The distances\nTotal variation, Hellinger and Kullback-Leibler take the value 1, thus they fail to capture the\nintuition that P (1) and P (2) are close to each other while they are far away from P (3).\n• It is shape preserving. Denote P (1), . . . , P (N) and assume that each P (j) can be written\nas a location shift of any other P (i), with i ̸= j.\nSuppose that each P (j) is deﬁned as\nP (j) = N(µj, Σ), then the barycenter has the closed form (Equation 5.11):\n¯P = N\n\n1\nN\nN\nX\nj=1\nµj, Σ\n\n\n(5.11)\nin contrast to the (Euclidean) average of the distributions\n1\nN\nPN\nj=1 P (j).\nTherefore, the concept of barycenter enables clustering among distributions, in a space whose metric\nis the Wasserstein distance. More simply, the barycenter in a space of distributions is the analogue\nof the centroid when the clustering takes place in a Euclidean space. The most common and\nwell-known algorithm for clustering data in the Euclidean space is k-means. Since it is an iterative\ndistance-based (aka representative based) algorithm, it is easy to propose variants of k-means by\nsimply changing the distance adopted to create clusters, such as the Manhattan distance (leading to\nk-medoids) or any kernel allowing for non-spherical clusters (i.e., kernel k-means). The crucial point\n34\n\nis that only the distance is changed, while the overall iterative two-step algorithm is maintained.\nThis is also valid in the case of the Wasserstein k-means, where the Euclidean distance is replaced\nby WST and centroids are replaced by barycenters:\n• Step 1 - Assign. Given the current k barycenters at iteration t, namely ¯P (1)\nt\n, . . . , ¯P (k)\nt\n,\nclusters C(1)\nt\n, . . . , C(k)\nt\nare identiﬁed by assigning each one of the distributions P (1), . . . , P (N)\nto the closest barycenter (Equation 5.12):\nC(i)\nt\n=\n\n\nP (j) ∈P : ¯P (i)\nt\n=\nargmin\nQ={ ¯P (1)\nt\n,..., ¯P (k)\nt\n}\nW(Q, P (j))\n\n\n, ∀i = 1, . . . , k\n(5.12)\n• Step 2 - Optimize. Given the new composition of the clusters, update the barycenters\n(Equation 5.13):\n¯P (i)\nt+1 = argmin\nQ\n1\n\f\f\fC(i)\nt\n\f\f\f\nX\nP∈C(i)\nt\nW(Q, P)\n(5.13)\nthat comes directly from Equation 5.10.\nAs in k-means, a key point of Wasserstein k-means is the initialization of the barycenters. In the\ncase that all the distributions in P are deﬁned on the same support, then they can be randomly\ninitialized, otherwise, a possibility is to start from k distributions randomly chosen among those in\nP. Finally, termination of the iterative procedure occurs when the result of the assignment step\ndoes not change any longer or a preﬁxed maximum number of iterations is achieved.\n5.4\nApproximations and computational issues\nThe issue of computational complexity of WST has been investigated also in the context of k-Nearest\nNeighbourhood (k-NN) ﬁrst in [70] then in [62] where an approximate Nearest Neighbour Search\nis proposed for the W1 distance in the context of image retrieval. The “ground” set is a ﬁnite set\nof Rd and each distribution over X has a ﬁnite support. Given a data set of n distributions, the\nk-distributions closer to a target v in the Wasserstein space are looked for.\nRecently, Atasu and Mittelholzer [71] proposed new approximate algorithms resulting in more\naccurate estimates that can be computed in linear time.\n35\n\n\nChapter 6\nMOEA with Wasserstein\nThis chapter presents the key algorithmic element of this thesis, a new evolutionary algorithm,\nnamely MOEA/WST (Multi-Objective Evolutionary Algorithm with Wasserstein), based on a\ndistributional representation of the individual.\n6.1\nGeneral framework\nMOEA/WST starts sampling the initial population, i.e., a set of candidate solutions of the problem,\nalso called individuals. For instance, in the case of sensor placement problem the individuals are the\nbinary vectors encoding the sensor placements as explained in Chapter 7; in the case of recommender\nsystems, the population is composed by a set of top-L rating matrices as explained in Chapter 8.\nThe initial individuals of the population are randomly sampled from the entire search space. The\nonly constraint is that all the individuals have to be diﬀerent (sampling without replacement).\nIn the next step for each candidate solution in the population all the objective functions are evaluated.\nAmong this population only the non-dominated solutions are selected, i.e., the Pareto set as in\nChapter 2. After that, the selection, crossover and mutation operators are used to generate the new\noﬀspring until a given number of new individuals are created. The newly generated individuals are\nadded to the population and the next generation starts. The individuals that “survive” between\na generation and the next one are chosen based on the dominance and the crowding distance as\nin NSGA-II. This process is repeated until a termination criteria is met, as a given number of\ngeneration or function evaluations.\nFigure 6.1 schematize the optimization process of MOEA/WST. In particular, the innovation of\nMOEA/WST is given by the new selection operator that will be discussed in the next section.\n37\n\nFigure 6.1: The general framework of MOEA/WST.\n6.2\nWasserstein based selection operator\nIn order to select the pairs of parents to be mated using the crossover operation, in MOEA/WST a\nnew selection method has been introduced which takes place into a space of probability distributions.\nThe idea that enables this operator is that, in some problem, the information in the input space can\nbe represented in an intermediate space of distributions, before computing the objective functions.\nTwo particular instances of this kind of problem will be discussed in Chapter 7 and 8 respectively.\nThis new selection operator, ﬁrst, randomly sample from the actual Pareto set two pairs of individuals\n(F1, M1) and (F2, M2). To choose between this two pairs of candidate parents a binary tournament\nis computed. Diﬀerently from NSGA-II this tournament is not based on the non-dominated sorting\nand the crowding distance, but on the distance between parents in each pair (Figure 6.2).\nSince in some situation a distance in the search space can be misleading, as deeply discussed in\nChapter 7.6, in MOEA/WST, a distance between the distributional representation of the candidate\nparents has been considered. Therefore, assume that h(Fi) and h(Mi) are the distributions associated\nto Fi and Mi respectively. Then the pair (Fi, Mi) that is chosen as the parents of the new oﬀspring\nis the one in which (Equation 6.1):\ni = argmax\ni∈{1,2}\nd(h(Fi), h(Mi))\n(6.1)\nThis favours exploration and diversiﬁcation. Any probabilistic distance could be considered, but for\nthe reason discussed in Chapter 5, in MOEA/WST the Wasserstein distance has been used.\nIn the case in which the problem is constrained, if at least one individual of the pair of parents is\nnot feasible the Constraint Violation (CV) is considered instead.\n38\n\nFigure 6.2: Two pairs of individuals are sampled from the Pareto front. As parents of the new\noﬀspring, the most diﬀerent pair is chosen. In this case F2 and M2 will be the parents of the new\noﬀspring.\nThen the pair of parents (Fi, Mi) is chosen according to Equation 6.2.\ni = argmin\ni∈{1,2}\n{CV (Fi), CV (Mi)}\n(6.2)\n6.3\nProblem speciﬁc crossover operator\nThe crossover is executed in the input space and for this reason it depends on the encoding of\nthe individuals. Problem tailored crossover operators can substantially improve the performance\n[28]. For the sensor placement problem, a problem speciﬁc crossover operator has been introduced\nwhich generates two “feasible-by-design” children from two feasible parents chosen according to the\nprevious selection.\nDenote with x, x′ ∈{0, 1}d two feasible parents and with J and J′ the two associated sets\nJ = {i : xi = 1} and J′ = {i : x′\ni = 1}. Finally, denote with c, c′ ∈{0, 1}d the two children\nof x and x′. In turn, every child c samples an index from J and c′ from J′, respectively FatherPool\nand MatherPool without replacement. This guarantees to have no children with more than p\nnon-zero components.\nFigure 6.3 shows an example comparing the behaviour of this problem speciﬁc crossover com-\npared to a typical 1-point crossover.\n39\n\nFigure 6.3: The comparison between one-point crossover and problem speciﬁc crossover.\n40\n\nChapter 7\nWater Distribution Networks\nThis chapter focus on the analysis of Water Distribution Networks (WDNs), in terms of resilience\nand vulnerability, and on the problem of detecting contamination in the water ﬂow.\nThe key element of this chapter is given by the representation of WDNs as discrete distributions\nwhich allows the deﬁnition of a new framework through the Wasserstein distance. This enables the\nuse of MOEA/WST.\n7.1\nWater networks\nA Water Distribution Network (WDN) is a complex system aims to carry potable water from a\nwater treatment plant to consumers in order to deliver water to satisfy residential, commercial, and\nindustrial needs.\nThe main components of a WDN are pumps, junctions, and pipes. Additional components are tanks\nto store water and valves to isolate equipment, buildings, and other areas of the water system for\nrepair as well as to control the direction and rate of ﬂow.\nIn this thesis ﬁve WDN models are considered.\nThe following three are benchmarks models:\n• Net1 (Figure 7.1a) is a small WDN provided by EPANET and WNTR, whose associated\ngraph consists of 11 nodes (1 reservoir, 1 tank and 9 junctions) and 13 pipes.\n• Hanoi (Figure 7.1b) is a benchmark used in the literature. It has 32 nodes (1 reservoir and\n31 junctions) and 34 pipes.\n• Anytown (Figure 7.1c) is another benchmark WDN, whose graph consists of 25 nodes (1\nreservoir, 2 tanks and 22 junctions) and 46 edges (3 pumps and 43 pipes).\n41\n\n(a) Net1\n(b) Hanoi\n(c) Anytown\nFigure 7.1: A schematic representation of the three benchmark WDNs.\nThe other two networks are real world-size WDNs:\n• Neptun (Figure 7.2a) is the WDN of the Romanian city of Timisoara, with an associated\ngraph of 333 nodes (1 reservoir and 332 junctions) and 339 edges (27 valves and 312 pipes).\n• Abbiategrasso (Figure 7.2b) refers to a pressure management zone in Milan (namely, Abbi-\nategrasso) with an associated graph consisting of 1213 nodes (1 reservoir and 1212 junctions)\nand 1393 edges (4 pumps, 4 valves and 1385 pipes).\nThese lasts two networks have been a pilot in the European project Icewater [72].\n(a) Neptun\n(b) Abbiategrasso\nFigure 7.2: A schematic representation of the two real word-size WDNs\n42\n\n7.2\nWasserstein for resilience evaluation\nGiven a graph G = (V, E) it is possible to associate to each node i = 1, . . . , n a discrete probability\ndistribution (Equation 7.1) as the fraction of nodes which are connected to i at a distance k:\nPk(i) = ni,k\nn −1\n(7.1)\nFigure 7.3 displays the distribution of the highlighted node of Anytown.\n(a) G′ is obtained removing the red edge of Anytown\n(G).\n(b) The node-node distances distribution of the high-\nlighted node.\nFigure 7.3: The Anytown water distribution network and an example of node-node distances\ndistribution.\nThe support of this distribution is 1, . . . , D(G) where D(G) is the diameter of G. The distance\ndistribution over the whole network is shown in Equation 7.2.\nPk(G) = 1\nn\nn\nX\ni=1\nni,k\nn −1 = 1\nn\nn\nX\ni=1\nPk(i)\n(7.2)\nLet G′ be the graph without the red edge and consider the distributions P = Pk(G) (Equation 7.3)\nand P ′ = Pk(G′) (Equation 7.4). In the case of Anytown D(G) = 8 and the two histograms are\ndisplayed in Figure 7.4\nP(G) = [0.147, 0.263, 0.297, 0.177, 0.083, 0.030, 0.003, 0]\n(7.3)\nP(G′) = [0.133, 0.237, 0.290, 0.183, 0.100, 0.043, 0.010, 0.003]\n(7.4)\nThe most widely used distance measure is the Kullback-Leibler (KL) divergence (Equation 7.5)\nwhich has the drawback of being asymmetric and possibly inﬁnite when there are points x such\n43\n\nthat P(x) = 0 and P ′(x) ≥0.\nKL\n\u0012\nP\n\f\f\f\f\nP + P ′\n2\n\u0013\n=\nZ\nP log\n2P\nP + P ′ dx\n(7.5)\nThe Jensen-Shannon (JS) divergence (Equation 7.6) is built on KL and is symmetric and always\ndeﬁnite.\nJS(P, P ′) = 1\n2KL\n\u0012\nP\n\f\f\f\f\nP + P ′\n2\n\u0013\n+ 1\n2KL\n\u0012\nP ′\n\f\f\f\f\nP + P ′\n2\n\u0013\n(7.6)\nFigure 7.4: The node-node distance distributions at network level of G and G′.\nThe use of Jensen-Shannon divergence in computing the dissimilarity between networks has been\nconsidered in [73]. To obtain a metric is often used the following form (Equation 7.7):\nJ S(P, P ′) =\np\nJS(P, P ′) ∈[0, 1]\n(7.7)\nIn the considered problem the network space is given by the basic network G and the subgraphs\nobtained by the removal of one or more edges. The elements of this space are represented as\nprobability distributions of node-node distances (Equation 7.1) and aggregated into a distributional\nrepresentations of the basic network and of the subgraphs (Equation 7.2). Given the drawbacks of\nKL and JS illustrated in Chapter 5, in the space of distributional representation the Wasserstein\ndistance is used as introduced in [74]. The result of this computation is mapped back into the\n44\n\nnetwork space as measures of network dissimilarity and labels of criticality of individual components.\nResults on real-word WDN\nFirstly, the centrality measures of the networks, Neptun and Abbiategrasso, are analysed (Table\n7.1). This two real-world WDNs are eﬀectively planar and “almost” regular. This can be due to the\nfact that their structure is strongly constrained by spatial characteristics making a classiﬁcation\nbased on nodal degree distribution less meaningful.\nTable 7.1: Centrality measure (deﬁned in Appendix A.1) of the two WDN, Neptun and Abbiategrasso.\nMeasure\nNeptun\nAbbiategrasso\nDiameter\n57\n83\nCharacteristic path length\n23.7613\n30.6126\nDensity\n0.0061\n0.0019\nLink-per-node ratio\n0.0019\n1.1467\nCentral point dominance\n0.2432\n0.3100\nClustering coeﬃcient\n0.0000\n0.0055\nThe second step in the analysis is clustering in order to identify the speciﬁc edges whose removal\ninduces a disconnection of the network (Figure 7.5).\nThe number of clusters k is set according to context information about the districtualization adopted\nby the water utility. Failures aﬀecting also only one pipe may imply a reduction in the eﬃciency of\nthe network and an increase in vulnerability.\n(a) The two critical edges (red) whose simultaneous\nremoval generates a disconnection in Neptun.\n(b) The three critical edges (red) whose simultaneous\nremoval generates a disconnection.\nFigure 7.5: The spectral clustering results over the two WDN, Neptun (with k = 2) and Abbiategrasso\n(with k = 3).\nOnce the edges identiﬁed by the clustering are removed the eﬃciency and vulnerability metrics are\n45\n\ncomputed (Table 7.2).\nThen, the probabilistic distances between the original networks and the once without the edges\nidentiﬁed by cluster are computed (Table 7.3).\nThe results reported in Table 7.2 and 7.3, which are quite unique in the literature given the size of\nthe networks analysed, demonstrate that probabilistic distance measures show better capacity to\ndiscriminate between diﬀerent networks not only globally but also edge-wise.\nTable 7.2: Eﬃciency and vulnerability metrics (deﬁned in Appendix A.2) of the two WDN, Neptun\nand Abbiategrasso. The algebraic connectivity λ2 is deﬁned as the second smallest eigenvalue of the\nLaplacian associated to the graph; λ2 = 0 means that the graph is disconnected.\nNeptun\nEEE\nVMEAN\nVMEAN\nVMEAN\nVMAX\nVMAX\nVMAX\nAlgebraic connectivity\nG\n0.068608\n0.018927\n0.072646\n0.0018\nG \\ {e1}\n0.065390\n0.024181\n0.211362\n0.0007\nG \\ {e2}\n0.064486\n0.024796\n0.194813\n0.0006\nG \\ {e1, e2}\n0.051924\n0.016642\n0.068246\n0.0000\nAbbiategrasso\nEEE\nVMEAN\nVMEAN\nVMEAN\nVMAX\nVMAX\nVMAX\nAlgebraic connectivity\nG\n0.047557\n0.003436\n0.150390\n0.0004\nG \\ {e1}\n0.045019\n0.003935\n0.181174\n0.0003\nG \\ {e2}\n0.046385\n0.003642\n0.205294\n0.0004\nG \\ {e3}\n0.040405\n0.002628\n0.060728\n0.0000\nG \\ {e1, e2, e3}\n0.031077\n0.002251\n0.057007\n0.0000\nTable 7.3: Probabilistic distances and loss of eﬃciency (deﬁned in Appendix A.2) between the\noriginal networks (Neptun and Abbiategrasso) and the once obtained removing some edges.\nNeptun\nJ S\nJ S\nJ S\nW\nW\nW\nLoss of eﬃciency\nG \\ {e1}\n0.1677\n3.3183\n0.0469\nG \\ {e2}\n0.2456\n5.4704\n0.0601\nG \\ {e1, e2}\n0.3286\n6.5542\n0.2432\nAbbiategrasso\nJ S\nJ S\nJ S\nW\nW\nW\nLoss of eﬃciency\nG \\ {e1}\n0.0935\n3.1040\n0.0534\nG \\ {e2}\n0.0528\n1.5170\n0.0246\nG \\ {e3}\n0.1843\n5.4871\n0.1504\nG \\ {e1, e2, e3}\n0.3633\n8.8845\n0.3465\nTo highlight this fact the heatmap of edge wise criticality, as Wasserstein distance, are shown in\nFigure 7.6.\nThis analysis framework supports decision making at design stage, to simulate alternative network\nlayouts of diﬀerent robustness, and also at operational stage where the decision to be taken can\nbe, which nodes/edges are to temporarily be removed for maintenance and rehabilitation. Indeed,\n46\n\ncritical tasks of WDN management can be supported by just using topological and geometric\ninformation. The analysis framework also helps for the eﬃcient and automatic deﬁnition of district\nmetered areas and to facilitate the localization of water losses through the deﬁnition of an optimal\nnetwork partitioning.\nThe modelling and algorithmic framework platform developed can be straightforwardly translated to\nmany networked infrastructures among which power grids, transit networks but also global supply\nchains networks whose vulnerability has been exposed in the recent COVID crisis.\n(a) Heatmap of the Wasserstein distance for all edges\nin Neptun.\n(b) Heatmap of the Wasserstein distance for all edges\nin Abbiategrasso.\nFigure 7.6: The color of each edge e depends on W(G, G \\ {e}), i.e., the Wasserstein distance\nbetween the original graph G and the one obtained removing the edge G \\ {e}.\n7.3\nHydraulic and quality simulation\nWater Distribution Networks face multiple challenges such as aging infrastructure, natural disasters,\nterrorist attack and much more. All these problem can potentially disrupt a large portion of a water\nsystem causing damage to infrastructure and outages to customers. Simulation and analysis tools\ncan help to explore the capacity of a WDN to handle disruptive events and guide the necessary\noperations to make a system more resilient over time.\nThe Water Network Tool for Resilience (WNTR) [75] is a Python package designed to simulate and\nanalyse resilience of WDNs. WNTR is based on EPANET 2.0, which is a tool to simulate ﬂowing\nof drinking water constituents within a WDN. WNTR contains an hydraulic and water quality\nsimulator that tracks the ﬂow over time of a contaminant injected in a speciﬁc location.\nThe simulation is computationally costly and scales linearly with the inverse of the simulation\ntimestep. To consider diﬀerent location in which the contaminant can be injected, it is necessary\nto run one simulation for each contamination event. The result of these simulations is a matrix,\nthe so-called Trace Matrix, which contains the percentage of contaminant in a speciﬁc location for\n47\n\neach event and simulation time. From the Trace Matrix is possible to extract the detection times\nmatrix that reports, for each node considered as a possible sensor location, the detection times of all\nthe diﬀerent contamination events. The detection takes place when the percentage of contaminant\nexceeds a given threshold (in the computation case τ ≥10%).\n7.4\nThe problem of sensors placement\nConsider a graph G = (V, E) and a set of possible locations for placing sensors L ⊆V . Thus,\na Sensor Placement (SP) is a subset of sensor locations, with the subset’s size less or equal to p\ndepending on the available budget. A SP is represented by a binary vector s ∈{0, 1}|L| whose\ncomponents are si = 1 if a sensor is located at node i, si = 0 otherwise. Therefore, a SP is given by\nthe nonzero components of s. An example, considering Net1, is given by s = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\nwhich means that two sensors are placed respectively at nodes 9 and 11, as shown in Figure 7.7.\nFigure 7.7: Example of a sensor placement in Net1. Sensors are placed at nodes 9 and 11.\nFor a WDN the vertices in V represent junctions, tanks, reservoirs or consumption points, and\nedges in E represent pipes, pumps, and valves.\nLet A ⊆V denote the set of contamination events a ∈A (i.e., the locations in which the contaminant\ncan be injected) which must be detected by a sensor placement s, and dai the impact measure\nassociated to a contamination event a detected by the i-th sensor. A probability distribution is\nplaced over possible contamination events associated to the nodes. In the computations assume –\nas usual in the literature – a uniform distribution, but in general diﬀerent distributions are also\npossible.\n48\n\nIn this thesis a general model of sensor placement is considered (Equation 7.8).\nmin\ns∈{0,1}|L|\nf1(s) =\nX\na∈A\nαa\n|L|\nX\ni=1\ndaixai\ns.t.\n|L|\nX\ni=1\nsi ≤p, si ∈{0, 1}\n(7.8)\nwhere:\n• αa is the probability for the contaminant to enter the network at node a.\n• dai is the impact for a sensor located at node i to detect the contaminant introduced at node\na.\n• xai is an indicator variable assuming value 1 if si = 1 and i is the ﬁrst sensor in the placement\ns detecting the contaminant injected at node a, i.e., the one with the minimum possible\nimpact; 0 otherwise.\nIn this study assume that all the events have the same chance of happening, that is αa =\n1\n|A|,\ntherefore f1(s) can be rewritten as (Equation 7.9):\nf1(s) = 1\n|A|\nX\na∈A\nˆta\n(7.9)\nwhere ˆta = P|L|\ni=1 daixai.\nAs a measure of risk, the standard deviation is considered (Equation 7.10).\nf2(s) = STDf1(s) =\ns\n1\n|A|\nX\na∈A\n(ˆta −f1(s))2\n(7.10)\nThis model can be specialized to diﬀerent objective functions as:\n• Detection time: the impact dai is the minimum detection time (MDT). For each event a\nand sensor placement s the MDT is deﬁned as MDTa = mini:si=1 dai.\n• Volume of contaminated water: the impact dai represents the amount of contaminated\nwater consumed prior to detection for scenario a and sensor located in i.\n• Probability of detection: the impact dai represents the probability for a sensor in node i\nto detect an event in a during the simulation period. dai is modelled as a Bernoulli random\nvariable assuming value 1 if the detection takes place and 0 otherwise, i.e., no detection at\ntime t of a concentration larger than τ.\nIn this study the detection time has been considered as the measure of impact in Equation 7.8.\n49\n\n7.5\nDistributional representation of sensor placements\nSensor Matrices\nDenote with Sℓthe so-called “sensor matrix”, where ℓ= 1, . . . , |L| is an index identifying the location\nwhere the sensor is deployed at. Each entry sℓ\nta represents the concentration of the contaminant for\nthe event a ∈A at the simulation step t = 0, . . . , K, with Tmax = K∆t. Without loss of generality,\nassume that the contaminant is injected at the beginning of the simulation (i.e., t = 0).\nFigure 7.8 shows the heatmaps of two sensor matrices of Net1, regarding respectively the nodes\n9 and 11. In this example, all the nodes are considered as possible sensor locations and all the\nnodes but 1 (the tank) and 2 (the reservoir) are considered as events (i.e., location in which the\ncontaminant can be injected).\n(a) Sensor placed at node 9.\n(b) Sensor placed at node 11.\nFigure 7.8: Examples of sensor matrices considering Net1 WDN.\nAnalogously, a “sensor placement matrix”, H(s) ∈R(K+1)×|A|, is deﬁned (Figure 7.9), where every\nentry hta represents the maximum concentration over those detected by the sensors in s, for the\nevent a and at time step t. Suppose to have a sensor placement s consisting of m sensors with\nassociated sensor matrices S1, . . . , Sm, then hta = maxj=1,...,m sj\nta ∀a ∈A.\nThere is a relation between s and the associated H(s): more precisely, the columns of H(s) having\nmaximum concentration at row t = 0 (i.e., injection time) are those associated to events with\ninjection occurring at the deployment locations of the sensors in s.\nMoreover, H(s) is the basic data structure on which MDT is computed. Unfortunately, the main\nissue is that it is not possible to work directly with sensor placement matrices. In searching for\nan optimal vector s, H(s) is just an additional observable information before computing the two\nobjectives f1(s) and f2(s).\n50\n\nFigure 7.9: Example of a placement matrix. Two sensors placed at node 9 and 11 respectively.\nPlacement Histogram\nThe information in H(s) about a placement can be represented as an histogram h(s) (Figure 7.10).\nConsider the time steps in the simulation ∆ti = ti −ti−1 where i = 1, ..., k are equidistanced in the\nsimulation time horizon (0, Tmax) with Tmax = k∆t, ∆t = 1 and k = 24. Consider also the discrete\nrandom variable |Ai| where Ai = {a ∈A : ˆta ∈∆ti}. To each sensor placement s it is possible to\nassociate not only the placement matrix H(s) but also the histogram h(s) whose bins are ∆ti and\nweights are |Ai|. In other words, each bin of the histogram h(s) represents the number of events\nthat are detected in a speciﬁc time range by s: these values can be extracted from the placement\nmatrix H(s); indeed, each column of this matrix represents an event, and the detection time of this\nevent is given by the row in which the contaminant concentration exceed a given threshold τ.\nFigure 7.10: Example of a placement histogram of Net1 WDN. Two sensors placed at node 9 and\n11 respectively. This histogram corresponds to the placement matrix displayed in Figure 7.9\nAn extra bin has been added (86400 to 90000) whose weight |Ak+1| represents for any sensor\n51\n\nplacement the number of contamination events which were undetected during the simulation (and\nhence the detection probability). The relation between SP and histograms is many to one: one\nhistogram indeed can be associated to diﬀerent SP. Intuitively the larger the probability mass in\nlower ∆ti the better is the sensor placement; the larger the probability mass in the higher ∆t\nthe worse is sensor placement. The worst SPs are those for which no detection took place in the\nsimulation horizon. An “ideal” placement can be deﬁned as the histogram in which |A1| = |A|.\n7.6\nSearch, Information and Objective space\nThe search space consists of all the possible SPs, given a set L of possible locations for their\ndeployment, and resulting feasible with respect to the constraints in (Equation 7.8); formally, the\nfeasible set is Ω=\nn\ns ∈{0, 1}|L| : P|L|\ni=1 si ≤p\no\n. As already mentioned, the computation of the two\nobjectives f1(s) and f2(s) requires the trace of the quality simulation. Beyond the computation of\nf1 and f2 matrix H(s) and histogram h(s) oﬀer a much richer representation. This entire process\ncan be schematized as in Figure 7.11.\nFigure 7.11: An example of how PI selects the new point.\nThen the Wasserstein distance, introduced in Chapter 5, can be used to explore the information\nspace. Any distance in Ωcan be highly misleading, in that two SPs s and s′ distant in Ωmight\ncorrespond to close values of H(s) and H(s′) sensor placement matrix, leading to close points in the\nobjective space. This means that the landscape of the problem may have a huge number of global\noptima, also signiﬁcantly distant among them in Ω. Indeed, assume to have s, s′ : d(s, s′) = dmax\n(e.g., if d(·, ·) is the Hamming distance, s = (0, 1, 0, 1, . . .) and s′ = (1, 0, 1, 0, . . .)), then it is anyway\npossible to have δ(H(s), H(s′)) ⋍0, and to observe (f1(s), f2(s)) ⋍(f1(s′), f2(s′)) with δ(·, ·) a\n52\n\nsuitable distance between matrices. In this thesis the landscape is explored through histograms in\nthe information space and their Wasserstein distance.\n7.7\nComputational settings\nSince the compared algorithms are non-deterministic algorithms, it is necessary to perform multiple\nrun of them to obtain statistically robust results. In particular, 30 runs of each algorithm have been\nperformed. In the two evolutionary algorithms, NSGA-II and MOEA/WST as mutation operator,\nthe Pymoo implementation of Bitﬂip Mutation [76] is used, with a probability of mutation equal to\n0.5.\nIn MOEA/WST a new problem speciﬁc crossover operator has been deﬁned and used, as described\nin Chapter 6.3, while in NSGA-II the Pymoo implementation of the one-point crossover [76] has\nbeen used. In these experiments, a population of 40 individuals is considered and at each generation\nan oﬀspring of 10 new chromosome is generated for a total of 100 generations in the case of Hanoi\nand 250 generations in the case of Neptun. The initial population is sampled randomly.\nTo make the comparison fair with qParEGO, in the experiments, q = 10 is considered. In this way,\nin each iteration of BO, a batch of 10 new points are observed.\n7.8\nComputational results\nHanoi\nFigures 7.12 and 7.13 display the average value and standard deviation of hypervolume (y-axis)\nobtained from experiments for diﬀerent values of p. In each experiment 30 replications have been\nperformed to generate the estimation sample. Given the signiﬁcant computation overhead inherent\nin ParEGO two diﬀerent units in the x-axis have been used: number of generations for MOEA/WST\nand NSGA-II and iterations for ParEGO on the left, while on the rights the units are wall-clock\ntime.\nIn terms of hypervolume MOEA/WST and NSGA-II oﬀer a balanced performance. In terms of\nwall-clock time NSGA-II has an advantage due to the computations of the Wasserstein distances\nrequired by MOEA/WST.\nParEGO tells a diﬀerent story: the sample eﬃciency of Bayesian optimization is transferred to\nParEGO which reaches much earlier than other methods high values of hypervolume. It is fair to\nsay that the advantage of ParEGO is oﬀset by a signiﬁcant computational overhead due to the\nupdating of the mean and variance of the Gaussian process and in particular the inversion of the\ncovariance matrix. Even if the BoTorch implementation of ParEGO is highly optimized, the impact\nof this overhead is clearly shown by the wall-clock time displayed in Figure 7.12 and 7.13.\n53\n\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure 7.12: Hypervolume curves of the three algorithms in the case of budget ≤3.\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure 7.13: Hypervolume curves of the three algorithms in the case of budget ≤7.\nThe diﬀerence in values of hypervolume between MOEA/WST, NSGA-II and qParEGO has been\ntested for statistical signiﬁcance for diﬀerent values of p and diﬀerent generations/iterations counts.\nA Wilcoxon test for MOEA/WST and NSGA-II for the samples in generations 25/50/100 (each\nnew generation requires 10 function evaluations) is used (Table 7.4). The null hypothesis (H0) is\nthat the samples are from the same distribution.\n54\n\nTable 7.4: Comparing hypervolume of MOEA/WST against those of the other two approaches\n(values are ×109) and with respect to diﬀerent budgets p and number of generations. Statistical\nsigniﬁcance has been investigated through a Wilcoxon test (p-value is reported).\nppp\nGenerations\nMOEA/WST\nNSGA-II\nParEGO\nMOEA/WST\nvs NSGA-II\np-value\nMOEA/WST\nvs ParEGO\np-value\n3\n25\n0.2188\n(0.3790)\n0.2190\n(0.4538)\n0.2496\n(0.1641)\n0.811\n<0.001\n50\n1.0828\n(0.5942)\n1.5883\n(0.2969)\n<0.001\n<0.001\n100\n2.0769\n(0.2225)\n2.2808\n(0.1601)\n<0.001\n<0.001\n7\n25\n2.0421\n(0.135)\n1.9517\n(0.1217)\n2.3189\n(0.0911)\n<0.001\n<0.001\n50\n2.2290\n(0.0608)\n2.1649\n(0.0825)\n0.001\n<0.001\n100\n2.3145\n(0.0414)\n2.3328\n(0.0891)\n0.686\n0.820\nFigure 7.14 displays the curve of coverage as the function of number of generations. The ﬁg-\nures show that MOEA/WST improves comparatively its coverage as the number p increases. The\nadvantage of MOEA/WST over NSGA-II is given more signiﬁcant in terms of coverage.\n(a) Budget ≤3.\n(b) Budget ≤7.\nFigure 7.14: Coverage over generations between the approximate Pareto fronts generated by NSGA-II\nand MOEA/WST.\nThe complete results considering budget 3, 7, 9, 15 and 20 are reported in Appendix B.1. To add\nfurther elements of assessment of the comparative performance of the methods in more challenging\n55\n\nconditions the algorithms have been tested on the real-life problem of Neptun.\nNeptun\nIn Figure 7.15 are reported the results of the Neptun WDN only for the two evolutionary algo-\nrithms, NSGA-II and MOEA/WST. ParEGO has been excluded from this experiments due to its\ncomputational overhead.\n(a) Hypervolume over generations.\n(b) Hypervolume over wall-clock time.\nFigure 7.15: Hypervolume curves of the two evolutionary algorithms in the case of budget ≤25.\nThe Wilcoxon test is used also in the case of Neptun, for MOEA/WST and NSGA-II for the samples\nin generations 50, 100, 150, 200 and 250 (Table 7.5). The null hypothesis (H0) is that the samples\nare from the same distribution.\nTable 7.5: Comparing hypervolume of MOEA/WST against the NSGA-II’s (values are ×109).\nStatistical signiﬁcance has been investigated through a Wilcoxon test (p-value is reported).\nGenerations\nMOEA/WST\nNSGA-II\nMOEA/WST vs NSGA-II\np-value\n50\n1.3377 (0.0826)\n0.0000 (0.0000)\n<0.001\n100\n1.3916 (0.0900)\n0.0000 (0.0000)\n<0.001\n150\n1.4150 (0.0915)\n0.0000 (0.0000)\n<0.001\n200\n1.4350 (0.0848)\n1.2232 (0.0374)\n<0.001\n250\n1.4530 (0.0880)\n1.1042 (0.0448)\n<0.001\nIn Neptun the comparative performance of MOEA/WST is quite impressive in terms of hypervolume.\n56\n\nIn terms of wall clock NSGA-II has a small advantage and then it stops at a lower value after having\nperformed its assigned 250 generations.\nAs for ParEGO, it is well known that the sample eﬃciency of Bayesian optimization methods\ndegrades as the dimension of the search space increase. Indeed, the wall clock times of ParEGO are\nabout four times the values of MOEA/WST. It is also worth remarking that ParEGO and NSGA-II\ncome from consolidated software frameworks, while MOEA/WST is still highly experimental.\n57\n\n\nChapter 8\nRecommender Systems\nThis chapter focus on the problem of recommend a given number of items to each user based on the\nrated items. A key element of this chapter is given by the mapping of each user and of the objectives\nfunction in a space of discrete distributions which is explored through the Wasserstein distance.\nThis enables the usage of the evolutionary algorithm presented in Chapter 6, namely MOEA/WST.\n8.1\nThe problem deﬁnition\nIn the most general framework, a Collaborative Filtering (CF) problem is based on the deﬁnition of\ntwo sets [77]:\n• The set of users U = {u1, u2, . . . , uM}, where M is the number of users.\n• The set of items O = {o1, o2, . . . , oN}, where N is the number of items.\nEach user expresses its judgement, or rating, r ∈X, where typical rating values can be binary\nor integers from a given range. The set of all the ratings given by the users on the items can be\nrepresented as a partially speciﬁed matrix R ∈RM×N, namely rating matrix (Table 8.1), where its\nentries ruo express the possible ratings of user u for item o. Usually, each user rates only a small\nnumber of items, thus the matrix elements are known in a small number of positions.\nTable 8.1: An example of a rating matrix.\nR\no1\no2\n. . .\noN\nu1\n?\n2\n. . .\n5\nu2\n4\n3\n. . .\n?\n. . .\n. . .\n. . .\n. . .\n. . .\nuM\n1\n?\n. . .\n4\n59\n\nOnce the rating matrix is ﬁlled, by any of the methods outlined in Chapter 4, the objective targeted\nin this thesis is to recommend a number L of items to each user (Table 8.2). A recommendation list\nS of length L for user ui is denoted as SL(ui).\nTable 8.2: An example of a top-L recommendation matrix.\nSL\nItem 1\nItem 1\n. . .\nItem L\nu1\no10\no36\n. . .\no2\nu2\no15\no51\n. . .\no28\n. . .\n. . .\n. . .\n. . .\n. . .\nuM\no39\no1\n. . .\no15\nIn the next sections the MovieLens dataset [78] has been used. MovieLens is the best known\nrepository of ratings for movies. It is also a benchmark in RS research. Datasets of diﬀerent sizes\nare provided. In the following experiments the version containing 1000 users, 1700 items and 100k\nratings has been used.\n8.2\nRepresenting user and items as a graph\nConsider now the rating matrix R as previously deﬁned. The basic idea of Collaborative Filtering\nmethods is that the observed ratings are highly correlated between users and items. If two users\nhave similar taste, it is very likely that the ratings given to the same object by these two users are\nsimilar. To compute the similarity between users or items diﬀerent metrics exist, for instance the\nCosine similarity (cos) and the Pearson correlation (ρ). Let R(1) and R(2) be two rows (columns) of\nthe rating matrix, then this two similarities measures are deﬁned as follows (Equations 8.1 and 8.2):\ncos\n\u0010\nR(1), R(2)\u0011\n=\nPN\ni=1 R(1)\ni R(2)\ni\nrPN\ni=1\n\u0010\nR(1)\ni\n\u00112rPN\ni=1\n\u0010\nR(2)\ni\n\u00112\n(8.1)\nρ\n\u0010\nR(1), R(2)\u0011\n=\nPN\ni=1\n\u0010\nR(1)\ni\n−R(1)\n\u0011 \u0010\nR(2)\ni\n−R(2)\n\u0011\nrPN\ni=1\n\u0010\nR(1)\ni\n−R(1)\n\u00112rPN\ni=1\n\u0010\nR(1)\ni\n−R(1)\n\u00112\n(8.2)\nwhere R(1) and R(2) are the sample mean respectively of R(1) and R(2). It is important to note that\nthe cosine similarity, in the case of positive values (as the rating matrix) is in the interval [0, 1],\nwhile the Pearson correlation assumes values in [−1, 1]. Figure 8.1 shows the distribution of cosine\nsimilarity between all pairs of users.\n60\n\nFigure 8.1: Distribution of cosine similarity between all pairs of users. The dotted red line is the\nthreshold τ.\nThe cosine similarity between individual users can be used to build a graph Gc = (Vc, Ec), in which\ntwo nodes (users) are linked together if their similarity is above a given threshold (the dotted red\nline in Figure 8.1); then Vc = {ui}i=1,...,M is the set of users and Ec = {(i, j) : cos (ui, uj) > τ} is\nthe set of edges. Each edge of this graph is then weighted based on the similarity cos(ui, uj). Figure\n8.2 displays the resulting graph, in which the edge color represents its weight. The nodes connected\nby a red edge are the most similar, while the ones connected by a green edge are the most diﬀerent.\nFigure 8.2: The cosine graph Gc.\n61\n\nAnother representation of the rating matrix is through the association to each user ui of a one-\ndimensional histogram h(ui): the bins are the equi-subdivisions of the interval [0, 1] for cosine\nsimilarity (and [−1, 1] for Pearson correlation) and the weights are the fraction of users whose\ncosine similarity falls in each bin; the same representation can be item driven. In Figure 8.3 cosine\nsimilarity is used with a bin length of 0.025.\n(a) User 16.\nLilac cluster in the\nWasserstein graph (Figure 8.7b).\n(b) User 33.\nBlue cluster in the\nWasserstein graph (Figure 8.7b).\n(c) User 300. Fuchsia cluster in the\nWasserstein graph (Figure 8.7b).\nFigure 8.3: Examples of users’ cosine similarity distributions.\nAccording to this representation each user is described by a signature, feature vector, given by the\nbins and the associated weights. In this feature space the elements are probabilistic distributions.\nMany models can be used to compute the distance between distributions, as analyzed in Chapter 5.\nIn this thesis, for the motivations expressed in the same chapter, the focus is on the Wasserstein\ndistance. Figure 8.4 shows the distribution of the Wasserstein distance over all the pairs of nodes.\nFigure 8.4: Distribution of Wasserstein distance between all pairs of users represented as histograms.\nThe dotted red line is the threshold τ.\n62\n\nThis distributional representation of the users enables the embedding of the rating matrix into\nanother graph (Figure 8.5) in which the nodes are the users that are linked if their distribution of\nsimilarity are close enough, i.e., their Wasserstein distance is below a given threshold.\nLet Gw = (Vw, Ew) be the Wasserstein graph, then Vw = {h(ui)}i=1,...,M is the set of users repre-\nsented as histograms and Ew = {(i, j) : W(h(ui), h(uj)) < τ} is the set of edges. The edge (i, j) is\nthen weighted based on the Wasserstein distance W(h(ui), h(uj)) between the similarity distributions\nof nodes i and j.\nFigure 8.5: The Wasserstein graph Gw.\nIn the same way each item can be represented as the distribution of the similarity with all the other\nitems and analogously, also the distributional representation of the items enables the embedding of\nR in a graph, in which the nodes are the items.\nTo simplify the optimization process to ﬁnd the top-L recommendation lists the users have been\nclustered.\nFirstly, the spectral clustering has been used on the original rating matrix. The resulting clusters\nhave been mapped in the two previously deﬁned graphs as shown in Figure 8.6.\nAs these ﬁgures highlight, the clusters obtained by the rating matrix are diﬃcult to explain. For\nthis reason, the spectral clustering have been then applied to the Wasserstein graph Gw.\n63\n\n(a) Clusters mapped on the cosine graph.\n(b) Clusters mapped on the Wasserstein graph.\nFigure 8.6: Results of the spectral clustering on the rating matrix. Three clusters have been\nidentiﬁed (blue, lilac and fuchsia).\nFigure 8.7b shows the three resulting clusters. This results have been mapped back in the initial\ngraph Gc (Figure 8.7a). Analyzing Figure 8.7 it is clear that the blue cluster contains the more\ncentral users, therefore this cluster is highly connected to the other two. Instead, the lilac cluster is\ncomposed by the most diﬀerent users.\n(a) Clusters mapped on the cosine graph.\n(b) Clusters mapped on the Wasserstein graph.\nFigure 8.7: Results of the spectral clustering on the Wasserstein graph. Three clusters have been\nidentiﬁed (blue, lilac and fuchsia).\n8.3\nObjective functions and its distributional representation\nFor the problem of ﬁnding the optimal top-L recommendation list, three conﬂicting objectives\nare considered, i.e., accuracy, coverage, and novelty. The distributional representation of these\nthree metrics enables the deﬁnition of an information space (Figure 8.8) that allows the use of\n64\n\nMOEA/WST analyzed in Chapter 6. In particular, each recommendation matrix can be represented\nby a three dimensional histogram that enables the selection process of MOEA/WST explained in\nChapter 6.2.\nFigure 8.8: Distributional representation of a top-L recommendation matrix and the information\nspace.\nAccuracy\nThe accuracy measures the similarity between the predicted rating and the true ratings.\nTo\neach recommendation list, it is possible to assign a score that represents how “good” the items\nrecommended to users are. This score is based on the sum of the ratings given by the users to the\nrecommended items and is given by Equation 8.3:\naccuracy =\n1\nM · L\nX\nui∈U\nX\noj∈SL(ui)\nr(ui, oj)\n(8.3)\nwhere r(ui, oj) is the rating given by user ui to item oj. Maximize this score ensures that the\nrecommendation list of each user contains only items that the user has given a high rating.\nThis particular deﬁnition of accuracy admits a distributional representation. The distribution is\ngiven by the values of accuracy of each user. This distribution can be represented by a histogram\n(Figure 8.9) in which the support points k1, . . . , kNa correspond to accuracy values, and the weights\nwki with i = 1, . . . , Na represent the fraction of users with a certain value of accuracy (Equation 8.4).\nwki = 1\nM\n\f\f\f\f\f\f\n\n\nui :\nX\noj∈SL(ui)\nr(ui, oj) ∈[ki, ki+1)\n\n\n\n\f\f\f\f\f\f\n(8.4)\n65\n\nFigure 8.9: Example of accuracy distributions over the users.\nOne problem with Collaborative Filtering recommendation is the “popularity bias”: popular items\nare being recommended too frequently while most of the items do not get attention. For this reason,\nin this thesis the accuracy is considered together with other two objectives, coverage and novelty.\nCoverage\nA recommender system is expected to provide M recommendation lists. Each list corresponds to a\nuser and consists of L items. The coverage is deﬁned as the number of diﬀerent items in all users’\ntop-L lists (Equation 8.5).\ncoverage = 1\nN\n\f\f\f\f\f\f\n[\nui∈U\nSL(ui)\n\f\f\f\f\f\f\n(8.5)\nThe objective function coverage is averaged over the total number of items N. Coverage reﬂects the\ndiversity of recommendation. A larger value of coverage is better because more choices are provided\nto the users.\nIt’s important to note that also the coverage admits a distributional representation. The distribution\nis given by the ratio between the non-duplicated items in the recommendation list and the total\nnumber of items for each user, i.e., the coverage of the user recommendation list SL(u). This\ndistribution can be represented by a histogram (Figure 8.10) in which the support points are the\nvalues of coverage k1, . . . , kNc, and the weights wki with i = 1, . . . , Nc represent the fraction of users\nwith a certain value of coverage (Equation 8.6).\nwki = 1\nM |{ui : |SL(ui)| ∈[ki, ki+1)}|\n(8.6)\n66\n\nFigure 8.10: Example of coverage distributions over the users.\nNovelty\nThe novelty reﬂects the number of unknown items (i.e., items that are still unrated) that are\nrecommended to users. This objective is based on the degree dj of an item oj that is the number of\ntimes it has been rated by a user. Then, the self-information [79] of the item oj is given by Equation\n8.7.\nNj = log2\nM\ndj\n(8.7)\nThe novelty is then deﬁned as the average self-information of all the items in the recommendation\nlists of each users (Equation 8.8).\nNovelty = 1\nM\nX\nui∈U\nX\nj∈SL(ui)\nNj\nL\n(8.8)\nIt’s important to note that novelty also admits a distributional representation. The distribution is\ngiven by the values of novelty P\ni∈SL(u)\nNi\nL for each user u. This distribution can be represented by\na histogram (Figure 8.11) in which the support points k1, . . . , kNn are the values of novelty, and\nthe weights wki with i = 1, . . . , Nn represent the number of users with a certain value of novelty\n(Equation 8.9).\nwki = 1\nM\n\f\f\f\f\f\f\n\n\nui :\nX\ni∈SL(ui)\nNi\nL ∈[ki, ki+1)\n\n\n\n\f\f\f\f\f\f\n(8.9)\n67\n\nFigure 8.11: Example of novelty distributions over the users.\nInformation space\nThe distributional representation of the three previously deﬁned objective can be viewed as a three\ndimensional histogram. For each recommendation list SL the support points of this histogram\nare the values of accuracy along the x-axis, the values of coverage along the y-axis and the values\nof novelty along the z-axis; the weights represents the fraction of users whose values of accuracy,\ncoverage and novelty fall in a speciﬁc range.\nThese distributions compose the so-called Information Space on which the MOEA/WST algorithm is\nbased. Therefore, it uses the Wasserstein distance to compare the histograms associated to diﬀerent\ntop-L recommendation lists, in the selection operator, to speed up the entire optimization process.\n8.4\nComputational settings\nIn MOEA/WST the top-L rating lists are encoded as L × M integer matrices. The entries of these\nmatrices are the integer id of recommended items.\nTo recombine chromosome, the Pymoo implementation of Simulated Binary Crossover [76] is used.\nIt simulates the working principle of the single-point crossover operator on binary data, by using a\nprobability distribution. Pymoo allows the deﬁnition of a parameter η to ﬁne-tune the exponential\ndistribution, in these experiments η = 3.0. As mutation operator, the Pymoo implementation of\nInverse Mutation [76] is used. This mutation is applied to permutations, and it randomly select a\nsegment of a chromosome and reverse its order. For instance, for the permutation [1, 2, 3, 4, 5] the\nsegment can be [2, 3, 4] which results in [1, 4, 3, 2, 5].\nIn these experiments, a population of 40 individuals is considered and at each generation an oﬀspring\nof 10 new chromosomes is generated for a total of 50 generations. The initial population is sampled\nrandomly. For a fair comparison between MOEA/WST and NSGA-II the same settings are used in\nboth algorithms.\n68\n\n8.5\nComputational results\nIn this section, the computational results over the MovieLens dataset are reported.\nFirst, the two algorithms, NSGA-II and MOEA/WST, have been used on the clusters resulting\nfrom the rating matrix. Figure 8.12 shows the Hypervolume over generation of both, NSGA-II (red)\nand MOEA/WST (blue) on the clusters computed on the original dataset (rating matrix). Since\nmultiple runs of the algorithms are performed, the charts display mean and standard deviation of\nthe metric.\n(a) Cluster 1.\n(b) Cluster 2.\n(c) Cluster 3.\nFigure 8.12: Mean and standard deviation of the hypervolume over the generations. Clusters are\nthe ones obtained using the spectral clustering on the rating matrix.\nThen the two algorithms have been used, with the same settings, on the clusters obtained from the\nWasserstein graph. Figure 8.13 shows the same comparative results where the clusters are computed\non the WST graph.\n(a) Cluster 1.\n(b) Cluster 2.\n(c) Cluster 3.\nFigure 8.13: Mean and standard deviation of the hypervolume over the generations. Clusters are\nthe ones obtained using the spectral clustering on the Wasserstein graph.\nIn both cases the Hypervolume curve of MOEA/WST converge faster than in the case of NSGA-II.\nIt is also important to note that, using the clusters over the Wasserstein graph, both algorithms\nperform well.\n69\n\nFigures 8.14, 8.15 display the curve of coverage as the function of number of generations. As in the\ncase of sensor placements, the advantage of MOEA/WST over NSGA-II is given more signiﬁcant in\nterms of coverage.\n(a) Cluster 1.\n(b) Cluster 2.\n(c) Cluster 3.\nFigure 8.14: Mean and standard deviation of the coverage over the generations. Clusters are the\nones obtained using the spectral clustering on the rating matrix.\n(a) Cluster 1.\n(b) Cluster 2.\n(c) Cluster 3.\nFigure 8.15: Mean and standard deviation of the coverage over the generations. Clusters are the\nones obtained using the spectral clustering on the Wasserstein graph.\n70\n\nChapter 9\nSoftware Resources\nIn this chapter the library and tools used in the experiments are presented. Python is chosen as\nthe programming language thanks to its ﬂexibility and to the high number of libraries related to\nmachine learning and optimization problems.\n9.1\nPymoo\nThe main library considered to model and to solve the multi-objective problems is Pymoo [80]\n(Python Multi-objective Optimization). This framework oﬀers state of the art single and multi-\nobjective optimization algorithms and many more features related to multi-objective optimization,\nsuch as visualization and decision making. Among all the genetic algorithms oﬀered by Pymoo,\nNSGA-II is considered in the experiments presented in the previous chapters. The strength of\nPymoo is its ﬂexibility; therefore, it allows the deﬁnition of customized problems as well as new\nalgorithms and genetic operators based on consolidated structures. These functionalities of Pymoo\nare used to develop the MOEA/WST algorithm deﬁned in Chapter 6.\nPymoo also oﬀers a rich set of performance indicator for multi-objective problems, among which the\nhypervolume is used.\n9.2\nBoTorch\nIn the experiments in Chapter 7 the qParEGO [81] implementation of BoTorch is used. BoTorch\n[82] is a library for Bayesian Optimization built on the well known open source machine learning\nframework PyTorch. This choice is driven by the fact that BoTorch is compatible with the problems\ndeﬁned using Pymoo. In this way, the same problem can be solved using algorithms of both, Pymoo\nand BoTorch frameworks.\n71\n\n9.3\nPython Optimal Transport\nDiﬀerent libraries related to the Wasserstein distance exist in Python, for instance SciPy [83] or\nGUDHI [84]. Python Optimal Transport (POT) [85] is one of the most complete frameworks.\nIt provides several solvers for optimization problems related to Optimal Transport. Among all\nthe functionalities oﬀered by this library the one explored and used in this thesis is the linear\nprogramming solver for the Earth Mover’s Distance in the case of single and multi-dimensional\ndiscrete distributions. These functions to compute the EMD are the core of the MOEA/WST\nalgorithm implemented in Pymoo.\nPOT also contains some approximations of the Wasserstein distance. Examples are the entropic\nregularization OT solver based on Sinkhorn [86] or the implementation of the sliced Wasserstein\ndistance [87]. These implementations are signiﬁcantly more eﬃcient in terms of computation time\nthan the one based on linear programming but presents problem of numerical instability. Another\nuseful functionality of POT is the computation of the Wasserstein barycenters [88] even in the case\nof distributions with diﬀerent supports [89].\n9.4\nWater Networks Tool for Resilience\nThe Water Network Tool for Resilience (WNTR, pronounced winter) [75] is a Python package\ndesigned to simulate and analyse resilience of water distribution networks. WNTR has an application\nprogramming interface (API) that is ﬂexible and allows for changes to the network structure and\noperations, along with simulation of disruptive incidents and recovery actions. It is based upon\nEPANET, which is a tool to simulate the movement and fate of drinking water constituents within\ndistribution systems.\nOver all the functionalities of WNTR, the hydraulic and water quality simulation are used to\nsimulate the ﬂow of a contaminant in diﬀerent water distribution networks. Therefore, a water\nquality simulation can be used to compute the percentage of contaminant ﬂow originating from a\nspeciﬁc location. In the experiments reported in Chapter 7 multiple simulations are executed for\neach network changing the location in which the contaminant is injected.\n9.5\nCytoscape and ClusterMaker\nCytoscape [90] is an open source software platform for visualizing complex networks and integrating\nthese with any type of attribute data. It is mainly used in ﬁeld like biology to analyse molecular\nand genomics systems, and social science, but Cytoscape is domain-independent and therefore it is\na powerful tool for complex network analysis in general. The key feature of Cytoscape is that it is\nexpandable and extensible; therefore, there exist hundreds of third parties’ plugins that extend its\n72\n\nfunctionalities.\nClusterMaker2 [91] is one of these plugins and it uniﬁes diﬀerent clustering techniques. In this\nthesis, the spectral clustering implementation of ClusterMaker2 is used in the networks related\nto the recommender systems in Chapter 8. As any spectral methods it uses the eigenvalues in\nan input similarity matrix to perform dimensionality reduction for clustering in fewer dimensions\nusing a standard k-means algorithm. In the case of graph clustering, the normalized Laplacian\nmatrix is used as similarity matrix. Consider a graph G the normalized Laplacian is deﬁned as\nLN(G) = D−1\n2 S(G)D−1\n2 where D is the degree matrix and S(G) = I + A(G) with I the identity\nmatrix and A(G) the adjacency matrix.\n73\n\n\nChapter 10\nConclusions\nThe key objective of this work is to show that the distributional framework for data analysis\nand in particular the Wasserstein distance and the associated analytical methods oﬀer signiﬁcant\nadvantages over comparing distributions using a set of parametric values such as mean, variance and\nhigher order moments. Indeed, the analysis of these parameters does not take the whole distribution\ninto account.\nEven if the roots of WST are in abstract spaces of probability distributions, WST and the associated\noptimal transport map oﬀer a visually intuitive representation of the similarity between distributions.\nThese advantages come at a considerable computational cost in particular in the multi-dimensional\ncase. To overcome this drawback substantial research work has been conducted in the last years to\nprovide feasible algorithm to compute barycenters and, as a consequence, to enable clustering in\nWST spaces. These results have allowed to widen the application of WST beyond the domain of\nimaging science, which was an early adopter of WST, to many applications in data analysis and\nmachine learning, for instance in the generation of adversarial deep networks.\nIn this thesis the representation power of WST has been applied to multi-task learning on networks\nmodelled as a multi-objective optimization problem.\nThis new approach has been instantiated in diﬀerent domains as networked infrastructure, speciﬁcally\nwater distribution networks and collaborative ﬁltering in recommender systems. WST has also\nenabled new operators in multi-task evolutionary learning for optimal sensor placement, for intrusion\ndetection, and for the design of multi-objective recommender systems.\nBeside the speciﬁc issues analyzed in this thesis, distributional inputs can occur in a number of\npractical situations. As already said, compare parametric features associated to distributions is not\nalways the right way. Commonly used kernels depend on the Euclidean distance between points.\nIn the case of distributional inputs, it is important to construct positive deﬁnite kernels on sets of\nprobability measures. The research on this topic has branched into two directions.\nA ﬁrst solution is to build a Wasserstein induced kernel, that has been proved to be eﬀective\n75\n\nfor instance in the problem of neural architectural search [64]. Using kernels limits the choice of\ndistribution distances as the resulting kernel has to be deﬁnite positive: a widely used distance\nas Kullback-Leibler does not qualify. The key diﬃculty of a Wasserstein kernel is that the kernel\nobtained computing the exponential of the squared Wasserstein distance between distributional\ninputs does not lead to a positive deﬁnite kernel. Therefore, it has been shown that many eigenvalues\nof the Wasserstein induced covariance matrix are negative.\nA very interesting perspective consists in embed directly the probabilistic distances in the learning\nprocess, without using a kernel. In this thesis a distributional distance based learning paradigm has\nbeen shown to be very eﬀective in simulation-optimization problem like optimal sensor placement in\nChapter 7 or in the context of recommender systems in Chapter 8.\nThese results agree with very recent results as to embed non-Euclidean distance in the learning\nprocess and oﬀer new insights into the design of algorithms of machine learning and optimization.\n76\n\nAppendix A\nMetrics on graphs\nIn the following the centrality measures and some vulnerability metrics on graphs are deﬁned.\nA.1\nCentrality measures\nConsider a graph G = (V, E) with |V | = n and |E| = m.\nThe density q of the network is the fraction of edges which are present in the network (Equation\nA.1).\nq =\n2m\nn(n −1)\n(A.1)\nThe link-per-node ration e of a graph is deﬁned as the number of edges with respect to the number\nof its nodes (Equation A.2).\ne = m\nn\n(A.2)\nThe diameter D(G) of a network is deﬁned as the largest distance (the largest shortest path) among\neach possible pair of nodes in the graph. Instead, the characteristic path length L(G) is the average\ndistance for every possible pair of nodes as in Equation A.3:\nL(G) =\n1\nn(n −1)\nn\nX\ni=1\nn\nX\nj=1:j̸=i\nd(i, j)\n(A.3)\nwhere d(i, j) is the distance between node i and node j.\nThe betweenness centrality bi of a node i is deﬁned as (Equation A.4):\nbi = 1\nn2\nn\nX\ns=1\nn\nX\nt=1\nηi\nst\n(A.4)\nwhere ηi\nst = 1 if node i lies on the shortest path from s to t and 0 otherwise.\nThe central point dominance c′\nb, based on betweenness centrality, is a measure for characterizing\n77\n\nthe organization of a network according to its path-related connectivity and is deﬁned as (Equation\nA.5):\nc′\nb =\n1\nn −1\nn\nX\ni=1\n(bmax −bi)\n(A.5)\nwhere bi is the betweenness centrality of the node i and bmax is the maximum value of betweenness\ncentrality over all the network’s nodes.\nThe clustering coeﬃcient cc is the number of triangles Ntg with respect to the overall number of\npossible connected triples Ntp, where a triple consists of three nodes connected at least by two edges\nwhile a triangle consists of three nodes connected exactly by three edges (Equation A.6).\ncc = Ntg\nNtp\n(A.6)\nA.2\nVulnerability measures\nConsider a graph G = (V, E) with |V | = n. The performance of the network after the removal of\nnodes/edges is often evaluated as the change of the eﬃciency, as in Equation A.7.\nE =\n1\nn(n −1)\nX\nij∈V :i̸=j\n1\ndij\n(A.7)\nwhere dij represents the distance between i and j. Normalization by n(n −1) ensures that E ≤1,\nin case of unweighted graph. The maximum value E = 1, is assumed if and only if the graph is\ncomplete.\nA way to measure the vulnerability of the network is using the loss of eﬃciency observed when we\nremove some nodes/edges. The relative drop in the network eﬃciency caused by the removal of a\nnode i from the graph is deﬁned as (Equation A.8):\nCE\n∆(i) =\nE(G)\nE(G \\ {v})\n(A.8)\nwhere G \\ {v} denotes the network G without the node i. The vulnerability of G is deﬁned as\n(Equations A.9 and A.10):\nVMAX(G) = max\ni∈V CE\n∆(i)\n(A.9)\nVMEAN(G) = 1\nn\nX\ni∈V\nCE\n∆(i)\n(A.10)\nAnalogous formulas can be written removing the edges.\n78\n\nAppendix B\nComputational Results\nIn the following the complete computational results are reported.\nB.1\nSensor placement in Hanoi WDN\nFigures B.1 - B.5 show the comparison between the three algorithms, MOEA/WST, NSGA-II and\nParEGO, in terms of hypervolume over generations and wall-clock time for diﬀerent sensor budgets p.\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure B.1: Hypervolume curves of the three algorithms in the case of budget ≤3.\n79\n\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure B.2: Hypervolume curves of the three algorithms in the case of budget ≤7.\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure B.3: Hypervolume curves of the three algorithms in the case of budget ≤9.\n80\n\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure B.4: Hypervolume curves of the three algorithms in the case of budget ≤15.\n(a) Hypervolume over generation.\n(b) Hypervolume over wall-clock time.\nFigure B.5: Hypervolume curves of the three algorithms in the case of budget ≤20.\nTable B.1 reports the results of Wilcoxon test between the hypervolumes of the three algorithms,\nMOEA/WST, NSGA-II and ParEGO, for diﬀerent generations and sensor budgets p.\n81\n\nTable B.1: Comparing hypervolume of MOEA/WST against those of the other two approaches\n(values are ×109) and with respect to diﬀerent budgets p and number of generations. Statistical\nsigniﬁcance has been investigated through a Wilcoxon test (p-value is reported).\nppp\nGenerations\nMOEA/WST\nNSGA-II\nParEGO\nMOEA/WST\nvs NSGA-II\np-value\nMOEA/WST\nvs ParEGO\np-value\n3\n25\n0.2188\n(0.3790)\n0.2190\n(0.4538)\n0.2496\n(0.1641)\n0.811\n<0.001\n50\n1.0828\n(0.5942)\n1.5883\n(0.2969)\n<0.001\n<0.001\n100\n2.0769\n(0.2225)\n2.2808\n(0.1601)\n<0.001\n<0.001\n7\n25\n2.0421\n(0.135)\n1.9517\n(0.1217)\n2.3189\n(0.0911)\n<0.001\n<0.001\n50\n2.2290\n(0.0608)\n2.1649\n(0.0825)\n0.001\n<0.001\n100\n2.3145\n(0.0414)\n2.3328\n(0.0891)\n0.686\n0.820\n9\n25\n2.2084\n(0.0608)\n2.0404\n(0.1079)\n2.3171\n(0.0880)\n<0.001\n<0.001\n50\n2.3189\n(0.0521)\n2.2350\n(0.0721)\n<0.001\n0.959\n100\n2.3880\n(0.0389)\n2.3517\n(0.0529)\n0.006\n<0.001\n15\n25\n2.2891\n(0.0560)\n2.1830\n(0.0715)\n2.3101\n(0.0920)\n<0.001\n0.398\n50\n2.3827\n(0.0456)\n2.3170\n(0.0612)\n<0.001\n<0.001\n100\n2.4317\n(0.0415)\n2.4364\n(0.0444)\n0.552\n<0.001\n20\n25\n2.2880\n(0.0489)\n2.2393\n(0.0605)\n2.3827\n(0.0892)\n0.001\n<0.001\n50\n2.3605\n(0.0433)\n2.3610\n(0.0590)\n0.809\n0.248\n100\n2.4186\n(0.0366)\n2.4415\n(0.0441)\n0.031\n0.001\n82\n\nBibliography\n[1] Rich Caruana.\nMultitask learning.\nMach. Learn., 28(1):41–75, 1997.\ndoi:\n10.1023/A:\n1007379606734. URL https://doi.org/10.1023/A:1007379606734.\n[2] Alekh Agarwal, Miroslav Dud´ık, and Zhiwei Steven Wu. Fair regression: Quantitative deﬁnitions\nand reduction-based algorithms. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,\nProceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June\n2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research,\npages 120–129. PMLR, 2019. URL http://proceedings.mlr.press/v97/agarwal19d.html.\n[3] Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations\nfor deep learning in NLP. In Anna Korhonen, David R. Traum, and Llu´ıs M`arquez, editors,\nProceedings of the 57th Conference of the Association for Computational Linguistics, ACL\n2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages 3645–3650.\nAssociation for Computational Linguistics, 2019. doi: 10.18653/v1/p19-1355. URL https:\n//doi.org/10.18653/v1/p19-1355.\n[4] Antonio Candelieri, Riccardo Perego, and Francesco Archetti. Green machine learning via\naugmented gaussian processes and multi-information source optimization. Soft Comput., 25\n(19):12591–12603, 2021. doi: 10.1007/s00500-021-05684-7. URL https://doi.org/10.1007/\ns00500-021-05684-7.\n[5] Antonio Candelieri, Andrea Ponti, and Francesco Archetti. Risk aware optimization of water\nsensor placement. In Krzysztof Krawiec, editor, GECCO ’21: Genetic and Evolutionary\nComputation Conference, Companion Volume, Lille, France, July 10-14, 2021, pages 295–\n296. ACM, 2021. doi: 10.1145/3449726.3459477. URL https://doi.org/10.1145/3449726.\n3459477.\n[6] Riccardo Perego, Antonio Candelieri, Francesco Archetti, and Danilo Pau.\nTuning deep\nneural network’s hyperparameters constrained to deployability on tiny systems. In Igor Farkas,\nPaolo Masulli, and Stefan Wermter, editors, Artiﬁcial Neural Networks and Machine Learning\n- ICANN 2020 - 29th International Conference on Artiﬁcial Neural Networks, Bratislava,\n83\n\nSlovakia, September 15-18, 2020, Proceedings, Part II, volume 12397 of Lecture Notes in\nComputer Science, pages 92–103. Springer, 2020. doi: 10.1007/978-3-030-61616-8\\ 8. URL\nhttps://doi.org/10.1007/978-3-030-61616-8_8.\n[7] Mohammad Loni, Sima Sinaei, Ali Zoljodi, Masoud Daneshtalab, and Mikael Sj¨odin. Deepmaker:\nA multi-objective optimization framework for deep neural networks in embedded systems.\nMicroprocess. Microsystems, 73:102989, 2020. doi: 10.1016/j.micpro.2020.102989. URL https:\n//doi.org/10.1016/j.micpro.2020.102989.\n[8] Ozan Sener and Vladlen Koltun. Multi-task learning as multi-objective optimization. In Samy\nBengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol`o Cesa-Bianchi, and\nRoman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual\nConference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8,\n2018, Montr´eal, Canada, pages 525–536, 2018. URL https://proceedings.neurips.cc/\npaper/2018/hash/432aca3a1e345e339f35a30c8f65edce-Abstract.html.\n[9] Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, and Sam Kwong. Pareto multi-task learning.\nIn Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alch´e-Buc, Emily B.\nFox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32:\nAnnual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December\n8-14, 2019, Vancouver, BC, Canada, pages 12037–12047, 2019. URL https://proceedings.\nneurips.cc/paper/2019/hash/685bfde03eb646c27ed565881917c71c-Abstract.html.\n[10] Marcela Zuluaga, Guillaume Sergent, Andreas Krause, and Markus P¨uschel. Active learning for\nmulti-objective optimization. In Proceedings of the 30th International Conference on Machine\nLearning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, volume 28 of JMLR Workshop\nand Conference Proceedings, pages 462–470. JMLR.org, 2013. URL http://proceedings.mlr.\npress/v28/zuluaga13.html.\n[11] Marcela Zuluaga, Andreas Krause, and Markus P¨uschel. e-pal: An active learning approach to\nthe multi-objective optimization problem. J. Mach. Learn. Res., 17:104:1–104:32, 2016. URL\nhttp://jmlr.org/papers/v17/15-047.html.\n[12] Amar Shah and Zoubin Ghahramani.\nPareto frontier learning with expensive correlated\nobjectives. In Maria-Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of the 33nd\nInternational Conference on Machine Learning, ICML 2016, New York City, NY, USA, June\n19-24, 2016, volume 48 of JMLR Workshop and Conference Proceedings, pages 1919–1927.\nJMLR.org, 2016. URL http://proceedings.mlr.press/v48/shahc16.html.\n[13] Xi Lin, Zhiyuan Yang, Qingfu Zhang, and Sam Kwong. Controllable pareto multi-task learning.\nCoRR, abs/2010.06313, 2020. URL https://arxiv.org/abs/2010.06313.\n84\n\n[14] Francesco Archetti and Antonio Candelieri. Bayesian optimization and data science. Springer,\n2019.\n[15] Peter I. Frazier. A tutorial on bayesian optimization. CoRR, abs/1807.02811, 2018. URL\nhttp://arxiv.org/abs/1807.02811.\n[16] Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. Max-value entropy search\nfor multi-objective bayesian optimization. In Hanna M. Wallach, Hugo Larochelle, Alina\nBeygelzimer, Florence d’Alch´e-Buc, Emily B. Fox, and Roman Garnett, editors, Ad-\nvances in Neural Information Processing Systems 32: Annual Conference on Neural In-\nformation Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,\nCanada, pages 7823–7833, 2019. URL https://proceedings.neurips.cc/paper/2019/hash/\n82edc5c9e21035674d481640448049f3-Abstract.html.\n[17] Eduardo C. Garrido-Merch´an and Daniel Hern´andez-Lobato. Predictive entropy search for\nmulti-objective bayesian optimization with constraints. Neurocomputing, 361:50–68, 2019. doi:\n10.1016/j.neucom.2019.06.025. URL https://doi.org/10.1016/j.neucom.2019.06.025.\n[18] Alma As-Aad Mohammad Rahat, Richard M. Everson, and Jonathan E. Fieldsend. Alternative\ninﬁll strategies for expensive multi-objective optimisation. In Peter A. N. Bosman, editor,\nProceedings of the Genetic and Evolutionary Computation Conference, GECCO 2017, Berlin,\nGermany, July 15-19, 2017, pages 873–880. ACM, 2017. doi: 10.1145/3071178.3071276. URL\nhttps://doi.org/10.1145/3071178.3071276.\n[19] Joshua D. Knowles. Parego: a hybrid algorithm with on-line landscape approximation for\nexpensive multiobjective optimization problems. IEEE Trans. Evol. Comput., 10(1):50–66,\n2006. doi: 10.1109/TEVC.2005.851274. URL https://doi.org/10.1109/TEVC.2005.851274.\n[20] Qingfu Zhang, Wudong Liu, Edward P. K. Tsang, and Botond Virginas. Expensive multiobjec-\ntive optimization by MOEA/D with gaussian process model. IEEE Trans. Evol. Comput., 14\n(3):456–474, 2010. doi: 10.1109/TEVC.2009.2033671. URL https://doi.org/10.1109/TEVC.\n2009.2033671.\n[21] Hu Zhang, Jianyong Sun, Tonglin Liu, Ke Zhang, and Qingfu Zhang. Balancing exploration\nand exploitation in multiobjective evolutionary optimization. Inf. Sci., 497:129–148, 2019. doi:\n10.1016/j.ins.2019.05.046. URL https://doi.org/10.1016/j.ins.2019.05.046.\n[22] Nicola Beume, Boris Naujoks, and Michael T. M. Emmerich. SMS-EMOA: multiobjective\nselection based on dominated hypervolume. Eur. J. Oper. Res., 181(3):1653–1669, 2007. doi:\n10.1016/j.ejor.2006.08.008. URL https://doi.org/10.1016/j.ejor.2006.08.008.\n85\n\n[23] Cynthia A Rodr´ıguez Villalobos and Carlos A Coello Coello. A new multi-objective evolutionary\nalgorithm based on a performance assessment indicator. In Proceedings of the 14th annual\nconference on Genetic and evolutionary computation, pages 505–512, 2012.\n[24] Qingfu Zhang and Hui Li. MOEA/D: A multiobjective evolutionary algorithm based on\ndecomposition. IEEE Trans. Evol. Comput., 11(6):712–731, 2007. doi: 10.1109/TEVC.2007.\n892759. URL https://doi.org/10.1109/TEVC.2007.892759.\n[25] Anupam Trivedi, Dipti Srinivasan, Krishnendu Sanyal, and Abhiroop Ghosh. A survey of\nmultiobjective evolutionary algorithms based on decomposition. IEEE Trans. Evol. Comput.,\n21(3):440–462, 2017. doi: 10.1109/TEVC.2016.2608507. URL https://doi.org/10.1109/\nTEVC.2016.2608507.\n[26] Hui Li, Kalyanmoy Deb, Qingfu Zhang, Ponnuthurai N. Suganthan, and Lei Chen. Comparison\nbetween MOEA/D and NSGA-III on a set of novel many and multi-objective benchmark\nproblems with challenging diﬃculties. Swarm Evol. Comput., 46:104–117, 2019. doi: 10.1016/j.\nswevo.2019.02.003. URL https://doi.org/10.1016/j.swevo.2019.02.003.\n[27] Jianyong Sun, Hu Zhang, Aimin Zhou, Qingfu Zhang, and Ke Zhang. A new learning-based\nadaptive multi-objective evolutionary algorithm. Swarm Evol. Comput., 44:304–319, 2019. doi:\n10.1016/j.swevo.2018.04.009. URL https://doi.org/10.1016/j.swevo.2018.04.009.\n[28] Kalyanmoy Deb and Christie Myburgh.\nA population-based fast algorithm for a billion-\ndimensional resource allocation problem with integer variables. Eur. J. Oper. Res., 261(2):\n460–474, 2017. doi: 10.1016/j.ejor.2017.02.015. URL https://doi.org/10.1016/j.ejor.\n2017.02.015.\n[29] Julian Blank and Kalyanmoy Deb. A running performance metric and termination criterion for\nevaluating evolutionary multi- and many-objective optimization algorithms. In IEEE Congress\non Evolutionary Computation, CEC 2020, Glasgow, United Kingdom, July 19-24, 2020, pages\n1–8. IEEE, 2020. doi: 10.1109/CEC48606.2020.9185546. URL https://doi.org/10.1109/\nCEC48606.2020.9185546.\n[30] Miqing Li and Xin Yao. Quality evaluation of solution sets in multiobjective optimisation:\nA survey. ACM Comput. Surv., 52(2):26:1–26:38, 2019. doi: 10.1145/3300148. URL https:\n//doi.org/10.1145/3300148.\n[31] Donald R. Jones, Matthias Schonlau, and William J. Welch. Eﬃcient global optimization\nof expensive black-box functions. J. Glob. Optim., 13(4):455–492, 1998. doi: 10.1023/A:\n1008306431147. URL https://doi.org/10.1023/A:1008306431147.\n86\n\n[32] Michael T. M. Emmerich, Kyriakos C. Giannakoglou, and Boris Naujoks.\nSingle- and\nmultiobjective evolutionary optimization assisted by gaussian random ﬁeld metamodels.\nIEEE Trans. Evol. Comput., 10(4):421–439, 2006. doi: 10.1109/TEVC.2005.859463. URL\nhttps://doi.org/10.1109/TEVC.2005.859463.\n[33] Kalyanmoy Deb, Samir Agrawal, Amrit Pratap, and T. Meyarivan. A fast and elitist multi-\nobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput., 6(2):182–197, 2002. doi:\n10.1109/4235.996017. URL https://doi.org/10.1109/4235.996017.\n[34] Stephen P. Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University\nPress, 2014. ISBN 978-0-521-83378-3. doi: 10.1017/CBO9780511804441. URL https://web.\nstanford.edu/%7Eboyd/cvxbook/.\n[35] Zhun Fan, Wenji Li, Xinye Cai, Han Huang, Yi Fang, Yugen You, Jiajie Mo, Caimin Wei,\nand Erik D. Goodman. An improved epsilon constraint-handling method in MOEA/D for\ncmops with large infeasible regions. Soft Comput., 23(23):12491–12510, 2019. doi: 10.1007/\ns00500-019-03794-x. URL https://doi.org/10.1007/s00500-019-03794-x.\n[36] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine\nlearning. Adaptive computation and machine learning. MIT Press, 2006. ISBN 026218253X.\nURL https://www.worldcat.org/oclc/61285753.\n[37] Harold J Kushner. A new method of locating the maximum point of an arbitrary multipeak\ncurve in the presence of noise. 1964.\n[38] Jonas Mockus, Vytautas Tiesis, and Antanas Zilinskas. The application of bayesian methods\nfor seeking the extremum. Towards global optimization, 2(117-129):2, 1978.\n[39] Raul Astudillo and Peter I. Frazier. Bayesian optimization of composite functions. In Kamalika\nChaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference\non Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97\nof Proceedings of Machine Learning Research, pages 354–363. PMLR, 2019.\nURL http:\n//proceedings.mlr.press/v97/astudillo19a.html.\n[40] Peter Auer. Using conﬁdence bounds for exploitation-exploration trade-oﬀs. J. Mach. Learn.\nRes., 3:397–422, 2002. URL http://jmlr.org/papers/v3/auer02a.html.\n[41] Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. Information-\ntheoretic regret bounds for gaussian process optimization in the bandit setting. IEEE Trans.\nInf. Theory, 58(5):3250–3265, 2012. doi: 10.1109/TIT.2011.2182033. URL https://doi.org/\n10.1109/TIT.2011.2182033.\n87\n\n[42] Kevin Swersky, Jasper Snoek, and Ryan Prescott Adams. Multi-task bayesian optimization. In\nChristopher J. C. Burges, L´eon Bottou, Zoubin Ghahramani, and Kilian Q. Weinberger, editors,\nAdvances in Neural Information Processing Systems 26: 27th Annual Conference on Neural\nInformation Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake\nTahoe, Nevada, United States, pages 2004–2012, 2013. URL https://proceedings.neurips.\ncc/paper/2013/hash/f33ba15effa5c10e873bf3842afb46a6-Abstract.html.\n[43] R´emi Bardenet, M´aty´as Brendel, Bal´azs K´egl, and Mich`ele Sebag. Collaborative hyperparameter\ntuning. In Proceedings of the 30th International Conference on Machine Learning, ICML\n2013, Atlanta, GA, USA, 16-21 June 2013, volume 28 of JMLR Workshop and Conference\nProceedings, pages 199–207. JMLR.org, 2013. URL http://proceedings.mlr.press/v28/\nbardenet13.html.\n[44] Michael A. Gelbart, Jasper Snoek, and Ryan P. Adams. Bayesian optimization with unknown\nconstraints. In Nevin L. Zhang and Jin Tian, editors, Proceedings of the Thirtieth Conference on\nUncertainty in Artiﬁcial Intelligence, UAI 2014, Quebec City, Quebec, Canada, July 23-27, 2014,\npages 250–259. AUAI Press, 2014. URL https://dslpitt.org/uai/displayArticleDetails.\njsp?mmnu=1&smnu=2&article_id=2460&proceeding_id=30.\n[45] Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. Multi-ﬁdelity multi-objective\nbayesian optimization: An output space entropy search approach. In The Thirty-Fourth AAAI\nConference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications\nof Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational\nAdvances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages\n10035–10043. AAAI Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/\nview/6560.\n[46] Syrine Belakaria, Aryan Deshwal, Nitthilan Kannappan Jayakodi, and Janardhan Rao Doppa.\nUncertainty-aware search framework for multi-objective bayesian optimization. In The Thirty-\nFourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative\nApplications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on\nEducational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February\n7-12, 2020, pages 10044–10052. AAAI Press, 2020. URL https://aaai.org/ojs/index.php/\nAAAI/article/view/6561.\n[47] Shinya Suzuki, Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, and Masayuki Karasuyama.\nMulti-objective bayesian optimization using pareto-frontier entropy. In Proceedings of the 37th\nInternational Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event,\nvolume 119 of Proceedings of Machine Learning Research, pages 9279–9288. PMLR, 2020. URL\nhttp://proceedings.mlr.press/v119/suzuki20a.html.\n88\n\n[48] Hisao Ishibuchi, Ryo Imada, Naoki Masuyama, and Yusuke Nojima. Dynamic speciﬁcation\nof a reference point for hypervolume calculation in SMS-EMOA. In 2018 IEEE Congress on\nEvolutionary Computation, CEC 2018, Rio de Janeiro, Brazil, July 8-13, 2018, pages 1–8. IEEE,\n2018. doi: 10.1109/CEC.2018.8477903. URL https://doi.org/10.1109/CEC.2018.8477903.\n[49] Andrea Ponti, Antonio Candelieri, and Francesco Archetti. A new evolutionary approach to\noptimal sensor placement in water distribution networks. Water, 13(12):1625, 2021.\n[50] Andrea Ponti, Antonio Candelieri, and Francesco Archetti. A wasserstein distance based\nmultiobjective evolutionary algorithm for the risk aware optimization of sensor placement.\nIntelligent Systems with Applications, 10:200047, 2021.\n[51] Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Jeanne M. VanBriesen,\nand Natalie S. Glance. Cost-eﬀective outbreak detection in networks. In Pavel Berkhin, Rich\nCaruana, and Xindong Wu, editors, Proceedings of the 13th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining, San Jose, California, USA, August\n12-15, 2007, pages 420–429. ACM, 2007. doi: 10.1145/1281192.1281239. URL https://doi.\norg/10.1145/1281192.1281239.\n[52] Bruno G. Galuzzi, Ilaria Giordani, Antonio Candelieri, Riccardo Perego, and Francesco Archetti.\nHyperparameter optimization for recommender systems through bayesian optimization. Comput.\nManag. Sci., 17(4):495–515, 2020. doi: 10.1007/s10287-020-00376-3. URL https://doi.org/\n10.1007/s10287-020-00376-3.\n[53] Nicolas Gillis, Le Thi Khanh Hien, Valentin Leplat, and Vincent Y. F. Tan. Distributionally\nrobust and multi-objective nonnegative matrix factorization. CoRR, abs/1901.10757, 2019.\nURL http://arxiv.org/abs/1901.10757.\n[54] Fei Zhu and Paul Honeine. Biobjective nonnegative matrix factorization: Linear versus kernel-\nbased models. IEEE Trans. Geosci. Remote. Sens., 54(7):4012–4022, 2016. doi: 10.1109/TGRS.\n2016.2535298. URL https://doi.org/10.1109/TGRS.2016.2535298.\n[55] Qiuzhen Lin, Xiaozhou Wang, Bishan Hu, Lijia Ma, Fei Chen, Jianqiang Li, and Carlos\nA. Coello Coello. Multiobjective personalized recommendation algorithm using extreme point\nguided evolutionary computation. Complex., 2018:1716352:1–1716352:18, 2018. doi: 10.1155/\n2018/1716352. URL https://doi.org/10.1155/2018/1716352.\n[56] Gaspard Monge. M´emoire sur la th´eorie des d´eblais et des remblais. Histoire de l’Acad´emie\nRoyale des Sciences de Paris, 1781.\n[57] Lev Kantorovitch. On the translocation of masses. Management Science, 1958. doi: 10.1287/\nmnsc.5.1.1. URL https://pubsonline.informs.org/doi/abs/10.1287/mnsc.5.1.1.\n89\n\n[58] Nicolas Bonneel, Gabriel Peyr´e, and Marco Cuturi.\nWasserstein barycentric coordinates:\nhistogram regression using optimal transport. ACM Trans. Graph., 35(4):71:1–71:10, 2016. doi:\n10.1145/2897824.2925918. URL https://doi.org/10.1145/2897824.2925918.\n[59] Gao Huang, Chuan Guo, Matt J. Kusner, Yu Sun, Fei Sha, and Kilian Q. Weinberger. Supervised\nword mover’s distance. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle\nGuyon, and Roman Garnett, editors, Advances in Neural Information Processing Systems 29:\nAnnual Conference on Neural Information Processing Systems 2016, December 5-10, 2016,\nBarcelona, Spain, pages 4862–4870, 2016. URL https://proceedings.neurips.cc/paper/\n2016/hash/10c66082c124f8afe3df4886f5e516e0-Abstract.html.\n[60] Mart´ın Arjovsky, Soumith Chintala, and L´eon Bottou. Wasserstein generative adversarial\nnetworks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International\nConference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017,\nvolume 70 of Proceedings of Machine Learning Research, pages 214–223. PMLR, 2017. URL\nhttp://proceedings.mlr.press/v70/arjovsky17a.html.\n[61] Yitong Meng, Xiao Yan, Weiwen Liu, Huanhuan Wu, and James Cheng. Wasserstein collabora-\ntive ﬁltering for item cold-start recommendation. In Tsvi Kuﬂik, Ilaria Torre, Robin Burke, and\nCristina Gena, editors, Proceedings of the 28th ACM Conference on User Modeling, Adaptation\nand Personalization, UMAP 2020, Genoa, Italy, July 12-18, 2020, pages 318–322. ACM, 2020.\ndoi: 10.1145/3340631.3394870. URL https://doi.org/10.1145/3340631.3394870.\n[62] Arturs Backurs, Yihe Dong, Piotr Indyk, Ilya P. Razenshteyn, and Tal Wagner. Scalable nearest\nneighbor search for optimal transport. In Proceedings of the 37th International Conference on\nMachine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings\nof Machine Learning Research, pages 497–506. PMLR, 2020. URL http://proceedings.mlr.\npress/v119/backurs20a.html.\n[63] Zhixian Chen, Tengfei Ma, Yangqiu Song, and Yang Wang. Wasserstein diﬀusion on graphs with\nmissing attributes. CoRR, abs/2102.03450, 2021. URL https://arxiv.org/abs/2102.03450.\n[64] Kirthevasan Kandasamy, Willie Neiswanger, JeﬀSchneider, Barnab´as P´oczos, and Eric P. Xing.\nNeural architecture search with bayesian optimisation and optimal transport. In Samy Bengio,\nHanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol`o Cesa-Bianchi, and Roman\nGarnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference\non Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr´eal,\nCanada, pages 2020–2029, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/\nf33ba15effa5c10e873bf3842afb46a6-Abstract.html.\n90\n\n[65] C´edric Villani. Optimal transport: old and new, volume 338. Springer Science & Business\nMedia, 2008.\n[66] Gabriel Peyr´e and Marco Cuturi. Computational optimal transport. Found. Trends Mach.\nLearn., 11(5-6):355–607, 2019. doi: 10.1561/2200000073. URL https://doi.org/10.1561/\n2200000073.\n[67] Rui Li, Fulan Qian, Xiuquan Du, Shu Zhao, and Yanping Zhang. A collaborative ﬁltering\nrecommendation framework based on wasserstein gan. In Journal of Physics: Conference Series,\nvolume 1684, page 012057. IOP Publishing, 2020.\n[68] Yuhong Zhang, Yuling Li, Yi Zhu, and Xuegang Hu. Wasserstein GAN based on autoencoder\nwith back-translation for cross-lingual embedding mappings. Pattern Recognit. Lett., 129:\n311–316, 2020. doi: 10.1016/j.patrec.2019.11.033. URL https://doi.org/10.1016/j.patrec.\n2019.11.033.\n[69] Kaan ¨Ocal, Ramon Grima, and Guido Sanguinetti. Parameter estimation for biochemical\nreaction networks using wasserstein distances.\nJournal of Physics A: Mathematical and\nTheoretical, 53(3):034002, 2019.\n[70] Piotr Indyk and Nitin Thaper. Fast image retrieval via embeddings. In 3rd international\nworkshop on statistical and computational theories of vision, volume 2, page 5, 2003.\n[71] Kubilay Atasu and Thomas Mittelholzer. Linear-complexity data-parallel earth mover’s distance\napproximations. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of\nthe 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long\nBeach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 364–373.\nPMLR, 2019. URL http://proceedings.mlr.press/v97/atasu19a.html.\n[72] M Fantozzi, I Popescu, T Farnham, F Archetti, P Mogre, E Tsouchnika, C Chiesa, A Tsertou,\nM Castro Gama, and M Bimpas. Ict for eﬃcient water resources management: the icewater\nenergy management and control approach. Procedia Engineering, 70:633–640, 2014.\n[73] Tiago A Schieber, Laura Carpi, Albert D´ıaz-Guilera, Panos M Pardalos, Cristina Masoller, and\nMart´ın G Ravetti. Quantiﬁcation of network structural dissimilarities. Nature communications,\n8(1):1–10, 2017.\n[74] Andrea Ponti, Antonio Candelieri, Ilaria Giordani, and Francesco Archetti. A novel graph-based\nvulnerability metric in urban network infrastructures: The case of water distribution networks.\nWater, 13(11):1502, 2021.\n91\n\n[75] Katherine A Klise, Regan Murray, and Terra Haxton. An overview of the water network tool\nfor resilience (wntr). 2018.\n[76] Kalyanmoy Deb, Karthik Sindhya, and Tatsuya Okabe. Self-adaptive simulated binary crossover\nfor real-parameter optimization. In Hod Lipson, editor, Genetic and Evolutionary Computation\nConference, GECCO 2007, Proceedings, London, England, UK, July 7-11, 2007, pages 1187–\n1194. ACM, 2007. doi: 10.1145/1276958.1277190. URL https://doi.org/10.1145/1276958.\n1277190.\n[77] G´abor Tak´acs, Istv´an Pil´aszy, Botty´an N´emeth, and Domonkos Tikk. Scalable collaborative\nﬁltering approaches for large recommender systems. J. Mach. Learn. Res., 10:623–656, 2009.\nURL https://dl.acm.org/citation.cfm?id=1577091.\n[78] F. Maxwell Harper and Joseph A. Konstan. The movielens datasets: History and context.\nACM Trans. Interact. Intell. Syst., 5(4):19:1–19:19, 2016. doi: 10.1145/2827872. URL https:\n//doi.org/10.1145/2827872.\n[79] Yi Zuo, Maoguo Gong, Jiulin Zeng, Lijia Ma, and Licheng Jiao. Personalized recommendation\nbased on evolutionary multi-objective optimization [research frontier]. IEEE Comput. Intell.\nMag., 10(1):52–62, 2015. doi: 10.1109/MCI.2014.2369894. URL https://doi.org/10.1109/\nMCI.2014.2369894.\n[80] Julian Blank and Kalyanmoy Deb. Pymoo: Multi-objective optimization in python. IEEE\nAccess, 8:89497–89509, 2020. doi: 10.1109/ACCESS.2020.2990567. URL https://doi.org/10.\n1109/ACCESS.2020.2990567.\n[81] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy.\nDiﬀerentiable expected hy-\npervolume improvement for parallel multi-objective bayesian optimization.\nIn Hugo\nLarochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien\nLin, editors, Advances in Neural Information Processing Systems 33:\nAnnual Con-\nference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-\n12,\n2020,\nvirtual,\n2020.\nURL https://proceedings.neurips.cc/paper/2020/hash/\n6fec24eac8f18ed793f5eaad3dd7977c-Abstract.html.\n[82] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham,\nAndrew Gordon Wilson, and Eytan Bakshy. Botorch: A framework for eﬃcient monte-carlo\nbayesian optimization.\nIn Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-\nFlorina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS\n2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/\n2020/hash/f5b1b89d98b7286673128a5fb112cb9a-Abstract.html.\n92\n\n[83] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David\nCournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St´efan J.\nvan der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew\nR. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, ˙Ilhan Polat, Yu Feng, Eric W.\nMoore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A.\nQuintero, Charles R. Harris, Anne M. Archibald, Antˆonio H. Ribeiro, Fabian Pedregosa, Paul\nvan Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc\nComputing in Python. Nature Methods, 17:261–272, 2020. doi: 10.1038/s41592-019-0686-2.\n[84] Cl´ement Maria, Jean-Daniel Boissonnat, Marc Glisse, and Mariette Yvinec.\nThe gudhi\nlibrary:\nSimplicial complexes and persistent homology.\nIn Hoon Hong and Chee Yap,\neditors, Mathematical Software - ICMS 2014 - 4th International Congress, Seoul, South\nKorea, August 5-9, 2014. Proceedings, volume 8592 of Lecture Notes in Computer Sci-\nence, pages 167–174. Springer, 2014.\ndoi: 10.1007/978-3-662-44199-2\\ 28.\nURL https:\n//doi.org/10.1007/978-3-662-44199-2_28.\n[85] R´emi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Zahdi Alaya, Aur´elie Boisbunon,\nStanislas Chambon, Laetitia Chapel, Adrien Corenﬂos, Kilian Fatras, Nemo Fournier, et al.\nPot: Python optimal transport. Journal of Machine Learning Research, 22(78):1–8, 2021.\n[86] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Christopher\nJ. C. Burges, L´eon Bottou, Zoubin Ghahramani, and Kilian Q. Weinberger, editors, Advances\nin Neural Information Processing Systems 26: 27th Annual Conference on Neural Information\nProcessing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe,\nNevada, United States, pages 2292–2300, 2013. URL https://proceedings.neurips.cc/\npaper/2013/hash/af21d0c97db2e27e13572cbf59eb343d-Abstract.html.\n[87] Nicolas Bonneel, Julien Rabin, Gabriel Peyr´e, and Hanspeter Pﬁster.\nSliced and radon\nwasserstein barycenters of measures. J. Math. Imaging Vis., 51(1):22–45, 2015. doi: 10.1007/\ns10851-014-0506-3. URL https://doi.org/10.1007/s10851-014-0506-3.\n[88] Martial Agueh and Guillaume Carlier.\nBarycenters in the wasserstein space.\nSIAM J.\nMath. Anal., 43(2):904–924, 2011. doi: 10.1137/100805741. URL https://doi.org/10.1137/\n100805741.\n[89] Marco Cuturi and Arnaud Doucet. Fast computation of wasserstein barycenters. In Proceedings\nof the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-\n26 June 2014, volume 32 of JMLR Workshop and Conference Proceedings, pages 685–693.\nJMLR.org, 2014. URL http://proceedings.mlr.press/v32/cuturi14.html.\n93\n\n[90] Paul Shannon, Andrew Markiel, Owen Ozier, Nitin S Baliga, Jonathan T Wang, Daniel Ramage,\nNada Amin, Benno Schwikowski, and Trey Ideker. Cytoscape: a software environment for\nintegrated models of biomolecular interaction networks. Genome research, 13(11):2498–2504,\n2003.\n[91] John H. Morris, Leonard Apeltsin, Aaron M. Newman, Jan Baumbach, Tobias Wittkop,\nGang Su, Gary D. Bader, and Thomas E. Ferrin. clustermaker: a multi-algorithm clustering\nplugin for cytoscape. BMC Bioinform., 12:436, 2011. doi: 10.1186/1471-2105-12-436. URL\nhttps://doi.org/10.1186/1471-2105-12-436.\n94",
    "pdf_filename": "Multi-Task Learning on Networks.pdf"
}