{
    "title": "Survey on Semantic Interpretation of Tabular Data: Challenges",
    "abstract": "Tabulardataplaysapivotalroleinvariousfields,makingitapopularformatfordatamanipula- tionandexchange,particularlyontheweb. Theinterpretation,extraction,andprocessingoftabular informationareinvaluableforknowledge-intensiveapplications. Notably,significanteffortshavebeen investedinannotatingtabulardatawithontologiesandentitiesfrombackgroundknowledgegraphs, aprocessknownasSemanticTableInterpretation(STI). STIautomationaidsinbuildingknowledge graphs,enrichingdata,andenhancingweb-basedquestionanswering. Thissurveyaimstoprovidea comprehensiveoverviewoftheSTIlandscape. Itstartsbycategorizingapproachesusingataxonomy of31attributes,allowingforcomparisonsandevaluations. Italsoexaminesavailabletools,assessing them based on 12 criteria. Furthermore, the survey offers an in-depth analysis of the Gold Stan- dards used for evaluating STI approaches. Finally, it provides practical guidance to help end-users choosethemostsuitableapproachfortheirspecifictaskswhilealsodiscussingunresolvedissuesand suggesting potential future research directions.",
    "body": "Survey on Semantic Interpretation of Tabular Data: Challenges\nand Directions\nMarco Cremaschi1 Blerina Spahiu2 Matteo Palmonari1\nErnesto Jimenez-Ruiz2\n1University of Milano - Bicocca\n{marco.cremaschi,blerina.spahiu,matteo.palmonari}@unimib.it\n2City, University of London\nernesto.jimenez-ruiz@city.ac.uk\nAbstract\nTabulardataplaysapivotalroleinvariousfields,makingitapopularformatfordatamanipula-\ntionandexchange,particularlyontheweb. Theinterpretation,extraction,andprocessingoftabular\ninformationareinvaluableforknowledge-intensiveapplications. Notably,significanteffortshavebeen\ninvestedinannotatingtabulardatawithontologiesandentitiesfrombackgroundknowledgegraphs,\naprocessknownasSemanticTableInterpretation(STI). STIautomationaidsinbuildingknowledge\ngraphs,enrichingdata,andenhancingweb-basedquestionanswering. Thissurveyaimstoprovidea\ncomprehensiveoverviewoftheSTIlandscape. Itstartsbycategorizingapproachesusingataxonomy\nof31attributes,allowingforcomparisonsandevaluations. Italsoexaminesavailabletools,assessing\nthem based on 12 criteria. Furthermore, the survey offers an in-depth analysis of the Gold Stan-\ndards used for evaluating STI approaches. Finally, it provides practical guidance to help end-users\nchoosethemostsuitableapproachfortheirspecifictaskswhilealsodiscussingunresolvedissuesand\nsuggesting potential future research directions.\nKeywords: SemanticTableInterpretation,SemanticAnnotation,Table,KnowledgeGraph,Table-\nto-KG Matching, Semantic Web\n1 Introduction\nTablesarewidelyusedandplayacrucialroleincreating,organising,andsharinginformation. Anotable\nexample of their significance as ways to organise human knowledge can be found in the oldest sample\nof writing on paper (on papyrus), dating back to around 2500 BC, in which Merer, an Egyptian naval\ninspector, documents his daily activities in a table (Fig. 1) [156].\nFigure 1: Portion of the diary of Merer (around 2600 BC), an official in charge of a team of workers\nresponsible for transporting limestone blocks from Tura to Giza to construct the Great Pyramid. The\ndocument details various aspects of the logistics involved in the transportation process, such as the\norganisationoflabour,theuseofboatstonavigatetheNileRiver,andthedailyactivitiesoftheworkers.\n1\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n4202\nvoN\n7\n]IA.sc[\n1v19811.1142:viXra\nToday, tables are extensively used in both business and scientific sectors, primarily in the form of\nspreadsheetsandothertabulardataformats. Theyfrequentlyappearindocuments,includingwebpages,\nand are used to publish large amounts of data on the web, especially after the uptake of the Open Data\nmovement. The large amount of tabular data consumed today covers a wide range of domains, such as\nfinance, mobility, tourism, sports, or cultural heritage [119]. The relevance and diversity of tabular data\ncan be sized by looking at the number of available tables and/or users of tabular data manipulation\ntools:\n• Web tables: in 2008 14.1 billion HTML tables were extracted, and it was found that 154 million\nwere high-quality tables (1.1%). In the Common Crawl 2015 repository, there are 233 million\ncontent tables1;\n• Wikipediatables: the2022EnglishsnapshotofWikipediacontains2803424tablesfrom21149260\narticles [110];\n• Spreadsheets: there are 750 million to 2 billion people in the world who use either Google Sheets\nor Microsoft Excel2.\nThe heterogeneity of tables and their application domains reflects differences in characteristics, such\nasthesize, cleanliness, andavailabilityofhuman-interpretabledescriptions(headers, metadata, descrip-\ntions of natural languages). Despite the simplicity of tabular data, understanding their meaning and\nautomating several downstream tasks remains challenging [60, 133].\nSemantic Table Interpretation (STI) encompasses various tabular data interpretation tasks that in-\nvolve labeling an input table using reference knowledge bases and shared vocabularies (these tasks\nare sometimes also referred to as table annotation or semantic modeling [151]). Since Knowledge\nGraphs (KGs) have become one of the most popular abstractions for knowledge bases and are equipped\nwithsharedvocabularies, STIcanbeunderstoodasatabletoKGsmatchingproblem. KGsareusedto\nrepresentrelationshipsbetweendifferententitiessuchaspeople,places,mountains,events,andsoon[72].\nTheyorganiseknowledgeingraphstructureswherethemeaningofthedataisencodedalongsidethedata\nin the graph. Resource Description Framework (RDF)3 is a data model for representing KGs that come\nwith an ecosystem of languages and protocols to foster interoperable data management. In RDF, most\nof the graph nodes represent instances and classes - referred to here as entities and types, respectively-\nandareidentifiedbyURIsorliterals (e.g.,strings,numbers); mostoftheedges,eachlabeledbyanRDF\nproperty, represent relations between nodes, i.e, two entities or an entity and a literal. Some of these\nedgeslinkentitiestotheirtypes(e.g.,dbo:City)ordatatypes(e.g.,xmls:integer). Finally,someedges\nare used to model the ontologies that organise the knowledge (e.g., subclass relations between types)\nand specify the meaning of the terms used in the graph through logical axioms. Labeling the elements\nof a table with elements of a knowledge graph supports their interpretation, e.g., by disambiguating the\nmeaning of the headers, or of the values that correspond to entities, and it is possible to transform the\ntable into actionable knowledge in different downstream application (see Section 1.1).\nSTI has developed as an active research area attracting the scientific community’s attention. An\nextensive number of approaches have been proposed to tackle STI tasks, from those that use heuristic\nmatching methods to those that use or include feature-based machine learning methods [106, 88] to the\nlatestonesthatuseorareentirelybasedonPre-trainedLanguageModels(PLM)suchasBERT[171,76]\nor generative Large Language Models (LLMs) like Llama [60, 179]. Additionally, studies have examined\nhow users approach reading tables [37]. Contributions to STI include methods inspired by a variety\nof Artificial Intelligence (AI ) paradigms and have been published in AI journals and conferences or\nin journals and conferences related to the sibling fields of Semantic Web, Natural Language Processing\n(NLP),andDataManagement(formoredetailsseeFig.8)[81,83,45];thisbroadscopesuggestthatthe\ntopic is considered relevant across different research sub-communities. Another initiative reflecting the\ninterest in the topic is the international Semantic Web Challenge on Tabular Data to Knowledge Graph\nMatching (SemTab), which has been proposed since 20194 and still running in 2024 [81, 83, 45]. The\ninitiative represents a community-driven effort to formalize the different STI tasks and develop shared\nevaluation protocols to compare different approaches.\nIn this paper, we propose a comprehensive survey on approaches proposed to address STI tasks,\nalso covering the latest approaches based on PLMs and LLMs. In Section 1.1, we present STI tasks\n1commoncrawl.org\n2askwonder.com/research/number-google-sheets-users-worldwide-eoskdoxav\n3www.w3.org/RDF/\n4cs.ox.ac.uk/isg/challenges/sem-tab\n2\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nNaturalPlace ...\n... dbo:mountainRange\nName Coordinates Height Range dbo:elevation\n... georss:point\nLe Mout Blanc 45° 49′ 57″ N, 06° 51′ 52″ E 4808 M. Blanc massif\nMountain xsd:string xsd:integer Mountain Range\nHohtälli 45° 59′ 20″ N, 7° 48′ 10″ E 3275 Pennine Alps\nSchema Level\nMonte Cervino 45° 58′ 35″ N, 07° 39′ 31″ E 4478 Pennine Alps Entity Level\nInput Data\nMount_Blanc 4808 Mou Mnt a_ sB sl ia fnc_\ndbo:elevation\ndbo:mountainRange\nFigure 2: Example of a well-formed relational table. Mount_Cervino ... Reference Knowledge Graph\nFigure 3: A sample of Knowledge Graph.\nmore precisely and summarise the impact of STI on research and applications and their challenges; In\nSection 1.2, we summarise the contributions of our paper and present its structure.\n1.1 STI: key definitions, impact and challenges\nInitsmostagreedandcompleteformalisation,theSTIprocessconsiderstwoinputs: i)arelationaltable,\nwhich is usually assumed to be well-formed and normalised (i.e., the table has a grid structure, where\nthe first row may contain the table headers and any other row contains values), as in Fig. 2; and ii) a\nreferenceKnowledgeGraph(KG)withitsvocabulary(i.e.,asetofsymbolsdenotingconcepts,datatypes,\nproperties, instances - also referred to as entities in the following) as in Fig. 3). The output of the STI\nprocess is a semantically annotated table, i.e., a table where its elements, typically values, columns,\nand column pairs, are annotated with symbols from the KG vocabulary. The exact specification of the\nannotations expected as the output of the STI process may differ in the proposed approaches. Here we\ndiscuss a canonical definition of a semantically annotated table to provide a first understanding of key\nSTI tasks, inspired by the SemTab Challenge, where the annotation process has been better formalised\nwith a community-driven effort.\nTo discuss this canonical definition, we use the example reported in Fig. 4.\nMountain xsd:string xsd:integer Mountain Range\ndbo:mountainRange\ndbo:elevation Schema Level\ngeorss:point Entity Level\nMount_Blanc 4 05 6° ° 4 59 1′ ′ 5 57 2″ ″ N E 4808 Mou Mnt a_ sB sl ia fnc_\nName Mountain Coordinates xsd:string Height xsd:integer Range Mountain_Range georss:point\nLe Mout Blanc Mount_Blanc 45° 49′ 57″ N, 06° 51′ 52″ E 4808 M. Blanc massif Mount_Blanc_Massife dbo:elevation\ndbo:mountainRange\nHohtälli [NIL: Hohtälli] 45° 59′ 20″ N, 7° 48′ 10″ E 3275 Pennine Alps Pennine_Alps\nMonte Cervino Mount_Cervino 45° 58′ 35″ N, 07° 39′ 31″ E 4478 Pennine Alps Pennine_Alps Hohtälli 4 75 °° 45 89 ′ ′ 12 00 ″″ EN 3275 Pennine_Alps\nAnnotated table georss:point dbo:elevation dbo:mountainRange\nMount_Cervino ... Statements derived from annotations\nFigure 4: Example of an annotated table.\nGiven:\n• a relational table T (Fig. 2);\n• a Knowledge Graph and its vocabulary (Fig. 3).\nT is annotated when:\n• eachcolumnisassociatedwithoneormoretypesfromtheKG[Column-TypeAnnotation(CTA)];\ne.g., the column Name in the Fig. 2 is annotated with the type Mountain; the column Height is\nannotated with datatype xsd:integer;\n• each cell in “entity columns” is annotated with an entity identifier or with NIL, if no entity in\nthe KG corresponds to the cell value [Cell-Entity Annotation (CEA)]; e.g., the cell Le Mout Blanc\nis annotated with Mont Blanc; the cell Hoht¨alli is annotated with NIL since it has not yet been\nincluded in the KG;\n3\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n• somepairsofcolumnsareannotatedwithabinaryproperty[Columns-PropertyAnnotation(CPA)];\ne.g., the pairs composed by the columns Name and Hight is annotated with dbo:elevation.\nThe result of the annotation process for the table considered in the example is shown in Fig. 4. Observe\nthat each bullet point can be interpreted as a high-level STI task to complete; also, the annotations can\nidentify in the table new entities not included in the reference KG (e.g., Hoht¨alli).\nSTIplaysarelevantroleintheAI researchandapplicationslandscape. Fromaresearch perspec-\ntive,thecapabilityofperformingSTItaskssuchasCEA,CTA,CPAareconsideredpartofabroaderset\nof tabular data understanding skills [171, 53, 179], which impact the application of AI to tabular data.\nAlso,CEAcanbeconsideredavariantofentitylinkingintexts,whileCTAandCPAarenottoodifferent\nfrom ontology matching when applied to different data formats (entity linking and ontology matching\nare both considered AI tasks [104, 95, 76]). From an application perspective, STI tasks can support\nthe automation of processes to construct and extend knowledge bases [166, 86] and enrich tabular data,\neventuallysupportingdownstreamapplicationstodataanalysis. Toprovideanideaofthecontributions\nof STI to these automation processes, we refer to Fig. 5. For KG construction, CTA and CPA anno-\ntations support the automatic or semi-automatic transformation of the data into a graph format with\nthe schema of the reference KG [66, 135, 129, 154]; CEA annotations disambiguate values in the input\ntable, thus supporting the reuse of canonical entity identifiers in the generated data [46, 31]. The same\nprinciples can be applied to support KG extension processes [168, 178], by adding to the graph only the\nnewentitiesandtriplesrepresentedinthetable. STIannotationscanbeusefulindata enrichment tasks\nwhere the generation of graph data is not needed, but links to entities in the KG can be used to query\ntheKG[68,23]orotherthird-partydatasources[126,47,32],augmentingtheinputdataandextending\nthe features used to develop analytical models. Other applications of STI annotations proposed in the\nliterature or potentially impactful on emergent services include the improvement of search engines and\nrecommender systems for tabular data [18, 24, 176, 177, 17] and question answering [171, 50].\nFigure 5: Examples of applications supported by STI.\nMachine interpretation of tabular data is challenging because of the limited context available to\nresolve semantic ambiguities, the layout of tables that can be difficult to handle, and the incompleteness\nof KGs in general.\nKey challenges involved in the annotation process include:\n• Dealing with the heterogeneity of domains and data distributions: thetablesmaycoverinformation\nthatreferstoverydifferentdomains(e.g.,Geographyvs Sports);thespecificityofthetablecontent\nmay vary significantly (from a table with basic information about most famous mountains, like\nFig. 2 to table that contains the composition of the rocks of this mountains5).\n• Dealing with limited contextual information: if compared with similar interpretation and disam-\nbiguation tasks on the textual document, the presence of contextual clues to support the interpre-\ntation and annotation of table elements may be limited and very diverse depending on the data\nsources;forexample,tableheadersareoftenmissing. Tablesinopendataportalsmaybedescribed\nby metadata, while tables published on web pages may have some surrounding text.\n• Detecting the type of columns: in a table, there can be columns that contain references to named\nentities(NE-columns)andcolumnsthatcontainstrings,numbers, dates,and,ingeneral,instances\n5en.wikipedia.org/wiki/List of rock formations\n4\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nof specific data types, which we refer to as literals (LIT-columns); distinguishing between the two\ntypes of columns is crucial to support the annotation process.\n• Matching tabular values against the KG: matching the values in the table to the data in the KG\nhelps collect evidence to interpret the table. However, the values referring to entities in the table\nmay differ from their labels in the KG, e.g., because of acronyms, aliases, and typos, while other\nvalues representing their features may differ for several reasons, e.g., because outdated, measured\ndifferently, and so on.\n• Dealing with multiple entities with similar names: the KG may contain many entities with similar\nor even equal names (homonyms) that have different or even the same types. For example, the\nmention of the Italo-French mountain Mont Blanc in Fig. 2 matches labels of more than a dozen\nentities, including a tunnel, a poem, a dessert, and another mountain on the moon6.\n• Dealing with Not In Lexicon (NIL)-mentions: some entities referred to in the table may not exist\nin the KG; while several approaches perform CEA by simply selecting the best candidate, i.e., the\nentitywiththehighestscoreaccordingtotheapproach,recognizingnewentitiesrequiresadecision\nwhether to link or not to link, which may be subtle.\n• Choosing the most appropriate types and properties: theKGmaycontainhundredsorthousandsof\ntypesandpropertiestochoosefromforannotatingcolumnsandcolumnpairs. Thefeaturesoflarge\nKGs make the decision even more challenging: entities are classified under multiple types, which\nmayreflectdifferentlevelsofspecificity(e.g.,MontBlanccanbeclassifiedasamountain,asummit,\na pyramidal peak, and so on, up to a geographic location); the specificity of the classification may\nchangedependingontheentity; severalpropertieshavesimilarmeanings,associatedwithdifferent\nlevels of specificity or different usage patterns [132].\n• Aggregate evidence from different tasks: the annotation of a table is, in principle, a collective\ndecision-making process; for example, the disambiguation of entities in a column helps suggest\ntypes to annotate the column (e.g., most of the best candidates for mountain mentions in Fig. 2\naremountains),butatypeorasetoftypesassociatedwithacolumnmayhelpdisambiguateentities\nmentioned therein (e.g., non-mountain candidate entities for “Mont Blanc”); finding strategies to\nmaximise evidence exchange across tasks requires multiple iterations or sophisticated aggregation\nmechanisms.\n• Dealingwithamountandshapeofdata: dependingontheapplicationscenarios,itmaybenecessary\nto process a large number of small tables or very large tables [31], which may imply different\nconstraints on the approaches or introduce slightly different challenges; more scenarios may also\nbecome more relevant in the future, such as processing streaming data that can be formatted as\ntabular data.\n1.2 Specific contributions and structure of the manuscript\nIn the presentation of this comprehensive survey on STI we make the following more specific contribu-\ntions, which highlights the main differences with previous surveys published on the same topic (see also\nSection 2.1 for a more detailed comparison):\n• A new taxonomy to organise and compare reviewed approaches comprising 31 specific attributes;\n• A new systematic literature review on 88 STI approaches published until October 2024, including\nlatest approaches based on LLMs;\n• Analysis of existing tools that support STI and a comparison between their functionality features;\n• Analysis of the Gold Standard (GS) used to evaluate STI approaches;\n• A guide that can help researchers and practitioners locate STI approaches most suited to their\ntasks;\n• Highlight and discuss open issues and future research directions.\n6en.wikipedia.org/wiki/Mont Blanc (disambiguation)\n5\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nThe paper is organised as follows: Section 2 highlights the differences between this survey and\nother similar surveys in the STI field and discusses the methodology used to collect all approaches\nreviewed in this paper. Section 3 defines a taxonomy composed of 31 attributes used to compare STI\napproaches. Sections from 4 to 9 help readers gain a comprehensive understanding of the techniques\nand solutions proposed so far. Section 10 draws open issues and future directions while Section 11\nconcludes the paper. The appendix section contains valuable and additional information regarding\nSTI approaches. Appendix A details information about the methodology to conduct the survey and\ncomparisons of approaches. Appendix B discusses tools for the STI process while Appendix C analyses\ntheGoldStandards(GSs)usedbySTIapproachestoevaluatetheirperformance. Additionalinformation\nabout approaches is provided in Appendix D.\n2 Scope and Methodology\nThis Section highlights the differences between this survey and other similar surveys in the STI field.\nThe second part describes the methodology we applied to our systematic literature review, based on\nthe well-established PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses)\nmethod7. Details on the systematic review results serve as a basis for the comprehensive analysis in the\nfollowing Sections.\n2.1 Differences from other STI surveys\nSTI approaches have been analysed in a few surveys [88, 177, 21, 106]; [88, 177, 21] have been published\nbefore the explosion in volume of STI related-works, also as a consequence of the SemTab challenge.\nMost recently, Liu et al. [106] aims to complement these surveys by providing a new classification of\nSTI approachesreflecting theheterogeneityof tabular dataand theresulting newchallenges. We aimto\nupdate and extend previous surveys by introducing a new classification schema of STI approaches and\ndiscussing new research directions in improving such systems. Nevertheless, our analysis encompasses\nnot only recent works but also older ones, allowing us to derive comprehensive guidelines (Section 10)\nfor selecting approaches based on specific user needs. Furthermore, we can identify and highlight the\nunresolved issues which are yet to be addressed.\nTo provide clarity, we highlight the following differences with the previously published surveys:\n• Survey scope: through a rigorous snowballing approach, we collected a comprehensive list of STI\napproaches that allowed us to discover 88 works. Moreover, our survey includes works of a wider\ntimeline (2007-2023);\n• Taxonomy: considering the comprehensive list of all the works in this field allowed us to specify\nand classify STI systems using different orthogonal dimensions. In this survey, we identify 31\ndimensions;\n• Processes: providing a better understanding of the entire processes of STI by shedding light on\neach step;\n• Deeper investigation: examining a wider range of approaches enabled us to delve deeper into the\nfield,thus,helpingresearchersandpractitionerstobetterunderstandandinspireimprovedornovel\napproaches. Similarly to [106], we delve into a more comprehensive comparison of the evaluation\nprocess;\n• Opportunitydiscovery: uncoveringresearchopportunitiesoftheexistingapproaches. Forinstance,\nunlike [177] and [106], we provide a more detailed analysis of the potentials of the available STI\napproaches;\n• Additional sections: including other important elements, e.g., delving deep into tools and GS, this\nsurvey provides the complete landscape of the STI process.\nAcomparisonofthesurveysispresentedinTable1,whichreflectstheaboveattributesandhighlights\nthe differences between them.\nTwoadditionalsurveys[15,62],whicharepartiallyrelevanttoSTI,werealsoconsidered. Unlike[62],\nourworkprovidesamorecomprehensiveanalysisofvariousapproachestotheEntityLinking(EL)task,\n7prisma-statement.org\n6\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\naccompanied by an in-depth discussion of the associated challenges. However, in contrast to [15], which\ndelvesintothetechnicalspecificsofentityresolutionusingNeuralNetwork(NN),ourfocusislessspecific\non technical details because it covers all STI methodologies.\nAttribute Thissurvey 2019[88] 2020[177] 2021[21] 2023[106]\nNo.ofApproaches 85 16 47 12 42\nYearsrange 2007—2023 2009—2017 2002—2019 2010—2019 2011—2021\nGoldStandards\n21 7(briefanalysis) 8\nanalysis\nFormalisationof\ntheSTIpipeline\n31 6 6 5\nTableclassification Tableexpansion Tableexpansion Lookupbased\nComparison at- NLPTasksonTable Tableinterpretation Tableinterpretation Iterative\n0\ntributes OtherProjects Tablesearch Tablesearch Featurebased\nDiscover and Under- Questionanswering Questionanswering KGmodelling\nstand KGaugmentation KGaugmentation Tablemodelling\nTableclassification\nTableclassification\nAdditionalsections Tools — — (extensionof[177])\nTablecorpora\nEvaluationcomparison\nFocusonother Focusontable\nNote — OnlyWebtables —\ndownstreamtasks understanding\nTable 1: Comparison between surveys on STI.\n2.2 Methodology\nTheobjectiveofthissystematicreviewistoprovideasynthesisofthestateofknowledgeandsuggestions\nfor future research. The PRISMA method has been designed to provide detailed reporting guidelines\nfor such reviews to ensure a comparable and comprehensive result. This method typically encompasses\nthreestages: i)identification,ii)screening,andiii)selection. Inthissection,weprovideashortoverview\nof the methodology employed to conduct this survey. Please refer to Appendix A.1 for more details.\nIn the identification stage, to efficiently search in different databases for related works, we defined\na set of 16 keywords related to semantic table interpretation. These keywords were ranked based on\nrelevance by five researchers. We conducted searches on platforms including Scopus, Web of Science,\nDBLP,andGoogleScholar,coveringtheperiodfrom2007toMay2023. Wealsoemployedasnowballing\ntechnique to include recent publications referencing key works.\nInstead, in the screening stage, two experts manually reviewed the identified papers, focusing on the\nsemantic table interpretation phases of the approaches and their relevance. A categorization process\nwas performed based on title, abstract, and keywords. Specific criteria were used, including generic and\nspecific annotation tags, to determine relevance.\nIn the selection stage, publications included in this survey were required to be directly related to\nsemantic table interpretation, published in English, and peer-reviewed. Using the specified keywords\ndefined within the PRISMA method, 134 papers were initially identified, which were reduced to 111\nafter the screening process. Manual annotation and further screening led to the exclusion of 17 papers,\nresulting in a total of 88 approaches discussed in the survey.\n3 Taxonomic analysis of STI Approaches\nIntroducing a taxonomy of features that characterise different STI approaches8 as to main objectives:\ni) defined STI more precisely by describing the tasks and subtasks, ii) allows us to comprehensively\nunderstandthevariousapproachesandtheiruniquecontributionstothefield. Fig.6depictsahigh-level\ntaxonomy of the features of STI approaches. The features are organised into dimensions. By analysing\neach dimension individually, we will present the main characteristics of the approaches proposed so far.\nThe reader should note that many dimensions are orthogonal; thus, an approach may be classified into\nmultiple other ones. To ensure that the information presented in the survey was verified and complete,\nwe contacted the authors via email and received 45 responses.\n8unimib-datai.github.io/sti-website/approaches/\n7\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nCPACTACEA\nTask\ntnednepeD\nDomain\nIndependent\nApplicati Po\norn/\npose\nLicence\nVaC ll io ds s Ce o ad tu ir oc oe\ndn\ne\naOp vse aon iu lr ace\nbility\nFeature\ndeS teuC cbN tj ieE oc nA t A TP AP XR OS OT NAI\nO\nC MHE YS U Tos oe lr Interface/ Annotation\na cn ln ao\nsC\nstT a\no\nify lt iui cp o\nm\nae n\ntin os n\nlE in nti kity ng\naD nna aPota nrta Net\nn\nIy t\nd o\nLip\ni\nto\nc\nae an\na t nit noe on\ntation\nHybrid\nSuS peu rvib seta dsk\nUnsupM ere vt ish edod\nFully\nautomatedRevision\nim eSdetam\notua\nfoO rmuI t apn tup tut KGSource\nstT or rip\neleInT da eb xle\nFigure 6: A taxonomy of the STI approaches.\nTASKS TASKS provide the conceptualisation of the output that STI approaches are expected to\nreturn. TASKS have been defined precisely because the quality of the output of the approaches is\nusually evaluated (only) against them. In this paper, we consider the TASKS that have been formalised\nin previous works [82, 83] or have appeared in the latest challenges:\n• CTA: theCTAtaskconcernsthepredictionofthesemantictypes(i.e.,KGclasses)foreverygiven\ntable column in a table.\n• CPA: the CPA task concerns the prediction of semantic properties (i.e., KG properties) that\nrepresent the relationship between some pair of columns.\n• CEA: the CEA task aims to predict the entity (i.e., instances) that a cell in table represents.\n• Cell-New Entity Annotation (CNEA): the CNEA task aims to predict which cell in the table\nrepresents an entity that does not occur in the KG and should be therefore labelled as NIL.\nNote that CTA (resp. CEA) task focuses on annotating table columns (resp. cells) that can be\nrepresented with a KG class/type (resp. KG entity). The formal definition presented in this Section is\nmore precise but less flexible than the intuitive definition provided in the introduction. The reason for\nthis choice is that most existing approaches in the literature focus on specific tasks that require a more\nrigorous definition. However, in the last section of this work, we will explore an expanded version of this\nformalisation that accounts for different application scenarios.\nSUB-TASK The STI process involves coordinating multiple specific annotation sub-tasks that con-\ntributetothefinalresults. Thesesub-tasksaremorefocusedthantheoverallconceptualtasksmentioned\nearlier. Approaches may vary in how they coordinate and the algorithms they employ for each sub-task.\nThis aspect evaluates an approach’s coverage of the sub-tasks within the STI process. We believe that\nthe granularity of the sub-task classification is the best one to report different techniques proposed in\nthe literature so far (Section 4). Some approaches implement just a few sub-tasks, while others consider\nthe implementation of all sub-tasks listed below.\n(i)ColumnClassification considersthecontentofthecellsofeachcolumntomarkacolumnasLiteral\ncolumn(LIT-column)ifvaluesincellsareliterals(e.g.,strings,numbers,datessuchas4808,10/04/1983),\norasNamed-Entity column (NE-column) ifvaluesareentities,instancesoftypes(e.g.,Mountain,Moun-\ntain Range such as Le Mout Blanc, M. Blanc massif). The Column Classification sub-task is useful,\nespecially, for the CEA and CTA tasks because the identification of NE-columns helps to concentrate\nthe Entity linking task on specific cells and the Type Annotation tasks on specific columns;\n8\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n(ii) Subject Detection has the goal of identifying, among the NE-columns, the column that all the\nothers are referring to, also called S-column (e.g., the Name column in Fig. 4). The Subject Detection,\nin some cases, is useful for the CPA task because it allows to find relations between other columns;\n(iii)TypeAnnotation pairsNE-columnswithconceptsoftheKG(e.g.,thecolumnNameisannotated\nwith Mountain in DBpedia). This sub-task represents the final output of the CTA task;\n(iv) Entity linking links cell to entity in the KG (e.g., the cell Le Mout Blanc is annotated with\ndbo:Mont Blanc in DBpedia). This sub-task represents the final output of the CEA task;\n(v)Datatype Annotation pairsLIT-columnswithadatatypeintheKG(e.g.,thecolumnCoordinates\nis of type georss:point). The Datatype Annotation sub-task is used in CPA because fine-grained types\nof Lit-columns are easier to match against KGs;\n(vi)PredicateAnnotationidentifiestherelationsbetweeneachpairofcolumns(e.g.,Namedbo:elevation\nHeight). This sub-task represents the final output of the CPA task;\n(vii) NIL Annotation considers strings that refer to entities for which a representation has not yet\nbeencreatedwithintheKG,namelyNIL-mentions (e.g.,thementionHoht¨alli). Thissub-taskrepresents\nthe final output of the CNEA task.\nThese sub-tasks are sometimes preceded by a sub-task of Data Preparation that is used to normalise\nthe contents (e.g., by standardising the case of letters and the format of numbers) to avoid the presence\nof syntactical discrepancies that can make annotation techniques ineffective.\nEach sub-task is computed by annotating cell values referring to one or more KGs. The general\napproach consists of searching the KG with the content of columns to find possible matching. For\nexample, if the majority of entities in the Name column (Fig. 4) is associated with dbo:Mountain, then\nallentitiesinthecolumncanbeassumedoftypedbo:Mountain. Similarly,ifthemajorityoftheconcepts\noftypedbo:Mountainareconnectedtodatatypesoftypexsd:integerbythepropertydbo:elevation,\nthenitcanbeidentifiedasthepropertyconnectingtheNamecolumnwiththeHeightcolumn. However,\nit is important to note that this approach only applies to trivial cases. Employing advanced methods\nandtechniquestoaddressambiguousresultsfrequentlyoccurringinreal-worldtablesbecomesnecessary\nto tackle more complex scenarios. These methods aim to identify suitable matches for elements that\ncannot be directly linked to entities within a KG.\nMETHOD Another crucial dimension in reviewing works on STI is the classification based on the\nmain algorithmic idea behind each approach. It is possible to identify three METHODS:\n• SUPERVISED category collects approaches that rely on a training set (e.g., a set of tables already\nannotated) that learn the annotations before applying them to the target tables;\n• UNSUPERVISED category collects approaches that do not use annotated data;\n• HYBRID category instead, collects approaches combining the above two categories.\nREVISION Some approaches are fully automated, while others require user intervention to select or\nvalidate annotations.\nDOMAIN Approachescantargettableswithgeneralorspecificdata(e.g.,biodata,geospatialdata).\nAPPLICATION/PURPOSE This dimension refers to the use of the approach for particular appli-\ncation purposes such as data enrichment, KG construction and KG extension. Annotated data might\nbe used as links to find new information for the entities in the table, thus enriching the input, or oth-\nerwise to extend and enrich KGs as described in Section 1. Moreover, supposing tables are specific to a\ngivendomain, thedatamightbeannotatedusingspecificontologiesorvocabulariestoconsiderthefinal\nannotations as newly constructed KG.\nLICENSE Whenitcomestoensuringreproducibilityinresearch,itiscrucialtoconsiderthelicensing\naspect. In this regard, we distinguish between different licensing models that govern the availability and\nuse of approaches:\n• OPEN SOURCE category collects approaches published under an open source license, facilitating\ncomparison and reuse (e.g., Apache, MIT);\n• CLOSED SOURCE assemble STI approaches, for which the code is not provided, and as such, it\nis not straightforward to implement or compare it;\n9\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n• NOT SPECIFIED approaches that do not specify any license information.\nVALIDATION The approaches might be validated using different GSs. Some use and validate their\nannotations using well-known GSs, and others provide a new GS together with the release of the new\napproach.\nCODE AVAILABILITY From a practical perspective, it is interesting to know the availability of\nthe code of a given STI approach.\nUSER INTERFACE/TOOL Several STI approaches also implement a User Interface (UI) so that\nthe STI process can be consumed and explored by users.\nINPUTS One of the dimensions for the classification of the approaches is the required INPUTS.\nAmong INPUTS, we can distinguish between SOURCES that are to be annotated and additional re-\nsources (KG) that support the annotation process.\n• SOURCES: different systems might need different input sources. Three sources are identified:\n(i) TABLES are most frequently considered as input (e.g., CSV files, XML files, Spreadsheets,\nand HTML files), (ii) ANNOTATIONS from already annotated data used as training datasets\n(supervised approaches), and (iii) FEATURES that support the STI approach with additional\ninformation such as out-table context (e.g., page title, table caption, texts).\n• KG: theannotationprocessisfacilitatedusingKGs. AKGcanbestoredbya(i)TRIPLESTORE\nthat supports entity searches by lookup APIs (e.g., DBpedia SPARQL Query Editor),and by (ii)\nINDEXING that allows efficient querying of large KGs that would otherwise require significant\ntime and resources.\nOUTPUTS The annotated data might be exported into different formats, such as RDF/XML, N3,\nand CSV.\n4 Sub-tasks\nThe taxonomy dimension SUB-TASKS refers to the completeness of the approach concerning the sub-\ntasksoftheSTIprocess. Someapproachesimplementjustafewsub-tasks,whileothersconsidertheim-\nplementation of all sub-tasks: i) Data Preparation (Section 4.1), ii) Column Classification (Section 4.2),\niii) Datatype Annotation (Section 4.3), iv) Subject Detection (Section 4.4), v) Entity Linking (Sec-\ntion 4.5), vi) Type Annotation (Section 4.6), vii) Predicate Annotation (Section 4.7), and viii) NIL\nAnnotation (Section 4.8).\n4.1 Data Preparation\nData Preparation is usually the first sub-task in an STI pipeline. This sub-task transforms the raw data\ninto a format suitable for analysis. Data Preparation plays a crucial role in STI as it ensures that the\ndata is appropriately structured and ready for analysis, enabling accurate interpretation and extraction\nofmeaningfulinsights. Itinvolvestransformingthevalueswithincellstoastandardisedformat,ensuring\nconsistency, and facilitating subsequent sub-tasks by eliminating variations in representation [56].\nTables consist of numerous cells with literal values that cannot be directly linked. Literal values\nencompassvarioustypes,includingnumericquantities,dates,andcoordinates. Multipledatapreparation\nsub-taskscanbeemployedtocleanandformatthesedatatypes. Forinstance,numericquantitieswithin\na column can be converted to a joint base unit. For example, values such as 10kg, 100g, and 34t,\nrepresenting weights, can be interpreted and converted to kilograms. The date is another frequently\nencounteredliteraltype,oftenappearingindiverseformatssuchas“4October1983”,“4-10-1983”,“Oct\n4, 1983”, “October 4, 1983”, “1983/10/4”, or “1983.10.4.” Normalising numeric and date values can\nbe challenging. However, it can significantly improve subsequent sub-tasks in the pipeline. Moreover,\ntable cells sometimes contain extraneous values, such as text in brackets or special characters, which\ncan confuse entity-linking algorithms and result in poor annotations. Hence, omitting such values can\nenhance the reliability and accuracy of the final results.\n10\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nIndeed, many state-of-the-art (SOTA) approaches in the field recognise the value of the Data Prepa-\nration sub-task and incorporate it before proceeding with other sub-tasks in the pipeline [63, 43, 116,\n115, 134, 175, 138, 55, 56, 180, 85, 176, 26, 35, 74, 120, 147, 174, 1, 12, 14, 38, 34, 29, 91, 143, 161,\n172, 9, 123, 3, 2, 4, 36, 78, 77, 75, 122, 123, 13, 64, 163, 181, 11]. These approaches can also be split\ninto multiple orthogonal categories depending on the type of data preparation technique they perform.\nThe most commonly used techniques are: i) spell checking [1, 3, 2, 4, 12, 29, 91, 172], ii) units of\nmeasurements conversion [175, 138, 56, 35, 14, 38], iii) cell cleaning [63, 134, 115, 138, 55, 85, 26,\n35, 36, 34, 3, 2, 4, 12, 14, 13, 38, 161, 9, 123, 163, 11], iv) acronym expansion [116, 138], v) format\ntranslation [43, 134, 64], and vi) language detection [56, 120].\nThe spell checking technique involves the automatic detection and correction of spelling errors in\nthe text. Some approaches employ this technique to clean table content and improve the accuracy and\nreadability of text [1, 12, 29, 91, 172]. The most used method to fix typos in the cells is by invoking\nautocorrection libraries: JenTab [1, 3, 2, 4] invokes Autocorrect library while Azzi et al. [12] invokes\nGurunudi and Wikipedia API. In the SOTA there are other libraries for the same purpose: TextBlob,\nSpark NLP, Pyspellchecker, Serpapi. LinkingPark [29] handles spelling errors by applying a tailored\nspelling corrector, which performs a one-edit distance check between each cell and a set of candidate\nentities. [91, 172] manage errors such as misspellings, incorrect spacing, and omission of special symbols\nor numbers by crawling through search engines (e.g., Google and Yandex)9.\nAnotherDataPreparationsub-stepintheSOTAistheunits of measurements conversion which\ninvolvesidentifyingtheunitsinthetableandapplyingappropriatemathematicalformulasorconversion\nfactors to convert the values into a standardised unit or a desired unit of measurement. This ensures\nuniformity and facilitates meaningful data analysis. Several approaches incorporate a numerical con-\nversion [175, 138, 56, 35, 14, 38]. InfoGather+ [175] assumes that there is a canonical string for every\nunit and scale. The system implements a set of conversion rules defined by the system administrator.\nThis process considers three components: left-hand side (LHS), right-hand side (RHS) and θ. LHS and\nRHS are strings that describe units and scales, while θ represents the conversion factor. Another ap-\nproachdevelopedbyRitzeetal.[138]normalisesunitsusingasetofmanuallygeneratedconversionrules\n(around200). InEll’sapproach[56], aconversionprocessisemployedforvaluesthatpertaintoweights,\nlengths, volumes, and times. This involves a classic pattern-matching technique, where a unit of mea-\nsurement follows a numeric value. Also, in MantisTable [41, 35, 40, 38], unit normalisation is achieved\nbyutilisingRegularExpressions(Regex)basedontherulesinitiallydescribedinInfoGather+[175],and\nthen it extends them to cover a complete set of units of measurement. The same technique is applied in\nKepler-aSI [14].\nThe most critical and applied technique in the Data Preparation sub-task is cell cleaning because\nit removes or modifies unnecessary or unwanted elements in a cell. In [115], tables are cleaned and\ncanonicalised (fixing syntax mistakes) using CyberNeko10 while [138, 35, 38, 1, 3, 2, 4, 14, 161, 123]\ncleans cells by removing HTML artefacts, special characters and additional whitespaces. Subsequent\napproaches [34, 147, 9, 36, 163, 11] use a more straightforward process by removing only parentheses\nand special characters. During the table loading step, the AMALGAM approach [12] incorporates the\ncapability to clean cells by addressing incorrect encoding through the utilisation of the Pandas library.\nSeveral approaches, including JenTab [1], MTab [120], and bbw [143], incorporate the ftfy library11\nwithin the cleaning step. This integration allows for the resolution of broken Unicode characters found\nin various forms, such as transforming “The Mona Lisa doesnA˜ƒAˆ¢A˜¢ˆa€ˇsAˆ¬A˜¢ˆa€ˇzAˆ¢t have eyebrows”,\nwhich converted to “The Mona Lisa doesn’t have eyebrows”. In the successive MTab4WikiData im-\nplementation [122], the preprocessing is simpler because of the effectiveness of the fuzzy entity search.\nKacprzak et al. [85] removes non-numerical chars from numeric columns. In DAGOBAH [26] encod-\ning homogenisation and special characters deletion (parentheses, square bracket and non-alphanumeric\ncharacters) are applied to optimise the lookups. The implementation was improved in the subsequent\nversion of DAGOBAH [78, 77, 75]. Some approaches [134, 55, 180, 35, 38, 1, 3, 2, 4, 13] apply stop-word\nremoval in this sub-task.\nTables often include acronyms and abbreviations, shortened terms formed by combining multiple\nwords’ initial letters or parts. To address such cases, several approaches employ acronym expan-\nsion [116, 138, 35, 14]. For instance, Mulwad et al.’s approach [116], recognises and expands acronyms\n9pypi.org/project/autocorrect, github.com/guruyuga/gurunudi, wikipedia.readthedocs.io/en/latest/code.html,\ntextblob.readthedocs.io/en/dev, nlp.johnsnowlabs.com, github.com/barrust/pyspellchecker, serpapi.com/spell-check,\nyandex.com\n10nekohtml.sourceforge.net\n11github.com/rspeer/python-ftfy\n11\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nand stylised literal values like phone numbers. Another approach [138] utilises transformation rules to\nresolve abbreviations, such as converting “co.” to “company”. MantisTable [35] leverages the Oxford\nEnglish Dictionary12 to decipher acronyms and abbreviations. Similarly, Kepler-Asi employs heuristic\nmethods to resolve acronyms and abbreviations [14].\nAnother possible data preparation technique is format translation which consists of translating\ndataintoadifferentstructure. Forexample,Cruzetal.[43]andQuercinietal.[134]translategeographic\nand temporal information into spatial and time series. In Tab2KG [64], the data is transformed in RDF\nMapping Language (RML) format.\nEventually, language detection implies detecting the language of the mentions to best address the\nsuccessive Entity Linking. Ell [56] applies some Regex to detect languages, while [120] uses pre-trained\nfastText models13 to predict the language of the whole table.\nMany approachesdonot specifyhowthe datais prepared tobeprocessed [70,71,157, 105,117,151,\n118, 162, 94, 131, 164, 22, 49, 57, 183, 142, 152, 19, 135, 58, 119, 129, 154, 153, 108, 27, 28, 98, 114, 124,\n155, 158, 29, 59, 89, 65, 103, 178, 69, 146, 170, 30, 50, 107, 149].\n4.2 Column Classification\nClassifying table columns entails categorising each as a Named Entity (NE) or a Literal (LIT). NE-\ncolumnscontainvaluesrepresentingentitiessuchasnames,locations,ororganisations. Incontrast,LIT-\ncolumnscontainvaluesrepresentingliteraldatatypessuchasnumbers, dates, orgeo-coordinates. Many\nexisting approaches utilise prior datatype classification to determine the type of columns. By classifying\ncolumns, subsequent semantic analysis and data manipulation become more feasible. These approaches\nassignspecifictypes(e.g.,number,date,geo-coordinate)byemploying: i)Regex matching [180,55,35,\n38,14,13,34,9,36,120,143,11],ii)statistical analysis [116,85,65],oriii)Machine Learning (ML)\ntechniques [178, 50]. Additionally, some approaches prioritise entity linking; in this scenario, unlinked\ncolumns are then classified as LIT-columns.\nSome approaches explicitly consider Column Classification as a distinct sub-task [116, 55, 180, 85,\n35, 14, 13, 38, 34, 65, 1, 3, 2, 4, 9, 120, 30, 26, 78, 77, 75, 36, 178, 50, 11], while many others implicitly\nperform Column Classification by identifying cell or column datatypes [70, 71, 22, 43, 134, 138, 135,\n154, 129, 143, 91, 7, 64, 50, 158, 123, 30]. TableMiner+ [180] utilises Regex patterns to identify empty,\ndate, number, and long text columns, categorising them as LIT-columns, while the rest are considered\nNE-columns. Efthymiou et al. [55] applies a column sampling to classify literal columns. Later, [35,\n38, 14, 13, 34, 9, 36, 120, 11] adopt a similar technique, employing additional Regex patterns and using\nmajority voting to determine column types. In addition, MTab [120] combines the use of Regex with\nSpaCy14 pre-trained model to perform column classification. Kim et al. [91] consider text, number, and\ndate as possible types while bbw [143] uses Regex to predict number, time, name and string datatypes.\nRegarding the statistical analysis, Mulwad et al. [116] developed a domain-independent and ex-\ntensible framework where it is possible to implement components to detect literal values; when all cells\nin a column are literal, the column is considered as “No-annotation”. Kacprzak et al. [85] considers\nas numeric the columns with at least 50% of numerical values, else the columns are classified as NE.\nSimilarly, also [65] classifies columns as either “character” or “numeric”.\nIn the ML techniques, Zhang et al. [178] proposes a column header classification model which was\ntrained on the T2D dataset. The TURL [50] approach uses an additional type embedding vector to\ndifferentiate NE columns.\nOtherapproachesperformColumnClassification,buttherearenotenoughdetailstocategorisethem.\nIn DAGOBAH [26] the process aims to identify a first low-level type for each column among five given\ntypes (Object, Number, Date, Unit, and Unknown). In the successor [78] numeric values are considered\nbothwithorwithoutthecorrespondingunitofmeasure. Nofurtherchangeswereappliedinconsecutive\napproaches [77, 75] except adding customised modules for organisation, location and currency detection\nin 2022 [75]. Similarly [158], considers string, date and numeric types. In [155] is unclear whether the\ntablecolumnsarealreadyclassifiedasNEandLIT. JenTab[1,3,2,4]considersobject, date, stringand\nnumbers. LinkingPark[30]leveragesstandardconversionfunctionsforint,float anddate-time datatype;\notherwise, cells are considered strings. There is no information about the aggregation function, but LIT\nand NE columns are considered differently.\n12public.oed.com/how-to-use-the-oed/abbreviations\n13fasttext.cc/docs/en/crawl-vectors.html\n14spacy.io\n12\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n4.3 Datatype Annotation\nIn many approaches, the Datatype Annotation of LIT-columns is tightly linked to the Column Classifi-\ncation. SimilarlytotheColumnClassificationsub-task,approachesexploitthreemethods: i)statistical\nanalysis [70, 71, 30, 119, 135, 129, 162, 85, 29, 122, 25], ii) Regex matching [138, 134, 43, 116, 135,\n154, 129, 180, 35, 38, 34, 9, 36, 143, 14, 13, 120, 123, 64, 11], or iii) ML techniques [155, 175, 158,\n63, 50, 178, 55, 27, 120, 123, 64]. In this sub-task it is possible to add an additional category related to\napproaches that use iv) other methods [94, 152, 154, 153].\nSeveral approaches employ statistical analysis by applying a set of rules to classify LIT and NE\ncolumns [70, 71]. Such rules concern how cell content is represented, i.e., the amount of text and num-\nbers/units. Inspired by Taheriyan et al. [154], [129] adopts statistical hypotheses as a metric for column\nannotation. Hierarchical clustering is employed by Neumaier et al. [119] to construct a background KG\nusing DBpedia. The nearest neighbours classification is applied to predict the most probable data type\nfor a given set of numerical values, also considering distribution similarity. NUMBER [85] is inspired\nfrom previous works [119, 129]. The evaluation process involves two main aspects. Firstly, the sim-\nilarity of value distributions is assessed by comparing them to the properties in a target KG using a\nKS test15. Secondly, the relative difference is computed between numerical values in a column and the\nnumericalvaluesofpropertieslinkedtotheentities. MTab4Wikidata[122],columntypesaredetermined\nafter the cells have already been linked to entities. LinkingPark [29, 30] uses precomputed statistics for\nnumeric datatypes, such as range, mean, and standard deviation and considers datatypes that match\nthe corresponding ranges as potential candidates. p-type [25] proposes a model built upon Probabilistic\nFinite-State Machines (PFSMs). In contrast to the standard use of Regex, PFSMs have the advantage\nof generating weighted posterior predictions even when a column of data is consistent with more than\none type of model.\nRegex is used to check if the content of the cells can be classified, for instance, as pH, temperature,\ntime, date, number, geo coordinates, iso8601 date, street address, hex colour, URL, image file, credit\ncard,emailaddress,IPaddress,ISBN(InternationalStandardBookNumber),boolean,id,currency,and\nIATA(InternationalAirTransportAssociation)codes. Ifthenumberofoccurrencesofthemostfrequent\nRegexTypes detected exceeds a given threshold, the column will be annotated as LIT-column, and the\nmostfrequentRegexTypewillbeassignedtothecolumnunderanalysis. Then, toselectthedatatypeto\nannotate the column, some approaches imply a mapping between RegexType and Datatype. [134, 116,\n43, 138, 135, 154, 180, 35, 143, 38, 34, 14, 178, 9, 36, 13, 11] utilise some or the entire list of the Regex\ndefined above to identify the datatype of the column under analysis.\nThelastmethodforDatatypeAnnotationregardsML techniques. Meimei[155]utilisesembeddings\nbymodellingatablewithaMarkovrandomfieldandemployingmulti-labelclassifierstofindthecorrect\nannotation,similartoInfoGather+[175]whichfocusesonlyonnumericalvalues. Anotherapproach[63],\nmodels different latent structures within the data and employs a Conditional Random Field (CRF) to\nperform semantic annotation in different domains (e.g., weather, flight status, and geocoding). The\napproach ColNet [27] utilises a Convolutional Neural Network (CNN) trained on positive and negative\nsamples to differentiate between different column types.\nOtherapproachescombineRegexwithML techniques; MTab[120]classifiescolumnsasNEorLIT\nusing Duckling Regex16 and SpaCy (a pre-trained classificator) with majority voting. Numeric columns\nareclassifiedusinganeuralnumericalembeddingmodel(EmbNum[121])throughrepresentationvectors\nfor numerical attributes without prior assumptions on data distribution. In contrast [123], used only\nSpaCy to identify LIT-columns. Tab2KG [64] uses the Dateparser library17 for classification in numeric,\nspatial,booleanortext. LaterthecolumnsarefurtherclassifiedintomorespecificcategoriesusingRegex\ncombined with the method described in [7], which implies classifying four kinds of numbers: nominal,\nordinal, interval, and ratio. Then fuzzy c-means is used for classification.\nSeveral other approaches in the field of STI have been proposed, each with its unique methodology.\nTheseapproaches,includingworkssuchas[157,105,117,151,118,131,164,49,57,115,183,142,19,58,\n56,108,176,28,74,114,98,124,147,174,12,59,89,103,161,172,69,170,146,163,181,107,149],donot\ninvolve semantic classification or Datatype Annotation sub-tasks for the columns. In [118], the concept\nof literal annotation was discussed as a potential area for future works, which was later implemented\nin [116]. The approach MAGIC, discussed in [146], uses entity embeddings with neighbour nodes up to\na depth of 2 without explicitly distinguishing between entities and literals. However, it is plausible that\nthis approach can also be extended to include Datatype Annotation. Specific approaches focus on the\n15TheKStestmeasuresthestatisticaldifferencebetweenthetwodistributions,providinginsightsintotheirsimilarity.\n16github.com/facebook/duckling\n17github.com/sisyphsu/dateparser\n13\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nmanual annotation of tables, providing a UI that allows users to select the most appropriate datatype\nmanually [94, 152, 154, 153].\nSeveral approaches involve Datatype Annotation; however, they lack sufficient details about how the\nannotationofthecolumnswithspecificdatatypesoccurs[22,55,158,1,3,2,4,91,65,26,78,77,75,50].\n4.4 Subject Detection\nAs previously illustrated (Section 3), the S-column is the column among the NE-columns that all the\nothers refer to. Some approaches define it as a “key” column that includes entity-based mentions that\ncould potentially be consulted in a KG, containing a large number of unique values.\nGenerally,approachesmightemployoneofthefollowingtechniquesforSubjectDetection: i)heuris-\ntic approaches, ii) statistical analysis, or iii) ML techniques.\nRegarding heuristic approaches, one common method is based on the column position within\nthe table. For example, some approaches designate the leftmost column as the S-column [55, 1, 91, 3,\n2, 4, 30, 50]. [151] instead, involves identifying columns with specific labels as the S-column, such as\ncolumns labelled as “title” or “label”. Another method for Subject Detection is to consider column\ndetection after linking entities. For instance, Zhang et al. [176, 178] use the column with the highest\nnumber of linked entities as an indicator for Subject Detection. Similarly, the approach proposed by\nHeist et al. [69], considers subject-predicate-object relations between the table’s columns and identifies\nthe S-column as the one with the highest number of entities in the subject position.\nTheuseofstatistical analysis toidentifytheS-columnisfoundinTableMiner+[180]; itusesaset\nofrulesbasedonthenumberofwords, thecapitalisation, andthementionsofmonthsordaysinaweek.\nIn MantisTable [35, 38, 34, 9, 36, 11] the subject is selected among the NE-columns using a calculated\nas a set of indicators such as the average number of words in each cell, the fraction of empty cells in the\ncolumn, the fraction of cells with unique content and the distance from the first NE-column. The same\nindicators are also used in [14]. DAGOBAH2019 [26], TAKCO [98] and MTab2021 [123] consider the\nfraction of cells with unique content and the column position in the table.\nSome works in the literature [162, 58] use ML techniques. TAIPAN [58] selects SVM and Decision\nTree as the best classifiers for this sub-task and uses as features the ratio of cells with disambiguated\nentities in a column and the number of relations between the columns. It is worth noting that [162]\nalso employs an SVM using features dependent on the name and type of the column and the values in\ndifferent column cells.\nTab2KG [64] uses a graph-based approach for subject detection, but the paper lacks details about\nthe implementation.\nEventually,therearemanyapproachesthatdonotperformS-columndetection[70,71,157,105,117,\n118, 63, 94, 131, 164, 22, 43, 49, 57, 116, 115, 134, 175, 183, 142, 152, 19, 135, 138, 119, 129, 154, 153,\n56, 85, 108, 27, 28, 74, 114, 120, 124, 147, 155, 158, 174, 12, 29, 59, 65, 78, 89, 103, 122, 143, 161, 172,\n13, 77, 146, 163, 170, 181, 107, 75, 149].\n4.5 Entity Linking\nEntity Linking, also known as named entity linking or entity resolution, is an NLP task that involves\nlinking named entities mentioned in the text to their corresponding entities in a KG. The goal is to\nidentify and disambiguate the entities mentioned in the text and connect them to unique identifiers.\nIn Entity Linking, a named entity refers to a specific named person, organisation, location, event, or\nother well-defined entity. For example, in the sentence “Barack Obama was born in Hawaii”, the named\nentity “Barack Obama” can be linked to the corresponding entry in a KG, such as dbr:Barack Obama\nin DBpedia o Barack Obama (Q76) in Wikidata. For this sub-task, approaches can be grouped into\nthree step within entity liking: i) mention detection [19], ii) candidate generation, and iii) entity\ndisambiguation [105,151,117,118,164,116,183,19,138,55,56,180,26,27,35,98,114,120,124,147,\n158, 1, 12, 29, 38, 34, 59, 78, 91, 122, 143, 161, 178, 3, 9, 13, 77, 123, 146, 170, 4, 30, 36, 75, 50, 107, 11].\nMention detection refers to the identification and extraction of mentions from tabular data. It\ninvolvesrecognisingspecificpiecesofinformationwithinatablerepresentingentities. Detectingmentions\nin a table can involve various techniques, such as NLP methods, Named Entity Recognition (NER)\nmethods, or pattern-matching algorithms. This sub-task analyses the table’s content, column headers,\nand other contextual information to accurately identify and classify the mentions.\nThe TabEL [19] approach identifies potential mentions within a given cell that can be associated\nwithentitiesinaKG. TabELidentifiesthelongestphraseswithinthecell’stextcontentwithanon-zero\n14\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nprobability of being linked to an entity e according to the probability distribution P(e|s) where s is a\nphrase. If the length of s is shorter than the length of the cell’s text content, TabEL continues searching\nfor the longest phrase. Unfortunately, there are no additional details on this method in the paper.\nIn the context of STI, a crucial role is played by the candidate generation sub-task, also known as\nlookup, which refers to the process of identifying potential entities based on the given input or query.\nWhen a query is posed, the system must generate a set of candidates for each cell that could potentially\nsatisfy the query. The candidate generation process may utilise various techniques, such as semantic\nparsing, entity recognition, or information retrieval. It could also leverage ML models trained on large\ndata corpora to generate likely candidates based on contextual patterns. The Lookup sub-task can be\ndivided into four methods: a) custom index [105, 151, 55, 56, 26, 27, 98, 114, 124, 158, 29, 34, 78, 122,\n77, 9, 123, 170, 36, 30, 75, 11], b) external lookup services [117, 118, 164, 116, 19, 138, 180, 176, 26,\n35, 38, 120, 147, 158, 1, 3, 4, 12, 59, 29, 91, 143, 161, 178, 13, 170, 146, 50], c) hybrid (both custom\nindex and external lookup services) [26, 158, 29, 170], and d) other [143, 164].\nCustom index refers to building a specialised index for specific requirements or use cases. When\nbuilding a custom index, there is flexibility in defining mappings, analysers, and other configurations\nbased on specific needs. One of the most adopted solutions is Elasticsearch18, a robust and scalable\nsearch and analytics engine. It uses a document-oriented approach, where data is organised and stored\nasJSONdocuments. SeveralapproachesrelyonElasticsearchforthelookupsub-task[26,98,78,77,75,\n34, 9, 36, 114, 124, 158, 29, 30, 11]. The simplest index can incorporate entity labels (rdfs:label) or\naliases (skos:altLabel). However, some approaches also add abbreviations (dbo:abbreviation), de-\nscriptions(rdfs:comment)[77,75,158],or,indexesforspecificentitytypes,name(foaf:name),surname\n(foaf:surname),andgivenname(foaf:givenName)[114]. TheMantisTableteambuildsaseparatesys-\ntem named LamAPI19 [10, 11] which is used across multiple versions of this system. LamAPI20 tool\nretrieves entities with the highest similarity between the mention in the cell and the entity’s label by\ncombiningdifferentsearchstrategies, suchasfull-textsearchbasedontokens, n-gramsandfuzzysearch.\nOther approaches build custom indexes using different solutions; Limaye et al. [105] presents a method\nthat utilises a catalogue which comprises types, entities and relations. Entities in the catalogue are\nassociated with lemmas, which are canonical strings extracted from Wikipedia, or synset names from\nWordNet21. Syed[151]developsahybridKGofstructuredandunstructuredinformationextractedfrom\nWikipedia augmented by RDF data from DBpedia and other Linked Data. The system is called Wiki-\ntologyandusesanInformationRetrieval(IR)index(Lucene)torepresentWikipediaarticles. Thesame\ntechniqueisusedbyMulwadetal.[117,118,116]. Elletal.[56]createsanindexforeachtypeofresource\n(entity, property, type) for each language. These indexes contain the names of the resources, according\nto DBpedia. For properties and classes, the names are obtained from the rdfs:label property in DB-\npedia. Efthymiou et al. [55] utilises a lookup-based method to establish connections. It leverages the\nlimited entity context available in Web tables to identify correspondences with the KG. The approach\nbuilds its custom search index over Wikidata, called FactBase, consisting of entities with corresponding\nIDs and textual descriptions. Another system named ColNet [27] involves two steps in its candidate\ngeneration. Firstly, a lookup step is performed to retrieve entities from the KG by matching cells based\non entity labels and anchors (e.g., Wikipedia link) using a lexical index composed of terminology and\nassertions from the KG. MTab4Wikidata [122], another version of MTab [120], focuses on annotating\ncells to Wikidata entities. It starts by downloading and extracting a Wikidata dump to build an index\nusing hash tables. The lookup process is then performed using a fuzzy search. The result is a ranking\nlist of entities based on edit distance scores. In the updated version of MTab 2021 [123], a WikiGraph\nindex is constructed, combining Wikidata, Wikipedia, and DBpedia. The lookup uses Keyword Search,\nFuzzy Search, and Aggregation Search. GBMTab [170] tackles candidate entity generation by differen-\ntiating the entities extraction from Wikidata and DBpedia. Only for DBpedia, the approach builds an\nindex using hash tables. Then, it uses the Levenshtein distance to calculate a string similarity between\nmentions and entities.\nThe second method employed for candidate generation uses external lookup services. This pro-\ncess refers to using a separate service or system to perform lookup or queries for retrieving specific\ninformation or data. The external lookup service usually utilises entity recognition, entity disambigua-\ntion, or semantic matching techniques. It may consider factors like textual similarity, context, or other\nrelevant information. In the STI, many services can be used to extract a set of possible entities given\n18www.elastic.co\n19github.com/unimib-datAI/lamAPI\n20lamapi.datai.disco.unimib.it/\n21wordnet.princeton.edu\n15\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\na string as input. The choice of the service depends on the specific requirements and context, such\nas the KG used to annotate the entities. Most approaches annotate table cells to DBpedia entities by\nusing related services, such as DBpedia API [120, 26], DBpedia Lookup Service [120, 147, 161] and\nDBpedia Spotlight [147, 146]. The same occurs for Wikidata, for which the following services are em-\nployed: Wikidata API [26, 158, 12, 143, 146], Wikidata Lookup Service [120, 1, 59, 161, 3, 2, 4, 50] and\nWikidata CirrusSearch Engine [26]. Other services used to execute the lookup sub-task are Wikipedia\nAPI[26,120,143,178],MediaWikiAPI[29,170]andWikibooks[143]. Insteadofexplicitlyusinglookup\nservices, some approaches perform SPARQL queries, a query language used to retrieve and manipulate\ndata stored in RDF format. This method is the default way to obtain information from triple stores.\nFor the approaches that do not provide any specific information on the lookup service, it is assumed\nthat SPARQL is employed. For instance, such queries are used to retrieve entities from YAGO [19],\nDBpedia [138, 180, 176, 35, 38, 147, 3, 2, 13, 4] and Wikidata [91, 143, 3, 2, 13, 4]. Furthermore, other\nsources are used, for instance, SearX [143] and Probase [164] where pattern matching is used to extract\ntriples.\nEntity disambiguation refers to the process of resolving ambiguous mentions to entities. When\ntables contain references to entities or mentions, such as names of people, locations, or organisations,\nthere can be ambiguity if the same name refers to multiple entities. Entity disambiguation in STI aims\ntoidentifyanddisambiguatetheseentitymentions, ensuringthateachmentioniscorrectlylinkedtothe\nappropriateentity. Thissub-taskcanbeperformedbyapplyingmultipletechniques: a)embedding [55,\n26, 59, 176, 178, 146, 107], b) similarity [105, 180, 124, 98, 147, 158, 35, 38, 34, 78, 161, 143, 9, 3, 77,\n30, 36, 11], c) contextual information [151, 138, 55, 27, 120, 158, 122, 123, 114, 12, 29, 34, 1, 78, 9,\n13, 77, 75, 30, 36, 107, 11], d) ML techniques [117, 158, 178, 11], e) language models [103, 75, 50,\n127, 100, 125, 159], f) probabilistic models [118, 116, 19, 98, 170], and g) other [164, 115, 56].\nIn graphs and natural language, embedding refers to representing nodes in a graph, or words in a\ntext, as dense vectors in a continuous vector space. These embeddings capture semantic and structural\nrelationships between nodes or words, allowing ML models to perform tasks such as node classification,\nlinkprediction,documentsimilarity,sentimentanalysis,andmore[130]. Someapproachesuseembedding\ntechniques to create vector representations of entities [55, 26, 59, 178, 146]. Every approach tries to\ncapture context information about entities in the KG and to incorporate that information in the vector\nrepresentation. [55, 176, 59] employ semantic embeddings obtained through Word2Vec [113] on KGs,\nwhile Zhang et al. [176, 178] use GloVe [128], Wikipedia2Vec [169] and RDF2Vec [136] to obtain a\nrepresentationofentities. DAGOBAH[26]usespre-trainedWikidataembedding[67],whileMAGIC[146]\nusesINKtechnique[148],whichtransformsthelocalneighbourhoodofanodeintheKGintoastructured\nformat. Radar Station [107] uses the PyTorch-BigGraph [101] framework for training embeddings.\nThe entity disambiguation sub-task could involve the computation of some similarities among\ntextual data. This type of score is usually adopted by lookup services to retrieve a ranked list of\ncandidates. Often,thedisambiguationstepinvolvestheselectionofthewinningcandidatebyconsidering\nthe string similarity between the entity label and mention. Some approaches use similarity, such as,\nLevenshtein distance [35, 147, 38, 34, 124, 158, 78, 143, 9, 77, 30, 36, 11], Jaccard similarity [105, 98, 9,\n36, 11], Cosine similarity [105, 161] and similarity based on Regex [78]. Limaye et al. [105] in addition\nto Jaccard applies also the TF-IDF22. TableMiner+ [180] measures the similarity between the Bag-\nOf-Words (BOW) representation of the entity and the BOW representations of different types of cell\ncontexts, such as row content and column content.\nContextual information during the CEA task considers the surrounding context of a table cell,\nsuch as neighbouring cells, column headers, or header row. Contextual information provides additional\nclues or hints about the meaning and intent of the mention. By analysing the context, a system can\nbetterunderstandthesemanticsofthecellandmakemoreaccurateannotations. Contextualinformation\nat column and row level is usually provided by CTA and CPA tasks, but some approaches take column\ntypes and properties into account to disambiguate entities even if those tasks are not explicitly treated.\nColumn types are used to disambiguate entities by assuming that entities in a column share the same\ntype. Most approaches rely on this assumption to perform this step [151, 138, 55, 27, 120, 114, 158, 12,\n13]. [151, 27, 13] limit the number of candidate entities by executing a new lookup query that includes\npredicted types. [138, 55, 120, 114, 158, 12] refine the candidates set by filtering out entities that do\nnot match the predicted type at the column level. Similarly, the other assumption considered by some\napproaches is that contextual information from CPA at the row level enables understanding the data\nbetter within its broader context [78, 122, 123, 75]. [78, 75] consider the semantic relations between\n22Theweightassignedtoaterminadocumentvectoristheproductofitstermfrequency(TF)andinversedocument\nfrequency(IDF).\n16\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\ncolumns by boosting the scores for each candidate entity when the relation is found. [122, 123] compute\ncontextsimilaritybetweencandidatetriplesandtablerowvaluesbyrankingentitiesbasedonthisscore.\nEventually, it selects the candidate with the highest context similarity as the final annotation. Most\napproaches also implement the disambiguation sub-step by adopting a hybrid solution (considering the\ninformation provided by CPA and CTA tasks) [29, 30, 9, 34, 36, 1, 77, 11]. Radar Station [107] focuses\non improving entity linking in the context of STI systems. It addresses disambiguation challenges by\nusing graph embeddings to identify similarities between entities, types, and relationships within tables.\nThemethodinvolvesconstructingaKDtreeofcontextentitiesforeachcolumnandusingittoselectthe\nK nearest context entities during prediction, ultimately enhancing the ranking of candidates provided\nby [122, 78, 143].\nOthermethodsthatcanbeemployedare ML techniques. Thesetechniquestypicallyinvolvetrain-\ning a ML model on a labelled dataset where cells are annotated with their corresponding entities. The\nmodellearnspatternsandrelationshipsbetweenthecellscontentandtheirassociatedentities. Topredict\nthe most appropriate entity, ML techniques consider various cell features, such as the textual content,\ncontext, neighbouring cells, and other relevant information. Several ML techniques can be employed\nto perform the disambiguation task, such as Support Vector Machine (SVM) [117], NN [158, 11] and\nRandom Forest [178]. Mulwad et al. [117] create a vector of features for each entity, and then an SVM\nis used to rank such vectors. Then a second SVM decides whether to link or not the entity mentioned\nin the cell. Thawani et al. [158] build a NN that learns adaptive weights and relationships from labelled\ndata. They use a 2-layer architecture with ReLU activation to obtain scores for each candidate. Zhang\net al. [178] extract two sets of features: lexical similarity (e.g., Levenshtein, Jaccard) and semantic simi-\nlarity(e.g.,Wikipediasearchrank). Eventually, aRandomForestistrainedtodetermineifitispossible\nto link an entity to a mention.\nLanguage models might be used for cell entity annotation by leveraging advanced models, such\nas BERT. Language models are trained on vast amounts of text data and have the ability to interpret\nnatural language. They can capture complex linguistic patterns, semantic relationships, and contextual\ncues. These models can be utilised to perform various NLP tasks, including entity recognition and\nlinking. In the context of CEA, an Large Language Model (LLM) can be fine-tuned or adapted to\nthis specific task. This involves training the model on a labelled dataset where cells are annotated with\ncorrespondingentities. OncetheLLMistrained,itcanbeappliedtounlabelledcellsinatabletopredict\nthe most likely entity annotations. The model considers the cell’s textual content, surrounding context,\nand potentially other relevant features to make these predictions. Recently LLMs have been employed\nto find semantic correlations between different cells at column and row level. The main advantage of\nusing LLMs is having a contextualised representations for each cell, considering the mention and table\nmetadata. Theadventof Large Language Models (LLMs)hasledtoanewcategoryofapproachesfor\ntable interpretation. Based on the architecture structure of LLMs, these approaches can be categorised\ninto three groups: i) encoder-decoder LLMs, ii) encoder-only LLMs, and iii) decoder-only LLMs [127].\nIndeed, shortly after the first edition of SemTab, some works [103, 50, 149] applied encoder-only LLMs\nto table interpretation. Although they did not participate in or compare with the SemTab challenge,\ntheycreatedadifferentexperimentalsetting. DuringtheSemTab2022instead,aBERT-based[51]model\nwas combined with a more traditional approach [75]. More recently, after the release of GPT-3.5 [125]\nandopen-sourcedecoder-onlyLLMssuchasLLAMA[159]andLLAMA2[160], someworkshavebegun\napplying encoder-based LLMs to table interpretation [102, 179]. In SemTab2023, a new decoder-only\nmodel was presented that uses BERT [48].\nStarting from encoder-based approaches, Ditto [103] utilises Transformer-based language models to\nperform a slightly different task; in fact, the goal is entity-matching between various tables. TURL [50]\nleverages a pre-trained TinyBERT [80] model to initialise a structure-aware Transformer encoder. Do-\nduo [149] performs CTA using a pre-trained language model, precisely fine-tuning BERT model on\nserialised tabular data. DAGOBAH SL 2022 [75] employs an ELECTRA-based cross-encoder, a variant\noftheBERTmodel. TheCrossEncodertakesaconcatenatedinput,includingleft-sidetableheaders,the\ntarget table header, right-side table headers, and the entity description. TorchicTab [48] is composed of\ntwo sub-systems: TorchicTab-Heuristic and TorchicTab-Classification. The classification model utilises\nDoduo [149].\nRegardingdecoder-basedapproaches,TableGPT[102]performsseveraltasks,includingentitylinking\nusing GPT. TableLlama [179], performs CEA, along with several other tasks, creating a multi-task\ndatasetfortabulardata,inwhichtheentitylinkingsub-datasetderivesfromtheTURL[50]dataset,and\nusing it to fine-tune LLama2 [160]. The advent of LLMs has also led to the publication of experiments\ncomparing different approaches based on LLM and ML [16].\n17\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nProbabilistic models are frameworks for representing and reasoning under uncertainty using prob-\nability theory. These models vary in their representation of dependencies and use diverse graphical\nstructures. SeveralProbabilisticGraphicalModel(PGM)canbealsousedtoresolvethedisambiguation\ntask, such as Markov models [118, 116, 19, 170] or Loopy Belief Propagation (LBP) [98]. Markov mod-\nels focus on sequential dependencies, while LBP employ message passing between nodes in the PGMs.\nBhagavatula et al. [19] adopt a representation for tables as graphical models. Within this approach,\nevery mention in the table is linked to a discrete random variable that represents the possible candidate\nentities associated with that mention using Independent Component Analysis. Mulwad et al. [118, 116]\nresolve ambiguities in table cell values by looking at the evidence from other values in the same row.\nThis is achieved by creating edges between each pair of cell values within a specific row. Kruit et al. [98]\nintroduce a PGM incorporating label similarities as priors. The model subsequently improves likelihood\nscoring to enhance the consistency of entity assignments across rows through Loopy Belief Propagation\n(LBP). Eventually, Yang et al. [170] create a disambiguation graph that utilises mentions and their\ncorresponding candidates from the same row or column in a table. The approach scores the semantic\nconnections between nodes using three features in the PGM: Prior, Context, and Abstract.\nOther approaches cannot be categorised in one of the previous groups. For instance, Munoz et\nal. [115] proposes an approach to extract RDF triples from Wikitables by linking each cell to DBpedia\nentities. The process involves following internal links within Wikipedia tables, as they can be directly\nmapped to DBpedia. Ell et al. [56] create some hypotheses for entities extracted in the previous phase\n(CandidateGeneration). Thesehypothesesincludetheentitytype,theURIinDBpedia,andaconfidence\nvalue. Theconfidencevalueisdeterminedbynormalisingthefrequencyvalueoftheentitybydividingit\nbythesumoffrequencyvaluesforallthecandidates. Wang[164]describestheprocessofunderstanding\na table using the Probase knowledge API. Eventually Kim et al. [91] remove candidates considering the\ncontent unrelated to the annotation.\nSome other approaches such as [183, 74, 174, 89, 163, 181] do not perform Entity Linking tasks\nspecifically.\n4.6 Type Annotation\nTheTypeAnnotationsub-taskinvolvesassigningaspecifictypefromareferenceKGtoeachNE-column.\nVarious approaches have been developed to address this sub-task, focusing on leveraging Entity Linking\ntechniques, partially or comprehensively, to identify the most frequent column type. This is particularly\ncrucial in unsupervised classification scenarios. Additionally, some approaches consider the information\nprovided by column headers to determine the most suitable type.\nThe most used methods to annotate NE-columns are: i) majority voting [70, 71, 117, 118, 162,\n134, 183, 138, 58, 56, 180, 12, 14, 29, 59, 91, 122, 143, 161, 123, 30, 151, 116, 35, 147, 158, 38, 34, 9, 36,\n1, 3, 2, 4, 98, 181, 11], ii) Term Frequency-Inverse Document Frequency (TF-IDF) [105, 131,\n135,154,124,26],iii)statistical methods [120,77,78,69,49,75],iv)machine learning [27,65,146,\n163, 170, 50, 64, 28, 74, 174, 149], or v) other [94, 175, 152, 22, 155, 13, 164, 114, 89, 178].\nMostresearchstudiesoncolumn-typepredictionutiliseacommonstrategycalledmajority voting.\nThismethodinvolvesdeterminingthemostfrequentlyoccurringtypeinacolumnanddecidingbasedon\nthe majority. This pure decision-making method is applied by [70, 71, 117, 151, 58, 118, 162, 134, 183,\n138,56,180,12,14,59,29,91,122,143,161,123,170,30]. Someapproachesgobeyondsimplemajority\nvoting and incorporate additional mechanisms to address specific situations. For instance, [116, 35, 147,\n158, 38, 34, 9, 36, 98, 181] set a threshold to prevent annotating a column when there is insufficient\nconfidence about the type. The approach in [134] applies a deduplication process to remove duplicate\ntypes within a column. After deduplication, the type frequencies in the column are summed using a\nlogarithmic function which measures the overall frequency and importance of the types present in the\ncolumn. In Kruit et al. [98], majority voting across types is also used to select candidate entities for\nindividual rows using Loopy Belief Propagation (LBP). This approach highlights how CTA and EL are\ninterconnected. Also, for LinkingPark [29, 30], the primary method used is majority voting to obtain\nthe most common (i.e., most frequent) type. In case multiple candidates have the same frequency,\nthe type selected for annotation is the most specific in the KG. For bbw [143], majority voting is the\nprimary selection algorithm. However, when multiple types have equal frequency, it selects the first\ncommon ancestor type in the KG. JenTab [1, 3, 2, 4] uses various techniques, including the Least\nCommonSubsumer(LCS),directparents(i.e.,majorityvoting),andpopularity. Followingtheontology\nhierarchy, the LCS represents the most specific type, obtained by excluding types occurring in less than\n50% of the cells. Zhou [181] selects the annotation based on level 2 and level 3 DBpedia classes.\n18\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nAnother method for Type Annotation is based on TF-IDF, as mentioned by [135, 154, 124].\nDAGOBAH [26] highlights the importance of setting a confidence threshold when using TF-IDF to\navoidwrongannotations. Therearealsosomevariations;forexample,Limaye[105]introducestheLeast\nCommon Ancestor (LCA) as a baseline approach against majority voting and the collective approach.\nThe collective approach considers EL output, features like Inverse Document Frequency (IDF), and the\ndistance calculated by counting edges between the considered entity and the potential column types\nobtained in LCA method. In the end, a PGM is used for choosing final annotations (CEA, CTA, and\nCPA). Also [131], uses a PGM combined with the TF-IDF approach.\nThereareapproachesthatusestatisticalmethods otherthanmajorityvoting;forexample,Nguyen[120]\nintroduces the concept of “type potential” which is computed as the cumulative probability entities in\na column corresponding to a specific type within the KG. “Type potential” considers statistics from\nnumerical columns, types from the candidate entities in the whole table, SpaCy type predictions and\nheader values to assess the likelihood of different types for the column. Similarly [78, 77, 75] consider\nvariousfactorssuchasfrequency,accumulatedlevel(ontologyhierarchy),andaccumulatedrankofWiki-\ndata23, for all candidate types of a target column. The final column type is determined using majority\nvoting as the deciding factor. Heist et al. [69] compute type frequency and relation frequency statistics\nin the DBpedia KG to identify best-suited types using co-occurrence. Deng [49] instead employs an im-\nplementation similar to the idea of majority voting using an overlap similarity between top-k candidate\ntypes for a given column. In the map-reduce like implementation, the overlap corresponds to the count\nof entities having a given type.\nAnother method implies using machine learning. The approach presented in [28] focuses on an-\nnotating columns that consist of phrases. For instance, the type dbo:Company can annotate a column\ncontaining “Google, Amazon and Apple Inc.”. To achieve this, they propose a method called Hybrid\nNeuralNetwork(HNN)thatcapturesthecontextualsemanticsofacolumn. TheHNNmodelusesabidi-\nrectional Recurrent Neural Network (RNN) and an attention layer (Att-BiRNN) to embed the phrases\nwithineachcell,allowingforcontextualunderstanding. AsimilarConvolutionalNeuralNetwork(CNN)\nconfiguration combined with majority voting is also used in [27]. Sherlock [74] is a multi-input deep\nNN for detecting types. It is trained on 686,765 data columns retrieved from the VizNet24 corpus by\nmatching 78 semantic types from DBpedia to column headers. Each matched column is characterised\nby 1,588 features describing the statistical properties, character distributions, word embeddings, and\nparagraph vectors of column values. Inspired by Sherlock, Sato [174] incorporates table context into\nsemantic type detection. It employs a hybrid model that combines “signals” from the global context\n(values from the entire table) and the local context (predicted types of neighbouring columns). Guo et\nal. [65] introduce a HNN model for single-column type annotation, which combines Deep Learning (DL)\nwith a PGM [96]. With a pre-annotated dataset, a co-occurence matrix is built, considering types for\neach column pair. This co-occurrence measure is used to annotate similar column pairs in other tables.\nTCN [163] treats a collection of tables as a graph, with cells as nodes and implicit connections as edges.\nThe connections are cells with the same content or position in different tables. Using graph NN, TCN\nlearns a table representation for predicting column types and relations. In the TURL approach [50],\nthe column header and the embedding representation of entities linked to the cells within the column\nare considered to determine the final annotation. Similarly, Tab2KG [64] creates a domain profile from\nthe KG and uses it together with a table profile to generate mappings using Siamese Networks between\nthe column content and the types in the KG. A domain profile associates relations with feature vectors\nrepresenting data types and statistical characteristics such as value distributions. Doduo [149] performs\nTypeAnnotationusingapre-trainedlanguagemodel,preciselyfine-tuningtheBERTmodelonserialised\ntabular data. Each column is encoded by appending a special token [CLS] at the beginning, and the\nresulting embedding representation serves as the contextualised column representation. Column types\nare predicted using a dense layer followed by an output layer with a size corresponding to the number\nof column types.\nOther approaches cannot be classified in the previously mentioned methods; for instance, in [94,\n152] a CRF is employed to make statistical predictions considering the context, such as column name\nand values. Similarly, [155] uses a Markov Network with three potential functions: column-content\n(similaritybetweenobservedcellsandacandidatecolumntype),column-column(thesimilaritybetween\nthe candidate type of a column and the currently assigned type of other columns), and title-column\n(similarity between the title and column type). Other approaches such as [22, 175] compute some\nconditionalfeaturesconsideringthepresenceofspecificmatchesinthecolumntitleandcontent. Another\n23www.wikidata.org/wiki/Help:Ranking\n24viznet.media.mit.edu\n19\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\napproach [164] uses a KG taxonomy constructed using type-entity extraction patterns. These patterns,\nsuchas“WhatistheAofI?”, whereArepresentstheseedattributestobediscoveredandIisanentity\nintypeCobtainedfromtheProbaseKG[165]. ThosepatternsarecomparedagainsttheProbase’slarge\nwebcorpusof50terabytes. Similarly,inLOD4ALL[114]twoscoresareusedtodeterminecolumntypes.\nOne score prioritises the most frequent ancestor types across the table, while the other emphasises the\nmostspecificentitytypesforeachentity. Ontheotherhand,C2[89],apatentedapproach[90],addresses\nthe type mapping by optimising smaller likelihood problems to reduce the number of candidate types\nconsidered. The approach starts with independently finding the top candidates for NE-columns. Best\ncandidate entities are used as pivots to narrow the search, while other features such as Background\nKnowledge Graph (BKG), diversity (reward deduplication during the scoring), tuple validation (type\nco-occurrence), and belief sharing (column headers from different tables) are used to enhance prediction\naccuracy. Zhangetal.[178]adoptsadifferentstrategybyleveragingthecolumnlabelandcolumnvalues\nto train a classifier for each type present in the KG. This classifier is then used to predict the most\nsuitable type for the column based on the learned patterns and characteristics. Eventually, a naive\napproach is applied in Kepler-aSI [13], for columns with more than one candidate type no annotation is\nprovided.\nThere are cases like [43, 14, 146, 123, 172] where the specific details about the column annotation\nsub-task are not provided, making it difficult to understand the exact methodology employed. This is in\npart because their code is not provided in open source as discussed in Section 8.\nFinally, some approaches do not deal with annotations on columns specifically, such as [157, 63, 57,\n115, 142, 19, 119, 129, 153, 55, 85, 108, 176, 103, 107].\n4.7 Predicate Annotation\nThe Predicate Annotation sub-task can be challenging, primarily due to the incompleteness of public\nKGs such as DBpedia or Wikidata. Additionally, the Predicate Annotation sub-task can be further\ncategorised into two parts: NE relations, which focus on the relationship between the subject column\n(S-column) and a named entity (NE) column, and LIT relations, which involve the relationship between\nthe subject column (S-column) and a literal (LIT) column.\nTheapproachescanbecategorisedinto: i)ruleset [70,71],ii)pattern matching [157,164,142,50],\niii) majority voting [105, 151, 117, 118, 162, 94, 116, 115, 22, 138, 58, 26, 35, 114, 158, 98, 147, 38, 14,\n91, 122, 143, 172, 78, 13, 146, 69, 77, 30, 36, 75, 11], iv) statistical [152, 154, 153, 180, 120, 29, 1, 34,\n3, 9, 178, 2, 4], and v) embedding [28, 163, 149].\nTheruleset methodismainlyappliedintheinitialapproaches[70,71]. Therulesetmethodconsists\nof a set of rules used to calculate a similarity score between the properties in the KG and the column\ntypes. In case the table title is provided it is taken into consideration for the score.\nThe pattern matching technique, used by [157, 164, 142], consists of searching for exact matches\nof subject and object pairs in a large corpus to retrieve possible properties. Similarly, TURL [50] aims\nto extract relations between columns without entity linking. It treats the concatenated table metadata\nas a sentence and considers the headers of the two columns as entity mentions.\nThe most commonly used approach is majority voting. Initially, Limaye et al. [105] defined a\nfeature vector based on the occurrence and frequency of relations between entities. The most frequently\noccurring relation is the selected one. A similar method is applied in [151, 117, 118, 162, 22, 116, 115,\n26, 35, 114, 147, 158, 98, 29, 38, 91, 122, 143, 13, 69, 36]. In [147] an additional criterion is introduced\nto handle cases where relations have equal occurrence. The approach uses column types to examine the\nResource Description Framework Schema (RDFS) range and domain in such situations. When multiple\nrelations have a valid range and domain, the approach selects the relations with the most specific range\nanddomaincolumntypes. Anotherimportantaspectishandlingduplicatecellswithinthesamecolumn,\nas the frequency count can be misleading in cases with a high number of duplicates. In [58], the authors\naddressthisissuebyconsideringpossibleduplicatecellsonlyonce. Incontrast, theT2Kapproach[138],\ndo not perform deduplication. Instead [94], takes a different approach by extracting relations for each\npair and uses the Stiner Tree Algorithm to compute the minimal tree among them.\nRecent approaches have introduced diverse methods for handling NE and LIT relations. Moreover,\nthe adoption of statistical or approximate matching methodologies have seen a noticeable increase.\nIn [152, 154, 153], the authors leverage existing user-defined KGs. The relations are annotated using\na directed weighted graph constructed on top of known properties, which are expanded using semantic\ntypes in the domain ontology. The properties are represented as weighted links between nodes. TableM-\niner+ [180] aims to enhance relation matching by employing the Dice similarity measure [52]. The Dice\n20\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nfunction calculates an overlap score by comparing the bag-of-words representations of the cell and the\nobject of a triple, and subsequently, the most frequent resulting relation is selected.\nWhenhandlingNEcolumns,severalapproachesemploystringsimilarityfunctionssuchasLevenshtein\ndistance (also known as Edit Distance), Jaccard Similarity, letter distance, or bag-of-words overlap.\nNotable examples of approaches that use these techniques include [120, 29, 1, 34, 3, 9, 178, 2, 4].\nFor LIT columns, various techniques are employed in different approaches. TeamTR [172] and\nJenTab[1,3,2,4]usefixedthresholdsforcomparingliteralsintheKGwiththevaluesinthetable. Sim-\nilarly, other approaches employ custom formulas, such as DAGOBAH [78], which uses an absolute value\nformula, while Mantistable SE [34] and MantisTable V [9] use an exponential function as threshold for\nliteralcomparison. TheMTabapproach[120]approximatescomparisonsusingathresholdandappliesa\ncustom formula for numeric values. Similarly, LinkingPark [29] uses pre-computed statistics specifically\ndesigned for numerical columns. A more detailed description of their process is provided in [30]. When\ndealingwithdates,afterparsing,theymaybetreatedsimilarlytonumericalvalues(e.g.,in[34,9,1,3]).\nIn DAGOBAH [78], the considered types include ID, number, string, and date types. The authors em-\nploy different matching techniques for matching properties for each data type. Date matching involves\nconsidering various formats. As described in the previous Section, the MAGIC approach [146] employs\nacomprehensiveprocedurethatsimultaneouslyaddressesCEA,CTA,andCPA.Majorityvotingisused\nas the selection strategy across columns, similar to the aforementioned approaches.\nSomeembedding-basedmethodshaverecentlyemergedfortheCPAtask. Thesemethodsleverage\nproperty features to represent the potential relationships between the target and surrounding columns.\nIn the approach proposed by Chen et al. [28], a property Vector algorithm (P2Vec) is introduced for\nPredicate Annotation. In the 2021 version of DAGOBAH [77], KG embedding is incorporated along\nwith existing features to enhance property disambiguation, while majority voting remains the selection\ncriteria. Another embedding-based method, TCN, is presented in Wang et al. [163]. TCN concatenates\ntheembeddingofthesubjectandobjectcolumnsandpassesthroughadenselayertogeneratepredictions\non their relationship. Lastly, in Doduo [149], the corresponding embedding representation, as described\nin the Type Annotation (Section 4.6), is extracted for each column. These embedding representations\nare also used for the CPA task.\nSomeapproachesneedmoredetailstofullyunderstandtheirprocesses. Forexample,ADOG[124]uses\nCEA results to extract properties for NE-columns, but the paper does not provide enough information\nabouttheunderlyingalgorithm. Similarly, MTab2021[123]andDAGOBAH2022[75]alsolackadequate\nmethodologydescription. Inthegeospatialdomain,Cruzetal.[43]mentionthatgeospatialclassification\nschemes can be modelled using a part-of or is-a relationship. However, the paper does not delve into the\nmethodology in detail.\nSeveral other approaches, such as [63, 131, 49, 57, 134, 175, 183, 19, 135, 119, 129, 55, 56, 85, 108,\n176,27,74,155,174,12,14,65,59,89,103,161,170,181,64,107]donotaddressPredicateAnnotation.\n4.8 NIL Annotation\nIn the context of NLP, the NIL [79] Annotation refers to the task of finding and linking whether a given\ninput belongs to a particular category, class or type called “NIL” or “None”. In STI, NIL Annotations\nindicatecellsintableslackingrelevantinformation. STIinvolvesextractingstructureddatafromtables,\nbutsomecellsmaynotcorrespondtoentitiesinaKG,leadingtoNotInLexicon(NIL)predictions. NIL\nAnnotations can be helpful in various applications, such as information extraction, question answering,\nor KG population, where the goal is to extract structured information from tables and integrate it\ninto a knowledge representation system. There are four common ways in the SOTA to perform NIL\nannotation[6]: i)no candidates [19,164,138],ii)threshold [117],iii)separate model [98,178,50,69],\nand iv) NIL predictor. Some approaches do not belong to any of the above categorisations. For the\nscope of this survey, it is possible to classify them considering the peculiarity of the NIL annotation\nprocess, which use v) external services for searching candidates [134, 142].\nSometimes in the EL, a candidate generator does not yield any corresponding entities for a mention\n(no candidates); such mentions are trivially considered unlinkable. Bhagavatula et al. [19] introduce\na variation of the EL task for tables, using a graphical model representation, where each mention in\nthe table is associated with a discrete random variable representing its candidate entities for identifying\nand disambiguating unlinked mentions in a Wikipedia table. After performing the CTA task, Wang et\nal. [164] proceed to “expand entities” by creating entities that lack corresponding labels within the KG.\nAlso [138] explicitly mentions that their T2K approach could fill the missing values to DBpedia and\nvice-versa (Web Tables), but it is only listed as a potential use and not validated.\n21\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nA second group of approaches set a threshold for the best linking probability (or a score), below\nwhich a mention is considered unlinkable. For instance, T2LD approach [117] links table cells to entities\nusing the results obtained from a CTA task, and then a query is sent to the KG for each cell, which\nreturns the top N possible entities which are then ranked using an SVM classifier. If the evidence is not\nstrong enough, it suggests that the table cell represents a new entity.\nTodiscoverNILmentions,itisalsopossibletotrainanadditionalbinaryclassifier(separate model)\nthat accepts, as input, mention-entity pairs after the ranking phase and several additional features. It\nmakes the final decision about whether a mention is linkable or not. In this group, Kruit et al. [98]\nemploy KG entity and relation embeddings to enhance the disambiguation process when label matching\nis insufficient. This approach contributes to discovering new facts for KG completion. The system\ndeveloped by [178] proposes a method for discovering new entities containing a subset of those entities\nthatcanbeextendedwithinformationfeatures: aneuralembeddingspace(Word2vecrepresentation),a\ntopical space (annotation of other entities) and a lexical space (normalised Levenshtein distance). Deng\net al. [50] propose an innovative approach that uses a Transformer encoder with masked self-attention\nto predict the masked entities based on other entities and the table context (e.g., caption/header). This\nencourages the model to learn factual knowledge from tables and encode it into entity embeddings\nfor annotation use. Eventually, Heist et al.’s algorithm [69] considers a data corpus from which co-\noccurring entities and related relationships can be extracted (e.g., listings in Wikipedia or a collection\nof spreadsheets). Furthermore, they assume that a KG which contains a subset of those entities can be\nextended with information learned about the co-occurring in the corpus.\nRegarding the NIL Annotation in the SOTA, some models developed for annotation of the free-form\ntext introduce an additional special “NIL” entity in the ranking step in the EL phase, so models can\npredict it as the best match for the mention [6]. It should be noted that currently, STI approaches do\nnot employ this technique.\nRelated to the use of external services, [134] describes an algorithm that uses web search engines\nto gather information about “unknown entities” (not present in the KG) and annotate them with the\ncorrect type analysing the snippet. Similarly, the approach in [142] searches for exact entity matches\nacrosstheSubject-Verb-Object(SVO)25TriplesoftheNever-EndingLanguageLearning(NELL)project.\nThe process creates a probabilistic model to estimate the posterior probability of a relationship along\nwith entity-pair instances, and then it uses this relation to create new entities.\n5 Method (Supervision)\nThis Section delves into the METHOD dimension and its distinctive categories. While we review the\napproaches proposed to solve individual tasks in Section 4, here we summarise the overall usage of\nlabelled data to train models that solve one or more specific tasks. We consider three categories of\napproaches. First, the UNSUPERVISED approaches (Section 5) do not rely on annotated data during\nthe STI process. Secondly, the SUPERVISED approaches (Section 5) utilise a training set, such as a\ncollection of pre-annotated tables. Some approaches are characterised by using both unsupervised and\nsupervised techniques; we can define these approaches as HYBRID (Section 5).\nThe chart in Fig. 7 displays the yearly distribution of approaches in supervised and unsupervised\ncategories. In the years leading up to 2019, the number of approaches in both categories is roughly the\nsame. However, in2019, theSemTabchallenge’sinauguraleditionledtoasignificantuptickinunsuper-\nvised methods, peaking at 13 approaches proposed in 2020. As of 2021, the gap between supervised and\nunsupervised approaches is closing due to the increasing use of GSs as training and the implementation\nof LLM (e.g., BERT) for annotations.\n25rtw.ml.cmu.edu/resources/svo\n22\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nHybrid\nSupervised 2\nUnsupervised\n4\n3\n3\n2 3\n3 2\n11\n3\n1 2 1 2 1 1 2 2 7 2 2 1 4 1 21 1 2 7 5 3\nFigure 7: A comparison of Supervised, Unsupervised and Hybrid approaches per year.\nUnsupervised Numerous approaches [70, 71, 157, 105, 151, 162, 131, 164, 22, 49, 57, 115, 134, 175,\n183, 142, 152, 138, 58, 56, 180, 85, 176, 27, 35, 114, 120, 124, 147, 158, 1, 12, 14, 29, 38, 34, 91, 122, 143,\n161, 172, 3, 2, 9, 13, 123, 4, 30, 36] (49) prioritise the utilisation of unsupervised methods, driven by\nthe challenges associated with acquiring high-quality datasets for real-world scenarios and the difficulty\nof modeling annotation problems for ML methods. Customised approaches offer greater control over\nthe results and higher annotation precision (as discussed in Appendix C). Table 3 in the Appendix A.2\ndisplays the techniques used in the Candidate Generation and Entity Disambiguation of EL step.\nSupervised While a relatively limited number of supervised approaches has been proposed (if com-\npared to the number of supervised approaches), these approaches (28) offer exciting solutions when im-\nplemented. Table 4 in the Appendix A.2 displays the techniques used by these approaches. Supervised\napproaches listed below use a collection of tabular or textual data to learn patterns and relationships\nbetween the input data and the corresponding labels. In the following, we briefly summarise the data\nused to train supervised approaches and the main idea behind these approaches.\nMulwad et al. [117] query Wikitology26 to extract entities and use a SVM model for entity ranking.\nQuercini et al. [134] collect label categories from DBpedia and snippets from Bing to train the text\nclassifier. Ermilov et al. [58] use a portion of the T2D Gold Standard27, where the S-column and\ncolumn-pairs have been annotated to train an SVM and a PGM. T2Dv2 dataset28 has been used by\nZhang et al. [178] to train a binary classifier and Chen et al. [27] to train a CNN. The former uses also\nthe WDC Tables dataset29 to train a random forest model. TabEl [19] parses Wikipedia tables to build\na corpus containing more than 1.6 million tables30. Such tables contain hyperlinks to Wikipedia, and\nTabELusesthesehyperlinksasprobabilityestimatesfortrainingaMarkovNetwork. Thesametraining\ntechnique is used also by Takeoka et al. [155] on a private dataset of 183 human-annotated tables with\n781 NE-columns and 4109 LIT-columns31. Pham et al. [129] use four different datasets: city, weather,\nmuseum and soccer32. Only city, museum and soccer datasets have been used to train random forest\nand logistic regression models. The weather dataset is only used in semantic labelling because it cannot\nprovide sufficient feature vectors for training classifiers. Neumaier et al. [119], propose a hierarchical\nclustering to build a BKG from DBpedia.Luo et al. [108] use English and Chinese dumps of Wikipedia\nfor training word and entity embeddings. In total, it collects 3818 mentions from 150 tables. Deng et\nal. [50] use Wikitable corpus to train a BERT model while Gottschalk et al. [64] creates a new synthetic\ndataset automatically extracted from GitHub repositories33. This dataset is then used for training the\nSiamese network.\nHybrid A small number of approaches (11) opt for solutions involving the use of supervised and\nunsupervised techniques. Since 2017, an increase in the use of semantic embeddings has been observed.\nTheembeddingsexploitavectorialrepresentationoftherichentitycontextinaKGtoidentifythetable’s\nmost relevant subset of entities. This technique is used in conjunction with lookup-focused [55, 59] or\nrule-based [26, 78, 77] methods. Others adopt a transformer-based embedding in combination with the\nuseofheuristics[75,107]orembeddingtechnique[146]. ColNet[27]utilisesaCCNmodelandamethod\nwhich automatically extracts samples from the KG. Kruit et al. [98] employ a Probabilistic Graphical\n26ebiquity.umbc.edu/project/html/id/83/Wikitology\n27webdatacommons.org/webtables/goldstandard.html\n28webdatacommons.org/webtables/goldstandardV2.html\n29webdatacommons.org/webtables\n30websail-fe.cs.northwestern.edu/TabEL\n31ThepaperreferencedUCIMLrepository,butitwasfoundtobeaprivatedatasetuponcontactingtheauthor.\n32github.com/usc-isi-i2/eswc-2015-semantic-typing,thesoccerdatasetisnolongeravailable.\n33github.com/search/advanced\n23\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n7002 9002 0102 1102 2102 3102 4102 5102 6102 7102 8102 9102 0202 1202 2202\nModelandfeaturesonT2DandWebaroo34 while[69]relyondistantsupervisiontoderiverulesforCPA\nand rule-mining techniques.\n6 Domain\nSTI approaches can be categorised as domain-dependent or domain-independent. Domain-dependent\nsystems address problems and provide solutions specific to the domain they are built for. Instead,\ndomain-independent STI approaches do not rely on domain knowledge and provide solutions not tied to\naspecificareaofexpertise. Amongalltheapproachesonly[70,71,43,108,22,119,85]canbeclassifiedas\ndomain-dependent. A few papers [70, 71, 22] are related to the food microbiology domain and present a\npredefinedsetofrulesspecificallybuilttoaddressthedifferentnumerical unitsinDatatypeAnnotation.\nTwo papers [119, 85], are designed to deal only with numerical data labelling. Finally, [43] is designed\nto address several challenges that come from the geospatial and temporal data manipulation and [108]\naddress data and KG written in different languages.\nThe remaining approaches can be considered domain-independent.\nDomain-dependent approaches, usually, are affected by the domain ontology used, such as Hignette\net al. [70, 71] that distinguish between symbolic and numeric columns, using some of the knowledge\ndescribed in the ontology, which has been created ad hoc.\n7 Application/Purpose\nThisSectiondiscussestheapplicationpurposeofapproachesrangingfromi)KG construction,ii)KG\nextension and tabular data enrichment, andiii)cross-lingual linking. Forthefirsttwopurposes\nespecially, we refer to Fig. 5 and Fig. 4.\nTheaimofKG construction istoderivemeaningfulinformationfromtabulardata,transformingit\ninto a structured and interconnected knowledge representation. This supports cross-domain knowledge\nintegration, discovery, and graph-based data analysis. Approaches [69, 56, 138, 180, 175, 98, 58, 91, 50,\n153, 152] employ STI to construct and populate KGs. Similarly, [115, 116] focus on extracting facts as\nRDF triples from annotated tables.\nSTIsignificantlyenhancesKG extension and tabular data enrichment byextractingstructured\ninformation from tables, linking it to an existing KG, and expanding the KG with interpreted graph\ndata. This process, involving automatic identification and annotation of mentions, relationships, and\ntable schema, ensures the extraction of comprehensive and accurate information from tabular data.\nApproaches such as [175, 69, 178, 64] discover new entities, types, and properties to enrich the KG,\nincludingidentifyingnewlabelsforknownentities. Additionally,[46,47,31],showcasehowSTIsupports\nadding more columns to input tables for downstream data analytics, using annotations as joins to fetch\nrelevant data from the external KG and export the output table. Semantic table interpretation provides\na means to bridge the language barrier, thus supporting cross-lingual linking of entities mentioned in\nthe tables. A similar, cross-lingual application is proposed in [108], which annotates a table containing\nentities expressed in one language with entities in a KG expressed in another.\nSince 2019, the majority of recent approaches have focused more on addressing the tasks outlined in\nthe SemTab challenge [26, 35, 120, 114, 158, 124, 147, 1, 12, 161, 143, 122, 78, 14, 29, 34, 91, 172, 9,\n3, 13, 77, 123, 170, 146, 30, 36, 75, 11], and less on downstream applications. We observe that in some\napplicationsofKGconstructionandtabulardataenrichment,themostimportanttasktofullyautomate\nis CEA (especially on large tables), while it is assumed that CPA and CTA can be manually performed\nor revised by a user to ensure a desired level of quality.\n8 License\nLicensing is vital in protecting intellectual property and establishing the terms under which software,\ncontent,orcreativeworkscanbeusedordistributed. Thus,itisveryimportanttoreviewSTIapproaches\nunder such dimension so that users can evaluate which one to use for their specific use case and ensure\ncompliance with legal requirements. There are 6 different licenses used by STI tools and approaches.\n34Thedatasetisnolongeravailable.\n24\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nThe most used one is Apache 2.035, an open-source software license widely used in the development\nand distribution of software. It allows users to freely use, modify, and distribute the licensed software.\nUsers must include a copy of the Apache 2.0 license, a clear attribution to the original authors, and\nclearly identifiable modification notices on all altered files. Such licensing is used by 23 approaches [94,\n135,138,119,129,154,153,56,180,27,28,35,174,38,34,103,3,2,9,4,50,36,149]. Thesecondmost\nused license is MIT36 used by 10 approaches [85, 74, 98, 158, 1, 143, 123, 30, 64]. The MIT License is a\npermissiveopen-sourcesoftwarelicensethatallowsuserstofreelyuse,modify,anddistributethelicensed\nsoftware. The Orange license37 is used by [26, 77, 75, 107]. GPL 3.038 is used by 2 approaches [58, 69]\nwhile2adoptsCCA4.039 [178,19],andeventually,[146]employsauniquelicensingbyGhentUniversity\n(Imec).\nAmong the approaches reviewed in this survey, 46 of them lack any specific licensing information.\n9 Validation\nThe effectiveness of the approaches proposed so far is usually evaluated in terms of annotation quality\nondifferentseparatecomputationaltasks(e.g.,usingPrecision,Recall,andF1scores). Intheliterature,\nthe open-source tool STILTool [42] is available for the automated evaluation of the quality of semantic\nannotations generated by semantic table interpretation methods. For each approach, we specify the\ndatasetsusedforitsevaluation. WereportthisassociationinTable6,discussedinAppendixC,wherewe\ndiscussthedatasetsusedfortableinterpretation. Averyfewapproachesalsoconsideredotherdimensions\nforevaluation,suchasexecutiontimesandscalability[31,50];thelatterdimensionisrelevant,especially\nfor entity linking, which may be inefficient on large tables.\n10 Open Issues and Potential Research Directions\nDespite the many contributions to advance STI discussed in this paper, we believe that there are some\nopenissuesassociatedwiththekeychallengeslistedinSection1;theseopenissuescouldhinderabroader\nuptake of STI solutions for downstream applications and, at the same time, suggest valuable questions\nfor researchers working in these fields.\ni) Heterogeneity of domains and data distributions: the lack of labelled data specifically\ntailored for a domain of interest prevents training and evaluation of domain-specific solutions. Potential\nsolutions to overcome this scarcity could be: a) involving domain experts in the annotation process,\nadditionally using crowd-sourcing platforms to engage a larger pool of annotators with domain-specific\nknowledge [137]; b) using specific data (e.g., [144, 5, 84]); c) developing pre-trained models on large\nGSs, which can be fine-tuned and/or adapted using a small amount of labelled data (in this way, STI\napproacheswouldreuseexistingannotationsandreducetheburdenofcreatingdomain-specificGSsfrom\nscratch) (e.g., [50]).\nii) Limited contextual information: missing context can introduce ambiguity, making it chal-\nlengingtodeterminetheintendedmeaningoftableelements. MostoftheGSsusedinrecentworkdonot\nprovide tables associated with extended context; consequently, these aspects have not been emphasised\nmuch in recent work. Possible solutions could be: a) reusing prior datasets based on web tables, which\nemphasise these challenges, or b) developing new datasets. In addition, researchers should consider\nc) techniques that infer missing context from the available information (e.g., table headers, table meta-\ndata,surroundingtext[50])ord)employingfinal-userfeedbacktoenhancethecontextualunderstanding\nof the table [75].\niii) Detecting the type of columns: theanalysisoftheSOTAhasshownthatdifferentapproaches\neffectivelymanagetypeannotation. ThemostcriticalopenchallengeisthedetectionofL-columns. Using\nRegex was found effective for identifying L-columns [36], but domain-specific literal values (e.g., for\ngenomics data of biological pattern) are not yet addressed. A potential solution is the definition of new\ndomain-specific regular expressions for the Type Annotation sub-task.\niv) Matching tabular values against the KG: STI approaches work well when the mentions\nin the NE-columns or literals in the L-columns are similar enough to the values in the KG. Regarding\nannotationofmentions,synonyms,aliases,abbreviations,andacronyms,shouldbeconsideredtoenhance\n35apache.org/licenses/LICENSE-2.0\n36opensource.org/license/mit\n37orangedatamining.com/license\n38gnu.org/licenses/gpl-3.0.html\n39creativecommons.org/licenses/by/4.0\n25\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nthe approach’s potential. This remains an open issue, as only a few approaches use indexes with aliases\n(e.g.,[36,11]). Whilethisdirectionseemspromising,thereisstillampleroomforimprovement. Itisalso\nnecessary to consider that the mention can contain typos or have syntactic differences from the entities\nin an KG. In such cases, using a) indices [36, 123, 11] and adequate b) similarity measures [178, 161]\ncan increase the results of the candidate generation. The SemTab challenge, which tests STI even on\ncorrupted data, has shown that this problem has not been adequately solved yet. Regarding the use of\nliteral values for matching (i.e., those in L-columns), the challenge arises due to inconsistencies between\nthe values in the KG and those in tabular data. Since KGs are known to be incomplete or not updated\nfrequentlyenough,thecorrectliteralvalueforagivenpropertymaysignificantlydeviatefromtheonein\nthe table (or in the KG). In the SOTA, this challenge is typically addressed by setting c) thresholds or\nranges(e.g.,[119]), butthesemethodsintroducetheriskofselectingincorrectannotations. Apromising\nresearch direction would involve leveraging d) statistical and ML methods to surmount this limitation\nand achieve even better results.\nv) Disambiguation of named entities: disambiguation remains a complex and challenging task\nwhen the table context is insufficient or unclear. Another aspect that makes disambiguation still chal-\nlengingisthepresenceofhomonymsintheKG,especiallywhentheybelongtoverysimilartypes. Inthis\ncase,onlythesurroundingcontextcanhelpdisambiguatedifferentcandidates. However,thisremainsan\nopen issue as not all approaches consider contextual analysis, or as depicted in challenge ii), sometimes\nthe context should be inferred. In the context of this challenge, homonym management plays a crucial\nrole. A possible research direction a) is to include models that consider all elements contributing to the\ncreation of the context (e.g., [50]). Some of the most recent approaches have proposed to use b) LLM to\ncapture complex linguistic patterns, semantic relationships, and contextual cues in the tabular data, ob-\ntaining some promising results in improving disambiguation (e.g., [149]). However, further investigation\nisneededtoexploretheuseofsuchmodels,theirefficiency,andcomparisonwithtraditionalapproaches.\nSomerecentapproacheshavealsoproposedusinglatentrepresentationsorfeature-basedneuralnetworks\nto re-rank candidate entities retrieved with more traditional techniques [8, 107]: these hybrid solutions\nare also promising.\nvi) NIL-mentions: Currently, only 10 approaches address NIL annotation, yielding inconsistent\nresults, as seen in the 2022 and 2023 SemTab challenges. The SOTA has not adequately tackled this\ncrucialaspectdespiteitssignificanceinKGextensionandconstructionforpracticalapplications. Limited\nNIL coverage in GSs biases algorithms toward always selecting the best candidate without deciding\nwhether to link. One solution is to a) develop GSs that better represent the problem, encouraging\nsolutionsthatdecideonlinkingthebestcandidateentity(e.g., [110]). Additionally, b)utilisetechniques\nand external sources (e.g., search engines) for enriched representations of mentions and entities [123].\nLastly, c) incorporate domain-specific expert knowledge to enhance NIL-mention identification.\nvii) Choosing the most appropriate types and properties: more than one type could capture\nthe meaning of one column. This is due especially to the hierarchical organisation of types in ontologies\n(e.g.,anactorisalsoaperson)butalsotothepresenceofverysimilartypes(e.g.,inWikidata). Selecting\nthe types that better captures the semantics of a column among all correct types is still an open issue.\nPossible solutions may come from a) using contextual information. Analogous issues affect the selection\nof properties to annotate pairs of columns, which is even more challenging: predicate annotation is\nusually performed after other sub-tasks, which increases the risk of error propagation.\nviii) Collective aggregation of evidence from different tasks: as described in Section 1,\ntable interpretation is a collective decision-making process. Finding strategies to maximise evidence\nexchange across sub-tasks effectively is challenging. a) Heuristic and b) ML approaches can be useful\nto overcome this challenge. The heuristic approach depends on expert-derived strategies and fixed\nrules, making it less adaptable to dynamic environments and potentially hindering its performance with\ndifferentdatainputs[36,30,4,123,11]. MLmodels,instead,offerthecapabilitytomakedecisionsbased\non learned patterns and relationships between different features, such as table data, annotations, and\ncontexts [149, 50]. In addition, ML techniques allow determining feature weights by iterating on data\nand adapting them incrementally.\nix) Amount and shape of data: the amount of data introduces two opposite challenges: data\nabundance and data scarcity. Data abundance can pose significant challenges for STI approaches.\na) Sampling, subset selection, feature selection, or dimensionality reduction can be employed to address\ndata abundance. Data scarcity can be addressed by b) data augmentation (e.g., [138, 109]). c) Tech-\nniques such as synthetic data generation, sampling methods, or data transformations can be used to\ncreate additional training instances. Moreover, d) transfer or active learning can help overcome data\nscarcity (e.g., [27]). However, this remains an open challenge as none of the reviewed approaches adopts\n26\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nany of these techniques for data augmentation.\nx) Annotation of complex formatted tables: annotating complex tables introduces unique\nchallenges due to their intricate structures, which often include merged cells, hierarchical data, and\nvarying formats. These complexities can obscure relationships between data points, making it difficult\nto apply standard annotation methods effectively. Web tables containing complex structures constitute\na small population and have not been the focus of research [180]. One solution could be to incorporate\na pre-process step that parse complex structures [173].\nInadditiontotheseopenissuescloselyrelatedtotheSTIprocess,itispossibletoidentifyotheropen\nissues related to the GSs.\ni) GSs Availability: ReliablebenchmarksareessentialforevaluatingtheeffectivenessofSTImeth-\nods. Ourreviewrevealedalackofhigh-qualitybenchmarks(seeAppendixC),impedingthedevelopment\nand assessment of STI techniques. To enhance robustness evaluations across diverse data distributions,\nit is crucial to assess STI approaches using various GSs. Additionally, the creation of domain-specific\nGSs tailored to specific applications is recommended.\nii) Multi-lingual GSs: The current limitation of predominantly English GS hampers the repro-\nducibility and generalization of STI approaches across languages in real-world scenarios. Integrating\nlanguage detection is crucial to address this issue and enhance STI systems. Additionally, creating\nmulti-lingual GSs is essential to support the training and evaluation of these systems, covering diverse\nlanguages, data sources, and domains for comprehensive coverage.\niii) GSs with NIL: as discussed above, NIL-mentions are absent or underrepresented in GSs used\nin SOTA. We believe that creating GSs that better cover this annotation type is very important.\niv) Evaluation metrics: different approaches use different metrics to evaluate their performance.\nFor instance, in the SemTab challenge, different formulas are used to calculate Precision, Recall and F1\nmeasures in relation to different datasets. For this reason, there is a need for standardised and concrete\nmetrics to effectively test and evaluate various approaches.\nRegarding tools for implementing STI approaches, the following open issues can be identified:\ni) Transferability: whilereviewingspecificapproaches,weobservedlimitationsintheirusabilityin\nreal-world scenarios. In fact, evidence of usage of STI approaches in real-world downstream applications\nis still limited.\nii) Replicability: while this survey includes numerous STI approaches, a significant portion of\nthem lack publicly available replication code. The lack of availability of open-source systems has two\nmain implications: testing and evaluating third-party approaches become a complex, time-consuming,\nand error-prone task; checking errors and understanding issues and limitations to advance the field is\ndifficult. Better sharing of source code can improve transparency and accelerate advancements in this\nfield.\niii) Usability: Just a handful of tools feature a UI, and among them, only a minority possess a\nwell-craftedUX.Toensuretheusabilityofthesesolutions,itisimperativetoconductusertests,monitor\nuser behaviour, and employ other techniques tailored to the UI and UX design process.\niv) Adaptability: Most of the approaches and tools come with static algorithms. However, when\nusers want to annotate their data, they would like to optimise algorithms for specific data distribu-\ntions. Improving the support for human-in-the-loop annotation with algorithms that exploit the feed-\nbackcollectedfromtheusersthroughtheUIwouldprovidesolutionsmorehelpfulinseveraldownstream\napplications.\n11 Conclusions\nThissurveyaimstoprovideacomprehensiveandin-depthanalysisofavailableapproachesthatperform\nSTI. It includes approaches from 2007 to the time of writing, resulting in the identification of 88\napproaches. Different criteria are used to compare and review STI approaches, which are organised into\nataxonomytoallowafaircomparisonandidentifypotentialfutureresearchareas. Thisanalysisallowed\nus to create the Table 8 in Appendix D, which provides support in selecting approaches in relation to\nvarious attributes, such as Method, Tasks, Code availability, License and Triple store. Also, tools and\nGS have undergone a thorough analysis using specific comparative criteria. As a result of such analysis,\nopenissueshavebeenaddressed,andpotentialresearchdirectionshavebeendescribed. Thesurveyaims\nto serve as a valuable resource for newcomers, providing an overview of the current SOTA in STI and\nfacilitatingtheirexplorationofpotentialdirectionsforenhancingSTIperformance. Infuturework,open\nissues for each approach will be identified. Another direction is to review the performance metrics used\nby each approach.\n27\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nReferences\n[1] N. Abdelmageed and S. Schindler. Jentab: Matching tabular data to knowledge graphs. In\nSemTab@ ISWC, pages 40–49, 2020.\n[2] N. Abdelmageed and S. Schindler. Jentab: A toolkit for semantic table annotations. In Second\nInternational Workshop on Knowledge Graph Construction, 2021.\n[3] N.AbdelmageedandS.Schindler. Jentabmeetssemtab2021’snewchallenges. InSemTab@ISWC,\npages 42–53, 2021.\n[4] N.AbdelmageedandS.Schindler. Jentab: Doctasolutionsaffecttheentirescores. Semantic Web\nChallenge on Tabular Data to Knowledge Graph Matching (SemTab), CEURWS. org, 2022.\n[5] N. Abdelmageed, S. Schindler, and B. K¨onig-Ries. Biodivtab: A table annotation benchmark\nbased on biodiversity research data. In SemTab@ ISWC, pages 13–18, 2021.\n[6] M.Alam,D.Buscaldi,M.Cochez,F.Osborne,D.R.Recupero,H.Sack,O.Sevgili,A.Shelmanov,\nM. Arkhipov, A. Panchenko, C. Biemann, M. Alam, D. Buscaldi, M. Cochez, F. Osborne, D. Re-\nfogiato Recupero, and H. Sack. Neural entity linking: A survey of models based on deep learning.\nSemant. Web, 13(3):527–570, jan 2022.\n[7] A. Alobaid, E. Kacprzak, and O. Corcho. Typology-based semantic labeling of numeric tabular\ndata. Semantic Web, 12(1):5–20, 2021.\n[8] R. Avogadro, M. Ciavotta, F. De Paoli, M. Palmonari, and D. Roman. Estimating link confidence\nfor human-in-the-loop table annotation. In International Conference on Web Intelligence and\nIntelligent Agent Technology, Venice, Italy, 2023.\n[9] R. Avogadro and M. Cremaschi. Mantistable v: A novel and efficient approach to semantic table\ninterpretation. In SemTab@ ISWC, pages 79–91, 2021.\n[10] R.Avogadro,M.Cremaschi,F.D’adda,F.DePaoli,M.Palmonari,etal. Lamapi: acomprehensive\ntool for string-based entity retrieval with type-base filters. In 17th ISWC workshop on ontology\nmatching (OM), 2022.\n[11] R. Avogadro, F. D’Adda, and M. Cremaschi. Feature/vector entity retrieval and disambigua-\ntion techniques to create a supervised and unsupervised semantic table interpretation approach.\nKnowledge-Based Systems, 304:112447, 2024.\n[12] R. Azzi, G. Diallo, E. Jim´enez-Ruiz, O. Hassanzadeh, V. Efthymiou, J. Chen, and K. Srinivas.\nAmalgam: makingtabulardatasetexplicitwithknowledgegraph. InSemTab@ ISWC,pages9–16,\n2020.\n[13] W. Baazouzi, M. Kachroudi, and S. Faiz. Kepler-asi at semtab 2021. In SemTab@ ISWC, pages\n54–67, 2021.\n[14] W. Baazouzi, M. Kachroudi, S. Faiz, E. Jim´enez-Ruiz, O. Hassanzadeh, V. Efthymiou, J. Chen,\nand K. Srinivas. Kepler-asi: Kepler as a semantic interpreter. In SemTab@ ISWC, pages 50–58,\n2020.\n[15] N. Barlaug and J. A. Gulla. Neural networks for entity matching: A survey. ACM Transactions\non Knowledge Discovery from Data (TKDD), 15(3):1–37, 2021.\n[16] F. Belotti, F. Dadda, M. Cremaschi, R. Avogadro, R. Pozzi, and M. Palmonari. Evaluating\nlanguage models on entity disambiguation in tables. arXiv preprint arXiv:2408.06423, 2024.\n[17] O. Benjelloun, S. Chen, and N. Noy. Google dataset search by the numbers. In International\nSemantic Web Conference, pages 667–682. Springer, 2020.\n[18] C. S. Bhagavatula, T. Noraset, and D. Downey. Methods for exploring and mining tables on\nwikipedia. In Proceedings of the ACM SIGKDD workshop on interactive data exploration and\nanalytics, pages 18–26, 2013.\n28\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[19] C. S. Bhagavatula, T. Noraset, and D. Downey. Tabel: Entity linking in web tables. In The\nSemantic Web - ISWC 2015, pages 425–441, 2015.\n[20] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Advances in neural information\nprocessing systems, 14, 2001.\n[21] S. Bonfitto, E. Casiraghi, and M. Mesiti. Table understanding approaches for extracting knowl-\nedge from heterogeneous tables. Wiley Interdisciplinary Reviews: Data Mining and Knowledge\nDiscovery, 11(4):e1407, 2021.\n[22] P. Buche, J. Dibie-Barthelemy, L. Ibanescu, and L. Soler. Fuzzy web data tables integration\nguided by an ontological and terminological resource. IEEE Transactions on Knowledge and Data\nEngineering, 25(4):805–819, 2013.\n[23] T.-C. Bucher, X. Jiang, O. Meyer, S. Waitz, S. Hertling, and H. Paulheim. scikit-learn pipelines\nmeet knowledge graphs: The python kgextension package. In The Semantic Web: ESWC 2021\nSatelliteEvents: VirtualEvent,June6–10,2021,RevisedSelectedPapers18,pages9–14.Springer,\n2021.\n[24] M. J. Cafarella, A. Halevy, D. Z. Wang, E. Wu, and Y. Zhang. Webtables: exploring the power of\ntables on the web. Proceedings of the VLDB Endowment, 1(1):538–549, 2008.\n[25] T. Ceritli, C. K. Williams, and J. Geddes. ptype: probabilistic type inference. Data Mining and\nKnowledge Discovery, 34(3):870—-904, 2020.\n[26] Y. Chabot, T. Labb´e, J. Liu, and R. Troncy. Dagobah: An end-to-end context-free tabular data\nsemantic annotation system. In SemTab@ ISWC, pages 41–48, 10 2019.\n[27] J. Chen, E. Jim´enez-Ruiz, I. Horrocks, and C. Sutton. Colnet: Embedding the semantics of web\ntablesforcolumntypeprediction. InProceedingsoftheAAAIConferenceonArtificialIntelligence,\nvolume 33, pages 29–36, 2019.\n[28] J. Chen, E. Jim´enez-Ruiz, I. Horrocks, and C. Sutton. Learning semantic annotations for tabular\ndata. arXiv preprint arXiv:1906.00781, 2019.\n[29] S. Chen, A. Karaoglu, C. Negreanu, T. Ma, J.-G. Yao, J. Williams, A. Gordon, and C.-Y. Lin.\nLinkingpark: An integrated approach for semantic table interpretation. In SemTab@ ISWC, 2020.\n[30] S.Chen,A.Karaoglu,C.Negreanu,T.Ma,J.-G.Yao,J.Williams,F.Jiang,A.Gordon,andC.-Y.\nLin. Linkingpark: An automatic semantic table interpretationsystem. Journal of Web Semantics,\n74:100733, 2022.\n[31] M. Ciavotta, V. Cutrona, F. De Paoli, N. Nikolov, M. Palmonari, and D. Roman. Supporting\nsemantic data enrichment at scale. In Technologies and Applications for Big Data Value, pages\n19–39. Springer, 2022.\n[32] M. Ciavotta, V. Cutrona, F. De Paoli, N. Nikolov, M. Palmonari, and D. Roman. Supporting\nsemantic data enrichment at scale. In Technologies and Applications for Big Data Value, pages\n19–39. Springer, 2022.\n[33] C. Cortes and V. Vapnik. Support-vector networks. Machine learning, 20:273–297, 1995.\n[34] M. Cremaschi, R. Avogadro, A. Barazzetti, D. Chieregato, and E. Jim´enez-Ruiz. Mantistable se:\nanefficientapproachforthesemantictableinterpretation. InSemTab@ ISWC,pages75–85, 2020.\n[35] M. Cremaschi, R. Avogadro, and D. Chieregato. Mantistable: an automatic approach for the\nsemantic table interpretation. SemTab@ ISWC, 2019:15–24, 2019.\n[36] M. Cremaschi, R. Avogadro, and D. Chieregato. s-elbat: a semantic interpretation approach for\nmessytable-s. SemanticWebChallengeonTabularDatatoKnowledgeGraphMatching(SemTab),\nCEUR-WS. org, 2022.\n[37] M. Cremaschi, J. A. Barbato, A. Rula, M. Palmonari, and R. Actis-Grosso. What really matters\nin a table? insights from a user study. In 2022 IEEE/WIC/ACM International Joint Conference\non Web Intelligence and Intelligent Agent Technology (WI-IAT), pages 263–269. IEEE, 2022.\n29\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[38] M. Cremaschi, F. De Paoli, A. Rula, and B. Spahiu. A fully automated approach to a complete\nsemantic table interpretation. Future Generation Computer Systems, 112:478 – 500, 2020.\n[39] M. Cremaschi, F. D’Adda, and S. Nocco. Mantistable ui: A web interface for comprehensive\nsemantic table interpretation management.\n[40] M. Cremaschi, A. Rula, A. Siano, and F. De Paoli. Mantistable: a tool for creating semantic\nannotations on tabular data. In The Semantic Web: ESWC 2019 Satellite Events: ESWC 2019\nSatellite Events, Portoroˇz, Slovenia, June 2–6, 2019, Revised Selected Papers 16, pages 18–23.\nSpringer, 2019.\n[41] M. Cremaschi, A. Rula, A. Siano, F. De Paoli, et al. Semantic table interpretation using man-\ntistable. In OM@ ISWC, pages 195–196, 2019.\n[42] M. Cremaschi, A. Siano, R. Avogadro, E. Jimenez-Ruiz, and A. Maurino. Stiltool: a semantic\ntable interpretation evaluation tool. In The Semantic Web: ESWC 2020 Satellite Events: ESWC\n2020 Satellite Events, Heraklion, Crete, Greece, May 31–June 4, 2020, Revised Selected Papers 17,\npages 61–66. Springer, 2020.\n[43] I. F. Cruz, V. R. Ganesh, C. Caletti, and P. Reddy. Giva: A semantic framework for geospatial\nand temporal data integration, visualization, and analytics. SIGSPATIAL’13, page 544–547, New\nYork, NY, USA, 2013.\n[44] V. Cutrona, F. Bianchi, E. Jim´enez-Ruiz, and M. Palmonari. Tough tables: Carefully evaluating\nentitylinkingfortabulardata. InThe Semantic Web–ISWC 2020, Athens, Greece, November 2–6,\n2020, pages 328–343. Springer.\n[45] V. Cutrona, J. Chen, V. Efthymiou, O. Hassanzadeh, E. Jimenez-Ruiz, J. Sequeda, K. Srinivas,\nN. Abdelmageed, M. Hulsebos, D. Oliveira, and C. Pesquita. Results of semtab 2021. In 20th\nInternational Semantic Web Conference, pages 1–12. CEUR Workshop Proceedings, 2022.\n[46] V. Cutrona, M. Ciavotta, F. D. Paoli, and M. Palmonari. ASIA: a tool for assisted semantic\ninterpretation and annotation of tabular data. In Proceedings of the ISWC 2019 Satellite Tracks,\nvolume 2456 of CEUR Workshop Proceedings, pages 209–212. CEUR-WS.org, 2019.\n[47] V. Cutrona, F. De Paoli, A. Koˇsmerlj, N. Nikolov, M. Palmonari, F. Perales, and D. Roman.\nSemantically-enabled optimization of digital marketing campaigns. In ISWC, pages 345–362.\nSpringer, 2019.\n[48] I. Dasoulas, D. Yang, X. Duan, and A. Dimou. Torchictab: Semantic table annotation with\nwikidata and language models. In CEUR Workshop Proceedings, pages 21–37. CEUR Workshop\nProceedings, 2023.\n[49] D. Deng, Y. Jiang, G. Li, J. Li, and C. Yu. Scalable column concept determination for web tables\nusing large knowledge bases. Proc. VLDB Endow., 6(13):1606–1617, Aug. 2013.\n[50] X. Deng, H. Sun, A. Lees, Y. Wu, and C. Yu. Turl: Table understanding through representation\nlearning. ACM SIGMOD Record, 51(1):33–40, 2022.\n[51] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova.BERT:Pre-trainingofdeepbidirectionaltrans-\nformers for language understanding. In J. Burstein, C. Doran, and T. Solorio, editors, Proceedings\nof the 2019 Conference of the North American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186,\nMinneapolis, Minnesota, June 2019. Association for Computational Linguistics.\n[52] L.R.Dice. Measuresoftheamountofecologicassociationbetweenspecies. Ecology,26(3):297–302,\n1945.\n[53] L. Du, F. Gao, X. Chen, R. Jia, J. Wang, J. Zhang, S. Han, and D. Zhang. Tabularnet: A neural\nnetwork architecture for understanding semantic structures of tabular data. In Proceedings of the\n27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 322–331, 2021.\n[54] T. Ebisu and R. Ichise. Generalized translation-based embedding of knowledge graph. IEEE\nTransactions on Knowledge and Data Engineering, 32(5):941–951, 2019.\n30\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[55] V. Efthymiou, O. Hassanzadeh, M. Rodriguez-Muro, and V. Christophides. Matching web tables\nwith knowledge base entities: From entity lookups to entity embeddings. In The Semantic Web –\nISWC 2017, pages 260–277, 2017.\n[56] B. Ell, S. Hakimov, P. Braukmann, L. Cazzoli, F. Kaupmann, A. Mancino, J. Altaf Memon,\nK. Rother, A. Saini, and P. Cimiano. Towards a large corpus of richly annotated web tables\nfor knowledge base population. In 5th International Workshop on Linked Data for Information\nExtraction, pages 2–13, 2017.\n[57] I. Ermilov, S. Auer, and C. Stadler. User-driven semantic mapping of tabular data. In 9th I-\nSEMANTICS’13,page105–112,NewYork,NY,USA,2013.AssociationforComputingMachinery.\n[58] I.ErmilovandA.-C.N.Ngomo. Taipan: Automaticpropertymappingfortabulardata. InKnowl-\nedge Engineering and Knowledge Management,pages163–179,Cham,2016.SpringerInternational\nPublishing.\n[59] Y. Eslahi, A. Bhardwaj, P. Rosso, K. Stockinger, and P. Cudr´e-Mauroux. Annotating web tables\nthrough knowledge bases: A context-based approach. In 2020 7th Swiss Conference on Data\nScience (SDS), pages 29–34, 2020.\n[60] X. Fang, W. Xu, F. A. Tan, J. Zhang, Z. Hu, Y. Qi, S. Nickleach, D. Socolinsky, S. Sengamedu,\nC. Faloutsos, et al. Large language models (llms) on tabular data: prediction, generation, and\nunderstanding–a survey (2024). URL https://arxiv. org/abs/2402.17944, 2024.\n[61] K. Fukushima. Neocognitron: A self-organizing neural network model for a mechanism of pattern\nrecognition unaffected by shift in position. Biological cybernetics, 36(4):193–202, 1980.\n[62] L. Getoor and A. Machanavajjhala. Entity resolution: theory, practice & open challenges. Pro-\nceedings of the VLDB Endowment, 5(12):2018–2019, 2012.\n[63] A. Goel, C. A. Knoblock, and K. Lerman. Exploiting structure within data for accurate labeling\nusing conditional random fields. In Proceedings of the 14th International Conference on Artificial\nIntelligence (ICAI), 2012.\n[64] S. Gottschalk and E. Demidova. Tab2kg: Semantic table interpretation with lightweight semantic\nprofiles. Semantic Web, 13(3):1–27, 2022.\n[65] T. Guo, D. Shen, T. Nie, and Y. Kou. Web table column type detection using deep learning\nand probability graph model. In Web Information Systems and Applications: 17th International\nConference, WISA 2020, Guangzhou, China, September 23–25, 2020, Proceedings 17, pages 401–\n414. Springer, 2020.\n[66] S. Gupta, P. Szekely, C. A. Knoblock, A. Goel, M. Taheriyan, and M. Muslea. Karma: A system\nformappingstructuredsourcesintothesemanticweb. InTheSemanticWeb: ESWC2012Satellite\nEvents, pages 430–434. Springer Berlin Heidelberg, 2015.\n[67] X.Han, S.Cao, X.Lv, Y.Lin, Z.Liu, M.Sun, andJ.Li. OpenKE: Anopentoolkitforknowledge\nembedding. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language\nProcessing: System Demonstrations, pages 139–144, Brussels, Belgium, Nov. 2018. Association for\nComputational Linguistics.\n[68] A. Harari and G. Katz. Few-shot tabular data enrichment using fine-tuned transformer architec-\ntures. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 1577–1591, 2022.\n[69] N.HeistandH.Paulheim. Informationextractionfromco-occurringsimilarentities. InProceedings\nof the Web Conference 2021, pages 3999–4009, 2021.\n[70] G. Hignette, P. Buche, J. Dibie-Barth´elemy, and O. Haemmerl´e. An ontology-driven annotation\nof data tables. In Web Information Systems Engineering – WISE 2007 Workshops, pages 29–40.\nSpringer Berlin Heidelberg, 2007.\n[71] G. Hignette, P. Buche, J. Dibie-Barth´elemy, and O. Haemmerl´e. Fuzzy annotation of web data\ntables driven by a domain ontology. In The Semantic Web: Research and Applications, pages\n638–653. Springer Berlin Heidelberg, 2009.\n31\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[72] A. Hogan, E. Blomqvist, M. Cochez, C. d’Amato, G. D. Melo, C. Gutierrez, S. Kirrane, J. E. L.\nGayo,R.Navigli,S.Neumaier,etal. Knowledgegraphs. ACMComputingSurveys(Csur),54(4):1–\n37, 2021.\n[73] M. Hulsebos, C¸. Demiralp, and P. Groth. Gittables: A large-scale corpus of relational tables.\nProceedings of the ACM on Management of Data, 1(1):1–17, 2023.\n[74] M. Hulsebos, K. Hu, M. Bakker, E. Zgraggen, A. Satyanarayan, T. Kraska, C¸. Demiralp, and\nC. Hidalgo. Sherlock: A deep learning approach to semantic data type detection. In 25th ACM\nSIGKDD, pages 1500–1508, 2019.\n[75] V.-P. Huynh, Y. Chabot, T. Labb´e, J. Liu, and R. Troncy. From heuristics to language models: A\njourney through the universe of semantic table interpretation with dagobah. SemTab, 2022.\n[76] V.-P. Huynh, Y. Chabot, and R. Troncy. Towards generative semantic table interpretation. In\nVLDB Workshops, 2023.\n[77] V.-P. Huynh, J. Liu, Y. Chabot, F. Deuz´e, T. Labb´e, P. Monnin, and R. Troncy. Dagobah: Table\nand graph contexts for efficient semantic annotation of tabular data. In SemTab@ ISWC, pages\n19–31, 2021.\n[78] V.-P.Huynh,J.Liu,Y.Chabot,T.Labb´e,P.Monnin,andR.Troncy. Dagobah: Enhancedscoring\nalgorithms for scalable annotations of tabular data. In SemTab@ ISWC, pages 27–39, 2020.\n[79] F. Ilievski, E. Hovy, P. Vossen, S. Schlobach, and Q. Xie. The role of knowledge in determining\nidentity of long-tail entities. Journal of Web Semantics, 61-62:100565, 2020.\n[80] X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and Q. Liu. TinyBERT: Distilling\nBERTfornaturallanguageunderstanding. InT.Cohn,Y.He,andY.Liu,editors,Findings of the\nAssociation for Computational Linguistics: EMNLP 2020, pages 4163–4174, Online, Nov. 2020.\nAssociation for Computational Linguistics.\n[81] E.Jim´enez-Ruiz,O.Hassanzadeh,V.Efthymiou,J.Chen,andK.Srinivas.Semtab2019: Resources\nto benchmark tabular data to knowledge graph matching systems. In The Semantic Web, pages\n514–530, Cham, 2020.\n[82] E.Jim´enez-Ruiz,O.Hassanzadeh,V.Efthymiou,J.Chen,andK.Srinivas.Semtab2019: Resources\nto benchmark tabular data to knowledge graph matching systems. In The Semantic Web, pages\n514–530, Cham, 2020. Springer.\n[83] E. Jimenez-Ruiz, O. Hassanzadeh, V. Efthymiou, J. Chen, K. Srinivas, and V. Cutrona. Results\nof semtab 2020. CEUR Workshop Proceedings, 2775:1–8, January 2020.\n[84] A. Jiomekong, C. Etoga, B. Foko, V. Tsague, M. Folefac, S. Kana, M. M. Sow, and G. Camara. A\nlarge scale corpus of food composition tables. SemTab, CEUR-WS. org, 2022.\n[85] E. Kacprzak, J. M. Gim´enez-Garc´ıa, A. Piscopo, L. Koesten, L.-D. Ib´an˜ez, J. Tennison, and\nE. Simperl. Making sense of numerical data-semantic labelling of web tables. In EKAW, Nancy,\nFrance, November 12-16, 2018, pages 163–178.\n[86] M. Kejriwal, C. A. Knoblock, and P. Szekely. Knowledge graphs: Fundamentals, techniques, and\napplications. 2021.\n[87] J.D.M.-W.C.KentonandL.K.Toutanova. Bert: Pre-trainingofdeepbidirectionaltransformers\nfor language understanding. In Proceedings of naacL-HLT, volume 1, page 2, 2019.\n[88] P.Keshvari-Fini, B.Janfada, andB.Minaei-Bidgoli. Asurveyonknowledgeextractiontechniques\nfor web tables. In 2019 5th International Conference on Web Research (ICWR), pages 123–127,\n2019.\n[89] U.KhuranaandS.Galhotra. Semanticannotationfortabulardata. CIKM:Proceedingsofthe30th\nACM International Conference on Information & Knowledge Management, page 844–853, 2021.\n[90] U.KhuranaandS.Galhotra.Semanticannotationfortabulardata,U.S.PatentUS20230161774A1,\n2021-11-24.\n32\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[91] D. Kim, H. Park, J. K. Lee, W. Kim, E. Jim´enez-Ruiz, O. Hassanzadeh, V. Efthymiou, J. Chen,\nandK.Srinivas. Generatingconceptualsubgraphfromtabulardataforknowledgegraphmatching.\nIn SemTab@ ISWC, pages 96–103, 2020.\n[92] R. Kindermann and J. L. Snell. Markov random fields and their applications. American Mathe-\nmatical Society, 1980.\n[93] T.Knap. Towardsodalic,asemantictableinterpretationtoolintheadequateproject. InLD4IE@\nISWC, pages 26–37.\n[94] C.A.Knoblock,P.Szekely,J.L.Ambite,A.Goel,S.Gupta,K.Lerman,M.Muslea,M.Taheriyan,\nandP.Mallick. Semi-automaticallyMappingStructuredSourcesintotheSemanticWeb,pages375–\n390. Springer, 2012.\n[95] N.Kolitsas, O.-E.Ganea, andT.Hofmann. End-to-endneuralentitylinking. InA.Korhonenand\nI.Titov,editors,Proceedingsofthe22ndConferenceonComputationalNaturalLanguageLearning,\npages 519–529, Brussels, Belgium, Oct. 2018. Association for Computational Linguistics.\n[96] D. Koller and N. Friedman. Probabilistic graphical models: principles and techniques. MIT press,\n2009.\n[97] K. Korini, R. Peeters, and C. Bizer. Sotab: The wdc schema. org table annotation benchmark.\nSemantic Web Challenge on Tabular Data to Knowledge Graph Matching (SemTab), CEUR-WS.\norg, 2022.\n[98] B. Kruit, P. Boncz, and J. Urbani. Extracting novel facts from tables for knowledge graph com-\npletion. In The Semantic Web – ISWC 2019, pages 364–381, Cham, 2019. Springer International\nPublishing.\n[99] J. Lafferty, A. McCallum, and F. Pereira. Conditional random fields: Probabilistic models for seg-\nmentingandlabelingsequencedata.2001. InProc. 18th International Conf. on Machine Learning,\npages 282–289, 2001.\n[100] J.LeeandK.Toutanova. Pre-trainingofdeepbidirectionaltransformersforlanguageunderstand-\ning. arXiv preprint arXiv:1810.04805, 3(8), 2018.\n[101] A. Lerer, L. Wu, J. Shen, T. Lacroix, L. Wehrstedt, A. Bose, and A. Peysakhovich. Pytorch-\nbiggraph: A large scale graph embedding system. Proceedings of Machine Learning and Systems,\n1:120–131, 2019.\n[102] P. Li, Y. He, D. Yashar, W. Cui, S. Ge, H. Zhang, D. R. Fainman, D. Zhang, and S. Chaudhuri.\nTable-gpt: Table-tuned gpt for diverse table tasks, 2023.\n[103] Y. Li, J. Li, Y. Suhara, A. Doan, and W.-C. Tan. Deep entity matching with pre-trained language\nmodels. VLDB, 2020.\n[104] Y. Li, W. Shen, J. Gao, and Y. Wang. Community question answering entity linking via lever-\naging auxiliary data. Proceedings of the Thirty-First International Joint Conference on Artificial\nIntelligence Main Track. Pages 2145-2151, 2022.\n[105] G. Limaye, S. Sarawagi, and S. Chakrabarti. Annotating and searching web tables using entities,\ntypes and relationships. Proc. VLDB Endow., 3(1-2):1338–1347, Sept. 2010.\n[106] J. Liu, Y. Chabot, R. Troncy, V.-P. Huynh, T. Labb´e, and P. Monnin. From tabular data to\nknowledge graphs: A survey of semantic table interpretation tasks and methods. Journal of Web\nSemantics, 76:100761, 2023.\n[107] J.Liu, V.-P.Huynh, Y.Chabot, andR.Troncy. Radarstation: Usingkgembeddingsforsemantic\ntable interpretation and entity disambiguation. In ISWC 2022, October 23–27, 2022, pages 498–\n515. Springer.\n[108] X. Luo, K. Luo, X. Chen, and K. Q. Zhu. Cross-lingual entity linking for web tables. In AAAI,\n2018.\n33\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[109] P.Machado,B.Fernandes,andP.Novais. Benchmarkingdataaugmentationtechniquesfortabular\ndata. In Intelligent Data Engineering and Automated Learning – IDEAL 2022, pages 104–112,\nCham, 2022. Springer International Publishing.\n[110] M. Marzocchi, M. Cremaschi, R. Pozzi, R. Avogadro, and M. Palmonari. Mammotab: a giant and\ncomprehensive dataset for semantic table interpretation. Proceedings of the SemTab2022, 2022.\n[111] S. Mazumdar and Z. Zhang. Visualizing semantic table annotations with tableminer+. In ISWC\n2016 Posters & Demonstrations Track. CEUR Workshop Proceedings, 2016.\n[112] I. Mazurek, B. Wiewel, and B. Kruit. Wikary: A dataset of n-ary wikipedia tables matched to\nqualified wikidata statements. Semantic Web Challenge on Tabular Data to Knowledge Graph\nMatching (SemTab), CEUR-WS. org, 2022.\n[113] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in\nvector space. Proceedings of Workshop at ICLR, 2013, 01 2013.\n[114] H. Morikawa. Semantic table interpretation using lod4all. SemTab@ ISWC, 2019:49–56, 2019.\n[115] E.Mun˜oz,A.Hogan,andA.Mileo. Triplifyingwikipedia’stables. InCEURWorkshopProceedings,\nLD4IE’13, page 26–37, Aachen, DEU, 2013. CEUR-WS.org.\n[116] V. Mulwad, T. Finin, and A. Joshi. Semantic message passing for generating linked data from\ntables. In The Semantic Web – ISWC 2013, pages 363–378. Springer Berlin Heidelberg, 2013.\n[117] V. Mulwad, T. Finin, Z. Syed, and A. Joshi. T2ld: Interpreting and representing tables as linked\ndata. In ISWC Posters & Demonstrations Track, ISWC-PD’10, pages 25–28, Aachen, Germany,\nGermany, 2010. CEUR-WS.org.\n[118] V. Mulwad, T. W. Finin, and A. Joshi. Automatically generating government linked data from\ntables. In AAAI 2011.\n[119] S.Neumaier,J.Umbrich,J.X.Parreira,andA.Polleres.Multi-levelsemanticlabellingofnumerical\nvalues. In The Semantic Web – ISWC 2016, pages 428–445, Cham, 2016. Springer International\nPublishing.\n[120] P. Nguyen, N. Kertkeidkachorn, R. Ichise, and H. Takeda. Mtab: matching tabular data to\nknowledge graph using probability models. arXiv preprint arXiv:1910.00246, 2019.\n[121] P. Nguyen, K. Nguyen, R. Ichise, and H. Takeda. Embnum: Semantic labeling for numerical\nvalueswithdeepmetriclearning. In8th Joint International Conference, JIST 2018, Awaji, Japan,\nNovember 26–28, 2018, pages 119–135, 2018.\n[122] P. Nguyen, I. Yamada, N. Kertkeidkachorn, R. Ichise, and H. Takeda. Mtab4wikidata at semtab\n2020: Tabular data annotation with wikidata. SemTab@ ISWC, 2775:86–95, 2020.\n[123] P. Nguyen, I. Yamada, N. Kertkeidkachorn, R. Ichise, and H. Takeda. Semtab 2021: Tabular data\nannotation with mtab tool. In SemTab@ ISWC, pages 92–101, 2021.\n[124] D. Oliveira and M. d’Aquin. Adog-annotating data with ontologies and graphs. SemTab@ ISWC,\n2019:1–6, 2019.\n[125] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,\nK. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.\nAdvances in neural information processing systems, 35:27730–27744, 2022.\n[126] M.Palmonari,M.Ciavotta,F.DePaoli,A.Koˇsmerlj,andN.Nikolov. Ew-shoppproject: Support-\ningeventandweather-baseddataanalyticsandmarketingalongtheshopperjourney. InAdvances\nin Service-Oriented and Cloud Computing, pages 187–191, Cham, 2020. Springer International\nPublishing.\n[127] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu. Unifying large language models and\nknowledge graphs: A roadmap. IEEE Transactions on Knowledge and Data Engineering, 2024.\n34\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[128] J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for word representation. In\nProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),\npages 1532–1543, 2014.\n[129] M. Pham, S. Alse, C. A. Knoblock, and P. Szekely. Semantic Labeling: A Domain-Independent\nApproach, pages 446–462. Springer International Publishing, Cham, 2016.\n[130] M. T. Pilehvar and J. Camacho-Collados. Embeddings in natural language processing: Theory and\nadvances in vector representations of meaning. Morgan & Claypool Publishers, 2020.\n[131] R. Pimplikar and S. Sarawagi. Answering table queries on the web using column keywords. Proc.\nVLDB Endow., 5(10):908–919, June 2012.\n[132] R. Porrini, M. Palmonari, and I. F. Cruz. Facet annotation using reference knowledge bases. In\nProceedings of the 2018 World Wide Web Conference, WWW ’18, page 1215–1224, Republic and\nCanton of Geneva, CHE, 2018. WWW.\n[133] J. Pujara, P. Szekely, H. Sun, and M. Chen. From tables to knowledge: Recent advances in table\nunderstanding. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &\nData Mining, pages 4060–4061, 2021.\n[134] G. Quercini and C. Reynaud. Entity discovery and annotation in tables. In Proceedings of the\n16th International Conference on Extending Database Technology, EDBT’13, pages693–704, New\nYork, NY, USA, 2013. ACM.\n[135] S. Ramnandan, A. Mittal, C. A. Knoblock, and P. Szekely. Assigning Semantic Labels to Data\nSources, pages 403–417.\n[136] P. Ristoski and H. Paulheim. Rdf2vec: Rdf graph embeddings for data mining. In The Semantic\nWeb–ISWC 2016, Kobe, Japan, October 17–21, 2016, Proceedings, Part I 15, pages 498–514.\nSpringer, 2016.\n[137] D. Ritze and C. Bizer. Matching web tables to dbpedia-a feature utility study. context, 42(41):19–\n31, 2017.\n[138] D. Ritze, O. Lehmberg, and C. Bizer. Matching html tables to dbpedia. In 5th International\nConference on Web Intelligence, Mining and Semantics, WIMS ’15, pages 10:1–10:6, New York,\nNY, USA, 2015. ACM.\n[139] D. Roman, M. Dimitrov, N. Nikolov, A. Putlier, D. Sukhobok, B. Elvesæter, A. Berre, X. Ye,\nA. Simov, and Y. Petkov. Datagraft: Simplifying open data publishing. In The Semantic Web,\npages 101–106, Cham, 2016. Springer.\n[140] D. Roman, N. Nikolov, A. Putlier, D. Sukhobok, B. Elvesæter, A. Berre, X. Ye, M. Dimitrov,\nA. Simov, M. Zarev, et al. Datagraft: One-stop-shop for open data management. Semantic Web,\n9(4):393–411, 2018.\n[141] C. Sarthou-Camy, G. Jourdain, Y. Chabot, P. Monnin, F. Deuz´e, V.-P. Huynh, J. Liu, T. Labb´e,\nand R. Troncy. Dagobah ui: A new hope for semantic table interpretation. In ESWC 2022:\nHersonissos, Crete, Greece, page 107–111, 2022.\n[142] Y. A. Sekhavat, F. Di Paolo, D. Barbosa, and P. Merialdo. Knowledge base augmentation using\ntabular data. In LDOW.\n[143] R.Shigapov,P.Zumstein,J.Kamlah,L.Oberl¨ander,J.Mechnich,andI.Schumm. bbw: Matching\ncsv to wikidata via meta-lookup. In CEUR Workshop Proceedings, volume 2775, pages 17–26.\nRWTH, 2020.\n[144] S. Singh, A. F. Aji, G. S. Tomar, and C. Christodoulopoulos. Redtable: A relation extraction\ndataset for knowledge extraction from web tables. In 29th International Conference on Computa-\ntional Linguistics, pages 2319–2327, 2022.\n[145] B. Spahiu, R. Porrini, M. Palmonari, A. Rula, and A. Maurino. Abstat: ontology-driven linked\ndata summaries with pattern minimalization. In ESWC 2016, Heraklion, Crete, Greece, May\n29–June 2, 2016, pages 381–395.\n35\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[146] B. Steenwinckel, F. De Turck, and F. Ongenae. Magic: Mining an augmented graph using ink,\nstarting from a csv. In SemTab@ ISWC, pages 68–78, 2021.\n[147] B. Steenwinckel, G. Vandewiele, F. De Turck, and F. Ongenae. Csv2kg: Transforming tabular\ndata into semantic knowledge. SemTab, ISWC Challenge, 2019.\n[148] B. Steenwinckel, G. Vandewiele, M. Weyns, T. Agozzino, F. D. Turck, and F. Ongenae. Ink:\nknowledge graph embeddings for node classification. x, 36(2):620–667, 2022.\n[149] Y.Suhara,J.Li,Y.Li,D.Zhang,C¸.Demiralp,C.Chen,andW.-C.Tan. Annotatingcolumnswith\npre-trainedlanguagemodels. InProceedings of the 2022 International Conference on Management\nof Data, pages 1493–1503, 2022.\n[150] Z. Sun, Z.-H. Deng, J.-Y. Nie, and J. Tang. Rotate: Knowledge graph embedding by relational\nrotation in complex space. arXiv preprint arXiv:1902.10197, 2019.\n[151] Z. Syed, T. Finin, V. Mulwad, and A. Joshi. Exploiting a web of semantic data for interpreting\ntables. In Proceedings of the Second Web Science Conference, volume 5, 2010.\n[152] M.Taheriyan,C.A.Knoblock,P.Szekely,andJ.L.Ambite. Ascalableapproachtolearnsemantic\nmodels of structured sources. In IEEE Computer Society, ICSC ’14, page 183–190, USA, 2014.\nIEEE Computer Society.\n[153] M.Taheriyan, C.A. Knoblock, P.Szekely, andJ. L.Ambite. Learningthesemanticsof structured\ndata sources. Web Semantics: Science, Services and Agents on the World Wide Web, 37–38:152 –\n169, 2016.\n[154] M. Taheriyan, C. A. Knoblock, P. Szekely, and J. L. Ambite. Leveraging linked data to discover\nsemanticrelationswithindatasources. InTheSemanticWeb–ISWC2016,pages549–565,Cham,\n2016. Springer International Publishing.\n[155] K. Takeoka, M. Oyamada, S. Nakadai, and T. Okadome. Meimei: An efficient probabilistic ap-\nproach for semantically annotating tables. In Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 33, pages 281–288, 2019.\n[156] P. Tallet. Les Papyrus de la Mer Rouge I: Le Journal de Merer. Institut Francais D’Archeologie\nOrientale, 2017.\n[157] C. Tao and D. W. Embley. Automatic hidden-web table interpretation, conceptualization, and\nsemantic annotation. Data & Knowledge Engineering, 68(7):683 – 703, 2009.\n[158] A. Thawani, M. Hu, E. Hu, H. Zafar, N. T. Divvala, A. Singh, E. Qasemi, P. A. Szekely, and\nJ. Pujara. Entity linking to knowledge graphs to infer column types and properties. SemTab@\nISWC, 2019:25–32, 2019.\n[159] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi`ere, N. Goyal,\nE.Hambro,F.Azhar,etal. Llama: Openandefficientfoundationlanguagemodels. arXiv preprint\narXiv:2302.13971, 2023.\n[160] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra,\nP. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu,\nJ. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini,\nR.Hou,H.Inan,M.Kardas,V.Kerkez,M.Khabsa,I.Kloumann,A.Korenev,P.S.Koura,M.-A.\nLachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra,\nI. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M.\nSmith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan,\nI. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and\nT. Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023.\n[161] S. Tyagi and E. Jimenez-Ruiz. Lexma: Tabular data to knowledge graph matching using lexical\ntechniques. In CEUR Workshop Proceedings, volume 2775, pages 59–64, 2020.\n[162] P. Venetis, A. Halevy, J. Madhavan, M. Pa¸sca, W. Shen, F. Wu, G. Miao, and C. Wu. Recovering\nsemantics of tables on the web. Proc. VLDB Endow., 4(9):528–538, June 2011.\n36\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[163] D.Wang, P.Shiralkar, C.Lockard, B.Huang, X.L.Dong, andM.Jiang. Tcn: tableconvolutional\nnetworkforwebtableinterpretation. InProceedingsoftheWebConference2021,pages4020–4032,\n2021.\n[164] J. Wang, H. Wang, Z. Wang, and K. Q. Zhu. Understanding tables on the web. In Proceedings of\nthe31stInternationalConferenceonConceptualModeling,ER’12,pages141–155.Springer-Verlag,\n2012.\n[165] Z. Wang, J. Huang, H. Li, B. Liu, B. Shao, H. Wang, J. Wang, Y. Wang, W. Wu, J. Xiao, and\nK. Zhu. Probase: a universal knowledge base for semantic search. Microsoft Research Asia, 05\n2011.\n[166] G. Weikum, X. L. Dong, S. Razniewski, and F. M. Suchanek. Machine knowledge: Creation and\ncuration of comprehensive knowledge bases. Found. Trends Databases, 10(2-4):108–490, 2021.\n[167] R.E.Wright.Logisticregression.Readingandunderstandingmultivariatestatistics,pages217–244,\n1995.\n[168] M. Yakout, K. Ganjam, K. Chakrabarti, and S. Chaudhuri. Infogather: entity augmentation and\nattributediscoverybyholisticmatchingwithwebtables.InProceedingsofthe2012ACMSIGMOD\nInternational Conference on Management of Data, pages 97–108, 2012.\n[169] I. Yamada, A. Asai, J. Sakuma, H. Shindo, H. Takeda, Y. Takefuji, and Y. Matsumoto.\nWikipedia2vec: An efficient toolkit for learning and visualizing the embeddings of words and\nentities from wikipedia. arXiv:1812.06280, 2018.\n[170] L. Yang, S. Shen, J. Ding, and J. Jin. Gbmtab: A graph-based method for interpreting noisy\nsemantic table to knowledge graph. In SemTab@ ISWC, pages 32–41, 2021.\n[171] P.Yin,G.Neubig,W.-t.Yih,andS.Riedel. Tabert: Pretrainingforjointunderstandingoftextual\nandtabulardata. InProceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, pages 8413–8426, 2020.\n[172] S.Yumusak,E.Jim´enez-Ruiz,O.Hassanzadeh,V.Efthymiou,J.Chen,andK.Srinivas.Knowledge\ngraph matching with inter-service information transfer. In SemTab@ ISWC, pages 104–108, 2020.\n[173] R. Zanibbi, D. Blostein, and J. R. Cordy. A survey of table recognition: Models, observations,\ntransformations, and inferences. Document Analysis and Recognition, 7:1–16, 2004.\n[174] D.Zhang,Y.Suhara,J.Li,M.Hulsebos,C¸.Demiralp,andW.-C.Tan. Sato: Contextualsemantic\ntype detection in tables. Proceedings of the VLDB Endowment, 13, 2020.\n[175] M. Zhang and K. Chakrabarti. Infogather+: Semantic matching and annotation of numeric and\ntime-varyingattributesinwebtables. InACMSIGMODInternationalConferenceonManagement\nof Data, page 145–156, 2013.\n[176] S. Zhang and K. Balog. Ad hoc table retrieval using semantic similarity. In International World\nWide Web Conference, WWW ’18, page 1553–1562, Republic and Canton of Geneva, CHE, 2018.\n[177] S.ZhangandK.Balog. Webtableextraction,retrieval,andaugmentation: Asurvey. ACM Trans.\nIntell. Syst. Technol., 11(2), jan 2020.\n[178] S. Zhang, E. Meij, K. Balog, and R. Reinanda. Novel entity discovery from web tables. In\nProceedings of The Web Conference 2020,WWW’20,page1298–1308,NewYork,NY,USA,2020.\nAssociation for Computing Machinery.\n[179] T. Zhang, X. Yue, Y. Li, and H. Sun. Tablellama: Towards open large generalist models for\ntables. InProceedings of NAACL: Human Language Technologies (Volume 1: Long Papers), pages\n6024–6044, 2024.\n[180] Z. Zhang. Effective and efficient semantic table interpretation using tableminer+. Semantic Web,\n8(6):921–957, 2017.\n37\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n[181] Y. Zhou, S. Singh, and C. Christodoulopoulos. Tabular data concept type detection using star-\ntransformers. In 30th ACM International Conference on Information & Knowledge Management,\npages 3677–3681, 2021.\n[182] Z.-H. Zhou and Z.-Q. Chen. Hybrid decision tree. Knowledge-based systems, 15(8):515–528, 2002.\n[183] S. Zwicklbauer, C. Einsiedler, M. Granitzer, and C. Seifert. Towards disambiguating web tables.\nIn ISWC (Posters & Demos), pages 205–208, 2013.\n38\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nA Scope and methodology\nA.1 Methodology\nIdentification In order to enhance the efficiency of our search in publication databases, the authors\ncollaboratively defined and established a set of keywords. The set of keywords is composed of semantic\ntable interpretation, table understanding, STI, table interpretation, semantic table analysis, semantic\ntable exploration, semantic table understanding, web tables, semantic annotation of tabular data, tabular\ndata annotation, table annotation, semantic interpretation of structured data, tabular data semantic\nlabelling, tabular data enrichment, SemTab challenge, or simply tabular data. Finally, we came up with\n16 keywords. Subsequently, these keywords underwent in-depth discussions among five researchers, who\nassigned scores ranging from 1 (denoting low relevance) to 5 (denoting high relevance) to each keyword.\nThe final score for each keyword is calculated as the average of the scores provided by each researcher.\nFinally, the list of ranked keywords represented a starting point for an extensive search on several\npublication platforms. The following search platforms for scientific publications were utilised: i) Scopus,\nii) Web of Science, iii) DBLP, and iii) Google Scholar.\nThetimeperiodwassetfrom2007,whentheSTIresearchfieldwasfirstapproached,untilMay2023,\nwhen the paper collection process was completed. To complement the extensive search, we incorporated\na snowballing technique, which involved exploring additional recent publications that referenced the key\nworks identified within our result corpus. Tracing the citations of central works aimed to capture the\nfield’s most up-to-date and relevant literature.\nScreening Two experts manually annotated the papers obtained during the Identification step. A\nkey aspect of the screening process was identifying which semantic table interpretation phases were\naddressed/describedineachpublication. Inaddition,thecriteriaforthisScreening stepwastherelevance\nand comprehensiveness of each publication regarding the STI tasks. These criteria were employed to\nassesshowthepublicationsaddressedtherelevantaspectsofSTIandcomprehensivelytreatedthesubject\nmatter. Asanadditionalstep, weperformedanannotationprocesswithpre-definedcategoriesbasedon\neachpublication’stitle,abstractandkeywords. Ifthecategorisationbasedonthesethreecomponentswas\nimpossible, the full text had to be consulted at this stage. The categories for this final step were divided\ninto generic tags (e.g., “semantic table interpretation”, and “gold standard”) and specific annotation\ntags (e.g., “supervised”, “domain independent” Section 6).\nInclusion This Section describes our methods for identifying the final subset of publications to be\nincluded in this survey. The first and foremost criteria for inclusion were that publications had to be:\ni) directly related to semantic table interpretation, ii) published in English, and iii) peer-reviewed. All\nthe paper’s authors decided on which publications to report based on their relevance to the assigned\ncategory.\nResults of the paper collection process Through the keywords mentioned above (Section A.1),\nabout 134 papers were grouped; this set further decreased the number to 111 publications after the\nScreening stage (Section A.1), removing unrelated or duplicate publications. This manual annotation\nfirst involves assessing whether a paper is relevant (1), not relevant (0) or the annotator is unsure about\nitsrelevance(2). Inthelattercase,athirdannotatorwoulddeterminewhethertoincludethepublication.\nThisdetailedscreeningstageledtotheexclusionof17morepapers,2ofwhichweresupersededbynewer\npublicationsbythesameauthors,and8werefinallydeemednotcloselyrelatedtotheSTI. Therefore,88\napproaches were discussed in the following survey, each one described in one or more publications. For\nthissurvey’sscope,asdiscussedinSection3,weidentifiedseveralcriteriaforcomparingSTIapproaches.\nFig.8summarisesthedistributionofapproachesinconferencesandjournals;fromthisanalysis,itcan\nbe deduced that the STI involves multiple research communities like Semantic Web, Data Management,\nAI ,andNLP. Fig.9showsagraphwiththecross-referencesbetweenthearticles40. Forsomeapproaches\nit is indicated whether they are derived from previously published versions.\n40An online interactive visualisation of the cross-references chart is available at\nobservablehq.com/@elia-guarnieri-ws/cross-reference. A tabular representation is available at pub-\nlic.tableau.com/app/profile/marco.cremaschi/viz/ChallengesandDirectionintheAnnotationofTabularData/Crossreference\n39\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\n27\n10\n6\n4 4\n3 3 3\n2 2 2 2\n1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nFigure 8: Number of approaches for each conference or journal. The extended version of the acronyms\nis shown in Table 7 in Appendix D.\nFigure 9: A cross-reference chart for the analysed papers.\nTable 2 provides a detailed comparison of all the approaches analysed.\n40\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nbaTmeS CWSI BDLV WWW IAAA DOMGIS CWSE SWOJ EI4DL CGK WAKE MKIC CSW ESIW ASIW SMIW LAITAPSGIS DDKGIS SDS WODL EDKT\nEEEI\nCSCI\nEEEI\nIACJI IACI SCITNAMES-I SCGF RE TBDE EKD\nYEAR AUTHOR METHOD PUBLICATION INDEX LICENCE TRIPLE STORE\n2007 Hignetteetal.[70] Unsup WISE — — Personalontologies\n2009 Hignetteetal.[71] Unsup ESWC — — Personalontologies\n2009 Taoetal.[157] Unsup DKE — — Personalontologies\n2010 Limayeetal.[105] Unsup VLDB — — Yago\n2010 Mulwadetal.[117] Sup ISWC — — Wikitology\n2010 Syedetal.[151] Unsup WSC Luceneforconcepts — Wikitology\n2011 Mulwadetal.[118] Sup AAAI — — DBpedia,Freebase,WordNet,Yago\n2011 Venetisetal.[162] Unsup VLDB — — Yago\n2012 Goeletal.[63] Sup ICAI — — —\n2012 Knoblocketal.[94] Sup ESWC — Apache2.0 Personalontologies\n2012 Pimplikaretal.[131] Unsup VLDB — — —\n2012 Wangetal.[164] Unsup ER — — —\n2013 Bucheetal.[22] Unsup IEEE — — —\n2013 Cruzetal.[43] Sup SIGSPATIAL — — —\n2013 Dengetal.[49] Unsup VLDB — — DBpedia,Freebase,Yago\n2013 Ermilovetal.[57] Unsup I-SEMANTICS — — —\n2013 Mulwadetal.[116] Sup ISWC — — DBpedia,Yago,Wikitology\n2013 Munozetal.[115] Unsup LD4IE — — DBpedia\n2013 Quercinietal.[134] Unsup EDBT — DBpedia\n2013 Zhangetal.[175] Unsup SIGMOD — — —\n2013 Zwicklbaueretal.[183] Unsup ISWC — — DBpedia\n2014 Sekhavatetal.[142] Unsup LDOW — — Yago\n2014 Taheriyanetal.[152] Unsup IEEE — — —\n2015 Bhagavatulaetal.[19] Sup ISWC — CCA4.0 Yago\n2015 Ramnandanetal.[135] Sup ESWC trainingdatawithLucene,notKGdata Apache2.0 —\n2015 Ritzeetal.[138] Unsup WIMS — Apache2.0 DBpedia\n2016 Ermilovetal.[58] Unsup EKAW — GPL3.0 DBpedia\n2016 Neumaieretal.[119] Sup ISWC — Apache2.0 DBpedia\n2016 Phametal.[129] Sup ISWC — Apache2.0 —\n2016 Taheriyanetal.[154] Sup JOWS — Apache2.0 CIDOC-CRM,EDM\n2016 Taheriyanetal.[153] Sup ISWC — Apache2.0 CIDOC-CRM\n2017 Efthymiouetal.[55] Hybrid ISWC — — —\n2017 Elletal.[56] Unsup LD4IE Labels+literals Apache2.0 DBpedia\n2017 Zhangetal.[180] Unsup JOWS — Apache2.0 Freebase\n2018 Kacprzaketal.[85] Unsup EKAW — MIT DBpedia\n2018 Luoetal.[108] Sup AAAI — — Wikipedia\n2018 Zhangetal.[176] Unsup WWW — — —\n2019 Chabotetal.[26] Unsup SemTab — Orange DBpedia\n2019 Chenetal.[27] Hybrid AAAI — Apache2.0 DBpedia\n2019 Chenetal.[27] Unsup IJCAI — Apache2.0 DBpedia\n2019 Cremaschietal.[35] Unsup SemTab — Apache2.0 DBpedia\n2019 Hulsebosetal.[74] Sup SIGKDD — MIT DBpedia\n2019 Kruitetal.[98] Hybrid ISWC — MIT DBpedia,Wikidata\n2019 Morikawaetal.[114] Unsup SemTab Elasticsearch — DBpedia\n2019 Nguyenetal.[120] Unsup SemTab — — DBpedia\n2019 Oliveiraetal.[124] Unsup SemTab ArangoDB+Elasticsearch — DBpedia\n2019 Steenwinckeletal.[147] Unsup SemTab — — DBpedia\n2019 Takeokaetal.[155] Sup AAAI — — WordNet\n2019 Thawanietal.[158] Unsup SemTab Elasticsearch MIT —\n2019 Zhangetal.[174] Sup VLDB — Apache2.0 DBpedia\n2020 Abdelmageedetal.[1] Unsup SemTab — MIT Wikidata\n2020 Azzietal.[12] Unsup SemTab — — Wikidata\n2020 Baazouzietal.[14] Unsup SemTab — — Wikidata\nThis\nwork\nis\nshared\nunder\na\nCC\nBY-SA\n4.0\nlicense\nunless\notherwise\nnoted\n41\nATC APC AEC\nAENC EDOC\nYEAR AUTHOR METHOD PUBLICATION INDEX LICENCE TRIPLE STORE\n2020 Chenetal.[29] Unsup SemTab Elasticsearch — Wikidata\n2020 Cremaschietal.[38] Unsup FGCS — Apache2.0 DBpedia\n2020 Cremaschietal.[34] Unsup SemTab LamAPI Apache2.0 DBpedia,Wikidata\n2020 Eslahietal.[59] Unsup SDS — — Wikidata\n2020 Guoetal.[65] Sup WISA — — —\n2020 Huynhetal.[78] Hybrid SemTab Sparkdataframes — Wikidata\n2020 Khuranaetal.[89] Sup CIKM — — —\n2020 Kimetal.[91] Unsup SemTab — — Wikidata\n2020 Lietal.[103] Sup VLDB — Apache2.0 —\n2020 Nguyenetal.[122] Unsup SemTab HashTable+SparseMatrix — Wikidata\n2020 Shigapovetal.[143] Unsup SemTab SeerXmetasearchAPI MIT Wikidata\n2020 Tyagietal.[161] Unsup SemTab — — Wikidata\n2020 Yumusaketal.[172] Unsup SemTab — — Wikidata\n2020 Zhangetal.[178] Sup WWW — CCA4.0 DBpedia\n2021 Abdelmageedetal.[3] Unsup SemTab — Apache2.0 DBpedia,Wikidata\n2021 Abdelmageedetal.[2] Unsup KGC — Apache2.0 DBpedia,Wikidata\n2021 Avogadroetal.[9] Unsup SemTab LamAPI Apache2.0 DBpedia,Wikidata\n2021 Baazouzietal.[13] Unsup SemTab — — Wikidata\n2021 Heistetal.[69] Hybrid WWW — GPL3.0 CaliGraph,DBpedia,Yago\n2021 Huynhetal.[77] Hybrid SemTab Elasticsearch Orange DBpedia,Wikidata\n2021 Nguyenetal.[123] Unsup SemTab CustomBM25 MIT DBpedia,Wikidata\n2021 Steenwinckeletal.[146] Hybrid SemTab — Imeclicense Wikidata\n2021 Wangetal.[163] Sup WWW — — —\n2021 Yangetal.[170] Sup SemTab — — Wikidata\n2021 Zhouetal.[181] Sup CIKM — — —\n2022 Abdelmageedetal.[4] Unsup KGC — Apache2.0 DBpedia,Wikidata\n2022 Chenetal.[30] Unsup JWS Elasticsearch MIT DBpedia,Wikidata\n2022 Cremaschietal.[36] Unsup SemTab LamAPI Apache2.0 DBpedia,Wikidata\n2022 Dengetal.[50] Sup SIGMOD — Apache2.0 —\n2022 Gottschalketal.[64] Sup SWJ — MIT —\n2022 Huynhetal.[75] Hybrid SemTab Elasticsearch Orange DBpedia,Wikidata\n2022 Liuetal.[107] Hybrid ISWC — Orange Wikidata\n2022 Suharaetal.[149] Sup SIGMOD — Apache2.0 Freebase,DBpedia\n2024 Zhangetal.[179] Sup arXiv — MIT Wikidata\nTable2: Comparisontable.\nThis\nwork\nis\nshared\nunder\na\nCC\nBY-SA\n4.0\nlicense\nunless\notherwise\nnoted\n42\nATC APC AEC\nAENC EDOC\nA.2 Techniques for Supervised and Unsupervised approaches\nTable 3 and Table 4 display the techniques used by unsupervised and supervised approaches analysed in\nthis survey.\n43\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 3: List of unsupervised techniques and related approaches.\nApproach CandidateGeneration EntityDisambiguation\nLimaye2010[105] YAGOcatalog similarity\nSyed2010[151] Wikitology CTA\nWang2012[164] patternmatching features\nMunoz2013[115] - redirects\nRitze2015[138] DBpedialookupservice CTA\nEll2017[56] customindex features\nZhang2017[180] externallookup similarity\nZhang2018[176] SPARQL entityembedding\nCremaschi2019[35] SPARQL similarity\nMorikawa2019[114] SPARQL,Elasticsearch CTA\nNguyen2019[120] DBpedialookupservice,DBpediaendpoint,WikipediaAPI,WikidataAPI CTA\nOliveira2019[124] Elasticsearch similarity\nSteenwinckel2019[147] DBpedialookupservice,DBpediaurls,DBpediaSpotlight similarity\nThawani2019[158] WikidataAPI,Elasticsearch similairty,CTA,ML\nAbdelmageed2020[1] Wikidatalookupservice CTA,CPA\nAzzi2020[12] WikidataAPI CTA\nChen2020[29] MediawikiAPI,Elasticsearch CTA,CPA\nCremaschi2020-1[38] SPARQL similarity\nCremaschi2020-2[34] Elasticsearch CTA,CPA\nKim2020[91] SPARQL features\nNguyen2020[122] customindex CPA\nShigapov2020[143] SearX,SPARQL,Wikibooks,WikipediaAPI,WikidataAPI similarity\nTyagi2020[161] Wikidatalookupservice,DBpedialookupservice similarity\nAbdelmageed2021-1[3] Wikidatalookupservice,SPARQL similarity\nAbdelmageed2021-2[2] Wikidatalookupservice,SPARQL similarity\nAvogadro2021[9] customindex similarity,CTA,CPA\nBaazouzi2021[13] SPARQL CTA\nNguyen2021[123] customindex CPA\nAbdelmageed2022[4] SPARQL,Wikidatalookupservice similarity\nChen2022[30] Elasticsearch similarity,CTA,CPA\nCremaschi2022[36] Elasticsearch similarity,CPA,CTA\n44\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 4: List of supervised techniques and related approaches.\nTechnique Approaches\nMulwad2010[117]\nSVMclassifier[33] Quercini2013[134]\nErmilov2016[58]\nNaiveBayes Quercini2013[134]\nBinaryclassifier Zhang2020[178]\nGoel2012[63]\nKnoblock2012[94]\nCRFclassifier[99] Zhang2019[174]\nRamnandan2015[135]\nGuo2020[65]\nMulwad2011[117]\nMulwad2013[116]\nMarkovNetwork[92] Zhang2013[175]\nBhagavatula2015[19]\nTakeoka2019[155]\nZhang2013[175]\nErmilov2016[58]\nProbabilisticGraphicalModels(PGMs)[96]\nKruit2019[98]\nYang2021[170]\nHierarchicalclustering Neumaier2016[119]\nLogisticRegression[167] Pham2016[129]\nLuo2018[108]\nHulsebos2019[74]\nMulti-LayerNeuralNetwork Zhang2019[174]\nZhou2021[181]\nGuo2020[65]\nChen2019[27]\nChen20192[28]\nCNN[61]\nGuo2020[65]\nWang2021[163]\nSteenwinckel\nHybridDecisionTree(HDT)embeddings[182]\n2021[146]\nZhang2018[176]\nWord2vecembeddings[113] Zhang2020[178]\nDeng2022[50]\nTransE[54]andRotatE[150]embeddings Liu2022[107]\nSiameseNetworks Gottschalk2022[64]\nLi2020[103]\nLanguagemodel(BERT)[87] Deng2022[50]\nSuhara2022[149]\nLatentDirichletAllocation(LDA)[20] Khurana2020[89]\nTableLLama\nLargeLanguageModels(LLama2-7B)[160]\n2024[179]\n45\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nApache 2.0 23\nMIT 9\nOrange 4\nGPL 3.0 2\nCCA 4.0 2\nImec licIemnesec 1\nFigure 10: The distribution of the licenses adopted by STI approaches.\nB STI tools\nB.1 Tools analysis\nThis Section analyses the tools that support STI. Several tools can support table interpretation by\nproviding data visualisation, manipulation, and statistical analysis features. This further analysis aims\nto gather information on the tools available for interpreting a table, or more generally, of a structured\ndata source, to identify their features, strengths, and limitations and assess their suitability for different\nuse cases.\nKarma41 [66] is an Open Source (Apache license 2.0) information integration tool that allows users\nto integrate data coming from different sources quickly and easily. Such sources include databases,\nspreadsheets,delimitedtextfiles,XML,JSON,CSVandWebAPI.Userscanleveragedifferentontologies\nto annotate their data with standard vocabularies, ensuring accurate integration. Karma provides a\nresponsive interface, fast processing, and batch mode for large datasets. Additionally, it offers data\ntransformation scripts to convert data into a common format. A demonstration video42 is available.\nTableMiner+[111]consistsmainlyoftwocomponents: aJavalibrarythatimplementsthehomonym\napproach [180] and an extension that constitutes a user-friendly UI for the semantic annotation of Web\ntables. The current version of the tool corresponds to the alpha 1.0 development phase. Although\nthe source code is available43, the use is limited as the queries refer to Freebase. Even after applying\nmodifications to exclude calls to the Freebase API and refer to DBpedia instead, an HTTPException\nerror with code 500 prevented the STI phase. Such an error probably indicates an incorrect formulation\nof the SPARQL queries within the TableMiner+ algorithm. Consequently, the analysis is based on the\ninformation provided in the paper [111].\nTheMAGICtool44[146]supportsuserstoannotatedatabyfollowingastructuredpipelinetoaugment\nthe semantics of a given table and provides a user-friendly graphical interface for column augmentation.\nHowever, it is important to note that the GUI lacks feedback on the produced annotations during table\nprocessing. The Instance Neighboring using Knowledge (INK) embedding technique can also enrich the\ntable with information from the same dataset, semantically enriching the overall dataset with external\nlinked data. A demonstration video of the MAGIC tool is available45.\nTheMTabtool46 [123]isdesignedtoautomaticallyannotatedatausingKGs. Itenrichestheoriginal\ntable data by adding schema and instance-level annotations. The tool supports multilingual tables and\nvariousformatssuchasExcel,CSV,andmarkdowntables. Thesystemoperatesthroughaseriesofsteps:\npreprocessing the tabular data and then enriching the table with semantic annotations using prediction\nand search functionality. Notably, the system achieved first place in the usability track of the SemTab\nchallenge. It includes a UI that offers features like table upload and an annotate button to initiate\nthe process comprising the mentioned tasks. Additionally, the UI allows users to search for entities in\npopular KGs like Wikidata and DBpedia. However, it is important to note that the search functionality\noperates independently and does not assist users in other aspects of the annotation process. The MTab\n41usc-isi-i2.github.io/karma\n42www.youtube.com/watch?v=h3 yiBhAJIc\n43github.com/ziqizhang/sti\n44github.com/IBCNServices/MAGIC\n45www.youtube.com/watch?v=ZhTKxcTBZNE\n46mtab.app/mtab\n46\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\ntool is accessible solely through an online web interface, with no available source code about the final\nversion47.\nMantisTable tool48 [35] is a user-friendly UI that facilitates the exploration of the annotation steps\nwithin the STI process. Specifically, the tool enables users to visually explore and execute annotations\nthrough all the sub-tasks of the STI process. It features a convenient right sidebar that offers additional\ninformation about each annotation in an info mode and allows manual editing of annotations using\nan edit mode widget. To support the annotation editing process, MantisTable leverages KG summary\nprofiles provided by ABSTAT [145].\nOpenRefine49 is an Open Resource tool able to support different formats such as TSV, CSV, Excel,\nXML,RDF/XML,JSON,N3andLOG.Itoffersaworkspacewithseveralfeatures,includingtheabilityto\nexportprojectsindifferentformats,exploredatathroughfiltersandfacetedexploration,applyclustering\nfor grouping cells, modify cells individually or in groups using transformation rules, modify columns by\nrenaming, deleting, or adding new ones, modify rows by filtering and flagging, display numerical value\ndistributions,andusesextensionsforadditionalfunctionality. OpenRefineoffersfunctionalitytoreconcile\nagainst user-edited data on Wikidata or other Wikibase instances or reconcile against a local dataset50.\nTrifacta51 is a collection of software used for data exploration and self-service data preparation for\nanalysis. Trifactaworkswithcloudandon-premisesdataplatforms. Itisdesignedforanalyststoexplore,\ntransform, and enrich raw data into clean and structured formats using techniques in ML, data visuali-\nsation, human-computer interaction, and parallel processing for non-technical users to prepare data for\nvariousbusinessprocessessuchasanalytics. Itiscomposedofthreemainproducts: i)TrifactaWrangler\n- a connected desktop application used to transform data for downstream analytics and visualisation;\nii) Wrangler Pro - support for large data volumes, deployment options for both cloud and on-premises\nenvironments, and the capability to schedule and operationalise data preparation workflows, iii) Wran-\ngler Enterprises - self-service functionalities to explore and transform data with centralised management\nof security, governance and operationalisation.\nOdalic addresses the limitations of TableMiner+ and is an Open Source tool. The code is available\ninGithub52 anditcanbeeasilyinstalledviaaDockerimage53. ItprovidesaUIfortableinterpretation,\ndataexportaslinkeddata,andresultsreviewthroughuserfeedback. ItsupportsCSVinputandmanual\nspecification of relationships between columns. Odalic can work with any KG accessible via SPARQL\nand perform STI using query results from different KG interrogations.\nDataGraft+ASIA54 referstotheintegrationofASIAandDatagraft: ASIAisatooltoassistusersin\nannotate tables and enrich their content using discovered links [46], and Datagraft [139], a cloud-based\ndata transformation and publishing platform that supports the design and execution of transformations\non tabular data. DataGraft+ASIA refers to the integration of ASIA and Datagraft: ASIA is a tool to\nassist users in annotate tables and enrich their content using discovered links [46], and Datagraft [140],\na cloud-based data transformation and publishing platform that supports the design and execution of\ntransformations on tabular data. Transformations in Datagraft include data cleaning functionalities but\nalsoRDFdatagenerationbasedontabletoRDFmappings(implementedwithGrafterizeframework55).\nASIA supports the annotation of a table: it exploits vocabulary suggestions from the knowledge graph\nprofiling tool ABSTAT [145] to annotate properties and column types, and entity linking algorithms\n(executed as services) to annotate cells. In addition, it uses data extension services to fetch data from\nthirdpartysourcesaddingnewcolumnstotheoriginaltable. Theuserscontroltheseoperationsfromthe\nGraphicalUserInterface(GUI)andchecktheresults. Asaconsequence,DataGraft+ASIAsupportstwo\nmainapplications: KGgenerationandtabulardataenrichment. ASIA-suportedannotationsaretraduced\nto data transformations specifications; these specifications can executed, making the transformations\nrepeatable, shareable, and extensible. Data can be exported in several tabular and RDF formats and\npublished in the DataGraft platform.\nDAGOBAH UI is a web interface designed to visualise, validate, enrich, and manipulate the results\nof the STI process through DAGOBAH API56. The tool allows table data extracted from various pre-\nloadedbenchmarksandadditionalfiles. ItutilisesDAGOBAH-SL,aRESTfulAPIthatimplementspre-\n47github.com/phucty/mtab dev-devversion\n48bitbucket.org/disco unimib/mantistable-tool\n49openrefine.org\n50openrefine.org/docs/manual/reconciling\n51trifacta.com\n52github.com/odalic\n53github.com/odalic/odalic-docker\n54datagraft.io\n55eubusinessgraph.eu/grafterizer-2-0\n56developer.orange.com/apis/table-annotation\n47\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nprocessing and STI functionalities. DAGOBAH UI addresses the problem of missing data by providing\nthe possibility of adding additional columns using the background knowledge provided by the KGs. The\ntool is only accessible through an online web interface, while the source code is unavailable.\n48\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nFunctionalities\nImportoftables\nImportoftablesviaAPI\nImportofontologies\nDefinitionofpersonalisedontologies\nSemi-automaticannotation/HITL\nAnnotationsuggestions\nAuto-completesupport\nSubjectcolumndetection\nCEA\nCTA\nCPA(NEcolumns)\nCPA(LITcolumns)\nTablemanipulation\nAutomatictableextension\nVisualisationofannotations\nAutosave\nExportmapping\nExportRDFtriplets\nOpenSource\nTable 5: table\nComparison of semantic table interpretation tools.\n49\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\namraK\n+reniMelbaT\ncigaM baTM\nelbaTsitnaM\nNATS\nenfieRnepO\natcafirT ciladO\ntfarGataD\nhabogaD IUTmeS\namaLLelbaT\nSemTUIisanOpenSource57 web-basedapplicationcomposedofafrontendmodulebuiltwithReact\nandRedux,andabackendserver. SemTUIfocusesontabulardataannotationandextensiontasksandis\ndecoupledfromDataGraft. Itimplementsa“link&extend”paradigm,inspiredbylinkedopendata,but\nmoregeneralandsupportedbyseveraldatalinkinganddataextensionservices(e.g.,geocodingservices,\ndata services, and so on). Compared to its first version ASIA, it provides a better GUI, and more\nfunctionalities to support human-in-the-loop tabular data annotation and extension. It is integrated\nwith end-to-end STI algorithms (improved from [36]) that provide a first annotation of an input table,\nwhich users are expected to revise and manipulate. Particular attention is given to the revision of entity\nlinking, which exploits a recent confidence-aware algorithm [8].\nTable 5 provides a comparison between tools.\nB.2 Comparison of tools with GUI\nIn this Section, we compare tools for STI or supporting STI tasks that also provide a GUI; these tools\nare introduced to assist users in applications listed in Section 7. We found twelve tools with these\nfeatures: Karma58 [66], TableMiner+ [111], MAGIC59 [146], MTab tool60 [123], MantisTable61 [35],\nOpenRefine62, Trifacta63, Odalic64 [93], DataGraft+ASIA65 [139, 46], DAGOBAH UI [141], SemTUI66,\nMantisTableUI67 [39].\nA short description for each tool is provided in Section B.2. Table 5 in Appendix B provide a com-\nparison of the tools based on some key features: i) table import, ii) ontology support, iii) ontology\nsupport, iv) semi-automatic semantic annotation/HITL, v) semantic annotation sugges-\ntions, vi) auto-complete support for the semantic annotation process, vii) STI sub-task,\nviii) table manipulation, ix) automatic table extension, x) graphical visualisation of seman-\ntic annotations, xi) auto save of current user workspace, xii) API services and SPARQL\nendpoint, xiii) export mapping and RDF triples, and xiv) open source.\nTable import: table import is a crucial functionality for enhancing usability from the users’ per-\nspective. It allows users to work with their tables without requiring manual data transfer, ensuring a\nsmootheruserexperience. Additionally,userscanperformvariousdataoperations,suchasfiltering,sort-\ning, aggregating, or visualising the data. Typically, tools provide two main methods for enabling table\nimport: wizardsandAPIs. Amongthetwelveanalysedtools,onlytwo(TableMiner+andOdalic)donot\noffer wizard functionality, while three (TableMiner+, Odalic, and OpenRefine) lack API functionalities\nfor table import.\nOntology support: amongtables,ontologiesplayanotherimportantrolethatwouldenhanceusers’\nsatisfaction and usability. They allow working with familiar and domain-specific terminology, ensuring\naccuracy and consistency in the semantic representation of the table. Moreover, the final annotated\ntables might be easily integrated with other systems. Tools reviewed in this survey offer users two\noptions: reusing existing ontologies, either by importing an ontology or searching vocabularies used in\nexisting KG, and creating personalised ones. Out of the 12 tools, 10 do not allow importing or reusing\nontologies. Only Karma and DataGraft+ASIA provide users with such functionality. Similarly, only\nDataGraft+ASIA supports users in defining their personalised ontology to annotate the data. Karma\nsupports users in importing different ontologies and combining them.\nSemi-automatic semantic annotation/HITL:semi-automaticsemanticannotationandhuman-\nin-the-loop ability allows users to review annotations. Users can correct, judge ambiguous or unclear\ninformation and refine automated annotations, improving the accuracy of the annotations. Almost half\nof the tools lack human-in-the-loop functionality. Such is implemented only in Karma, TableMiner+,\nMAGIC, MTab, MantisTable, Odalic, and DAGOBAH UI.\nSemi-automatic semantic annotation/HITL:semi-automaticsemanticannotationandhuman-\nin-the-loopabilityallowsuserstoreviewannotations. Userscancorrectandjudgeambiguousorunclear\ninformation and refine automated annotations, improving the accuracy of the annotations. Almost half\n57github.com/I2Tunimib\n58usc-isi-i2.github.io/karma\n59github.com/IBCNServices/MAGIC\n60mtab.app/mtab\n61bitbucket.org/disco unimib/mantistable-tool\n62openrefine.org\n63trifacta.com\n64github.com/odalic\n65datagraft.io\n66github.com/I2Tunimib\n67mantistable.datai.disco.unimib.it/\n50\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nof the tools lack human-in-the-loop functionality. Such is implemented only in Karma, TableMiner+,\nMAGIC, MTab, MantisTable, Odalic, and DAGOBAH UI.\nSemantic annotation suggestions: suchfunctionalitysavestimeandeffortforusersasitempow-\ners tools to automatically generate suggestions for the semantic annotation. In particular, for domains\nthatusersdonotknowabout,suchfunctionalitycanensuremoreaccurateandconsistentannotations,re-\nducingtheriskoferrorsorinconsistencies. Seventools,Karma,MAGIC,MantisTable,DataGraft+ASIA\nand SemTUI, provide users with annotation suggestions.\nAuto-complete support for the semantic annotation process: auto-complete functionality\nspeeds up the semantic annotation process by providing suggestions and/or completions for annota-\ntions. It drastically reduces the time and effort required for users to manually enter or search for an\nappropriate semantic term to use in the annotation process. Moreover, it prevents errors as a result of\nmiss-spelling. Karma, MantisTable, OpenRefine, Datagraft+ASIA, MantisTableUI and SemTUI imple-\nment auto-complete functionalities.\nSTI sub-tasks: not every STI sub-task is implemented in the available tools reviewed in this\nSection. Full implementation of the STI process would allow users full support to annotate every table\nelementaccurately. TableMiner+performsreconciliationbyannotatingcellswithspecificentitieswithin\nthe KG and identification of the S-column in a semi-automatic manner. The first feature is common\nto OpenRefine. Trifacta is the weakest tools concerning the implementation of STI sub-tasks, while\nTableMiner+,MTab,MantisTable,Odalic,MantisTableUI,DAGOBAHUIandSemTUIfullyimplement\nsuch functionalities.\nTable manipulation: tablemanipulationfunctionalityallowsuserstocleanandpreprocessthedata\nbefore performing semantic annotation. For example, among tools that implement such functionality,\nKarma and OpenRefine allow users to manipulate tables and refine them by allowing column modifica-\ntion, such as renaming, eliminating, or changing their order. This ensures that the data is in the desired\nform, removing any inconsistencies or errors that could affect the quality of the annotations. Despite\nbeing an important functionality, such is implemented only by almost half of the available tools (i.e.,\nKarma, OpenRefine, Trifacta, and DataGraft+ASIA) OpenRefine has features that are not common to\nothers in our analysis. For example the automatic creation of new columns, and the exploration of the\ncells through the facets.\nAutomatic table extension: this is an important functionality, especially for data enrichment\napplications as it automatically retrieves additional data from external sources. Furthermore, such\nfunctionalitycankeepthesemanticmodelup-to-date,reflectingthelatestknowledgeandinsightsdespite\nthe updated data. Only MAGIC, OpenRefine, Trifacta, DataGraft+ASIA, and SemTUI users might\nbenefit from such functionality.\nGraphical visualization of semantic annotations: graphical visualisation of semantic annota-\ntions supports users with a visual representation of the annotated data, allowing them to understand\nbetter the relationships and the structure of the data within the table. Moreover, it allows users to\nidentify inter-dependencies between different table parts, enhancing the overall semantic understanding.\nTableMiner+, OpenRefine, Trifacta and Odalic do not allow users to visualise annotations.\nAuto save of current user workspace: auto-saving ensures that the user’s work is continuously\nsaved, preventing data loss from system failure. It allows users to perform changes and modifications\nwith the assurance that their progress is automatically saved without worrying about manually saving\ntheir work. Such functionality might serve as a form of version control, enabling users to review and\nreverttopreviousversionsifneeded. Karma,OpenRefine,andTrifactahavetheautomaticsavingfeature\nof the current work status.\nExport mapping and RDF triples: exporting mappings and RDF triples allows the data anno-\ntated in the tool to be shared and integrated with other systems and applications, enabling interoper-\nability. Most available tools (Karma, MAGIC, MantisTable, Odalic, MantisTableUI, DataGraft+ASIA\nand DAGOBAH UI) allow both exports. Karma allows export in RDF format or JSON-LD. Regarding\nthe export of tabular data, Karma uses the R2RML format to highlight the annotations between the\ntable and the ontology. The other tools allow both exports. Only Trifacta does not implement any of\nthese functionalities.\nOpen Source: open-source tools provide transparency in their functionality, allowing users to un-\nderstand how the tool works and ensuring there are no hidden or proprietary algorithms or biases. All\nsoftware under such a license might be easily customised or modified. Only MTab, MantisTableUI, Tri-\nfacta and DAGOBAH UI do not provide the code in an open-source license. A detailed description of\nall tools can be found in the Appendix B.\n51\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nC Gold Standards\nGSsserveasabenchmarktomeasuretheperformanceofvariousapproachesandsystems. Moreover,GSs\nallow identifying the strengths and weaknesses of existing methods thus helping in the advancements\nof the state-of-the-art performance. Although several approaches deal with semantic annotations on\ntabular data, there are limited GSs for assessing the quality of these annotations. The main ones are\nT2Dv2, Limaye, Tough Table and SemTab. Table 6 in Appendix C shows statistics for the GSs68.\nThis Section considers only publicly available GSs. GSs for STI approaches can be classified based\non several dimensions.\nDomain: GSs can target a certain domain or cover a broad range of domains. Most of the avail-\nable GSs target cross-domain annotations. However, there are also some domain-specific GS such as\nIMDB [180], MusicBrainz [180], and BiodivTab [5].\nAnnotation coverage: GSsdifferinthelevelofgranularityatwhichannotationsareprovided. This\ncan range from fine-grained annotations capturing detailed semantic information at the cell or column\nlevel (classes, entities, predicates, e.g., WebTableStiching [137], 2T [44], and SemTab), to coarse-grained\nannotations(e.g.,LimayeAll[105],GitTables[73],TURL[50]),providingbroadersemanticcontextatthe\ntable or dataset level.\nNIL annotation: The previous Sections described how an approach should consider NIL annota-\ntions, which can be used for KG extension and construction. However, only three datasets currently\nconsider this type of annotation (i.e., [110], SemTab2022 R3 Biodiv, and SemTab 2022 R3 GitTables).\nThis underlines how more significant effort is needed on the part of the scientific community towards\nthis key challenge.\nDataset size: in STI, GSs should be composed of tables of varying sizes, from small to very large\ntables. This would allow systems to measure and evaluate their scalability performance. A signifi-\ncant proportion of GSs are relatively small (T2Dv2 [137], WebTableStiching [137], Limaye [105], Mu-\nsicBrainz[180],IMDB[180],Taheriyan[154],2T[44],REDTab[144],BiodivTab[5],andTSOTSA[84]).\nIn contrast, only a handful of them are larger (MammoTab69 [110], SOTAB [97], Wikary [112], GitTa-\nbles [73], and TURL [50]).\nDocumentation: GSs might be accompanied with documentation. It is important that certain\nfactors,suchastheavailabilityofguidelines,codeavailability,documentationonannotationconventions,\nandexamplesthataidinunderstandingandapplyingtheGS,areclearlystated. Thelistofwell-curated\nand documented datasets is limited (i.e., 2T [44], MammoTab [110], GitTables [73], REDTab [144],\nSOTAB [97], and BiodivTab [5]).\nTable 6 provides detailed statistics about GSs.\n68unimib-datai.github.io/sti-website/datasets/\n69unimib-datai.github.io/mammotab-docs/\n52\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 6: Statistics for the most common datasets. ‘—’ indicates unknown.\nCols Rows\nEnti- Usedfor\nGS Tables (min—max (min—max Classes Pred. KG\nties validationby\n—x¯) —x¯)\n[138, 58, 129, 55,\n1,2K 2,8K\n27,28,74,98,174,\nT2Dv2[137] 234 (1—30— (1—5K— 39 — 154 DBpedia\n38,59,65,89,178,\n4,52) 84,55)\n50,107]\n717\n300\nWebTableStitching[137] 50 (3—83— 9 400 6 DBpedia [137]\n(6—6—6)\n14,84)\n[183, 55, 180, 27,\nWikipedia\nLimaye[105] 6,5K — — 747 143K 90 28, 38, 59, 65, 89,\nYago\n107]\nLimayeAll[180] 6,3K 28,5K 136K — 227K — Freebase —\nLimaye200[180] 200 903 4,1K 615 — 361 Freebase —\nMusicBrainz[180] 1,4K 9,8K — — 93,3K 7K Freebase [180]\nIMDB[180] 7,4K 7,4K — — 92,3K — Freebase [180]\n2,5K 16K\nTaheriyan[154] 29 (3—71,3K— (1—13,8K— — — — Schema.org [154]\n529K) 957)\n802\n194K Wikidata\nToughTable(2T)[44] 180 (6—15,5K— 540 667K 0 —\n(1—8—4,46) DBpedia\n108K)\nMammoTab[110] 980K 5,6M 2,3M 2M 2,8M — Wikidata —\nSOTAB[97] 108K — — 91 — 176 Schema.org —\nWikary[112] 81,7K 22,5K 63,9K — 30,6K 188 Wikidata —\nSchema.org\nGitTables[73] 962K 11,5M 13,6M 2,4K — — —\nDBpedia\n44,6K 148K\nMusic\nREDTab[144] 9K (1—11— (1—353— 70 — 23 —\nLiterature\n4,86) 17,09)\nTURL[50]70 484K 2,8M 7,9M — 1,2M — DBpedia [50,179]\n1,2K 12,9K\nBiodivTab[5] 50 (1—43— (26—4,9K— 84 1,2K — Wikidata [5]\n23,96) 261)\nTSOTSACorpus[84] 16K — — 200 60K — FoodData —\n320 9K\nR1 64 (3—14— (7—586— 120 8,4K 116\n5,05) 143)\n59,6K 29,8K\nR2 11,9K (1—51— (1—1,5K— 14,8K 464K 6,7K\n5,55) 27,06)\nSemTab2019 R3 2,1K (4—1 80, —8K\n4,51)\n(6—153 2K 07— 5,7K 407K 7,6K DBpedia [ 12 46 7, ,3 15 5, 81 ]14,120,\n71,69)\n51,4K\n3,3K\nR4 817 (6—198— 1,7K 107K 2,7K\n(4—8—4,36)\n63,73)\n249K\n170K\nR1 34,3K (5—16— 136K 985K 136K\n(4—8—4,96)\n8,27)\n84,9K\n55,9K\nR2 12,1K (5—16— 438K 283K 43,8K\n(4—8—4,6)\n7,97)\n397K [1,12,14,29,38,\nSemTab2020 R3 62,6K 229K (3—16— 167K 768K 167K Wikidata 34,78,89,91,122,\n(3—7—3,66) 7,34) 143,161,172]\n670K\n79,6K\nR4 22,4K (6—15,5K— 32,5K 1,7M 56,5K\n(1—8—3,55)\n30,94)\n53\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nCols Rows\nEnti- Usedfor\nGS Tables (min—max (min—max Classes Pred. KG\nties validationby\n—x¯) —x¯)\n194K\n802 Wikidata\nR1 180 (6—15,5K— 539 667K 56,5K\n(1—8—4,46) DBpedia\n1,08K)\n29,3K\n5,6K\nR2 1,7K (5—58— 2,1K 47,4K 3,8K\nSemTab2021 (2—7—3,19) 17,73) [3,2,9,13,77,123,\nWikidata 146,170]\n58,9K\n17,9K\nR3 7,2K (5—21— 7,2K 58,9K 10,7K\n(2—5—2,48)\n9,18)\n9,9K 22,4K\nR1 3,8K 240 1,4K 319\n(2—5—2,56) (4—8—5,69)\nWikidata\n13,3K 28,5K\nR2HT 5,1K 398 1,9K 348\n(2—5—2,56) (4—8—5,57)\n97 81K Wikidata\nSemTab2022 R22T 180 802 195K — [4,30,36,107,75]\n111 177K DBpedia\nR3Biodiv 50 1,2K 12,9K 43 1,5K —\n6,2K DBpedia\nR3GitTables 7,6K 198K 841K 4,4K — — Schema.org\n1K Schema.org\n49,1K Wikidata\n26,1K\nR1 10,4K (3—11— — — — tfood —\n(2—4—2,51)\n5,72) Schema.org\nSemTab2023 Schema.org\nR2 — — — — — — —\ndbpedia\n54\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nD Additional Material\nTable 7 presents the acronyms with the respective names of the conferences or journals to which the\narticles analysed in this survey were submitted.\n55\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 7: Conferences and journals acronyms.\nAcronym Name\nAAAI AssociationfortheAdvancementofArtificialIntelligence\nCIKM TheConferenceonInformationandKnowledgeManagement\nDKE Data&KnowledgeEngineering\nEDBT InternationalConferenceonExtendingDatabaseTechnology\nEKAW EuropeanKnowledgeAcquisitionWorkshop\nER InternationalConferenceonConceptualModeling\nESWC ExtendedSemanticWebConference\nFGCS FutureGenerationComputerSystems\nI-SEMANTICSInternationalConferenceonSemanticSystems\nICAI InternationalConferenceonArtificialIntellicence\nIEEEICSC IEEEInternationalConferenceonSemanticComputing\nIEEETKDE IEEETransactionsonKnowledgeandDataEngineering\nIJCAI InternationalJointConferenceonArtificialIntellicenceOrganization\nISWC InternationalSemanticWebConference\nLD4IE InternationalConferenceonLinkedDataforInformationExtraction\nLDOW LinkedDataontheWeb\nJOWS JournalofWebSemantics\nKGC TheKnowledgeGraphConference\nLD4IE LinkedDataforInformationExtraction\nSDS SwissConferenceonDataScience\nSemTab SemanticWebChallengeonTabularDatatoKnowledgeGraphMatching\nSIGKDD InternationalConferenceonKnowledgeDiscovery&DataMining\nSIGMOD SpecialInterestGrouponManagementofData\nSIGSPATIAL InternationalConferenceonAdvancesinGeographicInformation\nSWJ SemanticWebJournal\nVLDB VeryLargeDataBases\nWISA WebInformationSystemsandApplications\nWISE WebInformationSystemsEngineering\nWSC WebScienceConference\nWWW TheWebConference\n56\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 8 provides support in selecting approaches in relation to various attributes, such as Method,\nTasks, Code availability, License and Triple store.\n57\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\nTable 8: Table for selecting approaches concerning the attributes Method, Tasks, Code availability,\nLicense and Triple store.\nTask\nLicence Triple Store References\nYES GPL3.0 DBpedia,Yago,CaliGraph 2021Heist[69]\nYES Apache2.0 DBpedia 2019Chen[27]\nNO - - 2017Efthymiou[55]\nNO - Wikidata 2020Huynh[78]\nNO Orange DBpedia,Wikidata 2021Huynh[77]\nYES Imeclicense Wikidata 2021Steenwinckel[146]\nYES MIT DBpedia,Wikidata 2019Kruit[98]\nNO - Wikipedia 2018Luo[108]\nYES Apache2.0 DBpedia 2016Neumaier[119]\nNO - - 2021Zhou[181]\nNO - WordNet 2019Takeoka[155]\nYES Apache2.0 - 2015Ramnandan[135]\nYES Apache2.0 DBpedia 2019Zhang[174]\nYES MIT - 2019Hulsebos[74]\nYES Apache2.0 CIDOC-CRM 2016Taheriyan[154]\nNO - - 2012Goel[63]\nYES Apache2.0 CIDOC-CRM,EDM 2016Taheriyan[153]\nYES Apache2.0 Personalontologies 2012Knoblock[94]\nYES MIT - 2022Gottschalk[64]\nNO CCA4.0 Yago 2015Bhagavatula[19]\nYES Apache2.0 - 2020Li[103]\nNO - Wikidata 2021Yang[170]\nNO - - 2013Cruz[43]\nNO CCA4.0 DBpedia 2020Zhang[178]\nNO - DBpedia,Freebase,WordNet,Yago 2011Mulwad[118]\nNO - DBpedia,Yago,Wikitology 2013Mulwad[116]\nNO - Wikitology 2010Mulwad[117]\nYES MIT Wikidata 2023Zhang[179]\nYES Apache2.0 - 2022Deng[50]\nNO - - 2013Ermilov[57]\nNO - Personalontologies 2009Tao[157]\nNO - - 2013Zhang[175]\nNO - DBpedia,Freebase,Yago 2013Deng[49]\nNO - Wikidata 2020Baazouzi[14]\nYES MIT DBpedia 2018Kacprzak[85]\nNO - Yago 2014Sekhavat[142]\nNO - - 2013Buche[22]\nNO - Personalontologies 2007Hignette[70]\nNO - Yago 2011Venetis[162]\nYES Apache2.0 DBpedia 2019Chen[27]\nYES GPL3.0 DBpedia 2016Ermilov[58]\nYES - Wikidata 2020Yumusak[172]\nNO Apache2.0 DBpedia 2017Ell[56]\nNO - DBpedia 2013Quercini[134]\nYES - - 2018Zhang[176]\nNO - DBpedia 2013Zwicklbauer[183]\nNO - Wikidata 2020Azzi[12]\nYES - Wikidata 2020Tyagi[161]\nNO - DBpedia 2013Munoz[115]\nNO MIT DBpedia,Wikidata 2021Nguyen[123]\nNO - - 2012Wang[164]\nNO - DBpedia 2019Steenwinckel[147]\nNO - Wikidata 2020Nguyen[122]\nNO - Wikitology 2010Syed[151]\nNO - Yago 2010Limaye[103]\nNO Orange DBpedia 2019Chabot[26]\nYES Apache2.0 DBpedia 2020Cremaschi[34]\nYES Apache2.0 DBpedia,Wikidata 2021Avogadro[9]\nYES Apache2.0 Freebase 2017Zhang[180]\nYES MIT - 2019Thawani[158]\nYES MIT DBpedia,Wikidata 2022Chen[30]\nYES MIT Wikida5ta8 2020Shigapov[143]\nYES - DBpedia 2019Oliveira[124]\nThis work is shared under a CC BY-SA 4.0 license unless otherwise noted\ndohteM\ndirbyH\ndesivrepuS\ndesivrepusnU\nAEC APC ATC\nAENC\nedoC\nelbaliavA",
    "pdf_filename": "Survey_on_Semantic_Interpretation_of_Tabular_Data_Challenges_and_Directions.pdf"
}