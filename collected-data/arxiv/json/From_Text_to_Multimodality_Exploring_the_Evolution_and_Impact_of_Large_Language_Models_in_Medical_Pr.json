{
    "title": "From Text to Multimodality Exploring the Evolution and Impact of Large Language Models in Medical Pr",
    "context": "Language Models (LLMs) have rapidly evolved from text-based systems to multimodal platforms, sig- niﬁcantly impacting various sectors including healthcare. This comprehensive review explores the progression of LLMs to Multimodal Large Language Models (MLLMs) and their growing inﬂuence in medical practice. We examine the current landscape of MLLMs in healthcare, analyzing their applications across clinical decision support, medical imaging, patient engagement, and research. The review highlights the unique capabilities of MLLMs in integrating diverse data types, such as text, images, and audio, to provide more comprehensive insights into patient health. We also address the challenges facing MLLM implementation, including data limitations, technical hurdles, and ethical considerations. By identifying key research gaps, this paper aims to guide future investigations in areas such as dataset development, modality alignment methods, and the establishment of ethical guidelines. As MLLMs continue to shape the future of healthcare, understanding their potential and limitations is crucial for their responsible and effective integration into medical practice. Index Terms—Multimodal Large Language Models (MLLMs), Medical Imaging, Clinical Decision Support, Patient Engagement, Data Integration The landscape of healthcare is constantly evolving, driven by an unprecedented explosion of data. Electronic health records, medical imaging, genomic sequencing, and wearable sensors generate an overwhelming amount of information, exceeding human capacity for efﬁcient analysis and inter- pretation [1]. This phenomenon presents both an opportunity and a challenge: ingesting this information can revolutionize healthcare, but doing so requires innovative tools capable of processing and synthesizing these diverse data streams. Artiﬁcial intelligence (AI) has emerged as a powerful force in addressing this challenge, with large language models (LLMs) at the forefront of this revolution. Initially, LLMs focused primarily on text-based tasks, demonstrating remarkable proﬁciency in understanding and generating human-like language [2]. However, the inherent multimodality of medicine, where clinical decisions often rely on the synthesis of information from diverse sources such as images, text, and genomics, necessitates more versatile models [3]. This need has given rise to Multimodal Large Language Models (MLLMs), a new generation of LLMs capable of processing and integrating information from various modalities. These advanced models potentially unlock a new era of precision medicine and personalized healthcare, offering a more comprehensive approach to medical data analysis and decision-making. A key strength of MLLMs is their ability to bridge the gap between unstructured and structured data, a particularly valuable feature in healthcare where information is often fragmented across different formats. For example, the REALM framework leverages LLMs to encode clinical notes and in- tegrates them with time-series EHR data, enhancing clinical predictions by incorporating external knowledge from knowl- edge graphs [4]. In a similar vein, the MedDr model [5] employs a diagnosis-guided bootstrapping strategy to build vision-language datasets, showcasing superior performance across various medical tasks through a retrieval-augmented diagnosis approach. These advancements underscore the po- tential of MLLMs to enhance data interoperability and extract",
    "body": "arXiv:2410.01812v4  [cs.CY]  19 Nov 2024\nFrom Text to Multimodality: Exploring the\nEvolution and Impact of Large Language Models in\nMedical Practice\nQian Niu1, Keyu Chen2, Ming Li2, Pohsun Feng3, Ziqian Bi4, Lawrence KQ Yan5, Yichao Zhang6,\nCaitlyn Heqi Yin7, Cheng Fei8, Junyu Liu1, Tianyang Wang9, Yunze Wang10, Silin Chen11, Benji Peng*,2\n1Kyoto University\n2Georgia Institute of Technology\n3National Taiwan Normal University\n4Indiana University\n5Hong Kong University of Science and Technology\n6The University of Texas at Dallas\n7University of Wisconsin-Madison\n8Cornell University\n9University of Liverpool\n10University of Edinburgh\n11Zhejiang University\n*Corresponding Email: benji@appcubic.com\nIndex Terms—large language models, medical practice, multi-\nmodality, artiﬁcial intelligence\nAbstract—Large\nLanguage\nModels\n(LLMs)\nhave\nrapidly\nevolved from text-based systems to multimodal platforms, sig-\nniﬁcantly impacting various sectors including healthcare. This\ncomprehensive review explores the progression of LLMs to\nMultimodal Large Language Models (MLLMs) and their growing\ninﬂuence in medical practice. We examine the current landscape\nof MLLMs in healthcare, analyzing their applications across\nclinical decision support, medical imaging, patient engagement,\nand research. The review highlights the unique capabilities\nof MLLMs in integrating diverse data types, such as text,\nimages, and audio, to provide more comprehensive insights into\npatient health. We also address the challenges facing MLLM\nimplementation, including data limitations, technical hurdles,\nand ethical considerations. By identifying key research gaps, this\npaper aims to guide future investigations in areas such as dataset\ndevelopment, modality alignment methods, and the establishment\nof ethical guidelines. As MLLMs continue to shape the future\nof healthcare, understanding their potential and limitations is\ncrucial for their responsible and effective integration into medical\npractice.\nIndex Terms—Multimodal Large Language Models (MLLMs),\nMedical Imaging, Clinical Decision Support, Patient Engagement,\nData Integration\nI. INTRODUCTION\nThe landscape of healthcare is constantly evolving, driven\nby an unprecedented explosion of data. Electronic health\nrecords, medical imaging, genomic sequencing, and wearable\nsensors generate an overwhelming amount of information,\nexceeding human capacity for efﬁcient analysis and inter-\npretation [1]. This phenomenon presents both an opportunity\nand a challenge: ingesting this information can revolutionize\nhealthcare, but doing so requires innovative tools capable\nof processing and synthesizing these diverse data streams.\nArtiﬁcial intelligence (AI) has emerged as a powerful force in\naddressing this challenge, with large language models (LLMs)\nat the forefront of this revolution.\nInitially, LLMs focused primarily on text-based tasks,\ndemonstrating remarkable proﬁciency in understanding and\ngenerating human-like language [2]. However, the inherent\nmultimodality of medicine, where clinical decisions often rely\non the synthesis of information from diverse sources such\nas images, text, and genomics, necessitates more versatile\nmodels [3]. This need has given rise to Multimodal Large\nLanguage Models (MLLMs), a new generation of LLMs\ncapable of processing and integrating information from various\nmodalities. These advanced models potentially unlock a new\nera of precision medicine and personalized healthcare, offering\na more comprehensive approach to medical data analysis and\ndecision-making.\nA key strength of MLLMs is their ability to bridge the\ngap between unstructured and structured data, a particularly\nvaluable feature in healthcare where information is often\nfragmented across different formats. For example, the REALM\nframework leverages LLMs to encode clinical notes and in-\ntegrates them with time-series EHR data, enhancing clinical\npredictions by incorporating external knowledge from knowl-\nedge graphs [4]. In a similar vein, the MedDr model [5]\nemploys a diagnosis-guided bootstrapping strategy to build\nvision-language datasets, showcasing superior performance\nacross various medical tasks through a retrieval-augmented\ndiagnosis approach. These advancements underscore the po-\ntential of MLLMs to enhance data interoperability and extract\n\nmeaningful insights from diverse sources, potentially revo-\nlutionizing how healthcare professionals access and utilize\npatient information.\nMLLMs show great potential for transforming healthcare\nby enabling a more comprehensive understanding of patient\nhealth, potentially leading to improved diagnostics, personal-\nized treatment plans, and enhanced patient engagement [6].\nFor instance, these models could analyze a patient’s medical\nhistory, imaging scans, and genetic data to provide more\naccurate diagnoses and predict disease risks, facilitating early\nintervention and tailored treatment strategies. In the ﬁeld of\nmedical imaging, the integration of LLMs has demonstrated\nsigniﬁcant progress. Research has shown the effectiveness of\nvisual language models (VLMs), a subset of MLLMs, in ana-\nlyzing various biomedical images, including brain MRIs, blood\ncell images, and chest X-rays [7]. A notable example is the\nLlaVA-Rad model, a lightweight and open-source multimodal\nsystem that has achieved state-of-the-art results on standard\nradiology tasks. This model has surpassed larger counterparts\nin both performance and accessibility, making it particularly\nsuitable for real-world clinical applications [6].\nMLLMs could also enhance communication between pa-\ntients and healthcare providers through interactive chatbots and\nvirtual assistants, potentially improving patient engagement\nand healthcare accessibility [8]. The creation of chatbots\nlike MedAide, which utilize optimized tiny-LLMs on edge\ndevices, demonstrates the capacity of MLLMs to provide\nmedical assistance in resource-limited settings and remote\nareas, addressing challenges in healthcare access [9]. However,\ndeveloping reliable and trustworthy medical chatbots requires\naddressing critical issues such as accuracy, privacy protection,\nand bias mitigation to meet the high standards required for\npatient care and safety.\nOur review aims to offer an overview of the current state\nof MLLMs in medicine and healthcare. We will not only\nexamine their architecture, capabilities, and limitations, but\nalso explore potential applications across various medical\ndomains. We will critically assess the challenges and research\ngaps impeding the widespread adoption of MLLMs in clinical\nsettings, including data limitations, technical difﬁculties, and\nethical considerations [10]. For example, the evaluation of\nLLMs in healthcare often relies on benchmarks that are usually\nunﬁt for real-world diagnostic frameworks and are likely\nvulnerable to data leakage [11], which indicates the need\nfor standardized evaluation frameworks and comprehensive\ndatasets that accurately reﬂect the clinical practice. By analyz-\ning the current research landscape and identifying key areas for\nfurther development, this review seeks to guide the responsible\nand effective integration of MLLMs into healthcare. Our\ngoal is to contribute to a brighter future where AI assists\nclinicians and enhances patient care, while addressing the\nunique challenges and requirements within the ﬁeld. In order\nto provide a clear overview of the various applications and\ncomponents of MLLMs in medicine, we present a taxonomy\nFig 1. This simpliﬁed taxonomy categorizes the key aspects\nof MLLMs in healthcare and medicine.\nII. THE RISE OF MULTIMODAL LARGE LANGUAGE\nMODELS IN MEDICINE\nA. LLMs and Their Evolution: From Text to Multimodal\nUnderstanding\nLarge language models (LLMs) represent a signiﬁcant ad-\nvancement in artiﬁcial intelligence, demonstrating remarkable\ncapabilities in comprehending and generating human-like text.\nArchitecturally, they often rely on the Transformer network\n[36], a powerful neural network structure that excels at cap-\nturing long-range dependencies and contextual relationships\nwithin text. LLMs are initially trained on massive text corpora,\na process known as pre-training, to develop a generalized\nunderstanding of language structure and patterns. This pre-\ntraining phase allows them to learn a wide range of linguistic\nfeatures and relationships, making them adaptable to various\ndownstream tasks.\nLLMs can be ﬁne-tuned on smaller, task-speciﬁc datasets\nto further reﬁne their performance in speciﬁc domains. For\nexample, ClinicalT5 [37] demonstrates how a general-purpose\nLLM (T5) can be adapted for clinical text by ﬁne-tuning it on\nthe MIMIC-III dataset. This adaptation to the medical domain\nis crucial for addressing the unique challenges of medical\nlanguage, including its specialized vocabulary and complex\nsemantic relationships [38].\nDespite impressive capabilities, LLMs may face many limi-\ntations. One notable issue is ”hallucination”, where the model\ngenerates plausible but incorrect or nonsensical information,\nas highlighted in the study by Ziaei and Schmidgall [39].\nHallucination can be particularly problematic in healthcare,\nwhere accuracy and reliability are the top priorities [28], [40].\nAdditionally, biases present in the training data can propagate\nto the model’s outputs, leading to unfair or discriminatory\noutcomes, as discussed in the paper by Reddy [41]. Addressing\nthese biases requires careful data curation and model develop-\nment strategies [42].\nIntegrating LLMs with other modalities, such as images\nand videos, results in MLLMs. MLLMs like GPT-4V [43],\n[44] and Gemini [45], [46] process and generate both text\nand visual information, which opens up new possibilities for\nmedical applications. For example, MLLMs can be used to\ngenerate captions for medical images [47], answer visual ques-\ntions about medical images [48], and even assist in medical\nreport generation [49]. On the other hand, MLLMs are still in\ntheir early stages, and these models often face challenges in\nterms of accuracy, reliability, and ethical considerations [50].\nFurther research is needed to fully explore the potential of\nMLLMs and address these challenges to enable their safe and\neffective deployment in clinical practice.\nB. Multimodality in Medicine: Embracing the Rich Variety of\nData\nMedicine is inherently multimodal, as it involves many\ntypes of information beyond just written text. For example,\nwhen a patient comes in with a possible lung infection, their\ncase might include several kinds of data: written information\n\nLLMs and MLLMs\nin Medicine\nApplications in\nMedicine\nClinical Decision Support\nDiagnosis and treatment\nrecommendations [1], [12]\nPrognostic prediction and\nrisk stratiﬁcation [13]\nMedical Imaging\nIntegration of visual and\ntextual data [14]\nReport generation and\nVQA [15], [16]\nPatient Engagement and\nCommunication\nChatbots & virtual assistants [9]\nPersonalized health\nrecommendations [17]\nPatient education [18]\nTechnical Aspects\nModality Alignment\nMethods\nMultimodal Converters:\nImages to text [19]\nMultimodal Perceivers:\nVision transformers [15]\nTools Assistance: Knowledge\ngraphs [20], [21]\nData-Driven Methods: Using\nlarge datasets [22], [23]\nKnowledge Integration\nFormat uniﬁcation [24], [25]\nGraph-based methods [26], [27]\nChallenges and\nLimitations\nData Scarcity and Quality\nLimited large-scale\nmultimodal datasets [22]\nBiases in training data [28]\nEthical and Regulatory\nConsiderations\nPrivacy & data security [29]\nBias and fairness in\nclinical outcomes [10], [13], [30]\nModel Interpretability and\nExplainability\nTrust and transparency in\nclinical decisions [3]\nOvercoming the\n”black box” nature [31]\nFuture Directions\nData Augmentation and\nMultilingual Support\nDevelopment of large\nmultilingual datasets [32]\nPrivacy-preserving\ndata sharing [33]\nAdvancements in\nModality Alignment\nMethods for cross-modality\ndata representation [34]\nEthics and Compliance\nRegulatory frameworks speciﬁc\nto MLLMs [35]\nKey Research\nGaps\nDataset standardization\nEthical guidelines for\nmultimodal AI systems\nImprovements in modality\nalignment and generalization\nFig. 1. Simpliﬁed Taxonomy of MLLMs in Medicine\n\nlike their medical history and symptoms noted by doctors,\nimages from chest X-rays, sound recordings of their breathing,\nand even genetic information to assess their personal risk.\nCombining these different types of information is important\nfor getting a complete picture of a patient’s health and more\naccurate and personalized medical care [51]. This is where\nmultimodal models shine, because they are designed to process\nand integrate various types of data.\nWe have seen a surge in developing MLLMs capable of\nprocessing and integrating diverse medical data types [52]. The\nstudy by Tian et al. [53] exempliﬁes this trend, showcasing\na Med-MLLM model that handles both visual and textual\ndata for improved clinical decision-making, particularly in rare\ndiseases and pandemics. MLLMs could revolutionize various\nmedical practices. For instance, in radiology, MLLMs are\nbeing explored for generating comprehensive reports [54],\nassisting in diagnosis by analyzing both images and clinical\nnotes [4], and facilitating visual search and querying within\npatient imaging history [55].\nMLLMs for more specialized medical tasks has also gained\nmomentum. SkinGPT-4 is a system designed for dermato-\nlogical diagnosis using both images and clinical data, which\noffers autonomous image evaluation and treatment recommen-\ndations [16]. Developing robust and reliable MLLMs requires\novercoming many challenges. Large, diverse, and unbiased\nmedical datasets across multiple modalities are crucial [48].\nAccuracy, interpretability, explainability, interoperability, and\nethics are important to be discussed before integrating into\nexisting clinical workﬂows [35].\nC. Modality Alignment Methods: Bridging the Semantic Gap\nIntegrating different data types into LLMs is challenging,\nmainly because of differences in how each type represents\ninformation. Aligning these modalities is essential for LLMs\nto process and reason over multimodal data. Researchers are\ncurrently exploring several methods for addressing this issue,\nwhich can be grouped into four main categories.\n• Multimodal Converters: These methods transform data\nfrom different modalities into a uniﬁed representation that\nLLMs can understand. For example, images might be\nconverted into textual descriptions or embeddings before\nbeing fed into the LLM. This approach is seen in models\nlike X-LLM [19], which treats modalities as foreign lan-\nguages and converts them to text, or LIFTED [56], which\ntransforms modalities into natural language descriptions\nfor improved clinical trial outcome prediction.\n• Multimodal Perceivers: These methods directly enhance\nthe LLMs’ perception of multimodal data. A vision\nencoder can be integrated into the LLM architecture to\nenable it to directly process and understand images and\ntexts. Med-Flamingo [15] incorporates a vision trans-\nformer for medical image understanding. Similar ap-\nproaches can be seen in models like SkinGPT-4 [16],\nwhich combines a vision transformer with a LLM for\ndermatological diagnosis, and MedVersa [34], which uses\na LLM as a learnable orchestrator to process both visual\nand linguistic information to interpret medical images.\n• Tools Assistance: These methods uses external tools for\nmultimodalities. A knowledge graph can link concepts\nacross modalities and provide additional context for the\nLLM. The study by Gao et al. [20] uses the Uniﬁed\nMedical Language System (UMLS) knowledge to en-\nhance diagnosis generation. A similar approach is used\nin BioLORD-2023 [21], which integrates LLMs with\nknowledge graphs to improve performance in semantic\ntextual similarity, biomedical concept representation, and\nnamed entity linking.\n• Data-Driven Methods: These methods rely on large-\nscale multimodal datasets to train LLMs directly on\nmultimodal tasks and often involves developing new\narchitectures and training strategies so the modals can\nlearn from different modalities simultaneously. Models\nlike BiomedGPT [23] are trained on those diverse mul-\ntimodal datasets. The recent open-source frameworks\nlike Hippocrates [22] further facilitates this approach\nby providing access to training datasets, codebases, and\nevaluation protocols, encouraging further collaborative\nefforts.\nEach method has its own strengths and weaknesses. Mul-\ntimodal converters are relatively simple but may lead to in-\nformation loss during conversion [57]. Multimodal perceivers\ncan potentially capture richer relationships between modalities,\nbut requires more complex architectures and training. Tools\nassistance uses existing knowledge bases and resources but\nmay not be comprehensive or up-to-date. Data-driven methods\ncan achieve high performance but require large and diverse\ndatasets.\nIII. APPLICATIONS OF MLLMS IN MEDICINE\nA. A. Clinical Decision Support\nWhile MLLMs integrate diverse data modalities, offering\na more comprehensive view of patient health and the ability\nto detect complex patterns for improved diagnosis, treatment\npersonalization, and risk assessment [58], their development\nis still in the early stages. As a result, LLMs continue\nto dominate the ﬁeld due to their maturity and established\nperformance. This section introduces both LLMs and MLLMs,\nwhile emphasizing the promise of multimodal models.\nDiagnosis and Treatment Recommendations: NYUTron\nis an LLM trained on clinical notes, for predicting patient\noutcomes with high accuracy [1]. PMC-LLaMA is a perfor-\nmant LLM for medical Q&A [59]–[61]. Almanac is an LLM\naugmented with retrieval capabilities from curated medical\nresources and has signiﬁcant improvements in factuality, com-\npleteness, user preference, and safety for clinical decision-\nmaking [12]. Med-PaLM 2 is a specialized LLM for medicine,\nshowcased superior performance on medical question an-\nswering and treatment recommendation tasks, signiﬁcantly\noutperforming GPT-3.5 [2]. Med-PaLM M is a MLLM achiev-\ning competitive performance on medical question answering,\nradiology report generation, etc. [62].\n\nPrognostic Prediction and Risk Stratiﬁcation: Beyond\ndiagnosis, LLMs have also shown promise in prognostic\nprediction and risk stratiﬁcation. Researchers have tried to use\nLLMs for prognostic prediction in immunotherapy, achieving\nencouraging results in improving accuracy and facilitating\nearly disease detection [13]. Studies have demonstrated the\npotential of LLMs and MLLMs to predict outcomes like\nmortality, length of stay, and readmission using structured\nEHR data, outperforming traditional machine learning models\nin few-shot settings. [26], [63] The Health-LLM, a LLM\nframework that has vision capability in the future integrating\nhealth reports and medical knowledge into LLMs, has also\nbeen proposed for enhanced disease prediction and personal-\nized health management, showcasing its superior performance\nover existing systems [64].\nDespite the potentials, LLM and MLLMs face limitations\nin clinical decision support. Explainability and interpretabil-\nity remain challenging, as their complex decision-making\nprocesses often lack transparency, hindering clinician trust\nand understanding [65]. Another concern is the potential\nfor bias and unfairness due to inherent biases in MLLM\ntraining data, which can exacerbate healthcare disparities [66].\nExtensive real-world validation in diverse clinical settings is\ncrucial to ensure the effectiveness and safety of MLLMs\nbefore widespread adoption, addressing potential risks and\nunexpected outcomes [35].\nSeveral real-world case studies have demonstrated the po-\ntential of LLMs in clinical decision support. One study showed\nthat an LLM optimized for diagnostic reasoning improved clin-\nicians’ differential diagnosis accuracy on challenging medical\ncases [67]. Another study found that an LLM could accurately\nclassify patient acuity levels in the emergency department,\ncomparable to human physicians [31].\nThe performance of LLMs in clinical decision support\nis often evaluated using traditional metrics like accuracy,\nprecision, recall, F1 score, and AUC [68]. Evaluating their\neffectiveness in this context requires moving beyond accu-\nracy and considering additional factors like interpretability,\nfairness, impact on clinical workﬂows, and user trust [69].\nThe development of standardized evaluation frameworks and\nbenchmarks, such as CLUE and BenchHealth, is crucial for\nassessing the clinical performance and real-world applicability\nof LLMs [70]–[72].\nB. Medical Imaging\nMLLMs are rapidly transforming medical imaging by of-\nfering potential for signiﬁcant improvements in diagnosis,\ntreatment planning, and patient care. These models, capable of\nprocessing and interpreting both textual and visual data, allow\nfor a more comprehensive understanding of patient conditions.\nThe MISS framework, proposed by Chen et al., treats med-\nical Visual Question Answering (VQA) as a generative task,\nachieving excellent results with fewer multimodal datasets\nand demonstrating the advantages of generative models in\npractical applications [14]. A key strength of MLLMs lies\nin their ability to analyze medical images in conjunction\nwith textual information such as radiology reports, clinical\nnotes, and patient history. This integration of multimodal data\nallows for a more holistic and nuanced understanding of a\npatient’s condition. Yildirim et al. demonstrate the value of\nthis approach in radiology, arguing that integrating multimodal\ndata can lead to a more comprehensive patient assessment\n[55]. MLLMs can automate the generation of radiology re-\nports, potentially improving efﬁciency and accuracy while\nreducing radiologists’ workload [54]. MLLMs also facilitate\nvisual question answering, enabling clinicians to interact with\nmedical images by asking speciﬁc questions and receiving\nrelevant information from the model [73].\nDespite advantages, several limitations hinder the adoption\nof MLLMs in medical imaging. One major challenge is the\nreliance on high-quality, labeled data. Chen et al. address\nthis issue in their work on the MISS framework, proposing\nsolutions for leveraging limited datasets [14]. Interpreting\ncomplex medical images may requires specialized knowledge\nthat current MLLMs do not fully possess. Mehandru et al.\nstress the need for high-ﬁdelity simulations to accurately\nassess LLM performance in these complex scenarios [73].\nEthics about fairness in image interpretation is also crucial,\nas these models can perpetuate existing healthcare disparities\nif not carefully designed and evaluated. Yildirim et al. discuss\nthese considerations in detail, focusing on design requirements\nfor ethical AI use in radiology [55].\nC. Patient Engagement and Communication\nMLLMs has changed patient engagement and communica-\ntion in healthcare. By integrating visual and textual modalities,\nMLLMs can create more personalized and interactive expe-\nriences, enhance patient education, facilitate communication,\nand provide tailored health recommendations.\nChatbots and Virtual Assistants: One of the most promis-\ning applications of MLLMs in patient engagement is chatbots\nand virtual assistants. Traditional chatbots often rely on rule-\nbased systems or simple ML models, with limited ability to\nunderstand complex queries and provide nuanced responses.\nMLLMs, however, can understand both text and images to\ncreate more natural and engaging conversations and result in\nimproved patient experiences [26], [74], [75].\nPersonalized Health Recommendations: MLLMs can also\nbe used to generate personalized health recommendations by\nanalyzing patient data and medical knowledge. By integrating\ninformation from electronic health records, medical literature,\nand even patient-provided images, MLLMs provide tailored\nadvice on lifestyle changes, medication adherence, etc [17].\nPatient Education: Educating patients improves health\noutcomes, but traditional methods often rely on static materials\nthat may be difﬁcult to understand or hard to be tailored\ntowards individual needs. MLLMs generates personalized ed-\nucational materials that are interactive, engaging, and easy to\ncomprehend. The MedSumm framework, for example, utilizes\nLLMs and VLMs to generate detailed summaries of Hindi-\nEnglish code-mixed medical queries, integrating visual aids\n\nto improve comprehension and support personalized medical\ncare [18].\nD. Research and Development\nMLLMs are offering promising solutions for literature re-\nview, drug discovery, clinical trial matching, and knowledge\nextraction. They have accelerated discoveries and enhanced\nknowledge extraction.\nLiterature Review and Knowledge Extraction: MLLMs\nare proving invaluable for navigating and synthesizing the\nvast and ever-growing body of biomedical literature. For\ninstance, BioLORD-2023 integrates LLMs with knowledge\ngraphs to achieve state-of-the-art performance in semantic\ntextual similarity, concept representation, and named entity\nlinking, enabling researchers to extract meaningful insights\nfrom complex medical texts [76], [77]. Similarly, MedMT5\ntries to overcome language barriers in medical research by\noffering a robust, open-source, multilingual model for the\nmedical domain, allowing for broader access to knowledge\nacross different languages [32].\nDrug Discovery: While still in the early stages, MLLMs in\ndrug discovery holds potential [78]. These models can analyze\ncomplex biological data, such as protein structures and drug\ninteractions, to identify potential drug targets and accelerate\nthe drug development process. By integrating information from\nvarious modalities, MLLMs can facilitate a more holistic\nunderstanding of disease mechanisms and drug interactions,\npotentially leading to the discovery of novel therapeutics and\npersonalized medicine approaches.\nClinical Trial Matching: MLLMs can signiﬁcantly im-\nprove the efﬁciency and accuracy of matching patients to\nsuitable clinical trials. These models can analyze patient data,\nincluding medical history, genetic information, and imaging\ndata, to identify potential eligibility criteria and match patients\nwith ongoing trials. The ability of MLLMs to process and\nunderstand multimodal data can enhance the identiﬁcation of\neligible patients, leading to more effective recruitment and\npotentially faster clinical trial completion.\nE. Administrative Tasks\nAdministrative tasks in healthcare is immense, which con-\nsumes signiﬁcant time and resources that could be allocated\nto improve patient care. MLLMs offer transformative solu-\ntions by automating many of these tasks, which streamlines\nprocesses and improves the overall efﬁciency. MLLMs can\nhandle tasks in documentation, billing, scheduling, etc. with\nremarkable speed and accuracy.\nAutomation of Documentation: MLLMs are transforming\nclinical documentation by automating tasks such as generating\nradiology reports [49] and transcribing medical conversations\n[79]. This automation can free up clinicians’ time, allowing\nthem to focus on patient care rather than paperwork. For\nexample, one study explored the use of LLMs to simplify radi-\nological reports for improved patient comprehension, ﬁnding\nthat LLMs can effectively create more accessible reports while\nacknowledging the need for careful validation to mitigate\npotential inaccuracies [80].\nBilling and Scheduling: The application of MLLMs in\nbilling and scheduling processes can signiﬁcantly improve\nefﬁciency and reduce errors. These models can analyze pa-\ntient data, insurance information, and scheduling constraints\nto automate appointment scheduling, generate billing codes,\nand process insurance claims. By streamlining these tasks,\nMLLMs can reduce administrative burdens on healthcare staff\nand improve patient satisfaction by reducing wait times and\nsimplifying billing processes.\nIV. RESEARCH GAPS AND UNANSWERED QUESTIONS\nA. Data Limitations and Needs\nWhile the potential of MLLMs in healthcare is signiﬁcant,\ntheir development and evaluation are hindered by limitations in\ndata resources. As highlighted by [62], medicine is inherently\nmultimodal, with data spanning text, imaging, genomics, and\nmore. Yet, current research faces several key challenges related\nto data:\nScarcity of Large-Scale, Multimodal Datasets: Existing\nbiomedical datasets are often limited in size and scope,\nparticularly those incorporating multiple modalities. Some\nresearchers mitigates the lack of datasets with locally-aligned\nphrase grounding annotations for complex semantic modeling\n[81], while other researchers often propose new dataset when\nreleasing new models [82]. The lack of large-scale datasets\nand their restricted size and scope is a major bottleneck for\ntraining robust and generalizable MLLMs for diverse medical\ntasks, especially when considering the need for datasets that\nreﬂect real-world clinical scenarios [64], [73].\nLack of Diversity and Representation: Existing datasets\noften lack diversity in terms of patient demographics, medical\nconditions, and healthcare settings. This issue is particularly\nrelevant when considering the potential biases introduced [83].\nChen et al. emphasizes the challenges of few-shot learning in\npredicting rare disease areas due to limited data [13]. The\nlack of representation results in biased models that perform\npoorly on underrepresented populations or speciﬁc medical\nconditions. The reliance on single-language data, primarily\nEnglish, is also a major concern [32], [84], [85]. It is difﬁcult\nto access large amounts of domain-speciﬁc pre-training data\nfor multiple languages, which makes it difﬁcult to resolve\nlinguistic bias [32].\nChallenges in Data Acquisition and Annotation: Obtain-\ning high-quality, annotated multimodal data in healthcare is\ncomplex and resource-intensive. [86] notes that medical image\nannotation is costly and time-consuming, while [87] points to\nthe lack of LLMs trained on medical records. This challenge\nis complicated by the need for expert annotations [61], [88].\nThe scarcity of medical image-text pairs for pre-training,\ndue to privacy and cost issues, is another major issue [14].\nAdditionally, ensuring data privacy and obtaining informed\nconsent are critical ethical considerations that require careful\nattention, particularly when dealing with sensitive medical\ninformation [35].\n\nB. Interdisciplinary Collaboration and Knowledge Integration\n1) Fostering Effective Interdisciplinary Collaboration: The\ndevelopment of clinically relevant and useful MultiModal\nLarge Language Models (MLLMs) requires bridging the gap\nbetween computer science and medicine. This interdisciplinary\nchallenge calls for collaboration among medical professionals,\ndata scientists, ethicists, and policymakers [65], [89], [90].\nSuch collaboration is essential to foster a shared understanding\nof both the technical capabilities of LLMs and the speciﬁc\nneeds and constraints of the healthcare domain.\nAs LLMs become more integrated into healthcare work-\nﬂows, it is crucial to deﬁne the roles and responsibilities\nof various stakeholders [91]. [10] stresses the importance of\nincentivizing users, developers, providers, and regulators to\nprepare for the transformative role of LLMs in evidence-based\nsectors. This preparation includes establishing clear guidelines\nfor accountability and oversight to ensure the safe and ethical\nuse of these powerful tools in healthcare settings.\nClinicians’ expertise is vital in guiding the development\nand evaluation of MLLMs to ensure they address real-world\nclinical needs [67], [92] illustrates how integrating an LLM\noptimized for diagnostic reasoning into a clinical workﬂow can\nimprove diagnostic accuracy and comprehensiveness. How-\never, further research is needed to explore effective methods\nfor incorporating clinicians’ feedback and domain expertise\nthroughout the model development process. This ongoing col-\nlaboration between healthcare professionals and AI developers\nis key to creating MLLMs that can truly enhance patient care\nand clinical decision-making [56], [93]–[95].\nC. Enhancing Knowledge Integration\nBeyond textual data, integrating domain-speciﬁc knowledge\nfrom sources like medical ontologies, knowledge graphs, and\nclinical guidelines is essential for the effectiveness of Large\nLanguage Models (LLMs) in complex medical tasks [81].\nA Signiﬁcant challenge in deploying LLMs for healthcare\nis addressing the issues of hallucinations and bias. LLMs\ncan generate factually incorrect information and perpetuate\nbiases present in their training data, which is particularly\nconcerning in medical contexts. To tackle this problem, [96]\nintroduces Med-HALT, a benchmark and dataset speciﬁcally\ndesigned to evaluate and mitigate hallucinations in medical\nLLMs. This tool emphasizes the critical need to address\nthese issues for safer healthcare applications. Additionally,\n[97] underscores the importance of incorporating diverse real-\nworld data and domain-speciﬁc knowledge to reduce factual\ninaccuracies and improve the model’s grounding in real-world\nclinical scenarios.\nThe development of multilingual models represents another\ncrucial area for advancement in medical LLMs. Most LLMs\nare trained primarily on English data, which limits their\naccessibility and applicability in diverse linguistic contexts.\nThe potential of bilingual ﬁne-tuned LLMs, such as Taiyi,\ncan achieve superior performance on biomedical NLP tasks\ncompared to general LLMs [98]. However, more research is\nneeded to develop effective methods for creating and evaluat-\ning multilingual medical LLMs that can cater to the needs of\ndiverse patient populations [84], [99].\nD. Ethical and Regulatory Framework\nThe potential of MLLMs in healthcare is clear, but their\ndeployment in real-world clinical settings presents signiﬁcant\nethical and regulatory challenges that demand careful consid-\neration and further research.\nA key issue is the lack of clear guidelines and regulations\nspeciﬁcally tailored for the development, deployment, and\nevaluation of LLMs in healthcare [87], [89]. Existing frame-\nworks for medical AI may not fully address the unique ethical\nand legal implications of LLMs, especially in the context of\nmultimodality. This gap in comprehensive guidance creates\nuncertainty for developers, clinicians, and regulators, which\ncould impede responsible innovation and safe implementation.\nBias, fairness, and transparency are critical concerns in\nthe use of LLMs in healthcare. Several studies highlight the\npotential for bias due to imbalances in training data [10], [13],\n[30]. This can result in unfair or inaccurate outcomes, partic-\nularly for underrepresented or marginalized populations. The\nlack of transparency in LLM and MLLM training processes\nand decision-making mechanisms also raises concerns about\naccountability and trust [89]. Future research should focus on\ndeveloping robust methods for identifying, quantifying, and\nmitigating biases, as well as ensuring transparency in their\ndevelopment and deployment.\nPatient privacy and data security are important when using\nLLMs in healthcare, as they involve processing sensitive\npatient information. Integrating multiple data modalities in\nMLLMs adds complexity to data management and raises ad-\nditional privacy concerns [3]. Developing secure data storage,\nde-identiﬁcation techniques, and access control mechanisms\nare crucial areas for future research. These challenges are\nparticularly evident in speciﬁc medical ﬁelds, such as dentistry,\nwhere the use of LLMs requires robust safeguards to protect\npatient data [33], [100], [101].\nAdditional research is needed to deﬁne the optimal balance\nbetween human oversight and LLM autonomy, and establish-\ning robust governance structures for LLMs in healthcare is\nessential to ensure accountability and public trust. A frame-\nwork for evaluating LLMs in healthcare, including a gover-\nnance layer to ensure accountability and public conﬁdence,\nhas been proposed [41]. Clear guidelines and standards are\nneeded for data governance, model development, performance\nevaluation, bias mitigation, and transparency. A collaborative\napproach involving developers, clinicians, ethicists, regulators,\nand patients is vital for establishing trust and promoting the\nresponsible use of LLMs in healthcare [102].\nE. Technical Advancements Required\nRealizing MLLMs’ potential requires overcoming signiﬁ-\ncant technical challenges. Existing research highlights several\nkey areas where advancements are urgently needed.\nAdvancing Modality Alignment Methods\n\nCurrent modality alignment methods, which aim to bridge\nthe semantic gap between different data types like text and\nimages, often struggle to capture the complex relationships\nand nuances present in medical data. This limitation hinders\nthe ability of MLLMs to integrate information effectively\nand generate accurate and coherent outputs [7], [103]. Novel\napproaches are needed to create more robust and nuanced\nalignment methods that can capture the complex interdepen-\ndencies between different modalities, ensuring a more holistic\nunderstanding of medical data.\nUnveiling the “Black Box”\nThe ”black box” nature of large language models, where\ntheir internal workings and decision-making processes remain\nopaque, is a signiﬁcant challenge for their deployment in high-\nstakes medical decisions. Clinicians need to understand the\nrationale behind AI-generated outputs to trust and validate\ntheir recommendations. The lack of transparency and inter-\npretability in current LLMs hinders the ability to identify\npotential biases, errors, or inconsistencies in their reasoning.\nFurther research to understand how LLMs make decisions,\nparticularly in the context of assessing clinical acuity is needed\n[31]. Developing methods to make LLMs more transparent and\ninterpretable is crucial for ensuring their safe and responsible\nuse in medical applications [104], [105].\nEnhancing Generalization and Robustness\nAchieving reliable generalization and robustness across di-\nverse medical contexts, patient populations, and languages is\ncrucial for the real-world deployment of MLLMs. Current\nmodels often struggle to generalize beyond their training data,\nwhich leads to inaccuracies and biases when applied to new\npopulations or scenarios. The study by Zhang et al. demon-\nstrates that while LLMs can effectively analyze data from\nspeciﬁc medical specialties, their performance often decreases\nwhen applied to other areas [73]. Additional efforts should\nfocus on developing methods to enhance the generalization ca-\npabilities of MLLMs, ensuring that they perform consistently\nand reliably across different medical contexts, diverse patient\npopulations, and various languages.\nDeveloping Efﬁcient and Scalable Models\nThe large size and computational demands of MLLMs\npose a signiﬁcant barrier to their deployment in resource-\nconstrained settings. Training and deploying these models\nrequire substantial computational power, which can be pro-\nhibitively expensive [106], [107]. Developing efﬁcient and\nscalable models that operates on less powerful devices or with\nreduced computational resources is crucial for making these\ntechnologies more accessible and equitable in healthcare.\nV. FUTURE DIRECTIONS AND CONCLUSION\nThis review has emphasized the potential of LLMs and\nMLLMs to revolutionize medicine and healthcare. While\nshowing early promise in areas like patient-trial matching\n[108], generating radiology reports [109], and assisting with\nclinical diagnostics [62], LLMs are still in their early stages.\nSigniﬁcant research gaps remain and must be addressed to\nunlock their full potential and ensure safe, responsible, and\nequitable integration into clinical practice.\nA. Data Augmentation and Access\nData Augmentation and Access: The scarcity of large-\nscale, high-quality, and diverse multimodal datasets is a major\nbottleneck [106]. This is especially true for languages other\nthan English [32]. Future research shall focus on:\nDataset Creation and Curation: Developing large, well-\nannotated datasets encompassing diverse medical specialties,\npatient populations, and languages is crucial [85]. This in-\ncludes incorporating visual data like medical images, alongside\ntext from EHRs, clinical notes, and medical literature [110].\nDatasets should represent real-world scenarios and address\nissues like imbalanced data [38]. The OmniMedVQA bench-\nmark provides a good example of a comprehensive dataset that\naddresses some of these challenges [48].\nPrivacy-Preserving Data Sharing: Investigating innovative\nmethods like federated learning [33] to enable collaborative\ndata sharing and model training while preserving patient\nprivacy.\nStandardization and Interoperability: Developing stan-\ndardized data formats and categories to facilitate data integra-\ntion and interoperability across different healthcare systems\nand institutions. This is crucial for training models that can\ngeneralize well to new settings [111].\nB. Advanced Modality Alignment\nA key area for future research is developing more so-\nphisticated methods for aligning different modalities. Future\nresearch could focus on developing novel architectures and\ntraining strategies that can better capture the complex relation-\nships between different modalities, leading to more accurate\nand robust predictions [112].\nC. Interpretability and Explainability\nA critical area for future research is enhancing the in-\nterpretability and explainability of MLLMs. This lack of\ntransparency in current LLMs MLLMs can hinder trust and\nadoption in clinical settings. Traditional evaluation methods\nfor MLLMs are usually insufﬁcient for clinical settings, as they\ndon’t adequately assess their impact on real-world workﬂows\n[73]. Future research should focus on developing methods to\nmake MLLM decision-making processes more transparent and\nunderstandable, such as generating human-readable explana-\ntions for their predictions or visualizing the processes that\ncontribute to their decisions.\nD. Robust Evaluation Frameworks\nRobust and standardized evaluation frameworks becomes\nincreasingly critical as MLLMs become increasingly sophis-\nticated. Current evaluation methods often rely on limited\ndatasets and metrics to non-clinical tasks, restricting the poten-\ntial to capture the full range of capabilities and biases [113].\nTo ensure the safe and effective of clinical MLLMs, future\neffort should spend on developing additional standardized\nbenchmarks with closer clinical relevance.\n\nE. Ethics and Compliance\nThe ethical implications of MLLMs in healthcare cannot\nbe overstated. Its training data contain sensitive patient in-\nformation, raising concerns about privacy and data security\n[29]. Biased training data can lead to discriminatory outcomes,\npotentially exacerbating existing health disparities. Therefore,\nclear regulatory frameworks and guidelines are necessary to\ngovern the development, deployment, and use of MLLMs in\nclinical settings [35]. Addressing these ethical and compliance\nchallenges will be beneﬁcial to establish trust and ensure the\nresponsible use of MLLMs in healthcare.\nREFERENCES\n[1] L. Y. Jiang, X. C. Liu, N. P. Nejatian, M. Nasir-Moin, D. Wang,\nA. Abidin, K. Eaton, H. A. Riina, I. Laufer, P. Punjabi, M. Miceli,\nN. C. Kim, C. Orillac, Z. Schnurman, C. Livia, H. Weiss, D. Kurland,\nS. Neifert, Y. Dastagirzada, D. Kondziolka, A. T. M. Cheung, G. Yang,\nM. Cao, M. Flores, A. B. Costa, Y. Aphinyanaphongs, K. Cho, and\nE. K. Oermann, “Health system-scale language models are all-purpose\nprediction engines,” Nature, vol. 619, no. 7969, pp. 357–362, jun 7\n2023.\n[2] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung,\nN. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl, P. Payne, M. Senevi-\nratne, P. Gamble, C. Kelly, A. Babiker, N. Sch¨arli, A. Chowdhery,\nP. Mansﬁeld, D. Demner-Fushman, B. Ag¨uera y Arcas, D. Web-\nster, G. S. Corrado, Y. Matias, K. Chou, J. Gottweis, N. Tomasev,\nY. Liu, A. Rajkomar, J. Barral, C. Semturs, A. Karthikesalingam, and\nV. Natarajan, “Large language models encode clinical knowledge,”\nNature, vol. 620, no. 7972, pp. 172–180, jul 12 2023.\n[3] J. N. Acosta, G. J. Falcone, P. Rajpurkar, and E. J. Topol, “Multimodal\nbiomedical AI,” Nature Medicine, vol. 28, no. 9, pp. 1773–1784, 9\n2022.\n[4] Yinghao Zhu, Changyu Ren, Shiyun Xie, Shukai Liu, Hangyuan Ji,\nZixiang Wang, Tao Sun, Long He, Zhoujun Li, Xi Zhu, and Cheng-\nwei Pan, “Realm: Rag-Driven Enhancement of Multimodal Electronic\nHealth Records Analysis via Large Language Models,” arXiv.org, 2024.\n[5] S. He, Y. Nie, Z. Chen, Z. Cai, H. Wang, S. Yang, and H. Chen,\n“Meddr:\nDiagnosis-guided\nbootstrapping\nfor\nlarge-scale\nmedical\nvision-language learning,” arXiv preprint arXiv:2404.15127, 2024.\n[6] J. M. Z. Chaves, S.-C. Huang, Y. Xu, H. Xu, N. Usuyama, S. Zhang,\nF. Wang, Y. Xie, M. Khademi, Z. Yang et al., “Training small\nmultimodal models to bridge biomedical competency gap: A case study\nin radiology imaging,” arXiv preprint arXiv:2403.08002, 2024.\n[7] M.-H. Van, P. Verma, and X. Wu, “On Large Visual Language\nModels for Medical Imaging Analysis: An Empirical Study,” in 2024\nIEEE/ACM Conference on Connected Health: Applications, Systems\nand Engineering Technologies (CHASE).\nIEEE, jun 19 2024, pp.\n172–176.\n[8] B. Mesk´o, “The Impact of Multimodal Large Language Models on\nHealth Care’s Future,” Journal of Medical Internet Research, vol. 25,\np. e52865, nov 2 2023.\n[9] Abdul Basit, Khizar Hussain, M. Hanif, and Muhammad Shaﬁque,\n“Medaide: Leveraging Large Language Models for On-Premise Medi-\ncal Assistance on Edge Devices,” arXiv.org, 2024.\n[10] S. Harrer, “Attention is not all you need: the complicated case of\nethically using large language models in healthcare and medicine,”\neBioMedicine, vol. 90, p. 104512, 4 2023.\n[11] D. Lyu, X. Wang, Y. Chen, and F. Wang, “Language model and its\ninterpretability in biomedicine: A scoping review,” iScience, vol. 27,\nno. 4, p. 109334, 4 2024.\n[12] C.\nZakka,\nR.\nShad,\nA.\nChaurasia,\nA. R.\nDalal,\nJ.\nL. Kim,\nM.\nMoor,\nR.\nFong,\nC.\nPhillips,\nK.\nAlexander,\nE.\nAshley\net al., “Almanac—retrieval-augmented language models for clinical\nmedicine,” NEJM AI, vol. 1, no. 2, p. AIoa2300068, 2024.\n[13] Zekai Chen, Mariann Micsinai Balan, and Kevin Brown, “Language\nModels are Few-shot Learners for Prognostic Prediction,” arXiv.org,\n2023.\n[14] Jiawei Chen, Dingkang Yang, Yue Jiang, Yuxuan Lei, and Lihua Zhang,\n“Miss: A Generative Pretraining and Finetuning Approach for Med-\nVQA,” arXiv.org, 2024.\n[15] Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Za-\nkka, Yashodhara Dalmia, E. Reis, P. Rajpurkar, and J. Leskovec, “Med-\nFlamingo: a Multimodal Medical Few-shot Learner,” ML4H@NeurIPS,\n2023.\n[16] J. Zhou, X. He, L. Sun, J. Xu, X. Chen, Y. Chu, L. Zhou, X. Liao,\nB. Zhang, S. Afvari, and X. Gao, “Pre-trained multimodal large\nlanguage model enhances dermatological diagnosis using SkinGPT-4,”\nNature Communications, vol. 15, no. 1, jul 5 2024.\n[17] D. Dao, J. Y. C. Teo, W. Wang, and H. D. Nguyen, “Llm-powered\nmultimodal ai conversations for diabetes prevention,” in Proceedings\nof the 1st ACM Workshop on AI-Powered Q&A Systems for Multimedia,\n2024, pp. 1–6.\n[18] Akash Ghosh, Arkadeep Acharya, Prince Jha, Aniket Gaudgaul, Ra-\njdeep Majumdar, Sriparna Saha, Aman Chadha, Raghav Jain, Setu\nSinha, and Shivani Agarwal, “Medsumm: A Multimodal Approach to\nSummarizing Code-Mixed Hindi-English Clinical Queries,” European\nConference on Information Retrieval, 2024.\n[19] Feilong Chen, Minglun Han, Haozhi Zhao, Qingyang Zhang, Jing Shi,\nShuang Xu, and Bo Xu, “X-LLM: Bootstrapping Advanced Large\nLanguage Models by Treating Multi-Modalities as Foreign Languages,”\narXiv.org, 2023.\n[20] Y. Gao, R. Li, J. Caskey, D. Dligach, T. Miller, M. M. Churpek, and\nM. Afshar, “Leveraging a medical knowledge graph into large language\nmodels for diagnosis prediction,” arXiv preprint arXiv:2308.14321,\n2023.\n[21] F. Remy, K. Demuynck, and T. Demeester, “Biolord-2023: seman-\ntic textual representations fusing large language models and clinical\nknowledge graph insights,” Journal of the American Medical Infor-\nmatics Association, vol. 31, no. 9, pp. 1844–1855, feb 27 2024.\n[22] Emre Can Acikgoz, Osman Batur .Ince, Rayene Bench, Arda Anil\nBoz, .Ilker Kesen, Aykut Erdem, and Erkut Erdem, “Hippocrates: An\nOpen-Source Framework for Advancing Large Language Models in\nHealthcare,” arXiv.org, 2024.\n[23] Kai Zhang, Jun Yu, Eashan Adhikarla, Rong Zhou, Zhiling Yan, Yixin\nLiu, Zheng Liu, Lifang He, Brian D Davison, Xiang Li, Hui Ren,\nS. Fu, James Zou, Wei Liu, Jing Huang, Chen Chen, Yuyin Zhou,\nTianming Liu, Xun Chen, Yong Chen, Quanzheng Li, Hongfang Liu,\nand Lichao Sun, “Biomedgpt: A Uniﬁed Biomedical Generative Pre-\ntrained Transformer for Vision, Language, and Multimodal Tasks,”\nNature Medicine, pp. 1–13, 2024.\n[24] Z. Shao, W. Dou, and Y. Pan, “Dual-level deep evidential fusion:\nIntegrating multimodal information for enhanced reliable decision-\nmaking in deep learning,” Information Fusion, vol. 103, p. 102113,\n2024.\n[25] Qinghao Ye, Haiyang Xu, Jiabo Ye, Mingshi Yan, Anwen Hu, Haowei\nLiu, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou, “mplug-Owl2:\nRevolutionizing Multi-modal Large Language Model with Modality\nCollaboration,” arXiv.org, 2023.\n[26] S. Niu, J. Ma, L. Bai, Z. Wang, L. Guo, and X. Yang, “Ehr-knowgen:\nKnowledge-enhanced multimodal learning for disease diagnosis gener-\nation,” Information Fusion, vol. 102, p. 102069, 2024.\n[27] Y. Ektefaie, G. Dasoulas, A. Noori, M. Farhat, and M. Zitnik, “Mul-\ntimodal learning with graphs,” Nature Machine Intelligence, vol. 5,\nno. 4, pp. 340–350, 2023.\n[28] K. Nassiri and M. A. Akhlouﬁ, “Recent Advances in Large Language\nModels for Healthcare,” BioMedInformatics, vol. 4, no. 2, pp. 1097–\n1143, apr 16 2024.\n[29] B. Peng, K. Chen, M. Li, P. Feng, Z. Bi, J. Liu, and Q. Niu, “Securing\nlarge language models: Addressing bias, misinformation, and prompt\nattacks,” arXiv preprint arXiv:2409.08087, 2024. [Online]. Available:\nhttps://arxiv.org/abs/2409.08087\n[30] L. Jiang, C. Liu, N. P. Nejatian, M. Nasir-Moin, D. Wang, A. Abidin,\nK. Eaton, H. A. Riina, I. Laufer, P. Punjabi, M. Miceli, N. C. Kim,\nC. M. Orillac, Z. Schnurman, C. Livia, H. Weiss, D. B. Kurland, S. N.\nNeifert, Y. M. Dastagirzada, D. S. Kondziolka, A. Cheung, G. Yang,\nM. Cao, M. Flores, A. Costa, Y. Aphinyanaphongs, K. Cho, and\nE. K. Oermann, “754 Prediction of 30-day All-Cause Readmission of\nNeurosurgery Patients Using Large Language Models,” Neurosurgery,\nvol. 70, no. Supplement 1, pp. 165–165, 4 2024.\n[31] C. Y. K. Williams, T. Zack, B. Y. Miao, M. Sushil, M. Wang, A. E.\nKornblith, and A. J. Butte, “Use of a Large Language Model to\nAssess Clinical Acuity of Adults in the Emergency Department,” JAMA\nNetwork Open, vol. 7, no. 5, p. e248895, may 7 2024.\n\n[32] Iker Garc’ia-Ferrero, R. Agerri, Aitziber Atutxa Salazar, Elena Cabrio,\nIker de la Iglesia, A. Lavelli, Bernardo Magnini, Benjamin Molinet,\nJohana Ramirez-Romero, German Rigau, J. M. Villa-Gonzalez, S.\nVillata, and Andrea Zaninello, “Medmt5: An Open-Source Multilingual\nText-to-Text LLM for the Medical Domain,” International Conference\non Language Resources and Evaluation, 2024.\n[33] D. Wang, L. Feng, J. Ye, J. Zou, and Y. Zheng, “Accelerating the\nintegration of ChatGPT and other largescale AI models into biomedical\nresearch and healthcare,” MedComm – Future Medicine, vol. 2, no. 2,\nmay 17 2023.\n[34] H.-Y. Zhou, S. Adithan, J. N. Acosta, E. J. Topol, and P. Rajpurkar,\n“A Generalist Learner for Multifaceted Medical Image Interpretation,”\narXiv preprint arXiv:2405.07988, 2024.\n[35] J. C. L. Ong, S. Y.-H. Chang, W. William, A. J. Butte, N. H. Shah,\nL. S. T. Chew, N. Liu, F. Doshi-Velez, W. Lu, J. Savulescu, and D. S. W.\nTing, “Ethical and regulatory challenges of large language models in\nmedicine,” The Lancet Digital Health, vol. 6, no. 6, pp. e428–e432, 6\n2024.\n[36] A. Vaswani, “Attention is all you need,” Advances in Neural Informa-\ntion Processing Systems, 2017.\n[37] Q. Lu, D. Dou, and T. Nguyen, “Clinicalt5: A Generative Language\nModel for Clinical Text,” in Findings of the Association for Compu-\ntational Linguistics: EMNLP 2022.\nAssociation for Computational\nLinguistics, 2022.\n[38] X. Meng, X. Yan, K. Zhang, D. Liu, X. Cui, Y. Yang, M. Zhang,\nC. Cao, J. Wang, X. Wang, J. Gao, Y.-G.-S. Wang, J.-m. Ji, Z. Qiu,\nM. Li, C. Qian, T. Guo, S. Ma, Z. Wang, Z. Guo, Y. Lei, C. Shao,\nW. Wang, H. Fan, and Y.-D. Tang, “The application of large language\nmodels in medicine: A scoping review,” iScience, vol. 27, no. 5, p.\n109713, 5 2024.\n[39] Rojin Ziaei and Samuel Schmidgall, “Language models are susceptible\nto incorrect patient self-diagnosis in medical applications,” arXiv.org,\n2023.\n[40] B. Peng, Z. Bi, P. Feng, Q. Niu, J. Liu, and K. Chen, “Emerging\ntechniques in vision-based human posture detection: Machine learning\nmethods and applications,” Authorea, 2024.\n[41] S. Reddy, “Evaluating large language models for use in healthcare: A\nframework for translational value assessment,” Informatics in Medicine\nUnlocked, vol. 41, p. 101304, 2023.\n[42] T. Han, A. Kumar, C. Agarwal, and H. Lakkaraju, “Medsafetybench:\nEvaluating and improving the medical safety of large language\nmodels,” 2024. [Online]. Available: https://arxiv.org/abs/2403.03744\n[43] J. Deng, K. Heybati, and M. Shammas-Toma, “When vision meets\nreality: Exploring the clinical applicability of GPT-4 with vision,”\nClinical Imaging, vol. 108, p. 110101, 4 2024.\n[44] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman,\nD. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4\ntechnical report,” arXiv preprint arXiv:2303.08774, 2023.\n[45] Ankit Pal and Malaikannan Sankarasubbu, “Gemini Goes to Med\nSchool: Exploring the Capabilities of Multimodal Large Language\nModels on Medical Challenge Problems & Hallucinations,” Clinical\nNatural Language Processing Workshop, 2024.\n[46] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut,\nJ. Schalkwyk, A. M. Dai, A. Hauth et al., “Gemini: a family of highly\ncapable multimodal models,” arXiv preprint arXiv:2312.11805, 2023.\n[47] Iryna Hartsock and Ghulam Rasool, “Vision-Language Models for\nMedical Report Generation and Visual Question Answering: A Re-\nview,” arXiv.org, 2024.\n[48] Yutao Hu, Tian-Xin Li, Quanfeng Lu, Wenqi Shao, Junjun He, Yu Qiao,\nand Ping Luo, “Omnimedvqa: A New Large-Scale Comprehensive\nEvaluation Benchmark for Medical LVLM,” arXiv.org, 2024.\n[49] T. Nakaura, R. Ito, D. Ueda, T. Nozaki, Y. Fushimi, Y. Matsui,\nM. Yanagawa, A. Yamada, T. Tsuboyama, N. Fujima, F. Tatsugami,\nK. Hirata, S. Fujita, K. Kamagata, T. Fujioka, M. Kawamura, and\nS. Naganawa, “The impact of large language models on radiology: a\nguide for radiologists on the latest innovations in AI,” Japanese Journal\nof Radiology, vol. 42, no. 7, pp. 685–696, mar 29 2024.\n[50] Yihe Fan, Yuxin Cao, Ziyu Zhao, Ziyao Liu, and Shaofeng Li,\n“Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in\nMultimodal Large Language Model Security,” arXiv.org, 2024.\n[51] S. Tripathi, R. Sukumaran, and T. S. Cook, “Efﬁcient healthcare with\nlarge language models: optimizing clinical workﬂow and enhancing\npatient care,” Journal of the American Medical Informatics Association,\nvol. 31, no. 6, pp. 1436–1440, jan 25 2024.\n[52] Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, Chenhui\nChu, and Dong Yu, “Mm-LLMs: Recent Advances in MultiModal\nLarge Language Models,” arXiv.org, 2024.\n[53] F. Liu, T. Zhu, X. Wu, B. Yang, C. You, C. Wang, L. Lu, Z. Liu,\nY. Zheng, X. Sun, Y. Yang, L. Clifton, and D. A. Clifton, “A medical\nmultimodal large language model for future pandemics,” npj Digital\nMedicine, vol. 6, no. 1, dec 2 2023.\n[54] R. Bhayana, “Chatbots and Large Language Models in Radiology: A\nPractical Primer for Clinical and Research Applications,” Radiology,\nvol. 310, no. 1, jan 1 2024.\n[55] N. Yildirim, H. Richardson, M. T. Wetscherek, J. Bajwa, J. Jacob,\nM. A. Pinnock, S. Harris, D. Coelho De Castro, S. Bannur, S. Hyland,\nP. Ghosh, M. Ranjit, K. Bouzid, A. Schwaighofer, F. P´erez-Garc´ıa,\nH. Sharma, O. Oktay, M. Lungren, J. Alvarez-Valle, A. Nori, and\nA. Thieme, “Multimodal Healthcare AI: Identifying and Designing\nClinically Relevant Vision-Language Applications for Radiology,” in\nProceedings of the CHI Conference on Human Factors in Computing\nSystems.\nACM, may 11 2024, pp. 1–22.\n[56] Wenhao Zheng, Dongsheng Peng, Hongxia Xu, Hongtu Zhu, Tianfan\nFu, and Huaxiu Yao, “Multimodal Clinical Trial Outcome Prediction\nwith Large Language Models,” arXiv.org, 2024.\n[57] Y. Park, S. Woo, S. Lee, M. A. Nugroho, and C. Kim, “Cross-modal\nalignment and translation for missing modality action recognition,”\nComputer Vision and Image Understanding, vol. 236, p. 103805, 2023.\n[58] S. Tripathi, K. Gabriel, P. K. Tripathi, and E. Kim, “Large language\nmodels reshaping molecular biology and drug development,” Chemical\nBiology & Drug Design, vol. 103, no. 6, 6 2024.\n[59] Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie,\n“Pmc-LLaMA: Towards Building Open-source Language Models for\nMedicine,” Journal of the American Medical Informatics Association,\n2023.\n[60] ——, “Pmc-LLaMA: Further Finetuning LLaMA on Medical Papers,”\narXiv.org, 2023.\n[61] C. Wu, W. Lin, X. Zhang, Y. Zhang, W. Xie, and Y. Wang, “Pmc-\nLLaMA: toward building open-source language models for medicine,”\nJournal of the American Medical Informatics Association, vol. 31,\nno. 9, pp. 1833–1843, apr 13 2024.\n[62] T. Tu, S. Azizi, D. Driess, M. Schaekermann, M. Amin, P.-C. Chang,\nA. Carroll, C. Lau, R. Tanno, I. Ktena et al., “Towards generalist\nbiomedical ai,” NEJM AI, vol. 1, no. 3, p. AIoa2300138, 2024.\n[63] Y. Zhu, Z. Wang, J. Gao, Y. Tong, J. An, W. Liao, E. M. Harrison,\nL. Ma, and C. Pan, “Prompting Large Language Models for Zero-\nShot Clinical Prediction with Structured Longitudinal Electronic Health\nRecord Data,” 2024.\n[64] Mingyu Jin, Qinkai Yu, Dong Shu, Chong Zhang, Lizhou Fan, Wenyue\nHua, Suiyuan Zhu, Yanda Meng, Zhenting Wang, Mengnan Du, and\nYongfeng Zhang, “Health-LLM: Personalized Retrieval-Augmented\nDisease Prediction System,” arXiv.org, 2024.\n[65] Y.-J. Park, A. Pillai, J. Deng, E. Guo, M. Gupta, M. Paget, and\nC. Naugler, “Assessing the research landscape and clinical utility of\nlarge language models: a scoping review,” BMC Medical Informatics\nand Decision Making, vol. 24, no. 1, mar 12 2024.\n[66] S. Schmidgall, R. Ziaei, C. Harris, E. Reis, J. Jopling, and M. Moor,\n“Agentclinic: a multimodal agent benchmark to evaluate AI in simu-\nlated clinical environments,” 2024.\n[67] Daniel McDuff, M. Schaekermann, Tao Tu, Anil Palepu, Amy Wang,\nJake Garrison, Karan Singhal, Yash Sharma, Shekoofeh Azizi, Kavita\nKulkarni, Le Hou, Yong Cheng, Yun Liu, S. Mahdavi, Sushant Prakash,\nAnupam Pathak, Christopher Semturs, Shwetak Patel, D. Webster,\nEwa Dominowska, Juraj Gottweis, Joelle Barral, Katherine Chou, G.\nCorrado, Yossi Matias, Jacob Sunshine, A. Karthikesalingam, and\nVivek Natarajan, “Towards Accurate Differential Diagnosis with Large\nLanguage Models,” arXiv.org, 2023.\n[68] Junda Wang, Zhichao Yang, Zonghai Yao, and Hong Yu, “Jmlr: Joint\nMedical LLM and Retrieval Training for Enhancing Reasoning and\nProfessional Question Answering Capability,” arXiv.org, 2024.\n[69] Kilian Carolan, Laura Fennelly, and A. Smeaton, “A Review of Multi-\nModal Large Language and Vision Models,” arXiv.org, 2024.\n[70] Amin Dada, Marie Bauer, Amanda Butler Contreras, Osman Alperen\nKoras, C. Seibold, Kaleb E. Smith, and Jens Kleesiek, “Clue: A Clinical\nLanguage Understanding Evaluation for LLMs,” arXiv.org, 2024.\n[71] F. Liu, H. Zhou, Y. Hua, O. Rohanian, A. Thakur, L. Clifton, and D. A.\nClifton, “Large Language Models in the Clinic: A Comprehensive\nBenchmark,” apr 25 2024.\n\n[72] Congyun Jin, Ming Zhang, Xiaowei Ma, Yujiao Li, Yingbo Wang, Yabo\nJia, Yuliang Du, Tao Sun, Haowen Wang, Cong Fan, Jinjie Gu, Chenfei\nChi, Xiangguo Lv, Fangzhou Li, Wei Xue, and Yiran Huang, “Rjua-\nMedDQA: A Multimodal Benchmark for Medical Document Question\nAnswering and Clinical Reasoning,” arXiv.org, 2024.\n[73] N. Mehandru, B. Y. Miao, E. R. Almaraz, M. Sushil, A. J. Butte, and\nA. Alaa, “Evaluating large language models as agents in the clinic,”\nnpj Digital Medicine, vol. 7, no. 1, apr 3 2024.\n[74] A. Mihalache, R. S. Huang, D. Mikhail, M. M. Popovic, R. Shor,\nA. Pereira, J. Kwok, P. Yan, D. T. Wong, P. J. Kertes et al., “Interpre-\ntation of clinical retinal images using an artiﬁcial intelligence chatbot,”\nOphthalmology Science, p. 100556, 2024.\n[75] A. Sharma, A. Saxena, A. Kumar, and D. Singh, “Depression detection\nusing multimodal analysis with chatbot support,” in 2024 2nd Interna-\ntional Conference on Disruptive Technologies (ICDT).\nIEEE, 2024,\npp. 328–334.\n[76] Franc¸ois Remy, Kris Demuynck, and Thomas Demeester, “Biolord-\n2023: Semantic Textual Representations Fusing LLM and Clinical\nKnowledge Graph Insights,” arXiv.org, 2023.\n[77] Q. Niu, J. Liu, Z. Bi, P. Feng, B. Peng, and K. Chen, “Large language\nmodels and cognitive science: A comprehensive review of similarities,\ndifferences, and challenges,” arXiv preprint arXiv:2409.02387, 2024.\n[78] B. Steurer, Q. Vanhaelen, and A. Zhavoronkov, “Multimodal trans-\nformers and their applications in drug target discovery for aging and\nage-related diseases,” The Journals of Gerontology: Series A, vol. 79,\nno. 9, 2024.\n[79] Ayo Adedeji, Sarita Joshi, and Brendan Doohan, “The Sound of\nHealthcare: Improving Medical Transcription ASR Accuracy with\nLarge Language Models,” arXiv.org, 2024.\n[80] Y. Artsi, V. Sorin, E. Konen, B. S. Glicksberg, G. Nadkarni, and\nE. Klang, “Large language models in simplifying radiological reports:\nsystematic review,” jan 9 2024.\n[81] B. Boecking, N. Usuyama, S. Bannur, D. C. Castro, A. Schwaighofer,\nS. Hyland, M. Wetscherek, T. Naumann, A. Nori, J. Alvarez-Valle,\nH. Poon, and O. Oktay, Making the Most of Text Semantics to\nImprove Biomedical Vision–Language Processing.\nSpringer Nature\nSwitzerland, 2022, pp. 1–21.\n[82] Sheng Zhang, Yanbo Xu, Naoto Usuyama, J. Bagga, Robert Tinn,\nSam Preston, Rajesh N. Rao, Mu-Hsin Wei, Naveen Valluri, Cliff\nWong, M. Lungren, Tristan Naumann, and Hoifung Poon, “Biomedclip:\na multimodal biomedical foundation model pretrained from ﬁfteen\nmillion scientiﬁc image-text pairs,” 2023.\n[83] S. Schmidgall, C. Harris, I. Essien, D. Olshvang, T. Rahman, J. W.\nKim, R. Ziaei, J. Eshraghian, P. Abadir, and R. Chellappa, “Addressing\ncognitive bias in medical language models,” 2024.\n[84] Y. Jin, M. Chandra, G. Verma, Y. Hu, M. De Choudhury, and S. Kumar,\n“Better to Ask in English: Cross-Lingual Evaluation of Large Language\nModels for Healthcare Queries,” in Proceedings of the ACM Web\nConference 2024, vol. 35.\nACM, may 13 2024, pp. 2627–2638.\n[85] P. Qiu, C. Wu, X. Zhang, W. Lin, H. Wang, Y. Zhang, Y. Wang,\nand W. Xie, “Towards Building Multilingual Language Model for\nMedicine,” 2024.\n[86] Y. Khare, V. Bagal, M. Mathew, A. Devi, U. D. Priyakumar, and\nC. Jawahar, “Mmbert: Multimodal BERT Pretraining for Improved\nMedical VQA,” in 2021 IEEE 18th International Symposium on\nBiomedical Imaging (ISBI).\nIEEE, apr 13 2021.\n[87] N. H. Shah, D. Entwistle, and M. A. Pfeffer, “Creation and Adoption\nof Large Language Models in Medicine,” JAMA, vol. 330, no. 9, p.\n866, sep 5 2023.\n[88] K. He, R. Mao, Q. Lin, Y. Ruan, X. Lan, M. Feng, and E. Cambria,\n“A Survey of Large Language Models for Healthcare: from Data,\nTechnology, and Applications to Accountability and Ethics,” 2023.\n[89] J. Clusmann, F. R. Kolbinger, H. S. Muti, Z. I. Carrero, J.-N. Eckardt,\nN. G. Laleh, C. M. L. L¨ofﬂer, S.-C. Schwarzkopf, M. Unger, G. P.\nVeldhuizen, S. J. Wagner, and J. N. Kather, “The future landscape of\nlarge language models in medicine,” Communications Medicine, vol. 3,\nno. 1, oct 10 2023.\n[90] A. M. Bean, K. Korgul, F. Krones, R. McCraith, and A. Mahdi,\n“Exploring the landscape of large language models in medical question\nanswering,” 2023.\n[91] Francois Barnard, Marlize Van Sittert, and Siri J. Rambhatla, “Self-\nDiagnosis and Large Language Models: A New Front for Medical\nMisinformation,” arXiv.org, 2023.\n[92] D. Umerenkov, Galina Zubkova, and A. Nesterov, “Deciphering Diag-\nnoses: How Large Language Models Explanations Inﬂuence Clinical\nDecision Making,” arXiv.org, 2023.\n[93] E. Malek, G.-M. Wang, A. Madabhushi, J. Cullen, C. Tatsuoka, and J. J.\nDriscoll, II, “Toward AI-Assisted Clinical Assessment for Patients with\nMultiple Myeloma: Feature Selection for Large Language Models,”\nBlood, vol. 142, no. Supplement 1, pp. 2328–2328, nov 2 2023.\n[94] R. Armitage, “Large language models must serve clinicians, not the\nreverse,” The Lancet Infectious Diseases, vol. 24, no. 5, pp. 453–454,\n5 2024.\n[95] G. Briganti, “A clinician’s guide to large language models,” Future\nMedicine AI, aug 17 2023.\n[96] Logesh Kumar Umapathi, Ankit Pal, and Malaikannan Sankarasubbu,\n“Med-HALT: Medical Domain Hallucination Test for Large Language\nModels,” Conference on Computational Natural Language Learning,\n2023.\n[97] Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu\nLi, “Clinicalgpt: Large Language Models Finetuned with Diverse\nMedical Data and Comprehensive Evaluation,” arXiv.org, 2023.\n[98] L. Luo, J. Ning, Y. Zhao, Z. Wang, Z. Ding, P. Chen, W. Fu, Q. Han,\nG. Xu, Y. Qiu, D. Pan, J. Li, H. Li, W. Feng, S. Tu, Y. Liu, Z. Yang,\nJ. Wang, Y. Sun, and H. Lin, “Taiyi: a bilingual ﬁne-tuned large\nlanguage model for diverse biomedical tasks,” Journal of the American\nMedical Informatics Association, vol. 31, no. 9, pp. 1865–1874, feb 29\n2024.\n[99] T. Grote and P. Berens, “A paradigm shift?—On the ethics of medical\nlarge language models,” Bioethics, vol. 38, no. 5, pp. 383–390, mar 25\n2024.\n[100] H. Huang, O. Zheng, D. Wang, J. Yin, Z. Wang, S. Ding, H. Yin,\nC. Xu, R. Yang, Q. Zheng, and B. Shi, “Chatgpt for shaping the\nfuture of dentistry: the potential of multi-modal large language model,”\nInternational Journal of Oral Science, vol. 15, no. 1, jul 28 2023.\n[101] M. Hu, J. Qian, S. Pan, Y. Li, R. L. J. Qiu, and X. Yang, “Advancing\nmedical imaging with language models: featuring a spotlight on Chat-\nGPT,” Physics in Medicine & Biology, vol. 69, no. 10, p. 10TR01, may\n3 2024.\n[102] A. Youssef, S. Stein, J. Clapp, and D. Magnus, “The Importance of\nUnderstanding Language in Large Language Models,” The American\nJournal of Bioethics, vol. 23, no. 10, pp. 6–7, oct 3 2023.\n[103] Jun-En Ding, Phan Nguyen Minh Thao, Wen-Chih Peng, Jian-Zhe\nWang, Chun-Cheng Chug, Min-Chen Hsieh, Yun-Chien Tseng, Ling\nChen, Dongsheng Luo, Chi-Te Wang, Pei-fu Chen, Feng Liu, and Fang-\nMing Hung, “Large Language Multimodal Models for 5-Year Chronic\nDisease Cohort Prediction Using EHR Data,” arXiv.org, 2024.\n[104] E. Alsentzer, M. J. Rasmussen, R. Fontoura, A. L. Cull, B. Beaulieu-\nJones, K. J. Gray, D. W. Bates, and V. P. Kovacheva, “Zero-shot\nInterpretable Phenotyping of Postpartum Hemorrhage Using Large\nLanguage Models,” jun 1 2023.\n[105] Aleksa Bisercic, Mladen Nikolic, M. Schaar, Boris Delibasic, P. Lio’,\nand A. Petrovi´c, “Interpretable Medical Diagnostics with Structured\nData Extraction by Large Language Models,” arXiv.org, 2023.\n[106] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian\nLiu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng\nGao, “Llava-Med: Training a Large Language-and-Vision Assistant for\nBiomedicine in One Day,” Neural Information Processing Systems,\n2023.\n[107] Z. Bi, S. A. Dip, D. Hajialigol, S. Kommu, H. Liu, M. Lu, and X. Wang,\n“Ai for Biomedicine in the Era of Large Language Models,” 2024.\n[108] Dyke Ferber, O. S. E. Nahhas, Georg W¨olﬂein, Isabella C. Wiest, J.\nClusmann, Marie-Elisabeth Lessman, S. Foersch, Jacqueline Lammert,\nMaximilian Tschochohei, Dirk J¨ager, Manuel Salto-Tellez, Nikolaus\nSchultz, Daniel Truhn, and J. N. Kather, “Autonomous Artiﬁcial Intel-\nligence Agents for Clinical Decision Making in Oncology,” arXiv.org,\n2024.\n[109] Z. Liu, A. Zhong, Y. Li, L. Yang, C. Ju, Z. Wu, C. Ma, P. Shu, C. Chen,\nS. Kim, H. Dai, L. Zhao, L. Sun, D. Zhu, J. Liu, W. Liu, D. Shen,\nX. Li, Q. Li, and T. Liu, “Radiology-GPT: A Large Language Model\nfor Radiology,” 2023.\n[110] Q. Xie, Q. Chen, A. Chen, C. Peng, Y. Hu, F. Lin, X. Peng, J. Huang,\nJ. Zhang, V. Keloth, X. Zhou, H. He, L. Ohno-Machado, Y. Wu, H. Xu,\nand J. Bian, “Me-LLaMA: Foundation Large Language Models for\nMedical Applications,” may 22 2024.\n[111] J. B. Longwell, I. Hirsch, F. Binder, G. A. Gonzalez Conchas, D. Mau,\nR. Jang, R. G. Krishnan, and R. C. Grant, “Performance of Large\n\nLanguage Models on Medical Oncology Examination Questions,”\nJAMA Network Open, vol. 7, no. 6, p. e2417641, jun 18 2024.\n[112] Meiqi Chen, Yixin Cao, Yan Zhang, and Chaochao Lu, “Quantifying\nand Mitigating Unimodal Biases in Multimodal Large Language Mod-\nels: A Causal Perspective,” arXiv.org, 2024.\n[113] Y. Huang, K. Tang, M. Chen, and B. Wang, “A Comprehensive Survey\non Evaluating Large Language Model Applications in the Medical\nIndustry,” 2024.",
    "pdf_filename": "From_Text_to_Multimodality_Exploring_the_Evolution_and_Impact_of_Large_Language_Models_in_Medical_Pr.pdf"
}