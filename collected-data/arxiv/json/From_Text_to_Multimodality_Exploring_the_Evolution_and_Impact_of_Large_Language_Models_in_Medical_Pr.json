{
    "title": "From Text to Multimodality: Exploring the",
    "abstract": "evolved from text-based systems to multimodal platforms, sig- addressingthischallenge,withlargelanguagemodels(LLMs) nificantly impacting various sectors including healthcare. This at the forefront of this revolution. comprehensive review explores the progression of LLMs to Initially, LLMs focused primarily on text-based tasks, MultimodalLargeLanguageModels(MLLMs)andtheirgrowing influenceinmedicalpractice.Weexaminethecurrentlandscape demonstrating remarkable proficiency in understanding and of MLLMs in healthcare, analyzing their applications across generating human-like language [2]. However, the inherent clinical decision support, medical imaging, patient engagement, multimodalityofmedicine,whereclinicaldecisionsoftenrely and research. The review highlights the unique capabilities on the synthesis of information from diverse sources such of MLLMs in integrating diverse data types, such as text, as images, text, and genomics, necessitates more versatile images, and audio, to provide more comprehensive insights into patient health. We also address the challenges facing MLLM models [3]. This need has given rise to Multimodal Large implementation, including data limitations, technical hurdles, Language Models (MLLMs), a new generation of LLMs andethicalconsiderations.Byidentifyingkeyresearchgaps,this capableofprocessingandintegratinginformationfromvarious paperaimstoguidefutureinvestigationsinareassuchasdataset modalities. These advanced models potentially unlock a new development,modalityalignmentmethods,andtheestablishment eraofprecisionmedicineandpersonalizedhealthcare,offering of ethical guidelines. As MLLMs continue to shape the future of healthcare, understanding their potential and limitations is a more comprehensive approach to medical data analysis and crucialfortheirresponsibleandeffectiveintegrationintomedical decision-making. practice. A key strength of MLLMs is their ability to bridge the IndexTerms—MultimodalLargeLanguageModels(MLLMs), gap between unstructured and structured data, a particularly MedicalImaging,ClinicalDecisionSupport,PatientEngagement, valuable feature in healthcare where information is often Data Integration fragmentedacrossdifferentformats.Forexample,theREALM framework leverages LLMs to encode clinical notes and in- I. INTRODUCTION tegrates them with time-series EHR data, enhancing clinical The landscape of healthcare is constantly evolving, driven predictions by incorporating external knowledge from knowl- by an unprecedented explosion of data. Electronic health edge graphs [4]. In a similar vein, the MedDr model [5] records, medical imaging, genomic sequencing, and wearable employs a diagnosis-guided bootstrapping strategy to build sensors generate an overwhelming amount of information, vision-language datasets, showcasing superior performance exceeding human capacity for efficient analysis and inter- across various medical tasks through a retrieval-augmented pretation [1]. This phenomenon presents both an opportunity diagnosis approach. These advancements underscore the po- and a challenge: ingesting this information can revolutionize tentialofMLLMsto enhancedata interoperabilityandextract 4202 voN 91 ]YC.sc[ 4v21810.0142:viXra",
    "body": "From Text to Multimodality: Exploring the\nEvolution and Impact of Large Language Models in\nMedical Practice\nQian Niu1, Keyu Chen2, Ming Li2, Pohsun Feng3, Ziqian Bi4, Lawrence KQ Yan5, Yichao Zhang6,\nCaitlyn Heqi Yin7, Cheng Fei8, Junyu Liu1, Tianyang Wang9, Yunze Wang10, Silin Chen11, Benji Peng*,2\n1Kyoto University\n2Georgia Institute of Technology\n3National Taiwan Normal University\n4Indiana University\n5Hong Kong University of Science and Technology\n6The University of Texas at Dallas\n7University of Wisconsin-Madison\n8Cornell University\n9University of Liverpool\n10University of Edinburgh\n11Zhejiang University\n*Corresponding Email: benji@appcubic.com\nIndex Terms—large language models, medical practice, multi- healthcare, but doing so requires innovative tools capable\nmodality, artificial intelligence of processing and synthesizing these diverse data streams.\nAbstract—Large Language Models (LLMs) have rapidly Artificialintelligence(AI)hasemergedasa powerfulforcein\nevolved from text-based systems to multimodal platforms, sig- addressingthischallenge,withlargelanguagemodels(LLMs)\nnificantly impacting various sectors including healthcare. This\nat the forefront of this revolution.\ncomprehensive review explores the progression of LLMs to\nInitially, LLMs focused primarily on text-based tasks,\nMultimodalLargeLanguageModels(MLLMs)andtheirgrowing\ninfluenceinmedicalpractice.Weexaminethecurrentlandscape demonstrating remarkable proficiency in understanding and\nof MLLMs in healthcare, analyzing their applications across generating human-like language [2]. However, the inherent\nclinical decision support, medical imaging, patient engagement, multimodalityofmedicine,whereclinicaldecisionsoftenrely\nand research. The review highlights the unique capabilities\non the synthesis of information from diverse sources such\nof MLLMs in integrating diverse data types, such as text,\nas images, text, and genomics, necessitates more versatile\nimages, and audio, to provide more comprehensive insights into\npatient health. We also address the challenges facing MLLM models [3]. This need has given rise to Multimodal Large\nimplementation, including data limitations, technical hurdles, Language Models (MLLMs), a new generation of LLMs\nandethicalconsiderations.Byidentifyingkeyresearchgaps,this capableofprocessingandintegratinginformationfromvarious\npaperaimstoguidefutureinvestigationsinareassuchasdataset\nmodalities. These advanced models potentially unlock a new\ndevelopment,modalityalignmentmethods,andtheestablishment\neraofprecisionmedicineandpersonalizedhealthcare,offering\nof ethical guidelines. As MLLMs continue to shape the future\nof healthcare, understanding their potential and limitations is a more comprehensive approach to medical data analysis and\ncrucialfortheirresponsibleandeffectiveintegrationintomedical decision-making.\npractice. A key strength of MLLMs is their ability to bridge the\nIndexTerms—MultimodalLargeLanguageModels(MLLMs),\ngap between unstructured and structured data, a particularly\nMedicalImaging,ClinicalDecisionSupport,PatientEngagement,\nvaluable feature in healthcare where information is often\nData Integration\nfragmentedacrossdifferentformats.Forexample,theREALM\nframework leverages LLMs to encode clinical notes and in-\nI. INTRODUCTION\ntegrates them with time-series EHR data, enhancing clinical\nThe landscape of healthcare is constantly evolving, driven predictions by incorporating external knowledge from knowl-\nby an unprecedented explosion of data. Electronic health edge graphs [4]. In a similar vein, the MedDr model [5]\nrecords, medical imaging, genomic sequencing, and wearable employs a diagnosis-guided bootstrapping strategy to build\nsensors generate an overwhelming amount of information, vision-language datasets, showcasing superior performance\nexceeding human capacity for efficient analysis and inter- across various medical tasks through a retrieval-augmented\npretation [1]. This phenomenon presents both an opportunity diagnosis approach. These advancements underscore the po-\nand a challenge: ingesting this information can revolutionize tentialofMLLMsto enhancedata interoperabilityandextract\n4202\nvoN\n91\n]YC.sc[\n4v21810.0142:viXra\nmeaningful insights from diverse sources, potentially revo- II. THE RISE OF MULTIMODALLARGE LANGUAGE\nlutionizing how healthcare professionals access and utilize MODELSIN MEDICINE\npatient information.\nA. LLMs and Their Evolution: From Text to Multimodal\nMLLMs show great potential for transforming healthcare\nUnderstanding\nby enabling a more comprehensive understanding of patient\nhealth, potentially leading to improved diagnostics, personal- Large language models (LLMs) represent a significant ad-\nized treatment plans, and enhanced patient engagement [6]. vancementin artificial intelligence, demonstrating remarkable\nFor instance, these models could analyze a patient’s medical capabilitiesincomprehendingandgeneratinghuman-liketext.\nhistory, imaging scans, and genetic data to provide more Architecturally, they often rely on the Transformer network\naccurate diagnoses and predict disease risks, facilitating early [36], a powerful neural network structure that excels at cap-\nintervention and tailored treatment strategies. In the field of turing long-range dependencies and contextual relationships\nmedical imaging, the integration of LLMs has demonstrated withintext.LLMsareinitiallytrainedonmassivetextcorpora,\nsignificant progress. Research has shown the effectiveness of a process known as pre-training, to develop a generalized\nvisual languagemodels(VLMs), a subset of MLLMs, in ana- understanding of language structure and patterns. This pre-\nlyzingvariousbiomedicalimages,includingbrainMRIs,blood training phase allows them to learn a wide range of linguistic\ncell images, and chest X-rays [7]. A notable example is the features and relationships, making them adaptable to various\nLlaVA-Rad model, a lightweightand open-sourcemultimodal downstream tasks.\nsystem that has achieved state-of-the-art results on standard LLMs can be fine-tuned on smaller, task-specific datasets\nradiology tasks. This model has surpassed larger counterparts to further refine their performance in specific domains. For\nin both performance and accessibility, making it particularly example,ClinicalT5[37]demonstrateshowageneral-purpose\nsuitable for real-world clinical applications [6]. LLM(T5)canbe adaptedforclinicaltextbyfine-tuningiton\nMLLMs could also enhance communication between pa- theMIMIC-IIIdataset.Thisadaptationto themedicaldomain\ntientsandhealthcareprovidersthroughinteractivechatbotsand is crucial for addressing the unique challenges of medical\nvirtual assistants, potentially improving patient engagement language, including its specialized vocabulary and complex\nand healthcare accessibility [8]. The creation of chatbots semantic relationships [38].\nlike MedAide, which utilize optimized tiny-LLMs on edge Despiteimpressivecapabilities,LLMsmayfacemanylimi-\ndevices, demonstrates the capacity of MLLMs to provide tations. One notableissue is ”hallucination”,wherethe model\nmedical assistance in resource-limited settings and remote generates plausible but incorrect or nonsensical information,\nareas,addressingchallengesinhealthcareaccess[9].However, as highlighted in the study by Ziaei and Schmidgall [39].\ndeveloping reliable and trustworthy medical chatbots requires Hallucination can be particularly problematic in healthcare,\naddressingcriticalissues suchas accuracy,privacyprotection, whereaccuracyandreliabilityarethe toppriorities[28], [40].\nand bias mitigation to meet the high standards required for Additionally,biases presentin the trainingdata can propagate\npatient care and safety. to the model’s outputs, leading to unfair or discriminatory\nOur review aims to offer an overview of the current state outcomes,asdiscussedinthepaperbyReddy[41].Addressing\nof MLLMs in medicine and healthcare. We will not only thesebiasesrequirescarefuldatacurationandmodeldevelop-\nexamine their architecture, capabilities, and limitations, but ment strategies [42].\nalso explore potential applications across various medical Integrating LLMs with other modalities, such as images\ndomains.We will critically assess the challengesand research and videos, results in MLLMs. MLLMs like GPT-4V [43],\ngapsimpedingthewidespreadadoptionofMLLMsinclinical [44] and Gemini [45], [46] process and generate both text\nsettings, including data limitations, technical difficulties, and and visual information, which opens up new possibilities for\nethical considerations [10]. For example, the evaluation of medical applications. For example, MLLMs can be used to\nLLMsinhealthcareoftenreliesonbenchmarksthatareusually generatecaptionsformedicalimages[47],answervisualques-\nunfit for real-world diagnostic frameworks and are likely tions about medical images [48], and even assist in medical\nvulnerable to data leakage [11], which indicates the need reportgeneration[49]. On the otherhand,MLLMsare still in\nfor standardized evaluation frameworks and comprehensive their early stages, and these models often face challenges in\ndatasetsthataccuratelyreflecttheclinicalpractice.Byanalyz- terms of accuracy, reliability, and ethical considerations [50].\ningthecurrentresearchlandscapeandidentifyingkeyareasfor Further research is needed to fully explore the potential of\nfurtherdevelopment,thisreviewseekstoguidetheresponsible MLLMsand addressthese challengesto enabletheir safe and\nand effective integration of MLLMs into healthcare. Our effective deployment in clinical practice.\ngoal is to contribute to a brighter future where AI assists\nB. Multimodality in Medicine: Embracingthe Rich Variety of\nclinicians and enhances patient care, while addressing the\nData\nunique challenges and requirements within the field. In order\nto provide a clear overview of the various applications and Medicine is inherently multimodal, as it involves many\ncomponents of MLLMs in medicine, we present a taxonomy types of information beyond just written text. For example,\nFig 1. This simplified taxonomy categorizes the key aspects when a patient comes in with a possible lung infection, their\nof MLLMs in healthcare and medicine. case might include several kinds of data: written information\nImprovementsinmodality\nalignmentandgeneralization\nKeyResearch Ethicalguidelinesfor\nGaps multimodalAIsystems\nDatasetstandardization\nEthicsandCompliance Regulatoryframeworksspecific\ntoMLLMs[35]\nAdvancementsin Methodsforcross-modality\nFutureDirections ModalityAlignment datarepresentation[34]\nPrivacy-preserving\ndatasharing[33]\nDataAugmentationand\nMultilingualSupport\nDevelopmentoflarge\nmultilingualdatasets[32]\nOvercomingthe\n”blackbox”nature[31]\nModelInterpretabilityand\nExplainability\nTrustandtransparencyin\nclinicaldecisions[3]\nBiasandfairnessin\nChallengesand clinicaloutcomes[10],[13],[30]\nLimitations EthicalandRegulatory\nConsiderations\nPrivacy&datasecurity[29]\nBiasesintrainingdata[28]\nLLMsandMLLMs\nDataScarcityandQuality\ninMedicine\nLimitedlarge-scale\nmultimodaldatasets[22]\nGraph-basedmethods[26],[27]\nKnowledgeIntegration\nFormatunification[24],[25]\nData-DrivenMethods:Using\nTechnicalAspects largedatasets[22],[23]\nToolsAssistance:Knowledge\ngraphs[20],[21]\nModalityAlignment\nMethods\nMultimodalPerceivers:\nVisiontransformers[15]\nMultimodalConverters:\nImagestotext[19]\nPatienteducation[18]\nPersonalizedhealth\nPatientEngagementand\nrecommendations[17]\nCommunication\nChatbots&virtualassistants[9]\nReportgenerationand\nVQA[15],[16]\nApplicationsin MedicalImaging\nMedicine\nIntegrationofvisualand\ntextualdata[14]\nPrognosticpredictionand\nriskstratification[13]\nClinicalDecisionSupport\nDiagnosisandtreatment\nrecommendations[1],[12]\nFig.1. SimplifiedTaxonomyofMLLMsinMedicine\nlike their medical history and symptoms noted by doctors, a LLM as a learnable orchestrator to process both visual\nimagesfromchestX-rays,soundrecordingsoftheirbreathing, and linguistic information to interpret medical images.\nand even genetic information to assess their personal risk. • Tools Assistance: These methods uses external tools for\nCombining these different types of information is important multimodalities. A knowledge graph can link concepts\nfor getting a complete picture of a patient’s health and more across modalities and provide additional context for the\naccurate and personalized medical care [51]. This is where LLM. The study by Gao et al. [20] uses the Unified\nmultimodalmodelsshine,becausetheyaredesignedtoprocess Medical Language System (UMLS) knowledge to en-\nand integrate various types of data. hance diagnosis generation. A similar approach is used\nWe have seen a surge in developing MLLMs capable of in BioLORD-2023 [21], which integrates LLMs with\nprocessingandintegratingdiversemedicaldatatypes[52].The knowledge graphs to improve performance in semantic\nstudy by Tian et al. [53] exemplifies this trend, showcasing textualsimilarity, biomedicalconceptrepresentation,and\na Med-MLLM model that handles both visual and textual named entity linking.\ndataforimprovedclinicaldecision-making,particularlyinrare • Data-Driven Methods: These methods rely on large-\ndiseases and pandemics. MLLMs could revolutionize various scale multimodal datasets to train LLMs directly on\nmedical practices. For instance, in radiology, MLLMs are multimodal tasks and often involves developing new\nbeing explored for generating comprehensive reports [54], architectures and training strategies so the modals can\nassisting in diagnosis by analyzing both images and clinical learn from different modalities simultaneously. Models\nnotes [4], and facilitating visual search and querying within like BiomedGPT [23] are trained on those diverse mul-\npatient imaging history [55]. timodal datasets. The recent open-source frameworks\nMLLMsformorespecializedmedicaltaskshasalsogained like Hippocrates [22] further facilitates this approach\nmomentum. SkinGPT-4 is a system designed for dermato- by providing access to training datasets, codebases, and\nlogical diagnosis using both images and clinical data, which evaluation protocols, encouraging further collaborative\noffersautonomousimageevaluationandtreatmentrecommen- efforts.\ndations[16]. Developingrobustand reliable MLLMs requires Each method has its own strengths and weaknesses. Mul-\novercoming many challenges. Large, diverse, and unbiased timodal converters are relatively simple but may lead to in-\nmedical datasets across multiple modalities are crucial [48]. formation loss during conversion [57]. Multimodal perceivers\nAccuracy, interpretability, explainability, interoperability, and canpotentiallycapturericherrelationshipsbetweenmodalities,\nethics are important to be discussed before integrating into but requires more complex architectures and training. Tools\nexisting clinical workflows [35]. assistance uses existing knowledge bases and resources but\nmaynotbecomprehensiveorup-to-date.Data-drivenmethods\nC. Modality Alignment Methods: Bridging the Semantic Gap can achieve high performance but require large and diverse\ndatasets.\nIntegrating different data types into LLMs is challenging,\nmainly because of differences in how each type represents III. APPLICATIONS OF MLLMSIN MEDICINE\ninformation. Aligning these modalities is essential for LLMs A. A. Clinical Decision Support\nto process and reason over multimodal data. Researchers are\nWhile MLLMs integrate diverse data modalities, offering\ncurrently exploring several methods for addressing this issue,\na more comprehensive view of patient health and the ability\nwhich can be grouped into four main categories.\nto detect complex patterns for improved diagnosis, treatment\n• Multimodal Converters: These methods transform data personalization, and risk assessment [58], their development\nfromdifferentmodalitiesintoaunifiedrepresentationthat is still in the early stages. As a result, LLMs continue\nLLMs can understand. For example, images might be to dominate the field due to their maturity and established\nconvertedinto textual descriptions or embeddingsbefore performance.ThissectionintroducesbothLLMsandMLLMs,\nbeingfedintothe LLM.Thisapproachisseen inmodels while emphasizing the promise of multimodal models.\nlike X-LLM [19], which treats modalities as foreignlan- Diagnosis and Treatment Recommendations: NYUTron\nguagesandconvertsthemtotext,orLIFTED[56],which is an LLM trained on clinical notes, for predicting patient\ntransforms modalities into natural language descriptions outcomes with high accuracy [1]. PMC-LLaMA is a perfor-\nfor improved clinical trial outcome prediction. mant LLM for medical Q&A [59]–[61]. Almanac is an LLM\n• MultimodalPerceivers:Thesemethodsdirectlyenhance augmented with retrieval capabilities from curated medical\nthe LLMs’ perception of multimodal data. A vision resourcesandhassignificantimprovementsinfactuality,com-\nencoder can be integrated into the LLM architecture to pleteness, user preference, and safety for clinical decision-\nenable it to directly process and understand images and making[12].Med-PaLM2isaspecializedLLMformedicine,\ntexts. Med-Flamingo [15] incorporates a vision trans- showcased superior performance on medical question an-\nformer for medical image understanding. Similar ap- swering and treatment recommendation tasks, significantly\nproaches can be seen in models like SkinGPT-4 [16], outperformingGPT-3.5[2].Med-PaLMMisaMLLMachiev-\nwhich combines a vision transformer with a LLM for ing competitive performance on medical question answering,\ndermatologicaldiagnosis,andMedVersa[34],whichuses radiology report generation, etc. [62].\nPrognostic Prediction and Risk Stratification: Beyond with textual information such as radiology reports, clinical\ndiagnosis, LLMs have also shown promise in prognostic notes, and patienthistory.Thisintegrationof multimodaldata\npredictionandriskstratification.Researchershavetriedtouse allows for a more holistic and nuanced understanding of a\nLLMs for prognostic prediction in immunotherapy,achieving patient’s condition. Yildirim et al. demonstrate the value of\nencouraging results in improving accuracy and facilitating thisapproachinradiology,arguingthatintegratingmultimodal\nearly disease detection [13]. Studies have demonstrated the data can lead to a more comprehensive patient assessment\npotential of LLMs and MLLMs to predict outcomes like [55]. MLLMs can automate the generation of radiology re-\nmortality, length of stay, and readmission using structured ports, potentially improving efficiency and accuracy while\nEHR data,outperformingtraditionalmachinelearningmodels reducing radiologists’ workload [54]. MLLMs also facilitate\nin few-shot settings. [26], [63] The Health-LLM, a LLM visual questionanswering, enablingclinicians to interactwith\nframework that has vision capability in the future integrating medical images by asking specific questions and receiving\nhealth reports and medical knowledge into LLMs, has also relevant information from the model [73].\nbeen proposed for enhanced disease prediction and personal- Despite advantages, several limitations hinder the adoption\nizedhealthmanagement,showcasingits superiorperformance of MLLMs in medical imaging. One major challenge is the\nover existing systems [64]. reliance on high-quality, labeled data. Chen et al. address\nDespite the potentials, LLM and MLLMs face limitations this issue in their work on the MISS framework, proposing\nin clinical decision support. Explainability and interpretabil- solutions for leveraging limited datasets [14]. Interpreting\nity remain challenging, as their complex decision-making complex medical images may requires specialized knowledge\nprocesses often lack transparency, hindering clinician trust that current MLLMs do not fully possess. Mehandru et al.\nand understanding [65]. Another concern is the potential stress the need for high-fidelity simulations to accurately\nfor bias and unfairness due to inherent biases in MLLM assess LLM performance in these complex scenarios [73].\ntrainingdata,whichcanexacerbatehealthcaredisparities[66]. Ethics about fairness in image interpretation is also crucial,\nExtensive real-world validation in diverse clinical settings is as these models can perpetuate existing healthcare disparities\ncrucial to ensure the effectiveness and safety of MLLMs if notcarefullydesignedand evaluated.Yildirim etal. discuss\nbefore widespread adoption, addressing potential risks and theseconsiderationsindetail,focusingondesignrequirements\nunexpected outcomes [35]. for ethical AI use in radiology [55].\nSeveral real-world case studies have demonstrated the po-\ntentialofLLMsinclinicaldecisionsupport.Onestudyshowed C. Patient Engagement and Communication\nthatanLLMoptimizedfordiagnosticreasoningimprovedclin-\nicians’ differentialdiagnosis accuracyon challengingmedical MLLMs has changed patient engagement and communica-\ncases[67].AnotherstudyfoundthatanLLMcouldaccurately tioninhealthcare.Byintegratingvisualandtextualmodalities,\nclassify patient acuity levels in the emergency department, MLLMs can create more personalized and interactive expe-\ncomparable to human physicians [31]. riences, enhance patient education, facilitate communication,\nThe performance of LLMs in clinical decision support and provide tailored health recommendations.\nis often evaluated using traditional metrics like accuracy, ChatbotsandVirtualAssistants:Oneofthemostpromis-\nprecision, recall, F1 score, and AUC [68]. Evaluating their ing applicationsof MLLMs in patientengagementis chatbots\neffectiveness in this context requires moving beyond accu- and virtual assistants. Traditional chatbots often rely on rule-\nracy and considering additional factors like interpretability, based systems or simple ML models, with limited ability to\nfairness, impact on clinical workflows, and user trust [69]. understand complex queries and provide nuanced responses.\nThe development of standardized evaluation frameworks and MLLMs, however, can understand both text and images to\nbenchmarks, such as CLUE and BenchHealth, is crucial for create more natural and engaging conversations and result in\nassessingtheclinicalperformanceandreal-worldapplicability improved patient experiences [26], [74], [75].\nof LLMs [70]–[72]. PersonalizedHealthRecommendations:MLLMscanalso\nbe used to generate personalized health recommendations by\nB. Medical Imaging analyzingpatientdata and medicalknowledge.By integrating\nMLLMs are rapidly transforming medical imaging by of- informationfrom electronic health records, medical literature,\nfering potential for significant improvements in diagnosis, and even patient-provided images, MLLMs provide tailored\ntreatmentplanning,andpatientcare.Thesemodels,capableof advice on lifestyle changes, medication adherence, etc [17].\nprocessingandinterpretingbothtextualandvisualdata,allow Patient Education: Educating patients improves health\nforamorecomprehensiveunderstandingofpatientconditions. outcomes,buttraditionalmethodsoftenrelyonstaticmaterials\nThe MISS framework, proposed by Chen et al., treats med- that may be difficult to understand or hard to be tailored\nical Visual Question Answering (VQA) as a generative task, towards individualneeds. MLLMs generates personalized ed-\nachieving excellent results with fewer multimodal datasets ucational materials that are interactive, engaging, and easy to\nand demonstrating the advantages of generative models in comprehend.TheMedSummframework,forexample,utilizes\npractical applications [14]. A key strength of MLLMs lies LLMs and VLMs to generate detailed summaries of Hindi-\nin their ability to analyze medical images in conjunction English code-mixed medical queries, integrating visual aids\nto improve comprehension and support personalized medical acknowledging the need for careful validation to mitigate\ncare [18]. potential inaccuracies [80].\nBilling and Scheduling: The application of MLLMs in\nD. Research and Development billing and scheduling processes can significantly improve\nefficiency and reduce errors. These models can analyze pa-\nMLLMs are offering promising solutions for literature re-\ntient data, insurance information, and scheduling constraints\nview, drug discovery, clinical trial matching, and knowledge\nto automate appointment scheduling, generate billing codes,\nextraction. They have accelerated discoveries and enhanced\nand process insurance claims. By streamlining these tasks,\nknowledge extraction.\nMLLMscanreduceadministrativeburdensonhealthcarestaff\nLiterature Review and Knowledge Extraction: MLLMs\nand improve patient satisfaction by reducing wait times and\nare proving invaluable for navigating and synthesizing the\nsimplifying billing processes.\nvast and ever-growing body of biomedical literature. For\ninstance, BioLORD-2023 integrates LLMs with knowledge IV. RESEARCH GAPS AND UNANSWEREDQUESTIONS\ngraphs to achieve state-of-the-art performance in semantic\nA. Data Limitations and Needs\ntextual similarity, concept representation, and named entity\nWhile the potential of MLLMs in healthcare is significant,\nlinking, enabling researchers to extract meaningful insights\ntheirdevelopmentandevaluationarehinderedbylimitationsin\nfrom complex medical texts [76], [77]. Similarly, MedMT5\ndata resources. As highlightedby [62], medicine is inherently\ntries to overcome language barriers in medical research by\nmultimodal, with data spanning text, imaging, genomics, and\noffering a robust, open-source, multilingual model for the\nmore.Yet,currentresearchfacesseveralkeychallengesrelated\nmedical domain, allowing for broader access to knowledge\nto data:\nacross different languages [32].\nScarcity of Large-Scale, Multimodal Datasets: Existing\nDrug Discovery:While stillintheearlystages, MLLMsin\nbiomedical datasets are often limited in size and scope,\ndrugdiscoveryholdspotential[78].Thesemodelscananalyze\nparticularly those incorporating multiple modalities. Some\ncomplex biological data, such as protein structures and drug\nresearchers mitigates the lack of datasets with locally-aligned\ninteractions, to identify potential drug targets and accelerate\nphrase groundingannotationsfor complexsemantic modeling\nthedrugdevelopmentprocess.Byintegratinginformationfrom\n[81], while other researchers often propose new dataset when\nvarious modalities, MLLMs can facilitate a more holistic\nreleasing new models [82]. The lack of large-scale datasets\nunderstanding of disease mechanisms and drug interactions,\nand their restricted size and scope is a major bottleneck for\npotentially leading to the discovery of novel therapeutics and\ntraining robust and generalizable MLLMs for diverse medical\npersonalized medicine approaches.\ntasks, especially when considering the need for datasets that\nClinical Trial Matching: MLLMs can significantly im-\nreflect real-world clinical scenarios [64], [73].\nprove the efficiency and accuracy of matching patients to\nLack of Diversity and Representation: Existing datasets\nsuitable clinicaltrials. These modelscan analyze patientdata,\noftenlackdiversityin termsofpatientdemographics,medical\nincluding medical history, genetic information, and imaging\nconditions, and healthcare settings. This issue is particularly\ndata,toidentifypotentialeligibilitycriteriaandmatchpatients\nrelevantwhenconsideringthepotentialbiasesintroduced[83].\nwith ongoing trials. The ability of MLLMs to process and\nChen et al. emphasizes the challenges of few-shot learning in\nunderstand multimodal data can enhance the identification of\npredicting rare disease areas due to limited data [13]. The\neligible patients, leading to more effective recruitment and\nlack of representation results in biased models that perform\npotentially faster clinical trial completion.\npoorly on underrepresented populations or specific medical\nconditions. The reliance on single-language data, primarily\nE. Administrative Tasks\nEnglish, is also a major concern[32], [84], [85]. It is difficult\nAdministrative tasks in healthcare is immense, which con- to access large amounts of domain-specific pre-training data\nsumes significant time and resources that could be allocated for multiple languages, which makes it difficult to resolve\nto improve patient care. MLLMs offer transformative solu- linguistic bias [32].\ntions by automating many of these tasks, which streamlines Challenges in Data Acquisition and Annotation:Obtain-\nprocesses and improves the overall efficiency. MLLMs can ing high-quality, annotated multimodal data in healthcare is\nhandle tasks in documentation, billing, scheduling, etc. with complexandresource-intensive.[86]notesthatmedicalimage\nremarkable speed and accuracy. annotationis costly and time-consuming,while [87] points to\nAutomation of Documentation: MLLMs are transforming the lack of LLMs trained on medical records. This challenge\nclinicaldocumentationbyautomatingtaskssuchasgenerating is complicated by the need for expert annotations [61], [88].\nradiology reports [49] and transcribing medical conversations The scarcity of medical image-text pairs for pre-training,\n[79]. This automation can free up clinicians’ time, allowing due to privacy and cost issues, is another major issue [14].\nthem to focus on patient care rather than paperwork. For Additionally, ensuring data privacy and obtaining informed\nexample,onestudyexploredtheuseofLLMstosimplifyradi- consent are critical ethical considerations that require careful\nological reports for improved patient comprehension, finding attention, particularly when dealing with sensitive medical\nthatLLMscaneffectivelycreatemoreaccessiblereportswhile information [35].\nB. InterdisciplinaryCollaborationandKnowledgeIntegration needed to develop effective methodsfor creating and evaluat-\ning multilingual medical LLMs that can cater to the needs of\n1) FosteringEffectiveInterdisciplinaryCollaboration: The\ndiverse patient populations [84], [99].\ndevelopment of clinically relevant and useful MultiModal\nLarge Language Models (MLLMs) requires bridging the gap D. Ethical and Regulatory Framework\nbetweencomputerscienceandmedicine.Thisinterdisciplinary\nThe potential of MLLMs in healthcare is clear, but their\nchallengecallsforcollaborationamongmedicalprofessionals,\ndeployment in real-world clinical settings presents significant\ndata scientists, ethicists, and policymakers [65], [89], [90].\nethical and regulatory challenges that demand careful consid-\nSuchcollaborationisessentialtofosterasharedunderstanding\neration and further research.\nof both the technical capabilities of LLMs and the specific\nA key issue is the lack of clear guidelines and regulations\nneeds and constraints of the healthcare domain.\nspecifically tailored for the development, deployment, and\nAs LLMs become more integrated into healthcare work-\nevaluation of LLMs in healthcare [87], [89]. Existing frame-\nflows, it is crucial to define the roles and responsibilities\nworksformedicalAImaynotfullyaddresstheuniqueethical\nof various stakeholders [91]. [10] stresses the importance of\nand legal implications of LLMs, especially in the context of\nincentivizing users, developers, providers, and regulators to\nmultimodality. This gap in comprehensive guidance creates\nprepareforthetransformativeroleofLLMsinevidence-based\nuncertainty for developers, clinicians, and regulators, which\nsectors.Thispreparationincludesestablishingclearguidelines\ncouldimpederesponsibleinnovationandsafeimplementation.\nfor accountabilityand oversightto ensure the safe and ethical\nBias, fairness, and transparency are critical concerns in\nuse of these powerful tools in healthcare settings.\nthe use of LLMs in healthcare. Several studies highlight the\nClinicians’ expertise is vital in guiding the development\npotentialforbiasduetoimbalancesintrainingdata[10],[13],\nand evaluation of MLLMs to ensure they address real-world\n[30]. This can result in unfair or inaccurate outcomes, partic-\nclinical needs [67], [92] illustrates how integrating an LLM\nularly for underrepresented or marginalized populations. The\noptimizedfordiagnosticreasoningintoaclinicalworkflowcan\nlack of transparency in LLM and MLLM training processes\nimprove diagnostic accuracy and comprehensiveness. How-\nand decision-making mechanisms also raises concerns about\never, further research is needed to explore effective methods\naccountabilityand trust [89]. Future research should focus on\nfor incorporating clinicians’ feedback and domain expertise\ndeveloping robust methods for identifying, quantifying, and\nthroughoutthe modeldevelopmentprocess.Thisongoingcol-\nmitigating biases, as well as ensuring transparency in their\nlaborationbetweenhealthcareprofessionalsandAIdevelopers\ndevelopmentand deployment.\nis key to creating MLLMs that can truly enhance patient care\nPatient privacy and data security are important when using\nand clinical decision-making [56], [93]–[95].\nLLMs in healthcare, as they involve processing sensitive\npatient information. Integrating multiple data modalities in\nC. Enhancing Knowledge Integration\nMLLMs adds complexity to data management and raises ad-\nBeyondtextualdata,integratingdomain-specificknowledge ditionalprivacy concerns[3]. Developingsecure data storage,\nfrom sources like medical ontologies, knowledge graphs, and de-identification techniques, and access control mechanisms\nclinical guidelines is essential for the effectiveness of Large are crucial areas for future research. These challenges are\nLanguage Models (LLMs) in complex medical tasks [81]. particularlyevidentinspecificmedicalfields,suchasdentistry,\nA Significant challenge in deploying LLMs for healthcare where the use of LLMs requires robust safeguards to protect\nis addressing the issues of hallucinations and bias. LLMs patient data [33], [100], [101].\ncan generate factually incorrect information and perpetuate Additionalresearch is neededto define the optimalbalance\nbiases present in their training data, which is particularly between human oversight and LLM autonomy, and establish-\nconcerning in medical contexts. To tackle this problem, [96] ing robust governance structures for LLMs in healthcare is\nintroduces Med-HALT, a benchmark and dataset specifically essential to ensure accountability and public trust. A frame-\ndesigned to evaluate and mitigate hallucinations in medical work for evaluating LLMs in healthcare, including a gover-\nLLMs. This tool emphasizes the critical need to address nance layer to ensure accountability and public confidence,\nthese issues for safer healthcare applications. Additionally, has been proposed [41]. Clear guidelines and standards are\n[97] underscorestheimportanceof incorporatingdiversereal- neededfordatagovernance,modeldevelopment,performance\nworld data and domain-specific knowledge to reduce factual evaluation, bias mitigation, and transparency. A collaborative\ninaccuraciesandimprovethemodel’sgroundinginreal-world approachinvolvingdevelopers,clinicians,ethicists,regulators,\nclinical scenarios. and patients is vital for establishing trust and promoting the\nThe developmentof multilingualmodelsrepresentsanother responsible use of LLMs in healthcare [102].\ncrucial area for advancement in medical LLMs. Most LLMs\nE. Technical Advancements Required\nare trained primarily on English data, which limits their\naccessibility and applicability in diverse linguistic contexts. Realizing MLLMs’ potential requires overcoming signifi-\nThe potential of bilingual fine-tuned LLMs, such as Taiyi, cant technical challenges. Existing research highlights several\ncan achieve superior performance on biomedical NLP tasks key areas where advancements are urgently needed.\ncompared to general LLMs [98]. However, more research is Advancing Modality Alignment Methods\nCurrent modality alignment methods, which aim to bridge unlock their full potential and ensure safe, responsible, and\nthe semantic gap between different data types like text and equitable integration into clinical practice.\nimages, often struggle to capture the complex relationships\nA. Data Augmentation and Access\nand nuances present in medical data. This limitation hinders\nthe ability of MLLMs to integrate information effectively Data Augmentation and Access: The scarcity of large-\nand generate accurate and coherent outputs [7], [103]. Novel scale,high-quality,anddiversemultimodaldatasetsisamajor\napproaches are needed to create more robust and nuanced bottleneck [106]. This is especially true for languages other\nalignment methods that can capture the complex interdepen- than English [32]. Future research shall focus on:\ndenciesbetween differentmodalities,ensuringa moreholistic Dataset Creation and Curation: Developing large, well-\nannotated datasets encompassing diverse medical specialties,\nunderstanding of medical data.\npatient populations, and languages is crucial [85]. This in-\nUnveiling the “Black Box”\ncludesincorporatingvisualdatalikemedicalimages,alongside\nThe ”black box” nature of large language models, where\ntext from EHRs, clinical notes, and medical literature [110].\ntheir internalworkingsand decision-makingprocesses remain\nDatasets should represent real-world scenarios and address\nopaque,isasignificantchallengefortheirdeploymentinhigh-\nissues like imbalanced data [38]. The OmniMedVQA bench-\nstakes medical decisions. Clinicians need to understand the\nmarkprovidesagoodexampleofacomprehensivedatasetthat\nrationale behind AI-generated outputs to trust and validate\naddresses some of these challenges [48].\ntheir recommendations. The lack of transparency and inter-\nPrivacy-PreservingDataSharing:Investigatinginnovative\npretability in current LLMs hinders the ability to identify\nmethods like federated learning [33] to enable collaborative\npotential biases, errors, or inconsistencies in their reasoning.\ndata sharing and model training while preserving patient\nFurther research to understand how LLMs make decisions,\nprivacy.\nparticularlyinthecontextofassessingclinicalacuityisneeded\nStandardization and Interoperability: Developing stan-\n[31].DevelopingmethodstomakeLLMsmoretransparentand\ndardizeddata formatsand categoriesto facilitate data integra-\ninterpretable is crucial for ensuring their safe and responsible\ntion and interoperability across different healthcare systems\nuse in medical applications [104], [105].\nand institutions. This is crucial for training models that can\nEnhancing Generalization and Robustness\ngeneralize well to new settings [111].\nAchieving reliable generalization and robustness across di-\nverse medical contexts, patient populations, and languages is B. Advanced Modality Alignment\ncrucial for the real-world deployment of MLLMs. Current\nA key area for future research is developing more so-\nmodelsoftenstruggletogeneralizebeyondtheirtrainingdata,\nphisticated methods for aligning different modalities. Future\nwhich leads to inaccuracies and biases when applied to new\nresearch could focus on developing novel architectures and\npopulations or scenarios. The study by Zhang et al. demon-\ntrainingstrategiesthatcanbettercapturethecomplexrelation-\nstrates that while LLMs can effectively analyze data from\nships between different modalities, leading to more accurate\nspecificmedicalspecialties,theirperformanceoftendecreases\nand robust predictions [112].\nwhen applied to other areas [73]. Additional efforts should\nfocusondevelopingmethodstoenhancethegeneralizationca- C. Interpretability and Explainability\npabilities of MLLMs, ensuring that they perform consistently A critical area for future research is enhancing the in-\nand reliably across different medical contexts, diverse patient terpretability and explainability of MLLMs. This lack of\npopulations, and various languages. transparency in current LLMs MLLMs can hinder trust and\nDeveloping Efficient and Scalable Models adoption in clinical settings. Traditional evaluation methods\nThe large size and computational demands of MLLMs forMLLMsareusuallyinsufficientforclinicalsettings,asthey\npose a significant barrier to their deployment in resource- don’t adequately assess their impact on real-world workflows\nconstrained settings. Training and deploying these models [73]. Future research should focus on developing methods to\nrequire substantial computational power, which can be pro- makeMLLMdecision-makingprocessesmoretransparentand\nhibitively expensive [106], [107]. Developing efficient and understandable, such as generating human-readable explana-\nscalablemodelsthatoperatesonlesspowerfuldevicesorwith tions for their predictions or visualizing the processes that\nreduced computational resources is crucial for making these contribute to their decisions.\ntechnologies more accessible and equitable in healthcare.\nD. Robust Evaluation Frameworks\nRobust and standardized evaluation frameworks becomes\nV. FUTURE DIRECTIONS AND CONCLUSION\nincreasingly critical as MLLMs become increasingly sophis-\nThis review has emphasized the potential of LLMs and ticated. Current evaluation methods often rely on limited\nMLLMs to revolutionize medicine and healthcare. While datasetsandmetricstonon-clinicaltasks,restrictingthepoten-\nshowing early promise in areas like patient-trial matching tial to capture the full range of capabilities and biases [113].\n[108], generating radiology reports [109], and assisting with To ensure the safe and effective of clinical MLLMs, future\nclinical diagnostics [62], LLMs are still in their early stages. effort should spend on developing additional standardized\nSignificant research gaps remain and must be addressed to benchmarks with closer clinical relevance.\nE. Ethics and Compliance [15] Michael Moor,QianHuang,ShirleyWu,Michihiro Yasunaga, C.Za-\nkka,YashodharaDalmia,E.Reis,P.Rajpurkar,andJ.Leskovec,“Med-\nThe ethical implications of MLLMs in healthcare cannot\nFlamingo:aMultimodalMedicalFew-shotLearner,”ML4H@NeurIPS,\nbe overstated. Its training data contain sensitive patient in- 2023.\nformation, raising concerns about privacy and data security [16] J. Zhou, X. He, L. Sun, J. Xu, X. Chen, Y. Chu, L. Zhou, X. Liao,\nB. Zhang, S. Afvari, and X. Gao, “Pre-trained multimodal large\n[29].Biasedtrainingdatacanleadtodiscriminatoryoutcomes,\nlanguagemodelenhancesdermatologicaldiagnosisusingSkinGPT-4,”\npotentially exacerbating existing health disparities. Therefore, NatureCommunications, vol.15,no.1,jul52024.\nclear regulatory frameworks and guidelines are necessary to [17] D. Dao, J. Y. C. Teo, W. Wang, and H. D. Nguyen, “Llm-powered\nmultimodal ai conversations for diabetes prevention,” in Proceedings\ngovern the development, deployment, and use of MLLMs in\nofthe1stACMWorkshoponAI-PoweredQ&ASystemsforMultimedia,\nclinicalsettings[35].Addressingtheseethicalandcompliance 2024,pp.1–6.\nchallenges will be beneficial to establish trust and ensure the [18] Akash Ghosh, Arkadeep Acharya, Prince Jha, Aniket Gaudgaul, Ra-\nresponsible use of MLLMs in healthcare. jdeep Majumdar, Sriparna Saha, Aman Chadha, Raghav Jain, Setu\nSinha, andShivani Agarwal, “Medsumm:AMultimodal Approach to\nREFERENCES Summarizing Code-Mixed Hindi-English Clinical Queries,” European\nConference onInformationRetrieval, 2024.\n[1] L. Y. Jiang, X. C. Liu, N. P. Nejatian, M. Nasir-Moin, D. Wang, [19] FeilongChen,MinglunHan,HaozhiZhao,QingyangZhang,JingShi,\nA. Abidin, K. Eaton, H. A. Riina, I. Laufer, P. Punjabi, M. Miceli, Shuang Xu, and Bo Xu, “X-LLM: Bootstrapping Advanced Large\nN.C.Kim,C.Orillac,Z.Schnurman,C.Livia,H.Weiss,D.Kurland, LanguageModelsbyTreatingMulti-ModalitiesasForeignLanguages,”\nS.Neifert,Y.Dastagirzada,D.Kondziolka,A.T.M.Cheung,G.Yang, arXiv.org,2023.\nM. Cao, M. Flores, A. B. Costa, Y. Aphinyanaphongs, K. Cho, and [20] Y. Gao, R. Li,J.Caskey, D. Dligach, T.Miller, M.M. Churpek, and\nE.K.Oermann,“Healthsystem-scalelanguagemodelsareall-purpose M.Afshar,“Leveragingamedicalknowledgegraphintolargelanguage\nprediction engines,” Nature, vol. 619, no. 7969, pp. 357–362, jun 7 models for diagnosis prediction,” arXiv preprint arXiv:2308.14321,\n2023. 2023.\n[2] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, [21] F. Remy, K. Demuynck, and T. Demeester, “Biolord-2023: seman-\nN.Scales,A.Tanwani,H.Cole-Lewis,S.Pfohl,P.Payne,M.Senevi- tic textual representations fusing large language models and clinical\nratne, P. Gamble, C. Kelly, A. Babiker, N. Scha¨rli, A. Chowdhery, knowledge graph insights,” Journal of the American Medical Infor-\nP. Mansfield, D. Demner-Fushman, B. Agu¨era y Arcas, D. Web- matics Association, vol.31,no.9,pp.1844–1855, feb272024.\nster, G. S. Corrado, Y. Matias, K. Chou, J. Gottweis, N. Tomasev, [22] Emre Can Acikgoz, Osman Batur .Ince, Rayene Bench, Arda Anil\nY.Liu,A.Rajkomar, J.Barral, C.Semturs,A.Karthikesalingam, and Boz, .Ilker Kesen, Aykut Erdem,andErkutErdem,“Hippocrates: An\nV. Natarajan, “Large language models encode clinical knowledge,” Open-Source Framework for Advancing Large Language Models in\nNature,vol.620,no.7972,pp.172–180, jul122023. Healthcare,” arXiv.org,2024.\n[3] J.N.Acosta,G.J.Falcone,P.Rajpurkar,andE.J.Topol,“Multimodal [23] KaiZhang,JunYu,EashanAdhikarla,RongZhou,ZhilingYan,Yixin\nbiomedical AI,” Nature Medicine, vol. 28, no. 9, pp. 1773–1784, 9\nLiu, Zheng Liu, Lifang He, Brian D Davison, Xiang Li, Hui Ren,\n2022.\nS. Fu, James Zou, Wei Liu, Jing Huang, Chen Chen, Yuyin Zhou,\n[4] Yinghao Zhu, Changyu Ren, Shiyun Xie, Shukai Liu, Hangyuan Ji,\nTianming Liu,XunChen, YongChen, Quanzheng Li, Hongfang Liu,\nZixiang Wang, Tao Sun, Long He, Zhoujun Li, Xi Zhu, and Cheng-\nand Lichao Sun, “Biomedgpt: A Unified Biomedical Generative Pre-\nweiPan,“Realm:Rag-Driven Enhancement ofMultimodalElectronic\ntrained Transformer for Vision, Language, and Multimodal Tasks,”\nHealthRecordsAnalysisviaLargeLanguageModels,”arXiv.org,2024.\nNatureMedicine, pp.1–13,2024.\n[5] S. He, Y. Nie, Z. Chen, Z. Cai, H. Wang, S. Yang, and H. Chen,\n[24] Z. Shao, W. Dou, and Y. Pan, “Dual-level deep evidential fusion:\n“Meddr: Diagnosis-guided bootstrapping for large-scale medical\nIntegrating multimodal information for enhanced reliable decision-\nvision-language learning,” arXivpreprintarXiv:2404.15127, 2024.\nmaking in deep learning,” Information Fusion, vol. 103, p. 102113,\n[6] J.M.Z.Chaves,S.-C.Huang,Y.Xu,H.Xu,N.Usuyama,S.Zhang,\n2024.\nF. Wang, Y. Xie, M. Khademi, Z. Yang et al., “Training small\n[25] QinghaoYe,HaiyangXu,JiaboYe,MingshiYan,AnwenHu,Haowei\nmultimodalmodelstobridgebiomedicalcompetencygap:Acasestudy\nLiu,QiQian,JiZhang,FeiHuang, andJingren Zhou,“mplug-Owl2:\ninradiology imaging,” arXivpreprintarXiv:2403.08002, 2024.\nRevolutionizing Multi-modal Large Language Model with Modality\n[7] M.-H. Van, P. Verma, and X. Wu, “On Large Visual Language\nCollaboration,” arXiv.org,2023.\nModels forMedical ImagingAnalysis: AnEmpirical Study,” in2024\n[26] S.Niu,J.Ma,L.Bai,Z.Wang,L.Guo,andX.Yang,“Ehr-knowgen:\nIEEE/ACM Conference on Connected Health: Applications, Systems\nKnowledge-enhancedmultimodallearningfordiseasediagnosisgener-\nand Engineering Technologies (CHASE). IEEE, jun 19 2024, pp.\nation,” InformationFusion,vol.102,p.102069,2024.\n172–176.\n[8] B. Mesko´, “The Impact of Multimodal Large Language Models on [27] Y. Ektefaie, G. Dasoulas, A.Noori, M. Farhat, and M. Zitnik, “Mul-\nHealth Care’s Future,” Journal ofMedical Internet Research,vol.25, timodal learning with graphs,” Nature Machine Intelligence, vol. 5,\np.e52865, nov22023. no.4,pp.340–350,2023.\n[9] Abdul Basit, Khizar Hussain, M. Hanif, and Muhammad Shafique, [28] K.NassiriandM.A.Akhloufi,“RecentAdvances inLargeLanguage\n“Medaide: LeveragingLargeLanguageModelsforOn-PremiseMedi- Models for Healthcare,” BioMedInformatics, vol. 4, no. 2, pp. 1097–\ncalAssistanceonEdgeDevices,” arXiv.org,2024. 1143,apr162024.\n[10] S. Harrer, “Attention is not all you need: the complicated case of [29] B.Peng,K.Chen,M.Li,P.Feng,Z.Bi,J.Liu,andQ.Niu,“Securing\nethically using large language models in healthcare and medicine,” large language models: Addressing bias, misinformation, and prompt\neBioMedicine, vol.90,p.104512,42023. attacks,” arXiv preprint arXiv:2409.08087, 2024. [Online]. Available:\n[11] D. Lyu, X. Wang, Y. Chen, and F. Wang, “Language model and its https://arxiv.org/abs/2409.08087\ninterpretability in biomedicine: A scoping review,” iScience, vol. 27, [30] L.Jiang,C.Liu,N.P.Nejatian, M.Nasir-Moin,D.Wang,A.Abidin,\nno.4,p.109334,42024. K. Eaton, H. A. Riina, I. Laufer, P. Punjabi, M. Miceli, N. C. Kim,\n[12] C. Zakka, R. Shad, A. Chaurasia, A. R. Dalal, J. L. Kim, C.M.Orillac,Z.Schnurman,C.Livia,H.Weiss,D.B.Kurland,S.N.\nM. Moor, R. Fong, C. Phillips, K. Alexander, E. Ashley Neifert, Y. M. Dastagirzada, D. S. Kondziolka, A. Cheung, G. Yang,\net al., “Almanac—retrieval-augmented language models for clinical M. Cao, M. Flores, A. Costa, Y. Aphinyanaphongs, K. Cho, and\nmedicine,” NEJMAI,vol.1,no.2,p.AIoa2300068, 2024. E.K.Oermann,“754Prediction of30-dayAll-Cause Readmission of\n[13] Zekai Chen, Mariann Micsinai Balan, and Kevin Brown, “Language NeurosurgeryPatients UsingLargeLanguageModels,”Neurosurgery,\nModels are Few-shot Learners for Prognostic Prediction,” arXiv.org, vol.70,no.Supplement 1,pp.165–165,42024.\n2023. [31] C. Y. K. Williams, T. Zack, B. Y. Miao, M. Sushil, M. Wang, A. E.\n[14] JiaweiChen,DingkangYang,YueJiang,YuxuanLei,andLihuaZhang, Kornblith, and A. J. Butte, “Use of a Large Language Model to\n“Miss: A Generative Pretraining and Finetuning Approach for Med- AssessClinicalAcuityofAdultsintheEmergencyDepartment,”JAMA\nVQA,”arXiv.org,2024. Network Open,vol.7,no.5,p.e248895, may72024.\n[32] IkerGarc’ia-Ferrero,R.Agerri,AitziberAtutxaSalazar,ElenaCabrio, [52] DuzhenZhang,YahanYu,ChenxingLi,JiahuaDong,DanSu,Chenhui\nIker de la Iglesia, A. Lavelli, Bernardo Magnini, Benjamin Molinet, Chu, and Dong Yu, “Mm-LLMs: Recent Advances in MultiModal\nJohana Ramirez-Romero, German Rigau, J. M. Villa-Gonzalez, S. LargeLanguageModels,”arXiv.org,2024.\nVillata,andAndreaZaninello,“Medmt5:AnOpen-SourceMultilingual [53] F. Liu, T. Zhu, X. Wu, B. Yang, C. You, C. Wang, L. Lu, Z. Liu,\nText-to-TextLLMfortheMedicalDomain,”InternationalConference Y.Zheng,X.Sun,Y.Yang,L.Clifton, andD.A.Clifton, “Amedical\nonLanguage ResourcesandEvaluation, 2024. multimodal large language model for future pandemics,” npj Digital\n[33] D. Wang, L. Feng, J. Ye, J. Zou, and Y. Zheng, “Accelerating the Medicine, vol.6,no.1,dec22023.\nintegrationofChatGPTandotherlargescaleAImodelsintobiomedical [54] R. Bhayana, “Chatbots and Large Language Models in Radiology: A\nresearchandhealthcare,” MedComm–FutureMedicine, vol.2,no.2, Practical Primer for Clinical and Research Applications,” Radiology,\nmay172023. vol.310,no.1,jan12024.\n[34] H.-Y. Zhou, S. Adithan, J. N. Acosta, E. J. Topol, and P. Rajpurkar, [55] N. Yildirim, H. Richardson, M. T. Wetscherek, J. Bajwa, J. Jacob,\n“AGeneralistLearnerforMultifaceted MedicalImageInterpretation,” M.A.Pinnock,S.Harris,D.CoelhoDeCastro,S.Bannur,S.Hyland,\narXivpreprintarXiv:2405.07988, 2024. P. Ghosh, M. Ranjit, K. Bouzid, A. Schwaighofer, F. Pe´rez-Garc´ıa,\n[35] J. C. L. Ong, S. Y.-H. Chang, W. William, A. J. Butte, N. H. Shah, H. Sharma, O. Oktay, M. Lungren, J. Alvarez-Valle, A. Nori, and\nL.S.T.Chew,N.Liu,F.Doshi-Velez,W.Lu,J.Savulescu,andD.S.W. A. Thieme, “Multimodal Healthcare AI: Identifying and Designing\nTing, “Ethical and regulatory challenges of large language models in Clinically Relevant Vision-Language Applications for Radiology,” in\nmedicine,” TheLancetDigitalHealth,vol.6,no.6,pp.e428–e432, 6 Proceedings oftheCHIConference onHumanFactors inComputing\n2024. Systems. ACM,may112024,pp.1–22.\n[36] A.Vaswani,“Attentionisallyouneed,”AdvancesinNeuralInforma- [56] Wenhao Zheng, Dongsheng Peng, Hongxia Xu, Hongtu Zhu,Tianfan\ntionProcessingSystems, 2017. Fu, and Huaxiu Yao, “Multimodal Clinical Trial Outcome Prediction\n[37] Q. Lu, D. Dou, and T. Nguyen, “Clinicalt5: A Generative Language withLargeLanguage Models,”arXiv.org,2024.\nModel for Clinical Text,” in Findings of the Association for Compu- [57] Y. Park, S.Woo,S. Lee,M. A.Nugroho, and C. Kim,“Cross-modal\ntational Linguistics: EMNLP 2022. Association for Computational alignment and translation for missing modality action recognition,”\nLinguistics, 2022. ComputerVisionandImageUnderstanding,vol.236,p.103805,2023.\n[38] X. Meng, X. Yan, K. Zhang, D. Liu, X. Cui, Y. Yang, M. Zhang, [58] S. Tripathi, K. Gabriel, P. K. Tripathi, and E. Kim, “Large language\nC. Cao, J. Wang, X. Wang, J. Gao, Y.-G.-S. Wang, J.-m. Ji, Z. Qiu, modelsreshapingmolecularbiologyanddrugdevelopment,”Chemical\nM. Li, C. Qian, T. Guo, S. Ma, Z. Wang, Z. Guo, Y. Lei, C. Shao, Biology&DrugDesign,vol.103,no.6,62024.\nW.Wang,H.Fan,andY.-D.Tang,“Theapplication oflargelanguage [59] ChaoyiWu,XiaomanZhang,YaZhang,YanfengWang,andWeidiXie,\nmodels in medicine: A scoping review,” iScience, vol. 27, no. 5, p. “Pmc-LLaMA: Towards Building Open-source Language Models for\n109713, 52024. Medicine,” Journal oftheAmerican Medical Informatics Association,\n[39] RojinZiaeiandSamuelSchmidgall,“Languagemodelsaresusceptible 2023.\nto incorrect patient self-diagnosis in medical applications,” arXiv.org, [60] ——,“Pmc-LLaMA:FurtherFinetuningLLaMAonMedicalPapers,”\n2023. arXiv.org,2023.\n[40] B. Peng, Z. Bi, P. Feng, Q. Niu, J. Liu, and K. Chen, “Emerging [61] C. Wu, W. Lin, X. Zhang, Y. Zhang, W. Xie, and Y. Wang, “Pmc-\ntechniquesinvision-basedhumanposturedetection:Machinelearning LLaMA:towardbuildingopen-sourcelanguagemodelsformedicine,”\nmethods andapplications,” Authorea,2024. Journal of the American Medical Informatics Association, vol. 31,\n[41] S.Reddy,“Evaluating largelanguagemodels foruseinhealthcare: A no.9,pp.1833–1843, apr132024.\nframeworkfortranslationalvalueassessment,”InformaticsinMedicine [62] T.Tu,S.Azizi, D.Driess,M.Schaekermann, M.Amin,P.-C.Chang,\nUnlocked, vol.41,p.101304,2023. A. Carroll, C. Lau, R. Tanno, I. Ktena et al., “Towards generalist\n[42] T. Han, A. Kumar, C. Agarwal, and H. Lakkaraju, “Medsafetybench: biomedical ai,”NEJMAI,vol.1,no.3,p.AIoa2300138, 2024.\nEvaluating and improving the medical safety of large language [63] Y. Zhu, Z. Wang, J. Gao, Y. Tong, J. An, W. Liao, E. M. Harrison,\nmodels,”2024.[Online]. Available: https://arxiv.org/abs/2403.03744 L. Ma, and C. Pan, “Prompting Large Language Models for Zero-\n[43] J. Deng, K. Heybati, and M. Shammas-Toma, “When vision meets ShotClinicalPredictionwithStructuredLongitudinalElectronicHealth\nreality: Exploring the clinical applicability of GPT-4 with vision,” RecordData,”2024.\nClinical Imaging,vol.108,p.110101,42024. [64] MingyuJin,QinkaiYu,DongShu,ChongZhang,LizhouFan,Wenyue\n[44] J.Achiam,S.Adler,S.Agarwal,L.Ahmad,I.Akkaya,F.L.Aleman, Hua, Suiyuan Zhu, Yanda Meng, Zhenting Wang, Mengnan Du, and\nD. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4 Yongfeng Zhang, “Health-LLM: Personalized Retrieval-Augmented\ntechnical report,” arXivpreprintarXiv:2303.08774, 2023. DiseasePrediction System,”arXiv.org,2024.\n[45] Ankit Pal and Malaikannan Sankarasubbu, “Gemini Goes to Med [65] Y.-J. Park, A. Pillai, J. Deng, E. Guo, M. Gupta, M. Paget, and\nSchool: Exploring the Capabilities of Multimodal Large Language C. Naugler, “Assessing the research landscape and clinical utility of\nModels on Medical Challenge Problems & Hallucinations,” Clinical large language models: a scoping review,” BMC Medical Informatics\nNaturalLanguage ProcessingWorkshop,2024. andDecisionMaking, vol.24,no.1,mar122024.\n[46] G.Team,R.Anil,S.Borgeaud,Y.Wu,J.-B.Alayrac,J.Yu,R.Soricut, [66] S.Schmidgall, R. Ziaei, C.Harris, E.Reis, J.Jopling, and M.Moor,\nJ.Schalkwyk,A.M.Dai,A.Hauthetal.,“Gemini:afamilyofhighly “Agentclinic: a multimodal agent benchmark to evaluate AI in simu-\ncapable multimodal models,”arXivpreprintarXiv:2312.11805, 2023. lated clinical environments,” 2024.\n[47] Iryna Hartsock and Ghulam Rasool, “Vision-Language Models for [67] Daniel McDuff, M.Schaekermann, TaoTu,AnilPalepu, AmyWang,\nMedical Report Generation and Visual Question Answering: A Re- JakeGarrison, KaranSinghal, YashSharma,Shekoofeh Azizi, Kavita\nview,”arXiv.org,2024. Kulkarni,LeHou,YongCheng,YunLiu,S.Mahdavi,SushantPrakash,\n[48] YutaoHu,Tian-XinLi,QuanfengLu,WenqiShao,JunjunHe,YuQiao, Anupam Pathak, Christopher Semturs, Shwetak Patel, D. Webster,\nand Ping Luo, “Omnimedvqa: A New Large-Scale Comprehensive Ewa Dominowska, Juraj Gottweis, Joelle Barral, Katherine Chou, G.\nEvaluation BenchmarkforMedical LVLM,”arXiv.org,2024. Corrado, Yossi Matias, Jacob Sunshine, A. Karthikesalingam, and\n[49] T. Nakaura, R. Ito, D. Ueda, T. Nozaki, Y. Fushimi, Y. Matsui, VivekNatarajan,“TowardsAccurateDifferentialDiagnosiswithLarge\nM. Yanagawa, A. Yamada, T. Tsuboyama, N. Fujima, F. Tatsugami, LanguageModels,”arXiv.org,2023.\nK. Hirata, S. Fujita, K. Kamagata, T. Fujioka, M. Kawamura, and [68] JundaWang,ZhichaoYang, Zonghai Yao,andHongYu,“Jmlr:Joint\nS. Naganawa, “The impact of large language models on radiology: a Medical LLM and Retrieval Training for Enhancing Reasoning and\nguideforradiologistsonthelatestinnovationsinAI,”JapaneseJournal Professional QuestionAnsweringCapability,” arXiv.org,2024.\nofRadiology, vol.42,no.7,pp.685–696,mar292024. [69] KilianCarolan,LauraFennelly,andA.Smeaton,“AReviewofMulti-\n[50] Yihe Fan, Yuxin Cao, Ziyu Zhao, Ziyao Liu, and Shaofeng Li, ModalLargeLanguageandVisionModels,”arXiv.org,2024.\n“UnbridledIcarus:ASurveyofthePotentialPerilsofImageInputsin [70] AminDada, Marie Bauer, AmandaButler Contreras, OsmanAlperen\nMultimodal LargeLanguageModelSecurity,” arXiv.org,2024. Koras,C.Seibold,KalebE.Smith,andJensKleesiek,“Clue:AClinical\n[51] S.Tripathi, R.Sukumaran,andT.S.Cook,“Efficient healthcare with LanguageUnderstanding Evaluation forLLMs,”arXiv.org,2024.\nlarge language models: optimizing clinical workflow and enhancing [71] F.Liu,H.Zhou,Y.Hua,O.Rohanian,A.Thakur,L.Clifton,andD.A.\npatientcare,”JournaloftheAmericanMedicalInformaticsAssociation, Clifton, “Large Language Models in the Clinic: A Comprehensive\nvol.31,no.6,pp.1436–1440,jan252024. Benchmark,” apr252024.\n[72] CongyunJin,MingZhang,XiaoweiMa,YujiaoLi,YingboWang,Yabo [92] D.Umerenkov,GalinaZubkova,andA.Nesterov,“DecipheringDiag-\nJia,YuliangDu,TaoSun,HaowenWang,CongFan,JinjieGu,Chenfei noses: How Large Language Models Explanations Influence Clinical\nChi, Xiangguo Lv, Fangzhou Li, Wei Xue, and Yiran Huang, “Rjua- Decision Making,”arXiv.org,2023.\nMedDQA:AMultimodalBenchmarkforMedicalDocumentQuestion [93] E.Malek,G.-M.Wang,A.Madabhushi,J.Cullen,C.Tatsuoka,andJ.J.\nAnsweringandClinical Reasoning,” arXiv.org,2024. Driscoll,II,“TowardAI-AssistedClinicalAssessmentforPatientswith\n[73] N.Mehandru,B.Y.Miao,E.R.Almaraz,M.Sushil,A.J.Butte,and Multiple Myeloma: Feature Selection for Large Language Models,”\nA. Alaa, “Evaluating large language models as agents in the clinic,” Blood,vol.142,no.Supplement1,pp.2328–2328, nov22023.\nnpjDigitalMedicine, vol.7,no.1,apr32024. [94] R. Armitage, “Large language models must serve clinicians, not the\n[74] A. Mihalache, R. S. Huang, D. Mikhail, M. M. Popovic, R. Shor, reverse,” TheLancetInfectious Diseases,vol.24,no.5,pp.453–454,\nA.Pereira,J.Kwok,P.Yan,D.T.Wong,P.J.Kertesetal.,“Interpre- 52024.\ntationofclinicalretinalimagesusinganartificialintelligencechatbot,” [95] G. Briganti, “A clinician’s guide to large language models,” Future\nOphthalmology Science, p.100556,2024. Medicine AI,aug172023.\n[75] A.Sharma,A.Saxena,A.Kumar,andD.Singh,“Depressiondetection [96] LogeshKumarUmapathi, AnkitPal, andMalaikannan Sankarasubbu,\nusingmultimodalanalysiswithchatbotsupport,”in20242ndInterna- “Med-HALT:MedicalDomainHallucination TestforLargeLanguage\ntional Conference on Disruptive Technologies (ICDT). IEEE, 2024, Models,” Conference on Computational Natural Language Learning,\npp.328–334. 2023.\n[76] Franc¸ois Remy, Kris Demuynck, and Thomas Demeester, “Biolord- [97] GuangyuWang,GuoxingYang,ZongxinDu,LongjunFan,andXiaohu\n2023: Semantic Textual Representations Fusing LLM and Clinical Li, “Clinicalgpt: Large Language Models Finetuned with Diverse\nKnowledge GraphInsights,”arXiv.org,2023. Medical DataandComprehensive Evaluation,” arXiv.org,2023.\n[77] Q.Niu,J.Liu,Z.Bi,P.Feng,B.Peng,andK.Chen,“Largelanguage [98] L.Luo,J.Ning,Y.Zhao,Z.Wang,Z.Ding,P.Chen,W.Fu,Q.Han,\nmodelsandcognitivescience:Acomprehensivereviewofsimilarities, G.Xu,Y.Qiu,D.Pan,J.Li,H.Li,W.Feng,S.Tu,Y.Liu,Z.Yang,\ndifferences, andchallenges,” arXivpreprintarXiv:2409.02387, 2024. J. Wang, Y. Sun, and H. Lin, “Taiyi: a bilingual fine-tuned large\n[78] B. Steurer, Q. Vanhaelen, and A. Zhavoronkov, “Multimodal trans- languagemodelfordiversebiomedicaltasks,”JournaloftheAmerican\nformers and their applications in drug target discovery for aging and MedicalInformaticsAssociation,vol.31,no.9,pp.1865–1874,feb29\nage-related diseases,” TheJournals ofGerontology: Series A,vol.79, 2024.\nno.9,2024. [99] T.GroteandP.Berens,“Aparadigmshift?—Ontheethicsofmedical\nlargelanguagemodels,”Bioethics,vol.38,no.5,pp.383–390,mar25\n[79] Ayo Adedeji, Sarita Joshi, and Brendan Doohan, “The Sound of\n2024.\nHealthcare: Improving Medical Transcription ASR Accuracy with\n[100] H. Huang, O. Zheng, D. Wang, J. Yin, Z. Wang, S. Ding, H. Yin,\nLargeLanguageModels,”arXiv.org,2024.\nC. Xu, R. Yang, Q. Zheng, and B. Shi, “Chatgpt for shaping the\n[80] Y. Artsi, V. Sorin, E. Konen, B. S. Glicksberg, G. Nadkarni, and\nfutureofdentistry:thepotentialofmulti-modallargelanguagemodel,”\nE.Klang,“Largelanguagemodelsinsimplifyingradiological reports:\nInternational JournalofOralScience, vol.15,no.1,jul282023.\nsystematic review,” jan92024.\n[101] M.Hu,J.Qian,S.Pan,Y.Li,R.L.J.Qiu,andX.Yang,“Advancing\n[81] B.Boecking,N.Usuyama,S.Bannur,D.C.Castro,A.Schwaighofer,\nmedicalimagingwithlanguagemodels:featuringaspotlightonChat-\nS. Hyland, M. Wetscherek, T. Naumann, A. Nori, J. Alvarez-Valle,\nGPT,”PhysicsinMedicine&Biology,vol.69,no.10,p.10TR01,may\nH. Poon, and O. Oktay, Making the Most of Text Semantics to\n32024.\nImprove Biomedical Vision–Language Processing. Springer Nature\n[102] A. Youssef, S. Stein, J. Clapp, and D. Magnus, “The Importance of\nSwitzerland, 2022,pp.1–21.\nUnderstanding Language in Large Language Models,” The American\n[82] Sheng Zhang, Yanbo Xu, Naoto Usuyama, J. Bagga, Robert Tinn,\nJournalofBioethics, vol.23,no.10,pp.6–7,oct32023.\nSam Preston, Rajesh N. Rao, Mu-Hsin Wei, Naveen Valluri, Cliff\n[103] Jun-En Ding, Phan Nguyen Minh Thao, Wen-Chih Peng, Jian-Zhe\nWong,M.Lungren,TristanNaumann,andHoifungPoon,“Biomedclip:\nWang, Chun-Cheng Chug, Min-Chen Hsieh, Yun-Chien Tseng, Ling\na multimodal biomedical foundation model pretrained from fifteen\nChen,DongshengLuo,Chi-TeWang,Pei-fuChen,FengLiu,andFang-\nmillion scientific image-text pairs,”2023.\nMingHung,“LargeLanguageMultimodalModelsfor5-YearChronic\n[83] S. Schmidgall, C. Harris, I. Essien, D. Olshvang, T. Rahman, J. W.\nDiseaseCohortPrediction UsingEHRData,”arXiv.org,2024.\nKim,R.Ziaei,J.Eshraghian,P.Abadir,andR.Chellappa,“Addressing\n[104] E.Alsentzer, M.J.Rasmussen,R.Fontoura, A.L.Cull,B.Beaulieu-\ncognitive biasinmedical language models,”2024.\nJones, K. J. Gray, D. W. Bates, and V. P. Kovacheva, “Zero-shot\n[84] Y.Jin,M.Chandra,G.Verma,Y.Hu,M.DeChoudhury,andS.Kumar,\nInterpretable Phenotyping of Postpartum Hemorrhage Using Large\n“BettertoAskinEnglish:Cross-LingualEvaluationofLargeLanguage\nLanguageModels,”jun12023.\nModels for Healthcare Queries,” in Proceedings of the ACM Web\n[105] AleksaBisercic, MladenNikolic, M.Schaar, BorisDelibasic, P.Lio’,\nConference 2024,vol.35. ACM,may132024,pp.2627–2638.\nand A. Petrovic´, “Interpretable Medical Diagnostics with Structured\n[85] P. Qiu, C. Wu, X. Zhang, W. Lin, H. Wang, Y. Zhang, Y. Wang, DataExtraction byLargeLanguageModels,”arXiv.org,2023.\nand W. Xie, “Towards Building Multilingual Language Model for\n[106] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian\nMedicine,” 2024.\nLiu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng\n[86] Y. Khare, V. Bagal, M. Mathew, A. Devi, U. D. Priyakumar, and Gao,“Llava-Med:TrainingaLargeLanguage-and-VisionAssistantfor\nC. Jawahar, “Mmbert: Multimodal BERT Pretraining for Improved Biomedicine in One Day,” Neural Information Processing Systems,\nMedical VQA,” in 2021 IEEE 18th International Symposium on 2023.\nBiomedical Imaging(ISBI). IEEE,apr132021. [107] Z.Bi,S.A.Dip,D.Hajialigol,S.Kommu,H.Liu,M.Lu,andX.Wang,\n[87] N.H.Shah,D.Entwistle, andM.A.Pfeffer, “Creation andAdoption “AiforBiomedicine intheEraofLargeLanguageModels,”2024.\nof Large Language Models in Medicine,” JAMA, vol. 330, no. 9, p. [108] Dyke Ferber, O. S. E. Nahhas, Georg Wo¨lflein, Isabella C. Wiest, J.\n866,sep52023. Clusmann,Marie-ElisabethLessman,S.Foersch,JacquelineLammert,\n[88] K. He, R. Mao, Q. Lin, Y. Ruan, X. Lan, M. Feng, and E. Cambria, Maximilian Tschochohei, Dirk Ja¨ger, Manuel Salto-Tellez, Nikolaus\n“A Survey of Large Language Models for Healthcare: from Data, Schultz,DanielTruhn,andJ.N.Kather,“AutonomousArtificialIntel-\nTechnology, andApplications toAccountability andEthics,”2023. ligenceAgentsforClinical DecisionMakinginOncology,”arXiv.org,\n[89] J.Clusmann,F.R.Kolbinger,H.S.Muti,Z.I.Carrero,J.-N.Eckardt, 2024.\nN. G. Laleh, C. M. L. Lo¨ffler, S.-C. Schwarzkopf, M. Unger, G. P. [109] Z.Liu,A.Zhong,Y.Li,L.Yang,C.Ju,Z.Wu,C.Ma,P.Shu,C.Chen,\nVeldhuizen, S. J.Wagner, andJ.N. Kather, “Thefuture landscape of S. Kim, H. Dai, L. Zhao, L. Sun, D. Zhu, J. Liu, W. Liu, D. Shen,\nlargelanguagemodelsinmedicine,”CommunicationsMedicine,vol.3, X.Li,Q.Li,andT.Liu,“Radiology-GPT: ALargeLanguage Model\nno.1,oct102023. forRadiology,” 2023.\n[90] A. M. Bean, K. Korgul, F. Krones, R. McCraith, and A. Mahdi, [110] Q.Xie,Q.Chen,A.Chen,C.Peng,Y.Hu,F.Lin,X.Peng,J.Huang,\n“Exploringthelandscapeoflargelanguagemodelsinmedicalquestion J.Zhang,V.Keloth,X.Zhou,H.He,L.Ohno-Machado,Y.Wu,H.Xu,\nanswering,” 2023. and J. Bian, “Me-LLaMA: Foundation Large Language Models for\n[91] Francois Barnard, Marlize Van Sittert, and Siri J. Rambhatla, “Self- Medical Applications,” may222024.\nDiagnosis and Large Language Models: A New Front for Medical [111] J.B.Longwell,I.Hirsch,F.Binder,G.A.GonzalezConchas,D.Mau,\nMisinformation,” arXiv.org,2023. R. Jang, R. G. Krishnan, and R. C. Grant, “Performance of Large\nLanguage Models on Medical Oncology Examination Questions,”\nJAMANetworkOpen,vol.7,no.6,p.e2417641, jun182024.\n[112] Meiqi Chen, Yixin Cao, Yan Zhang, and Chaochao Lu, “Quantifying\nandMitigatingUnimodalBiasesinMultimodalLargeLanguageMod-\nels:ACausalPerspective,” arXiv.org,2024.\n[113] Y.Huang,K.Tang,M.Chen,andB.Wang,“AComprehensiveSurvey\non Evaluating Large Language Model Applications in the Medical\nIndustry,”2024.",
    "pdf_filename": "From_Text_to_Multimodality_Exploring_the_Evolution_and_Impact_of_Large_Language_Models_in_Medical_Pr.pdf"
}