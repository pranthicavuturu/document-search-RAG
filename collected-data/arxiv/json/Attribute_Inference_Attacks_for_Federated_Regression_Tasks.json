{
    "title": "Attribute Inference Attacks for Federated Regression Tasks",
    "abstract": "FederatedLearning(FL)enablesmultipleclients,suchasmo- bilephonesandIoTdevices,tocollaborativelytrainaglobal machine learning model while keeping their data localized. However,recentstudieshaverevealedthatthetrainingphase ofFLisvulnerabletoreconstructionattacks,suchasattribute inferenceattacks(AIA),whereadversariesexploitexchanged messagesandauxiliarypublicinformationtouncoversensi- tive attributes of targeted clients. While these attacks have beenextensivelystudiedinthecontextofclassificationtasks, theirimpactonregressiontasksremainslargelyunexplored. Inthispaper,weaddressthisgapbyproposingnovelmodel- basedAIAsspecificallydesignedforregressiontasksinFL environments. Our approach considers scenarios where ad- Figure1:AverageperformanceofdifferentAIAswhenfour versaries can either eavesdrop on exchanged messages or clients train a neural network through FedAvg with 1 local directly interfere with the training process. We benchmark epochandbatchsize32.Eachclientstores|D |datapoints our proposed attacks against state-of-the-art methods using c randomly sampled from ACS Income dataset (Ding et al. real-worlddatasets.Theresultsdemonstrateasignificantin- 2024).Theadversaryinfersthegenderattributeofeverydata crease in reconstruction accuracy, particularly in heteroge- neousclientdatasets,acommonscenarioinFL.Theefficacy sampleheldbytheclientgivenaccesstothereleased(pub- of our model-based AIAs makes them better candidates for lic)information. empiricallyquantifyingprivacyleakageforfederatedregres- siontasks. explored for regression tasks, which are, needless to say, 1 Introduction equally important for practical applications. Quite surpris- Federated learning (FL) enables multiple clients to collab- ingly,ourexperiments,asshowninFig.1,demonstratethat oratively train a global model (McMahan et al. 2017; Lian the accuracy of state-of-the-art gradient-based AIA under et al. 2017; Li et al. 2020). Since clients’ data is not col- a honest-but-curious adversary (Lyu and Chen 2021; Chen lectedbyathirdparty,FLnaturallyoffersacertainlevelof etal.2022)(referredtoaspassive)dropssignificantlyfrom privacy.Nevertheless,FLalonedoesnotprovideformalpri- 71%onaclassificationtaskto50%(randomguess)onare- vacy guarantees, and recent works have demonstrated that gression task once the targeted client holds more than 256 clients’ private information can still be easily leaked (Lyu datapoints.Furthermore,evenamorepowerful(active)ad- et al. 2020; Liu, Xu, and Wang 2022). For instance, an ad- versarycapableofforgingthemessagestothetargetedclient versarywithaccesstotheexchangedmessagesandknowl- toextractmoreinformation(LyuandChen2021;Chenetal. edgeofsomepublicinformation(e.g.,client’sprovidedrat- 2022) offers only limited improvement to the AIA perfor- ings) (Lyu and Chen 2021; Chen et al. 2022; Feng et al. mance on regression tasks. Detailed information about this 2021) can reconstruct a client’s sensitive attributes (e.g., experimentisinAppendixB.1. gender/religion) in an attack known as attribute inference Inthispaper,weshowthatfederatedtrainingofregression attack (AIA). Additionally, the adversary can reconstruct tasksdoesnotinherentlyenjoyhigherprivacy,butitissim- client’s training samples such as images (Geiping et al. plymorevulnerabletootherformsofattacks.Whileexisting 2020;Yinetal.2021). FL AIA attacks for classification tasks are gradient-based However, these reconstruction attacks for FL have pri- (see Sec. 2.3), we show that model-based AIAs—initially marilybeentestedonclassificationtasksandhavenotbeen proposed for centralized training (Fredrikson et al. 2014; 4202 voN 91 ]GL.sc[ 1v79621.1142:viXra",
    "body": "Attribute Inference Attacks for Federated Regression Tasks\nFrancescoDiana1,OthmaneMarfoq2,ChuanXu1,3,4,5,GiovanniNeglia1,3,Fre´de´ricGiroire1,3,4,5,\nEoinThomas6\n1INRIA\n2Meta\n3Universite´ Coˆted’Azur\n4CNRS\n5I3S\n6Amadeus\nfrancesco.diana@inria.fr,omarfoq@meta.com,chuan.xu@inria.fr,giovanni.neglia@inria.fr,frederic.giroire@inria.fr,\neoin.thomas@amadeus.com\nAbstract\nFederatedLearning(FL)enablesmultipleclients,suchasmo-\nbilephonesandIoTdevices,tocollaborativelytrainaglobal\nmachine learning model while keeping their data localized.\nHowever,recentstudieshaverevealedthatthetrainingphase\nofFLisvulnerabletoreconstructionattacks,suchasattribute\ninferenceattacks(AIA),whereadversariesexploitexchanged\nmessagesandauxiliarypublicinformationtouncoversensi-\ntive attributes of targeted clients. While these attacks have\nbeenextensivelystudiedinthecontextofclassificationtasks,\ntheirimpactonregressiontasksremainslargelyunexplored.\nInthispaper,weaddressthisgapbyproposingnovelmodel-\nbasedAIAsspecificallydesignedforregressiontasksinFL\nenvironments. Our approach considers scenarios where ad- Figure1:AverageperformanceofdifferentAIAswhenfour\nversaries can either eavesdrop on exchanged messages or\nclients train a neural network through FedAvg with 1 local\ndirectly interfere with the training process. We benchmark\nepochandbatchsize32.Eachclientstores|D |datapoints\nour proposed attacks against state-of-the-art methods using c\nrandomly sampled from ACS Income dataset (Ding et al.\nreal-worlddatasets.Theresultsdemonstrateasignificantin-\n2024).Theadversaryinfersthegenderattributeofeverydata\ncrease in reconstruction accuracy, particularly in heteroge-\nneousclientdatasets,acommonscenarioinFL.Theefficacy sampleheldbytheclientgivenaccesstothereleased(pub-\nof our model-based AIAs makes them better candidates for lic)information.\nempiricallyquantifyingprivacyleakageforfederatedregres-\nsiontasks.\nexplored for regression tasks, which are, needless to say,\n1 Introduction equally important for practical applications. Quite surpris-\nFederated learning (FL) enables multiple clients to collab- ingly,ourexperiments,asshowninFig.1,demonstratethat\noratively train a global model (McMahan et al. 2017; Lian the accuracy of state-of-the-art gradient-based AIA under\net al. 2017; Li et al. 2020). Since clients’ data is not col- a honest-but-curious adversary (Lyu and Chen 2021; Chen\nlectedbyathirdparty,FLnaturallyoffersacertainlevelof etal.2022)(referredtoaspassive)dropssignificantlyfrom\nprivacy.Nevertheless,FLalonedoesnotprovideformalpri- 71%onaclassificationtaskto50%(randomguess)onare-\nvacy guarantees, and recent works have demonstrated that gression task once the targeted client holds more than 256\nclients’ private information can still be easily leaked (Lyu datapoints.Furthermore,evenamorepowerful(active)ad-\net al. 2020; Liu, Xu, and Wang 2022). For instance, an ad- versarycapableofforgingthemessagestothetargetedclient\nversarywithaccesstotheexchangedmessagesandknowl- toextractmoreinformation(LyuandChen2021;Chenetal.\nedgeofsomepublicinformation(e.g.,client’sprovidedrat- 2022) offers only limited improvement to the AIA perfor-\nings) (Lyu and Chen 2021; Chen et al. 2022; Feng et al. mance on regression tasks. Detailed information about this\n2021) can reconstruct a client’s sensitive attributes (e.g., experimentisinAppendixB.1.\ngender/religion) in an attack known as attribute inference Inthispaper,weshowthatfederatedtrainingofregression\nattack (AIA). Additionally, the adversary can reconstruct tasksdoesnotinherentlyenjoyhigherprivacy,butitissim-\nclient’s training samples such as images (Geiping et al. plymorevulnerabletootherformsofattacks.Whileexisting\n2020;Yinetal.2021). FL AIA attacks for classification tasks are gradient-based\nHowever, these reconstruction attacks for FL have pri- (see Sec. 2.3), we show that model-based AIAs—initially\nmarilybeentestedonclassificationtasksandhavenotbeen proposed for centralized training (Fredrikson et al. 2014;\n4202\nvoN\n91\n]GL.sc[\n1v79621.1142:viXra\nKasiviswanathan, Rudelson, and Smith 2013; Yeom et al. Algorithm1:FLFramework\n2018)—maybemoreeffectiveforregressiontasks.Figure1 Output:θT\nillustrates that a model-based attack on the server’s global\nServers:\nmodel(i.e.,thefinalmodeltrainedthroughFL)alreadyper-\n1: fort∈{0,...,T −1}do\nformsatleastaswellastheSOTAgradient-basedpassiveat- 2: sselectsasubsetoftheclientsCt ⊆C,\ns\ntack.Moreover,ithighlightsthatevenmorepowerfulattacks 3: sbroadcaststheglobalmodelθttoCt,\ns\n(upto30p.p.moreaccurate)couldbelaunchediftheadver- 4: swaitsfortheupdatedmodelsθtfromeveryclientc∈Ct,\nc s\nsary had access to the optimal local model of the targeted 5: scomputesθt+1byaggregatingthereceivedupdatedmod-\nclient(i.e.,amodeltrainedonlyontheclient’sdataset). els.\nClientc∈C:Inputθ,Outputθ\nc\nMotivatedbytheseobservations,weproposeanewtwo- 6: whileFLtrainingisnotcompleteddo\nstepmodel-basedAIAforfederatedregressiontasks.Inthis 7: clistensforthearrivalofnewglobalmodelθ,\nattack, the adversary first (approximately) reconstructs the 8: cupdatesitslocalmodel:θ ←Local Updatec(θ,D )\nc c\nclient’s optimal local model and then applies an existing 9: csendsbackθ totheserver.\nc\nmodel-basedAIAtothatmodel.\nOurmaincontributionscanbesummarizedasfollows:\nAlgorithm 2: Client c’s local update rule\n• We provide an analytical lower bound for model-based (Local Updatec(θt,D )) in FedAvg (McMahan et al.\nc\nAIA accuracy in the least squares regression problem. 2017)\nThisresultmotivatestheadversary’sstrategytoapproxi- Input:servermodelθt,localdatasetD ,batchsizeB,numberof\nc\nmatetheclient’soptimallocalmodelinfederatedregres- localepochsE,learningrateη.\nsiontasks.(Sec.3). 1: θt(0)←θt,B←(splitD intobatchesofsizeB),k←0\nc c\n2: foreachlocalepochefrom1toEdo\n• We propose methods for approximating optimal local 3: forbatchb∈Bdo\nm cho ad ne gl es dw mh ee sr se aga ed sve or rsa dr ii re es ctc lyan ine teit rh fe er ree wav ie thsd tr ho ep tro an inie nx g- 4: θ gct (( θk ct(k+ ),1 b) )=←\nB1\n(cid:80)θ ct x( ∈k b) ∇− ℓ(θη ct(× k),g x( )θ ct(k),b), where\nprocess(Sec.4). 5: k←k+1\n6: Returnθt(K),whereK =E⌈Sc⌉\nc B\n• Our experiments show that our model-based AIAs are\nb lee at kte ar geca fon rd fid edat ee rs atef dor ree gm rep si sr ii oc nal tl ay skq su (a Sn et cif .y 5i )n .g privacy Let θ∗ = argmin θ∈RdL(θ) be a global optimal model,\ni.e., a minimizer of Problem (1). A general framework to\nlearn such a global model in a federated way is shown\nin Algorithm 1; it generalizes a large number of FL al-\n2 Preliminaries gorithms, including FedAvg (McMahan et al. 2017), Fed-\nProx (Li et al. 2020), and FL with different client sam-\nplingtechniques(NishioandYonetani2019;Chen,Horvath,\n2.1 Federatedlearning and Richtarik 2020; Jee Cho, Wang, and Joshi 2022). The\nmodel θT—the output of Algorithm 1—is the tentative so-\nlution of Problem (1). Its performance depends on the spe-\nWe denote by C the set of all clients participating to FL.\ncific FL algorithm, which precises how clients are selected\nLet D = {(x (i),y (i)),i = 1,...,S } denote the local\nc c c c in line 2, how the updated local models are aggregated in\ndatasetofclientc ∈ C withsizeS ≜ |D |.Eachdatasam-\nc c line5,andhowthelocalupdateruleworksinline8.Forex-\nple (x (i),y (i)) is a pair consisting of an input x (i) and\nc c c ample,inFedAvg,clientsareselecteduniformlyatrandom\nofanassociatedtargetvaluey (i).InFL,clientscooperate\nc among the available clients, the local models are averaged\ntolearnaglobalmodel,whichminimizesthefollowingem-\nwithconstantweights,andtheclientsperformlocallymul-\npiricalriskoverallthedataownedbyclients:\ntiplestochasticgradientsteps(Algorithm2).\n(cid:88) 2.2 ThreatModel\nminL(θ)= p L (θ,D )\nc c c\nθ∈Rd\nc∈C Honest-but-curious adversary We describe first an\n(cid:88)\n(cid:32)\n1\n(cid:88)Sc (cid:33) honest-but-curious adversary,1 which is a standard threat\n= p ℓ(θ,x (i),y (i)) . (1) modelinexistingliterature(Melisetal.2019;Geipingetal.\nc S c c\nc 2020;Yinetal.2021;Nasr,Shokri,andHoumansadr2019),\nc∈C i=1\nincluding the FL one (Kairouz et al. 2021, Table 7), (Lyu\nand Chen 2021; Chen et al. 2022). This passive adversary,\nwhereℓ(θ,x (i),y (i))measuresthelossofthemodelθon\nc c who could be the server itself, is knowledgeable about the\nthesample(x (i),y (i))∈D andp isthepositiveweight\nc c c c\n(cid:80)\nofclientc,s.t., p = 1.Commonchoicesofweights\nc∈C c 1Inwhatfollows,werefertotheclientusingfemalepronouns\narep c = |C1 | orp c = (cid:80) cS ∈c CSc. andtheadversaryusingmalepronouns,respectively.\ntrained model structure, the loss function, and the train- restofthepaper.\ning algorithm, and may eavesdrop on communication be-\ntween the attacked client and the server but does not inter- 2.3 Attributeinferenceattack(AIA)forFL\nferewiththetrainingprocess.Forinstance,duringtraining AIAleveragespublicinformationtodeduceprivateorsensi-\nround t, the adversary can inspect the messages exchanged tiveattributes(Kasiviswanathan,Rudelson,andSmith2013;\nbetween the server and the attacked client (denoted by c), Lyu and Chen 2021; Chen et al. 2022; Fredrikson et al.\nallowinghimtorecovertheparametersoftheglobalmodel 2014;Yeometal.2018).Forexample,anAIAcouldrecon-\nθt and the updated client model θt(K) (Algorithm 2). Let structauser’sgenderfromarecommendermodelbyhaving\nc\nT ⊆ {t|c ∈ Ct,∀t ∈ 0,...,T −1}denotethesetofcom- access to the user’s provided ratings. Formally, each input\nc s\nmunicationroundsduringwhichtheadversaryinspectsmes- x (i) of client c consists of public attributes xp(i) and of\nc c\nsagesexchangedbetweentheserverandtheattackedclient a sensitive attribute s (i). The target value, assumed to be\nc\nandM ={(θt,θt),∀t∈T }denotethecorrespondingset public,isdenotedbyyp(i).Theadversary,havingaccessto\nc c c c\nofmessages. {(xp(i),yp(i)),i = 1,...,S }andM ,aimstorecoverthe\nc c c c\nWhen it comes to defenses against such an adversary, sensitiveattributess c(i).2\nit is crucial to understand that traditional measures like\nExisting gradient-based AIA for FL Chen et al. (2022)\nencrypted communications are ineffective if the attacker\npresent AIAs specifically designed for the FL context and\nis the FL server. More sophisticated cryptographic tech-\nboth passive and active adversaries. The central idea in-\nniques like secure aggregation protocols (Bonawitz et al.\nvolvesidentifyingsensitiveattributevaluesthatyieldvirtual\n2017; Kadhe et al. 2020) allow the server to aggregate lo-\ngradients closely resembling the client’s model updates—\ncalupdateswithouthavingaccesstoeachindividualupdate\nreferredtoaspseudo-gradients—intermsofcosinesimilar-\nand, then, do hide the client’s updated model θt from the\nc ity. Formally, the adversary solves the following optimiza-\nserver. Nevertheless, they come with a significant compu-\ntionproblem:\nt sa pt aio rsn eo vv ee cr th oe ra ad gg(Q reu go ac tioe nt (a Kl. a2 ir0 o2 u0 z) ea tn ad l.a 2r 0e 2i 1n )e .f Mfic oie ren ot vf eo rr\n, argmax\n(cid:88) CosSim(cid:18) ∂ℓ(θt,{(xp c(i),s c(i),y cp(i))}) ,θt−θt(cid:19)\n,\nthey are vulnerable to poisoning attacks, as they hinder the {sc(i)}S i=c 1t∈T\n∂θt c\nserver from detecting (and removing) potentially harmful (2)\nupdates from malicious clients (Blanchard et al. 2017; Yin whereT ⊆T forapassiveadversaryandT ⊆T ∪Tafor\nc c c\net al. 2018; El Mhamdi 2020). For instance, Trame`r et al. anactiveadversary.Theactiveadversarysimplysendsback\n(2022,Sec.4.4)introduceanewclassofdatapoisoningat- tothetargetedclientcherownmodelθ(t−1) ateachattack\nc\ntacks that succeed when training models with secure mul- roundinTa.\ntipartycomputation.Alternatively,TrustedExecutionEnvi- c\nChen et al. (2022) assume that the sensitive attributes\nronments(TEEs) (Sabt,Achemlal,andBouabdallah2015;\nare categorical and discrete random variables. Neverthe-\nSingh et al. 2021) provide an encrypted memory region to\nless, problem (2) can be solved efficiently using a gradient\nensure the code has been executed faithfully and privately.\nmethod with the reparameterization trick and the Gumbel\nThey can then both conceal clients’ updated models and\nsoftmaxdistribution(Jang,Gu,andPoole2017).From(2),\ndefend against poisoning attacks. However, implementing\nwe observe that, since gradients incorporate information\na reliable TEE platform in FL remains an open challenge\nfromallsamples,theattackperformancedeterioratesinthe\ndue to the infrastructure resource constraints and the re-\npresenceofalargelocaldataset.Forexample,theattackac-\nquiredcommunicationprocessesneededtoconnectverified\ncuracy almost halves on the Genome dataset for the clas-\ncodes(Kairouzetal.2021).\nsification task when the client’s local dataset size increases\nfrom50to1000samples(LyuandChen2021,Table8).Our\nMalicious adversary We also consider a stronger ac-\nexperiment(Figure1)onaregressiontaskcorroboratesthis\ntive adversary who can interfere with the training process.\nfinding:whenthelocaldatasetsizeincreasesfrom64to256,\nSpecifically, this adversary can modify the messages sent\ntheattackaccuracydropsfrom60%tothelevelofrandom\nto the clients and have the clients update models θt con-\nguessing.\ncocted to reveal more private information. Let Ta be the\nc\nsetofroundsduringwhichtheadversaryattacksclientcby Model-based AIA As an alternative, the AIA can be ex-\nsendingmaliciousmodelθt.Asabove,theadversarycould ecuted directly on the model (rather than on the model\nbetheserveritself.Thisadversaryhasbeenwidelyconsid- pseudo-gradients), as initially proposed for centralized\nered in the literature on reconstruction attacks (Wen et al. training in (Kasiviswanathan, Rudelson, and Smith 2013;\n2022; Boenisch et al. 2023) and membership inference at- Fredriksonetal.2014).Givenamodelθ,theadversarycan\ntacks (Nguyen et al. 2023; Nasr, Shokri, and Houmansadr infer the sensitive attributes by solving the following opti-\n2019).Somestudieshavealsoexploredthepossibilityofa mizationproblems:\nmalicious adversary modifying the model architecture dur- argminℓ(θ,(xp(i),s (i),yp(i))), ∀i∈{1,...,S }, (3)\nc c c c\ningtraining(Fowletal.2022;Zhaoetal.2023),eventhough sc(i)\nsuchattacksappeartobeeasilydetectable.Inthispaper,we\n2In (Fredrikson et al. 2014; Yeom et al. 2018), the adver-\ndonotallowtheadversarytomodifythemodelarchitecture.\nsary possesses additional information, including estimates of the\nFor simplicity, we will refer to these two adversaries as marginalsorthejointdistributionofthedatasamples.However,in\npassive and active adversaries, respectively, throughout the thispaper,wedonotconsidersuchamorepowerfuladversary.\nBelowweprovidetheoreticalguarantees(Prop.1)forthe Algorithm 3: Reconstruction of client-c local model by a\naccuracy of the model-based AIAs to least squares regres- passiveadversaryforfederatedleastsquaresregression\nsionproblems.OurtheoreticalresultsupportsthatinanFL Input:theservermodelsθti(0) = θti(0)andthelocalup-\nc\nsetting,theadversarymayadvantageouslystartbyestimat- datedmodelsθ cti(K)atalltheinspectedroundst\ni\n∈ T\nc\n=\ningtheclient’soptimallocalmodel,i.e.,themodelthatmin- {t ,t ,...,t }.\nimizestheclient’sempiricalloss.\n1 2 nc\n1: LetΘ\nin\n=[θ ct1(0) θ ct2(0) ... θ ctnc(0)]T ∈Rnc×d\n3 Model-basedAIAguaranteesforleast\n (θ ct1(0)−θ ct1(K))T 1 \n.\nsquaresregression. 2: LetΘ out =  . .  ∈Rnc×(d+1)\nIn this section, we provide novel theoretical guarantees for\n(θ\nctnc(0)−θ ctnc(K))T\n1\nthe accuracy of the model-based AIA (Problem (3)) in the 3: (θˆ∗)T ←lastrowof(cid:0) (ΘT Θ )†ΘT Θ (cid:1)\nc out out out in\ncontext of least squares regression. In particular, we show\n4:\nReturnθˆ∗astheestimatorforclientc’slocalmodel\nc\nthat the better the model θ fits the local data and the more\nthesensitiveattributeaffectsthefinalprediction,thehigher\ntheAIAaccuracy.\nProposition 1 indicates that the model-based AIA per-\nProposition1. LetE c bethemeansquareerrorofagiven formsbetterthemorethemodeloverfitsthedataset.Thisob-\nleast squares regression model θ on the local dataset of servationjustifiesthefollowingtwo-stepattackinaFLset-\nclientcandθ[s]bethemodelparametercorrespondingtoa ting:theadversaryfirstreconstructstheoptimallocalmodel\nbinarysensitiveattribute.Theaccuracyofthemodel-based of the targeted client c, i.e., θ∗ = argmin L (θ,D ),\nc θ∈Rd c c\nAIA(3)islargerthanorequalto1− 4Ec . andthenexecutetheAIAin(3)onthereconstructedmodel.3\nθ[s]2\nIn the following, we will detail our approaches for recon-\nProof. Lets bethevectorincludingalltheunknownsensi- structing the optimal local model by passive and active ad-\nc\ntivebinaryattributes{s (i),∀i∈{1,...,S }}ofclientc.Let versary,respectively.\nc c\nx\nc\n∈RSc×dbethedesignmatrixwithrankdandy\nc\n∈RSc\nbe the labels in the local dataset D of the client c. Let 4 ReconstructingthelocalmodelinFL\nc\nθ[:p]∈Rd−1betheparameterscorrespondingtothepublic\nIn this section, we show how an adversary may recon-\nattributes.Theadversaryhasaccesstopartialdatainstances struct the optimal local model of client c, i.e., θ∗ =\nain ndD tc hw eh coic rh rec so pn os ni dst is ngof lath be elp su yb cli ∈ca Rtt Sri cb .utesP∈RSc×(d−1) arg Fim rsi tn ,θ w∈ eRd pL roc v( iθ d, eD ac n).\nefficient approach for least\nsqc\nuares\nThe goalfor the adversaryis to decodethe values of the regressionunderapassiveadversary.Weprovethatthead-\nbinary sensitive attribute s c ∈ {0,1}Sc given (P,y c) by versarycanexactlyreconstructtheoptimallocalmodelun-\nsolving (3), i.e., checking for each point, which value for derdeterministicFLupdatesandprovideprobabilisticguar-\nthesensitiveattributeleadstoasmallerloss. antees on the reconstruction error under stochastic FL up-\nIt is easy to check that the problem can be equivalently dates(Sec.4.1).\nsolved through the following two-step procedure. First, the Second,weshowthatanactiveadversarycanpotentially\nadversarycomputesthevectorofrealvalues: reconstructanyclient’slocalmodel(notjustleastsquarere-\ngressionones)inafederatedsetting(Sec.4.2).\ny −Pθ[:p]\n˜s =argmin||Pθ[:p]+s θ[s]−y ||2 = c .\nc sc∈RSc c c 2 θ[s] 4.1 Passiveapproachforlinearleastsquares\nWe consider thatclients cooperatively train a linear regres-\nThen, the adversary reconstruct the vector of sensitive fea-\nturesˆs\nc\n∈{0,1}Sc asfollows sionmodelwithquadraticloss.Werefertothissettingasa\nfederated least squares regression. The attack is detailed in\n(cid:26) 0 ifs˜ (i)< 1 Alg.3andinvolvesasinglematrixcomputation(line3)after\nsˆ c(i)=\n1\nothec\nrwise\n2 , ∀i∈{1,...,S c}. (4) the exchanged messages M\nc\nhave been collected. A† rep-\nresentsthepseudo-inverseofmatrixA.Theorem1provides\nLetebethevectorofresidualsforthelocaldataset,i.e., theoretical guarantees for the distance between the recon-\ne =y −(Pθ[:p]+s θ[s]).Wehavethen structedmodelandtheoptimallocalone,whenthemodelis\nc c c\ntrained through FedAvg (McMahan et al. 2017) with batch\ny −Pθ[:p]−e e sizeBandlocalepochsE.Theformalstatementofthethe-\ns = c c =˜s − c . (5)\nc θ[s] c θ[s] oremanditsproofareinAppendixA.1.\nTheorem 1 (Informal statement). Consider a federated\nLetussaythatthesensitivefeatureofsampleihasbeen\nleastsquaresregressionwithalargenumberofclientsand\nper lr ieo sne to hu atsl |y sr (e ic )on −str s˜uc (ite )d |, ≥i.e. 1, /s 2c ,(i a) n̸=\nd\nfsˆ rc o( mi), (5th )e in t( f4 o) l, loim ws- assumethati)clientchasd-rankdesignmatrixx\nc\n∈RSc×d,\nc c\nthat |e c(i)|2 ≥ θ[s]2/4. As E cS c = ∥e c∥2 2, there can be at 3Notethatthismodelisoptimalintermsofthetrainingerror,\nmost4E cS c/θ[s]2 sampleserroneouslyreconstructed,from butnotingeneralofthefinaltesterror.Onthecontrary,itislikely\nwhichwecanconcludetheresult. tooverfitthelocaldataset.\nii)sheupdatestheglobalmodelthroughstochasticgradient Algorithm 4: Reconstruction of client-c local model by an\nstepswithsub-Gaussiannoisewithscaleσandsmalllearn- activeadversarya\ningrateη,andiii)thelocaldatadistributionofthetargeted Input: Let Ta be set of rounds during which the adver-\nc\nclientisdifferentfromtheglobaldatadistribution.Byeaves- saryattacksclientcandθa bethecorrespondingmalicious\nc\ndroppingonn c >dmessageexchangesbetweenclientcand model.\ntheserver,theerrorofthereconstructedmodelθˆ c∗ ofAlgo- 1: θ ca ←latestmodelreceivedfromclientc\nrithm3isupperboundedw.p.≥1−δwhenη ≤ Sc 2: fort∈Tado\nand\n2λmax(xT cxc)\n3:\nasendsc\nthemodelθatoclientc,\nc\n (cid:115)  4: awaitstheupdatedmodelfromθ cfromclientc,\n(cid:13) (cid:13) (cid:13)θˆ c∗−θ c∗(cid:13) (cid:13) (cid:13)\n2\n=Oησd E(cid:24) S Bc(cid:25)d+ n1 c+ ·λln2 δd . (6) 5: a θ caco anm dpu thte es ct oh re rep ss pe ou nd do i- ng gra mdi oe mnt eθ nca t v− ecθ tc ora sn fd ou llp od wa it ne gs\nAdam(KingmaandBa2015,Alg.1),\n6: Returnθaastheestimatorforclientc’slocalmodel\nWhen the batch size is equal to the local dataset size, c\nAlg. 3 exactly reconstructs the optimal local model (proof\ninAppendixA.2):\n4.2 Activeapproach\nProposition 2. Consider a federated least squares regres-\nsionandassumethatclientchasd-rankdesignmatrixand Hereweconsideranactiveadversary(e.g.,theserveritself)\nupdates the global model through full-batch gradient up- thatcanmodify theglobalmodelweights θt torecoverthe\ndates (i.e., B = S ) and an arbitrary number of local client’s optimal local model. To achieve this, the adversary\nc\nepochs. Once the adversary eavesdrops on d + 1 commu- cansimplysendbacktothetargetedclientcherownmodel\nnication exchanges between client c and the server, it can θ(t−1)insteadoftheaveragedmodelθt.Inthisway,clientc\nc\nrecovertheclient’soptimallocalmodel. isledtocomputeherownoptimallocalmodel.\nFinally, the following proposition shows that our attack We propose a slightly more sophisticated version of this\nforthefull-batchgradientcaseisorder-optimalintermsof activeattack.Specifically,wesuggestthattheadversaryem-\nthe number of messages the adversary needs to eavesdrop. ulates the Adam optimization algorithm (Kingma and Ba\nTheproofisinAppendixA.3. 2015) for the model updated by client c by adjusting the\nlearningrateforeachparameterbasedonthemagnitudeand\nProposition 3. Consider that the federated least squares\nhistoryofthegradients,andincorporatingmomentum.The\nregression is trained through FedAvg with one local step\nmotivationistwofold.First,theclientdoesnotreceiveback\n(E = 1)andfullbatch(B = S foreachclientc ∈ C).At\nc exactlythesamemodelandthuscannoteasilydetecttheat-\nleast one client is required to communicate with the server\ntack.Second,Adamisknowntominimizethetrainingerror\nΩ(d) times for the global model to be learned, and the ad-\nfasterthanstochasticgradientdescentatthecostofoverfit-\nversaryneedstoeavesdropatleastΩ(d)messagesfromthis\ntingmoretothetrainingdata(Zhouetal.2020b;Zouetal.\nclienttoreconstructheroptimallocalmodel.\n2023). We can then expect Adam to help the adversary re-\nToy example illustration Here, we illustrate the perfor- constructtheclient’soptimallocalmodelbetterforagiven\nmance of our Alg. 3 on a toy dataset detailed in Ap- numberofmodifiedmessages,andourexperimentsinSec.5\npendix B.2. Figure 2 (left) demonstrates that as the batch confirmthatthisisthecase.\nsize increases, the reconstructed model is closer to the op- The details of this attack are outlined in Alg. 4. We ob-\ntimal local model (as shown in our Theorem 1). Moreover, serve that the adversary does not need to systematically\nsincethemodeloverfitsmorethedataset(withsmallerloss), modifyallmessagessenttothetargetclientcbutcanmodify\ntheAIAaccuracyincreases(Figure2(right)). justahandfulofmessagesthatarenotnecessarilyconsecu-\ntive.Thiscontributestothedifficultyofdetectingtheattack.\n5 Experiments\n5.1 Datasets\nMedical (Lantz 2013). This dataset includes 1,339\nrecords and 6 features: age, gender, BMI, number of chil-\ndren, smoking status, and region. The regression task is to\npredict each individual’s medical charges billed by health\ninsurance.Thedatasetisspliti.i.d.between2clients.\nFigure 2: The performance of our passive approach for re-\nconstructing optimal local model (left) and the triggered Income (Ding et al. 2024). This dataset contains census\nAIA(right)onatoydatasetwithtwoclientstrainingalinear information from 50 U.S. states and Puerto Rico, spanning\nmodelwithsized = 11underbatchsize64,256and1024 from2014to2018.Itincludes15featuresrelatedtodemo-\nfor 5 seeds each, respectively. The passive adversary only graphicinformationsuchasage,occupation,andeducation\neavesdroppedd+1messages. level. The regression task is to predict an individual’s in-\ncome. We investigate two FL scenarios, named Income-L\nand Income-A, respectively. In Income-L, there are 10 Model-based with Oracle (Model-w-O): To provide an\nclients holding only records from the state of Louisiana upper bound on the performance of our approach, we as-\n(15,982recordsintotal).Theseclientscanbeviewedasthe sume the existence of an oracle that provides the optimal\nlocal entities working for the Louisiana State Census Data local model for the first step of our attack. In practice, the\nCenter.Weexaminevariouslevelsofstatisticalheterogene- optimal local model is determined empirically by running\nityamongtheselocalentities,withthesplittingstrategyde- Adamforaverylargenumberofiterations.\ntailed in Appendix B.3. In Income-A, there are 51 clients,\neachrepresentingacensusregionandcollectivelycovering 5.4 Experimentalresults\nall regions. Every client randomly selects 20% of the data\npoints from the corresponding census region, resulting in a Datasets\nIncome-L Income-A Medical\ntotalof332,900records. AIA(%)\nForallthedatasets,eachclientkeeps90%ofitsdatafor Grad 60.36±0.67 54.98±0.29 87.26±0.92\ntraininganduses10%forvalidation. Passive Grad-w-O 71.44±0.33 56.10 ±1.12 91.06±0.55\nOurs 75.27 ±0.32 55.75±0.17 95.90 ±0.04\n5.2 FLtrainingandattacksetup\nActive\nGrad 60.24±0.60 54.98±0.29 87.26±0.92\nInalltheexperiments,eachclientfollowsFedAvg(Alg.2) (10Rnds)\nGrad-w-O 80.69±0.55 56.10±1.12 91.06±0.55\ntotrainaneuralnetworkmodelwithasinglehiddenlayerof Ours 82.02 ±0.85 63.53 ±0.73 95.93 ±0.07\n128 neurons, using ReLU as activation function. The num- Active Grad 60.24±0.60 53.36±0.40 87.26±0.92\nber of communication rounds is fixed to T = ⌈100/E⌉ (50Rnds) Grad-w-O 80.69±0.55 56.12±0.12 91.06±0.55\nwhere E is the number of local epochs. Each client partic- Ours 94.31 ±0.11 78.09 ±0.25 96.79 ±0.79\nipatestoallrounds,i.e.,T\nc\n= {0,...,T −1}.Thelearning Model-w-O 94.31±0.11 78.31±0.07 96.79±0.79\nrate is tuned for each training scenario (different datasets\nand number of local epochs), with values provided in Ap- Table 1: The AIA accuracy over all clients’ local datasets\npendix B.4. The passive adversary may eavesdrop all the evaluatedunderbothhonest-but-curious(passive)andmali-\nexchanged messages until the end of the training. The ac- cious (active) adversaries across Income-L, Income-A, and\ntiveadversarylaunchestheattackafterT rounds4 foraddi- Medical FL datasets (Sec. 5.1). The standard deviation is\ntional⌈10/E⌉and⌈50/E⌉rounds.Everyattackisevaluated evaluatedoverthreeFLtrainingrunswithdifferentrandom\noverFLtrainingsfrom3differentrandomseeds.ForMed- seeds. All clients run FedAvg with 1 epoch and batch size\nical dataset, the adversary infers whether a person smokes 32.ForIncome-L,weconsiderthedatasetwith40%ofdata\nornot.ForIncome-LandIncome-Adatasets,theadversary heterogeneity(AppendixB.3).\ninfers the gender. The AIA accuracy is the fraction of the\ncorrect inferences over all the samples. We have also con- From Table 1, we see that our attacks outperform\nductedexperimentsforfederatedleastsquaresregressionon gradient-based ones in both passive and active scenarios\nthesamedatasets.TheresultscanbefoundinAppendixC.1. acrossallthreedatasets.Notably,ourpassiveattackachieves\nimprovementsofover15and8percentagepoints(p.p.)for\n5.3 Baselinesandourattackimplementation theIncome-LandMedicaldatasets,respectively.Evenwhen\nthegradient-basedmethodhasaccesstoanoracle,ourpas-\nGradient-based: We compare our method with the sive attacks still achieves higher accuracy on two datasets\n(gradient-based)SOTA(Sec.2.3).Thebaselineperformance and comes very close on Income-A. When shifting to ac-\nis affected by the set of inspected rounds T considered tive attacks, the gains are even more substantial. For in-\nin(2).WeselecttheinspectedroundsT basedontwocrite- stance, when the attack is active for 50 rounds, we achieve\nria:thehighestcosinesimilarityandthebestAIAaccuracy. gainsof13,22,and5percentagepoints(p.p.)inIncome-L,\nInarealattack,theadversaryisnotexpectedtoknowtheat- Income-A, and Medical, respectively, over Grad-w-O, and\ntackaccuracybeforehand.Therefore,werefertotheattack evenlargergainsoverthemorerealisticGrad.Furthermore,\nbased on the highest cosine similarity as Grad and to the theattackaccuracyreachestheperformanceexpectedfrom\nother as Grad-w-O (Gradient with Oracle), as it assumes an adversary who knows the optimal local model. Interest-\ntheexistenceofanoraclethatprovidestheattackaccuracy. ingly, while our attacks consistently improve as the adver-\nThe details for the tuning of T and other hyper-parameter sary’scapacityincreases(movingfromapassiveattackerto\nsettingscanbefoundinAppendix B.4. anactiveoneandincreasingthenumberofroundsoftheac-\ntiveattack),thisisnotthecaseforgradient-basedmethods.\nOur Attacks: Our attacks consist of two steps: 1) re-\nconstructing the optimal local model, and 2) executing the Impact of data heterogeneity. We simulate varying lev-\nmodel-basedAIA(3).Forthefirststep,apassiveadversary els of heterogeneity in the Income-L dataset and illustrate\nusesthelast-returnedmodelfromthetargetedclient,while howtheattackperformanceevolvesinFigure3(left).First,\nan active adversary executes Alg. 4. The details of the hy- we observe that as the data is more heterogeneously split,\nperparametersettingscanbefoundinAppendixB.4. the accuracy of AIA improves for all approaches. Indeed,\nthedatasplittingstrategy(AppendixB.3)leadstoagreater\n4Wealsoexaminetheimpactoftheattack’sstartinground.The degreeofcorrelationbetweentheclients’sensitiveattributes\nresultsarepresentedintheAppendixC.2. andthetargetvariableathigherlevelsofheterogeneity.This\nFigure3:TheAIAaccuracyoverallclients’localdatasetsunderdifferentheterogeneitylevels(left)(0%representsi.i.dcase),\nbatchsizes(center),andlocalepochs(right)forIncome-Ldataset.Thedefaultvaluesforheterogeneitylevel,batchsizeBand\nlocalepochsEaresetto40%,32,and1,respectively.Themaliciousadversaryattacks⌈50/E⌉roundsafter⌈100/E⌉communi-\ncationrounds.Crossesrepresentpassiveattacks,whiledotsrepresentactiveattacks.Dashedlinescorrespondtogradient-based\nattacks(Grad),andsolidlinescorrespondtomodel-basedattacks(OursandModel-w-O).\nintrinsiccorrelationfacilitatestheoperationofallAIAs.We We observe that for all methods, clients with smaller\nobserve in these experiments, as in previous ones, that ac- datasets are more vulnerable to the attacks, because the\ntiveGraddoesnotnecessarilyofferadvantagesoverpassive modelsoverfitthedatasetmoreeasily.Moreover,forclients\nGrad. In the more homogeneous case (which is less realis- with more than 20000 data points, Grad provides an attack\ntic in an FL setting), our passive attack performs slightly performanceclosetorandomguessing.\nworse than Grad, but its accuracy increases more rapidly\nImpactofdefensemechanisms. Tomitigateprivacyleak-\nwithheterogeneity,resultinginanAIAaccuracyadvantage\nage, we apply a federated version of DP-SGD (Abadi\nof over 20 p.p. in the most heterogeneous case. Our active\netal.2016),whichprovidessample-leveldifferentialprivacy\nattack over 50 additional rounds consistently outperforms\nguarantees(Dworketal.2006;Choudhuryetal.2019).Our\nGradbyatleast30p.p.andisalmostindistinguishablefrom\nexperimentsshowthatevenwiththisdefensemechanismin\nModel-w-O.\nplace, our approach still outperforms the baselines in most\nImpactofbatchsize. Figure3(center)showsthattheper- ofthescenarios.TheresultsareinAppendixC.4.\nformance of our attacks slightly decrease as the batch size\nincreases. A possible explanation for this is that a larger 6 Discussionandconclusions\nbatch size results in fewer local updates per epoch, leading\ntheclienttoreturnalessoverfittedmodel.Despitethis,our Inourwork,wehavedemonstratedtheeffectivenessofus-\napproachconsistentlyoutperformsGradinallcases. ing model-based AIA for federated regression tasks, when\nthe attacker can approximate the optimal local model. For\nImpact of the number of local epochs. Figure 3 (right) an honest-but-curious adversary, we proposed a computa-\nshowsthatunderpassiveattacks,ourapproachisnotsensi- tionallyefficientapproachtoreconstructtheoptimallinear\ntive to the number of local epochs, whereas Grad’s perfor- localmodelinleastsquaresregression.Incontrast,forneu-\nmance deteriorates to the level of random guessing as the ralnetworkscenarios,ourpassiveapproachinvolvesdirectly\nnumber of local epochs increases to 5. Interestingly, active utilizingthelastreturnedmodel(Sec.5.3).Webelievemore\nGradsignificantlyimprovesuponpassiveGradasthenum- sophisticated reconstruction techniques may exist, and we\nberoflocalepochsincreases.Whileouractiveapproachpro- plantoinvestigatethisaspectinfuturework.\ngressively performs slightly worse, it still maintains an ad- Thereadermaywonderifthesuperiorityofmodel-based\nvantageofover10p.p.comparedtoGrad. attacksovergradient-basedonesalsoholdsforclassification\ntasks.Somepreliminaryexperimentsweconductedsuggest\nImpactofthelocaldatasetsize.\nthattherelationshipisinverted.Weadvanceapartialexpla-\nThe figure on the\nnation for this observation. For a linear model with binary\nright shows how\ncross-entropy loss, it can be shown that the model-based\neach client’s dataset\nAIA(3)onabinarysensitiveattributeisequivalenttoasim-\nsize impacts in-\nplelabel-basedattack,wheretheattributeisuniquelyrecon-\ndividual (active)\nstructedbasedonthelabel.Thisapproachleadstopoorper-\nAIA accuracy in\nformance because the attack relies only on general popula-\nIncome-A dataset.\ntioncharacteristicsandignoresindividualspecificities.This\nThe experiment\nobservation also holds experimentally for neural networks\nsetting is the same\ntrainedontheIncome-Ldataset,largelyduetotheinherent\nasinTable1with50\nunfairnessofthelearnedmodels.Forexample,forthesame\nactiverounds.\nset of public features, being a man consistently results in a References\nhigher probability of being classified as wealthy compared Abadi, M.; Chu, A.; Goodfellow, I.; McMahan, H. B.;\ntobeingawoman.Asaconsequence,theAIAinfersgender Mironov,I.;Talwar,K.;andZhang,L.2016. DeepLearning\nsolelybasedonthehighorlowincomelabel.Theseprelim- withDifferentialPrivacy. InProceedingsofthe2016ACM\ninary remarks may prompt new interesting perspectives on SIGSACConferenceonComputerandCommunicationsSe-\ntherelationshipbetweenfairnessandprivacy(seeforexam- curity.ACM.\npletheseminalpaper(ChangandShokri2021)).\nAgarwal, A.; Negahban, S.; and Wainwright, M. J. 2012.\nLastbutnotleast,tomitigateprivacyleakage,beyonddif-\nStochasticoptimizationandsparsestatisticalrecovery:Op-\nferential privacy mechanisms, there are empirical defenses\ntimal algorithms for high dimensions. Advances in Neural\nsuch as Mixup (Zhang et al. 2018), which trains a model\nInformationProcessingSystems,25.\non composite data samples obtained through linear com-\nAkiba, T.; Sano, S.; Yanase, T.; Ohta, T.; and Koyama, M.\nbinations of sample pairs, and TAPPFL (Arroyo Arevalo\n2019. Optuna: A Next-generation Hyperparameter Opti-\net al. 2024), which learns low-dimensional representations\nmization Framework. In Proceedings of the 25th ACM\nthatminimizeinformationaboutprivateattributes.However,\nSIGKDD International Conference on Knowledge Discov-\ntheeffectivenessofthesedefenseshasnotyetbeendemon-\nery & Data Mining, KDD ’19, 2623–2631. New York,\nstratedonregressiontasks,andweleavethisforfuturework.\nNY, USA: Association for Computing Machinery. ISBN\n9781450362016.\n7 Acknowledgements\nArroyo Arevalo, C.; Noorbakhsh, S. L.; Dong, Y.; Hong,\nThis research was supported in part by the Groupe La\nY.; and Wang, B. 2024. Task-Agnostic Privacy-Preserving\nPoste, sponsor of the Inria Foundation, in the framework\nRepresentationLearningforFederatedLearningagainstAt-\nof the FedMalin Inria Challenge, as well as by the France\ntributeInferenceAttacks. ProceedingsoftheAAAIConfer-\n2030 program, managed by the French National Research\nenceonArtificialIntelligence,38:10909–10917.\nAgencyundergrantagreementsNo.ANR-21-PRRD-0005-\nBlanchard,P.;ElMhamdi,E.M.;Guerraoui,R.;andStainer,\n01, ANR-23-PECL-0003, and ANR-22-PEFT-0002. It was\nJ.2017. Machinelearningwithadversaries:Byzantinetol-\nalso funded in part by the European Network of Excel-\nerantgradientdescent. Advancesinneuralinformationpro-\nlence dAIEDGE under Grant Agreement Nr. 101120726,\ncessingsystems,30.\nby SmartNet and LearnNet, and by the French govern-\nment National Research Agency (ANR) through the UCA Boenisch,F.;Dziedzic,A.;Schuster,R.;Shamsabadi,A.S.;\nJEDI (ANR-15-IDEX-01), EUR DS4H (ANR-17-EURE- Shumailov, I.; and Papernot, N. 2023. When the Curious\n004), and the 3IA Coˆte d’Azur Investments in the Future Abandon Honesty: Federated Learning Is Not Private. In\nprojectwiththereferencenumberANR-19-P3IA-0002. 2023 IEEE 8th European Symposium on Security and Pri-\nThe authors are grateful to the OPAL infrastructure from vacy(EuroS&P),175–199.\nUniversite´Coˆted’Azurforprovidingresourcesandsupport. Bonawitz, K.; Ivanov, V.; Kreuter, B.; Marcedone, A.;\nMcMahan, H. B.; Patel, S.; Ramage, D.; Segal, A.; and\nSeth, K. 2017. Practical Secure Aggregation for Privacy-\nPreserving Machine Learning. In Proceedings of the\n2017 ACM SIGSAC Conference on Computer and Com-\nmunications Security, CCS ’17, 1175–1191. New York,\nNY, USA: Association for Computing Machinery. ISBN\n9781450349468.\nChang, H.; and Shokri, R. 2021. On the privacy risks of\nalgorithmic fairness. In 2021 IEEE European Symposium\nonSecurityandPrivacy(EuroS&P),292–303.IEEE.\nChen,C.;Lyu,L.;Yu,H.;andChen,G.2022. PracticalAt-\ntribute Reconstruction Attack Against Federated Learning.\nIEEETransactionsonBigData,1–1.\nChen, W.; Horvath, S.; and Richtarik, P. 2020. Optimal\nClient Sampling for Federated Learning. Workshop in\nNeurIPS2020:PrivacyPreservingMachineLearning.\nChoudhury,O.;Gkoulalas-Divanis,A.;Salonidis,T.;Sylla,\nI.; Park, Y.; Hsu, G.; and Das, A. 2019. Differential\nPrivacy-enabled Federated Learning for Sensitive Health\nData.WorkshoponMachinelearningforHealthinNeurIPS.\nDing, F.; Hardt, M.; Miller, J.; and Schmidt, L. 2024. Re-\ntiringadult:newdatasetsforfairmachinelearning. InPro-\nceedingsofthe35thInternationalConferenceonNeuralIn-\nformation Processing Systems, NIPS ’21. Red Hook, NY,\nUSA:CurranAssociatesInc. ISBN9781713845393.\nDwork, C.; McSherry, F.; Nissim, K.; and Smith, A. 2006. Kingma, D. P.; and Ba, J. 2015. Adam: A Method for\nCalibrating Noise to Sensitivity in Private Data Analysis. StochasticOptimization. InBengio,Y.;andLeCun,Y.,eds.,\nIn Halevi, S.; and Rabin, T., eds., Theory of Cryptography, 3rdInternationalConferenceonLearningRepresentations,\n265–284. Berlin, Heidelberg: Springer Berlin Heidelberg. ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Confer-\nISBN978-3-540-32732-5. enceTrackProceedings.\nElMhamdi,E.M.2020.RobustDistributedLearning.Ph.D. Lantz,B.2013.MachineLearningwithR.PacktPublishing.\nthesis,EPFL. ISBN1782162143.\nFeng, T.; Hashemi, H.; Hebbar, R.; Annavaram, M.; and Li,T.;Sahu,A.K.;Zaheer,M.;Sanjabi,M.;Talwalkar,A.;\nNarayanan,S.S.2021. Attributeinferenceattackofspeech and Smith, V. 2020. Federated optimization in heteroge-\nemotion recognition in federated learning settings. arXiv neousnetworks. MLSys.\npreprintarXiv:2112.13416. Li,X.;andOrabona,F.2020. AHighProbabilityAnalysis\nFowl, L. H.; Geiping, J.; Czaja, W.; Goldblum, M.; and ofAdaptiveSGDwithMomentum. InWorkshoponBeyond\nGoldstein, T. 2022. Robbing the Fed: Directly Obtaining FirstOrderMethodsinMLSystemsatICML’20.\nPrivate Data in Federated Learning with Modified Models. Lian, X.; Zhang, C.; Zhang, H.; Hsieh, C.; Zhang, W.; and\nIn The Tenth International Conference on Learning Rep- Liu, J. 2017. Can Decentralized Algorithms Outperform\nresentations, ICLR 2022, Virtual Event, April 25-29, 2022.\nCentralized Algorithms? A Case Study for Decentralized\nOpenReview.net. ParallelStochasticGradientDescent.InAdvancesinNeural\nFredrikson,M.;Lantz,E.;Jha,S.;Lin,S.;Page,D.;andRis- InformationProcessingSystems30:AnnualConferenceon\ntenpart, T. 2014. Privacy in pharmacogenetics: An end-to- NeuralInformationProcessingSystems2017,5330–5340.\nend case study of personalized warfarin dosing. In 23rd Liu, P.; Xu, X.; and Wang, W. 2022. Threats, attacks and\n{USENIX} Security Symposium ({USENIX} Security 14),\ndefenses to federated learning: issues, taxonomy and per-\n17–32. spectives. Cybersecurity,5(1):4.\nGeiping, J.; Bauermeister, H.; Dro¨ge, H.; and Moeller, M.\nLyu,L.;andChen,C.2021. ANovelAttributeReconstruc-\n2020. InvertingGradients-Howeasyisittobreakprivacy\ntionAttackinFederatedLearning. arXiv:2108.06910.\ninfederatedlearning? InLarochelle,H.;Ranzato,M.;Had-\nLyu,L.;Yu,H.;Ma,X.;Chen,C.;Sun,L.;Zhao,J.;Yang,\nsell, R.; Balcan, M.; and Lin, H., eds., Advances in Neu-\nQ.;andYu,P.S.2020. PrivacyandRobustnessinFederated\nralInformationProcessingSystems33:AnnualConference\nLearning:AttacksandDefenses.\non Neural Information Processing Systems 2020, NeurIPS\n2020,December6-12,2020,virtual. McMahan, B.; Moore, E.; Ramage, D.; Hampson, S.; and\ny Arcas, B. A. 2017. Communication-efficient learning of\nJang,E.;Gu,S.;andPoole,B.2017. CategoricalReparam-\ndeepnetworksfromdecentralizeddata. InArtificialIntelli-\neterizationwithGumbel-Softmax. InInternationalConfer-\ngenceandStatistics,1273–1282.PMLR.\nenceonLearningRepresentations.\nMelis, L.; Song, C.; De Cristofaro, E.; and Shmatikov, V.\nJee Cho, Y.; Wang, J.; and Joshi, G. 2022. Towards Un-\n2019.Exploitingunintendedfeatureleakageincollaborative\nderstandingBiasedClientSelectioninFederatedLearning.\nlearning. In2019IEEEsymposiumonsecurityandprivacy\nInCamps-Valls,G.;Ruiz,F.J.R.;andValera,I.,eds.,Pro-\n(SP),691–706.IEEE.\nceedingsofThe25thInternationalConferenceonArtificial\nIntelligence and Statistics, volume 151 of Proceedings of Nasr, M.; Shokri, R.; and Houmansadr, A. 2019. Compre-\nMachineLearningResearch,10351–10375.PMLR. hensiveprivacyanalysisofdeeplearning:Passiveandactive\nwhite-box inference attacks against centralized and feder-\nJin, C.; Ge, R.; Netrapalli, P.; Kakade, S. M.; and Jordan,\nated learning. In 2019 IEEE Symposium on Security and\nM. I. 2017. How to Escape Saddle Points Efficiently. In\nPrivacy(SP),739–753.IEEE.\nPrecup, D.; and Teh, Y. W., eds., Proceedings of the 34th\nInternationalConferenceonMachineLearning,volume70 Nesterov,Y.2003.Introductorylecturesonconvexoptimiza-\nofProceedingsofMachineLearningResearch,1724–1732. tion:Abasiccourse,volume87. SpringerScience&Busi-\nPMLR. nessMedia.\nKadhe,S.;Rajaraman,N.;Koyluoglu,O.O.;andRamchan- Nguyen, T.; Lai, P.; Tran, K.; Phan, N. H.; and Thai, M.\ndran, K. 2020. FastSecAgg: Scalable Secure Aggregation 2023. Active Membership Inference Attack under Local\nfor Privacy-Preserving Federated Learning. arXiv preprint DifferentialPrivacyinFederatedLearning.\narXiv:2009.11248. Nishio,T.;andYonetani,R.2019.Clientselectionforfeder-\nKairouz,P.;McMahan,H.B.;Avent,B.;Bellet,A.;Bennis, atedlearningwithheterogeneousresourcesinmobileedge.\nM.;Bhagoji,A.N.;Bonawitz,K.;Charles,Z.;Cormode,G.; In2019IEEEInternationalConferenceonCommunications\nCummings,R.;etal.2021. Advancesandopenproblemsin (ICC),1–7.IEEE.\nfederated learning. Foundations and Trends® in Machine Quoc,D.L.;Gregor,F.;Arnautov,S.;Kunkel,R.;Bhatotia,\nLearning,14(1–2):1–210. P.;andFetzer,C.2020.Securetf:Asecuretensorflowframe-\nKasiviswanathan,S.P.;Rudelson,M.;andSmith,A.2013. work. InProceedingsofthe21stInternationalMiddleware\nThepoweroflinearreconstructionattacks. InProceedings Conference,44–59.\nofthetwenty-fourthannualACM-SIAMsymposiumonDis- Rigollet, P.; and Hutter, J.-C. 2023. Lecture Notes: High-\ncretealgorithms,1415–1433.SIAM. DimensionalStatistics.\nSabt,M.;Achemlal,M.;andBouabdallah,A.2015. Trusted Zhou, P.; Feng, J.; Ma, C.; Xiong, C.; Hoi, S. C.; and\nExecution Environment: What It is, and What It is Not. In E, W. 2020b. Towards Theoretically Understanding Why\n2015IEEETrustcom/BigDataSE/ISPA,volume1,57–64. Sgd Generalizes Better Than Adam in Deep Learning. In\nLarochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.; and\nShao, J. 2003. Mathematical Statistics. Springer Texts in\nLin, H., eds., Advances in Neural Information Processing\nStatistics.Springer. ISBN9780387953823.\nSystems33:AnnualConferenceonNeuralInformationPro-\nSingh, J.; Cobbe, J.; Quoc, D. L.; and Tarkhani, Z. 2021.\ncessingSystems2020,NeurIPS2020,December6-12,2020,\nEnclaves in the Clouds: Legal Considerations and Broader\nvirtual.\nImplications. Commun.ACM,64(5):42–51.\nZou, D.; Cao, Y.; Li, Y.; and Gu, Q. 2023. Understanding\nTrame`r,F.;Shokri,R.;Joaquin,A.S.;Le,H.;Jagielski,M.; the Generalization of Adam in Learning Neural Networks\nHong, S.; and Carlini, N. 2022. Truth Serum: Poisoning with Proper Regularization. In The Eleventh International\nMachineLearningModelstoRevealTheirSecrets. InACM Conference on Learning Representations, ICLR 2023, Ki-\nCCS. gali,Rwanda,May1-5,2023.OpenReview.net.\nVlaski,S.;andSayed,A.H.2021. DistributedLearningin\nNon-Convex Environments—Part I: Agreement at a Linear\nReproducibilityChecklist\nRate. IEEE Transactions on Signal Processing, 69: 1242–\nThispaper:\n1256.\nWen, Y.; Geiping, J.; Fowl, L.; Goldblum, M.; and Gold- • Includesaconceptualoutlineand/orpseudocodedescrip-\nstein,T.2022. FishingforUserDatainLarge-BatchFeder- tionofAImethodsintroduced.Yes\natedLearningviaGradientMagnification.InChaudhuri,K.; • Clearlydelineatesstatementsthatareopinions,hypothe-\nJegelka,S.;Song,L.;Szepesva´ri,C.;Niu,G.;andSabato,S., sis,andspeculationfromobjectivefactsandresults.Yes\neds.,InternationalConferenceonMachineLearning,ICML • Provides well marked pedagogical references for less-\n2022,17-23July2022,Baltimore,Maryland,USA,volume familiarereaderstogainbackgroundnecessarytorepli-\n162ofProceedingsofMachineLearningResearch,23668– catethepaper.Yes\n23684.PMLR.\nDoesthispapermaketheoreticalcontributions?Yes\nYeom,S.;Giacomelli,I.;Fredrikson,M.;andJha,S.2018.\n• All assumptions and restrictions are stated clearly and\nPrivacyriskinmachinelearning:Analyzingtheconnection\nformally.Yes\ntooverfitting. In2018IEEE31stComputerSecurityFoun-\ndationsSymposium(CSF),268–282.IEEE. • Allnovelclaimsarestatedformally.Yes\nYin, D.; Chen, Y.; Kannan, R.; and Bartlett, P. 2018. • Proofsofallnovelclaimsareincluded.Yes\nByzantine-robustdistributedlearning:Towardsoptimalsta- • Proofsketchesorintuitionsaregivenforcomplexand/or\ntistical rates. In International Conference on Machine novelresults.Yes\nLearning,5650–5659.PMLR.\n• Appropriatecitationstotheoreticaltoolsusedaregiven.\nYin, H.; Mallya, A.; Vahdat, A.; Alvarez, J. M.; Kautz, Yes\nJ.; and Molchanov, P. 2021. See through Gradients: Im- • All theoretical claims are demonstrated empirically to\nage Batch Recovery via GradInversion. In Proceedings of hold.Yes\ntheIEEE/CVFConferenceonComputerVisionandPattern\n• All experimental code used to eliminate or disprove\nRecognition,16337–16346.\nclaimsisincluded.NA\nYousefpour,A.;Shilov,I.;Sablayrolles,A.;Testuggine,D.;\nDoesthispaperrelyononeormoredatasets?Yes\nPrasad, K.; Malek, M.; Nguyen, J.; Ghosh, S.; Bharadwaj,\nA.; Zhao, J.; Cormode, G.; and Mironov, I. 2021. Opacus: • A motivation is given for why the experiments are con-\nUser-FriendlyDifferentialPrivacyLibraryinPyTorch. ductedontheselecteddatasets.No\nZhang, H.; Cisse´, M.; Dauphin, Y. N.; and Lopez-Paz, D. • All novel datasets introduced in this paper are included\ninadataappendix.NA\n2018. mixup: Beyond Empirical Risk Minimization. In\n6thInternationalConferenceonLearningRepresentations, • Allnoveldatasetsintroducedinthispaperwillbemade\nICLR2018,Vancouver,BC,Canada,April30-May3,2018, publicly available upon publication of the paper with a\nConferenceTrackProceedings. licensethatallowsfreeusageforresearchpurposes.NA\nZhao, J. C.; Sharma, A.; Elkordy, A. R.; Ezzeldin, Y. H.; • All datasets drawn from the existing literature (poten-\nAvestimehr, S.; and Bagchi, S. 2023. LOKI: Large-scale tiallyincludingauthors’ownpreviouslypublishedwork)\nData Reconstruction Attack against Federated Learning areaccompaniedbyappropriatecitations.Yes\nthroughModelManipulation. In2024IEEESymposiumon • All datasets drawn from the existing literature (poten-\nSecurityandPrivacy(SP),30–30.IEEEComputerSociety. tiallyincludingauthors’ownpreviouslypublishedwork)\nZhou, D.; Chen, J.; Cao, Y.; Tang, Y.; Yang, Z.; and Gu, arepubliclyavailable.Yes\nQ.2020a. OntheConvergenceofAdaptiveGradientMeth- • Alldatasetsthatarenotpubliclyavailablearedescribed\nodsforNonconvexOptimization.InOPT2020:12thAnnual in detail, with explanation why publicly available alter-\nWorkshoponOptimizationforMachineLearning. nativesarenotscientificallysatisficing.NA\nDoesthispaperincludecomputationalexperiments?Yes\n• Anycoderequiredforpre-processingdataisincludedin\ntheappendix.Yes\n• All source code required for conducting and analyzing\ntheexperimentsisincludedinacodeappendix.Yes\n• All source code required for conducting and analyzing\nthe experiments will be made publicly available upon\npublication of the paper with a license that allows free\nusageforresearchpurposes.Yes\n• All source code implementing new methods have com-\nments detailing the implementation, with references to\nthepaperwhereeachstepcomesfrom.Partial\n• Ifanalgorithmdependsonrandomness,thenthemethod\nusedforsettingseedsisdescribedinawaysufficientto\nallowreplicationofresults.Yes\n• This paper specifies the computing infrastructure used\nforrunningexperiments(hardwareandsoftware),includ-\ning GPU/CPU models; amount of memory; operating\nsystem;namesandversionsofrelevantsoftwarelibraries\nandframeworks.Partial\n• This paper formally describes evaluation metrics used\nand explains the motivation for choosing these metrics.\nYes\n• This paper states the number of algorithm runs used to\ncomputeeachreportedresult.Yes\n• Analysisofexperimentsgoesbeyondsingle-dimensional\nsummariesofperformance(e.g.,average;median)toin-\nclude measures of variation, confidence, or other distri-\nbutionalinformation.Yes\n• The significance of any improvement or decrease in\nperformance is judged using appropriate statistical tests\n(e.g.,Wilcoxonsigned-rank).No\n• Thispaperlistsallfinal(hyper-)parametersusedforeach\nmodel/algorithminthepaper’sexperiments.Partial\n• This paper states the number and range of values tried\nper(hyper-)parameterduringdevelopmentofthepaper,\nalong with the criterion used for selecting the final pa-\nrametersetting.Yes\nAppendices can observe that λ min(cid:16) ΘT ou ntΘ cout(cid:17) = n1 cλ min(cid:0) ΘT outΘ out(cid:1) =\n1 σ2 (Θ ) = 1 min ∥Θ z∥2. Now, consider\nA TheoreticalResults tn hc atm thi en comout ponentsnc ofthez g,∥ rz a∥ d= ie1 ntno ou it se2 e(θ)areindepen-\nA.1 FullstatementandproofofTheorem1 dent, each with variance lower bounded by τ2 > 0, it fol-\nlows that E[∥Θ z∥2] ≥ n τ2 d ∥z∥2 = n τ2 d . This\nTheorem 1. Consider training a least squares regression out 2 c d+1 2 c d+1\nsuggeststhatσ2 (Θ )growslinearlywithn andthenit\nthroughFedAvg(Alg.2)withbatchsizeB andlocalepochs min out c\nE.Assumethat is possible to lower bound λ min(cid:16) ΘT ou ntΘ cout(cid:17) with a positive\n1. theclient’sdesignmatrixx ∈ Rm×d hasrankdequal constant.\nc\ntothenumberoffeaturesplusone;5\nProof. LetH = xTx whichispositivedefinite.Lety ∈\n2. the components of the stochastic (mini-batch) gradi- c c c\nRmbethelabelsinthelocaldatasetD withsizem=|D |.\nent are distributed as sub-Gaussian random variables c c\nwith variance proxy σ2, i.e., E[exp(e(θ)[i]/σ2)] ≤ ∥x θ−y ∥2\nL (θ)= c c (8)\nexp(1),∀θ,∀i ∈ {1,2,...,d}, where e(θ) = g(θ) − c m\n∇L c(θ);6 We know that θ∗ = (xTx )−1xTy . When computing\n3. the input model vectors at an observed round are inde- c c c c c\nthestochasticgradient,wehave:\npendentofthepreviousstochasticgradientscomputedby\n2\ntheattackedclient; g(θ)=∇L (θ)+e(θ)= (Hθ−Hθ∗)+e(θ). (9)\n4. there exists λ > 0 such that ∀n ∈ N, we can always c m c\nselectn cobservationroundssothc atλ min(cid:16) ΘT ou ntΘ cout(cid:17) ≥λ, A ext er co uu tn esd At, li gf os re il te hc mted 2, .c Lli ee tn θt ctc (r ke )ce bi eve ts heth mes oe dr ev ler afm teo rd te hl ean kd -\nwhere λ (A) denotes the smallest eigenvalue of the th local update. To simplify the notation, in the following,\nmin\nmatrixA,andΘ isdefinedinAlg.3. wereplacee(θt(k))bye .Replacing(9)inline4ofAlgo-\nout c k\nrithm2,wehave\nThe error of the reconstructed model θˆ∗ of Algorithm 3 is\nc\nupperboundedw.p.≥1−δwhenη ≤ 2λmaxm (xT cxc) and (cid:18) 2η (cid:19)K (cid:34) (cid:18) 2η (cid:19)K(cid:35)\n(cid:13) (cid:13)\n (cid:115) (cid:108)m(cid:109)d+1+ln2d θ ct(K)= I− mH θ ct(0)+ I− I− mH θ c∗\n(cid:13) (cid:13)θˆ c∗−θ c∗(cid:13)\n(cid:13) 2\n=Oησd dE\nB n c·λ\nδ . (7)\n(cid:88)K (cid:18) 2η (cid:19)k−1\n− I− H ηe .\nm K−k+1\nBeforepresentingtheproof,wediscusstheassumptions. k=1\nThe first assumption can be relaxed at the cost of replac- whereK = E⌈m⌉asineachepochthereare⌈m⌉local\nB B\ning in the proof the inverse H−1 of the matrix H = xT cx\nc steps. Let W =\n(cid:104) I−(cid:0)\nI−\n2ηH(cid:1)K(cid:105)\n. W is proven to be\nby its pseudo-inverse H†. The second assumption is com- m\ninvertibleinLemma2,thenwehave:\nmon in the analysis of stochastic gradient methods (Agar-\nwal,Negahban,andWainwright2012;Jinetal.2017;Vlaski\nandSayed2021;LiandOrabona2020;Zhouetal.2020a). θt(0)=W−1(cid:0) θt(0)−θt(K)(cid:1) +θ∗\nc c c c\nThethirdassumptionistechnicallynotsatisfiedinoursce-\nnario as the stochastic gradients computed by the attacked\n−W−1(cid:88)K (cid:18)\nI−\n2η\nH(cid:19)k−1\nηe (10)\nclientibeforeanobservedroundt havecontributedtode- m K−k+1\nn\nk=1\nterminethemodelssentbackbyclientiatroundst<t and\nthen the global model θtn(0) sent by the server to clin ent i. Let γt = −ηW−1(cid:80)K k=1(cid:0) I− 2 mηH(cid:1)k−1 e K−k+1. Let\nNevertheless,weobservethatθtn(0)isalmostindependent x[i]betheith elementofvectorxandX[i,:]andX[:,i]be\nonclient-i’sstochasticgradientsifthesetofclientsisvery theith rowandcolumnofthematrixX,respectively.Since\nlarge. Moreover, the assumption is verified if we assume a every element in e is sub-Gaussian and the weighted sum\nmorepowerfuladversarywhocanactasamaninthemiddle ofindependentsub-Gaussianvariablesisstillsub-Gaussian,\nandarbitrarilymodifiesthemodelsenttotheclient.Finally, γ[i]issub-GaussianwithE[γt[i]]=0and\nt dh ae taf ao su sr uth mpa ts is ou nm ”p ft oio rn\na\nc go er nr ee rs ip co ln id ns eat ro ret gh re es“ sw ioe nll- pb re oh ba lev med\n,\n(cid:88)K (cid:13) (cid:13)(cid:18)\n2η\n(cid:19)k−1(cid:13) (cid:13)2\nVar[γt[i]]≤dη2σ2∥W−1∥2 (cid:13) I− H (cid:13)\nwhich is required to be able to prove the consistency of 2 (cid:13) m (cid:13)\n(cid:13) (cid:13)\ntheestimators,i.e.,thattheyconvergewithprobability1to k=1 2\nt fh oe\nr\nec xo arr mec pt lev (a Slu he aoas 20th 0e 3,n Tu hm mb .er 3.o 1f 1)s )a .m Inple ths isdi cv oe nrg tee xs t,(s wee\ne =\nλd 2η2 (σ W2 )(cid:88)K (cid:13) (cid:13)\n(cid:13) (cid:13)(I−\n2 mη H)k−1(cid:13) (cid:13)\n(cid:13)\n(cid:13)2\nmin k=1 2\n5Rememberthataclient’sdesignmatrixhasanumberofrows\ndη2σ2 (cid:88)K 2η\nequaltotheinputfeaturesofthesamplesintheclient’slocaltrain- = ρ2 ((I− H)k−1),\ningdataset. λ2 (W) max m\nmin k=1\n6Note that, by Jensen’s inequality, this condition implies a\nboundedvarianceforeachcomponentofthestochasticgradients.\nwhereρ (A)isthespectralradiusofmatrixA. estimatesforeachrowareindependent.Wecanthenapply\nmax\nLetΛbeadiagonalmatrixwhoseentriesarethepositive the union bound and obtain that the Euclidean distance be-\neigenvaluesofHandλ (H)bethelargesteigenvalueof tweenthetwovectorscanbeboundedasfollows,whichcon-\nmax\nH,i.e.,λ (H) = ∥Λ∥ .Whenη ≤ m ,thediago- cludestheproof:\nmax 1 2λmax(H)\nnalvaluesin 2ηΛarepositiveandsmallerthanorequalto1.\nm (cid:13) (cid:13)2 d2η2σ2K d+1+ln2d\nMoreover,thematrix(I−2ηH)k−1ispositivesemi-definite (cid:13)θˆ∗−θ∗(cid:13) ≤ · δ , w.p.≥1−δ.\nandwehaveρ [(I− 2ηm H)k−1]≤1.Thus,wehave (cid:13) c c(cid:13) 2 λ2 min(W) n cλ\nmax m (18)\ndη2σ2K\nVar[γ[i]]≤ . (11)\nλ2 (W)\nmin\nAbout the Eigenvalues of the Matrix W. H = xTx is\nEquation(10)forn observationcanbewritteninacom- c c\nc diagonalizable, i.e., H = UΛUT with U an orthonormal\npactwayas\nmatrixandΛadiagonalone.Aftersomecalculations\nΘ =Θ (W−1,θ∗)T +ΓT, (12)\nin out c\nwhereΓ=(γt1,...,γtc).\nW=I−(cid:18)\nI−\n2η\nH(cid:19)E⌈m b⌉\nLet us denote W−1 as V. We can determine estimators m\n(Vˆ,θˆ c∗) for (V,θ c∗), through ordinary least squares (OLS) (cid:32) (cid:18)\n2η\n(cid:19)E⌈m b⌉(cid:33)\nminimization.Inparticular,ifweextracttherelationinvolv- =U I− I− Λ UT.\ningthei-throwofVandθ∗,weobtain: m\nc\nΘ in[:,i]=Θ out(V[i,:],θ c∗[i,:])T +ΓT[:,i]. (13) Then\nTheOLSestimatoris (cid:18)\n2η\n(cid:19)E⌈m b⌉\n(Vˆ[i,:],θˆ c∗[i])T = argmin ∥Θ in[:,i]−Θ out(v;θ)∥2 2, λ min(W)=1− 1− mλ min(H)\nv∈Rd,θ∈R\n(14) (cid:18) 2η (cid:19)E⌈m b⌉\nandcanbeexpressedinclosedformas λ max(W)=1− 1− mλ max(H)\n(Vˆ[i,:],θˆ∗[i])T =(cid:0) ΘT Θ (cid:1)−1 ΘT Θ [:,i]. (15)\nc out out out in Lemma 2. Let A be a symmetric positive definite matrix.\nAmorecompactrepresentationisthefollowing I−(I−A)nisinvertibleforn≥0.\n(cid:13) (cid:13)2\n(Vˆ,θˆ∗)T = argmin (cid:13)Θ −Θ (W′ θ)T(cid:13) ,\nc (cid:13) in out (cid:13) Proof. SinceAispositivedefiniteandsymmetric,itcanbe\nV∈Rd×d,θ∈Rd F\ndecomposedtoUΛUT,whereUUT =IandΛisadiago-\nandthecorrespondingclosedformis nalmatrixwhoseentriesarethepositiveeigenvaluesofA.\nThuswehave\n(Vˆ,θˆ∗)T =(cid:0) ΘT Θ (cid:1)−1 ΘT Θ ∈R(d+1)×d. (16)\nc out out out in\nI−(I−A)n =UIUT −(UIUT −UΛUT)n\nNotethatthisishowθ∗isestimatedinAlgorithm3line3.\nc\nThe presentation of separate linear systems for eachrow =UIUT −U(I−Λ)nUT\ni in (13) is also instrumental to the rest of the proof. We\n=U(I−(I−Λ)n)UT.\nobserve that (13) describes a regression model with inde-\npendentsub-gaussiannoise,andthenfromTheorem2.2and\nSinceΛiswithonlypositivevaluesondiagonal,eigenvalues\nRemark2.3in(RigolletandHutter2023),wehavethatfor ofI−(I−A)narenon-zeros.SoI−(I−A)nisinvertible\nagivenrowi∈{1,...,d},w.p.atleast1− dδ, anditsinverseisU(I−(I−Λ)n)−1UT.\n(θˆ∗[i]−θ∗[i])2 ≤(θˆ∗[i]−θ∗[i])2+∥Vˆ[i,:]−V[i,:]∥2\nc c c c 2\nA.2 ProofofProposition2\nd+1+log2d\n≤Var[γ[i]] δ .\n(cid:16) (cid:17) Proof. When FedAvg is executed with full batch (i.e.,\nn cλ min ΘT ou ntΘ cout e(θ)=0),accordingtoEqs.9and10,wehave\nFrom(11)andthefourthassumption,itfollowsthatw.p.at 2\nleast1− dδ g(θ)=∇L c(θ)= m(Hθ−Hθ c∗)\n(θˆ∗[i]−θ∗[i])2 ≤\ndη2σ2K\n·\nd+1+log2 δd\n. (17)\nθ ct(0)=W−1(cid:0) θ ct(0)−θ ct(K)(cid:1) +θ c∗. (19)\nc c λ2 (W) n λ\nmin c Thenoncen >d,bysolvingdmultivariatelinearequa-\nc\nWe are going now to consider that each row is estimated tions (Eq. 19), we obtain the exact optimal local model\nthrough adisjoint set of n inspected messages,so that the θ∗.\nc c\nA.3 ProofofProposition3 k >0,bysubstitutingθ∗ andθ∗ into(25),wecanseethat\n2 [1] [2]\nProof. To prove the lower bound for the communications, θ∗ ̸=0.Therefore,wecanprovethenthateveryelementof\n[d]\nwe construct a specific “hard” scenario. This scenario is theglobaloptimumisnon-zero,i.e.,θ∗ ̸=0,∀i∈{1,..,d}.\n[i]\ninspired by the lower bound for the convergence of gradi-\nNow, suppose that we run the FedAvg with one local\nentmethodsminimizingsmoothconvexfunctions(Nesterov\nstep under the above scenario, with initial global model\n2003,Sect.2.1.2). θ(0) = 0, i.e., θ0(0) = 0,∀c ∈ C. According to the pre-\nLetcbetheclienthavingthelocaldataset(x ,y )such c\nc c viousanalysis,weknowthat∀t∈{0,1...,d−1}:\nthatH =xTx isatridiagonalmatrixwithH [i,i+1]=\nH c[i+c 1,i]c =c −1/2 and H c[i,i] = 1,∀i ∈ c {1,2,...,d}, θ ct(E) [t+1] =θ ct(E) [t+2] =...=θ ct(E) [d] =0, (28)\nandxT cy\nc\n=[1/2,0,0,...,0]T.7Wehave\nand\nL (θ) = 1 (cid:0) θTH θ−2(xTy )Tθ−yTy (cid:1) θ(t) [t+1] =θ(t) [t+2] =...=θ(t) [d] =0. (29)\nc m c c c c c\nTherefore,toreachthenon-zerosglobaloptimum,theclient\n(cid:32) d d−1 (cid:33)\n1 (cid:88) (cid:88) cneedstocommunicatewiththeserver(beselectedbythe\n= θ2 − θ θ −θ −C(20)\nm [i] [i] [i+1] [1] server)atleastdtimes.\ni=1 i=1 Moreover, to recover the local optimum of client c, the\nwhereC = yTy isaconstantandθ∗ = argminL (θ) = adversary must listen on the communication channel for at\nc c c c\n(H )−1xTy =[1− 1 ,1− 2 ,...,1− d ]T (Nesterov leastdtimes.Infact,supposethattheclientcholdsanother\nc c c d+1 d+1 d+1 local data set which gives H′ equals to H but for the last\n2003). According to (20), we know that if θ = θ = c c\n[i] [i+1]\nrowandthelastcolumnthatarezeros.Underthiscase,the\n...=θ =0,then∇L (θ) =...=∇L (θ) =0.\n[d] c [i+1] c [d] adversarywillhavethesameobservationunderH andun-\nAtthesametime,foranyotherclient∀c¯∈C\\{c},weas- c\nderH′ tillroundd−1.\nsumetheirlocaloptimumarezeroswheretheirlocaldataset c\nX = Iandy = 0.Inthissetting,weknowthatiftheith\nc¯ c¯ B Thedetailsofexperimentalsetups\nelement of the global model is zero, i.e., θ(t) = 0, then\n[i]\nθt(E) =0. B.1 ExperimentinFigure1\nc¯ [i]\nLet n = |C| be the number of clients and assume that WeevaluatedifferentAIAswhenfourclientstrainaneural\neveryclienthasmlocaldatasamples.Thentheglobalem- network(asinglehiddenlayerof128neuronsusingReLU\npiricalriskanditsgradientshavethefollowingexpressions: as activation function) through FedAvg with 1 local epoch\nand batch size 32. Each client stores |D | data points ran-\n(cid:32) d d−1 (cid:33) c\n1 (cid:88) (cid:88) domlysampledfromACSIncomedataset(Dingetal.2024).\nL(θ)= n×θ2 − θ θ −θ −C′ ,\nnm [i] [i] [i+1] [1] Thisdatasetcontainscensusinformationfrom50U.S.states\ni=1 i=1 andPuertoRico,spanningfrom2014to2018.Itincludes15\n(21)\nfeaturesrelatedtodemographicinformationsuchasage,oc-\n1 cupation,andeducationlevel.Theadversaryinfersthegen-\n∇L(θ) = (2n×θ −θ −1), (22)\n[1] nm [1] [2] der attribute of every data sample held by the client given\n1 (cid:0) (cid:1) accesstothereleased(public)information.\n∇L(θ) = 2n×θ −θ −θ ,∀i∈{2,...,d−1},\n[i] nm [i] [i−1] [i+1] The regression task is to predict an individual’s income.\n(23) The classification task is to predict whether an individ-\nual has an income higher than the median income of the\n1 (cid:0) (cid:1)\n∇L(θ) = 2n×θ −θ , (24) wholedataset,i.e.,39K$.Totraintheclassificationtask,for\n[d] nm [d] [d−1]\neach sample i with target income y , the label is given by\ni\nwhereC′isaconstant.Accordingto(22),(23)and(24),the 1 .\nglobaloptimumθ∗satisfies:\nyi>39K\nB.2 Toydatasetsetting\nθ∗ = (1+θ∗ )/2n, (25)\n[1] [2] WetestourproposedpassiveLMRA(Alg.3)onatoyfed-\nθ [∗ i] = 2nθ [∗ i+1]−θ [∗ i+2],∀i∈{1,...,d−2},(26) eratedleastsquaresregressionwithtwoclients.Eachclient\nθ∗ = 2nθ∗ . (27) c has 1024 samples with 10 features, where nine numeri-\n[d−1] [d]\ncal features are sampled from a uniform distribution over\nEquations26and27showthatθ∗ isproportionaltoθ∗ for [0,1) and one binary feature is sampled from a Bernoulli\n[i] [d]\neveryi ∈ {1,...,d−1},i.e.,θ∗ = k ×θ∗ wherek > 0. distribution with p = 1/2. The prediction y is generated\nSinceθ∗ =k ×θ∗ andθ∗ =[i] k ×i θ∗ w[d h] erek >i 0and fromtheregressionmodely = x cθ∗ +ϵwhereϵisdrawn\n[1] 1 [d] [2] 2 [d] 1 from N(0,0.1)Sc and the optimal local model θ∗ ∈ Rd is\n7One example for the local data (x , y ) satisfying the con- drawnfromthestandardnormaldistributionwhered = 11.\nc c\ndition: x ∈ Rd×d with x [1,1] = 1;x [i + 1,i + 1] = ThetrainingisrunbyFedAvgwith1localepoch,batchsize\nc c c\n(cid:113) 64,256,and1024,and5seedseach,respectively.Thenum-\n1− 1 and x [i+1,i] = −1 ,∀i ∈ {1,...,d−1};\n4xc[i,i]2 c 2xc[i,i] ber of communication rounds are 300 and the honest-but-\nx c[i,i+1]=x c[i,j]=0,∀|i−j|≥1.y c ∈Rdwithy c[1]= 1 2 curiousadversaryonlyeavesdroppedd+1 = 12messages\nandy [i+1]= −xc[i+1,i]yc[i],∀i∈{1,...,d−1}. fromroundsT ={i∗20|i∈{0,1,...,11}}.\nc xc[i+1,i+1]\nAlgorithm 5: Splitting strategy for Income-L dataset with setto1·10−6.ForMedical,thelearningrateissetto2·10−6.\nheterogeneitylevelh∈[0,0.5]\nInput: the initial Income-L dataset D =\nHyperparamters for Gradient-based attacks For the\n{(xp(i),s(i),y(i)),i=1,...,|D|}\npassive adversary, the set of inspected messages T is se-\n1: med←medianvaluein{y(i),i=1,...,|D|} lected in Tp = {{first max{1,⌊f|T |⌋} rounds in T },\n2: Let D h = {((xp(i),s(i),y(i)) ∈ D |(s(i) = man∧ for f ∈ F}. For the active adversarc y, T is selectedc in\ny(i)>med)∨(s(i)=woman∧y(i)<=med)} Tp∪{{first max{1,⌊f|Ta|⌋}roundsinTa}, forf ∈F}.\nc c\n3: LetD l =D\\D h WesetF ={0.01,0.05,0.1,0.2,0.5,1}\n4: k ←min(|D h|,|D l|) To solve (2) with the Gumbel-softmax trick, we set the\n5: D h′ ←samplerandomlykpointsfromD h Gumbel-softmax temperature to 1.0 and use a SGD opti-\n6: D l′ ←samplerandomlykpointsfromD l mizer with a learning rate tuned from the set {10n,n =\n7: D h′ s ←samplerandomly(0.5−h)kpointsfromD h′ 2,3,...,6}foreveryattack.\n8: D′ ←samplerandomly(0.5−h)kpointsfromD′\nls l\n9: D′ ←(D′ \\D′ )∪D′ Hyperparameters for our active attack In our attack\nh h hs ls\n10: D′ ←(D′\\D′ )∪D′ with an active adversary, detailed in Alg. 4, Adams’ hy-\nl l ls hs\n11: SplitD′equallyamongthefirst5clients perparameters are selected following a tuning process per-\nl\n12: SplitD′ equallyamongthelast5clients formed using Optuna (Akiba et al. 2019) hyperparameter\nh\noptimization framework. In all the experiments, values for\nthe learning rate, β and β are optimized to minimize\n1 2\neach client’s training loss. Learning rate is tuned in range\nNote that, for the full batch scenario (i.e., B = S ), nu-\nc [0.1,50], whereas β and β values are tested in range\nmerical inversion errors occurred in line 3 may prevent the 1 2\n[0.6,0.999].Theoptimalhyperparameters’setisdetermined\nexactcomputationofthelocalmodel,particularlywhenΘ\nout after50trials.\nis ill-conditioned. That explains why in Figure 2, we have\n||θˆ∗ − θ∗|| close to but not exactly equal to zero when\n2 C Additionalexperimentalresults\nB =S .8\nc\nC.1 Federatedleastsquaresregression\nB.3 DatasplittingstrategyforIncome-Ldataset\nHere, we show the results of AIAs for federated least\nFor Income-L dataset, we apply a splitting strategy to con- squaresregressiontask,onIncome-L,Income-AandMedi-\ntrol statisticalheterogeneity among the10 clients, which is caldatasets.Inalltheexperiments,eachclienttrainsalinear\ndetailedinAlg.5. modelfor300communicationroundswith1localepochand\nTo achieve this, we first partition the initial dataset into batchsize32.Thelearningrateissetto5·10−3.Thepassive\ntwoclusters,D handD l,whichexhibitstrongopposingcor- adversary may eavesdrop all the exchanged messages until\nrelations between the sensitive attribute and the target in- theendofthetraining.Theactiveadversarylaunchestheat-\ncome.Moreprecisely,D hcontainssamplesofrichmenand tack after 300 rounds for additional 10 and 50 rounds. All\npoorwomenandD l containssamplesofpoormenandrich attacks are targeted at a randomly chosen single client. To\nwomen(lines2-3).Wethenrandomlyselectmin(|D h|,|D l|)\napproximate the optimal local model of the targeted client,\nsamples from each cluster to have balanced size, denoted ourpassiveadversaryappliesAlg.3andouractiveadversary\nbyD h′ andD h′ (lines5-6).Initially,D h′ andD l′ haveclearly appliesAlg.4.\ndifferentdistributions.Byrandomlyswappingafractionof\nToreducethetaskdifficultybyalinearmodel,weshrink\n0.5−hofsamplesbetweenthetwoclusters(lines7-8),the\nthe feature space of Income-L and Income-A. More pre-\ndistributions of D′ and D′ become more similar as h de-\nh l cisely, we remove ‘Occupation’, ‘Relationship’, and ‘Place\ncreases.Lastly,eachclusterisdividedequallyintodatasets\nofBirth’features,transform‘RaceCode’and‘MaritalSta-\nforfiveclients(lines11-12).\ntus’ from categorical to binary features (i.e., White/Others\nand Married/Not married), and reduce the cardinality of\nB.4 Hyperparameters\n‘ClassofWorker’to3groups(Publicemployess/Privateem-\nLearning rates for FL training on neural net- ployees/Others).\nwork In the experiments on Income-L, clients train\nHyperparameters We optimize the set of messages for\ntheir model using varying batch sizes from the set\nboth our method and gradient-based passive attacks. For\nB = {32,64,128,256,512,1024}. The learning rates are\ntunedintherange[1·10−7,5·10−6],accordingtothebatch gradient-based attacks, the set of inspected messages T\nsize:5·10−7forbatchsizesof32and64,1·10−6forabatch is selected in Tp = {{firstt rounds in T c}, for t ∈\nsize of 128, 2 · 10−6 for batch sizes of 256 and 512, and {1,5,10,20,50,100,150,300}}.Forourattack,weexplore\n3·10−6forabatchsizeof1024.Wekeepthesamelearning a much larger number of sets of messages as our attack is\ncomputationally-light,evolvingonlysimplematrixcompu-\nrates when varying the number of local epochs and the\ntation. In particular, we randomly sample 107 sets of size\ndataheterogeneitylevel.ForIncome-A,thelearningrateis\nd + 1 and choose the one which minimizes the condition\n8Inrealpractice,theadversarycanoptimizethesetofthemes- numberofΘ out,sinceanill-conditionedmatrixΘ outleadsto\nsagesconsideredtominimizetheconditionnumberofΘ . ahighnumericalinversionerrorasmentionedinApp.B.2.\nout\nAllotherhyperparametersareconsistentwiththoseusedin\ntheneuralnetworkexperiments.\nDatesets\nIncome-L Income-A Medical\nAIA(%)\nGrad 53.10±1.40 49.74±3.17 87.76±3.80\nPassive Grad-w-O 58.19±0.41 55.97±0.38 94.68 ±0.23\nOurs 59.05 ±0.40 56.56 ±0.41 94.13±0.16\nActive\nGrad 53.10±1.40 49.74±3.17 87.76±3.80\n(10Rnds) Grad-w-O 59.06 ±0.07 57.18 ±0.39 94.68 ±0.23\nOurs 57.99±1.71 56.44±0.12 90.47±5.12\nActive\nGrad 53.10±1.40 49.74±3.17 87.76±3.80\n(50Rnds) Grad-w-O 60.69 ±0.30 57.18 ±0.39 94.68 ±0.23\nOurs 59.10±0.16 56.22±0.06 93.91±0.08\nModel-w-O 59.10±0.16 56.56±0.41 94.13±0.16\nTable 2: The AIA accuracy over one (random chosen) tar-\ngeted client local dataset, evaluated under both honest-but-\ncurious (passive) and malicious (active) adversaries across Figure 4: The AIA accuracy over all clients’ local datasets\nIncomeL,Income-AandMedicalFLdatasets.Thestandard underdifferentstartingpointsofactiveattackforIncome-L\ndeviationisevaluatedoverthreeFLtrainingruns.Allclients dataset(40%heterogeneitylevel).Theclientstrainaneural\nsolve a least squares regression problem running FedAvg networkthroughFedAvgwith1localepochandbatchsize\nwith1epochandbatchsize32.Forincome-L,weconsider 32.\nani.i.dsetting.\nResults in Table 2 show that our attacks outperform the whereas Grad does not demonstrate the same level of ef-\nbaselineGradinbothpassiveandactivescenariosonacross fectiveness.\nall three datasets. Notably, our passive attack achieves im-\nprovements of over 4, 5 and 7 percentage points (p.p.) C.4 Defense\nforIncome-L,Income-AandMedicaldatasets,respectively. Tomitigateprivacyleakage,weapplyafederatedversionof\nEven when the gradient-based method has access to an or- DP-SGD(Abadietal.2016),whichprovides(ϵ,δ)sample-\nacle, our passive attacks still achieves higher accuracy on level differential privacy guarantees (Dwork et al. 2006;\nIncome-A and Income-L and comes very close on Medi- Choudhuryetal.2019).Moreprecisely,theclientsclipand\ncaldataset.Moreimportantly,ourpassiveattackreachesal- addGaussiannoisestotheirgradientsinFL.WeusedOpa-\nready to the performance expected from an adversary who cus (Yousefpour et al. 2021) to incorporate a (1,1·10−5)-\nknowstheoptimallocalmodel,demonstratingtheeffective- differentially private defense on Income-L and Medical\nness of our passive approach in approximating the optimal datasets, and (1,1·10−6)-differentially private defense on\nlocal model (Alg. 3). When shifting to active attacks, the Income-A.Allattacksaretargetedatarandomlychosensin-\nperformancegainoverGradremainslargelyconsistentafter gle client. Other experimental settings are consistent with\n50activerounds. thoseusedintheneuralnetworkexperiments.\nHyperparameters for defense We adjust the clipping\nC.2 Impactofthestartingroundforactiveattack\nnormforeachdatasetandselecttheonethatyieldsthelow-\nIn our implementations, with a local epoch of 1, all ac-\nest validation loss in the final global model. For Income-L\ntive attacks were initiated from the 100th communication\nandIncome-Adatasets,theclippingnormistunedoverthe\nround. Here, we vary the starting round of the active at- set{1·106,3·106,5·106,7·106,9·1061·107,3·107,5·107}.\ntacks and run the attacks for additional 50 rounds. We il-\nForMedicaldataset,theclippingnormistunedovertheset\nlustrate the attacks’ performance in Figure 4. We observe {5·105,7·105,9·105,1·106,3·106,5·106,7·106,9·106}.\nthat our approach shows slight improvements when the at-\ntack is launched in the later phases of training. However,\nTable 3 presents the results with both active and honest-\nthegradient-basedmethodGradismoreeffectiveduringthe\nbut-curious adversaries. Our passive attacks significantly\nearlytrainingphase.Overall,ourapproachmaintainsanad-\noutperform Grad baselines on Income-A and Medical\nvantageofover12percentagepoints.\ndatasets,achievingover30and8percentagepointimprove-\nmentsonIncome-AandMedicaldatasets,respectively.Fur-\nC.3 Impactofthenumberofactiverounds\nthermore, our attacks improve also Grad-w-O baseline by\nWeevaluatetheperformanceofactiveattacksunderdiffer- 4 percentage points on Income-A and 3 percentage points\nentnumbersofactiverounds|Ta|(Figure5),duringwhich on Medical. Surprisingly, passive gradient-based attacks\nc\nan active adversary launches attacks. Our attack becomes demonstratebetterperformancethanOursonIncome-L,de-\nmore powerful as the number of active rounds increases, spite having near-zero cosine similarity. This observation\nDatasets\nIncome-L Income-A Medical\nFigure 5: The AIA accuracy over all clients’ local datasets AIA(%)\nunder different numbers of active rounds for Income-L Grad 59.34±3.58 50.52±2.49 63.51±6.63\ndataset (40% heterogeneity level). The clients train a neu- Passive Grad-w-O 77.67 ±1.01 53.83±0.19 91.09±0.08\nral network through FedAvg with 1 local epoch and batch Ours 48.69±4.03 58.08 ±0.11 94.19 ±0.23\nsize32.\nActive\nGrad 59.34±3.58 50.52±2.49 63.51±6.63\n(10Rnds) Grad-w-O 77.67 ±1.01 54.42±2.77 91.09±0.08\nOurs 62.04±3.16 57.60 ±0.85 93.96 ±0.41\ns riu cg fg oe rst grth adat iec no t-s bin ase edsim ati tl aa cr kit sy ’ om pa ty imn izo at tib oe n.a Msu oi vt ia nb gle tom te ht e- (5A 0c Rti nv de s) GrG adr -a wd -O 5 79 7. .3 64 7± ±3 1. .5 08 1 5 50 4. .5 42 2± ±2 2. .4 79 7 6 93 1. .5 01 9± ±6 0. .6 03 8\nactive adversary, our attacks exhibit minimal performance Ours 71.37±1.86 57.25 ±0.86 94.30 ±0.08\nchangesbetweenrounds10and50onIncome-AandMed-\nicaldatasets,astheyapproachtheempiricaloptimalperfor-\nModel-w-O 79.33±1.11 58.53±0.61 94.30±0.08\nmance achievable by Model-w-O. Conversely, on Income-\nTable 3: The AIA accuracy over one (random chosen) tar-\nL,whereperformancemarginsarelarger,ourattacksurpass\ngetedclient’slocaldatasetevaluatedunderbothhonest-but-\nGrad by 3 and 12 percentage points after 10 and 50 active\ncurious (passive) and malicious (active) adversaries across\nrounds,respectively,withpotentialforfurtheroptimization\nIncomeL,Income-AandMedicalFLdatasets.Thestandard\ntomatchtheoptimallocalmodelperformance.\ndeviationisevaluatedoverthreeFLtrainingruns.Allclients\ntrain a neural network through a federated version of DP-\nSGDwith1localepochandbatchsize32,providing(ϵ=1,\nδ = 1 · 10−5) sample level differential privacy for every\nclientonMedicalandIncome-L,and(ϵ = 1,δ = 1·10−6)\nsampleleveldifferentialprivacyonIncome-A.",
    "pdf_filename": "Attribute_Inference_Attacks_for_Federated_Regression_Tasks.pdf"
}