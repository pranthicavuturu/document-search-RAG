{
    "title": "Indicative Summarization of Long Discussions",
    "context": "Online forums encourage the exchange and discussion of different stances on many top- ics. Not only do they provide an opportunity to present one’s own arguments, but may also gather a broad cross-section of others’ argu- ments. However, the resulting long discussions are difficult to overview. This paper presents a novel unsupervised approach using large lan- guage models (LLMs) to generating indicative summaries for long discussions that basically serve as tables of contents. Our approach first clusters argument sentences, generates cluster the generated cluster labels into argumentation frames resulting in a two-level summary. Based on an extensively optimized prompt engineer- ing approach, we evaluate 19 LLMs for genera- tive cluster labeling and frame classification. To evaluate the usefulness of our indicative summaries, we conduct a purpose-driven user study via a new visual interface called DISCUS- SION EXPLORER: It shows that our proposed indicative summaries serve as a convenient nav- igation tool to explore long discussions.1 1 Online discussion forums are a popular medium for discussing a wide range of topics. As the size of a community grows, so does the average length of the discussions held there, especially when current controversial topics are discussed. On Change- MyView (CMV),2 for example, discussions often go into the hundreds of arguments covering many perspectives on the topics in question. Initiating, participating in, or reading discussions generally has two goals: to learn more about others’ views on a topic and/or to share one’s own. To help their users navigate large volumes of arguments in long discussions, many forums offer basic features to sort them, for example, by time of creation or popularity. However, these alternative views may not capture the full range of perspectives *Equal contribution. 1Code: https://github.com/webis-de/EMNLP-23 2https://www.reddit.com/r/changemyview/ exchanged, so it is still necessary to read most of them for a comprehensive overview. In this paper, we depart from previous approaches to summariz- ing long discussions by using indicative summaries instead of informative summaries.3 Figure 1 illus- trates our three-step approach: first, the sentences of the arguments are clustered according to their latent subtopics. Then, a large language model gen- ter as its label. Finally, the argument frame (Chong and Druckman, 2007; Boydstun et al., 2014) of each cluster label is predicted as a generalizable operationalization of perspectives on a discussion’s topic. From this, a hierarchical summary is created in the style of a table of contents, where frames act as headings and cluster labels as subheadings. To our knowledge, indicative summaries of this type have not been explored before (see Section 2). Our four main contributions are: (1) A fully un- supervised approach to indicative summarization of long discussions (Section 3). We develop robust prompts for generative cluster labeling and frame assignment based on extensive empirical evaluation and best practices (Section 4). (2) A comprehen- sive evaluation of 19 state-of-the-art, prompt-based, large language models (LLMs) for both tasks, sup- ported by quantitative and qualitative assessments (Section 5). (3) A user study of the usefulness of in- dicative summaries for exploring long discussions (Section 5). (4) DISCUSSION EXPLORER, an inter- active visual interface for exploring the indicative summaries generated by our approach and the cor- responding discussions.4 Our results show that the GPT variants of OpenAI (GPT3.5, ChatGPT, and GPT4) outperform all other open source models at the time of writing. LLaMA and T0 perform well, but are not competitive with the GPT models. Regarding the usefulness of the summaries, users preferred our summaries to alternative views to ex- plore long discussions with hundreds of arguments. 3Unlike an informative summary, an indicative summary does not capture as much information as possible from a text, but only its gist. This makes them particularly suitable for long documents like books in the form of tables of contents. 4https://discussion-explorer.web.webis.de/ arXiv:2311.01882v1  [cs.CL]  3 Nov 2023",
    "body": "Indicative Summarization of Long Discussions\nShahbaz Syed †*\nDominik Schwabe †*\nKhalid Al-Khatib ‡\nMartin Potthast †§\n†Leipzig University\n‡University of Groningen\n§ScaDS.AI\nshahbaz.syed@uni-leipzig.de\nAbstract\nOnline forums encourage the exchange and\ndiscussion of different stances on many top-\nics. Not only do they provide an opportunity\nto present one’s own arguments, but may also\ngather a broad cross-section of others’ argu-\nments. However, the resulting long discussions\nare difficult to overview. This paper presents\na novel unsupervised approach using large lan-\nguage models (LLMs) to generating indicative\nsummaries for long discussions that basically\nserve as tables of contents. Our approach first\nclusters argument sentences, generates cluster\nlabels as abstractive summaries, and classifies\nthe generated cluster labels into argumentation\nframes resulting in a two-level summary. Based\non an extensively optimized prompt engineer-\ning approach, we evaluate 19 LLMs for genera-\ntive cluster labeling and frame classification.\nTo evaluate the usefulness of our indicative\nsummaries, we conduct a purpose-driven user\nstudy via a new visual interface called DISCUS-\nSION EXPLORER: It shows that our proposed\nindicative summaries serve as a convenient nav-\nigation tool to explore long discussions.1\n1\nIntroduction\nOnline discussion forums are a popular medium for\ndiscussing a wide range of topics. As the size of\na community grows, so does the average length of\nthe discussions held there, especially when current\ncontroversial topics are discussed. On Change-\nMyView (CMV),2 for example, discussions often\ngo into the hundreds of arguments covering many\nperspectives on the topics in question. Initiating,\nparticipating in, or reading discussions generally\nhas two goals: to learn more about others’ views\non a topic and/or to share one’s own.\nTo help their users navigate large volumes of\narguments in long discussions, many forums offer\nbasic features to sort them, for example, by time of\ncreation or popularity. However, these alternative\nviews may not capture the full range of perspectives\n*Equal contribution.\n1Code: https://github.com/webis-de/EMNLP-23\n2https://www.reddit.com/r/changemyview/\nexchanged, so it is still necessary to read most of\nthem for a comprehensive overview. In this paper,\nwe depart from previous approaches to summariz-\ning long discussions by using indicative summaries\ninstead of informative summaries.3 Figure 1 illus-\ntrates our three-step approach: first, the sentences\nof the arguments are clustered according to their\nlatent subtopics. Then, a large language model gen-\nerates a concise abstractive summary for each clus-\nter as its label. Finally, the argument frame (Chong\nand Druckman, 2007; Boydstun et al., 2014) of\neach cluster label is predicted as a generalizable\noperationalization of perspectives on a discussion’s\ntopic. From this, a hierarchical summary is created\nin the style of a table of contents, where frames act\nas headings and cluster labels as subheadings. To\nour knowledge, indicative summaries of this type\nhave not been explored before (see Section 2).\nOur four main contributions are: (1) A fully un-\nsupervised approach to indicative summarization\nof long discussions (Section 3). We develop robust\nprompts for generative cluster labeling and frame\nassignment based on extensive empirical evaluation\nand best practices (Section 4). (2) A comprehen-\nsive evaluation of 19 state-of-the-art, prompt-based,\nlarge language models (LLMs) for both tasks, sup-\nported by quantitative and qualitative assessments\n(Section 5). (3) A user study of the usefulness of in-\ndicative summaries for exploring long discussions\n(Section 5). (4) DISCUSSION EXPLORER, an inter-\nactive visual interface for exploring the indicative\nsummaries generated by our approach and the cor-\nresponding discussions.4 Our results show that the\nGPT variants of OpenAI (GPT3.5, ChatGPT, and\nGPT4) outperform all other open source models\nat the time of writing. LLaMA and T0 perform\nwell, but are not competitive with the GPT models.\nRegarding the usefulness of the summaries, users\npreferred our summaries to alternative views to ex-\nplore long discussions with hundreds of arguments.\n3Unlike an informative summary, an indicative summary does\nnot capture as much information as possible from a text, but\nonly its gist. This makes them particularly suitable for long\ndocuments like books in the form of tables of contents.\n4https://discussion-explorer.web.webis.de/\narXiv:2311.01882v1  [cs.CL]  3 Nov 2023\n\nSummary generation\nUnit clustering \nCluster labeling &\nframe assignment\nDiscussion\nCluster 1\nCluster 2\nCluster 3\nLabel 1\nLabel 2\nLabel 3\n...\nFrames: A, B, F\nFrames: C, D, G\nFrames: B, E, G\nSummary presentation\nTopic\nConceptual\nExample (simplified)\nFrame A\nFrame B\nFrame C\n- Label 1\n- Label 4\n- Label 3\nTopic\n...\n...\n...\n- Label 2\n- Label 1\nPolitical\nEconomic\nCrime & Punishment\n- U.S. real estate policy has sent\n  prices soaring since the 90s. (85)\n- Bias to American issues. (45)\n- U.S. real estate policy has sent\n  prices soaring since the 90s. (68)\n- Fragmented economic power. (20)\n- Violent crime declined since the\n  90s, but remains a problem. (102) \nThis is the best time in human history. (655)\n(replies; click label to view)\nFigure 1: Left: Illustration of our approach to generating indicative summaries for long discussions. The main steps\nare (1) unit clustering, (2) generative cluster labeling, and (3) multi-label frame assignment in order of relevance.\nRight: Conceptual and exemplary presentation of our indicative summary in table of contents style. Frames act as\nheadings and the corresponding cluster labels as subheadings.\n2\nRelated Work\nPrevious approaches to generating discussion sum-\nmaries have mainly focused on generating extrac-\ntive summaries, using two main strategies: extract-\ning significant units (e.g., responses, paragraphs,\nor sentences), or grouping them into specific cate-\ngories, which are then summarized. In this section,\nwe review the relevant literature.\n2.1\nExtractive Summarization\nExtractive approaches use supervised learning or\ndomain-specific heuristics to extract important en-\ntities from discussions as extractive summaries.\nFor example, Klaas (2005) summarized UseNet\nnewsgroup threads by considering thread structure\nand lexical features to measure message impor-\ntance. Tigelaar et al. (2010) identified key sen-\ntences based on author names and citations, fo-\ncusing on coherence and coverage in summaries.\nRen et al. (2011) developed a hierarchical Bayesian\nmodel for tracking topics, using a random walk al-\ngorithm to select representative sentences. Ranade\net al. (2013) extracted topic-relevant and emotive\nsentences, while Bhatia et al. (2014) and Tarn-\npradab et al. (2017) used dialogue acts to summa-\nrize question-answering forum discussions. Egan\net al. (2016) extracted key points using dependency\nparse graphs, and Kano et al. (2018) summarized\nReddit discussions using local and global context\nfeatures. These approaches generate informative\nsummaries, substituting discussions without back-\nreferencing to them.\n2.2\nGrouping-based Summarization\nGrouping-based approaches group discussion units\nlike posts or sentences, either implicitly or explic-\nitly. The groups are based on queries, aspects, top-\nics, dialogue acts, argument facets, or key points\nannotated by experts. Once the units are grouped,\nindividual summaries are generated for each group\nby selecting representative members, respectively.\nThis grouping-then-summarization paradigm\nhas been primarily applied to multi-document sum-\nmarization of news articles (Radev et al., 2004).\nFollow-up work proposed cluster link analysis\n(Wan and Yang, 2008), cluster sentence ranking\n(Cai et al., 2010), and density peak identification in\nclusters (Zhang et al., 2015). For abstractive multi-\ndocument summarization, Nayeem et al. (2018)\nclustered sentence embeddings using a hierarchical\nagglomerative algorithm, identifying representative\nsentences from each cluster using TextRank (Mihal-\ncea and Tarau, 2004) on the induced sentence graph.\nSimilarly, Fuad et al. (2019) clustered sentence em-\nbeddings and selected subsets of clusters based on\nimportance, coverage, and variety. These subsets\nare then input to a transformer model trained on the\nCNN/DailyMail dataset (Nallapati et al., 2016) to\ngenerate a summary. Recently, Ernst et al. (2022)\nused agglomerative clustering of salient statements\nto summarize sets of news articles, involving a su-\npervised ranking of clusters by importance.\nFor Wikipedia discussions, Zhang et al. (2017)\nproposed the creation of a dynamic summary tree\nto ease subtopic navigation at different levels of de-\ntail, requiring editors to manually summarize each\n\ntree node’s cluster. Misra et al. (2015) used sum-\nmarization to identify arguments with similar as-\npects in dialogues from the Internet Argument Cor-\npus (Walker et al., 2012). Similarly, Reimers et al.\n(2019) used agglomerative clustering of contextual\nembeddings and aspects to group sentence-level ar-\nguments. Bar-Haim et al. (2020a,b) examined the\nmapping of debate arguments to key points written\nby experts to serve as summaries.\nOur approach clusters discussion units, but in-\nstead of a supervised selection of key cluster mem-\nbers, we use vanilla LLMs for abstractive summa-\nrization. Moreover, our summaries are hierarchical,\nusing issue-generic frames as headings (Chong and\nDruckman, 2007; Boydstun et al., 2014) and gener-\nating concise abstractive summaries of correspond-\ning clusters as subheadings. Thus our approach is\nunsupervised, facilitating a scalable and generaliz-\nable summarization of discussions.\n2.3\nCluster Labeling\nCluster labeling involves assigning representative\nlabels to document clusters to facilitate clustering\nexploration. Labeling approaches include compar-\ning term distributions (Manning et al., 2008), select-\ning key terms closest to the cluster centroid (Role\nand Nadif, 2014), formulating key queries (Gollub\net al., 2016), identify keywords through hypernym\nrelationships (Poostchi and Piccardi, 2018), and\nweak supervision to generate topic labels Popa and\nRebedea (2021). These approaches often select a\nsmall set of terms as labels that do not describe a\ncluster’s contents in closed form. Our approach\novercomes this limitation by treating cluster label-\ning as a zero-shot abstractive summarization task.\n2.4\nFrame Assignment\nFraming involves emphasizing certain aspects of a\ntopic for various purposes, such as persuasion (Ent-\nman, 1993; Chong and Druckman, 2007). Frame\nanalysis for discussions provides insights into dif-\nferent perspectives on a topic (Morstatter et al.,\n2018; Liu et al., 2019). It also helps to identify\nbiases in discussions resulting, e.g., from word\nchoice (Hamborg et al., 2019b,a). Thus, frames\ncan serve as valuable reference points for organiz-\ning long discussions. We use a predefined inven-\ntory of media frames (Boydstun et al., 2014) for\ndiscussion summarization. Instead of supervised\nframe assignment (Naderi and Hirst, 2017; Ajjour\net al., 2019; Heinisch and Cimiano, 2021), we use\nprompt-based LLMs for more flexibility.\n3\nIndicative Discussion Summarization\nOur indicative summarization approach takes the\nsentences of a discussion as input and generates\na summary in the form of a table of contents, as\nshown in Figure 1. Its three steps consist of clus-\ntering discussion sentences, cluster labeling, and\nframe assignment to cluster labels.\n3.1\nUnit Clustering\nGiven a discussion, we extract its sentences as dis-\ncussion units. The set of sentences is then clustered\nusing the density-based hierarchical clustering al-\ngorithm HDBSCAN (Campello et al., 2013). Each\nsentence is embedded using SBERT (Reimers and\nGurevych, 2019) and these embeddings are then\nmapped to a lower dimensionality using UMAP\n(McInnes et al., 2017).5\nUnlike previous ap-\nproaches that rank and filter clusters to generate\ninformative summaries (Ernst et al., 2022; Syed\net al., 2023), our summaries incorporate all clus-\nters. The sentences of each cluster are ranked by\ncentrality, which is determined by the λ value of\nHDBSCAN. A number of central sentences per\ncluster are selected as input for cluster labeling by\nabstractive summarization.\nMeta-sentence filtering\nSome sentences in a dis-\ncussion do not contribute directly to the topic, but\nreflect the interaction between its participants. Ex-\namples include sentences such as “I agree with\nyou.” or “You are setting up a straw man.” Pilot\nexperiments have shown that such meta-sentences\nmay cause our summarization approach to include\nthem in the final summary. As these are irrele-\nvant to our goal, we apply a corpus-specific and\nchannel-specific meta-sentence filtering approach,\nrespectively. Corpus-specific filtering is based on a\nsmall set of frequently used meta-sentences M in\na large corpus (e.g., on Reddit). It is bootstrapped\nduring preprocessing, and all sentences in it are\nomitted by default.6\nOur pilot experiments revealed that some sen-\ntences in discussions are also channel-specific (e.g.,\nfor the ChangeMyView Subreddit).\nTherefore,\nwe augment our sentence clustering approach by\nadding a random sample M′ ⊂M to the set of sen-\ntences D of each individual discussion before clus-\ntering, where |M′| = max{300, |D|}. The maxi-\nmum value for the number of meta-sentences |M′|\n5Implementation details are given in Appendix B.\n6The set is used like a typical stop word list, only for sentences.\n\nis chosen empirically, to maximize the likelihood\nthat channel-specific meta-sentences are clustered\nwith corpus-specific ones.\nAfter clustering the\njoint set of meta-sentences and discussion sen-\ntences D ∪M′, we obtain the clustering C. Let\nmC = |C ∩M′| denote the number of meta-\nsentences and dC = |C ∩D| the number of discus-\nsion sentences in a cluster C ∈C. The proportion\nof meta-sentences in a cluster is then estimated as\nP(M′|C) =\nmC\nmC+dC .\nA cluster C is classified as a meta-sentence clus-\nter if P(M′|C) > θ·P(M′), where P(M′) = |M′|\n|D|\nassumes that meta-sentences are independent of\nothers in a discussion. The noise threshold θ = 2\n3\nwas chosen empirically. Sentences in a discussion\nthat either belong to a meta-sentence cluster or\nwhose nearest cluster is considered to be one are\nomitted. In our evaluation, an average of 23% of\nsentences are filtered from discussions. Figure 2\nillustrates the effect of meta-sentence filtering on a\ndiscussion’s set of sentence.\n3.2\nGenerative Cluster Labeling\nMost cluster labeling approaches extract keywords\nor key phrases as labels, which limits their fluency.\nThese approaches may also require training data\nacquisition for supervised learning. We formulate\ncluster labeling as an unsupervised abstractive sum-\nmarization task. We experiment with prompt-based\nlarge language models in zero-shot and few-shot\nsettings. This enables generalization across multi-\nple domains, the elimination of supervised learning,\nand fluent cluster labels with higher readability in\ncomparison to keywords or phrases.\nWe develop several prompt templates specifi-\ncally tailored for different types of LLMs. For\nencoder-decoder models, we carefully develop ap-\npropriate prompts based on PromptSource (Bach\net al., 2022), a toolkit that provides a comprehen-\nsive collection of natural language prompts for var-\nious tasks across 180 datasets. In particular, we\nanalyze prompts for text summarization datasets\nwith respect to (1) descriptive words for the gener-\nation of cluster labels using abstractive summariza-\ntion, (2) commonly used separators to distinguish\ninstructions from context, (3) the position of in-\nstructions within prompts, and (4) the granularity\nlevel of input data (full text, document title, or sen-\ntence). Since our task is about summarizing groups\nof sentences, we chose prompts that require the\nfull text as input to ensure that enough contextual\n(a) Joint clustering of a discussion and meta-sentences D∪M ′.\n(b) The sampled meta-sentences M ′ ⊂M highlighted gray.\n(c) Classification of meta-sentence clusters to be omitted.\nFigure 2: Effect of meta-sentence filtering: (a and b) A\ndiscussion’s sentences D are jointly clustered with a\nsample of meta-sentences M ′ ⊂M. (c) Then each\ncluster is classified as a meta-sentence cluster based\non its proportion of meta-sentences and its neighboring\nclusters. Meta-sentence clusters are omitted.\ninformation is provided (within the limits of each\nmodel’s input size). Section 4.1 provides details on\nthe prompt engineering process.\n\n3.3\nFrame Assignment\nAny controversial topic can be discussed from dif-\nferent perspectives. For example, “the dangers of\nsocial media” can be discussed from a moral or a\nhealth perspective, among others. In our indicative\nsummaries, we use argumentation frame labels as\ntop-level headings to operationalize different per-\nspectives. An argumentation frame may include\none or more groups of relevant arguments. We\nassign frame labels from the issue-generic frame\ninventory shown in Table 1 (Boydstun et al., 2014)\nto each cluster label derived in the previous step.7\nWe use prompt-based models in both zero-shot\nand few-shot settings for frame assignment. In\nour experiments with instruction-tuned models,\nwe designed two types of instructions, shown in\nFigure 10, namely direct instructions for models\ntrained on instruction–response samples, and dia-\nlog instructions for chat models. The instructions\nare included along with the cluster labels in the\nprompts. Moreover, including the citation of the\nframe inventory used in our experiments has a posi-\ntive effect on the effectiveness of some models (see\nAppendix D.1 for details).\n3.4\nIndicative Summary Presentation\nGiven the generated labels of all sentence clusters\nand the frame labels assigned to each cluster label,\nour indicative summary groups the cluster labels\nby their respective frame labels. The cluster label\ngroups of each frame label are then ordered by\ncluster size. This results in a two-level indicative\nsummary, as shown in Figures 1 and 4.\n4\nPrompt Engineering\nUsing prompt-based LLMs for generative clus-\nter labeling and frame assignment requires model-\nspecific prompt engineering as a preliminary step.\nWe explored the 19 model variants listed in Table 2.\nTo select the most appropriate models for our task,\nwe consulted the HELM benchmark (Liang et al.,\n2022), which compares the effectiveness of differ-\nent LLMs for different tasks. Further, we have in-\ncluded various recently released open source mod-\nels (with optimized instructions) as they were re-\nleased. Since many of them were released during\nour research, we reuse prompts previously opti-\nmized prompts for the newer models.8\n7For detailed label descriptions see Table 6 in the Appendix.\n8See Appendices C and D for details.\nFrame Inventory\nCapacity & Resources\nFairness & Equality\nConstitutionality &\nHealth & Safety\nJurisprudence\nMorality\nCrime & Punishment\nPolicy Prescription & Evaluation\nCultural Identity\nPolitical\nEconomic\nPublic Opinion\nExternal Regulation &\nQuality of Life\nReputation\nSecurity & Defense\nTable 1: Inventory of frames proposed by Boydstun et al.\n(2014) to track the media’s framing of policy issues.\nModel\nVariants\nDescription\nPre-InstructGPT\nT0\nvanilla\nEncoder-decoder model trained on datasets\ntransformed as task-specific prompts.\nBLOOM\nvanilla\nA multlingual autoregressive model with 176B\nparameters for prompt-based text completion.\nGPT-NeoX\n20B\nOpen source alternative to GPT-3.\nOPT\n66B\nAutoregressive model with similar effective-\nness to GPT-3, but more efficient data collec-\ntion and training.\nDirect Instruction\nLLaMA-CoT\nvanilla\nLLaMA-30B fine-tuned on chain-of-thought\nand reasoning samples (Si and Lin, 2023).\nAlpaca\n7B\nLLaMA-7B fine-tuned based on 52k self-\ninstruct responses (Wang et al., 2022).\nOASST\nvanilla\nLLaMA-30B fine-tuned on the OpenAssistant\nConversations dataset (Köpf et al., 2023) using\nreinforcement learning.\nPythia\n12B\nSuite of LLMs trained on public data to in-\nvestigate the effects of training and scaling on\nvarious model properties.\nGPT*\n3.5, Chat, 4\nOpenAI models GPT3.5 (text-davinci-003),\nChatGPT (gpt-3.5-turbo), and GPT4.\nDialogue Instruction\nLLaMA\n30B, 65B\nSuite of open-source LLMs from Meta AI\ntrained on public datasets.\nVicuna\n7B, 13B\nLLaMA models fine-tuned using conversa-\ntions collected by ShareGPT (https://sharegpt.\ncom)\nBaize\n7B, 13B\nOpen source chat model trained on 100k di-\nalogues generated by letting ChatGPT (GPT\n3.5-turbo) talk to itself.\nFalcon\n40B,\n40B-Instruct\nTrained on the RefinedWeb corpus (Penedo\net al., 2023), which was obtained by filtering\nand deduplication of public web data.\nTable 2: LLMs studied for cluster labeling and frame as-\nsignment. Older models are listed by Pre-InstructGPT\n(prior to GPT3.5) and newer models are listed by\ntheir respective prompt types investigated ( Direct /\nDialogue ). See Appendices C and D for details.\n\nGPT3.5 for Generative Cluster Labeling\nGenerate a single descriptive phrase that describes\nthe following debate in very simple language, without\ntalking about the debate or the author.\nDebate: \"\"\"{text}\"\"\"\nGPT4 for Frame Assignment\nThe following {input_type}a contains all available\nmedia frames as defined in the work from {authors}:\n{frames} For every input, you answer with three of\nthese media frames corresponding to that input, in\norder of importance.\naA list of frame labels or a JSON with frame labels\nand their descriptions.\nFigure 3: The best performing instructions for cluster\nlabeling and frame assignment. For frame assignment,\nciting the frame inventory using the placeholder {au-\nthors} has a positive impact on the effectiveness of some\nmodels (see Appendix D.1 for details).\n4.1\nCluster Labeling\nThe prompts for the encoder-decoder model T0\nare based on the PROMPTSOURCE (Bach et al.,\n2022) toolkit. We have experimented with differ-\nent prompt templates and tried different combina-\ntions of input types (e.g. “text”, “debate”, “dis-\ncussion”, and “dialogue”) and output types (e.g.\n“title”, “topic”, “summary”, “theme”, and “thesis”).\nThe position of the instruction within a prompt was\nalso varied, taking into account prefix and suffix\npositions. For decoder-only models like BLOOM,\nGPT-NeoX, OPT-66B, and OPT, we experimented\nwith hand-crafted prompts. For GPT3.5, we fol-\nlowed the best practices described in OpenAI’s API\nand created a single prompt.\nPrompts were evaluated on a manually annotated\nset of 300 cluster labels using BERTScore (Zhang\net al., 2020). We selected the most effective prompt\nfor each of the above models for cluster labeling.\nOur evaluation in Section 5 shows that GPT3.5\nperforms best in this task. Figure 3 (top) shows the\nbest prompt for this model.9\n4.2\nFrame Assignment\nFor frame assignment, models were prompted to\npredict a maximum of three frame labels for a given\ncluster label, ordered by relevance. Experiments\nwere conducted with both direct instructions and\ndialogue prompts in zero-shot and few-shot set-\n9ChatGPT and GPT4 were released after our evaluation.\ntings. In the zero-shot setting, we formulated three\nprompts containing (1) only frame labels, (2) frame\nlabels with short descriptions, and (3) frame labels\nwith full text descriptions (see Appendix D.2 for\ndetails). For the few-shot setting, we manually an-\nnotated up to two frames from the frame inventory\nof Table 1 for each of the 300 cluster labels gen-\nerated by the best model GPT3.5 in the previous\nstep. We included 42 examples (3 per frame) in\nthe few-shot prompt containing the frame label, its\nfull-text description, and three examples. The re-\nmaining 285 examples were used for subsequent\nframe assignment evaluation. Our evaluation in\nSection 5 shows that GPT4 performs best on this\ntask. Figure 3 (bottom) shows its best prompt.\n5\nEvaluation\nTo evaluate our approach, we conducted automatic\nand manual evaluations focused on the cluster la-\nbeling quality and the frame assignment accuracy.\nWe also evaluated the utility of our indicative sum-\nmaries in a purpose-driven user study in which\nparticipants had the opportunity to explore long\ndiscussions and provide us with feedback.\n5.1\nData and Preprocessing\nWe used the “Winning Arguments” corpus from\nTan et al. (2016) as a data source for long dis-\ncussions.\nIt contains 25,043 discussions from\nthe ChangeMyView Subreddit that took place be-\ntween 2013 and 2016. The corpus was prepro-\ncessed by first removing noise replies and then\nmeta-sentences. Noise replies are marked in the\nmetadata of the corpus as “deleted” by their re-\nspective authors, posted by bots, or removed by\nmoderators. In addition, replies that referred to\nthe Reddit guidelines or forum-specific modera-\ntion were removed using pattern matching (see Ap-\npendix A for details). The remaining replies were\nsplit into a set of sentences using Spacy (Honni-\nbal et al., 2020). To enable the unit clustering (of\nsentences) as described in Section 3.1, the set of\nmeta-sentences M is bootstrapped by first cluster-\ning the entire set of sentences from all discussions\nin the corpus and then manually examining the clus-\nters to identify those that contain meta-sentences,\nresulting in |M| = 955 meta-sentences. After fil-\ntering out channel-specific noise, the (cleaned) sets\nof discussion sentences are clustered as described.\nEvaluation Data\nFrom the preprocessed discus-\nsions, 300 sentence clusters were randomly se-\n\nModel\nMean Rank\n# First\nLength\nMin\nMax\nMean\nGPT3.5\n1.38\n225\n3\n27\n9.44\nBLOOM\n2.95\n33\n1\n37\n8.13\nGPT-NeoX\n3.20\n20\n1\n34\n7.42\nOPT\n3.36\n12\n1\n30\n8.27\nT0\n3.72\n28\n1\n18\n3.10\nTable 3: Results of the qualitative evaluation of gen-\nerative cluster labeling. Shown are (1) the mean rank\nof a model from four annotators and (2) the number of\ntimes a model was ranked first by an annotator. GPT3.5\n(text-davinci-003) performed better than other models\nand generated longer labels on average.\nlected. Then, we manually created a cluster label\nand up to three frame labels for each cluster. Due\nto the short length of the cluster labels, up to two\nframes per label were sufficient. After excluding\n57 examples with ambiguous frame assignments,\nwe obtained a reference set of 243 cluster label\nsamples, each labeled with up to two frames.\n5.2\nGenerative Cluster Labeling\nThe results of the automatic cluster labeling evalu-\nation using BERTScore and ROUGE are shown in\n(Appendix) Tables 7 and 8, respectively. We find\nthat ChatGPT performs best. To manually evaluate\nthe quality of the cluster labels, we used a ranking-\nbased method in which four annotators scored the\ngenerated cluster labels against the manually anno-\ntated reference labels of each of the 300 clusters.\nTo provide additional context for the cluster con-\ntent, the five most semantically similar sentences to\nthe reference label from each cluster were included,\nas well as five randomly selected sentences from\nthe cluster. To avoid possible bias due to the length\nof the cluster labels by different models, longer la-\nbels were truncated to 15 tokens.10 To determine an\nannotator’s model ranking, we merged the prefer-\nence rankings for all clusters using reciprocal rank\nfusion (Cormack et al., 2009). Annotator agree-\nment was calculated using Kendall’s W for rank\ncorrelation (Kendall, 1948), which yielded a value\nof 0.66, indicating substantial agreement.\nThe average ranking of each model is shown in\nTable 3 along with the length distributions of the\ngenerated cluster labels.11 GPT3.5 showed supe-\n10Figure 9 in the Appendix shows the annotation interfaces.\n11As newer models were published after our manual evalua-\ntion, we show an automatic evaluation of all models using\nhuman and GPT3.5-based reference labels in the Appendix\nModel\nZero-Shot\nFew-Shot\n–\nshort\nfull\nAlpaca-7B\n39.1\n39.5\n28.4\n20.6\nBaize-7B\n34.2\n34.6\n39.1\n30.9\nBaize-13B\n42.4\n48.1\n42.0\n39.5\nBLOOM\n26.7\n31.7\n25.5\n–\nChatGPT\n60.92\n58.03\n58.82\n63.42\nFalcon-40B\n46.5\n46.5\n46.1\n38.3\nFalcon-40B-Inst.\n51.4\n44.4\n32.9\n28.4\nGPT3.5\n53.53\n60.91\n58.03\n53.94\nGPT4\n63.41\n60.52\n65.41\n67.11\nGPT-NeoX\n19.3\n25.1\n31.3\n31.3\nLLaMA-30B\n45.7\n41.2\n39.1\n40.7\nLLaMA-CoT\n46.9\n54.34\n49.8\n57.23\nLLaMA-65B\n53.14\n50.65\n39.5\n–\nOASST\n48.65\n48.1\n53.55\n47.7\nOPT\n16.0\n13.2\n14.8\n–\nPythia\n31.7\n33.3\n30.5\n29.6\nT0\n48.65\n54.34\n55.64\n49.85\nVicuna-7B\n28.4\n36.2\n35.4\n20.2\nVicuna-13B\n44.0\n40.7\n42.0\n38.3\nTable 4: Results of an automatic evaluation of 19 LLMs\n(sorted alphabetically) for frame assignment, indicating\nthe five best models in each setting. Shown are the per-\ncentages of samples where the first frame predicted by\na model is one of the reference frames. The three zero-\nshot columns denote the prompt type: frame label only,\nlabel with short description, and label with full descrip-\ntion. Model types are also indicated: Pre-InstructGPT ,\nDirect / Dialogue . Missing values are model infer-\nences that exceed our computational resources.\nrior effectiveness in generating high-quality cluster\nlabels. It ranked first in 225 out of 300 comparisons,\nwith an average score of 1.38 by the four annotators.\nThe cluster labels generated by GPT3.5 were longer\non average (9.4 tokens) and thus more informative\nthan those generated by the other models, which\noften generated disjointed or incomplete labels. In\nparticular, T0 generated very short labels on aver-\nage (3.1 tokens) that were generic/non-descriptive.\n5.3\nFrame Assignment\nIn the zero-/few-shot frame assignment settings de-\nscribed in Section 4.2, we prompted the models\nto predict three frames per cluster label in order\nof relevance. Using the manually annotated refer-\nence set of 243 cluster labels and their frame labels,\nwe evaluated the accuracy of the frames predicted\nfor each cluster label that matched the reference\nframes. The results for the first predicted frame\nin Tables 7 and 8.\n\nare shown in Table 4. In most cases, GPT4 out-\nperforms all other models in the various settings,\nwith the exception of the zero-shot setting with a\nshort prompt, where GPT3.5 narrowly outperforms\nGPT4 with 60.9% accuracy versus 60.5%. Among\nthe top five models, the GPT* models that follow\ndirect user instructions perform consistently well,\nwith the LLaMA-/65B/-CoT and T0 models show-\ning strong effectiveness among the open-source\nLLMs. Conversely, the OPT model performs con-\nsistently worse in all settings. The few-shot setting\nshows greater variance in results, suggesting that\nthe models are more sensitive to the labeled exam-\nples provided in the prompts. Including a citation\nto the frame inventory paper in the instructions (see\nFigure 10) significantly improved the effectiveness\nof Falcon-40B (12%) and LLaMA-65B (9%) in the\nzero-shot setting (see Appendix D.1 for details).\n5.4\nUsefulness Evaluation\nIn addition to assessing each step of our approach,\nwe conducted a user study to evaluate the effec-\ntiveness of the resulting indicative summaries. In\nthis study, we considered two key tasks: explo-\nration and participation. With respect to explo-\nration, our goal was to evaluate the extent to which\nthe summaries help users explore the discussion\nand discover new perspectives. With respect to par-\nticipation, we wanted to assess how effectively the\nsummaries enabled users to contribute new argu-\nments by identifying the appropriate context and\nlocation for a response.\nWe asked five annotators to explore five ran-\ndomly selected discussions from our dataset, for\nwhich we generated indicative summaries using our\napproach with GPT3.5. To facilitate intuitive ex-\nploration, we developed DISCUSSION EXPLORER\n(see Section 5.5), an interactive visual interface\nfor the evaluated discussions and their indicative\nsummaries. In addition to our summaries, two\nbaselines were provided to annotators for compar-\nison: (1) the original web page of the discussion\non ChangeMyView, and (2) a search engine in-\nterface powered by Spacerini (Akiki et al., 2023).\nThe search engine indexed the sentences within a\ndiscussion using the BM25 retrieval model. This\nallowed users to explore interesting perspectives\nby selecting self-selected keywords as queries, as\nopposed to the frame and cluster labels that our\nsummaries provide. Annotators selected the best of\nthese interfaces for exploration and participation.\nResults\nWith respect to the exploration task, the\nfive annotators agreed that our summaries outper-\nformed the two baselines in terms of discovering\narguments from different perspectives presented\nby participants. The inclusion of argumentation\nframes proved to be a valuable tool for the annota-\ntors, facilitating the rapid identification of different\nperspectives and the accompanying cluster labels\nshowing the relevant subtopics in the discussion.\nFor the participation task, three annotators pre-\nferred the original web page, while our summaries\nand the search engine were preferred by the remain-\ning two annotators (one each) when it came to iden-\ntifying the appropriate place in the discussion to\nput their arguments. In a post-study questionnaire,\nthe annotators revealed that the original web page\nwas preferred because of its better display of the\nvarious response threads, a feature not comparably\nreimplemented in DISCUSSION EXPLORER. The\noriginal web page felt “more familiar.” However,\nwe anticipate that this limitation can be addressed\nby seamlessly integrating our indicative summaries\ninto a given discussion forum’s web page, creating\na consistent experience and a comprehensive and\neffective user interface for discussion participation.\n5.5\nDISCUSSION EXPLORER\nOur approach places emphasis on summary presen-\ntation by structuring indicative summaries into a\ntable of contents for discussions (see Section 3).\nTo demonstrate the effectiveness of this presenta-\ntion style in exploring long discussions, we have\ndeveloped an interactive tool called DISCUSSION\nEXPLORER.12 This tool illustrates how such sum-\nmaries can be practically applied. Users can par-\nticipate in discussions by selecting argumentation\nframes or cluster labels. Figure 4 presents indica-\ntive summaries generated by different models, pro-\nviding a quick overview of the different perspec-\ntives. This two-level table of contents-like sum-\nmary provides effortless navigation, allowing users\nto switch between viewing all arguments in a frame\nand understanding the context of sentences in a\ncluster of the discussion (see Figure 5).\n6\nConclusion\nWe have developed an unsupervised approach to\ngenerating indicative summaries of long discus-\nsions to facilitate their effective exploration and\nnavigation. Our summaries resemble tables of con-\n12https://discussion-explorer.web.webis.de/\n\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversation with a \ndepressed person\nFigure 4: DISCUSSION EXPLORER provides a concise overview of indicative summaries from various models\nfor a given discussion. The summary is organized hierarchically: The argument frames act as heading, while the\nassociated cluster labels act as subheadings, similar to a table of contents. Cluster sizes are also indicated. Clicking\non a frame lists all argument sentences in a discussion that assigned to that frame, while clicking on a cluster label\nshows the associated argument sentences that discuss a subtopic in the context of the discussion (see Figure 5).\ntents, which list argumentation frames and concise\nabstractive summaries of the latent subtopics for\na comprehensive overview of a discussion. By\nanalyzing 19 prompt-based LLMs, we found that\nGPT3.5 and GPT4 perform impressively, with\nLLaMA fine-tuned using chain-of-thought being\nthe second best. A user study of long discussions\nshowed that our summaries were valuable for ex-\nploring and uncovering new perspectives in long\ndiscussions, an otherwise tedious task when rely-\ning solely on the original web pages. Finally, we\npresented DISCUSSION EXPLORER, an interactive\nvisual tool designed to navigate through long dis-\ncussions using the generated indicative summaries.\nThis serves as a practical demonstration of how\nindicative summaries can be used effectively.\n\n7\nLimitations\nWe focused on developing a technology that facili-\ntates the exploration of long, argumentative discus-\nsions on controversial topics. We strongly believe\nthat our method can be easily generalized to other\ntypes of discussions, but budget constraints pre-\nvented us from exploring these as well. We also in-\nvestigated state-of-the-art language models to sum-\nmarize these discussions and found that commer-\ncial models (GPT3.5, GPT4) outperformed open-\nsource models (LLaMA, T0) in generating indica-\ntive summaries. Since the commercial models are\nregularly updated, it is important to note that the\nresults of our approach may differ in the future.\nAlthough one can define a fixed set of prompts for\neach model, our systematic search for the optimal\nprompts based on an evaluation metric is intended\nto improve the reproducibility of our approach as\nnewer models are released regularly.\nTo evaluate the effectiveness of the generated\nsummaries, we conducted a user study with five\nparticipants that demonstrated their usefulness in\nexploring discussions. Further research is needed\non how to effectively integrate summaries of this\ntype into discussion platform interfaces, which was\nbeyond the scope of this paper.\nAcknowledgments\nThis work was partially supported by the Eu-\nropean Commission under grant agreement GA\n101070014 (OpenWebSearch.eu)\nReferences\nYamen Ajjour, Milad Alshomary, Henning Wachsmuth,\nand Benno Stein. 2019. Modeling frames in argu-\nmentation. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n2915–2925, Hong Kong, China. Association for Com-\nputational Linguistics.\nChristopher Akiki, Odunayo Ogundepo, Aleksandra\nPiktus, Xinyu Zhang, Akintunde Oladipo, Jimmy\nLin, and Martin Potthast. 2023. Spacerini: Plug-and-\nplay search engines with pyserini and hugging face.\nCoRR, abs/2302.14534.\nStephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert\nWebson, Colin Raffel, Nihal V. Nayak, Abheesht\nSharma, Taewoon Kim, M Saiful Bari, Thibault\nFevry, Zaid Alyafeai, Manan Dey, Andrea San-\ntilli, Zhiqing Sun, Srulik Ben-David, Canwen Xu,\nGunjan Chhablani, Han Wang, Jason Alan Fries,\nMaged S. Al-shaibani, Shanya Sharma, Urmish\nThakker, Khalid Almubarak, Xiangru Tang, Xian-\ngru Tang, Mike Tian-Jian Jiang, and Alexander M.\nRush. 2022. Promptsource: An integrated develop-\nment environment and repository for natural language\nprompts.\nRoy Bar-Haim, Lilach Eden, Roni Friedman, Yoav Kan-\ntor, Dan Lahav, and Noam Slonim. 2020a. From ar-\nguments to key points: Towards automatic argument\nsummarization. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, ACL 2020, Online, July 5-10, 2020, pages\n4029–4039. Association for Computational Linguis-\ntics.\nRoy Bar-Haim, Yoav Kantor, Lilach Eden, Roni Fried-\nman, Dan Lahav, and Noam Slonim. 2020b. Quanti-\ntative argument summarization and beyond: Cross-\ndomain key point analysis. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2020, Online, Novem-\nber 16-20, 2020, pages 39–49. Association for Com-\nputational Linguistics.\nSumit Bhatia, Prakhar Biyani, and Prasenjit Mitra. 2014.\nSummarizing online forum discussions – can dia-\nlogue acts of individual messages help? In Proceed-\nings of the 2014 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 2127–\n2131, Doha, Qatar. Association for Computational\nLinguistics.\nStella Biderman, Hailey Schoelkopf, Quentin Anthony,\nHerbie Bradley, Kyle O’Brien, Eric Hallahan, Mo-\nhammad Aflah Khan, Shivanshu Purohit, USVSN Sai\nPrashanth, Edward Raff, Aviya Skowron, Lintang\nSutawika, and Oskar van der Wal. 2023.\nPythia:\nA suite for analyzing large language models across\ntraining and scaling.\nSid Black, Leo Gao, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021.\nGPT-Neo:\nLarge\nScale Autoregressive Language Modeling with Mesh-\nTensorflow.\nAmber E. Boydstun, Dallas Card, Justin Gross, Paul\nResnick, and Noah A. Smith. 2014. Tracking the de-\nvelopment of media frames within and across policy\nissues.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\n\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\nter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023. Sparks of artificial general in-\ntelligence: Early experiments with gpt-4.\nXiaoyan Cai, Wenjie Li, Ouyang You, and Hong Yan.\n2010. Simultaneous ranking and clustering of sen-\ntences: A reinforcement approach to multi-document\nsummarization.\nIn COLING 2010, 23rd Interna-\ntional Conference on Computational Linguistics, Pro-\nceedings of the Conference, 23-27 August 2010, Bei-\njing, China, pages 134–142. Tsinghua University\nPress.\nRicardo J. G. B. Campello, Davoud Moulavi, and Jörg\nSander. 2013. Density-based clustering based on hi-\nerarchical density estimates. In Advances in Knowl-\nedge Discovery and Data Mining, 17th Pacific-Asia\nConference, PAKDD 2013, Gold Coast, Australia,\nApril 14-17, 2013, Proceedings, Part II, volume 7819\nof Lecture Notes in Computer Science, pages 160–\n172. Springer.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nDennis Chong and James N. Druckman. 2007. Framing\ntheory, Annual Review of Political Science, pages\n103–126.\nGordon V. Cormack, Charles L. A. Clarke, and Stefan\nBüttcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd Annual International ACM\nSIGIR Conference on Research and Development\nin Information Retrieval, SIGIR 2009, Boston, MA,\nUSA, July 19-23, 2009, pages 758–759. ACM.\nCharlie Egan, Advaith Siddharthan, and Adam Wyner.\n2016. Summarising the points made in online politi-\ncal debates. In Proceedings of the Third Workshop\non Argument Mining (ArgMining2016), pages 134–\n143, Berlin, Germany. Association for Computational\nLinguistics.\nRobert M Entman. 1993. Framing: Towards clarifica-\ntion of a fractured paradigm. McQuail’s reader in\nmass communication theory, 390:397.\nOri Ernst, Avi Caciularu, Ori Shapira, Ramakanth Pa-\nsunuru, Mohit Bansal, Jacob Goldberger, and Ido\nDagan. 2022. Proposition-level clustering for multi-\ndocument summarization.\nIn Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 1765–1779, Seat-\ntle, United States. Association for Computational\nLinguistics.\nTanvir Ahmed Fuad, Mir Tafseer Nayeem, Asif Mah-\nmud, and Yllias Chali. 2019. Neural sentence fusion\nfor diversity driven abstractive multi-document sum-\nmarization. Comput. Speech Lang., 58:216–230.\nTim Gollub, Matthias Busse, Benno Stein, and Matthias\nHagen. 2016. Keyqueries for clustering and labeling.\nIn Information Retrieval Technology - 12th Asia In-\nformation Retrieval Societies Conference, AIRS 2016,\nBeijing, China, November 30 - December 2, 2016,\nProceedings, volume 9994 of Lecture Notes in Com-\nputer Science, pages 42–55. Springer.\nMaarten Grootendorst. 2022. Bertopic: Neural topic\nmodeling with a class-based TF-IDF procedure.\nCoRR, abs/2203.05794.\nFelix Hamborg, Anastasia Zhukova, and Bela Gipp.\n2019a. Automated identification of media bias by\nword choice and labeling in news articles. In 19th\nACM/IEEE Joint Conference on Digital Libraries,\nJCDL 2019, Champaign, IL, USA, June 2-6, 2019,\npages 196–205. IEEE.\nFelix Hamborg, Anastasia Zhukova, and Bela Gipp.\n2019b. Illegal aliens or undocumented immigrants?\ntowards the automated identification of bias by word\nchoice and labeling. In Information in Contemporary\nSociety - 14th International Conference, iConference\n2019, Washington, DC, USA, March 31 - April 3,\n2019, Proceedings, volume 11420 of Lecture Notes\nin Computer Science, pages 179–187. Springer.\nPhilipp Heinisch and Philipp Cimiano. 2021. A multi-\ntask approach to argument frame classification at vari-\nable granularity levels. it - Information Technology,\n63(1):59–72.\nMatthew Honnibal, Ines Montani, Sofie Van Lan-\ndeghem, and Adriane Boyd. 2020. spaCy: Industrial-\nstrength Natural Language Processing in Python.\nRyuji Kano, Yasuhide Miura, Motoki Taniguchi, Yan-\nYing Chen, Francine Chen, and Tomoko Ohkuma.\n2018.\nHarnessing popularity in social media for\nextractive summarization of online conversations.\nIn Proceedings of the 2018 Conference on Empir-\nical Methods in Natural Language Processing, pages\n1139–1145, Brussels, Belgium. Association for Com-\nputational Linguistics.\nMaurice George Kendall. 1948. Rank correlation meth-\nods.\nMike Klaas. 2005. Toward indicative discussion fora\nsummarization. UBC CS TR-2005, 4.\nAndreas Köpf, Yannic Kilcher, Dimitri von Rütte,\nSotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\nAbdullah Barhoum, Nguyen Minh Duc, Oliver\nStanley, Richárd Nagyfi, Shahul ES, Sameer Suri,\nDavid Glushkov, Arnav Dantuluri, Andrew Maguire,\nChristoph Schuhmann, Huu Nguyen, and Alexander\nMattick. 2023.\nOpenassistant conversations - de-\nmocratizing large language model alignment. CoRR,\nabs/2304.07327.\n\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\nmar, Benjamin Newman, Binhang Yuan, Bobby Yan,\nCe Zhang, Christian Cosgrove, Christopher D. Man-\nning, Christopher Ré, Diana Acosta-Navas, Drew A.\nHudson, Eric Zelikman, Esin Durmus, Faisal Ladhak,\nFrieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang,\nKeshav Santhanam, Laurel J. Orr, Lucia Zheng, Mert\nYüksekgönül, Mirac Suzgun, Nathan Kim, Neel\nGuha, Niladri S. Chatterji, Omar Khattab, Peter\nHenderson, Qian Huang, Ryan Chi, Sang Michael\nXie, Shibani Santurkar, Surya Ganguli, Tatsunori\nHashimoto, Thomas Icard, Tianyi Zhang, Vishrav\nChaudhary, William Wang, Xuechen Li, Yifan Mai,\nYuhui Zhang, and Yuta Koreeda. 2022. Holistic eval-\nuation of language models. CoRR, abs/2211.09110.\nSiyi Liu, Lei Guo, Kate K. Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding U.S. gun violence. In Pro-\nceedings of the 23rd Conference on Computational\nNatural Language Learning, CoNLL 2019, Hong\nKong, China, November 3-4, 2019, pages 504–514.\nAssociation for Computational Linguistics.\nChristopher D. Manning, Prabhakar Raghavan, and Hin-\nrich Schütze. 2008. Introduction to information re-\ntrieval. Cambridge University Press.\nLeland McInnes, John Healy, and sk Steve Astels. 2017.\nhdbscan: Hierarchical density based clustering. J.\nopen-source Softw., 2(11):205.\nRada Mihalcea and Paul Tarau. 2004. TextRank: Bring-\ning order into text. In Proceedings of the 2004 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 404–411, Barcelona, Spain. Asso-\nciation for Computational Linguistics.\nAmita Misra, Pranav Anand, Jean E. Fox Tree, and Mar-\nilyn Walker. 2015. Using summarization to discover\nargument facets in online idealogical dialogue. In\nProceedings of the 2015 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 430–440, Denver, Colorado. Association for\nComputational Linguistics.\nFred Morstatter, Liang Wu, Uraz Yavanoglu, Steven R.\nCorman, and Huan Liu. 2018.\nIdentifying fram-\ning bias in online news. ACM Trans. Soc. Comput.,\n1(2):5:1–5:18.\nNona Naderi and Graeme Hirst. 2017.\nClassifying\nframes at the sentence level in news articles.\nIn\nProceedings of the International Conference Recent\nAdvances in Natural Language Processing, RANLP\n2017, pages 536–542, Varna, Bulgaria. INCOMA\nLtd.\nRamesh Nallapati, Bowen Zhou, Cícero Nogueira dos\nSantos, Çaglar Gülçehre, and Bing Xiang. 2016.\nAbstractive text summarization using sequence-to-\nsequence rnns and beyond. In Proceedings of the\n20th SIGNLL Conference on Computational Natural\nLanguage Learning, CoNLL 2016, Berlin, Germany,\nAugust 11-12, 2016, pages 280–290. ACL.\nMir Tafseer Nayeem, Tanvir Ahmed Fuad, and Yl-\nlias Chali. 2018. Abstractive unsupervised multi-\ndocument summarization using paraphrastic sentence\nfusion.\nIn Proceedings of the 27th International\nConference on Computational Linguistics, COLING\n2018, Santa Fe, New Mexico, USA, August 20-26,\n2018, pages 1191–1204. Association for Computa-\ntional Linguistics.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welin-\nder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instruc-\ntions with human feedback. In NeurIPS.\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow,\nRuxandra Cojocaru, Alessandro Cappelli, Hamza\nAlobeidli, Baptiste Pannier, Ebtesam Almazrouei,\nand Julien Launay. 2023. The refinedweb dataset\nfor falcon LLM: outperforming curated corpora with\nweb data, and web data only. CoRR, abs/2306.01116.\nHanieh Poostchi and Massimo Piccardi. 2018. Cluster\nlabeling by word embeddings and wordnet’s hyper-\nnymy. In Proceedings of the Australasian Language\nTechnology Association Workshop 2018, Dunedin,\nNew Zealand, ALTA 2018, December 10-12, 2018,\npages 66–70.\nCristian Popa and Traian Rebedea. 2021. BART-TL:\nweakly-supervised topic label generation. In Pro-\nceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume, EACL 2021, Online, April 19\n- 23, 2021, pages 1418–1425. Association for Com-\nputational Linguistics.\nDragomir R. Radev, Hongyan Jing, Magorzata Sty,\nand Daniel Tam. 2004. Centroid-based summariza-\ntion of multiple documents. Inf. Process. Manag.,\n40(6):919–938.\nSarvesh Ranade, Jayant Gupta, Vasudeva Varma, and\nRadhika Mamidi. 2013. Online debate summariza-\ntion using topic directed sentiment analysis. In Pro-\nceedings of the Second International Workshop on\nIssues of Sentiment Discovery and Opinion Mining,\nWISDOM 2013, Chicago, IL, USA, August 11, 2013,\npages 7:1–7:6. ACM.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing. Associa-\ntion for Computational Linguistics.\nNils Reimers, Benjamin Schiller, Tilman Beck, Jo-\nhannes Daxenberger, Christian Stab, and Iryna\n\nGurevych. 2019. Classification and clustering of\narguments with contextualized word embeddings. In\nProceedings of the 57th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 567–\n578, Florence, Italy. Association for Computational\nLinguistics.\nZhaochun Ren, Jun Ma, Shuaiqiang Wang, and Yang\nLiu. 2011. Summarizing web forum threads based on\na latent topic propagation process. In Proceedings of\nthe 20th ACM International Conference on Informa-\ntion and Knowledge Management, CIKM ’11, page\n879–884, New York, NY, USA. Association for Com-\nputing Machinery.\nFrançois Role and Mohamed Nadif. 2014.\nBeyond\ncluster labeling: Semantic interpretation of clusters’\ncontents using a graph representation. Knowl. Based\nSyst., 56:141–155.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\nM Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Févry, Jason Alan Fries, Ryan\nTeehan, Teven Le Scao, Stella Biderman, Leo Gao,\nThomas Wolf, and Alexander M. Rush. 2022. Multi-\ntask prompted training enables zero-shot task gener-\nalization. In The Tenth International Conference on\nLearning Representations, ICLR 2022, Virtual Event,\nApril 25-29, 2022. OpenReview.net.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ilic, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, Jonathan Tow, Alexander M. Rush,\nStella Biderman, Albert Webson, Pawan Sasanka Am-\nmanamanchi, Thomas Wang, Benoît Sagot, Niklas\nMuennighoff, Albert Villanova del Moral, Olatunji\nRuwase, Rachel Bawden, Stas Bekman, Angelina\nMcMillan-Major, Iz Beltagy, Huu Nguyen, Lucile\nSaulnier, Samson Tan, Pedro Ortiz Suarez, Vic-\ntor Sanh, Hugo Laurençon, Yacine Jernite, Julien\nLaunay, Margaret Mitchell, Colin Raffel, Aaron\nGokaslan, Adi Simhi, Aitor Soroa, Alham Fikri\nAji, Amit Alfassy, Anna Rogers, Ariel Kreisberg\nNitzav, Canwen Xu, Chenghao Mou, Chris Emezue,\nChristopher Klamm, Colin Leong, Daniel van Strien,\nDavid Ifeoluwa Adelani, and et al. 2022. BLOOM:\nA 176b-parameter open-access multilingual language\nmodel. CoRR, abs/2211.05100.\nQingyi Si and Zheng Lin. 2023. Alpaca-cot: An in-\nstruction fine-tuning platform with instruction data\ncollection and unified large language models inter-\nface. https://github.com/PhoebusSi/alpaca-CoT.\nShahbaz Syed, Timon Ziegenbein, Philipp Heinisch,\nHenning Wachsmuth, and Martin Potthast. 2023.\nFrame-oriented summarization of argumentative dis-\ncussions. In Proceedings of the 24th Meeting of the\nSpecial Interest Group on Discourse and Dialogue,\nSIGDIAL 2023, Prague, Czechia, September 11 - 15,\n2023, pages 114–129. Association for Computational\nLinguistics.\nChenhao Tan,\nVlad Niculae,\nCristian Danescu-\nNiculescu-Mizil, and Lillian Lee. 2016. Winning ar-\nguments: Interaction dynamics and persuasion strate-\ngies in good-faith online discussions. In Proceedings\nof the 25th International Conference on World Wide\nWeb, WWW 2016, Montreal, Canada, April 11 - 15,\n2016, pages 613–624. ACM.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\nAn instruction-following llama model. https://github.\ncom/tatsu-lab/stanford_alpaca.\nSansiri Tarnpradab, Fei Liu, and Kien A Hua. 2017.\nToward extractive summarization of online forum\ndiscussions via hierarchical attention networks. In\nThe Thirtieth International Flairs Conference.\nAlmer S. Tigelaar, Rieks op den Akker, and Djoerd\nHiemstra. 2010. Automatic summarisation of discus-\nsion fora. Nat. Lang. Eng., 16(2):161–192.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurélien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. CoRR,\nabs/2302.13971.\nMarilyn A. Walker, Jean E. Fox Tree, Pranav Anand,\nRob Abbott, and Joseph King. 2012. A corpus for\nresearch on deliberation and debate. In Proceed-\nings of the Eighth International Conference on Lan-\nguage Resources and Evaluation, LREC 2012, Is-\ntanbul, Turkey, May 23-25, 2012, pages 812–817.\nEuropean Language Resources Association (ELRA).\nXiaojun Wan and Jianwu Yang. 2008. Multi-document\nsummarization using cluster-based link analysis. In\nProceedings of the 31st Annual International ACM\nSIGIR Conference on Research and Development in\nInformation Retrieval, SIGIR 2008, Singapore, July\n20-24, 2008, pages 299–306. ACM.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-\nisa Liu, Noah A. Smith, Daniel Khashabi, and Han-\nnaneh Hajishirzi. 2022. Self-instruct: Aligning lan-\nguage model with self generated instructions. CoRR,\nabs/2212.10560.\nCanwen Xu, Daya Guo, Nan Duan, and Julian McAuley.\n2023.\nBaize: An open-source chat model with\nparameter-efficient tuning on self-chat data. arXiv\npreprint arXiv:2304.01196.\n\nAmy X. Zhang, Lea Verou, and David R. Karger. 2017.\nWikum: Bridging discussion forums and wikis us-\ning recursive summarization. In Proceedings of the\n2017 ACM Conference on Computer Supported Co-\noperative Work and Social Computing, CSCW 2017,\nPortland, OR, USA, February 25 - March 1, 2017,\npages 2082–2096. ACM.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher\nDewan, Mona T. Diab, Xian Li, Xi Victoria Lin,\nTodor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shus-\nter, Daniel Simig, Punit Singh Koura, Anjali Srid-\nhar, Tianlu Wang, and Luke Zettlemoyer. 2022.\nOPT: open pre-trained transformer language mod-\nels. CoRR, abs/2205.01068.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In 8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nYang Zhang, Yunqing Xia, Yi Liu, and Wenmin Wang.\n2015. Clustering sentences with density peaks for\nmulti-document summarization.\nIn NAACL HLT\n2015, The 2015 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Denver,\nColorado, USA, May 31 - June 5, 2015, pages 1262–\n1267. The Association for Computational Linguistics.\nA\nPreprocessing\nDeleted posts were matched using: \"[deleted]\",\n\"[removed]\", \"[Wiki][Code][/r/DeltaBot]\", \"[His-\ntory]\". To remove posts from moderators, we used:\n• \"hello, users of cmv! this is a footnote from\nyour moderators\"\n• \"comment has been remove\"\n• \"comment has been automatically removed\"\n• \"if you would like to appeal, please message\nthe moderators by clicking this link.\"\n• \"this comment has been overwritten by an\nopen source script to protect\"\n• \"then simply click on your username on red-\ndit, go to the comments tab, scroll down as\nfar as possibe (hint:use res), and hit the new\noverwrite button at the top.\"\n• \"reply to their comment with the delta sym-\nbol\"\nB\nClustering Implementation\nWe employed HDBSCAN, a soft clustering algo-\nrithm (Campello et al., 2013) to cluster the contex-\ntual sentence embeddings from SBERT (Reimers\nand Gurevych, 2019). As these embeddings are\nhigh dimensional, we follow Grootendorst (2022)\nand apply dimensionality reduction on these em-\nbeddings via UMAP (McInnes et al., 2017) and\ncluster them based on their euclidean distance.\nMost parameters were selected according to official\nrecommendations for UMAP,13 and HDBSCAN.14\nUMAP Parameters\nmetric\nWe set this to “cosine” because this is\nthe natural metric for SBERT embeddings.\nn_neighbors\nWe set this to 30 instead of the de-\nfault value of 15 because this makes the reduction\nfocus more on the global structure. This is impor-\ntant since the local structure is more sensitive to\nnoise.\nn_components\nWe set this value to 10.\nmin_dist\nWe set this value to 0 because this al-\nlows the points to be packed closer together which\nmakes separating the clusters easier.\nHDBSCAN Parameters\nmetric\nWe set this to “euclidean” because this\nthe target metric that UMAP uses for reducing the\npoints.\ncluster_selection_method\nWe set this value to\n“leaf”. An alternative choice for this options is\n“eom”. This option has the tendency to create unrea-\nsonably large clusters. There are instances where\nit creates only two or three clusters even for very\nlarge discussions. The “leaf” method does not\nsuffer from this problem but it is more dependent\non the “min_cluster_size” parameter.\nmin_cluster_size\nThis parameter is the most im-\nportant one for this approach. It is also not straight\nforward to find a value for this since the sizes of\nthe main subtopics of a discussion depend on the\nsize of the discussion. To find a good value, we\nsampled 50 discussion randomly and 50 discus-\nsion stratified by discussion length from all dis-\ncussions. We compute the clustering for all 100\n13https://umap-learn.readthedocs.io/en/latest/clustering.html\n14https://hdbscan.readthedocs.io/en/latest/parameter_\nselection.html\n\nExploring the Discussion via an Indicative Summary \nFigure 5: An exploratory view provided by DISCUSSION EXPLORER to quickly navigate a long discussion via\nan indicative summary. On the left, clicking on a cluster label lists all its constituent sentences. On the right, a\nspecific sentence from the chosen cluster is presented in the context of the discussion. Softly highlighted are the\nsentences from other clusters that surround the selected sentence. Users can thus easily skim a discussion with\nseveral arguments for relevant information using the indicative summary in this exploratory view.\ndiscussion for different values for min_cluster_size\nand manually determine a lower and upper bound\nfor min_cluster_size that give a good clustering.\nWe computed a regression model using the follow-\ning function family as a basis: f(x|a, b) = a · xb\nThe input variable x is the number of sentences in\nthe discussion and the output variable is the aver-\nage of the upper and lower bound. This yields the\nfollowing function for computing min_cluster_size:\nf(x) = 0.421 · x0.559. Figure 6 visualizes upper\nand lower bounds as well as the found model.\nC\nGenerative Cluster Labeling\nModel Descriptions\nGiven the large number of\nmodels investigated in the paper for both the tasks,\nwe categorized them based on their release time-\nlines. Models older than GPT3.5 are listed under\nPre-InstructGPT such as T0, BLOOM, GPT-NeoX,\nand OPT. The Direct and Dialogue labels refer to\nmodels released after GPT3.5 which differ in their\nprompt styles as shown in Figure 7. Best prompts\nfor the manually evaluated models (Section 5.2)\nare shown in Figure 8.\n1. T0 (Sanh et al., 2022) is a prompt-based encoder-\ndecoder model, fine-tuned on multiple tasks in-\nFigure 6: Blue vertical bars show the upper and lower\nbound for min_cluster_size that yield a good clustering\nfor the corresponding discussion. The red curve shows\nthe optimal fit for the regression.\ncluding summarization, and surpasses GPT-3 in\nsome tasks despite being much smaller. It was\ntrained on prompted datasets where supervised\ndatasets were transformed into prompts.\n2. BLOOM (Scao et al., 2022) is an autoregressive\nLLM with 176B parameters, which specializes\nin prompt-based text completion for multiple\nlanguages. It also supports instruction-based\n\ntask completions for previously unseen tasks.\n3. GPT-NeoX (Black et al., 2021) is an open-\nsource, general-purpose alternative to the GPT-3\nmodel (Ouyang et al., 2022) containing 20B pa-\nrameters.\n4. OPT (Zhang et al., 2022) is an autoregressive\nLLM with 66B parameters from the suite of\ndecoder-only pre-trained transformers. These\nmodels offer similar performance and sizes as\nGPT-3 while employing more efficient practices\nfor data collection and model training.\n5. GPT3.5 (Brown et al., 2020; Ouyang et al.,\n2022) is an instruction-following LLM with\n175B parameters that outperforms the GPT-3\nmodel across several tasks by consistently ad-\nhering to user-provided instructions and gener-\nating high-quality, longer outputs. We used the\ntext-davinci-003 variant. In contrast to the other\nopen-source models, it is accessible exclusively\nthrough the OpenAI API.15\nPrompt Descriptions\nWe investigated several\nprompt templates for each model and selected the\nbest performing one. All the prompts investigated\nfor the encoder-decoder T0 model are shown in Ta-\nble 11. Prompt templates for the decoder-only Pre-\nInstructGPT models (BLOOM, OPT, GPT-NeoX)\nare listed in Table 12. Prompt templates for the\ninstruction-following LLMs are listed in Table 13.\nAutomatic Evaluation\nFor the sake of comple-\ntion, we automatically evaluated the recently re-\nleased (at the time of writing) instruction-following\nmodels. To adapt them to generative cluster label-\ning, we devised two instructions (Figure 7) similar\nto the direct and dialogue style instructions used\nfor frame assignment (Section 3.3). Next, we com-\nputed BERTScore and ROUGE against two sets of\nreferences: (1) manually annotated ground-truth\nlabels for 300 clusters, and (2) cluster labels from\nGPT3.5 which was the best model as per our man-\nual evaluation (Section 5.2, Table 3). Complete\nresults for BERTScore along with length distribu-\ntions for the generated cluster labels are shown in\nTable 7, while results for ROUGE are shown in\nTable 8.\nManual Evaluation\nTable 9 shows the guideline\nprovided to the annotators. Figure 9 shows the\n15https://platform.openai.com/docs/models/gpt-3-5\nDirect Instruction for Cluster Labeling\nEvery input is the content of a debate. For every\ninput, you generate a single descriptive phrase that\ndescribes that input in very simple language, without\ntalking about the debate or the author.\nDialogue Instruction for Cluster Labeling\nA chat between a curious user and an artificial intelli-\ngence assistant. The user presents a debate and the\nassistant generates a single descriptive phrase that\ndescribes the debate in very simple language, without\ntalking about the debate or the author.\nFigure 7: Direct and dialogue-style instructions for gen-\nerative cluster labeling prompts. The best prompts for\neach model are shown in Figure 8.\nannotation interface used to collect the rankings for\ncluster label quality.\nD\nFrame Assignment\nModel Descriptions\nWe categorize the models\naccording to the instruction style followed for fine-\ntuning and generation. Instructions for each type\nare shown in Figure 10. The best prompts for each\nmodel are listed in Figure 11.\nDirect Instruction Models\n1. LLaMA-COT16 is a finetuned model on datasets\ninducing chain-of-thought and logical deduc-\ntions (Si and Lin, 2023).\n2. Alpaca (Taori et al., 2023) is finetuned from\nthe LLaMA 7B model (Touvron et al., 2023)\nusing 52K self-instructed instruction-following\nexamples (Wang et al., 2022).\n3. OASST 17 is finetuned from LLaMA 30B on\nthe OpenAssistant Conversations dataset (Köpf\net al., 2023) using reinforcement learning.\n4. Pythia (Biderman et al., 2023) is a suite of\nLLMs trained on public data to study the impact\nof training and scaling on various model prop-\nerties. We used the 12B variant finetuned on\nthe OpenAssistant Conversations dataset (Köpf\net al., 2023).\n5. GPT* includes models such as text-davinci-003,\ngpt-3.5-turbo (ChatGPT), and GPT-4 (Bubeck\n16https://huggingface.co/ausboss/llama-30b-supercot\n17https://huggingface.co/OpenAssistant/\noasst-rlhf-2-llama-30b-7k-steps-xor\n\nBest Prompts for Generative Cluster Labeling\nT0\nRead the following context and answer the question.\nContext: {text}\nQuestion: What is the title of the discussion?\nAnswer:\nBLOOM\nAI assistant: I am an expert AI assistant and I am\nvery good in identifying titles of debates.\nDEBATE START {text} DEBATE END\nAI assistant: The title of the debate between the two\nparticipants is \"\nGPT-NeoX\nDISCUSSION START {text} DISCUSSION END\nQ: What is the topic of the discussion?\nA: The topic of the discussion is \"\nOPT-66B\nDEBATE START {text} DEBATE END\nQ: What is the topic of the debate?\nA: The topic of the debate is \"\nGPT3.5 (text-davinci-003)\nGenerate a single descriptive phrase that describes\nthe following debate in very simple language, without\ntalking about the debate or the author.\nDebate: \"\"\"{text}\"\"\"\nFigure 8: Best prompts for generative cluster labeling\nfor each model. These prompts were chosen based on\nthe automatic evaluation of several prompts for each\nmodel against 300 manually annotated cluster labels.\net al., 2023) from the OpenAI API. These\nmodels are not open-source but have demon-\nstrated state-of-the-art performance across vari-\nous tasks.\nDialogue Instruction Models\n1. LLaMA (Touvron et al., 2023) is a suite of open-\nsource LLMs trained on public datasets. We\nutilized the 30B and 65B variants.\n2. Vicuna (Chiang et al., 2023) is finetuned from\nLLaMA using user-shared conversations col-\nlected from ShareGPT.18 It has shown competi-\ntive performance when evaluated using GPT-4\nas a judge. We used the 7B and 13B variants of\nthis model.\n3. Vicuna (Xu et al., 2023) is an open-source chat\nmodel trained on 100k dialogues generated by\nallowing ChatGPT (GPT 3.5-turbo) to converse\nwith itself. We used the 7B and 13B variants of\nthis model.\n18https://sharegpt.com/\nFigure 9: Annotation interface for ranking-based quali-\ntative evaluation of cluster labels.\n4. Falcon19 is trained on the RefinedWeb dataset\n(Penedo et al., 2023), which is derived through\nextensive filtering and deduplication of publicly\navailable web data. It is currently the state-of-\nthe-art (at the time of writing) on the open-llm-\nleaderboard.20 We utilized the 40B and 40B-\nInstruct variants of this model.\nD.1\nCitation Impact on Frame Assignment\nWe conducted additional experiments to evaluate\nthe impact of providing the citation of the media\nframes corpus paper by Boydstun et al. (2014) as\nadditional information in the instructions shown\nin Section 3.3. This piece of information was pro-\nvided after the substring “defined by” in the prompt\ntemplate. Table 5 shows the results. We note that\nproviding the citation information has a positive\n19https://falconllm.tii.ae/\n20https://huggingface.co/spaces/HuggingFaceH4/open_llm_\nleaderboard\n\nDirect Instruction for Frame Assignment\nThe following {input_type}a contains all available\nmedia frames as defined in the work from {authors}:\n{frames} For every input, you answer with three of\nthese media frames corresponding to that input, in\norder of importance.\naA list of frame labels or a JSON with frame labels\nand their descriptions.\nDialogue Instruction for Frame Assignment\nA chat between a curious user and an artificial intelli-\ngence assistant. The assistant knows all media frames\nas defined by ... : {frames}. The assistant answers\nwith three of these media frames corresponding to\nthe user’s text, in order of importance.\nFigure 10: Best performing instructions for frame as-\nsignment. Providing the citation for the frame inventory\nvia the placeholder {authors} positively affects the per-\nformance of some models (Appendix D.1).\nPrompt\nFalcon-40B ChatGPT LLaMA-65B\nCite.\n–\nCite.\n–\nCite.\n–\nZero-Shot\n46.5\n34.2\n60.9 60.1 53.1\n44.4\nZero-Shot (short) 46.5\n42.8\n58.0 57.2 50.6\n42.4\nZero-Shot (full)\n46.1\n46.5\n58.8 60.9 39.5\n39.1\nFew-Shot\n38.3\n39.1\n63.4 64.6\n–\n–\nTable 5: Analysis of the impact of providing citation of\nthe media frames corpus paper as additional information\nin the instructions for the frame assignment. Providing\ncitation information (Cite.) shows up to 12% improve-\nment for Falcon-40B and 9% for LLaMA-65B under\nzero-shot setting (with only frame labels in the prompt).\nimpact on the performance of the models. The im-\nprovement is up to 12% for Falcon-40B and 9% for\nLLaMA-65B under zero-shot setting (only frame\nlabels without descriptions in the prompt). This\nimprovement can be attributed to the models be-\ning trained on a large text corpus, with the citation\nserving as a strong signal for generating more ac-\ncurate labels. However, ChatGPT is only slightly\naffected.\nD.2\nZero-Shot and Few-Shot Prompts for\nFrame Assignment\nD.2.1\nZero-Shot (short)\n[\n\"economic\",\n\"capacity and resources\",\n\"morality\",\n\"fairness and equality\",\n\"legality, constitutionality and\njurisprudence\",\n,→\n\"policy prescription and evaluation\",\n\"crime and punishment\",\n\"security and defense\",\n\"health and safety\",\n\"quality of life\",\n\"cultural identity\",\n\"public opinion\",\n\"political\",\n\"external regulation and reputation\"\n]\nD.2.2\nZero-Shot\n{\n\"economic\": {\n\"description\": \"costs, benefits, or other\nfinancial implications\"\n,→\n},\n\"capacity and resources\": {\n\"description\": \"availability of physical,\nhuman or financial resources, and\ncapacity of current systems\"\n,→\n,→\n},\n\"morality\": { \"description\": \"religious or\nethical implications\" },\n,→\n\"fairness and equality\": {\n\"description\": \"balance or distribution of\nrights, responsibilities, and resources\"\n,→\n},\n\"legality, constitutionality and\njurisprudence\": {\n,→\n\"description\": \"rights, freedoms, and\nauthority of individuals, corporations,\nand government\"\n,→\n,→\n},\n\"policy prescription and evaluation\": {\n\"description\": \"discussion of specific\npolicies aimed at addressing problems\"\n,→\n},\n\"crime and punishment\": {\n\"description\": \"effectiveness and\nimplications of laws and their\nenforcement\"\n,→\n,→\n},\n\"security and defense\": {\n\"description\": \"threats to welfare of the\nindividual, community, or nation\"\n,→\n},\n\"health and safety\": {\n\"description\": \"health care, sanitation,\npublic safety\"\n,→\n},\n\"quality of life\": {\n\"description\": \"threats and opportunities for\nthe individual's wealth, happiness, and\nwell-being\"\n,→\n,→\n},\n\"cultural identity\": {\n\"description\": \"traditions, customs, or\nvalues of a social group in relation to a\npolicy issue\"\n,→\n,→\n},\n\"public opinion\": {\n\"description\": \"attitudes and opinions of the\ngeneral public, including polling and\ndemographics\"\n,→\n,→\n},\n\"political\": {\n\n\"description\": \"considerations related to\npolitics and politicians, including\nlobbying, elections, and attempts to sway\nvoters\"\n,→\n,→\n,→\n},\n\"external regulation and reputation\": {\n\"description\": \"international reputation or\nforeign policy of the U.S.\"\n,→\n}\n}\nD.2.3\nZero-Shot (full)\n{\n\"economic\": {\n\"description\": \"The costs, benefits, or\nmonetary/financial implications of the\nissue (to an individual, family,\ncommunity, or to the economy as a\nwhole).\"\n,→\n,→\n,→\n,→\n},\n\"capacity and resources\": {\n\"description\": \"The lack of or availability\nof physical, geographical, spatial,\nhuman, and financial resources, or the\ncapacity of existing systems and\nresources to implement or carry out\npolicy goals.\"\n,→\n,→\n,→\n,→\n,→\n},\n\"morality\": {\n\"description\": \"Any perspective or policy\nobjective or action (including proposed\naction) that is compelled by religious\ndoctrine or interpretation, duty, honor,\nrighteousness or any other sense of\nethics or social responsibility.\"\n,→\n,→\n,→\n,→\n,→\n},\n\"fairness and equality\": {\n\"description\": \"Equality or inequality with\nwhich laws, punishment, rewards, and\nresources are applied or distributed\namong individuals or groups. Also the\nbalance between the rights or interests\nof one individual or group compared to\nanother individual or group.\"\n,→\n,→\n,→\n,→\n,→\n,→\n},\n\"legality, constitutionality and\njurisprudence\": {\n,→\n\"description\": \"The constraints imposed on or\nfreedoms granted to individuals,\ngovernment, and corporations via the\nConstitution, Bill of Rights and other\namendments, or judicial interpretation.\nThis deals specifically with the\nauthority of government to regulate, and\nthe authority of individuals/corporations\nto act independently of government.\"\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n},\n\"policy prescription and evaluation\": {\n\"description\": \"Particular policies proposed\nfor addressing an identified problem,\nand figuring out if certain policies will\nwork, or if existing policies are\neffective.\"\n,→\n,→\n,→\n,→\n},\n\"crime and punishment\": {\n\"description\": \"Specific policies in practice\nand their enforcement, incentives, and\nimplications. Includes stories about\nenforcement and interpretation of laws by\nindividuals and law enforcement,\nbreaking laws, loopholes, fines,\nsentencing and punishment. Increases or\nreductions in crime.\"\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n},\n\"security and defense\": {\n\"description\": \"Security, threats to\nsecurity, and protection of one's person,\nfamily, in-group, nation, etc. Generally\nan action or a call to action that can be\ntaken to protect the welfare of a person,\ngroup, nation sometimes from a not yet\nmanifested threat.\"\n,→\n,→\n,→\n,→\n,→\n,→\n},\n\"health and safety\": {\n\"description\": \"Healthcare access and\neffectiveness, illness, disease,\nsanitation, obesity, mental health\neffects, prevention of or perpetuation\nof gun violence, infrastructure and\nbuilding safety.\"\n,→\n,→\n,→\n,→\n,→\n},\n\"quality of life\": {\n\"description\": \"The effects of a policy on\nindividuals' wealth, mobility, access to\nresources, happiness, social structures,\nease of day-to-day routines, quality of\ncommunity life, etc.\"\n,→\n,→\n,→\n,→\n},\n\"cultural identity\": {\n\"description\": \"The social norms, trends,\nvalues and customs constituting\nculture(s), as they relate to a specific\npolicy issue.\"\n,→\n,→\n,→\n},\n\"public opinion\": {\n\"description\": \"References to general social\nattitudes, polling and demographic\ninformation, as well as implied or actual\nconsequences of diverging from or\n\\\"getting ahead of\\\" public opinion or\npolls.\"\n,→\n,→\n,→\n,→\n,→\n},\n\"political\": {\n\"description\": \"Any political considerations\nsurrounding an issue. Issue actions or\nefforts or stances that are political,\nsuch as partisan filibusters, lobbyist\ninvolvement, bipartisan efforts,\ndeal-making and vote trading, appealing\nto one's base, mentions of political\nmaneuvering. Explicit statements that a\npolicy issue is good or bad for a\nparticular political party.\"\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n},\n\"external regulation and reputation\": {\n\"description\": \"The United States' external\nrelations with another nation; the\nexternal relations of one state with\nanother; or relations between groups.\nThis includes trade agreements and\noutcomes, comparisons of policy outcomes\nor desired policy outcomes.\"\n,→\n,→\n,→\n,→\n,→\n,→\n}\n}\n\nD.2.4\nFew-Shot\n{\n\"economic\": {\n\"description\": \"The costs, benefits, or\nmonetary/financial implications of the\nissue (to an individual, family,\ncommunity, or to the economy as a\nwhole).\",\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Necessity of minimum wage laws and their\neffects on the labor market.\",\n,→\n\"Consequences of unregulated capitalism and\nthe potential of a libertarian\nsociety.\",\n,→\n,→\n\"Risk-based insurance premiums determined\nby complex modeling of probability and\ncost factors.\"\n,→\n,→\n]\n},\n\"capacity and resources\": {\n\"description\": \"The lack of or availability\nof physical, geographical, spatial,\nhuman, and financial resources, or the\ncapacity of existing systems and\nresources to implement or carry out\npolicy goals.\",\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Potential of biofuels as an alternative to\nfossil fuels.\",\n,→\n\"Physical fitness tests measure upper body\nstrength and running ability for\nmilitary service.\",\n,→\n,→\n\"Physical strength and endurance needed for\nmodern combat.\"\n,→\n]\n},\n\"morality\": {\n\"description\": \"Any perspective or policy\nobjective or action (including proposed\naction) that is compelled by religious\ndoctrine or interpretation, duty, honor,\nrighteousness or any other sense of\nethics or social responsibility.\",\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Fighting for the weak and vulnerable\ndespite the odds.\",\n,→\n\"Victim-blaming debate on police\nbrutality.\",\n,→\n\"Potential corruption of some native\ncanadian bands and the need for\ntransparency.\"\n,→\n,→\n]\n},\n\"fairness and equality\": {\n\"description\": \"Equality or inequality with\nwhich laws, punishment, rewards, and\nresources are applied or distributed\namong individuals or groups. Also the\nbalance between the rights or interests\nof one individual or group compared to\nanother individual or group.\",\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Differences between humanism and feminism\nand their respective goals.\",\n,→\n\"Disparities in scholarship opportunities\nfor minority students.\",\n,→\n\"Violent suppression of native american\npopulations for centuries leading to a\nlack of advocacy and rights.\"\n,→\n,→\n]\n},\n\"legality, constitutionality and\njurisprudence\": {\n,→\n\"description\": \"The constraints imposed on or\nfreedoms granted to individuals,\ngovernment, and corporations via the\nConstitution, Bill of Rights and other\namendments, or judicial interpretation.\nThis deals specifically with the\nauthority of government to regulate, and\nthe authority of individuals/corporations\nto act independently of government.\",\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Guns acquired through legal and illegal\nchannels for criminal use.\",\n,→\n\"Importance of the 2nd amendment and the\nimplications of gun ownership in a\ndemocracy.\",\n,→\n,→\n\"Relevance of sexual history in rape cases.\"\n]\n},\n\"policy prescription and evaluation\": {\n\"description\": \"Particular policies proposed\nfor addressing an identified problem,\nand figuring out if certain policies will\nwork, or if existing policies are\neffective.\",\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Religious scientists making major\ncontributions to the world despite\nmajority of scientists being agnostic\natheists.\",\n,→\n,→\n,→\n\"Pros and cons of voluntary registration.\",\n\"Collective ownership of production for the\nbetterment of society, with workers\nprofiting from the sale of their\nlabor.\"\n,→\n,→\n,→\n]\n},\n\"crime and punishment\": {\n\"description\": \"Specific policies in practice\nand their enforcement, incentives, and\nimplications. Includes stories about\nenforcement and interpretation of laws by\nindividuals and law enforcement,\nbreaking laws, loopholes, fines,\nsentencing and punishment. Increases or\nreductions in crime.\",\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Complexities of police shootings and\nrace.\",\n,→\n\"Men are more likely to commit violent\ncrimes than women.\",\n,→\n\"Punishment as a response to crime debated,\nwith consideration of morality,\nseverity, and aims.\"\n,→\n,→\n]\n},\n\"security and defense\": {\n\"description\": \"Security, threats to\nsecurity, and protection of one's person,\nfamily, in-group, nation, etc. Generally\nan action or a call to action that can be\ntaken to protect the welfare of a person,\ngroup, nation sometimes from a not yet\nmanifested threat.\",\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Protective physical self-defense in a\nfight.\",\n,→\n\n\"Powerful military technology making\ninfantry obsolete in war.\",\n,→\n\"Protection of infants and mentally\ndisabled through social policy.\"\n,→\n]\n},\n\"health and safety\": {\n\"description\": \"Healthcare access and\neffectiveness, illness, disease,\nsanitation, obesity, mental health\neffects, prevention of or perpetuation\nof gun violence, infrastructure and\nbuilding safety.\",\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Complexities of food choices and their\neffects on health.\",\n,→\n\"Potentially fatal consequences of taking\ntoo much acetaminophen.\",\n,→\n\"Encouraging healthy habits without shaming\nor pressuring people to lose weight.\"\n,→\n]\n},\n\"quality of life\": {\n\"description\": \"The effects of a policy on\nindividuals' wealth, mobility, access to\nresources, happiness, social structures,\nease of day-to-day routines, quality of\ncommunity life, etc.\",\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Differences between adults and children in\nterms of understanding and\nperception.\",\n,→\n,→\n\"Importance of extracurriculars and\nacademics for college admissions.\",\n,→\n\"Appropriate times to yell at customer\nservice workers.\"\n,→\n]\n},\n\"cultural identity\": {\n\"description\": \"The social norms, trends,\nvalues and customs constituting\nculture(s), as they relate to a specific\npolicy issue.\",\n,→\n,→\n,→\n\"examples\": [\n\"Rapid shift in acceptance of homosexuality\nin the u.s.\",\n,→\n\"Collective action necessary for social\nprogress and change.\",\n,→\n\"Complexities of gender identity and\nexpression.\"\n,→\n]\n},\n\"public opinion\": {\n\"description\": \"References to general social\nattitudes, polling and demographic\ninformation, as well as implied or actual\nconsequences of diverging from or\n\\\"getting ahead of\\\" public opinion or\npolls.\",\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Gender roles and expectations are socially\nconstructed and changing.\",\n,→\n\"Pros and cons of the 40-hour work week.\",\n\"Potential appeal of a political\ncandidate.\"\n,→\n]\n},\n\"political\": {\n\"description\": \"Any political considerations\nsurrounding an issue. Issue actions or\nefforts or stances that are political,\nsuch as partisan filibusters, lobbyist\ninvolvement, bipartisan efforts,\ndeal-making and vote trading, appealing\nto one's base, mentions of political\nmaneuvering. Explicit statements that a\npolicy issue is good or bad for a\nparticular political party.\",\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Differences between right-wing and\nleft-wing politics.\",\n,→\n\"Complexities of anarchy.\",\n\"Power struggle between branches of\ngovernment.\"\n,→\n]\n},\n\"external regulation and reputation\": {\n\"description\": \"The United States' external\nrelations with another nation; the\nexternal relations of one state with\nanother; or relations between groups.\nThis includes trade agreements and\noutcomes, comparisons of policy outcomes\nor desired policy outcomes.\",\n,→\n,→\n,→\n,→\n,→\n,→\n\"examples\": [\n\"Implications of us involvement in nato and\nits allies.\",\n,→\n\"Potential consequences of us intervention\nin ukraine.\",\n,→\n\"Conflicting opinions on us involvement in\nforeign affairs.\"\n,→\n]\n}\n}\n\nBest Prompts for Frame Assignment\nAlpaca-7B (Direct Instruction)\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that\nappropriately completes the request.\n### Instruction:\n{instruction}\n### Input:\n{input}\n### Response:\nVicuna-7B, 13B (Dialogue Instruction)\n{instruction}\nUSER: {input}\nASSISTANT:\nPythia, OASST (Direct Instruction)\n<|system|>{instruction}<|endoftext|> <|prompter|>{input}<|endoftext|><|assistant|>\nLLaMA-30B, 65B (Dialogue Instruction)\n{instruction}\nUSER: {input}\nASSISTANT: [\"\nLLaMA-CoT (Direct Instruction)\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that\nappropriately completes the request.\n### Instruction:\n{instruction}\n### Input:\n{input}\n### Response:\nFalcon-40B, Instruct (Dialogue Instruction)\n{instruction}\nUSER: {input}\nASSISTANT: [\"\nBaize-7B, 13B (Dialogue Instruction)\n{instruction}\n[|Human|]{input}\n[|AI|]\nGPT3.5 (Direct Instruction)\n{instruction}\nInput: \"\"\" {input} \"\"\"\nAnswer:\nChatGPT (Direct Instruction)\n{\n\"role\": \"system\",\n\"content\": \"{instruction}\"\n},\n{\n\"role\": \"user\",\n\"content\": \"{input}\"\n}\nGPT4 (Direct Instruction)\n{\n\"role\": \"system\",\n\"content\": \"{instruction}\"\n},\n{\n\"role\": \"user\",\n\"content\": \"{input}\"\n}\nFigure 11: Best prompts for frame assignment for each model. The direct and dialogue instruction to be used with\neach prompt is shown in Figure 10.\n\nFrame\nDescription\nCapacity & Resources\nThe lack of or availability of physical, geographical, spatial, human, and financial\nresources, or the capacity of existing systems and resources to implement or carry\nout policy goals.\nConstitutionality & Jurisprudence\nThe constraints imposed on or freedoms granted to individuals, government, and\ncorporations via the Constitution, Bill of Rights and other amendments, or judicial\ninterpretation. This deals specifically with the authority of government to regulate,\nand the authority of individuals/corporations to act independently of government.\nCrime & Punishment\nSpecific policies in practice and their enforcement, incentives, and implications.\nIncludes stories about enforcement and interpretation of laws by individuals and law\nenforcement, breaking laws, loopholes, fines, sentencing and punishment. Increases\nor reductions in crime.\nCultural Identity\nThe social norms, trends, values and customs constituting culture(s), as they relate\nto a specific policy issue.\nEconomic\nThe costs, benefits, or monetary/financial implications of the issue (to an individual,\nfamily, community or to the economy as a whole).\nExternal Regulation & Reputation\nA country’s external relations with another nation; the external relations of one\nstate with another; or relations between groups. This includes trade agreements and\noutcomes, comparisons of policy outcomes or desired policy outcomes.\nFairness & Equality\nEquality or inequality with which laws, punishment, rewards, and resources are\napplied or distributed among individuals or groups. Also the balance between the\nrights or interests of one individual or group compared to another individual or\ngroup.\nHealth & Safety\nHealthcare access and effectiveness, illness, disease, sanitation, obesity, mental\nhealth effects, prevention of or perpetuation of gun violence, infrastructure and\nbuilding safety.\nMorality\nAny perspective—or policy objective or action (including proposed action)— that\nis compelled by religious doctrine or interpretation, duty, honor, righteousness or\nany other sense of ethics or social responsibility.\nPolicy Prescription & Evaluation\nParticular policies proposed for addressing an identified problem, and figuring out\nif certain policies will work, or if existing policies are effective.\nPolitical\nAny political considerations surrounding an issue. Issue actions or efforts or stances\nthat are political, such as partisan filibusters, lobbyist involvement, bipartisan\nefforts, deal-making and vote trading, appealing to one’s base, mentions of political\nmaneuvering. Explicit statements that a policy issue is good or bad for a particular\npolitical party.\nPublic Opinion\nReferences to general social attitudes, polling and demographic information, as\nwell as implied or actual consequences of diverging from or getting ahead of public\nopinion or polls.\nQuality of Life\nThe effects of a policy, an individual’s actions or decisions, on individuals’ wealth,\nmobility, access to resources, happiness, social structures, ease of day-to-day rou-\ntines, quality of community life, etc.\nSecurity & Defense\nSecurity, threats to security, and protection of one’s person, family, in-group, nation,\netc. Generally an action or a call to action that can be taken to protect the welfare of\na person, group, nation sometimes from a not yet manifested threat.\nOther\nAny frames that do not fit into the above categories.\nTable 6: Descriptions of frames as per Boydstun et al. (2014). For zero-shot prompts, we experimented with\nproviding (1) list of frames, (2) frames with relevant aspects from the descriptions (e.g. the economic frame has\nthe aspects “costs”, “benefits”, “financial implications”), and (3) frames with complete descriptions as additional\ncontext.\n\nModel\nReference\nGPT3.5\nLength\nP\nR\nF1\nP\nR\nF1\nMin Max Mean\nAlpaca-7B\n0.20\n0.15\n0.17\n0.31\n0.28\n0.29\n3\n21\n7.92\nBaize-13B\n0.17\n0.15\n0.16\n0.33\n0.32\n0.32\n1\n39\n8.47\nBaize-7B\n0.223\n0.19\n0.20\n0.383\n0.38\n0.383\n2\n46\n10.73\nBLOOM\n0.15\n0.09\n0.11\n0.22\n0.19\n0.20\n1\n54\n8.13\nFalcon-40B\n0.12\n0.09\n0.10\n0.17\n0.17\n0.17\n1\n57\n9.57\nFalcon-40B-Inst.\n0.223\n0.18\n0.20\n0.34\n0.32\n0.33\n2\n33\n9.34\nChatGPT\n0.232\n0.241\n0.231\n0.392\n0.431\n0.411\n3\n34\n11.10\nGPT4\n0.21\n0.19\n0.20\n0.37\n0.36\n0.37\n4\n18\n7.50\nGPT-NeoX\n0.19\n0.07\n0.12\n0.24\n0.17\n0.20\n1\n34\n7.42\nLLaMA-30B\n0.12\n0.06\n0.08\n0.19\n0.17\n0.17\n1\n46\n9.58\nLLaMA-CoT\n0.241\n0.212\n0.222\n0.411\n0.393\n0.402\n3\n29\n8.45\nLLaMA-65B\n0.08\n0.02\n0.05\n0.14\n0.14\n0.14\n1\n46\n10.27\nOASST\n0.223\n0.212\n0.213\n0.392\n0.402\n0.402\n3\n31\n10.15\nOPT\n0.16\n0.09\n0.12\n0.22\n0.19\n0.20\n1\n30\n8.27\nPythia\n0.19\n0.13\n0.16\n0.31\n0.27\n0.29\n2\n34\n7.69\nT0\n0.15\n0.00\n0.06\n0.15\n0.03\n0.09\n1\n18\n3.10\nGPT3.5\n0.232\n0.203\n0.213\n–\n–\n–\n3\n27\n9.44\nVicuna-13B\n0.21\n0.212\n0.213\n0.36\n0.393\n0.37\n3\n39\n11.87\nVicuna-7B\n0.20\n0.19\n0.19\n0.34\n0.37\n0.35\n2\n42\n11.47\nTable 7: Complete results of automatic evaluation via BERTScore for the cluster labeling task of all 19 LLMs. We\ncompared them against the manually annotated reference and GPT3.5, the best model from our manual evaluation.\nThe top three models are indicated for each metric. Similar to the ROUGE evaluation, we see a strong performance\nby ChatGPT and LLaMA-CoT. Also shown are the statistics of the length of the generated cluster labels (in number of\ntokens).\nModel\nReference\nGPT3.5\nR-1\nR-2\nR-LCS\nR-1\nR-2\nR-LCS\nAlpaca-7B\n13.89\n3.10\n12.65\n19.98\n6.08\n18.05\nBaize-13B\n14.44\n2.28\n13.02\n24.59\n8.23\n22.53\nBaize-7B\n17.40\n2.88\n14.95\n26.35\n9.43\n23.89\nBLOOM\n12.52\n2.52\n11.34\n13.10\n3.74\n12.20\nFalcon-40B\n14.30\n3.06\n13.26\n13.08\n3.49\n11.92\nFalcon-40B-Inst.\n17.59\n3.973\n15.483\n21.72\n7.66\n19.57\nChatGPT\n20.151\n4.881\n17.421\n29.521\n10.992\n25.752\nGPT4\n16.43\n2.84\n14.42\n27.763\n9.573\n24.803\nGPT-NeoX\n12.93\n2.37\n11.72\n11.67\n2.41\n10.72\nLLaMA-30B\n12.30\n2.60\n11.19\n12.07\n2.70\n11.14\nLLaMA-CoT\n18.912\n4.502\n16.832\n28.942\n11.691\n26.381\nLLaMA-65B\n10.25\n1.93\n9.40\n10.81\n2.49\n9.95\nOASST\n18.283\n3.58\n16.15\n27.13\n9.09\n23.88\nOPT\n11.67\n2.68\n10.87\n10.56\n2.17\n9.55\nPythia\n14.78\n2.99\n13.23\n21.64\n6.44\n19.67\nT0\n9.80\n2.01\n9.61\n7.64\n1.70\n7.52\nGPT3.5\n16.82\n2.96\n14.61\n–\n–\n–\nVicuna-13B\n16.90\n3.02\n14.81\n25.32\n8.66\n22.66\nVicuna-7B\n17.04\n2.62\n14.81\n23.88\n7.42\n20.87\nTable 8: Complete results of automatic evaluation via ROUGE for the cluster labeling task of all 19 LLMs. We\ncompared them against the manually annotated reference and GPT3.5, the best model from our manual evaluation.\nThe top three models are indicated for each metric. We see that ChatGPT and LLaMA-CoT perform strongly across\nthe board.\n\nGuideline for judging the quality of the clustering\nTask: Given a reference text and a set of hypotheses, rank the hypotheses based on how similar they\nare to the reference text.\nHow similar are the small texts to the reference text?\nDrag and drop the boxes with the texts on the left and bring them in your preferred order on the right.\nThe most preferred text is on the top and the less you prefer a text, the lower it should be in the ranking.\nSimilarity is less in a sense of exact meaning but much rather in a meaning of is there some relation\nbetween the reference and hypotheses.\nTo get a better understanding of the meaning of the reference, the title of the original discussion and\nsome central sentences from the cluster are provided (click the “show cluster” button next to the\nreference). The central sentences are selected based on how central they are in the original cluster and\ntheir mean similarity to the reference and hypotheses. So these are not perfectly representative to the\ncluster, but they can help you to get a better understanding of some hard to understand meanings.\nRecommended Strategy for judging:\nThe relation between the reference and hypotheses is understandable:\n→only read the reference and the hypotheses\nThe reference is a bit weird:\n→read the title to get a better idea in what context the reference is used\nThe hypotheses are hard to understand:\n→read the central sentences from the cluster for more context\nThe relation between the reference and hypotheses are not clear:\n→read the central and random sentences from the cluster\nNote: We are looking for a label that sufficiently describes the content of a cluster of sentences. It is\nimportant to understand that the reference is not the perfect label but rather strongly representative of\nthe cluster.\nWhen a lot of hypotheses talk about something that is not in the reference, it is sensible to include this\ninformation in the reference (implicitly) to make it “complete” while ranking the hypotheses.\nExample:\nReference: responsibilities between employee and employer\nMajority of the given hypotheses mention: “the service industry”\nUpdated Reference: responsibilities between employee and employer in the service industry\nIn the end we are looking for the central meaning of the cluster and it is very likely that at least one\nmodel got the central meaning right and the task is to guess what model got the central meaning best\nbased on what the reference suggests the best central meaning is.\nTable 9: Guideline for judging the quality of the clustering.\n\nModel\nZero-Shot\nZero-Shot (short)\nZero-Shot (full)\nFew-Shot\ntop 1\ntop 2\ntop 3\ntop 1\ntop 2\ntop 3\ntop 1\ntop 2\ntop 3\ntop 1\ntop 2\ntop 3\nAlpaca-7B\n39.1\n53.9\n64.2\n39.5\n51.0\n64.6\n28.4\n37.4\n57.2\n20.6\n26.7\n49.4\nBLOOM\n26.7\n46.5\n53.5\n31.7\n52.7\n57.6\n25.5\n51.9\n60.1\n–\n–\n–\nBaize-13B\n42.4\n53.5\n58.4\n48.1\n59.3\n63.4\n42.0\n53.5\n60.5\n39.5\n46.5\n49.4\nBaize-7B\n34.2\n44.4\n52.7\n34.6\n46.9\n56.8\n39.1\n46.5\n53.9\n30.9\n38.3\n45.7\nFalcon-40B\n46.5\n68.3\n72.0\n46.5\n67.5\n75.7\n46.1\n56.8\n64.2\n38.3\n53.5\n68.3\nFalcon-40B-Inst.\n51.4\n64.6\n72.8\n44.4\n56.4\n68.3\n32.9\n44.9\n57.6\n28.4\n49.4\n63.8\nChatGPT\n60.9\n76.1\n86.4\n58.0\n78.6\n88.5\n58.8\n76.1\n84.8\n63.4\n80.2\n90.1\nGPT-4\n63.4\n82.3\n91.8\n60.5\n84.4\n90.1\n65.4\n83.1\n90.5\n67.1\n84.8\n88.5\nGPT-NeoX\n19.3\n28.4\n50.6\n25.1\n31.3\n51.9\n31.3\n36.6\n50.2\n31.3\n39.5\n49.0\nLLaMA-30B\n45.7\n63.0\n70.8\n41.2\n57.2\n65.4\n39.1\n58.0\n66.3\n40.7\n70.0\n77.8\nLLaMA-CoT\n46.9\n73.3\n84.0\n54.3\n75.7\n85.6\n49.8\n71.2\n82.3\n57.2\n70.0\n77.0\nLLaMA-65B\n53.1\n65.4\n81.9\n50.6\n70.8\n82.3\n39.5\n64.6\n78.6\n–\n–\n–\nOASST\n48.6\n72.8\n82.3\n48.1\n66.3\n76.5\n53.5\n73.7\n82.7\n47.7\n65.0\n79.8\nOPT-66B\n16.0\n18.9\n43.2\n13.2\n16.5\n45.3\n14.8\n18.1\n45.7\n–\n–\n–\nPythia\n31.7\n44.0\n52.3\n33.3\n43.6\n49.4\n30.5\n39.1\n44.9\n29.6\n34.2\n38.7\nT0++\n48.6\n58.4\n64.2\n54.3\n60.1\n65.4\n55.6\n59.7\n63.8\n49.8\n52.3\n53.5\nGPT3.5\n53.5\n74.1\n81.9\n60.9\n65.4\n66.7\n58.0\n58.8\n59.7\n53.9\n57.6\n58.0\nVicuna-13B\n44.0\n52.7\n62.1\n40.7\n55.1\n67.1\n42.0\n53.1\n64.6\n38.3\n50.2\n60.1\nVicuna-7B\n28.4\n34.6\n50.2\n36.2\n48.1\n61.3\n35.4\n42.8\n55.1\n20.2\n24.3\n46.1\nTable 10: Complete results of automatic evaluation for the frame assignment task. Shown are the % of examples\nwhere the first, second, and third predicted frames by a model are one of the reference frames. For the zero-shot\nsetting, values are shown for each of the prompt type: only frame label, label with short description, and label with\nfull description. Missing values are model inferences that exceeded our computational resources.\nPrompt Templates for T0\nprefix\nWhat {output_type} would you choose for the {input_type} below?\n{text}\npostfix\n{text}\nWhat {output_type} would you choose for the {input_type} above?\nprefix-postfix\nWhat {output_type} would you choose for the {input_type} below?\n{text}\nWhat {output_type} would you choose for the {input_type} above?\nshort\n{input_type}:\n{text}\n{output_type}:\nexplicit\n{input_type} START\n{text}\n{input_type} END\n{output_type} OF THE {input_type}:\nquestion answering\nRead the following context and answer the question.\nContext:\n{text}\nQuestion: What is the {output_type} of the {input_type}?\nAnswer:\nTable 11: Prompt templates investigated for T0 model for generative cluster labeling.\n\nPrompt Templates for BLOOM, GPT-NeoX, OPT, GPT3.5\ndialogue\nAI assistant: I am an expert AI assistant. How can I help you?\nHuman: Can you tell me what the {output_type} of the following {input_type} is?\n{input_type} START\n{text}\n{input_type} END\nAI assistant: The {output_type} of the {input_type} is \"\nexplicit\n{input_type} START\n{text}\n{input_type} END\n{output_type} of the {input_type}: \"\nassistant solo\nAI assistant: I am an expert AI assistant and I am very good in identifying\n{output_type} of debates.\n,→\n{input_type} START\n{text}\n{input_type} END\nAI assistant: The {output_type} of the {input_type} between the two participants\nis \"\n,→\nquestion answering\n{input_type} START\n{text}\n{input_type} END\nQ: What is the {output_type} of the {input_type}?\nA: The {output_type} of the {input_type} is \"\nGPT3.5\nGenerate a single descriptive phrase that describes the following debate in very\nsimple language, without talking about the debate or the author.\n,→\nDebate: \"\"\"{text}\"\"\"\nTable 12: Prompt templates investigated for generative cluster labeling with the four decoder-only models. The\ninput_type is either “debate” or “discussion” and the output_type is either “title” or “topic”.\n\nPrompt Templates for Instruction-following LLMs\nGPT3.5\n{instruction}\nInput: \"\"\"{input}\"\"\"\nAnswer:\nAlpaca-7B, LLaMA-CoT\nBelow is an instruction that describes a task, paired with an input that provides\nfurther context. Write a response that appropriately completes the request.\n,→\n### Instruction:\n{instruction}\n### Input:\n{input}\n### Response:\nBaize-13B, Baize-7B\n{instruction}\n[|Human|]{input}\n[|AI|]\nBLOOM, Falcon-40B, Falcon-40B-Instruct, GPT-NeoX, LLaMA-30B, LLaMA-65B, OPT-66B,\nVicuna-13B, Vicuna-7B\n{instruction}\nUSER: {input}\nASSISTANT:\nOASST, Pythia\n<|system|>{instruction}<|endoftext|><|prompter|>{input}<|endoftext|><|assistant|>\nT0++\n{instruction}\nInput: {input}\nTable 13: Prompt templates used for experiments with instruction-following model.\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversa-\ntion with a depressed person\nIndicative Summary (LLaMA-CoT)\nHealth & Safety\n• Depression is a complex mental health issue that varies in severity and treatment options. [98] (Policy\nPrescription & Evaluation)\n• Impact of depression and how to help those affected. [35] (Morality)\n• Personal journey of overcoming depression and finding happiness. [17] (Quality of Life)\nMorality\n• Gratitude and appreciation for the little things in life can help improve happiness and perspective. [39]\n(Quality of Life)\n• Perspective and its importance in life. [22] (Fairness & Equality)\n• Positive self-talk and growth mindset [21] (Fairness & Equality)\nPolicy Prescription & Evaluation\n• Comparing situations to others’ can be helpful or harmful. [97] (Morality)\n• Effectiveness of advice in different situations [25] (Capacity & Resources)\n• Psychology and the power of the brain to reprogram thought patterns. [22] (Morality)\nTable 14: Indicative Summary from LLaMA-CoT.\n\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversa-\ntion with a depressed person\nIndicative Summary (GPT3.5)\nFairness & Equality\n• Complexities of comparing one’s own struggles to those of others. [97] (Quality of Life)\n• Advice can be helpful or unhelpful depending on how it is used. [25] (Morality)\n• Focusing on personal goals and eliminating negative self-talk to create a growth mindset. [21] (Quality\nof Life)\nHealth & Safety\n• How to help those with depression. [35] (Quality of Life)\nMorality\n• Differences between sadness and depression. [98] (Quality of Life)\n• Reflecting on blessings and practicing gratitude to increase happiness. [39] (Quality of Life)\n• Mindful awareness and reprogramming of thought patterns to take charge of emotions. [22] (Quality of\nLife)\n• Gaining perspective to appreciate life and understand how one’s actions affect others. [22] (Fairness &\nEquality)\n• A journey of self-discovery and growth through difficult times. [17] (Quality of Life)\nTable 15: Indicative Summary from GPT3.5.\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversa-\ntion with a depressed person\nIndicative Summary (GPT4)\nFairness & Equality\n• Acknowledging personal struggles while recognizing others’ hardships [97] (Quality of Life)\nHealth & Safety\n• Understanding and managing depression as a complex mental state [98] (Quality of Life)\n• Importance of gratitude for happiness and mental health [39] (Quality of Life)\n• Impact of different approaches to supporting depressed individuals. [35] (Quality of Life)\n• Controlling and reprogramming thought patterns through mindful awareness and rational evaluation of\nemotions. [22] (Quality of Life)\nPolicy Prescription & Evaluation\n• Effectiveness of advice depends on individual and context. [25] (Quality of Life)\nQuality of Life\n• Gaining perspective for personal growth and understanding. [22] (Morality)\n• Focusing on positive mindset and self-growth [21] (Health & Safety)\n• Overcoming challenges and finding happiness through personal growth and change. [17] (Morality)\nTable 16: Indicative Summary from GPT4.\n\nCMV: Today is the best time period in human history to be alive for the vast majority of people.\nIndicative Summary (LLaMA-CoT)\nCapacity & Resources\n• The importance of having a private space for studying and building projects. [33] (Quality of Life)\nCrime & Punishment\n• Crime rates have changed over time. [60] (Security & Defense)\nCultural Identity\n• Nostalgia for the 90s [82] (Quality of Life)\nEconomic\n• Housing affordability is a complex issue with many factors at play. [203] (Capacity & Resources)\n• Global poverty has decreased significantly over the past few decades. [135] (Capacity & Resources)\n• Global trends and perspectives [48] (Policy Prescription & Evaluation)\nHealth & Safety\n• AIDS pandemic was more fatal than the current one. [97] (Capacity & Resources)\n• Current mental health epidemic and its causes. [32] (Capacity & Resources)\nPolicy Prescription & Evaluation\n• Climate change is a serious issue that needs to be addressed. [113] (Economic)\n• Concentration of military and economic power in history. [47] (Economic)\nQuality of Life\n• Best time period in human history to be alive. [72] (Economic)\n• Quality of Life vs Expectations: Happiness Debate [68] (Other)\n• Progress and improvement in society and culture [51] (Cultural Identity)\n• Impact of technology on human connection and fulfillment. [39] (Cultural Identity)\n• Middle Ages vs. Modern Times: Quality of Life Comparison [29] (Cultural Identity)\nSecurity & Defense\n• Statistics and data points in a debate about safety and progress [43] (Health & Safety)\nTable 17: Indicative Summary from LLaMA-CoT.\n\nCMV: Today is the best time period in human history to be alive for the vast majority of people.\nIndicative Summary (GPT3.5)\nCrime & Punishment\n• Violent crime rate has significantly decreased since the 1990s, but still remains an issue. [60] (Fairness\n& Equality)\nCultural Identity\n• A constant flow of information and societal changes causing a crisis of meaning. [39] (Quality of Life)\nEconomic\n• Catastrophic climate change leading to economic and ecological collapse. [113] (Health & Safety)\n• Fragmented global economic and military power. [47] (Security & Defense)\nFairness & Equality\n• Housing prices have skyrocketed in the past decade, making it difficult for the average American to\nafford a home. [203] (Economic)\n• Decrease in global poverty and hunger since the 90s, with a majority of the world population still living\nin poverty. [135] (Capacity & Resources)\n• Differences between the 90s and the 2000s, and the effects of time periods on different generations.\n[82] (Quality of Life)\n• Making progress towards a better world for future generations. [51] (Quality of Life)\n• Throwing around statistics without meaning and misusing percentages. [43] (Policy Prescription &\nEvaluation)\n• Room to study and compete in the job market. [33] (Capacity & Resources)\n• A comparison of the lifestyles of lower-class people in the Middle Ages and modern times. [29]\n(Quality of Life)\nHealth & Safety\n• Effects of pandemics on population growth and life expectancy, with a comparison to the Bubonic\nPlague. [97] (Quality of Life)\nMorality\n• Mental health crisis in the modern world and its potential causes. [32] (Quality of Life)\nPolitical\n• Strong bias towards American perspective on global issues. [48] (Cultural Identity)\nQuality of Life\n• Best time period in human history to be alive. [72] (Fairness & Equality)\n• Balance between quality of life, expectations, and happiness, and how they relate to each other. [68]\n(Fairness & Equality)\nTable 18: Indicative Summary from GPT3.5.\n\nCMV: Today is the best time period in human history to be alive for the vast majority of people.\nIndicative Summary (GPT4)\nCrime & Punishment\n• Violent crime rates have decreased since the 90s. [60] (Security & Defense)\nCultural Identity\n• Nostalgia for the 90s and differing opinions on the era [82] (Quality of Life)\n• Assuming most users are American [48] (Public Opinion)\nEconomic\n• Housing affordability crisis in various locations [203] (Quality of Life)\n• Reduced global poverty and hunger rates [135] (Fairness & Equality)\n• Concentration of military and economic power in history [47] (Security & Defense)\nHealth & Safety\n• Climate change and its worsening effects on Earth and humanity. [113] (Quality of Life)\n• Comparing pandemics and death rates throughout history [97] (Quality of Life)\n• Mental health awareness and treatment in modern society. [32] (Quality of Life)\nPolicy Prescription & Evaluation\n• Acknowledging progress while recognizing room for improvement [51] (Quality of Life)\nQuality of Life\n• Best time to be alive debate [72] (Economic)\n• Happiness influenced by expectations and quality of life. [68] (Economic)\n• Misunderstanding and misuse of statistics [43] (Policy Prescription & Evaluation)\n• Crisis of meaning and disconnection in modern society [39] (Cultural Identity)\n• Importance of personal space for productivity and success [33] (Economic)\n• Simple life in the Middle Ages vs modern lower class life [29] (Economic)\nTable 19: Indicative Summary from GPT4.\n\nCMV: There shouldn’t be anything other than the metric system.\nIndicative Summary (LLaMA-CoT)\nCapacity & Resources\n• Boiling and freezing points of water [154] (Quality of Life)\nEconomic\n• Use of different size bottles in the dairy industry. [87] (Capacity & Resources)\n• The cost of switching to the metric system is too high. [59] (Capacity & Resources)\nHealth & Safety\n• Temperature ranges and weather conditions [86] (Quality of Life)\n• Temperature range and clothing suggestions [63] (Quality of Life)\nPolicy Prescription & Evaluation\n• Merits of Celsius and Fahrenheit temperature scales [283] (Constitutionality & Jurisprudence)\n• Merits of the imperial and metric systems [196] (Constitutionality & Jurisprudence)\n• Use of miles and feet in measuring distances [140] (Quality of Life)\n• Merits of different systems of measurement [106] (Economic)\n• Base 12 is better than base 10 for certain calculations. [104] (Capacity & Resources)\n• Precision of measurements in inches and millimeters [75] (Quality of Life)\n• Use of feet and inches for measuring height [72] (Constitutionality & Jurisprudence)\n• Importance of precision in measurements [64] (Capacity & Resources)\n• Metric vs. Imperial: Which system is better? [52] (Constitutionality & Jurisprudence)\n• Merits of different counting systems [49] (Fairness & Equality)\n• Merits of a decimal time system [48] (Economic)\n• Merits of different scales and their practicality [46] (Capacity & Resources)\n• Merits of different systems [42] (Economic)\nTable 20: Indicative Summary from LLaMA-CoT.\n\nCMV: There shouldn’t be anything other than the metric system.\nIndicative Summary (GPT3.5)\nCapacity & Resources\n• Over intuitive systems and their advantages. [106] (Quality of Life)\n• For a more efficient counting system. [104] (Policy Prescription & Evaluation)\n• Usefulness of different measurements for everyday use. [87] (Quality of Life)\nEconomic\n• Legacy system rooted in society with benefits for everyday use and practical applications, but costly to\ntransition away from. [196] (Fairness & Equality)\n• Counting systems and their relative merits. [49] (Fairness & Equality)\nFairness & Equality\n• Comparing the practicality of Celsius and Fahrenheit for everyday use, with no clear advantage to\neither. [283] (Quality of Life)\n• Temperature scale based on water’s freezing and boiling points. [154] (Constitutionality & Jurispru-\ndence)\n• Advantages and disadvantages of using inches and centimeters for measurements. [75] (Constitutionality\n& Jurisprudence)\n• Usefulness of feet and inches for measuring human height. [72] (Quality of Life)\n• A wide range of temperatures from chilly to hot, requiring different levels of clothing. [63] (Quality of\nLife)\n• Costly transition to international standardization with little net benefit to average American. [59]\n(Economic)\n• Advantages and disadvantages of the metric system. [52] (Constitutionality & Jurisprudence)\n• Advantages and disadvantages of different scales. [46] (Capacity & Resources)\n• Pros and cons of different systems. [42] (Policy Prescription & Evaluation)\nHealth & Safety\n• Extremely cold temperatures ranging from -50C to +50C across the globe. [86] (Quality of Life)\nConstitutionality & Jurisprudence\n• Use of miles, yards, feet, and kilometers for measuring distances. [140] (Policy Prescription &\nEvaluation)\n• Precision and accuracy in measurement. [64] (Policy Prescription & Evaluation)\n• Complexities of measuring time. [48] (Policy Prescription & Evaluation)\nTable 21: Indicative summary from GPT3.5.\n\nCMV: There shouldn’t be anything other than the metric system.\nIndicative Summary (GPT4)\nCapacity & Resources\n• Water freezing and boiling points discussion [154] (Health & Safety)\n• Base 12 system advantages [104] (Economic)\n• Measurement units and their precision in various contexts [75] (Quality of Life)\nCultural Identity\n• Preference for miles over kilometers in everyday language and distances [140] (Quality of Life)\n• Preference based on familiarity and upbringing [106] (Quality of Life)\n• Preference for feet and inches in measuring height [72] (Quality of Life)\nEconomic\n• Costly and challenging transition to new system. [59] (Capacity & Resources)\n• Using different counting systems and their efficiency in various situations. [49] (Capacity & Resources)\nHealth & Safety\n• Temperature range discussion and its effects on daily life [86] (Quality of Life)\n• Temperature and clothing preferences [63] (Quality of Life)\nQuality of Life\n• Comparing Celsius and Fahrenheit for everyday use [283] (Capacity & Resources)\n• Imperial system vs. Metric system debate [196] (Cultural Identity)\n• Metric and imperial measurements in daily life and their usefulness. [87] (Capacity & Resources)\n• Misunderstanding precision and accuracy in measurements [64] (Health & Safety)\n• Metric system advantages and precision debate [52] (Policy Prescription & Evaluation)\n• Alternative time measurement systems [48] (Cultural Identity)\n• Usefulness and subjectivity of different scales [46] (Fairness & Equality)\n• Old system versus new system for everyday life [42] (Economic)\nTable 22: Indicative summary from GPT4.\nCMV: Shoe sizes should be the same for both men and women\nIndicative Summary (LLaMA-CoT)\nFairness & Equality\n• Men and women’s feet are different in size and shape. [73] (Policy Prescription & Evaluation)\n• Differences between men’s and women’s shoes and the impact of unisex shoes. [44] (Policy Prescription\n& Evaluation)\n• Shoe sizes vary by sex due to differences in foot shape. [30] (Quality of Life)\n• Women with broad but small feet struggle to find shoes that fit. [19] (Quality of Life)\n• Differences in clothing proportions for men and women [17] (Policy Prescription & Evaluation)\nPolicy Prescription & Evaluation\n• Pros and cons of standardizing shoe sizes [64] (Economic)\n• Use of different measurement systems [21] (Economic)\nTable 23: Indicative summary from LLaMA-CoT.\n\nCMV: Shoe sizes should be the same for both men and women\nIndicative Summary (GPT3.5)\nFairness & Equality\n• Men and women’s feet are differently shaped. [73] (Cultural Identity)\n• Multiple shoe sizing systems causing confusion. [64] (Quality of Life)\n• Gender-specific shoe design and comfort. [44] (Quality of Life)\n• Different shoe sizes for men and women based on width and length. [30] (Quality of Life)\n• Different measurement standards for length. [21] (Constitutionality & Jurisprudence)\n• Wide feet struggle to find shoes that fit properly. [19] (Quality of Life)\n• Clothing designed differently for men and women. [17] (Cultural Identity)\nTable 24: Indicative summary from GPT3.5.\nCMV: Shoe sizes should be the same for both men and women\nIndicative Summary (GPT4)\nEconomic\n• Shoe durability and gender differences in footwear preferences [44] (Quality of Life)\nFairness & Equality\n• Standardizing shoe sizes for everyone [64] (Quality of Life)\n• Differences in clothing proportions for men and women [17] (Cultural Identity)\nHealth & Safety\n• Differences in men’s and women’s feet [73] (Quality of Life)\nQuality of Life\n• Shoe sizes differ for men and women due to width and shape differences in feet. [30] (Fairness &\nEquality)\n• Different measurement systems for shoe sizes [21] (Cultural Identity)\n• Finding shoes for wide and small feet [19] (Fairness & Equality)\nTable 25: Indicative summary from GPT4.\nCMV: Social media is the most destructive addiction in our society\nIndicative Summary (LLaMA-CoT)\nEconomic\n• Role of money in society and its impact on humanity. [23] (Capacity & Resources)\n• Role of capitalism in society. [20] (Policy Prescription & Evaluation)\n• Costs of running systems and offsetting those costs. [19] (Capacity & Resources)\nFairness & Equality\n• Discrimination lawsuit against Amazon founder [25] (Constitutionality & Jurisprudence)\nHealth & Safety\n• The impact of opioid addiction on individuals and society is devastating. [107] (Morality)\nMorality\n• Social media addiction vs opioid crisis [38] (Capacity & Resources)\nPolicy Prescription & Evaluation\n• Pros and cons of social media and its impact on society. [48] (Morality)\n• Measuring impact of technology on society [35] (Economic)\n• The importance of education and community for a better world. [26] (Capacity & Resources)\n• The impact of social media on society [26] (Public Opinion)\n• The impact of social media on mental health is debated. [24] (Health & Safety)\nTable 26: Indicative summary from LLaMA-CoT.\n\nCMV: Social media is the most destructive addiction in our society\nIndicative Summary (GPT3.5)\nEconomic\n• Complexities of money as a social construct. [23] (Fairness & Equality)\n• Costly infrastructure needed to run systems. [19] (Capacity & Resources)\nFairness & Equality\n• Importance of education, societal injustices, and the consequences of comparing oneself to others. [26]\n(Quality of Life)\n• Powerful man accused of denying bathroom access to employees. [25] (Constitutionality & Jurispru-\ndence)\n• Effects of capitalism on human behavior. [20] (Economic)\nHealth & Safety\n• Effects of social media on mental health. [24] (Quality of Life)\nMorality\n• Devastating consequences of opioid addiction leading to death and destruction. [107] (Health & Safety)\n• Effects of social media and opioid use on mental health. [38] (Health & Safety)\n• Negative effects of social media outweigh the positives, leading to a lack of critical thinking and a\nmoral panic. [26] (Quality of Life)\nPublic Opinion\n• Pros and cons of social media. [48] (Cultural Identity)\nQuality of Life\n• Measuring societal impact through quality of life and direction of society. [35] (Cultural Identity)\nTable 27: Indicative summary from GPT3.5.\nCMV: Social media is the most destructive addiction in our society\nIndicative Summary (GPT4)\nEconomic\n• Money as a social construct and tool for exchange [23] (Quality of Life)\n• Capitalism and human nature discussion [20] (Fairness & Equality)\n• Costs and responsibilities of using resources and services [19] (Capacity & Resources)\nHealth & Safety\n• Opioid crisis and its impact on individuals and society [107] (Quality of Life)\n• Social media and opioid addiction relationship [38] (Quality of Life)\n• Social media’s impact on mental health and potential link to suicide rates. [24] (Quality of Life)\nConstitutionality & Jurisprudence\n• Lawsuit against Bezos for denying bathroom access [25] (Health & Safety)\nQuality of Life\n• Social media as a tool for connection and learning [48] (Capacity & Resources)\n• Measuring impact through quality of life and societal direction [35] (Fairness & Equality)\n• Improving society through better education and empathy. [26] (Fairness & Equality)\n• Impact of social media on society and individuals [26] (Cultural Identity)\nTable 28: Indicative summary from GPT4.",
    "pdf_filename": "Indicative Summarization of Long Discussions.pdf"
}