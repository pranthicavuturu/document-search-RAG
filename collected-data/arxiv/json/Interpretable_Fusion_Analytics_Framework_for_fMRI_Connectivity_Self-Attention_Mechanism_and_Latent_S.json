{
    "title": "Interpretable Fusion Analytics Framework for fMRI Connectivity Self-Attention Mechanism and Latent S",
    "context": "There have been several attempts to use deep learning based on brain fMRI signals to classify cognitive impairment diseases. However, deep learning is a hidden black box model that makes it difﬁcult to interpret the process of classiﬁcation. To address this issue, we propose a novel analytical framework that interprets the classiﬁcation result from deep learning processes. We ﬁrst derive the region of interest (ROI) functional connectivity network (FCN) by embedding functions based on their similar signal patterns. Then, using the self-attention equipped deep learning model, we classify diseases based on their FCN. Finally, in order to interpret the classiﬁcation results, we employ a latent space item-response interaction network model to identify the signiﬁcant functions that exhibit distinct connectivity patterns when compared to other diseases. The application of this proposed framework to the four types of cognitive impairment shows that our approach is valid for determining the signiﬁcant ROI functions. Keywords fMRI · ADNI · Functional Connectivity Network · Deep Learning · Latent Space Item-Response Model Recently, Deep Neural Networks (DNN) have emerged as popular models of computation in classifying the different cognitive impairment groups in neuroimaging research [1, 2]. However, when it comes to classifying diseases with functional magnetic resonance imaging (fMRI) data (i.e., time–series data in resting state fMRI), improving classiﬁcation accuracy has proved to be challenging given that the brain dynamics captured are high–dimensional, and not readily interpretable due to the complexity of subject–speciﬁc temporal and spatial signals (i.e., spatial maps with associated time courses between nodes). As such, typical deep learning models consist of hidden black box structures, which makes the interpretation of how the model actually produced the output hard to interpret. Previous studies have mainly focused on summarizing brain functions called Regions of Interests (ROIs) signals, comparing two ROI signal patterns by using methods such as Pearson correlation matrices [3] and Fisher transformation score [4]. Despite the fact that this approach offers valuable advantages, such as the ability to simply and intuitively capture the whole–brain interactions as proxy representation of networks, these comparisons of pairwise–(dis)similarities only considers conditional relationships by controlling for high degrees of correlation, such as triangular correlation [5]. By doing so, a lot of valuable information may be lost due to the relative simplicity of this approach. ∗Under review †Equal contribution ‡Corresponding author arXiv:2207.01581v1  [cs.LG]  4 Jul 2022",
    "body": "INTERPRETABLE FUSION ANALYTICS FRAMEWORK FOR FMRI\nCONNECTIVITY: SELF–ATTENTION MECHANISM AND LATENT\nSPACE ITEM–RESPONSE MODEL∗\nJeong-Jae Kim†\nYonsei University\njeongjaekim@yonsei.ac.kr\nYeseul Jeon†\nYonsei University\njeon9677@yonsei.ac.kr\nSuMin Yu\nDuke University\nsumin.yu@duke.edu\nJunggu Choi\nYonsei University\njunggu.choi@yonsei.ac.kr\nSanghoon Han‡\nYonsei University\nsanghoon.han@yonsei.ac.kr\nABSTRACT\nThere have been several attempts to use deep learning based on brain fMRI signals to classify\ncognitive impairment diseases. However, deep learning is a hidden black box model that makes it\ndifﬁcult to interpret the process of classiﬁcation. To address this issue, we propose a novel analytical\nframework that interprets the classiﬁcation result from deep learning processes. We ﬁrst derive the\nregion of interest (ROI) functional connectivity network (FCN) by embedding functions based on\ntheir similar signal patterns. Then, using the self-attention equipped deep learning model, we classify\ndiseases based on their FCN. Finally, in order to interpret the classiﬁcation results, we employ a\nlatent space item-response interaction network model to identify the signiﬁcant functions that exhibit\ndistinct connectivity patterns when compared to other diseases. The application of this proposed\nframework to the four types of cognitive impairment shows that our approach is valid for determining\nthe signiﬁcant ROI functions.\nKeywords fMRI · ADNI · Functional Connectivity Network · Deep Learning · Latent Space Item-Response Model\nIntroduction\nRecently, Deep Neural Networks (DNN) have emerged as popular models of computation in classifying the different\ncognitive impairment groups in neuroimaging research [1, 2]. However, when it comes to classifying diseases with\nfunctional magnetic resonance imaging (fMRI) data (i.e., time–series data in resting state fMRI), improving classiﬁcation\naccuracy has proved to be challenging given that the brain dynamics captured are high–dimensional, and not readily\ninterpretable due to the complexity of subject–speciﬁc temporal and spatial signals (i.e., spatial maps with associated\ntime courses between nodes). As such, typical deep learning models consist of hidden black box structures, which\nmakes the interpretation of how the model actually produced the output hard to interpret.\nPrevious studies have mainly focused on summarizing brain functions called Regions of Interests (ROIs) signals,\ncomparing two ROI signal patterns by using methods such as Pearson correlation matrices [3] and Fisher transformation\nscore [4]. Despite the fact that this approach offers valuable advantages, such as the ability to simply and intuitively\ncapture the whole–brain interactions as proxy representation of networks, these comparisons of pairwise–(dis)similarities\nonly considers conditional relationships by controlling for high degrees of correlation, such as triangular correlation [5].\nBy doing so, a lot of valuable information may be lost due to the relative simplicity of this approach.\n∗Under review\n†Equal contribution\n‡Corresponding author\narXiv:2207.01581v1  [cs.LG]  4 Jul 2022\n\nThe nature of fMRI data is inherently high–dimensional signal data that consists of three dimensions; patient group,\ntime, and ROIs. Given that multivariate data may suffer from the curse of dimensionality, reducing dimensionality is\ninevitable; this step is crucial in order to facilitate the identiﬁcation, analyses, and interpretation of the data, which are\noften done using a univariate feature selection procedure that considers neither the spatial structure of the data, nor the\nmultivariate characteristics of the signal.\nIn order to avoid redundancy and noise while maintaining core latent features in the data to represent functional\nbrain network with the goal of embedding brain functions to estimate their connections, we implemented several\nlinear and non–linear dimensionality reduction techniques; Principal Component Analysis (PCA) [6], T–stochastic\nneighbor embedding (t–SNE) [7], Uniforma Manifold Approximation Projection (UMAP) [8]. t–SNE and UMAP\nmodel the manifold using stochastic (i.e., converting neighborhood’s distance into conditional probability that represents\nsimilarity) and topological (i.e., fuzzy simplicial complex with edge weights representing the likelihood of connectivity)\ninformation, respectively. By using unsupervised and non-linear manifold learning to project ROIs onto spaces of lower\ndimensionality, t–SNE and UMAP preserves the distance and identities of probable neighborhood (i.e., ROIs, nodes).\nHowever, since dimension methods only return the latent position of ROIs, we must deﬁne connections between ROIs\nusing their latent position on R2 space. To accomplish this, we used TDA’s mapper [9] to implement partial clustering,\nwhich we then used to deﬁne connections. If some ROIs are assigned to the same cluster, those ROIs are assumed\nto be connected to one another. Similarly, we can apply this concept at the end to other partial clusters that deﬁne\nconnections from local to global connections. We then built a FCN that captures all degrees of similarities between ROIs\n(Pearsons’s r, Fisher Z–transformed, PCA, t–SNE, UMAP) and were interested in comparing the capabilities of the\ndifferent dimension reduction methods for distinctively representing functional network patterns from one population to\nanother.\nIn this study, our main aim was to identify the signiﬁcant ROIs from each cognitive disease group that exhibits distinct\nsignal patterns from other groups. We assume that if the FCN accurately represents the connections, the classiﬁcation\nmodel based on each patient’s FCN network returns are highly accurate. However, due to the dimensionality reduction,\nit is still difﬁcult to validate their connections unless the data does not contain any labels, since it is an unsupervised\nlearning approach. To combat these shortcoming, we came up with a novel analytical framework. We did this by\nadopting a classiﬁcation model, self–attention equipped deep neural network, which can handle correlated structure\ndata and train their adjacency connections well [10, 11, 12]. Attention Mechanism is used to focus on speciﬁc input\nvalues from sequence–based tasks that are most relevant to the input in order to reduce information loss and increase\ninformation power [13]. Our study, which focused on networks with ROIs correlations with inter–dependencies in\nits input sequences, used a self–attention mechanism that maximized local interactions by incorporating multi–head\nself–attention layers onto a deep neural network architecture. The similarity of two ROIs in an input sequence is\ncaptured by an attention score measuring the distance of their representations simultaneously attending to every ROI\ndata including its own data. Self–attention estimates the interaction between input values and generates outputs that\nfocus on reﬂecting the predicted interaction feature when the model performs predictions, classiﬁcations or other\ncalculations. This self–attention deep model aids in the training of network information, not only for local connections\nbut also for global connections. If the accuracy is sufﬁcient, the output is a reliable source to decipher what brain\nfunctions or connectivity distinguishes the different disease population pairs.\nThe self–attention deep model not only improves prediction accuracy, but it also produces the ROIs attention distribution\nof each patient. The attention distribution of the ROIs indicates how the self–attention deep model trains the correlated\nstructured input data; each ROI in the attention distribution deﬁnes the likelihood of how one speciﬁc ROI relates to\nother ROIs, producing a representation of every ROI and the weights among different ROIs. Fig. 3 depicts the scalar\nweight, a weighted sum indicating the relation between one ROI point to all other points. The learned attentional\nrepresentation is subsequently fed through a softmax layer for normalization of the neighborhood, in order to train an\nend–to–end deep learning model and to obtain the map of attention weights. We can then use self–attention deep model\nto summarize the FCN connectivity into ROI attention distribution and infer how the deep learning model arrived at that\nclassiﬁcation decision based on the output of the ROIs attention distribution. As a result, the self–attention deep model\nis more efﬁcient than other deep learning models in terms of interpreting the model’s process through the output of\nattention distribution.\nIn terms of classiﬁcation result interpretation, one of the most efﬁcient statistical methods for handling correlated\nstructure is network analysis. This network visualizes the relationship of ROIs in an intuitive way and allows us to\ndirectly inspect signiﬁcant network features that represent a speciﬁc group over different pairs of disease populations.\nSpeciﬁcally, network modeling estimates the relationships of interactions among nodes based on their dependency\nstructure. It can provide global and local representation of nodes simultaneously. By visual scanning of latent position\nof each ROI, we can distinguish particular ROIs that share connectivities with other regions (i.e., more likely to be\nlocated in the center on the latent interaction map) from speciﬁc ROIs that are unique and independent (i.e. located\n2\n\nrelatively away from the center of interaction map); by this visualization, we can ﬁgure out which ROIs contribute to\nthe classiﬁcation of the different disease groups.\nWe estimated and visualized the ROIs relationships using the Latent Space Item Response Model (LSIRM) [14]. This\nwas done by mapping unobserved interactions among regions onto the interaction map based on the latent distance\nregions, where the interactions among ROIs are quantiﬁed from the weight representation output of the self–attention\ndeep model. The LSIRM views binary item response data as bipartite network data that estimates the relationships\nbetween respondents(patients) and items(ROIs). This model measures the distances between the respondents(patients)\nand items(ROIs) as a penalty term in order to model the respondents’ probabilities of giving the correct (or positive)\nresponses. Here, the respondent–item distances represent their relations given the respective main effects. Since, we our\nclassiﬁcation result is regarded as continuous item response data, we adopted continuous version of LSIRM [15]. The\nbetween–regions distances indicate interactions in the network of interest, where shorter distances indicate stronger\nbetween–regions connections.\nThe LSIRM model can quantify closeness between ROIs by reﬂecting degrees of similarities. We were able to select\nthe signiﬁcant ROIs of each disease group that were unique to that particular group by using a statistical network model.\nThis way, were able to focus on a selected subset signiﬁcant ROIs to see what regions were important to focus on in the\norder to gain insight into understanding the different characteristics of the disease groups. The subsequent section will\ngo over our ﬁndings from our analytical framework in greater detail.\nWe sought to validate the feasibility of application of the proposed fusion deep learning analytics framework by\nclassifying resting state–fMRI (rs–fMRI) data for neurodegenerative diseases in different stages. There are different\nlevels of cognitive impairment, characterized by the severity brain function impairment. We used resting brain scans\nprovided by Alzheimer’s disease Neuroimaging Initiative (ADNI) database, a representative multisite longitudinal\nstudy that has been used in various studies [16] [17] for exploring biomarkers for AD diagnosis. Since over a thousand\npublications have used the ADNI data, it allows us to examine if the current methods in our work produce meaningful\nfeatures consistent with previous ﬁndings in addition to discovery of latent functional ROI groups.\nResults\nA novel analytical framework for determining the ROIs features that differentiate between diseases\nIn this study, we aim to model an approach that helps highlight an decipher the distinct ROIs that distinguishes two\ndifferent diseases, such as Alzheimer’s Disease (AD) vs. Mild Cognitive Impairment (MCI), AD vs. Early MCI (EMCI),\nAD vs. Late MCI (LMCI), and EMCI vs. LMCI. Our framework is shown in Fig. 1. Our method consists of three steps:\n(1) building a FCN using ﬁve different methods to represent community information, (2) developing a self–attention\nclassiﬁcation deep model for disease pairs, and (3) developing a network model for extracting meaningful features\nbased on attention–distribution.\nStep1: ROI connectivity network of diseases to ﬁgure out the interaction structure\nIn the ﬁrst step, we built a FCN among regions based on their rs–fMRI Blood–Oxygen–Level–Dependent (BOLD)\nsignals to ﬁgure out the correlated relationships between ROIs, which encompasses the unique characteristics of each\nparticular disease. We extracted the 116 rs-fMRI BOLD signals using automated anatomical labeling(AAL)-116\ntemplate [18]. Table 2 describes AAL-116 templates. Fig. 2 shows the ROIs, rs–fMRI BOLD signal and the resulting 5\nunique FCN graphs for sample LMCI patients (see Appendix A for the FCN graphs from other disease groups. First,\nsubﬁeld (a) of each ﬁgure represents the rs–fMRI BOLD signal for patients within the disease group showing much\nﬂuctuations within the majority of the ROI BOLD signals even during resting state as well as the intricacies of the\ninter–connectivity within these ROIs. Past research has used Pearson’s r or Fisher’s z values to generate FCN, which\nis shown in (b) and (c) of each ﬁgure. These correlation–based FCNs are intricately interconnected. It is difﬁcult to\nproperly comprehend the special attributes present in each area.\nIn order to decipher the relationship between the heavily interconnected brain regions, this study administered the brain\nregions into latent spaces in order to estimate the latent position between brain regions. Fig. 2 (d) shows the results of\nbrain region patterns embedded in 2 axes with the highest exploratory power. This was calculated by utilizing PCA\nwhich is based in linear space. This was done by distributing the ROIs in a euclidean space and evaluating how the ROIs\nare positioned within the latent space. The ﬁnal FCN based through PCA (linear space–based FCN) was constructed by\nusing the Mapper’s partial clustering method, which determines that ROIs are connected if they were clustered to the\nsame group. Fig. 2 (e) utilized the t–SNE(stochastic space–based FCN), which embedded the relationship between\nthe different brain regions into a latent space. This method assumes that the patterns between the brain regions are\na speciﬁc probability distribution and learns the degree of similarity between these different distributions. Fig. 2 (f)\n3\n\nZ1\nZ2\n0\nFigure 1: Illustration of the proposed approach Step 1: Construct Functional Connectivity Network(FCN;b) from\nresting state-fMRI BOLD signals (a) using ﬁve different methods: (1) Pearson’s r score, (2) Fisher’s z score, (3) PCA,\n(4) t-SNE, and (5) UMAP. Extract adjacency matrix(c) from FCN. Step 2: Implement binary classiﬁcation model(d)\nto two pairs of diseases based on adjacency matrix of each disease and extract attention distribution matrix from\nself-attention model(e). Export the attention distribution matrices of participants in each group(f) and select meaningful\nROIs(g). Step 3: Using the latent space item response model, estimate relationships between ROIs based on their latent\npositions(h) and summarize each disease group using meaningful ROIs that distinguish between the diseases(i).\n4\n\nused UMAP (topological space–based FCN) whose key beneﬁt to capture how topologically similar the waveforms\nof bold signals generated by the ROIs are. By assuming a variety of different latent spaces, we are able to view the\ncomplicated web of ROIs connectivity from multiple different perspectives, which enables us to understand the structure\nof ROIs characteristics. In this study, we used the aforementioned FCN generated in 5 different ways as the input for\nthe classiﬁcation model that classiﬁes the disease pairs in step 2.\nStep2: Binary Classiﬁcation model based on ROI connectivity network\nIf disease classiﬁcation done through each patient’s FCN is successful, the meaningful features of ROIs from FCN that\nwere utilized to determine this classiﬁcation can be said to be representing speciﬁc and distinct characteristics of the\ndisease. This study used the self–attention deep learning to carry out disease classiﬁcation through FCN where there\nexists dependency between data. This model trains the overall relationship between the different observations and their\nlocal relationship for each unique observation, which has the advantage of being able to learn the dependency structure\nof the data well. Furthermore, it is also possible to obtain the map of attention weights of the ROIs representing how the\nspeciﬁc patterns of FCN connectivity have contributed to successful classiﬁcation decisions.\nTable 1 shows the performance of the self–attention deep model. When compared the classiﬁcation performance to the\nrecent studies [19, 20] and the baseline models [21, 22, 23]) (i.e.,eXtreme Gradient Boosting, Multi Layer Perceptron,\nConvolutional Neural Networks), our method outperforms in all disease group pairs. Noticeably, the stochastic based\nand topological based FCN, representing the hidden connectivity among ROIs, yielded the highest accuracy among\ndisease group pairs reﬂecting the superiority of utilizing high dimensional dependency ROI structure.\nMethod\nAD/MCI\nEMCI/AD\nLMCI/AD\nEMCI/LMCI\n[19]\n0.8890\n-\n-\n-\n[20]\n-\n0.7920\n0.6520\n0.6090\nPEARSON+XGBoost\n0.7949\n0.8206\n0.8511\n0.7802\nFISHER+XGBoost\n0.7460\n0.6254\n0.6353\n0.6776\nPEARSON+MLP\n0.8132\n0.7600\n0.7809\n0.7457\nFISHER+MLP\n0.7835\n0.7533\n0.7900\n0.7605\nLINEAR+MLP\n0.7461\n0.7333\n0.7146\n0.7452\nSTOCHASTIC+MLP\n0.7659\n0.7600\n0.6427\n0.7381\nTOPOLOGICAL+MLP\n0.7819\n0.7067\n0.6518\n0.6838\nPEARSON+CNN\n0.8654\n0.7733\n0.7355\n0.7667\nFISHER+CNN\n0.8648\n0.7390\n0.7809\n0.7267\nLINEAR+CNN\n0.7747\n0.7586\n0.7891\n0.7600\nSTOCHASTIC+CNN\n0.8176\n0.7657\n0.7246\n0.8200\nTOPOLOGICAL+CNN\n0.8192\n0.7600\n0.7155\n0.7600\nPEARSON+Self–Attn\n0.8659\n0.8067\n0.8809\n0.8071\nFISHER+Self–Attn\n0.8813\n0.8133\n0.8718\n0.8152\nLINEAR+Self–Attn\n0.9022\n0.8467\n0.8627\n0.8624\nSTOCHASTIC+Self–Attn\n0.9033\n0.8867\n0.8900\n0.8971\nTOPOLOGICAL+Self–Attn\n0.9104\n0.8733\n0.9173\n0.8695\nTable 1: Table 1 shows the performance of our self–attention deep model. When compared to the baseline model,\nour method outperforms in all disease group pairs.(XGBoost: eXreme Gradient Boosting [21], MLP: Multi Layer\nPerceptron [22], CNN: Convolutional Neural Networks [23], Self–Attn: Self–Attention Deep Model, PEARSON: Pear-\nson’s r–based FCN, FISHER: Fisher’s z–based FCN, LINEAR: Linear space–based FCN, STOCHASTIC: Stochastic\nspace–based FCN, TOPOLOGICAL: Topological space–based FCN)\nThrough the self–attention deep model, we obtain the attention distribution Wp,(i,j)\n∈\nR4×116×116, p\n=\n{AD, MCI, EMCI, LMCI}, (i, j) = {1, · · · , 116}. From each pair of diseases, there are 116 number of attention\ndistribution matrix Wi,j ∈R116×116 that represent the relationship with 116 number of j ROIs. For example, in the p\ndisease group, if the i ROI attention distribution has a high value with the j ROI, we can infer that the i ROI and j ROI\nhave similar reaction patterns within the p disease group. Here, the sum of each row equals to one. Fig. 3 shows the\nattention distribution matrix of each pair of disease. In each attention distribution matrix, all values are consistently\naligned by row indicating that there are certain ROIs that have consistent associations with other ROIs. Through this\nrationale, we are able to assume that the columns that contain ROIs with the brighter values sufﬁciently represent the\nunique characteristics of each disease. Fig. 3 shows that for the most part, the ROI’s attention distribution network\ndoes not vary greatly (e.g., subtle differences in the color scheme) among the disease groups in question such as AD\nvs. MCI, AD vs. EMCI, AD vs. LMCI, and EMCI vs. LMCI. This phenomena occurs because the data from resting\n5\n\n(a) rs–fMRI BOLD signal\n(b) Pearson’s r–based FCN\n(c) Fisher’s z–based FCN\n(d) Linear space–based FCN\n(e) Stochastic space–based FCN\n(f) Topological space–based FCN\nFigure 2: Correlation coefﬁcient–based FCN and latent space–based FCN\n6\n\n#\nName\n#\nName\n#\nName\n#\nName\n1\nPrecentral_L\n30\nInsula_R\n59\nParietal_Sup_L\n88\nTemp_Pole_Mid_R\n2\nPrecentral_R\n31\nCingulum_Ant_L\n60\nParietal_Sup_R\n89\nTemporal_Inf_L\n3\nFrontal_Sup_L\n32\nCingulum_Ant_R\n61\nParietal_Inf_L\n90\nTemporal_Inf_R\n4\nFrontal_Sup_R\n33\nCingulum_Mid_L\n62\nParietal_Inf_R\n91\nCerebelm_Crus1_L\n5\nFrontal_Sup_Orb_L\n34\nCingulum_Mid_R\n63\nSupraMarginal_L\n92\nCerebelm_Crus1_R\n6\nFrontal_Sup_Orb_R\n35\nCingulum_Post_L\n64\nSupraMarginal_R\n93\nCerebelm_Crus2_L\n7\nFrontal_Mid_L\n36\nCingulum_Post_R\n65\nAngular_L\n94\nCerebelm_Crus2_R\n8\nFrontal_Mid_R\n37\nHippocampus_L\n66\nAngular_R\n95\nCerebelum_3_L\n9\nFrontal_Mid_Orb_L\n38\nHippocampus_R\n67\nPrecuneus_L\n96\nCerebelum_3_R\n10\nFrontal_Mid_Orb_R\n39\nParaHippo_L\n68\nPrecuneus_R\n97\nCerebelum_4_5_L\n11\nFrontal_Inf_Oper_L\n40\nParaHippo_R\n69\nParacentral_Lob_L\n98\nCerebelum_4_5_R\n12\nFrontal_Inf_Oper_R\n41\nAmygdala_L\n70\nParacentral_Lob_R\n99\nCerebelum_6_L\n13\nFrontal_Inf_Tri_L\n42\nAmygdala_R\n71\nCaudate_L\n100\nCerebelum_6_R\n14\nFrontal_Inf_Tri_R\n43\nCalcarine_L\n72\nCaudate_R\n101\nCerebelum_7_L\n15\nFrontal_Inf_Orb_L\n44\nCalcarine_R\n73\nPutamen_L\n102\nCerebelum_7_R\n16\nFrontal_Inf_Orb_R\n45\nCuneus_L\n74\nPutamen_R\n103\nCerebelum_8_L\n17\nRolandic_Oper_L\n46\nCuneus_R\n75\nPallidum_L\n104\nCerebelum_8_R\n18\nRolandic_Oper_R\n47\nLingual_L\n76\nPallidum_R\n105\nCerebelum_9_L\n19\nSupp_Motor_L\n48\nLingual_R\n77\nThalamus_L\n106\nCerebelum_9_R\n20\nSupp_Motor_R\n49\nOccipital_Sup_L\n78\nThalamus_R\n107\nCerebelum_10_L\n21\nOlfactory_L\n50\nOccipical_Sup_R\n79\nHeschl_L\n108\nCerebelum_10_R\n22\nOlfactory_R\n51\nOccipital_Mid_L\n80\nHeschl_R\n109\nVermis_1_2\n23\nFrontal_Sup_Med_L\n52\nOccipical_Mid_R\n81\nTemporal_Sup_L\n110\nVermis_3\n24\nFrontal_Sup_Med_R\n53\nOccipital_Inf_L\n82\nTemporal_Sup_R\n111\nVermis_4_5\n25\nFrontal_Mid_Orb_L\n54\nOccipital_Inf_R\n83\nTempl_Pole_Sup_L\n112\nVermis_6\n26\nFrontal_Mid_Orb_R\n55\nFusiform_L\n84\nTempl_Pole_Sup_R\n113\nVermis_7\n27\nRectus_L\n56\nFusiform_R\n85\nTemporal_Mid_L\n114\nVermis_8\n28\nRectus_R\n57\nPostcentral_L\n86\nTemporal_Mid_R\n115\nVermis_9\n29\nInsula_L\n58\nPostcentral_R\n87\nTempl_Pole_Mid_L\n116\nVermis_10\nTable 2: Automated Anatomical Labeling–116 template\nstate was rarely affected by external factors. Nonetheless, the group classiﬁcation performed yielded an average of 90%\nclassiﬁcation accuracy, demonstrating that the attention distribution network of each disease does indeed encompass\nsubtle differences. Thus, we are able to infer that there are ROIs in each of the disease groups that can be grouped\ntogether in similar patterns.\nFurthermore, based on the previously generated attention distribution, we extracted ROIs with large differences\nin distribution for each disease pair. Fig. 12 shows the regions with the greatest distribution differences for each\ndisease group. We used the Kullback–Leibler Divergence (KLD) method to quantify the difference between the two\ndistributions from each comparison pair. This was used in order to determine the distinctive ROIs with unique patterns\nthat distinguishes the two groups. The greater KLD value of the ROI, the greater the attention distribution difference\nbetween the different disease groups. We appended the other diseases’ groups of KLD values in the supplementary\nmaterials. Patients diagnosed with a high likelihood to develop AD showed signiﬁcantly smaller Thalamus (77,\n78) and Putamen (73, 74) volume, both which has been shown to have an effect on declining cognition in the AD\npopulation [24]. The top 3rd, 4th distinctive ROIs are Pallidum_R (76) and Pallidum_L (75). The 5th signiﬁcant\nROI is Hippocampus_R (38), for which both the volume and activation difference has been shown to be signiﬁcant in\nthe AD and MCI group [25, 26]. The 6th, 7th ROIs are Cerebelum_4_5_R (98), Cerebelum_4_5_L (97), which has\ngenerally been shown to be primarily related to sensorimotor control [27, 28]. Although the functional relevance of the\nCerebellum in AD is still in its infancy, it has been suggested to be related to structural and functional cerebellar changes\nand the topography of neurodegeneration [29]. There has also been research suggesting that AD and frontotemporal\ndementia are related to the distinct and circumscribed atrophy in the Cerebellum [30].\nWe then compared AD with both EMCI and LMCI. First, when comparing AD and EMCI, the top 1 and 6 regions were\nPutamen_R (74), Putamen_L (73) respectively, top 2 was Hippocampus_R (38), and top 3 and 7 were Pallidum_R (76),\nPallidum_L (75), respectively. Top–4,5 were Fusiform_R (56), Fusiform_L( 55), and it is known the Fusiform (55,\n56) is related to facial recognition [31]. Recent research has shown that EMCI patients show alteration in Fusiform\n7\n\n(55, 56) connectivity in the Middle occipital gyrus (52, 53) and Anterior cingulate (31, 32) [32]. When compared to\nAD and EMCI, the AD and LMCI disease pair group shows greater contrast differences in right Parahippocampal\ngyrus (40). The Parahippocampal gyrus (39, 40) is thought to be involved in the limbic system [33] as well as memory\nencoding and retrieval [34, 35, 36] showed that the Parahippocampal gyrus (39, 40) also plays a crucial role in the\nprogression of LMCI to AD. Lastly, we compared early MCI and late MCI. The region with the greatest distribution\ndifferences between EMCI and LMCI was Fusiform_L (55), a region that previous research has shown to have functional\nconnectivity differences between the two groups [37]. The region with the second most differences in distribution was\nright Middle frontal gyrus (8), which previous research has shown to exhibit a reduction in functional connectivity\nin LMCI compared to EMCI [38]. The top brain regions analyzed in the previous sections prove to be meaningful\nbiomarkers and are supported by previous research.\nDifferent patterns of ROIs from the attention–distribution\nWe then looked at regions that showed distribution differences for results based on the self–attention distribution\nclassiﬁcation model. In general, these ROIs were correlated based on location proximity and functional similarities\nrather than exhibiting individualized patterns. In order to decipher these types of dependent structures, this study\nutilized the attention distribution network generated from the classiﬁcation model to generate a region network for each\npatient. By doing so, we were able to observe which regions showed characteristics of each disease despite individual\ndifferences. Furthermore, we could compare the characteristics of the different disease groups through ROI network\nconnectivity.\nWe used the concept of LSIRM in this section to estimate the latent positions of nodes based on their connectivity.\nBecause the original LSIRM models binary data, we adjusted the continuous version of LSIRM to model continuous\nvalues. In order to separate these strongly correlated ROIs, we extracted the top 25% of the attention distribution matrix\ncolumns with the highest probability and highest coefﬁcient variation. Table 3 displays the top 29 unique ROIs that\nare highly correlated with a subset of brain regions. Using the network model, we aim to investigate how these top 29\nunique ROIs are located as latent variables that represent the connection with other unique ROIs among the different\ndisease pairs.\nTo process the network model, we constructed a matrix Mn,r, n = 1, · · · , Np, r = 1, · · · , 29 for each patient–ROIs.\nHere, Np indicates the number of patients from each disease group p = {AD, MCI, EMCI, LMCI}. Based on\nthis, we estimated the latent positions of these ROIs to identify the most commonly appeared as essential features\nin distinguishing the disease from the other diseases. We summarized the sub connectivity of ROIs and highlighted\nthe ROI nodes in Section . Through this network connectivity, we are able to study which ROIs are meaningful in\ndistinguishing between the different disease groups and also visualize the differences in functional clusters through\nstudying the sub connectivity of these ROIs.\nStep3: Summary of FCN Networks for each disease group using Network Model\nFig. 4 to 7 show the differences in disease network between the two groups. Blue indicates meaningful regions that\nshow different values from the attention distribution matrix when compared to the other disease groups. The orange, on\nthe other hand, indicates ROIs that were selected before analysis to be meaningful in both disease groups, but were\nshown to only be meaningful in one group post–analysis. Finally, green indicates regions that were meaningful in both\ndisease groups. According to results from the continuous analysis LSIRM [15] used in the current study, we were\nable to decipher structural relationships of ROIs and extract ROIs that were signiﬁcant in patients in all the disease\ngroups. In order to see the overall connectivity, we explored connectivity structures in ROIs that were ﬂagged to be\nsigniﬁcant in the disease network based on the FCN we established in Section . The higher saturation colors indicates\nhigh probability values that were assigned as meaningful features in all patient groups using LSIRM. Here, the ROI\nnodes which were not selected prior to LSIRM but are directly connected to the these ROIs were represented by the\nsame color with a lower brightness level.\nAD/MCI\nAccording to Fig. 4 (a), Cluster A is comprised of Cerebelum_7_L (101) and Cerebelum_8_L (103). These two\nregions did not show activity in MCI, and the majority of regions that reacted in AD were connected to the Cerebellum\nregions. This difference can be seen the AD group shows smaller grey matter volume in the cerebellar anterior lobe\ncompared to the non–AD group [39]. Cluster C with Hippocampus_R (38) and cluster D with Cingulum_Mid_L (33)\nand Cingulum_Mid_R (34) of Fig. 4 (a) show the cluster of regions and their direct connectivity that were more reactive\nin AD compared to MCI. Hippocampus_R (38) of cluster C showed greater reactivity in AD when compared to MCI\n8\n\n(a) AD (AD vs MCI)\n(b) MCI (AD vs MCI)\n(c) AD (AD vs EMCI)\n(d) EMCI (AD vs EMCI)\n(e) AD (AD vs LMCI)\n(f) LMCI (AD vs LMCI)\n(g) EMCI (EMCI vs LMCI)\n(h) LMCI (EMCI vs LMCI)\nFigure 3: Attention distribution matrix of each pair of disease\n9\n\nTop\nAD vs MCI\nAD vs EMCI\nAD\nMCI\nAD\nEMCI\nTop–1\nPostcentral_L\nCingulum_Mid_L\nFusiform_R\nFusiform_L\nTop–2\nPostcentral_R\nPostcentral_L\nCerebelum_6_L\nTemporal_Inf_L\nTop–3\nTemporal_Inf_L\nFusiform_R\nPallidum_R\nCingulum_Mid_L\nTop–4\nSupp_Motor_Area_R\nPrecentral_R\nPostcentral_L\nPallidum_R\nTop–5\nFusiform_L\nPallidum_L\nFusiform_L\nFusiform_R\nTop–6\nCingulum_Mid_L\nTemporal_Inf_L\nCerebelum_6_R\nFrontal_Inf_Orb_L\nTop–7\nFusiform_R\nFusiform_L\nHippocampus_R\nCerebelum_6_L\nTop–8\nCerebelum_8_R\nSupp_Motor_Area_R\nCingulum_Mid_L\nFrontal_Inf_Tri_R\nTop–9\nCerebelum_6_L\nInsula_L\nCerebelum_7b_L\nPutamen_R\nTop–10\nPutamen_L\nCerebelum_6_R\nPutamen_R\nCingulum_Mid_R\nTop–11\nCerebelum_8_L\nCerebelum_4_5_R\nCerebelum_4_5_L\nCerebelum_6_R\nTop–12\nPrecentral_R\nPostcentral_R\nTemporal_Inf_L\nTemporal_Inf_R\nTop–13\nThalamus_L\nCerebelum_4_5_L\nCingulum_Mid_R\nVermis_8\nTop–14\nTemporal_Mid_R\nCerebelum_6_L\nCerebelum_8_L\nInsula_L\nTop–15\nCerebelum_4_5_R\nPutamen_R\nHippocampus_L\nPallidum_L\nTop–16\nInsula_R\nCerebelum_8_R\nRolandic_Oper_R\nFrontal_Sup_R\nTop–17\nRolandic_Oper_R\nCerebelum_Crus2_R\nPallidum_L\nCerebelum_9_R\nTop–18\nPrecentral_L\nSupraMarginal_R\nCerebelum_Crus2_L\nTemporal_Sup_R\nTop–19\nTemporal_Inf_R\nRolandic_Oper_R\nCerebelum_7b_R\nPostcentral_L\nTop–20\nInsula_L\nHippocampus_R\nPutamen_L\nCerebelum_7b_L\nTop–21\nPutamen_R\nCingulum_Mid_R\nTemporal_Inf_R\nCerebelum_8_R\nTop–22\nCerebelum_7b_R\nPallidum_R\nInsula_L\nRolandic_Oper_L\nTop–23\nTemporal_Mid_L\nThalamus_L\nCerebelum_Crus2_R\nPutamen_L\nTop–24\nHippocampus_R\nPutamen_L\nRolandic_Oper_L\nRolandic_Oper_R\nTop–25\nCerebelum_4_5_L\nVermis_4_5\nCerebelum_8_R\nInsula_R\nTop–26\nCerebelum_10_R\nParacentral_Lobule_L\nCerebelum_3_L\nCerebelum_Crus2_L\nTop–27\nCingulum_Mid_R\nVermis_8\nFrontal_Inf_Tri_R\nCerebelum_3_L\nTop–28\nPallidum_L\nPrecentral_L\nFrontal_Sup_R\nFrontal_Inf_Tri_L\nTop–29\nCerebelum_7b_L\nSupp_Motor_Area_L\nLingual_R\nHippocampus_R\nTop\nAD vs LMCI\nEMCI vs LMCI\nAD\nLMCI\nEMCI\nEMCI\nTop–1\nPallidum_L\nCerebelum_8_L\nPutamen_L\nPutamen_L\nTop–2\nPutamen_L\nCerebelum_8_R\nPutamen_R\nFusiform_R\nTop–3\nCerebelum_8_L\nPallidum_R\nPallidum_R\nPallidum_L\nTop–4\nCerebelum_8_R\nPutamen_L\nPallidum_L\nPutamen_R\nTop–5\nPutamen_R\nPallidum_L\nTemporal_Inf_L\nHippocampus_R\nTop–6\nPallidum_R\nPutamen_R\nFusiform_L\nPallidum_R\nTop–7\nCerebelum_6_L\nHippocampus_R\nFusiform_R\nFusiform_L\nTop–8\nCerebelum_7b_R\nVermis_8\nTemporal_Inf_R\nHippocampus_L\nTop–9\nFusiform_L\nCerebelum_7b_L\nHippocampus_R\nTemporal_Inf_R\nTop–10\nInsula_R\nCerebelum_6_L\nInsula_L\nTemporal_Inf_L\nTop–11\nCerebelum_Crus2_R\nCerebelum_4_5_R\nOlfactory_R\nCingulum_Mid_R\nTop–12\nVermis_8\nFusiform_R\nRolandic_Oper_R\nThalamus_L\nTop–13\nVermis_7\nCingulum_Mid_R\nCerebelum_6_L\nCerebelum_6_L\nTop–14\nCerebelum_9_R\nVermis_6\nTemporal_Mid_R\nInsula_R\nTop–15\nLingual_R\nCerebelum_9_R\nInsula_R\nCerebelum_4_5_L\nTop–16\nCerebelum_6_R\nThalamus_L\nFrontal_Inf_Orb_R\nCerebelum_8_L\nTop–17\nHippocampus_R\nCerebelum_7b_R\nHippocampus_L\nOlfactory_R\nTop–18\nFusiform_R\nTemporal_Mid_R\nRolandic_Oper_L\nInsula_L\nTop–19\nCerebelum_4_5_R\nCerebelum_6_R\nCerebelum_7b_R\nCingulum_Mid_L\nTop–20\nCerebelum_9_L\nCerebelum_4_5_L\nCerebelum_7b_L\nCerebelum_6_R\nTop–21\nCerebelum_7b_L\nVermis_7\nCingulum_Mid_R\nRolandic_Oper_R\nTop–22\nInsula_L\nCerebelum_Crus2_R\nParaHippo_R\nPrecentral_L\nTop–23\nOlfactory_L\nInsula_L\nCerebelum_3_R\nParaHippo_R\nTop–24\nRolandic_Oper_L\nOlfactory_R\nThalamus_R\nCerebelum_4_5_R\nTop–25\nOlfactory_R\nRectus_L\nThalamus_L\nCerebelum_7b_R\nTop–26\nPrecuneus_L\nTemporal_Inf_R\nOlfactory_L\nThalamus_R\nTop–27\nCerebelum_Crus1_L\nTemporal_Mid_L\nCingulum_Mid_L\nParaHippo_L\nTop–28\nRolandic_Oper_R\nRolandic_Oper_L\nFrontal_Med_Orb_R\nTemporal_Mid_R\nTop–29\nThalamus_L\nLingual_R\nCerebelum_4_5_R\nAmygdala_L\nTable 3: This table displays the top 29 ROIs that show distribution differences between disease group pairs.\n10\n\nand Hippocampus (37, 38), ParaHippo (39, 40), Putamen (73, 74), Pallidum (75, 76), Amygdala (41, 42) are densely\npopulated in this area.\nCluster F of Fig. 4 (b) shows ROIs, Postcentral_L (57) and Postcentral_R (58), that were more reactive in MCI compared\nto AD. This Postcentral (57, 58) is directly connected to Cingulum_Mid (33, 34), Precentral (1, 2), Paracentral_Lob_L\n(69).\nCluster B of Fig. 4 (a) and Cluster E of Fig. 4 (b) corresponds to Cerebelum 4_5_R (98) that reacted to both AD and\nMCI. Both results show that Cerebelum 4_5_R (98) is not only connected with other Cerebellum regions, but is also\ndirectly connected to Fusiform_L (55) and Fusiform_R (56), regions that are related to facial recognition.\nAD/EMCI\nCluster A and B of Fig. 5 (a), which are Hippocampus_L (37), Lingual_R (48), Cerebelum_4_5_L (97), were found to\nbe meaningful regions not in EMCI but only in AD. Hippocampus (37, 38) in both hemispheres are directly connected.\nThese regions are also directly connected to ParaHippo (39, 40), Putamen (73, 74), Pallidum (75, 76), Amygdala (41,\n42) and the results are similar to the results described in Section . Fusiform_R (56)and Cerebelum_8_L (103) are\ndirectly connected to Hippocampus_R (38), and are similar to cluster A and B of Fig. 4 (a). Hippocampus_L (37) and\nLingual_R (48) are not only directly connected to Lingual_L (47), but also to Calcarine (43, 44), Cuneus (45, 46),\nFusiform_L (56) and Cerebelum_6_L (99). Cluster D and E of Fig. 5 (a) were more active in AD relative to EMCI and\nincluded the Hippocampus_R (38), Rolandic_Oper_R (18) regions. We are able to see that Rolandic_Oper_R (18) is\ndirectly connected to Putamen (73, 74), Pallidum (75, 76) and Heschl_L (79).\nCluster F of Fig. 5 (b) was active in EMCI but not AD, and Cerebelum_9_R (106) was analyzed. This region was\nadjacent to Cerebelum_Crus2_R (94), Cerebelum_7b_R (102) and Cerebelum_9_L (105). Cluster H, I and J of Fig. 5\n(b) are regions that were more active in EMCI relative to AD, and regions Cingulum_Mid_L (33), Cingulum_Mid_R\n(34), Pallidum_L (75) and Cerebelum_Crus2_L (93) were analyzed. Cingulum_Mid is directly connected to Precentral\n(1, 2), Supp_Motor (19, 20), Postcentral (57, 58) and SupraMarginal (63, 64).\nCluster C of Fig. 5 (a) and cluster G of (b) are regions that were active in both AD and EMCI, and corresponds\nto Fusiform_L (55) and Fusiform_R (56). Fusiform (55, 56) is directly connected with Hippocampus (37, 38) and\nParaHippo (39, 40).\nAD/LMCI\nCluster A of Fig. 6 (a) was active in AD but not LMCI, and Temporal_Mid_R(86) was analyzed. Cluster B of Fig. 6 (a)\nreacted more in AD relative to LMCI, and Cerebelum_6_L (99) was analyzed. Not only is this region connected with\nmultiple Cerebelum (91, 92, 100) areas, but is also connected to Fusiform_L (55), Lingual (47, 48), multiple Vermis\n(112, 113, 114).\nCluster C of Fig. 6 (b) was active only in LMCI and not AD, and Rolandic_Oper_R (18) was analyzed. This region was\nconnected with Heschl (79, 80), Insula (29, 30) and Temporal_Sup (81, 82). Cluster D, E, and F of Fig. 6 (b) are regions\nmore active in LMCI relative to AD, and regions Putamen_L (73), Cerebelum_4_5_R (98) and Vermis_8 (114) were\nanalyzed. Putamen (73, 74) is connected to Olfactory (21, 22), Hippocampus (37, 38), Amygdala (41, 42), Pallidum\n(75, 76) and Thalamus_L (77).\nEMCI/LMCI\nCluster A, B, and C of Fig. 7 (a) were regions that were only active in EMCI, and Frontal_Inf_Orb_R (16),\nFrontal_Med_Orb_R (26), and Cerebelum_3_R (96) were analyzed. Cerebelum_3_R (96) is directly connected\nto Cerebelum_3_L (95) and Vermis_3 (110). ROIs that are connected to Frontal_Inf_Orb (15, 16) and Frontal_Inf_Tri\n(13, 14), can be grouped as Frontal regions. We can also see that they are directly connected to Putamen_R (74). The\nFrontal_Med_Orb_R (26) is directly connected to Frontal_Med_Orb_L (25), Rectus (27, 28), and Frontal_Sup_Orb_R\n(6). Cluster D are regions that were more active in EMCI relative to LMCI, and include Putamen_L (73), Pallidum_L\n(75) regions. The ROIs that were primarily connected to these regions can largely be deﬁned as Caudate (71, 72), Pal-\nlidum_R (76), Thalamus (77, 78), Hippocampus (37, 38), and Insula (29, 30). Other regions include Rolandic_Oper_L\n(17), Amygdala_R (42), Fusiform_L (55), and Cerebelum_8_L (103).\nFig. 7 (b), on the other hand, shows the FCN extracted for LMCI, which shows no signiﬁcant ROIs that were signiﬁcantly\nactive only in LMCI. There is, however, cluster E, that shows ROIs more active in LMCI relative to EMCI. This\ncluster is comprised of ROIs connected to Temporal_Mid_R(86) and Cerebelum_6_L (99). Temporal_Mid_L (85) and\nTemporal_lnf_R(90) are ROIs connected with Temporal_Mid_R (86). ROIs connected with Cerebelum_6_L (99) are\n11\n\nA\nB\nC\nD\nB\nC\nA\nD\n(93) Cerebelum_Crus2_L\n(94) Cerebelum_Curs2_R\n(101) Cerebelum_7b_L\n(102) Cerebelum_7b_R\n(103) Cerebelum_8_L\n(104) Cerebelum_8_R\n(105) Cerebelum_9_L\n(106) Cerebelum_9_R\n(107) Cerebelum_10_L\n(108) Cerebelum_10_R\n(114) Vermis_8\n(40) ParaHippo_R\n(56) Fusiform_R\n(95) Cerebelum_3_L\n(96) Cerebelum_3_R\n(97) Cerebelum_4_5_L\n(98) Cerebelum_4_5_R\n(100) Cerebelum_6_R\n(110) Vermis_3\n(111) Vermis_4_5\n(37) Hippocampus_L\n(38) Hippocampus_R\n(39) ParaHippo_L\n(42) Amygdala_L\n(73) Putamen_L\n(74) Putamen_R\n(75) Pallidum L\n(20) Supp_Motor_Area_L\n(31) Cingulum_Ant_L\n(32) Cingulum_Ant_R\n(33) Cingulum_Mid_L\n(34) Cingulum_Mid_R\n(58) Post_Central_R\n(a) AD\nE\nF\nF\nE\n(56) Fusiform_R\n(55) Fusiform_L\n(95) Cerebelum_3_L\n(96) Cerebelum_3_R\n(97) Cerebelum_4_5_L\n(98) Cerebelum_4_5_R\n(100) Cerebelum_6_R\n(110) Vermis_3\n(111) Vermis_4_5\n(1) Precentral_L\n(2) Precentral_R\n(18) Rolandic_Oper_R\n(33) Cingulum_Mid_L\n(34) Cingulum_Mid_R\n(57) Postcentral_L\n(58) Postcentral_R\n(64) SupraMarginal_L\n(69) Paracentral_Lob_L\n(b) MCI\nFigure 4: Network Summary in AD vs MCI\n12\n\nA\nC\nE\nA\nC\nD\nE\nD\nB\nB\n(43) Calcarine_L\n(44) Calcarine_R\n(45) Cuneus_L\n(46) Cuneus_R\n(47) Lingual_L\n(48) Lingual_R\n(95) Cerebelum_3_L\n(97) Cerebelum_4_5_L\n(98) Cerebelum_4_5_R\n(99) Cerebelum_6_L\n(111) Vermis_4_5\n(53) Occipital_Inf_L\n(55) Fusiform_L\n(56) Fusiform_R\n(85) Temporal_Mid_L\n(89) Temporal_Inf_L\n(90) Temporal_Inf_R\n(93) Cerebelm_Crus2_L\n(100) Cerebelum_6_R\n(101) Cerebelum_7b_L\n(103) Cerebelum_8_L\n(104) Cerebelum_8_R\n(37) Hippocampus_L\n(39) ParaHippo_L\n(40) ParaHippo_R\n(73) Putamen_L\n(74) Putamen_R\n(76) Pallidum_R\n(86) Temporal_Mid_R\n(38) Hippocampus_R\n(42) Amygdala_R\n(75) Pallidum_L\n(17) Rolandic_Oper_L\n(18) Rolandic_Oper_R\n(29) Insula_L\n(30) Insula_R\n(79) Heschl_L\n(81) Temporal_Sup_L\n(82) Temporal_Sup_R\n(a) AD\nF\nF\nG\nG\nH\nI\nJ\nI\nJ\nH\n(37) Hippocampus_L\n(38) Hippocampus_R\n(40) ParaHippo_R\n(48) Lingual_R\n(53) Occipital_Inf_L\n(55) Fusiform_L\n(56) Fusiform_R\n(73) Putamen_L\n(76) Pallidum_R\n(86) Temporal_Mid_R\n(89) Temporal_Inf_L\n(90) Temporal_Inf_R\n(97) Cerebelum_4_5_L\n(98) Cerebelum_4_5_R\n(99) Cerebelum_6_L\n(100) Cerebelum_6_R\n(106) Cerebelum_9_R\n(114) Vermis_8\n(115) Vermis_9\n(21) Olfactory_L\n(22) Olfactory_R\n(42) Amygdala_R\n(71) Caudate_L\n(72) Caudate_R\n(74) Putamen_R\n(75) Pallidum_L\n(77) Thalamus_L\n(78) Thalamus_R\n(91) Cerebelm_Crus1_L\n(92) Cerebelm_Crus1_R\n(93) Cerebelm_Crus2_L\n(94) Cerebelm_Crus2_R\n(101) Cerebelum_7b_L\n(102) Cerebelum_7b_R\n(103) Cerebelum_8_L\n(104) Cerebelum_8_R\n(105) Cerebelum_9_L\n(1) Precentral_L\n(2) Precentral_R\n(18) Rolandic_Oper_R\n(19) Supp_Motor_L\n(20) Supp_Motor_R\n(31) Cingulum_Ant_L\n(32) Cingulum_Ant_R\n(33) Cingulum_Mid_L\n(34) Cingulum_Mid_R\n(57) Postcentral_L\n(58) Postcentral_R\n(63) SupraMarginal_L\n(64) SupraMarginal_R\n(b) EMCI\nFigure 5: Network Summary in AD vs EMCI\n13\n\nA\nA\nB\nB\n(85) Termporal_Mid_L\n(86) Termporal_Mid_R\n(90) Termporal_Inf_R\n(47) Lingual_L\n(48) Lingual_R\n(55) Fusiform_L\n(91) Cerebelm_Crus1_L\n(92) Cerebelm_Crus1_R\n(97) Cerebelum_4_5_L\n(99) Cerebelum_6_L\n(100) Cerebelum_6_R\n(112) Vermis_6\n(113) Vermis_7\n(114) Vermis_8\n(a) AD\nC\nD\nC\nE\nF\nF\nE\nD\n(17) Rolandic_Oper_L\n(18) Rolandic_Oper_R\n(29) Insula_L\n(30) Insula_R\n(79) Heschl_L\n(81) Temporal_Sup_L\n(82) Temporal_Sup_R\n(21) Olfactory_L\n(22) Olfactory_R\n(37) Hippocampus_L\n(38) Hippocampus_R\n(40) ParaHippo_R\n(41) Amygdala_L\n(42) Amygdala_R\n(73) Putamen_L\n(74) Putamen_R\n(75) Pallidum_L\n(76) Pallidum_R\n(77) Thalamus_L\n(56) Fusiform_R\n(96) Cerebelum_3_R\n(97) Cerebelum_4_5_L\n(98) Cerebelum_4_5_R\n(100) Cerebelum_6_R\n(101) Cerebelum_7b_L\n(105) Cerebelum_9_L\n(106) Cerebelum_9_R\n(110) Vermis_3\n(113) Vermis_7\n(114) Vermis_8\n(b) LMCI\nFigure 6: Network Summary in AD vs LMCI\n14\n\nlargely Fusiform (55, 56), Lingual (47, 48), and multiple Vermis (112, 113). Other regions include Cerebelum_Crus1_L\n(91), Cerebelum_4_5_L (97), and Cerebelum_6_R (100).\nDiscussion\nIn this paper, we provide a unique analytical methodology for determining the network structure of different disease\ngroups. To summarize, we ﬁrst built the FCN, which depicted the associated connections between the ROIs. It aids\nin the summarization of overall structure by projecting complicated data into a low–dimensional structure in order\nto demonstrate the relationships between ROI functions. We built the FCN on the basis of these relationships. By\nemploying each patient’s FCN, we estimated the ROI distribution using the classiﬁcation model of the self–attention\ndeep learning. By taking into account the correlated complex structure, our method takes advantage of capturing the\nROIs signal patterns without losing information. Through our new model, classiﬁcation accuracy between two different\ndisease groups can be increased greatly. Therefore, the output of ROIs distributions is validated to reveal the hidden\ntraits that distinguishes between the different disease groups.\nDespite the fact that the self–attention model validates FCN from each patient and outputs the ROIs attention distribution\nof each patient, we still need to determine the overall signiﬁcant ROIs among patients who represent each cognitive\ndisease group. To extract meaningful ROIs from the ROIs distribution, we used the latent space item response network\nmodel that can extract the important ROIs by considering the interactions among ROIs from each patient. Section shows\nthe result of meaningful clusters based on the ROIs extracted from the network model. These clusters denote connection\nsubgroups, each of which is formed of the network model’s most important ROI functions and their ﬁrst direct\nconnections in FCN. This enables a more in–depth understanding of the peculiarities of different illnesses by evaluating\nROIs dependence structure.\nOur method also revealed signiﬁcant biological ﬁndings, which have been steadily veriﬁed through several studies.\nTherefore, these convincing ﬁndings validates our method to determining the features of cognitive diseases in a more\nintuitive manner by examining ROI connectivity. Here, not only did our research provide comparable results to prior\nextensive works, but it also identiﬁed that the Cerebellum is a growing function that has lately been researched for\ncognitive impairment.\nFirst, when comparing AD to MCI, we discovered that the Hippocampus (37, 38) plays an important role in expressing\nAD characteristics (Fig. 4(a) Cluster C). Many studies have shown that having Hippocampus (37, 38) dysfunction\naffects memory [40, 41, 42]. Based on our approach, We also discovered connections between Hippocampus (37, 38)\nand Putamen (73, 74) and ParaHippo (39, 40), which have been linked to cognitive impairment in Alzheimer’s disease\n[43, 44, 24]. When compared to EMCI, the biomarkers in AD may be clearly revealed (Fig. 5 (a)). These biomarkers\nare detected in connections between Hippocampus (37, 38) and ParaHippo (39, 40), Putamen (73, 74), Pallidum (75,\n76), and Amgydala (41, 42) [45, 46, 47].\nSecond, our method provides additional information about Cingulum_Mid (33, 34) towards MCI, which is solely\nregarded as one of the most important ROI in AD [48, 49, 50, 51, 52]. Cingulum_Mid (33, 34) is responsible for\nprocessing motor and attention–related activities [53]. However, our method discovered that Cingulum_Mid (33,\n34) is more prominent in MCI and EMCI than in AD (Fig. 4 (a), Fig. 4 (b), Fig. 5 (b)). According to our ﬁndings,\nCingulum_Mid (33, 34) is linked to the Postcentral (57, 58), Precentral (1, 2), and Paracentral_Lob (69, 70), all of which\nare known to process motor information. The ﬂuorodeoxyglucose(FDG) positron emission tomography(PET) modality\nhas been used to investigate all four of the above–mentioned areas as relevant indicators in MCI [54]. Furthermore,\nthe overall fractional anisotropy value of Cingulum_Mid (33, 34) in MCI differs from that of other cognitive illness\ngroups [53]. In the network of EMCI compared to AD, our model found that Cingulum_Mid (33, 34) is linked to\nSupramarginal (63, 64), which is associated to motor attention–related activity (Fig. 5 (b)). These linkages have lately\nbeen examined in relation to planning and cognitive control processing [55, 56]. As a result, Cingulum_Mid (33, 34),\nwhich has previously gone unnoticed, should be regarded a cognitive as well as a motor function in MCI and EMCI.\nThird, Fusiform (55, 56) is the ROI that is important in revealing the characteristics of both AD and MCI. Fusiform\n(55, 56) is known for processing facial recognition [31]. Recently, Fusiform (55, 56) has been studied for revealing the\ngenetic and epigenetic basis of AD [57]. Our method showed that Fusiform (55, 56) is both widely reacted as signiﬁcant\nROI of AD and EMCI (Fig. 5 (a), (b)) and Fusiform (55, 56) is connected to Cerebellum functions. This connection\nshows consistency in all network results (Fig. 4– 6). According to the global hub node centrality analysis [58], Fusiform\n(55, 56) and Cerebellum regions play important roles in constituting the key makeup of disease characteristics of MCI.\nAs such, we are able to observe through our model that Fusiform (55, 56) and Cerebellum regions, which play key roles\nin both MCI and AD, are greatly related to one another.\n15\n\nA\nD\nB\nA\nB\nC\nC\nD\n(6) Frontal_Sup_Orb_R\n(10) Frontal_Mid_Orb_R\n(13) Frontal_Inf_Tri_L\n(14) Frontal_Inf_Tri_R\n(15) Frontal_Inf_Orb_L\n(16) Frontal_Inf_Orb_R\n(25) Frontal_Mid_Orb_L\n(26) Frontal_Mid_Orb_R\n(27) Rectus_L\n(28) Rectus_R\n(74) Putamen_R\n(17) Rolandic_Oper_L\n(21) Olfactory_L\n(22) Olfactory_R\n(29) Insula_L\n(30) Insula_R\n(37) Hippocampus_L\n(38) Hippocampus_R\n(42) Amygdala_L\n(55) Fusiform_L\n(71) Caudate_L\n(72) Caudate_R\n(73) Putamen_L\n(75) Pallidum_L\n(76) Pallidum_R\n(77) Thalamus_L\n(78) Thalamus_R\n(89) Temporal_Inf_L\n(103) Cerebelum_8_L\n(95) Cerebelum_3_L\n(96) Cerebelum_3_R\n(110) Vermis_3\n(a) EMCI\nE\nE\n(47) Lingual_L\n(48) Lingual_R\n(53) Occipital_Inf_L\n(55) Fusiform_L\n(56) Fusiform_R\n(85) Temporal_Mid_L\n(86) Temporal_Mid_R\n(90) Temporal_Inf_R\n(91) Cerebelm_Crus1_L\n(97) Cerebelum_4_5_L\n(99) Cerebelum_6_L\n(100) Cerebelum_6_R\n(112) Vermis_6\n(113) Vermis_7\n(b) LMCI\nFigure 7: Network Summary in EMCI vs LMCI\n16\n\nLast but not least, our methodology determined that the Cerebellum is a signiﬁcant ROI function in investigating\nAD. Originally, the Cerebellum was thought to have a required function for exercise and activity [59, 60]. There\nhave been several research that the Cerebellum is related to processing cognitive function [61, 62, 63] and emotional\nmodulation [64]. Recently, the Cerebellum has been assigned as useful biomarkers in clinical AD patients [65].\nAccording to our result, Cerebelum_4_5_R (98) has a signiﬁcant ROI function in both AD and MCI(Fig. 4 (a), (b)).\nThis ﬁnding is consistent with a research that investigated at spatial patterns of brain activity and found that both AD\nand MCI had decreased activity in Cerebelum_4_5_R (98) compared to the control group [66]. However, in terms of\nCerebellum_8_L (103), we discovered that this ROI function exhibited higher response in AD compared to MCI(Fig. 4\n(a)), resulting in the same ﬁnding in global brain connectivity (GBC) research [67]. The preceding results suggest that\nCerebellum should be considered in both AD and MCI.\nMethods\nfMRI Data\nIn this study, we utilized resting-state fMRI (rs–fMRI) data collected from Alzheimer disease (AD), early mild cognitive\nimpairment (EMCI), mild cognitive impairment (MCI), late mild cognitive impairment (LMCI), and control groups\nfrom Alzheimer’s disease neuroimaging initiative (ADNI) dataset. The ADNI dataset is composed of four consecutive\ncohorts (ADNI1, ADNI2, ADNI–GO, and ADNI3). Participants were recruited for initial periods in the ADNI1 cohorts\n(October 2004). Follow–up of participants were recruited to the ADNI3 cohort period. To facilitate preprocessing of the\nfMRI data, we ﬁltered data with the same acquisition protocols as the database. A total of three protocol conditions\n(200 timepoints, TR = 3000 ms, 48 slices) were applied for selection. After ﬁltering based on three conditions, a total\nof 552 participants remained in the ADNI2, ADNI-go, and ADNI3 cohorts. The ADNI1 cohort was excluded because\nit did not contain data that met the aforementioned conditions. As a result, we used axial rs-fMRI data from 57 AD\npatients, 93 EMCI patients, 53 LMCI patients, 78 MCI patients, and 272 control participants.\nMRI Acquisition\nThe participants included in this study participated in scanning at diverse sites through 3T MRI scanners manufactured\nby Philips Medical Systems or Siemens Healthineers. The detailed MRI protocols of the ADNI dataset were reported in\nthe webpage (http://adni.loni.usc.edu/methods/mri-tool/mri-acquisition/). In the ADNI2 and ADNI-go cohorts, MRI\nscanning was performed at twenty-six different sites with Philips 3T MRI scanners, using synchronized scanning\nparameters. In the case of the ADNI3 cohort, Siemens 3T MRI scanners were used to collect fMRI data with\nsynchronized parameters.\nMRI Preprocessing\nAll scanned imaging data included in the ADNI database was checked for their quality by trained analysts. Two levels\nof quality control were performed. First, consistency of protocol parameters was investigated. Second, series-speciﬁc\nquality such as body motion, anatomic coverage, and other artifacts were checked. After conducting two levels of quality\ncontrol, each image was classiﬁed as four quality labels (1 to 3: acceptable and 4: unusable). We preprocessed rs–fMRI\ndata whose quality was acceptable for our research. To extract region of interest (ROI) time courses from rs–fMRI\ndata, SPM12 (www.ﬁl.ion.ucl.ac.uk/spm/) and DPARSFA toolbox (V5.1, http://rfmri.org/dpabi) was applied. The\ndefault preprocessing pipeline for ROI time courses extraction was used, including slice-time correction, realignment,\nnormalization with Echo Planar Imaging(EPI) template, detrending, and smoothing with 6mm kernel. Temporal ﬁltering\nwith a range from 0.01Hz to 0.1Hz was performed to remove physiological noises. After preprocessing, we obtained\ntemporal signals, correlation coefﬁcient, and Fisher’s Z–transformed correlation coefﬁcients.\nDimension Reduction\nTo deﬁne functional connectivity, we ﬁrst need to map ROIs latent locations into R2 space using dimension reduction.\nSince we were interested in the connectivity of ROIs from each patient, we reduced signal data of ROIs into ROIs\nwith two coordinates by training their signal pattern similarity among ROIs. We began by embedding the ROIs\ntime series data on R2 space using three dimension reduction methods: (1) Principal Component Analysis (PCA),\nt–Stochastic Neighbor Embedding (t–SNE), and Uniform Manifold Approximation and Projection (UMAP). However,\nsince dimension methods only return the latent position of ROIs, it is crucial to deﬁne connections between ROIs using\ntheir latent position on R2 space. To accomplish this, we used TDA’s mapper [9] to implement partial clustering, which\nwe then used to deﬁne connections. If some ROIs are assigned to the same cluster, those ROIs are assumed to be\n17\n\nconnected to one another. Similarly, we can apply this concept to other partial clusters that deﬁne connections from\nlocal to global connections at the end. As a result, we could construct the FCN of each patient.\nPrincipal component analysis (PCA)\nPCA is a technique that uses orthogonal transformation to reduce high-dimensional data to low-dimensional data.\nIt converts high-dimensional space samples that are likely to be related to each other into low-dimensional space\nsamples (main components) that are not linearly related. The axis with the most signiﬁcant variance is the ﬁrst principal\ncomponent, and the second greatest variance is the second principal component. This decomposition divides the sample\ninto the components that best represent the differences of information that have important implications for data analysis.\nt-Stochastic Neighbor Embedding (t–SNE)\nt–SNE is a non-linear dimension reduction method that aids in understanding the data with impact information. It is\nbased on t-distribution, which is comparable to normal distribution but has the heavy–tail component that is helpful in\ncovering up the far distribution element of high dimensional data. When two data construct similar structures, they\nnearly correspond to each other based on the similarity value from the t-distribution. The t–SNE results depict the\nembedded points whose distances, trained by calculating the points’ resemblance in structure. reﬂect their degree of\nsimilarity.\nUniform Manifold Approximation and Projection (UMAP)\nUMAP is a nonlinear dimension reduction method that models the manifold using a topological structure. Because it is\nbased on topological space, the embedding points are close in proximity if the two data points have similar topological\nfeatures. It ﬁrst reorganizes the data into a fuzzy simplicial complex, which then produces the connections based\non the hyper-parameter that controls the connectivity around the data. Then, it projects the connected data into a\nlow-dimensional space based on their connection, where the connection indicates the aforementioned close proximity.\nMapper\nThe mapper can achieve the complexity of the topological space by combining and calculating simple values such as\npoints, lines, triangles, etc. There are two main steps for this process. First, high-dimensional topological space data is\ntransferred into a measure space such as a real space represented as a graph. This function could be any real function\nthat reﬂects the characteristics of the data. In the next step, the graph is split into countable subsets of data, and is then\nclustered within subsets. This process is implemented to explore the interrelationships between the subsets, which will\nidentify the structural relationships within the data. Each cluster becomes a node, and each node is connected to other\nnodes when they share the same data attributes. The network generated based on these nodes and connections enables\nthe topological structure of high-dimensional data to be expressed in a k−simplex.\nPartial Clustering\nPartial clustering employs any standard clustering algorithm towards subsets of the original data set and then analyzes\nthe interactions between the sub–clusters formed in this manner. If U and V are non–empty subsets of the data set, then\nthe sub–clusters formed by each U and V may have non-empty intersections, which are used to construct a simplicial\ncomplex. These sub-clusters are referred to as vertices or nodes, and the non–empty intersection between clusters is\nreferred to as an edge. This process results in a simple complex of dots, lines, and triangles that can be used to infer the\ntopological structure of high-dimensional data.\nSelf–Attention Deep Model (Self–Attn)\nAttention Mechanism is used to focus on speciﬁc input values from sequence-based tasks that is most relevant to the\ninput in order to reduce information loss and increase information power [13]. Basically, our self–attention mechanism\ntakes into account the temporal context of the spatially embedded representations and assigns relatively higher weights\nto time points at which the corresponding representations carry informative features for a target task. Here, the\ninformativeness is determined adaptively with the learnable parameters in combination with other objectives.\nThe inputs here are the encoding values of the adjacency matrix among ROIs calculated from the FCN generated in\nthis study. Thus, each input has query, key, value vector values. If we assume there are a total R number of ROIs, we\ncan express that Qr ∈Rd, Kr ∈Rd and Vr ∈Rd where r = 1, · · · , R. Based on these features, the output of the\n18\n\nattention layer output is as follows:\nYROIr =\nR\nX\nj=1\n(Softmax(QrK⊤\nj )Vj),\n(1)\nwhere r, j = 1, · · · , R. Therefore, the ﬁnal YROIr is not simply a vector with ROIr information but a ROIr vector that\nreﬂects information about ROI connectivity. If we collect these vectors and compute them as a matrix, we are able to\ngenerate a self–attention matrix about ROIs. By multiprocessing Self–attention like those mentioned above, we utilized\nmulti–head self–attention that jointly learns information about different location interactions. This study applied a total\nof 128 parallel self–attention and used 116 ROIs. The learning process was a 10–fold cross validation, batch size of 8,\nAdam [68] optimizer, learning rate of 0.01 and utilizing the cross entropy loss.\nLatent Space Item Response Model (LSIRM)\nLSIRM [14] is the model that regards item response structure dataset as a bipartite network and estimates the interaction\nbetween items and respondents. We set our goals to estimate the latent positions of ROI functions based on the\ninteraction among patients. Since the original LSIRM is designed for item response dataset where each cell value is 0\nor 1. However, we applies LSIRM to ROI–patient dataset where each cell value is continuous. Therefore, we adopt\ncontinuous version of LSIRM [15] to estimate the latent positions of ROI. Equation (2) shows the continuous version of\nLSIRM:\nP(yji | Θ) ∼Normal(θj + βi −||uj −vi||, σ2).\n(2)\nwhere, yji is probability of patient i reacts on ROI j. Each Θ represents {θ = {θj}, β = {βi}, U = {uj}, V = {vi}}\nand ||uj −vi|| represents the Euclidean distance between patient i and ROI j. LSRM consists of two parts; an attribute\npart and an interaction part. In attribute part, there are two parameters, θj ∈R and βi ∈R, where βi and θj represents\nthat how many patients i reacts on ROI j. If the value of βi is large then many ROI from patient i react and the value of\nθj is large it represents many patient react on j ROI. In an interaction part, there are latent conﬁguration of patient i and\nROI j, uj and vi. With this latent positions, we can catch interactions between patient i and ROI j and visualize them\nin a Euclidean space. The shorter the distance between uj and vi, the greater the probability that patient i reacts on ROI\ni. Additionally, if latent position for patient i and k, uj and uk, are close ,then the patient i and k have similar reaction\npattern.\nTo estimate parameters in LSIRM, we use Bayesian inference. We specify prior distribution for the parameters:\nβi|τ 2\nβ ∼N(0, τ 2\nβ),\nτ 2\nβ > 0\nθj|σ2 ∼N(0, σ2\nθ),\nσ2 > 0\nσ2 ∼Inv-Gamma(a, b),\na>0,\nb > 0\nσ2\nθ ∼Inv-Gamma(aσ, bσ),\naσ > 0,\nbσ > 0\nuj ∼MVNd(0, Id)\nvi ∼MVNd(0, Id).\n(3)\nwhere 0 is a d–vector of zeros and Idis the d × d identify matrix. The posterior distribution of LSRM is proportional to\nπ(Θ, σ2 | Y) ∝\nY\nj\nY\ni\nP (yji | Θ)yji (1 −P (yji | Θ))1−yji\n×\nY\nj\nπ(θj | σ2\nθ)π(σ2\nθ)\nY\ni\nπ(βi)\n×\nY\nj\nπ(uj)\nY\ni\nπ(vi)π(σ2)\n(4)\nTherefore, we could obtain latent positions of ROI uj which represents the reactions pattern from patients. Since our\nmain interest is to compare the different patterns of ROI from different disease group, we extract the latent positions of\nROI uj from each disease group and compare the difference among ROI by mapping on euclidean space R2.\n19\n\nMetrics\nKullback–Leibler Divergence (KLD)\nThe KLD that measures the similarity between the two distributions q(θ) and π(θ | D) which is\nKLD\n\u0010\nq(θ) || π(θ | D)\n\u0011\n=\nZ\nq(θ) log\nq(θ)\nπ(θ | D)dθ\n=\nZ\nq(θ) log q(θ)dθ −\nZ\nq(θ) log π(θ, D)dθ + log π(D)\n= −(Eq[log(π(θ, D))] −Eq[log q(θ)]) + log π(D),\n(5)\nwhere θ is the parameter and D is the data set. Since log π(D) is not a function of model parameters, minimising the\nKLD is equivalent to maximizing Eq[log(π(θ, D))] −Eq[log q(θ)], the evidence lower bound (ELBO).\nCoefﬁcient of Variation(CV)\nThe CV is calculated by dividing the standard deviation by the mean. It is used to compare data with different\nmeasurement units. In other words, the variance is affected by the scale. Therefore, the scale is normalized by dividing\nthe mean. The greater the relative difference, the greater the value of the coefﬁcient of variation.\nAcknowledgements\nThis research was supported in part by the Brain Research Program through the National Research Foundation of\nKorea(NRF) funded by the Ministry of Science and ICT (2017M3C7A1029485) and in part by the National Research\nFoundation of Korea (NRF) Grant through the Korea Government [Ministry of Science and ICT (MSIT)] under Grant\n2019R1A2C1007399.\nReferences\n[1] Dong Wen, Zhenhao Wei, Yanhong Zhou, Guolin Li, Xu Zhang, and Wei Han. Deep learning methods to\nprocess fmri data and their application in the diagnosis of cognitive impairment: a brief overview and our opinion.\nFrontiers in neuroinformatics, 12:23, 2018.\n[2] Simeon Spasov, Luca Passamonti, Andrea Duggento, Pietro Lio, Nicola Toschi, Alzheimer’s Disease Neuroimag-\ning Initiative, et al. A parameter-efﬁcient deep learning approach to predict conversion from mild cognitive\nimpairment to alzheimer’s disease. Neuroimage, 189:276–287, 2019.\n[3] Mingxia Liu, Daoqiang Zhang, and Dinggang Shen. Relationship induced multi-template learning for diagnosis\nof alzheimer’s disease and mild cognitive impairment. IEEE transactions on medical imaging, 35(6):1463–1474,\n2016.\n[4] Ali Khazaee, Ata Ebrahimzadeh, and Abbas Babajani-Feremi. Application of advanced machine learning methods\non resting-state fmri network for identiﬁcation of mild cognitive impairment and alzheimer’s disease. Brain\nimaging and behavior, 10(3):799–817, 2016.\n[5] Yifat Brill-Karniely, Dvir Dror, Tal Duanis-Assaf, Yoel Goldstein, Ouri Schwob, Talya Millo, Natalie Orehov, Tal\nStern, Mohammad Jaber, Netanel Loyfer, et al. Triangular correlation (trc) between cancer aggressiveness, cell\nuptake capability, and cell deformability. Science advances, 6(3):eaax2861, 2020.\n[6] George H Dunteman. Principal components analysis. Number 69. Sage, 1989.\n[7] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research,\n9(11), 2008.\n[8] Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for\ndimension reduction. arXiv preprint arXiv:1802.03426, 2018.\n[9] Frédéric Chazal and Bertrand Michel. An introduction to topological data analysis: fundamental and practical\naspects for data scientists. arXiv preprint arXiv:1710.04019, 2017.\n[10] Shizhe Chen, Jia Chen, Qin Jin, and Alexander Hauptmann. Class-aware self-attention for audio event recognition.\nIn Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval, pages 28–36, 2018.\n20\n\n[11] Jie Zheng, Andi Xia, Lin Shao, Tao Wan, and Zengchang Qin. Stock volatility prediction based on self-attention\nnetworks with social information. In 2019 IEEE Conference on Computational Intelligence for Financial\nEngineering & Economics (CIFEr), pages 1–7. IEEE, 2019.\n[12] Yongbin Sun, Yue Wang, Ziwei Liu, Joshua Siegel, and Sanjay Sarma. Pointgrow: Autoregressively learned\npoint cloud generation with self-attention. In Proceedings of the IEEE/CVF Winter Conference on Applications of\nComputer Vision, pages 61–70, 2020.\n[13] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align\nand translate. arXiv preprint arXiv:1409.0473, 2014.\n[14] Minjeong Jeon, Ick Hoon Jin, Michael Schweinberger, and Samuel Baugh. Mapping unobserved item–respondent\ninteractions: A latent space item response model with interaction map. Psychometrika, pages 1–26, 2021.\n[15] Yeseul Jeon, Dongjun Chung, Jina Park, and Ick Hoon Jin. Network-based trajectory analysis of topic interaction\nmap for text mining of covid-19 biomedical literature, 2021.\n[16] Clifford R Jack Jr, Matt A Bernstein, Nick C Fox, Paul Thompson, Gene Alexander, Danielle Harvey, Bret\nBorowski, Paula J Britson, Jennifer L. Whitwell, Chadwick Ward, et al. The alzheimer’s disease neuroimaging\ninitiative (adni): Mri methods. Journal of Magnetic Resonance Imaging: An Ofﬁcial Journal of the International\nSociety for Magnetic Resonance in Medicine, 27(4):685–691, 2008.\n[17] Susanne G Mueller, Michael W Weiner, Leon J Thal, Ronald C Petersen, Clifford R Jack, William Jagust, John Q\nTrojanowski, Arthur W Toga, and Laurel Beckett. Ways toward an early diagnosis in alzheimer’s disease: the\nalzheimer’s disease neuroimaging initiative (adni). Alzheimer’s & Dementia, 1(1):55–66, 2005.\n[18] Nathalie Tzourio-Mazoyer, Brigitte Landeau, Dimitri Papathanassiou, Fabrice Crivello, Olivier Etard, Nicolas\nDelcroix, Bernard Mazoyer, and Marc Joliot. Automated anatomical labeling of activations in spm using a\nmacroscopic anatomical parcellation of the mni mri single-subject brain. Neuroimage, 15(1):273–289, 2002.\n[19] Manhua Liu, Fan Li, Hao Yan, Kundong Wang, Yixin Ma, Li Shen, Mingqing Xu, Alzheimer’s Disease Neuroimag-\ning Initiative, et al. A multi-model deep convolutional neural network for automatic hippocampus segmentation\nand classiﬁcation in alzheimer’s disease. Neuroimage, 208:116459, 2020.\n[20] Chong-Yaw Wee, Chaoqiang Liu, Annie Lee, Joann S Poh, Hui Ji, Anqi Qiu, Alzheimers Disease Neuroimage\nInitiative, et al. Cortical graph neural network for ad and mci diagnosis and transfer learning across populations.\nNeuroImage: Clinical, 23:101929, 2019.\n[21] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm\nsigkdd international conference on knowledge discovery and data mining, pages 785–794, 2016.\n[22] Shangran Qiu, Prajakta S Joshi, Matthew I Miller, Chonghua Xue, Xiao Zhou, Cody Karjadi, Gary H Chang,\nAnant S Joshi, Brigid Dwyer, Shuhan Zhu, et al. Development and validation of an interpretable deep learning\nframework for alzheimer’s disease classiﬁcation. Brain, 143(6):1920–1933, 2020.\n[23] Hasib Zunair, Aimon Rahman, Nabeel Mohammed, and Joseph Paul Cohen. Uniformizing techniques to process ct\nscans with 3d cnns for tuberculosis prediction. In International Workshop on PRedictive Intelligence In MEdicine,\npages 156–168. Springer, 2020.\n[24] Laura W de Jong, Karin van der Hiele, Ilya M Veer, JJ Houwing, RGJ Westendorp, ELEM Bollen, Paul W\nde Bruin, HAM Middelkoop, Mark A van Buchem, and Jeroen van der Grond. Strongly reduced volumes of\nputamen and thalamus in alzheimer’s disease: an mri study. Brain, 131(12):3277–3285, 2008.\n[25] Clifford R Jack, Ronald C Petersen, Yue Cheng Xu, Peter C O’Brien, Glenn E Smith, Robert J Ivnik, Bradley F\nBoeve, Stephen C Waring, Eric G Tangalos, and Emre Kokmen. Prediction of ad with mri-based hippocampal\nvolume in mild cognitive impairment. Neurology, 52(7):1397–1397, 1999.\n[26] Arnold Bakker, Gregory L Krauss, Marilyn S Albert, Caroline L Speck, Lauren R Jones, Craig E Stark, Michael A\nYassa, Susan S Bassett, Amy L Shelton, and Michela Gallagher. Reduction of hippocampal hyperactivity improves\ncognition in amnestic mild cognitive impairment. Neuron, 74(3):467–474, 2012.\n[27] Mario Manto and Peter Mariën. Schmahmann’s syndrome-identiﬁcation of the third cornerstone of clinical\nataxiology. Cerebellum & ataxias, 2(1):1–5, 2015.\n[28] Roberta M Kelly and Peter L Strick. Cerebellar loops with motor cortex and prefrontal cortex of a nonhuman\nprimate. Journal of neuroscience, 23(23):8432–8444, 2003.\n[29] Heidi IL Jacobs, David A Hopkins, Helen C Mayrhofer, Emiliano Bruner, Fred W van Leeuwen, Wijnand\nRaaijmakers, and Jeremy D Schmahmann. The cerebellum in alzheimer’s disease: evaluating its role in cognitive\ndecline. Brain, 141(1):37–47, 2018.\n21\n\n[30] Christine C Guo, Rachel Tan, John R Hodges, Xintao Hu, Saber Sami, and Michael Hornberger. Network-\nselective vulnerability of the human cerebellum to alzheimer’s disease and frontotemporal dementia. Brain,\n139(5):1527–1538, 2016.\n[31] Nancy Kanwisher, Josh McDermott, and Marvin M Chun. The fusiform face area: a module in human extrastriate\ncortex specialized for face perception. Journal of neuroscience, 17(11):4302–4311, 1997.\n[32] Suping Cai, Tao Chong, Yun Zhang, Jun Li, Karen M von Deneen, Junchan Ren, Minghao Dong, Liyu Huang,\nAlzheimer’s Disease Neuroimaging Initiative, et al. Altered functional connectivity of fusiform gyrus in subjects\nwith amnestic mild cognitive impairment: a resting-state fmri study. Frontiers in human neuroscience, 9:471,\n2015.\n[33] Rei Enatsu, Jorge Gonzalez-Martinez, Juan Bulacio, Yuichi Kubota, John Mosher, Richard C Burgess, Imad\nNajm, and Dileep R Nair. Connections of the limbic network: a corticocortical evoked potentials study. Cortex,\n62:20–33, 2015.\n[34] Basant K Puri, Philip M Jakeman, M Agour, KDR Gunatilake, KAC Fernando, AI Gurusinghe, IH Treasaden,\nAD Waldman, and P Gishen. Regional grey and white matter volumetric changes in myalgic encephalomyeli-\ntis (chronic fatigue syndrome): a voxel-based morphometry 3 t mri study. The British journal of radiology,\n85(1015):e270–e273, 2012.\n[35] Xia-an Bi, Qian Xu, Xianhao Luo, Qi Sun, and Zhigang Wang. Analysis of progression toward alzheimer’s disease\nbased on evolutionary weighted random support vector machine cluster. Frontiers in neuroscience, 12:716, 2018.\n[36] Peipeng Liang, Jie Xiang, Hong Liang, Zhigang Qi, Kuncheng Li, Alzheimer’s Disease NeuroImaging Initiative,\net al. Altered amplitude of low-frequency ﬂuctuations in early and late mild cognitive impairment and alzheimer’s\ndisease. Current Alzheimer Research, 11(4):389–398, 2014.\n[37] Suping Cai, Liyu Huang, Jia Zou, Longlong Jing, Buzhong Zhai, Gongjun Ji, Karen M Von Deneen, Junchan Ren,\nAifeng Ren, and Alzheimer’s Disease Neuroimaging Initiative. Changes in thalamic connectivity in the early and\nlate stages of amnestic mild cognitive impairment: a resting-state functional magnetic resonance study from adni.\nPloS one, 10(2):e0115573, 2015.\n[38] Eek-Sung Lee, Kwangsun Yoo, Young-Beom Lee, Jinyong Chung, Ji-Eun Lim, Bora Yoon, and Yong Jeong.\nDefault mode network functional connectivity in early and late mild cognitive impairment. Alzheimer Disease &\nAssociated Disorders, 30(4):289–296, 2016.\n[39] Eric M Reiman, Yakeel T Quiroz, Adam S Fleisher, Kewei Chen, Carlos Velez-Pardo, Marlene Jimenez-Del-Rio,\nAnne M Fagan, Aarti R Shah, Sergio Alvarez, Andrés Arbelaez, et al. Brain imaging and ﬂuid biomarker analysis\nin young adults at genetic risk for autosomal dominant alzheimer’s disease in the presenilin 1 e280a kindred: a\ncase-control study. The Lancet Neurology, 11(12):1048–1056, 2012.\n[40] Julia Spaniol, Patrick SR Davidson, Alice SN Kim, Hua Han, Morris Moscovitch, and Cheryl L Grady. Event-\nrelated fmri studies of episodic encoding and retrieval: meta-analyses using activation likelihood estimation.\nNeuropsychologia, 47(8-9):1765–1779, 2009.\n[41] Scott A Small, Scott A Schobel, Richard B Buxton, Menno P Witter, and Carol A Barnes. A pathophysiological\nframework of hippocampal dysfunction in ageing and disease. Nature Reviews Neuroscience, 12(10):585–601,\n2011.\n[42] Xavier Delbeuck, Martial Van der Linden, and Fabienne Collette. Alzheimer’disease as a disconnection syndrome?\nNeuropsychology review, 13(2):79–92, 2003.\n[43] J Patrick Kesslak, Orhan Nalcioglu, and Carl W Cotman. Quantiﬁcation of magnetic resonance scans for\nhippocampal and parahippocampal atrophy in alzheimer’s disease. Neurology, 41(1):51–51, 1991.\n[44] Matthew Bobinski, MJ De Leon, J Wegiel, S Desanti, A Convit, LA Saint Louis, H Rusinek, and HM Wisniewski.\nThe histological validation of post mortem magnetic resonance imaging-determined hippocampal volume in\nalzheimer’s disease. Neuroscience, 95(3):721–725, 1999.\n[45] Liana G Apostolova, Rebecca A Dutton, Ivo D Dinov, Kiralee M Hayashi, Arthur W Toga, Jeffrey L Cummings,\nand Paul M Thompson. Conversion of mild cognitive impairment to alzheimer disease predicted by hippocampal\natrophy maps. Archives of neurology, 63(5):693–699, 2006.\n[46] Ya-di Li, Hui-jin He, Hai-bo Dong, Xiao-yuan Feng, Guo-ming Xie, and Ling-jun Zhang. Discriminative analysis\nof early-stage alzheimer’s disease and normal aging with automatic segmentation technique in subcortical gray\nmatter structures: a multicenter in vivo mri volumetric and dti study. Acta Radiologica, 54(10):1191–1200, 2013.\n[47] Wen-Zhen Zhu, Wei-de Zhong, Wei Wang, Chuan-jia Zhan, Cheng-yuan Wang, Jian-pin Qi, Jian-zhi Wang, and\nTing Lei. Quantitative mr phase-corrected imaging to investigate increased brain iron deposition of patients with\nalzheimer disease. Radiology, 253(2):497–504, 2009.\n22\n\n[48] Takashi Yoshiura, Futoshi Mihara, Koji Ogomori, Atsuo Tanaka, Koichiro Kaneko, and Kouji Masuda. Diffusion\ntensor in posterior cingulate gyrus: correlation with cognitive decline in alzheimer’s disease. Neuroreport,\n13(17):2299–2302, 2002.\n[49] Andreas Fellgiebel, Matthias J Müller, Paulo Wille, Paulo R Dellani, Armin Scheurich, Lutz G Schmidt, and Peter\nStoeter. Color-coded diffusion-tensor-imaging of posterior cingulate ﬁber tracts in mild cognitive impairment.\nNeurobiology of aging, 26(8):1193–1198, 2005.\n[50] KJCJ Kantarci, CR Jack, YC Xu, NG Campeau, PC O’Brien, GE Smith, RJ Ivnik, BF Boeve, E Kokmen,\nEG Tangalos, et al. Regional metabolic patterns in mild cognitive impairment and alzheimer’s disease: a 1h mrs\nstudy. Neurology, 55(2):210–217, 2000.\n[51] Stephen W Scheff and Douglas A Price. Alzheimer’s disease-related synapse loss in the cingulate cortex. Journal\nof Alzheimer’s Disease, 3(5):495–505, 2001.\n[52] Gwénaëlle Catheline, Olivier Periot, Marion Amirault, Marc Braun, Jean-François Dartigues, Sophie Auriacombe,\nand Michèle Allard.\nDistinctive alterations of the cingulum bundle during aging and alzheimer’s disease.\nNeurobiology of aging, 31(9):1582–1592, 2010.\n[53] Yi-Cheng Lin, Yao-Chia Shih, Wen-Yih I Tseng, Yu-Hsiu Chu, Meng-Tien Wu, Ta-Fu Chen, Pei-Fang Tang, and\nMing-Jang Chiu. Cingulum correlates of cognitive functions in patients with mild cognitive impairment and early\nalzheimer’s disease: a diffusion spectrum imaging study. Brain topography, 27(3):393–402, 2014.\n[54] Lele Xu, Xia Wu, Rui Li, Kewei Chen, Zhiying Long, Jiacai Zhang, Xiaojuan Guo, Li Yao, Alzheimer’s\nDisease Neuroimaging Initiative, et al. Prediction of progressive mild cognitive impairment by multi-modal\nneuroimaging biomarkers. Journal of Alzheimer’s Disease, 51(4):1045–1056, 2016.\n[55] Marcos Domic-Siede, Martín Irani, Joaquín Valdés, Marcela Perrone-Bertolotti, and Tomás Ossandón. Theta\nactivity from frontopolar cortex, mid-cingulate cortex and anterior cingulate cortex shows different roles in\ncognitive planning performance. NeuroImage, 226:117557, 2021.\n[56] James F Cavanagh and Michael J Frank. Frontal theta as a mechanism for cognitive control. Trends in cognitive\nsciences, 18(8):414–421, 2014.\n[57] Dingailu Ma, Irfete S Fetahu, Mei Wang, Rui Fang, Jiahui Li, Hang Liu, Tobin Gramyk, Isabella Iwanicki, Sophie\nGu, Winnie Xu, et al. The fusiform gyrus exhibits an epigenetic signature for alzheimer’s disease. Clinical\nepigenetics, 12(1):1–16, 2020.\n[58] Lulu Zhang, Huangjing Ni, Zhinan Yu, Jun Wang, Jiaolong Qin, Fengzhen Hou, Albert Yang, Alzheimer’s Disease\nNeuroimaging Initiative (ADNI, et al. Investigation on the alteration of brain functional network and its role in the\nidentiﬁcation of mild cognitive impairment. Frontiers in neuroscience, 14:1027, 2020.\n[59] Jeremy D Schmahmann, Carl M Anderson, Natika Newton, and Ralph D Ellis. The function of the cerebellum\nin cognition, affect and consciousness: Empirical support for the embodied mind. Consciousness & emotion,\n2(2):273–309, 2001.\n[60] Neelum T Aggarwal, Robert S Wilson, Todd L Beck, Julia L Bienias, and David A Bennett. Motor dysfunction in\nmild cognitive impairment and the risk of incident alzheimer disease. Archives of neurology, 63(12):1763–1769,\n2006.\n[61] Jeremy D Schmahmann and Janet C Sherman. The cerebellar cognitive affective syndrome. Brain: a journal of\nneurology, 121(4):561–579, 1998.\n[62] Jennifer L Whitwell, Stephen D Weigand, Bradley F Boeve, Matthew L Senjem, Jeffrey L Gunter, Mariely DeJesus-\nHernandez, Nicola J Rutherford, Matthew Baker, David S Knopman, Zbigniew K Wszolek, et al. Neuroimaging\nsignatures of frontotemporal dementia genetics: C9orf72, tau, progranulin and sporadics. Brain, 135(3):794–806,\n2012.\n[63] Jeremy D Schmahmann. Dysmetria of thought: clinical consequences of cerebellar dysfunction on cognition and\naffect. Trends in cognitive sciences, 2(9):362–371, 1998.\n[64] Jeremy D Schmahmann, Jeffrey B Weilburg, and Janet C Sherman.\nThe neuropsychiatry of the cerebel-\nlum—insights from the clinic. The cerebellum, 6(3):254–267, 2007.\n[65] G Russo, DS Sardina, P Alongi, R Coppola, V Puglisi, A Stefano, R Giugno, LM Grimaldi, S Scalisi, M Midiri,\net al. 79. amyloid-pet analysis based on tissue probability maps. Physica Medica: European Journal of Medical\nPhysics, 56:111–112, 2018.\n[66] Zhiqun Wang, Chaogan Yan, Cheng Zhao, Zhigang Qi, Weidong Zhou, Jie Lu, Yong He, and Kuncheng Li. Spatial\npatterns of intrinsic brain activity in mild cognitive impairment and alzheimer’s disease: A resting-state functional\nmri study. Human brain mapping, 32(10):1720–1740, 2011.\n23\n\n[67] Jungho Cha, Jung-Min Hwang, Hang Joon Jo, Sang Won Seo, Duk L Na, and Jong-Min Lee. Assessment of\nfunctional characteristics of amnestic mild cognitive impairment and alzheimer’s disease using various methods of\nresting-state fmri analysis. BioMed research international, 2015, 2015.\n[68] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,\n2014.\n24\n\nA\nFunctional Connectivity Network\n(a) rs–fMRI BOLD signal\n(b) Pearson’s r–based FCN\n(c) Fisher’s z–based FCN\n(d) Linear space–based FCN\n(e) Stochastic space–based FCN\n(f) Topological space–based FCN\nFigure 8: Correlation coefﬁcient–based FCN and latent space–based FCN of AD patient\n25\n\n(a) rs–fMRI BOLD signal\n(b) Pearson’s r–based FCN\n(c) Fisher’s z–based FCN\n(d) Linear space–based FCN\n(e) Stochastic space–based FCN\n(f) Topological space–based FCN\nFigure 9: Correlation coefﬁcient–based FCN and latent space–based FCN of MCI patient\n26\n\n(a) rs–fMRI BOLD signal\n(b) Pearson’s r–based FCN\n(c) Fisher’s z–based FCN\n(d) Linear space–based FCN\n(e) Stochastic space–based FCN\n(f) Topological space–based FCN\nFigure 10: Correlation coefﬁcient–based FCN and latent space–based FCN of EMCI patient\n27\n\n(a) rs–fMRI BOLD signal\n(b) Pearson’s r–based FCN\n(c) Fisher’s z–based FCN\n(d) Linear space–based FCN\n(e) Stochastic space–based FCN\n(f) Topological space–based FCN\nFigure 11: Correlation coefﬁcient–based FCN and latent space–based FCN of LMCI patient\n28\n\nB\nKullback–Leibler Divergence value for compared diseases’ group\nPutamen_L\nPutamen_R\nPallidum_R\nPallidum_L\nHippocampus_R\nCerebellum_4_5_R\nCerebellum_4_5_L\nOccipital_Sup_R\nTemporal_Inf_L\nCerebellum_8_L\nCingulum_Mid_L\nRolandic_Oper_R\nCingulum_Mid_R\nCerebellum_6_R\nPostcentral_L\nThalamus_R\nOccipital_Sup_L\nCerebellum_6_L\nParaHippocampal_R\nLingual_R\nSupraMarginal_L\nFusiform_R\nInsula_R\nTemporal_Inf_R\nCerebellum_8_R\nCerebellum_9_L\nCerebellum_7b_L\nThalamus_L\nFusiform_L\nFrontal_Mid_R\nFrontal_Inf_Tri_R\nInsula_L\nOccipital_Mid_R\nCerebellum_Crus2_R\nOccipital_Mid_L\nHippocampus_L\nOlfactory_R\nPostcentral_R\nFrontal_Sup_L\nFrontal_Sup_R\nSupp_Motor_Area_R\nCerebellum_7b_R\nParaHippocampal_L\nTemporal_Sup_L\nLingual_L\nCalcarine_R\nFrontal_Sup_Medial_L\nPrecentral_R\nVermis_8\nPrecentral_L\nFrontal_Sup_Orb_L\nPrecuneus_R\nRolandic_Oper_L\nCuneus_R\nParietal_Inf_L\nCerebellum_Crus2_L\nTemporal_Mid_R\nOccipital_Inf_L\nTemporal_Sup_R\nCuneus_L\nAmygdala_R\nFrontal_Sup_Medial_R\nFrontal_Mid_L\nSupp_Motor_Area_L\nSupraMarginal_R\nTemporal_Mid_L\nOlfactory_L\nPrecuneus_L\nCerebellum_Crus1_L\nFrontal_Sup_Orb_R\nCerebellum_9_R\nCalcarine_L\nRectus_R\nTemporal_Pole_Mid_R\nFrontal_Inf_Orb_R\nFrontal_Inf_Oper_L\nRectus_L\nFrontal_Inf_Oper_R\nVermis_7\nCingulum_Ant_L\nCingulum_Ant_R\nFrontal_Inf_Tri_L\nCerebellum_3_L\nParietal_Sup_L\nFrontal_Mid_Orb_L\nFrontal_Inf_Orb_L\nCaudate_R\nCerebellum_Crus1_R\nVermis_4_5\nVermis_9\nVermis_6\nFrontal_Med_Orb_R\nFrontal_Mid_Orb_R\nParacentral_Lobule_L\nTemporal_Pole_Sup_R\nCingulum_Post_R\nCingulum_Post_L\nCaudate_L\nAmygdala_L\nParietal_Inf_R\nAngular_R\nHeschl_L\nTemporal_Pole_Mid_L\nOccipital_Inf_R\nCerebellum_3_R\nParacentral_Lobule_R\nParietal_Sup_R\nTemporal_Pole_Sup_L\nHeschl_R\nCerebellum_10_R\nVermis_3\nAngular_L\nFrontal_Med_Orb_L\nCerebellum_10_L\nVermis_10\nVermis_1_2\nBrain Region\n0.000\n0.002\n0.004\nKL\n(a) AD vs MCI\n(b) AD vs EMCI\n(c) AD vs LMCI\n(d) EMCI vs LMCI\nFigure 12: Kullback–Leibler Divergence value for compared diseases’ group\n29",
    "pdf_filename": "Interpretable_Fusion_Analytics_Framework_for_fMRI_Connectivity_Self-Attention_Mechanism_and_Latent_S.pdf"
}