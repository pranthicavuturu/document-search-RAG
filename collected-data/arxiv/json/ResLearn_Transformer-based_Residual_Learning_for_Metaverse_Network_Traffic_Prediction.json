{
    "title": "ResLearn: Transformer-based Residual Learning for",
    "abstract": "predicting Metaverse network traffic, addressing the growing performance events, one of which attracted an audience of 36 demandforintelligentresourcemanagementineXtendedReality million users [4], [5]. Healthcare, training, and marketing for (XR)services.Wefirstintroduceastate-of-the-arttestbedcaptur- Metaverse services have also grown recently [6], [7]. Cloud ingareal-worlddatasetofvirtualreality(VR),augmentedreality (AR), and mixed reality (MR) traffic, made openly available rendering for Metaverse is crucial to offloading computing for further research. To enhance prediction accuracy, we then resourcestomaketheservicesaffordable,apopulartechnique propose a novel view-frame (VF) algorithm that accurately for VR games [8]. Consequently, the Ericsson 2022 report identifies video frames from traffic while ensuring privacy emphasizes the growing need for more intelligent interactions compliance, and we develop a Transformer-based progressive betweenXRservicesandthenetworktomaintainhighQuality error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series of Service (QoS) [3]. Therefore, network management is predictions by using fully connected neural networks to reduce crucial for Internet service providers (ISPs) to accommodate errors, particularly during peak traffic, outperforming prior adequate resources and avoid cybersickness among users [9]– workby99%.OurcontributionsofferInternetserviceproviders [11]. (ISPs) robust tools for real-time network management to satisfy Metaversetrafficconsistsofvideo,audio,andcontrolflows Quality of Service (QoS) and enhance user experience in the Metaverse. [8],amongalldownlinkvideoframesareresource-demanding IndexTerms—MetaverseNetworkTrafficPrediction,Residual in the case of VR, and both uplink/downlink video frames for Learning,ExtendedReality(XR),virtualreality(VR),augmented AR and MR traffic. Therefore, predicting the frame size is reality (AR), and mixed reality (MR). vital, and for latency-related issues, it is essential to predict frame inter-arrival time and frame duration [12]. Predicting I. INTRODUCTION framesize,inter-arrivaltime,andframedurationwillhelpISPs The Metaverse is a comprehensive ecosystem of inter- prepareandmanagetheMetaversenetworkforholisticandin- connected virtual worlds that provide immersive experiences telligenttrafficmanagement.However,thereneedstobemore to users. The ecosystem enhances existing and generates real-world Metaverse data and research in prediction to make new value from economic, environmental, social, and cultural progress in the field. Essentially, frame-related information is perspectives [1]. Services in the Metaverse ecosystem are timeseriesdata.Therecentadventofdifferentstate-of-the-art designed to be accessed using immersive extended reality artificialintelligence(AI)basedtimeseriesmodelshasshown (XR)environments.XRisanumbrellatermthatdescribesthe tremendous progress in time series predictions [13]. The only technologiesaffectingtheuser’simmersiveexperience,suchas VR frame size prediction work is available at [14]; therefore, virtualreality(VR),augmentedreality(AR),andmixedreality we consider it state-of-the-art (SoA) work for benchmark (MR)[2].VRallowsuserstointeractwithvirtuallygenerated comparison. The work studies different AI models to predict environmentsdesignedtosimulatereal-worldexperiences.AR VR frame size. It establishes stacked LSTM to produce better overlaysinteractive,virtuallygeneratedinformationontoreal- results based on transfer learning methodologies. Therefore, worldobjectsorwithinreal-worldspaces.XRtechnologieslie the solution aims for online prediction, imperative for real- on a spectrum between AR and VR. In cases where the dis- time network management. However, the work is evaluated tinction between the realities is ambiguous, the experience is onasmalldatasetcapturedinacontrolledenvironment.Also, considered MR. As the Metaverse’s growth continues and XR the performance can be improved with further reduction in evolves, the popularity of its services increases. Driven by the the error. The frame identification methodology used in the rapid growth of the Metaverse, Internet traffic is expected to work might need to be revised because the frame loss for 120 surpass current forecasts significantly [3]. The entertainment Mbps is more than 54 Mbps since the dataset is captured in and social media industries have seen the most substantial a controlled environment. Our literature review identifies the 4202 voN 7 ]IA.sc[ 1v49811.1142:viXra",
    "body": "ResLearn: Transformer-based Residual Learning for\nMetaverse Network Traffic Prediction\nYoga Suhas Kuruba Manjunath∗, Mathew Szymanowski ∗, Austin Wissborn∗,\nMushu Li †, Lian Zhao∗, and Xiao-Ping Zhang ‡\n∗Department of Electrical, Computer & Biomedical Engineering, Toronto Metropolitan University, Toronto, Canada\n†Department of Computer Science and Engineering, Lehigh University, Bethlehem, PA, USA\n‡ Shenzhen Key Laboratory of Ubiquitous Data Enabling, Tsinghua Shenzhen International\nGraduate School, Tsinghua University,\nEmail: {yoga.kuruba@torontomu.ca, austin.wissborn@torontomu.ca, mszymanowski@torontomu.ca,\nmul224@lehigh.edu, l5zhao@torontomu.ca, xpzhang@ieee.org}\nAbstract—Our work proposes a comprehensive solution for growth of Metaverse services, as evidenced by popular virtual\npredicting Metaverse network traffic, addressing the growing performance events, one of which attracted an audience of 36\ndemandforintelligentresourcemanagementineXtendedReality million users [4], [5]. Healthcare, training, and marketing for\n(XR)services.Wefirstintroduceastate-of-the-arttestbedcaptur-\nMetaverse services have also grown recently [6], [7]. Cloud\ningareal-worlddatasetofvirtualreality(VR),augmentedreality\n(AR), and mixed reality (MR) traffic, made openly available rendering for Metaverse is crucial to offloading computing\nfor further research. To enhance prediction accuracy, we then resourcestomaketheservicesaffordable,apopulartechnique\npropose a novel view-frame (VF) algorithm that accurately for VR games [8]. Consequently, the Ericsson 2022 report\nidentifies video frames from traffic while ensuring privacy\nemphasizes the growing need for more intelligent interactions\ncompliance, and we develop a Transformer-based progressive\nbetweenXRservicesandthenetworktomaintainhighQuality\nerror-learning algorithm, referred to as ResLearn for Metaverse\ntraffic prediction. ResLearn significantly improves time-series of Service (QoS) [3]. Therefore, network management is\npredictions by using fully connected neural networks to reduce crucial for Internet service providers (ISPs) to accommodate\nerrors, particularly during peak traffic, outperforming prior adequate resources and avoid cybersickness among users [9]–\nworkby99%.OurcontributionsofferInternetserviceproviders\n[11].\n(ISPs) robust tools for real-time network management to satisfy\nMetaversetrafficconsistsofvideo,audio,andcontrolflows\nQuality of Service (QoS) and enhance user experience in the\nMetaverse. [8],amongalldownlinkvideoframesareresource-demanding\nIndexTerms—MetaverseNetworkTrafficPrediction,Residual in the case of VR, and both uplink/downlink video frames for\nLearning,ExtendedReality(XR),virtualreality(VR),augmented AR and MR traffic. Therefore, predicting the frame size is\nreality (AR), and mixed reality (MR).\nvital, and for latency-related issues, it is essential to predict\nframe inter-arrival time and frame duration [12]. Predicting\nI. INTRODUCTION\nframesize,inter-arrivaltime,andframedurationwillhelpISPs\nThe Metaverse is a comprehensive ecosystem of inter- prepareandmanagetheMetaversenetworkforholisticandin-\nconnected virtual worlds that provide immersive experiences telligenttrafficmanagement.However,thereneedstobemore\nto users. The ecosystem enhances existing and generates real-world Metaverse data and research in prediction to make\nnew value from economic, environmental, social, and cultural progress in the field. Essentially, frame-related information is\nperspectives [1]. Services in the Metaverse ecosystem are timeseriesdata.Therecentadventofdifferentstate-of-the-art\ndesigned to be accessed using immersive extended reality artificialintelligence(AI)basedtimeseriesmodelshasshown\n(XR)environments.XRisanumbrellatermthatdescribesthe tremendous progress in time series predictions [13]. The only\ntechnologiesaffectingtheuser’simmersiveexperience,suchas VR frame size prediction work is available at [14]; therefore,\nvirtualreality(VR),augmentedreality(AR),andmixedreality we consider it state-of-the-art (SoA) work for benchmark\n(MR)[2].VRallowsuserstointeractwithvirtuallygenerated comparison. The work studies different AI models to predict\nenvironmentsdesignedtosimulatereal-worldexperiences.AR VR frame size. It establishes stacked LSTM to produce better\noverlaysinteractive,virtuallygeneratedinformationontoreal- results based on transfer learning methodologies. Therefore,\nworldobjectsorwithinreal-worldspaces.XRtechnologieslie the solution aims for online prediction, imperative for real-\non a spectrum between AR and VR. In cases where the dis- time network management. However, the work is evaluated\ntinction between the realities is ambiguous, the experience is onasmalldatasetcapturedinacontrolledenvironment.Also,\nconsidered MR. As the Metaverse’s growth continues and XR the performance can be improved with further reduction in\nevolves, the popularity of its services increases. Driven by the the error. The frame identification methodology used in the\nrapid growth of the Metaverse, Internet traffic is expected to work might need to be revised because the frame loss for 120\nsurpass current forecasts significantly [3]. The entertainment Mbps is more than 54 Mbps since the dataset is captured in\nand social media industries have seen the most substantial a controlled environment. Our literature review identifies the\n4202\nvoN\n7\n]IA.sc[\n1v49811.1142:viXra\n(a)\nFig. 1: System model of the proposed solution. x in fx[t]\nrepresents one of the features. EDA is the exploratory data\nanalysis.\nfollowing gaps: i) the need for holistic, comprehensive, and\nreal-world Metaverse datasets and ii) accurate frame-related\ndata predicting algorithms.\nWe chart out a state-of-the-art Metaverse testbed to capture\na holistic, comprehensive, and real-world Metaverse dataset (b)\ncomprising VR games, VR videos, VR chat/VoIP, AR, and Fig. 2: (a) PDF of packet lengths, and (b) PDF of inter-arrival\nMR traffic. We also make it open for the research fraternity time for a sample Metaverse traffic segment.\navailable at [15]. Our work treats the Metaverse traffic in\nwhen audio and control-related flows are transmitted with\nsegments to enhance the predictability of the data at higher slightly higher inter-arrival time. The len and dur are\nTH th\nspeed.Weproposeanaccurateview-frame(VF)algorithmthat\ncalculatedfromthefirstsegmentatasession’sstartfortheVF\nhelps to identify the types of video frames using application-\nalgorithm. All packets within these thresholds are collected\nlevel information to comply with privacy-related policies. Our\nto identify the frames. The method is verified on different\nproposed VF algorithm can predict the number of frames in a\nMetaverserenderingplatforms:Metaairlink[18],andVirtual\nsegment,totalframesize,andframeinter-arrivaltime.Finally,\nDesktop Streamer (VDS) [19].\nwe propose a state-of-the-art residual learning (ResLearn) Basedontherequirement,oneofthefeaturesisselectedfor\nalgorithmthatusestransformer[16]topredicttime-seriesdata prediction. These features undergo Exploratory Data Analysis\nand fully connected neural networks (FCNN) to learn errors (EDA) and Data Engineering to ensure data quality and\nwith a bias to identify the peaks of the frame-related data for integrity, followed by Time Series Data Preparation with\naccurate network management. Our solution outperforms the segmentation for model training. The core of the system is\nSoA work [14] by 99% in reducing the prediction errors. The frame feature prediction (fx[t]), where the previous frame\nimplementation of the solution is made open for the research feature values (fx[t − 1]) are used as inputs to predict the\ncommunity at [17]. current network traffic behaviour. With this information, we\nprovide the mathematical problem statement to predict key\nII. SYSTEMMODEL\nfeatures of the Metaverse network traffic features. Let f be a\nt\nThe system model, in Figure 1 illustrates the proposed frame vector, identified by VF algorithm for a given segment,\nframework for predicting Metaverse network traffic, focus- having frame-related information given as f t =[f tc,f ts,f tiat],\ning on frame-level features. The process begins with data where t indicates the time index of the given segment. Let\npreprocessing, where the VF algorithm is applied to extract\nfx[t−1]representstheMetaverseframe-relatednetworktraffic\nrelevant frame-related data. The key features extracted from at the previous time step, where x indicates one of the three\ntheincomingtrafficincludeframecount(fc),framesize(fs), frame-related features in f [t−1]. Therefore, frame count, size,\nand frame inter-arrival time (IAT) (fiat). Our VF algorithm andinter-arrivaltimeareindividuallypredictedusinghistorical\nworksonapplication-levelfeatures:time,packetlength,packet data. The prediction function for the current network traffic,\ndirection, and packet inter-arrival time. Frame-related packets fx[t], is\nhave a more considerable length with relatively more minor\ninter-arrival time. We use this property to determine the fx[t]=ψ(fx[t−1]), (1)\nthresholds for packet length and inter-arrival time to identify\nwhere ψ(·) is the prediction model.\nframe-relatedpacketsasshowninFigure2.InFigure2,len\nTH\nis determined as 25% of the maximum length of the observed III. RESLEARN:TRANSFORMER-BASEDRESIDUAL\npacket length. dur is the frame duration threshold deter- LEARNINGFORMETAVERSENETWORKTRAFFIC\nth\nmined between the first two peaks. The first peak represents PREDICTION\nthe start of the video frame packet with less inter-arrival time, The residual Learning (ResLearn) algorithm is a two-\nand the second peak represents the end of the video frame step prediction approach involving a transformer deep neural\nnetwork model [16] designed to enhance Metaverse network\ntraffic forecasting by leveraging residual learning inspired by\nResNet [20]. Transformer is known for learning short and\nlong-term dependencies from time series data. However, the\npredictionerrorisinevitableduetotherandomnessintroduced\nby network health and users in Metaverse infrastructure.\nHowever, we can learn the nature of error using a neural\nnetwork.ResLearnisanovelapproachthatusesaTransformer\nin the first step, given as F (·), the predictive Transformer\n1\nmodel.TheresidualfromtheF (·)isfedtoafullyconnected\n1\nneural network (FCNN) to learn the nature of the error, given\nas F (·). The final prediction model from Eq. (1) is given as\n2\nψ(·)=F (·)+F (·).\n1 2\nFigure3illustratestheworkflowoftheResLearnalgorithm.\nThe input data is split into training (y ) and validation\ntrain\n(y ) sets. The first model, including a transformer network,\nval\nprocesses the training data and generates an initial prediction Fig. 3: ResLearn algorithm.\nresult (y ). This output, called Output 1, is then com-\ntrain pred\npared to the actual training data to calculate the residuals, Algorithm 1 Residual Learning (ResLearn) Training\nwhich capture the difference between the predicted and true Data: Timeseriessegmenteddata(SX ∈S )whereN isthe\nvalues. These residuals are passed to the second model, an N N\nsize of the segment and X is segment number\nFCNN designed to learn and predict the patterns in the\nResult: ResLearn model (M ).\nRL\nresiduals, producing a corrected prediction (res ). Both\npred initialization\npredictions from the transformer and FCNN are combined\nmodel1 = transformer() ▷ to learn short and long-term\nto form the final output (y ) of the ResLearn model. This\nout dependencies\ncombined output is then validated with the unseen validation\nmodel2 = dense() ▷ to learn residuals\ndata, improving the final prediction’s overall accuracy. The\nwhile i != X do\nResLearn training algorithm is shown in Algorithm 1. S NX train, val = splitData(SX, T )\nis a time-series data segment, where N is the segment size Ni R\nmodel1.Train(train)\nand X is the number of segments. For each segment, the\nT = model1.Predict(train) ▷ predicts the data\nPR\ndata is split into training and validation sets. The transformer\nRes = train - T\nPR\nmodel is trained on the training set, and its predictions, T ,\nPR Res = |min(Res)| ▷ bias to identify peaks\nB\nare computed. The residuals, representing the error between\nresidualTrain = Res + Res\nB\nthe actual and predicted values, are calculated and adjusted\nmodel2.Train(residualTrain)\nby adding a bias, Res , to highlight essential peaks. The\nB M = model1 + model2\nRL\ndense model is then trained on these residuals, and the final\nRes = M .Predict(val)\nPR RL\nResLearn model, M , is created by combining the outputs\nRL error metrics(val, Res ) ▷ calculates all error metrics\nPR\nof both models. The combined model is then evaluated on the\ni++\nvalidation set using error metrics. The process is repeated for end\neachsegment,refiningthepredictionaccuracyiterativelyuntil return M\nRL\nthe validation error is stabilized for M . The algorithm’s\nRL\noutput is the final ResLearn model M , which integrates\nRL\nthe strengths of both models to deliver improved predictive IV. EXPERIMENTATIONSETUPANDRESULTS\nperformance. A. Datasets and predictability\nThe time complexity of the ResLearn algorithm, which The experiments are designed to evaluate the performance\ninvolves training a transformer model and a FCNN, can of various VR, AR, and MR services across three datasets, as\nbe approximated as follows: the training complexity of the showninTableI.TheDatasetI[15](in-housedataset)focuses\ntransformer model is typically O(T · N2), where T is the on diverse services, including gaming, video streaming, and\nnumber of training epochs and N is the sequence length. communication (chat/VoIP), and is tested with applications\nThe training complexity of the FCNN can be approximated such as Dirt Rally 2.0, Bigscreen, VR Chat, Solar System,\nas O(T′·N·D), where T′ is the number of epochs, D is the and Reality Mixer. Figure 4 shows the testbed used in the\nnumber of neurons in the hidden layer, and N represents the data capture. In the testbed, a virtual desktop streamer (VDS)\nnumber of training samples [21]. Considering X segments of rendering platform is used for the setup. A cloud computer\ndata, the overall time complexity of the algorithm is given by with a VDS server is a rendering device to which the VDS\nO(X·(T ·N2+T′·N ·D)). client on the Oculus Quest 2 is connected. Traffic manager\np\nFig. 4: Experimental platform used for data capture. Fig. 5: frame size time series data with roll-over averaging\nwindow.\nis used to simulate low latency networks to replicate real- TABLE I: Datasets and plan of experiments.\nworld scenarios. Traffic is captured on the cloud computer\nExp. services Applications\nusing Wireshark. More details and packet captures (pcap) are\nDirtRally2.0,Bigscreen,\nVRGame,VRVideo,\navailable at [15]. Dataset II [8] examines slow and fast VR exp.1 VRChat,SolarSystem,\nVRchat/VoIP,AR,MR\ntrafficusingSteamVRHomeandBeatSabertostudytheim- RealityMixer\npact of different traffic patterns. Dataset III [22] involves two\nexperiments: the first explores fast and slow VR traffic across exp.1 SlowVRTraffic,Fast SteamVRHome,Beat\nVRTraffic Saber\nBeat Saber, Medal of Honor, Forklift Simulator, and Cooking\nSimulator,whilethesecondfocusesonasubsetofapplications\n(ForkliftSimulator,CookingSimulator,BeatSaber,andMedal FastVRTrafficGame1,\nBeatSaber,Medalof\nFastVRTrafficGame2,\nofHonor)toassessnetworkperformanceundervaryingtraffic exp.1 Honor,ForkliftSim,\nSlowVRTrafficGame1,\nconditions further. We use 50% of data for training, in which SlowVRTrafficGame2 CookingSim.\n20% of the data is used for validation. Another 50% of the SForkliftSim,Cooking\nSlowVRTraffic,Fast\nexp.2 Sim,BeatSaber,Medalof\ndata is used for testing. The solution is developed in Python VRTraffic\nHonor\nusing data science libraries such as Scikit-learn (Sklearn),\nNumPy, and Pandas. The implementation is available at [17].\nThe experiments are conducted on a Windows system with an (Root Mean Squared Error), MAPE (Mean Absolute Percent-\nNvidia RTX2800S GPU. The Windows environment is set up age Error), and SMAPE (Symmetric Mean Absolute Percent-\nwithAnacondatosupportmachinelearninglibraries,including age Error). These metrics quantify the differences between\nTensorFlow. predicted and actual traffic values, aiding in assessing the\nThe analysis of data predictability begins with an ex- model’s accuracy. The RMSE measures the square root of\nploratory data analysis (EDA) that suggests randomness, the average squared differences between predicted and actual\nshowninFigure5depictedbyblueline,inthenetworktraffic values, emphasizing more significant errors, and is given by:\ndata. Runs test is a statistical procedure which determines\nwhether a sequence of data within a given distribution have (cid:118)\n(cid:117) n\nbeen derived with a random process or not [23]. Runs test of RMSE =(cid:117) (cid:116) n1 (cid:88) (yˆ i−y i)2,\nthe raw data provides a p-value of 0.15, which indicates no\ni=1\nsignificantevidenceagainstthenullhypothesisofrandomness.\nHowever, a deeper examination using decomposition tech- where yˆ i represents the predicted value, y i is the actual\nniques reveals underlying patterns in the time series, breaking value, and n is the number of predictions. The MAPE is used\nit down into trend, seasonal, and residual components. This is to compute the average percentage error, offering an intuitive\nfurtherreinforcedbyapplyingarollingwindowaverage(with interpretation of prediction errors, and is formulated as:\na window size of 20), where the rolling mean (depicted by\nn (cid:12) (cid:12)\nthe red line in Figure 5) closely follows the shape of the data,\nMAPE =\n100%(cid:88)(cid:12) (cid:12)y i−yˆ i(cid:12)\n(cid:12).\nrevealingacleartrend.ThecorrespondingRunstest,nowwith n (cid:12) y i (cid:12)\ni=1\na p-value close to zero, confirms that the data is predictable\nand not random. Rolling statistics effectively uncovers this Lastly, SMAPE provides a symmetric approach to percent-\nstructure, making the data suitable for forecasting models. age error by accounting for both over- and under-predictions.\nIt is computed as:\nB. Performancce Metrics\nn\nThe performance of Metaverse network traffic prediction\nSMAPE =\n1 (cid:88) |yˆ i−y i|\n.\nmodels can be evaluated using the following metrics: RMSE n (|yˆ|+|y |)/2\ni i\ni=1\nItesataD\nIItesataD\nIIItesataD\nTABLE II: Performance for frame size from Dataset I TABLE III: Performance for frame count from Dataset II\nMetrics Metrics\nModel Model\nRMSE MAPE SMAPE RMSE MAPE SMAPE\nNon-ResidualAlgorithm Non-ResidualAlgorithm\nTransformer 4872.49 0.0078 0.78 Transformer 0.042 0.0072 0.72\nLSTM 4904.88 0.0079 0.79 LSTM 0.042 0.0073 0.73\n%SMAPEImprovement %SMAPEImprovement\nGRU 4915.61 0.0079 0.79 GRU 0.043 0.0076 0.76\nStackedLSTM 4929.88 0.0079 0.79 StackedLSTM 0.043 0.0076 0.77\nResLearnSolution ResLearnSolution\nTransformer 2164.95 0.0024 0.24 68.87% Transformer 0.018 0.0020 0.20 71.85%\nLSTM 2725.03 0.0034 0.34 56.78% LSTM 0.017 0.0023 0.23 68.67%\nGRU 2786.97 0.0031 0.31 61.04% GRU 0.018 0.0025 0.25 67.09%\nStackedLSTM 3666.30 0.0046 0.46 41.78% StackedLSTM 0.019 0.0022 0.22 71.72%\nNote: The top table provides results for the Non-residual version\nof the model in which residuals are not learned. The bottom table\nTABLE IV: Performance for frame IAT from Dataset III exp.\nprovidestheresultoftheproposedsolution.The%SMAPEimprove-\nment is given in the fifth column. 1\nMetrics\nModel\nRMSE MAPE SMAPE\nSMAPE balances the errors across different magnitudes of Non-ResidualAlgorithm\nTransformer 0.037 0.0032 0.32\nactual and predicted values, making it particularly suitable for\nLSTM 0.034 0.0029 0.29\n%SMAPEImprovement\ndynamicenvironmentslikeMetaversetrafficprediction.These GRU 0.034 0.0030 0.30\nStackedLSTM 0.033 0.0027 0.29\nmetrics offer a comprehensive view of model performance,\nResLearnSolution\nhelping improve prediction accuracy for fluctuating network Transformer 0.029 0.0020 0.20 38.01%\ndemands. LSTM 0.030 0.0021 0.21 25.11%\nGRU 0.035 0.0025 0.25 13.74%\nStackedLSTM 0.028 0.0019 0.19 36.04%\nC. Performance Evaluation\nThe Tables II III, IV, & V present the performance eval-\nuation of various models (Transformer, LSTM, GRU, and inSMAPE,reachingover99%improvementacrossallscenar-\nStacked LSTM) across three datasets, with metrics such as ios. Similar reductions are observed in other settings, like the\nRMSE, MAPE, and SMAPE. Table II shows the performance Steam VR house 40 Mbps, where SMAPE decreased from\nfor frame size (Dataset I), Table III for frame count (Dataset 562.87 to 0.45, showcasing ResLearn’s superior accuracy.\nII), Table IV for frame IAT (Dataset III, exp 1), and Table Figure6comparestimeseriespredictionofResLearnandnon-\nV for frame size (Dataset III, exp2). Each table compares the ResLearnsolutions.Overall,theResLearnsolutionissuperior\nmodels’non-residualversion(whereresidualsarenotlearned) for network management because it accurately predicts the\nwith the residual learning approach, the ResLearn algorithm. peaks at which maximum resource is required.\nIn each case, SMAPE improvement is calculated, highlight-\ning the percentage improvement in predictive accuracy when\nresidual learning is applied. TABLE V: Performance for frame size from Dataset III exp.\nThe results indicate that the ResLearn algorithm signifi- 2\ncantly improves performance across all models and datasets,\nMetrics\nModel\nespecially regarding SMAPE. For example, the transformer RMSE MAPE SMAPE\nmodel in Table II achieves a SMAPE reduction from 0.78 to Non-ResidualAlgorithm\nTransformer 78.409 0.0103 1.04\n0.24(68.87%improvement),andasimilartrendisobservedin LSTM 74.140 0.009 0.98\n%SMAPEImprovement\nTables III and IV, where the transformer and Stacked LSTM GRU 78.014 0.0103 1.03\nStackedLSTM 78.677 0.0104 1.04\nmodels show substantial SMAPE improvements of over 70%.\nResLearnSolution\nTheobservationissimilartoDatasetIIIexp2;however,GRU Transformer 42.950 0.0041 0.41 60.69%\nis better than the transformer. This demonstrates that residual LSTM 42.860 0.0041 0.41 58.08%\nGRU 40.724 0.004 0.40 61.39%\nlearning can enhance the accuracy of time series models, StackedLSTM 48.184 0.0042 0.42 60.1%\nparticularlyforthetransformerarchitecture,makingitthemost\neffective among the evaluated models across all datasets.\nTABLE VI: SMAPE comparison between Transfer Learning\nSoA and ResLearn Solution\nD. Performance Comparision and Discussion\nTransfer %SMAPE\nThecomparisonofSMAPEbetweentheSoAtransferlearn- Traffic LearningSoA ResLearn Improve-\ningmodel[14]andtheproposedResLearnsolution(TableVI) [14] ment\nBeatSaber40Mbps 404.05 0.36 99.91%\ndemonstratesasignificantperformanceimprovementinfavour\nBeatSaber54Mbps 285.29 1.01 99.64%\nof ResLearn. In various traffic conditions, as considered in\nBeatSaber120Mbps 371.82 0.15 99.95%\n[14],suchasBeatSaberandSteamVRhouseatdifferentMbps SteamVRhouse40Mbps 562.87 0.45 99.92%\nrates, ResLearn consistently achieves a near-perfect reduction SteamVRhouse54Mbps 404.41 0.69 99.82%\n[4] Qualcomm,“Themobilefutureofextendedreality(XR),”https://www.\nqualcomm.com/content/dam/qcomm-martech/dm-assets/documents/\nawe 2017 - the mobile future of extended reality -for pdf 1.pdf,\n112020,(Accessedon08/14/2024).\n[5] Roblox,“Robloxpartnerswithsonymusicentertainmenttobringtheir\nartists into the metaverse,” https://corp.roblox.com/newsroom/2021/07/\nroblox-partners-sony-music-entertainment-bring-artists-metaverse, 06\n2021,(Accessedon08/14/2024).\n[6] A. Musamih, I. Yaqoob, K. Salah, R. Jayaraman, Y. Al-Hammadi,\nM.Omar,andS.Ellahham,“Metaverseinhealthcare:Applications,chal-\nlenges, and future directions,” IEEE Consumer Electronics Magazine,\n(a) (b) vol.12,no.4,pp.33–46,2022.\n[7] H. Wang, H. Ning, Y. Lin, W. Wang, S. Dhelim, F. Farha, J. Ding,\nand M. Daneshmand, “A survey on the metaverse: The state-of-the-\nart,technologies,applications,andchallenges,”IEEEInternetofThings\nJournal,vol.10,no.16,pp.14671–14688,2023.\n[8] S.Zhao,H.Abou-zeid,R.Atawia,Y.S.K.Manjunath,A.B.Sediq,and\nX.-P.Zhang,“Virtualrealitygamingonthecloud:Arealitycheck,”in\n2021IEEEGlobalCommunicationsConference(GLOBECOM). IEEE,\n2021,pp.1–6.\n[9] I. T. Feldstein and S. R. Ellis, “A simple video-based technique for\nmeasuringlatencyinvirtualrealityorteleoperation,”IEEETransactions\nonVisualizationandComputerGraphics,vol.27,no.9,pp.3611–3625,\n2020.\n(c) (d) [10] M.Li,J.Gao,C.Zhou,X.Shen,andW.Zhuang,“Userdynamics-aware\nedge caching and computing for mobile virtual reality,” IEEE Journal\nFig. 6: (a) ResLearn prediction of 18th segment for Dataset I, ofSelectedTopicsinSignalProcessing,vol.17,no.5,pp.1131–1146,\n2023.\n(b) 18th segment prediction from non-ResLearn solution, (c)\n[11] Y. S. K. Manjunath, S. Zhao, X.-P. Zhang, and L. Zhao, “Time-\nResLearn’sOverallpredictionofDatasetI,(d)non-ResLearn’s distributed feature learning for internet of things network traffic clas-\noverall prediction of Dataset I. All four figures are predicted sification,”IEEETransactionsonNetworkandServiceManagement,p.\n”earlyaccess”,2024.\nforframesize.ResLearnissignificantlybetteratpredictingthe\n[12] W.Luo,W.Liu,D.Lian,andS.Gao,“Futureframepredictionnetwork\npeak necessary for network management for higher resource for video anomaly detection,” IEEE Transactions on Pattern Analysis\nconsumption. andMachineIntelligence,vol.44,no.11,pp.7505–7520,2022.\n[13] M. Jin, H. Y. Koh, Q. Wen, D. Zambon, C. Alippi, G. I. Webb,\nI.King,andS.Pan,“Asurveyongraphneuralnetworksfortimeseries:\nForecasting, classification, imputation, and anomaly detection,” IEEE\nV. CONCLUSIONANDFUTUREWORK TransactionsonPatternAnalysisandMachineIntelligence,2024.\n[14] S.Vaidya,H.Abou-Zeid,andD.Krishnamurthy,“Transferlearningfor\nOur work significantly advances Metaverse network traffic onlinepredictionofvirtualrealitycloudgamingtraffic,”inGLOBECOM\n2023-2023IEEEGlobalCommunicationsConference,2023,pp.4668–\nprediction by introducing a comprehensive, real-world dataset\n4673.\nanddevelopingnovelalgorithmsincludingtheview-frameand [15] Y.S.KurubaManjunath,L.Zhao,andX.-P.Zhang,“Metaversenetwork\nResLearnalgorithms.ThesealgorithmsenableISPstomanage traffic for classification and prediction,” 2024. [Online]. Available:\nhttps://dx.doi.org/10.21227/0qs9-f852\nnetwork resources in an effective manner, satisfying the QoS\n[16] A.Vaswani,“Attentionisallyouneed,”AdvancesinNeuralInformation\nandenhancingtheuserexperienceforMetaverseapplications. ProcessingSystems,2017.\nGiven that our solution substantially reduces prediction errors [17] Y.S.K.Manjunath,M.Szymanowski,andA.Wissborn,“yoga-suhas-\nkm/reslearn: Reslearn: Transformer-based residual learning for meta-\nabout 99% than the SoA [14], future work can focus on\nverse network traffic prediction,” https://github.com/yoga-suhas-km/\nexpanding the dataset to cover a broader range of Metaverse ResLearn,(Accessedon10/11/2024).\napplications and environments, integrating advanced AI tech- [18] Meta,“Setupandconnectmetaquestlinkandairlink—metastore,”\nhttps://www.meta.com/help/quest/articles/headsets-and-accessories/\nniques to improve prediction accuracy further, and exploring\noculus-link/connect-with-air-link/,(Accessedon10/08/2024).\nreal-time deployment in diverse network architectures. Addi- [19] V.Desktop,“Virtualdesktopstreamer,”https://www.vrdesktop.net/,(Ac-\ntionally, adaptive algorithms for dynamic resource allocation cessedon09/29/2024).\n[20] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage\nin response to traffic fluctuations will be investigated for en-\nrecognition,”in2016IEEEConferenceonComputerVisionandPattern\nhancing the robustness in provisioning Metaverse ecosystem. Recognition(CVPR),2016,pp.770–778.\n[21] B. Shah and H. Bhavsar, “Time complexity in deep learning models,”\nProcediaComputerScience,vol.215,pp.202–210,2022.\nREFERENCES [22] S. Baldoni, F. Battisti, F. Chiariotti, F. Mistrorigo, A. B. Shofi,\nP.Testolina,A.Traspadini,A.Zanella,andM.Zorzi,“Questset:AVR\n[1] E.KontogianniandL.Anthopoulos,“Towardsastandardizedmetaverse datasetfornetworkandqualityofexperiencestudies,”inProceedingsof\ndefinition:Empiricalevidencefromtheitumetaversefocusgroup,”IEEE the15thACMMultimediaSystemsConference,ser.MMSys’24,2024,p.\nEngineeringManagementReview,2024. 408–414.[Online].Available:https://doi.org/10.1145/3625468.3652187\n[2] A.SuhandJ.Prophet,“Thestateofimmersivetechnologyresearch:A [23] C.Asano,“Runstestforacirculardistributionandatableofprobabil-\nliteratureanalysis,”ComputersinHumanbehavior,vol.86,pp.77–90, ities,”AnnalsoftheInstituteofStatisticalMathematics,vol.17,no.1,\n2018. pp.331–346,1965.\n[3] E. Ekudden, “Future network trends driving universal metaverse\nmobility,” https://www.ericsson.com/4a7138/assets/local/reports-papers/\nericsson-technology-review/docs/2022/technology-trends-2022.pdf,\n2022,(Accessedon08/14/2024).",
    "pdf_filename": "ResLearn_Transformer-based_Residual_Learning_for_Metaverse_Network_Traffic_Prediction.pdf"
}