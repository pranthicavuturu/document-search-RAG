{
    "title": "Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Intelligence",
    "context": "",
    "body": "0 \n \n \nMatti Pietikäinen and Olli Silvén  \nCHALLENGES OF \nARTIFICIAL INTELLIGENCE: \nFROM MACHINE LEARNING \nAND COMPUTER VISION TO \nEMOTIONAL INTELLIGENCE \n \n \n \nCenter for Machine Vision and Signal Analysis (CMVS) \nUniversity of Oulu \nhttps://www.oulu.fi/cmvs/ \n \n \n \n \n\n1 \n \n \n \nCHALLENGES OF ARTIFICIAL INTELLIGENCE - \nFROM \nMACHINE \nLEARNING \nAND \nCOMPUTER \nVISION TO EMOTIONAL INTELLIGENCE \n \nAuthors of the book: \nMatti Pietikäinen is Professor Emeritus at the University of \nOulu's Center for Machine Vision and Signal Analysis (CMVS). \nHe is a pioneer in Finnish machine vision research - investigating \nand teaching artificial intelligence since the early 1980s. He is \none of Finland's most cited researchers in technology and \ncomputing, and has received several major international awards \nand honors, most recently King-Sun Fu Prize (2018) and Highly \nCited Researcher (2018). \nBiography: Matti Pietikäinen \n \nOlli Silvén is Professor of Signal Processing Engineering at the \nCenter for Machine Vision and Signal Analysis. He has been \nstudying machine vision and artificial intelligence since 1981. In \nparticular, he has focused on technologies and implementations \nof real-time energy-efficient machine vision systems and \nindustrial applications. Since 2018, he has lectured on the highly \npopular course Introduction to Artificial Intelligence at the \nUniversity of Oulu. \nBiography: Olli Silvén \n© Copyright: Authors and University of Oulu \nPublisher: Center for Machine Vision and Signal Analysis, \n                   First edition in English, December 2021 \nISBN: 978-952-62-3199-0 (electronic publication) \nWWW: http://urn.fi/urn:isbn:9789526231990 \n \n\n1 \n \n \n \n \nForeword \n \nArtificial intelligence has become a part of everyday conversa-\ntion and our lives. It is considered as the new electricity that is \nrevolutionizing the world. Artificial intelligence is heavily in-\nvested in both industry and academy. Artificial intelligence tech-\nnology leaders like Google, Facebook and Amazon are growing \nand their dominance is already causing concern. The United \nStates has been a leading country in both research and applica-\ntion of artificial intelligence, but China, which is investing heav-\nily in the topic, is expected to surpass it in the next few years. \nArtificial intelligence is feared to take a lot of jobs, and even in \nthe next few decades, it is believed to become super-intelligent  \n- and to take power from people. \nHowever, there is also a lot of hype in the current artificial intel-\nligence debate. There is often talk of artificial intelligence even \nin a context that does not actually represent actual artificial in-\ntelligence, but rather the regular evolution of digital technology \ntowards more advanced functionalities. The combination of dif-\nferent technologies enables the development of completely new \ntypes of applications that mimic intelligent operations, human-\noid robots being futuristic examples. Artificial intelligence based \non so-called deep learning has achieved impressive results in \nmany problems, but its limits are already visible. Artificial intel-\nligence has been under research since the 1940s, and the industry \nhas seen many ups and downs due to over-expectations and re-\nlated disappointments that have followed. \nThe purpose of this book is to give a realistic picture of artificial \nintelligence, its history, its potential and limitations. We believe \nthat artificial intelligence is a helper - not a ruler of humans. We \nbegin by describing what artificial intelligence in the true sense \nof the word is and how it has evolved over the decades. After \nfundamentals, we explain the importance of massive data for the \ncurrent mainstream of artificial intelligence. The most common \nrepresentations for artificial intelligence, methods, and machine \nlearning are covered. In addition, the main application areas are \nintroduced. \nComputer vision has long been central to the development of ar-\ntificial intelligence. The book provides a general introduction to \ncomputer vision, and includes an exposure to the results and ap-\nplications of our own research. Emotions are central to human \nintelligence, but little use has been made in artificial intelligence. \n\n2 \n \nIn this book we present the basics of emotional intelligence and \nour own research on the topic. \nWe discuss super-intelligence that transcends human under-\nstanding, explaining why such achievement seems impossible on \nthe basis of present knowledge, and how artificial intelligence \ncould be improved. Finally, a summary is made of the current \nstate of artificial intelligence and what to do in the future. \nIn most countries, the growing importance of artificial intelli-\ngence skills has been noted over the last few years. In the appen-\ndix of the book, we look at the development of artificial intelli-\ngence education, especially from the perspective of contents at \nour own university.  \nThis book is based on the authors' 40 years of experience in cut-\nting-edge research, teaching and application of artificial intelli-\ngence and machine vision to a variety of problems. The book is \nintended for a wide range of readers: high school students, \nhigher-education students, researchers, professionals working in \nindustry or elsewhere, anyone interested in artificial intelligence \n– including the decision-makers. \nMuch of the content of the book is based on the work of our re-\nsearch group over the past decades, as evidenced by literary ref-\nerences and artwork. The first edition in Finnish was published \nin November 2019.  We received valuable content suggestions \nfor it from Satu Räsänen, Janne Heikkilä, Guoying Zhao and \nTapio Seppänen, Li Liu, Tuomas Holmberg and Jie Chen as-\nsisted with the illustration. We also got useful comments from \nPirkko Ekdahl and Tuukka Bogdanoff. We are grateful to all \nthose who supported us in the completion of the book! For this \nEnglish edition Google Translate based on artificial intelligence \nwas used to produce the first translated versions of the text for \nmost of the chapters, and then edited by the authors. Additional \nmaterial written for the second Finnish edition to be published in \nearly 2022 is also included. \n \n \nMatti Pietikäinen                                                   Olli Silvén \n \n \n \n \n \n \n\n3 \n \n \nTable of Contents \nForeword .................................................................................... 1 \nTable of Contents ....................................................................... 3 \n1 \nIntroduction ........................................................................ 5 \n1.1 About Artificial Intelligence ....................................... 5 \n1.2 Artificial Intelligence Hype in Finland ....................... 6 \n1.3 Data and Machine Learning in Central Roles ............. 7 \n1.4 On the Impact of and Investing in AI .......................... 9 \n1.5 Machine Vision Research at the University of Oulu. 11 \n1.6 The Risks and Challenges of AI ................................ 12 \n1.7 Realism is Needed instead of Hype in AI ................. 13 \n1.8 References ................................................................. 15 \n2 \nWhat is AI and How has it Progressed? ........................... 17 \n2.1 What is AI?................................................................ 17 \n2.2 Symbolic AI  vs. Connectionist Neural Networks .... 20 \n2.3 Central Areas of AI ................................................... 22 \n2.4 Weak and Strong AI – or Super AI? ......................... 23 \n2.5 History of Artificial Intelligence ............................... 23 \n2.6 A Summary of AI History ......................................... 37 \n2.7 References ................................................................. 39 \n3 \nArtificial Intelligence Representation Methods ................ 44 \n3.1 Introduction ............................................................... 44 \n3.2 Symbolic Artificial Intelligence ................................ 45 \n3.3 Data-driven Artificial Intelligence ............................ 47 \n3.4 Symbolic + Data-driven Artificial Intelligence ......... 48 \n3.5 Representation of Information .................................. 50 \n3.6 What Matters: Presentation, Data, or Algorithms? ... 64 \n3.7 References ................................................................. 64 \n4 \nMachine Learning ............................................................. 66 \n4.1 Introduction to Data-driven Machine Learning ........ 66 \n4.2 Processing of Data ..................................................... 68 \n4.3 Supervised Learning .................................................. 69 \n4.4 Learning Classification ............................................. 74 \n4.5 Deep Learning and Convolutional Neural Networks 83 \n4.6 Unsupervised Learning ............................................. 90 \n4.7 Reinforcement Learning ............................................ 94 \n4.8 Recurrent Neural Networks (RNN)........................... 97 \n4.9 GAN – Generative Adversarial Network .................. 99 \n4.10 Measuring Machine Learning Outcomes .................. 99 \n4.11 References ............................................................... 102 \n5 \nArtificial Intelligence Applications ................................ 104 \n5.1 Speech Recognition and Personal Assistants .......... 106 \n5.2 Natural Language Processing .................................. 109 \n5.3 Playing Games......................................................... 111 \n5.4 Self-driving Vehicles............................................... 113 \n5.5 Big Data Analytics and Data Fusion ....................... 115 \n5.6 Medical Applications .............................................. 117 \n5.7 Audiovisual Video Content Retrieval ..................... 120 \n\n4 \n \n5.8 References ............................................................... 121 \n6 \nComputer Vision - The Engine for AI Research ............ 124 \n6.1 General about Computer Vision .............................. 124 \n6.2 Steps of the Traditional Computer Vision Process . 125 \n6.3 Current Research Areas ........................................... 130 \n6.4 Computer Vision Changing our Everyday Lives .... 135 \n6.5 Center for Machine Vision and Signal Analysis ..... 137 \n6.6 References ............................................................... 139 \n7 \nLocal Binary Pattern – a Breakthrough .......................... 141 \n7.1 Local Binary Pattern Method .................................. 141 \n7.2 LBP in Face Recognition ........................................ 145 \n7.3 LBP: Present and Future ......................................... 146 \n7.4 References ............................................................... 149 \n8 \nTowards Machine Vision Applications .......................... 151 \n8.1 Visual Quality Control ............................................ 152 \n8.2 Face Analysis and Biometric Identification ............ 155 \n8.3 3-D Computer Vision and Augmented Reality ....... 164 \n8.4 Machine Perception in Human-robot Interaction .... 167 \n8.5 Machine Vision in Medical Image Analysis ........... 174 \n8.6 References ............................................................... 176 \n9 \nEmotion AI – the Next Breakthrough? ........................... 179 \n9.1 Introduction ............................................................. 179 \n9.2 Cognition and Emotions Go Hand in Hand ............ 182 \n9.3 Applications of Emotion AI .................................... 183 \n9.4 Facial Expressions in Emotion Recognition ........... 186 \n9.5 Micro-expressions and their Identification ............. 189 \n9.6 Threats and Practical Problems ............................... 193 \n9.7 Challenges and Future Perspectives ........................ 194 \n9.8 References ............................................................... 196 \n10 Is Super-intelligence a Threat? ....................................... 199 \n10.1 Super-intelligence and Risks of AI ......................... 199 \n10.2 Significant Limitations with Current AI ................. 201 \n10.3 Artificial vs. Human Intelligence ............................ 206 \n10.4 How from Now on Towards Strong AI? ................. 209 \n10.5 References ............................................................... 213 \n11 Summary - Does the AI Hype Continue? ....................... 214 \n11.1 Artificial Intelligence Today ................................... 214 \n11.2 Prospects and Challenges for AI ............................. 218 \n11.3 References ............................................................... 222 \nAppendix L1: What should be Taught about AI? .................. 225 \nTable of Figures ..................................................................... 235 \n \n \n \n\n5 \n \n1 Introduction \n1.1 \nAbout Artificial Intelligence \nDid you notice when Netflix recommended you a TV show you \nmight like? Did you notice that the customer service agent Chris \nwas really a chatbot? Or did you know that in industry the quality \nof products has already long been monitored with artificial intel-\nligence technologies? Artificial intelligence has become a part of \nour daily lives, and its impacts extend beyond everything (Pie-\ntikäinen et al., 2017). \nWe are in the midst of artificial intelligence hype. Undeniably, \nartificial intelligence and machine learning are prerequisites for \na new industrial revolution in which machines are helping or \neven replacing humans in advanced functions. Modern artificial \nintelligence systems learn through massive training data and be-\ncome capable of identifying objects and making accurate predic-\ntions. Examples of recent developments include the ability of de-\nvices to recognize speech, predictive text input, better language \ntranslation programs, advanced Internet search engines that \nshow you tailored ads and recommendations, intelligent robots, \ncomputer vision based recognition of faces and other objects, as \nwell as the development of driver’s assistance systems and au-\ntonomous vehicles. \nArtificial intelligence creates opportunities to improve the en-\nergy efficiency of societies. It can promote people's learning, \nsafety and health by enabling machines and the environment to \nadapt their actions to emotional states and behaviors. \nOn the other hand, artificial intelligence can be used to influence \npeople, infamously demonstrated by Cambridge Analytica in the \n2016 US presidential election, which polarized voters' attitudes \nby targeting news and fake news based on people's media behav-\nior. This has contributed to the regulatory requirements of tech-\nnology (Hern, 2018). \nArtificial intelligence can be defined in many ways. Regardless \nof the definition, artificial intelligence research has two main ob-\njectives: to make computers more usable, and to understand the \nprinciples that make intelligence possible. During the recent ar-\ntificial intelligence boom it has been suggested that the term \n“machine learning” should be used instead of artificial intelli-\ngence. However, learning is only one, albeit essential, part of in-\ntelligent activity and artificial intelligence, so such a definition \nis neither correct nor complete. For example, a human being has \nnearly 100 billion neurons in the central nervous system, but the \nrest of the body has much more for sensory perception, motor \nfunctions, and information transfer. \n\n6 \n \nSince the early days of artificial intelligence research, the subject \nhas been approached in two different ways: through symbolic \ndata processing and data-driven connectionist neural networks. \nSymbolic artificial intelligence derives its name from the aim to \nrepresent properties of a phenomenon or object by symbols that \nare abstractions of the observations. Symbolic artificial intelli-\ngence builds databases and rules for how the world associated \nwith that problem is working. \nSymbolic processing is particularly well suited for reasoning and \nusing  abstractions  in problem solving. The artificial intelligence \nhype of the 1980s was based on rule-based expert systems, using \nsymbolic artificial intelligence for applications such as medical \ndiagnoses or legal advice. The big problem was that creating and \nteaching the systems had to be done largely manually. However, \nthe systems could justify how they reached the conclusions. \nArtificial neural networks are based on data-driven connectionist \ncomputing. They consist of simple computing elements that are \nconnected to each other, resembling human nerve tissue, and can \nbe taught. Recent developments in artificial intelligence are \nbased on deep learning neural networks that are able to automat-\nically classify objects in the image, recognize speech, or, for ex-\nample, make predictions of market developments based on ex-\namples. The main problem is that huge amounts of examples are \nrequired for training, and the systems can’t justify their deci-\nsions. While even a common housefly appears to learn from a \nsingle example, deep learning, at least in its present form, does \nnot seem to be a future-proof machine learning model. \n1.2 \nArtificial Intelligence Hype in Finland \nIn the 1980s the first artificial intelligence enthusiasm spread to \nFinland. In Spring 1984, Tekes, the National Technology \nAgency, launched the FINPRINT IT Development Program. The \naim was to achieve and maintain international competitiveness, \nespecially in the IT hardware and software industry (Tekes: \nTekoäly 1985-89). Of its five subprograms, two were related to \nartificial intelligence: 1) Artificial intelligence (Linnainmaa, \n1989) and 2) Pattern recognition applications (Rämö, 1988). \nNow watching the FINPRINT-motivated A-Studio TV program \nfrom 1988, the optimism and the applications considered at that \ntime were very similar to the current ones: military intelligence, \nintelligent weapons and Star Wars, disability technology, nu-\nclear power plant monitoring, Finnish language database inter-\npreter, restoration of works of art, and planning cancer treatment. \nThe main technology was mostly rule-based expert systems, to \nwhich human experts' knowledge had to be brought largely man-\nually. However, learning neural network systems were already \nseen as a future trend. Even then, ethical issues related to strong \n\n7 \n \nartificial intelligence resembling human intelligence were dis-\ncussed. The Encyclopedia of Artificial Intelligence, which pre-\nsents the different areas of artificial intelligence in Finnish, was \npublished in 1993 (Hyvönen et al., 1993). \nTekes and the Academy of Finland have also had other programs \nin the field of artificial intelligence. Particularly important for \nmachine vision applications and our own research was the Tekes \nMachine Vision in Industrial Automation Program 1992-1996 \n(Pau & Savisalo, 1996). \nThe Pattern Recognition Society of Finland was founded in 1977 \nand the Finnish Artificial Intelligence Society (FAIS) in 1986. \nThe author of this book, Matti Pietikäinen, has been a key mem-\nber in both societies. Teaching of artificial intelligence and dig-\nital image processing was started at the University of Oulu in the \nacademic year 1982-83. The first AI course, based on Patrick \nHenry Winston's classic book Artificial Intelligence, took place \nin the Spring of 1983 (Winston, 1977). \nAt that time symbolic computing and knowledge engineering \nwere at the center of artificial intelligence. In addition to a few \nother research units, our group received a Symbolics computer \nfor the research and teaching from the Ministry of Education. \nThe computer supported symbolic processing and LISP pro-\ngramming language particularly well. \n1.3 \nData and Machine Learning in Central Roles \nIn the late 1980s, artificial intelligence established itself as a sci-\nentific discipline. The new hypotheses had to be comprehen-\nsively tested, the results analyzed, and they had to be compared \nwith previous results. The use of statistical models based on \nprobability estimation increased. We moved from the “toy \nworld” problems to real world applications. The computing \nspeed and capacity of computers increased, allowing for more \nsophisticated methods and larger amounts of data. \nWith advanced tools, deep learning neural networks can easily \nproduce impressive results in many problems. However, the per-\nformance may still fall far from the real application needs and \nmay require much more computational resources than traditional \nmethods. For this reason, developers should also explore alter-\nnative schemes that may reach the performance requirements. \nThe importance of knowing alternative approaches can be seen \nfrom a recent study by Ferrari Dacrema et al. (2019)  on neural \napproaches to recommendation systems. These are used e.g. to \npredict the \"rating\" or \"preference\" a user would give to an item, \nsuch  as in playlist generators for video and music services, prod-\nuct recommenders for services, or content recommenders for so-\ncial media platforms (Wiki-Recommender). Their study indi-\ncated that reproducing recent results published in top forums was \nvery challenging and that in this application area, most of the \n\n8 \n \nproposed modern machine learning based solutions could be out-\nperformed with much simpler heuristic methods such as nearest-\nneighbor or graph-based approaches. \nUnderstanding the fundamentals, differences, and uses of both \nsymbolic and data driven artificial intelligence is important, as \nwell as understanding the different ways of representation in AI. \nData and representation of knowledge related to the application \nproblem, search methods, feature representations describing the \nproperties of the objects, and methods for reducing the dimen-\nsions of the feature representation play a central role. The roles \nof data and knowledge are viewed crucial (Figure 1.1). \nMachine learning can be done in a variety of ways: using super-\nvised learning, unsupervised learning, or the recently much-dis-\ncussed reinforcement learning. A major breakthrough in ma-\nchine learning (Kritzhevsky et al., 2012) is based on the massive \nincrease in data available over the Internet, the rapid develop-\nment of computer hardware that enables to use it, and method \ninventions since the 1980s. Such method innovations include \nmultilayer neural network and the convolutional neural network \n(CNN) using the backpropagation algorithm and their subse-\nquent improvements. It was shown that in image recognition us-\ning multilayer learning neural network and a massive number of \ntraining samples improved the results significantly. Since then, \nmany new applications have been developed that were previ-\nously considered impossible. \n \n \n \n \n \n \n \n \nFigure 1.1. The roles of data and knowledge in artificial intelli-\ngence. \nIn the current AI boom, major technology companies such as \nGoogle, Amazon, Facebook, Microsoft, Apple, IBM, Nvidia, \nUber, and Chinese internet giants Alibaba, Baidu and Tencent \nare investing heavily in various artificial intelligence applica-\ntions and their development tools. The technology platform in-\ndustry formed by such companies and the massive amount of \ndata they own seem to dominate the industry, and their power is \nconstantly growing. It is usually necessary for other players to \nuse the platforms and computing capabilities provided by such \ncompanies to keep up with the development, which can also be \na risk to privacy. \napplication-independent algorithms \ndata and/or knowledge \nAI application \n\n9 \n \nAndrew Ng, a leading expert in deep learning said in his famous \nassessment that \"artificial intelligence is new electricity\", mean-\ning that it can revolutionize industry in the same way that elec-\ntricity once did. Technology investor Steve Jurvetson made a \nmore questionable assessment in Helsinki at Slush 2016: \"Deep \nlearning is mankind's greatest invention since the scientific \nmethod.\" “It can be used to teach a machine to do anything and \nit will revolutionize our world faster than anyone believes” (Ko-\ntilainen, 2017). \nHowever, development is significantly hampered by the increas-\ning energy consumption of the latest artificial intelligence appli-\ncations - doubling every 3-4 months according to Open AI \n(Tuomi, 2019). For example, training the best current natural \nlanguage interpretation methods have been estimated to produce \napproximately the same amount of carbon dioxide as five pas-\nsenger cars over their lifetime. \nIn the foreseeable future, artificial intelligence will, based on our \nunderstanding, be integrated with other technologies, improving \nthe functionality and usability of applications and adaptability to \nnew situations. The current hype will be replaced by regular dig-\nital technology development, where a natural step is to introduce \nsmarter features for machines and other systems. \nIn general, people want the latest technology for their smart \nphones, home appliances, and cars. The companies that can de-\nliver will grow and survive. For example, the fate of Nokia \nsmartphones was largely due to its inability to respond to Apple's \ntouchscreen user interface. Properly applied artificial intelli-\ngence can also increase security, enhance operations, save en-\nergy, etc. More generally, only companies, communities and \ncountries that are able to exploit the opportunities provided by \nnew technologies, including artificial intelligence can succeed in \nthe international competition. \nBy integrating various technologies related to artificial intelli-\ngence, such as mass data, machine learning, speech recognition, \nmachine vision and robotics, a whole new range of applications \ncan be created - a futuristic example is humanoid robots. The \nmost challenging applications consist of many integrated com-\nponents. For example, fully autonomous vehicles would require \nreliable 2-D and 3-D vision and other sensor information to work \nin changing conditions, map data, satellite navigation, extremely \nfast and reliable response to human, animal and other traffic ac-\ntions, and continuous redesign of the driving route - and machine \nlearning from all that. How, then, can we trust that such complex \nsystems will work reliably in all practical circumstances? \n1.4 \nOn the Impact of and Investing in AI \nArtificial intelligence and automation will have a significant im-\npact on many jobs. For example, robots are already replacing \n\n10 \n \nmany jobs in the industry today, and automated cash registers are \nreplacing human operated ones in stores. Amazon has recently \nintroduced a fully automated store where customers sign up with \ntheir smartphone (Leinonen, 2018). Versatile camera and sensor \nsystems monitor what each customer purchases, and the off-site \nsystem automatically bills purchases from the customer's ac-\ncount. Similar solutions requiring high sensor densities will be-\ncome more common, e.g., enabled by the future wireless com-\nmunication technologies provided by the University of Oulu's \n6G flagship program (www.oulu.fi/6gflagship/). \nMany jobs will disappear or be partially replaced by technology \nas digitalization is spreading across society. The workforce to \nimplement and maintain the new solutions needs to be educated, \npossessing the ability to orientate themselves to new tasks. Con-\nsequently, the future artificial-intelligence reliant society will \nneed data-literate citizens capable of reading, using, interpreting \nand communicating data (Executive Office, 2016). \nIn the field of artificial intelligence, major national projects have \nbeen or are being launched. The United States has been a leader \nin artificial intelligence research and development, although un-\nder President Trump’s administration, the national efforts were \nnot increased in line with President Obama's plans. Now major \ntechnology companies such as Amazon, Apple, Google, Face-\nbook and Microsoft are investing in the industry. In February-\n2019, President Trump signed a decree on artificial intelligence \nand its regulation in response to the threat posed by China in this \narea. Apparently, the provision does not apply to research and \ndevelopment. In Spring 2021 President Biden promised to in-\ncrease significantly funding of strategically central research ar-\neas, including AI.  \nProfessors Geoffrey Hinton and Yoshua Bengio, who began \ntheir careers in Canada, have been pioneers in developing deep \nlearning methods with Professor Yann LeCun. (These three sci-\nentists won The Turing Award 2018, which is often called the \nNobel Prize in computing.) The Canadian government has re-\ncently launched an extensive program to stay ahead and support \nthe development of the artificial intelligence industry in the \ncountry. \nChina has made artificial intelligence a strategic priority and in-\nvests huge amounts in AI research. Thus, it can be expected to \nreach the US level, and by the end of the 2020s it could be the \nleading developer and exploiter of artificial intelligence. Many \nother countries, such as Japan, the United Kingdom, Germany \nand the United Arab Emirates, have also prepared and launched \ntheir own national artificial intelligence programs. \nFinland, too, has responded to the major societal effects of arti-\nficial intelligence, and has begun to invest in research and appli-\ncations in the field. On 7 February 2017, the then Prime Minister \n\n11 \n \nJuha Sipilä opened a discussion session at Säätytalo (the House \nof Estates)  entitled \"How we accept artificial intelligence and its \npotential as a society\". After that, a steering group was set up to \nfind out how Finland could be promoted as the world's best pro-\nvider of artificial intelligence. Since then, several actions have \nbeen planned. A summary of these actions is presented in (Ai-\nlisto et al., 2019). \nEducation plays a key role in how we can respond to major chal-\nlenges. There has been talk of retraining up to a million Finns, \nbut this should also mean upgrading current skills to increase the \ndata literacy mentioned above. Based on our own long-term ex-\nperience, in Appendix L1 we present what should be taught to a \nwider audience, and what to future specialists in artificial intel-\nligence. \n1.5 \nMachine Vision Research at the University of Oulu \nMatti Pietikäinen, the first author of this book, began research on \ncomputer vision and artificial intelligence in the Fall of 1980, \nwhen he went on to do his PhD research at the University of \nMaryland for 14 months, supervised by Professor Azriel Rosen-\nfeld, a pioneer of digital image analysis and machine vision. The \nstudy was on the classification of textures that tell about the sur-\nface structure of objects in the images. Inspired by excellence in \nguidance and a highly international research environment, he de-\nfended his dissertation in Oulu in May 1982. After returning to \nOulu from Maryland in late 1981, he subsequently founded the \nMachine Vision Research group, which later became a highly \nrespected research unit in its field internationally. \nOlli Silvén, the co-author of the book, was recruited as the first \ngraduate student in the new group in December 1981. After earn-\ning his doctoral degree, he has played a key role in many of the \nresearch group's projects, particularly in those focusing on ma-\nchine vision applications. In Spring 2018, he held the first Intro-\nduction to Artificial Intelligence course for University of Oulu \nstudents representing all backgrounds. The contents of the \ncourse form the basis of chapters on the fundamentals of artifi-\ncial intelligence (Chapters 3 and 4) in this book. \nComputer vision has been the key engine of artificial intelligence \nresearch since it was linked to the deep learning breakthrough in \n2012. In this book, we generally look from the computer vision \npoint of view what has been achieved and what is going on. In \naddition, we introduce the main findings of the machine vision \nresearch at the University of  Oulu. The most significant interna-\ntional breakthrough has been the so-called Local Binary Pattern \n(LBP) method and its application to face recognition (Pie-\ntikäinen et al., 2011). LBP-related publications have been among \nthe most cited Finnish publications in the field of artificial intel-\nligence and computer science in the 2000s. \n\n12 \n \nThe major application areas of our group's research include in-\ndustrial visual quality control, biometric identification, remote \nheart rate measurement, speech recognition from mouth move-\nments, 3-D machine vision and its use in augmented reality, in-\ntelligent robots and human-machine interaction, and medical ap-\nplications. This book gives the reader a good idea of what com-\nputer vision is, what applications it can be used for, and what \nchallenges it faces. \nEmotions and empathy play a central role in human-to-human \ninteraction. Much of the communication between people is non-\nverbal: facial expressions, gestures, body movements, and vari-\nations in speech tone. \nWhen talking to an intelligent robot or chatbot, a person feels \n\"machine-like\", insensitive speech most unpleasant. The use of \nemotions, or related affective computing, is expected to be the \nnext major artificial intelligence breakthrough. Many compa-\nnies, such as Affectiva, Microsoft, Apple and Google, have \nstarted investing into this domain. However, there are still many \nunresolved research challenges ahead of any large-scale deploy-\nment of technology. \nThis book discusses emotional intelligence, its applications and \nchallenges from the perspective of machine vision. For instance, \nrecognizing micro-expressions associated with hidden emotions \nis considered (Chapter 9). \n1.6 \n The Risks and Challenges of AI \nThe risks of artificial intelligence have recently been the subject \nof discussion due to the threat scenarios presented, for example,  \nby the late physicist Stephen Hawking and entrepreneur Elon \nMusk. However, we believe that artificial intelligence will be a \nhelper for humans, not a ruler. Given the significant capability \nlimitations of current artificial intelligence and machine learning \ntechnologies over human intelligence, we do not believe that any \n\"super-intelligence\" can be achieved, at least not in the foresee-\nable future. \nIn any case, the introduction of artificial intelligence involves \nmany ethical issues that need to be discussed and necessary \nmeasures taken, for example, through appropriate regulations. \nHowever, over-control, e.g., in terms of data availability, can be-\ncome a barrier to development and thus prevent Europe (and Fin-\nland) from being among the leading artificial intelligence pro-\nviders. \nOn the other hand, Finland is a society based on trust, which can \nsupport the use of advanced solutions still in their infancy. At the \nsame time, efforts must be made to locally process human infor-\nmation, avoiding excessive data collection into global cloud \ncomputing centers. Promoting such developments requires long-\n\n13 \n \nterm research efforts, where the strategic focus is on the good of \nindividual citizen. \nThe machine learns from the training material provided, whether \ngood or bad. Consequently, machine learning methods have been \nfound to be vulnerable to adversarial attacks (Heaven, 2019). By \nteaching almost completely true-like but falsified data, the sys-\ntems can be made to produce false results. This can be a major \nproblem, for example, in medical applications, self-driving ve-\nhicles, or weapons systems (Finlayson et al., 2019). \nThere are also high risks associated with applications where ma-\nchine learning and artificial intelligence may not play a key role. \nThese include combining vast amounts of information from mul-\ntiple sources and creating a accurate profiles of individuals. The \nresults can be used for both good and bad. The sources of infor-\nmation range from social media behavior, Internet searches, \nshopping data, health services, and banking. In these cases, de-\ncentralization provides at least moderate protections against se-\ncurity disasters. \nPrivacy also needs to be taken care of, for example, when using \nconcealed face recognition or other identity disclosure technol-\nogy. Information security is best ensured by solutions where ma-\nchine learning and human-centered analytics are done with re-\nsources embedded solely in a vehicle, a room, or even wearable \ntechnology.   \nSuch a potential privacy-driven development would clearly fa-\nvor a different kind of earning logic than the current one of the \nInternet giants. They are determined to protect their centralized \nmodel, which also appears to be in the interests of many super-\npowers. \nFinland's special strengths in the development of distributed ar-\ntificial intelligence applications are strongly linked to the exper-\ntise in embedded information and communications technology \nrequired by the Internet of Things (IoT). However, utilizing this \nrequires strategic choices and targeted research funding. \n1.7 \nRealism is Needed instead of Hype in AI \nArtificial intelligence as discipline has experienced many hype \nseasons and winters throughout its history. The current artificial \nintelligence boom is based almost exclusively on deep neural \nnetwork technology, the potential of which could have been \noverlooked without an increase in the supply of mass data. That \nis why Google, Amazon, Facebook, Apple and other big players \nwho have obtained data from the Internet have been at the fore-\nfront of development. Applications with no or limited mass data \nhave received less attention. \n\n14 \n \nThis has clearly not been understood, but artificial intelligence \nresearchers have largely focused on experimenting with and tun-\ning deep learning schemes. Even the pioneer of deep learning, \nProfessor Geoffrey Hinton, has recently admitted, like Max \nPlanck, a physicist, that \"science progresses from one funeral at \na time\" (LeVine, 2017). \nFigure 1.2 shows the peaks of AI development over the decades. \nThese will be addressed in later chapters of the book. We will \nalso look at how artificial intelligence should be developed to be \nbetter, and more like human intelligence, to achieve the next \nbreakthrough. \nExperts know the limitations of current artificial intelligence \ntechnology, to which it can be applied well and poorly. They also \nknow that it will at some point be replaced or supplemented with \nbetter solutions. Without an effective link between top expertise \nin research and application developers, we are easily in the same \nsituation as with expert systems based on processing symbolic \ninformation in the 1980s. Everyone tried to apply them, but in \nthe end, the biggest winners were tool and platform developers. \n \n \n \n \n \n \n \n \n \n \nFigure 1.2. AI hype cycles over time. (© 123RF) \nFor example, the authors of this book, living in northern condi-\ntions, do not believe in the introduction of vehicles that are com-\npletely autonomous in changing traffic and weather. There are \nenormous expectations, but also complex technical challenges \nand ethical issues that appear unsurmountable. It would be better \nfor us to focus on limited, secure application environments or \ntasks that facilitate human time. For instance, in January 2020 a \nCanadian automotive components manufacturer decided to con-\ncentrate on driver’s assistance systems instead of self-driving \n(Bickis,  2020). \nInstead of artificial intelligence a better term could be machine \nintelligence. Distinctly technological, it could better withstand \n1950s-60s: \nPerceptron in neural compu-\nting, formal logic, general \nproblem solver (GPS)  \n1970s-80s: \nRule based systems \n1960s-70s: \nNatural language  \nprocessing \n2010s-?: \nMachine learning with \ndeep neural networks \n1990s: \nNeural computing  \n\n15 \n \nhighs and lows. With the advancement of technology, applica-\ntions and systems are gaining features that appear intelligent, and \nthere is no need for actual comparison with real intelligence or \nhuman intelligence. \nAt the end of the book, we discuss what's true and hype about \ntoday's artificial intelligence. In recent years, machine learning \nand artificial intelligence applications have finally begun to \ncome to fruition. Development has been accelerated by advances \nin computing technology, particularly the Internet, which has \nprovided the ability to acquire massive data sets and thereby sup-\nported the development of AI methodology. We have witnessed \nthe departure from experiments in limited laboratory environ-\nments to global applications used by much of the humanity. \nThe objective of this book is to provide a first-hand view of the \ndevelopment, present and future of artificial intelligence, ma-\nchine vision and emotional intelligence. Because of the over-ex-\npectations of artificial intelligence, the book aims to give a real-\nistic picture of the situation today and expected developments \nover the next few years. In addition, the book introduces the ba-\nsics that anyone studying AI needs to know to understand its po-\ntential for a variety of problems. \nOur approach is largely data, methodology, technology and ap-\nplication oriented. We leave the social implications and ethical \nissues to experts in their respective fields. We think that in Finn-\nish these are well addressed in Maija-Riitta Ollila's book, \n“Tekoälyn etiikkaa” (Ethics of Artificial Intelligence), published \nin 2019 (Ollila, 2019). In English, Paula Boddington in her book \n“Towards a code of ethics for artificial intelligence” (Bodding-\nton, 2017) considers how to produce realistic and workable eth-\nical codes or regulations for AI. \n1.8 \nReferences \nAilisto H (ed.), Neuvonen A, Nyman H, Halen M & Seppälä S \n(2019) Tekoälyn kokonaiskuva ja kansallinen osaamiskartoitus \n– loppuraportti (A general view to AI and a survey on national \nknow-how – Final report). Valtioneuvoston kanslia, 15.1.2019, \n84 p. \nBickis I (2020) Magna scaling back Lyft partnership as fully \nself-driving systems look further off. Toronto Star, January 16, \n2020. \nBoddington P (2017) Towards a Code of Ethics for Artificial In-\ntelligence. Cham, Switzerland, Springer, 124 p. \nExecutive Office (2016) Preparing for the Future of Artificial \nIntelligence.  President Obama’s National Science and Technol-\nogy Council Committee on Technology, USA, 2016.  \nFerrari Dacrema M, Cremonesi P & Jannach D (2019) Are we \nreally making much progress? A worrying analysis of recent \n\n16 \n \nneural recommendation approaches. Proc. 13th ACM Conference \non Recommender Systems, 101-109. \nFinlayson SG, Bowers JD, Ito J, Zittrain JL, Beam AL & Kohane \nIS (2019) Adversarial attacks on medical machine learning. Sci-\nence 363 (6433):1287-1289. \nHeaven D (2019) Deep trouble for deep learning. Nature \n574:163-166, 10.10.2019. \nHern A (2018) Cambridge Analytica scandal “highlights need \nfor AI regulation”, Guardian 16.4.2018. \nHyvönen E, Karanta I & Syrjänen M (eds.) (1993) Tekoälyn en-\nsyklopedia (Encyclopedia of Artificial Intelligence). Gaudea-\nmus, 356 p. \nKotilainen S (2017) Tekoälyn vallankumous on alkanut – tätä \nkaikkea se tarkoittaa (The revolution of AI has begun – it \nmeans this all). Tivi 5/2017.  \nKrizhevsky A, Sutskever I &, Hinton GE (2012) Imagenet clas-\nsification with deep convolutional neural networks.  Advances \nin Neural Information Processing Systems, 1097-1105. \nLeinonen T (2018) Verkkokaupan jätti perusti kivijalkakaupan \n(The giant of e-commerce established a ground floor shop). Ka-\nleva 20.2.2018. \nLeVine S (2017) Artificial intelligence pioneer says we need to \nstart over. Communications of the ACM. \nLinnainmaa S (ed.) (1989) Tekoäly 1985-1989 (Artificial Intel-\nligence 1985-1989). IT Development Program, Tekes, 232 p. \nOllila M-R (2019) Tekoälyn etiikkaa (Ethics of Artificial Intel-\nligence). Otava, 366 p. \nPau LF & Savisalo H (1996) Machine Vision Technology Pro-\ngramme 1992-1996 – Evaluation report. Tekes Technology Pro-\ngramme Report 16/96, 34 p. \nPietikäinen M, Hadid A, Zhao G & Ahonen T (2011) Computer \nVision Using Local Binary Patterns. Springer, 207 p. \nPietikäinen M, Silvén O & Pirttikangas S (2017) Tekoälyn ope-\ntusta on lisättävä ja syvennettävä (We should have more and \ndeeper AI teaching in Finland). Helsingin Sanomat 20.4.2017. \nRämö E (ed.) (1988) Hahmontunnistuksen sovelluksia (Applica-\ntios of pattern recognition). IT Development Program, Tekes, 82 \np. \nTuomi I (2019) Sähkönkulutus on tekoälyn kompastuskivi \n(Electricity consumption is an obstacle for AI). Helsingin Sano-\nmat 31.8.2019. \nWinston PH (1977) Artificial Intelligence. 1st Edition, Addison \nWesley. \nWiki-Recommender: Recommender system  \n \n\n17 \n \n2 What is AI and How has it Progressed? \n2.1 \nWhat is AI? \nAccording to an early definition artificial intelligence is research \non issues that are needed to make computers intelligent. This \nmeans that you should first define what intelligence means. In \nanother definition, AI tackles problems for which solutions are \nnot yet known, i.e., the border between an intelligent and ordi-\nnary machine is changing. \nIn the current AI boom it has also been suggested that instead of \nAI we should talk about machine learning. Machine learning is, \nhowever, only one, albeit a very important part of intelligent be-\nhavior and AI, which means that this definition is not correct. \nIn their widely used book Stuart Russell and Peter Norvig (2010) \ndivide the definitions of AI into four different categories. These \ncan be placed as in Table 2.1 into two dimensions. \nTable 2.1 Grouping AI into different definitions \nThink like humans                     Think rationally \nAct like humans                      Act rationally \nThe definitions in the upper row are related to the processes of \nhuman thinking and decision making, whereas the lower row \ndeals with human behavior. The approaches in the left column \ncompare the success of AI to human performance. The right col-\numn is concerned with approaches that measure machine perfor-\nmance against an ideal rational measure. A system is rational \nwhen it makes right things based on the knowledge it has. \n \n \n \n \n \n \n \nFigure 2.1. The Turing test. (© 123RF) \nFor acting like humans, Alan Turing presented the following \nwidely referred method to test machine intelligence (Russell & \nNorvig, 2010). We assume that on one side of the wall is the \nevaluator of intelligence (human interrogator) and on the other \nside either a human or a machine (Figure 2.1). \nThe discussion is done, for example, with computer terminals. If \nthe interrogator concludes that he or she has been discussing with \nInterrogator \nHuman \nIntelligent machine \n\n18 \n \na human, even though the party was a computer, according to \nTuring’s definition the machine has intelligence.  \nTo pass the test, the machine has to \n1) be able for natural language processing (e.g., English or \nFinnish) needed for communication, \n2) have knowledge representations in order to store what ma-\nchine already knows or learns to know,  \n3) be able to automatic reasoning in order to use stored \nknowledge for answering questions and making new conclu-\nsions, and  \n4) use machine learning in order to adapt to new situations and \nbe able to express and generalize models from its working \nenvironment.  \nThe Turing test avoided direct human-machine interaction, as-\nsuming that intelligence can be measured based on written verbal \ncommunications. The variant called total Turing test includes \ntwo other necessary properties of an intelligent system: percep-\ntual information obtained, e.g., with a video camera sensor and \npossibility to manipulate physical objects. Therefore, we need \nalso  \n5) machine vision and other sensor data, such as speech, for per-\nception of objects, and  \n6) robotics for manipulating objects and moving in the working \nenvironment. \nThese six areas in fact form the main parts of the scientific field \ncalled Artificial Intelligence.  \nThinking like humans can be achieved in three different ways.  \n1) We can try to find the solution through our own thinking, 2) \nby using psychological tests to understand actions of another \nperson, and 3) by observing brain activities with the help of tech-\nnology.  With these means we can try to find out a good enough \ntheory about human mind, on the basis of which it would be pos-\nsible to write computer programs, for example,  to solve different \ntypes of problems. The multi-disciplinary cognitive science con-\nsiders computational AI models together with experimental \nmodels and has evolved into its own field of science. \nThinking rationally (i.e., ”the laws of thought”) principle has \nits basis in decision processes used in philosophy. For example, \n”Socrates is a human” and ”All humans are mortal”,  therefore \n”Socrates is mortal”. These kinds of laws of thought called logic \nare considered to master the actions of human mind. The prob-\nlem is that it is often very difficult to express problems to be \nsolved with logic, especially in problems containing uncertainty. \nThe computational complexity will also become far too high in \nreal-world problems.   \n\n19 \n \nActing rationally principle based on agents is utilized by Rus-\nsell ja Norvig (2010). Figure 2.2 shows the basic structure of an \nagent. An agent is anything such that percepts its environment \nwith sensors and acts in its environment with the help of actua-\ntors. Human senses include vision, hearing, touch, smell and \ntaste. Hands, legs and mouth are actuators. As sensors a robot \ncan have different types of cameras and microphones, and mo-\ntors, legs or wheels, and loudspeakers and avatar displays as ac-\ntuators. The agent can also just be a goal-oriented program, \nwhich reacts to the inputs in its working environment and auton-\nomously performs some action. A very simple agent could, for \nexample, compute the square root of a number given as input and \nreturn the result to the user or another program. \n \n \n \n \n \n \n \nFigure 2.2. A rationally acting agent. (© 123RF) \nAn intelligent agent can act autonomously percept its environ-\nment, adapt to changes, defining and pursuing goals, and contin-\nuing its own existence. The rational agent tries to achieve the \nbest possible result with the knowledge it has at each moment.  \nFor example, an autonomous mobile robot could percept its en-\nvironment using machine vision, avoid unexpected obstacles in \nfront of it and due to this action change its original route, and \nfinally find the destination where it was planned to go. The best \nresult could be the shortest or safest possible route.   \nAll the skills needed for passing the Turing test would also allow \nrational actions. With its knowledge representation and ability to \nreason the agent can make good decisions. It should be able to  \nuse a natural language to cope  with complex environments \nbased on instructions given by a human. Ability to learn is also \nneeded for understanding new information and for efficient be-\nhavior.    \nThe rational agent principle has clear advantages compared to \nthe other definitions of AI mentioned above. In addition to the \nproper way of reasoning there are also other mechanisms for \nachieving rational actions. The agent approach is also much \nmore useful for developing various applications than those based \non human behavior or human thinking.  \nPercepts \nActs \nEnvironment \nActuators \nSensors \n\n20 \n \n2.2 \nSymbolic AI  vs. Connectionist Neural Networks  \nFrom the beginning of AI research the domain has been ap-\nproached by two very different manners: symbolic data pro-\ncessing and connectionist computing based on neural networks. \nThe term symbolic AI is based on the assumption that a given \npart or property of a phenomenon or object can be represented \nwith symbols. For example, the most well-known equation of \nAlbert Einstein’s relativity theory, E = mc2  (where E = energy, \nm = mass and c = speed of light), is a symbolic representation. \nThe value for energy can be calculated for different mass values \nwithout seeing or learning any specific values beforehand. \nIn symbolic AI, large knowledge bases and rules are built to de-\nscribe how the world related to a given problem is working. For \nexample, one of the rules related to recognizing animals in the \nzoo could be: ”If the animal is a mammal and it has a long neck, \nthen it is a giraffe”. \nOntologies are often used in building systems. In computer sci-\nence, the ontology means a description of concepts and their re-\nlations in a given application problem. By using rules and \nknowledge it is straightforward to build a system than can do \nreasoning. \nSymbolic systems can also answer to questions. After getting a \nreply, it is easy to follow the chain of reasoning to find out why \nthe system ended up to a given solution.  \nSymbolic processing fits very well to reasoning and using ab-\nstractions in problem solving. The AI boom in 1980s was mainly \nbased on rule-based expert systems (Figure 2.3). \n \n \n \n \n \nFigure 2.3. A rule-based system. (© 123RF) \nLearning is the major problem, because the creation of rules and \nknowledge is very laborious. Often the rules and knowledge are \nbuilt manually. \nArtificial neural networks (or neural networks) are based on \ndata-driven connectionist computations.  They are composed \nof very simple computing elements that are interconnected in a \nway that roughly resembles human nervous tissue. The neural \nnetworks can be trained. \nreasoning algorithms \nknowledge base \nexpert system \n\n21 \n \nNeural networks suit particularly well to the problems of pattern \nrecognition (Figure 2.4) and prediction with the help of numer-\nous training samples. With vision humans can recognize quickly \ndifferent types of objects, other people and their expressions and \ngestures. By hearing we can recognize speech and other sounds. \nFor this kind of perception complex symbolic reasoning is not \nneeded. \n \n \n \n \n \n \n \n \n \n \n \nFigure 2.4. Pattern recognition with a multi-layer neural net-\nwork. (© 123RF) \nIt is also possible to do pattern recognition, prediction and ma-\nchine learning with methods of traditional statistical pattern \nrecognition and data analysis (Duda et al., 2001), (Bishop, 2006). \nFor this reason, instead of connectionist computing we use the \nterm data-driven artificial intelligence in Chapter 3.  \nTraditionally, pattern recognition systems are trained with two \noptional approaches: supervised or unsupervised. In supervised \nlearning training samples from known different categories are \nused, for example, representing numbers 0-9 for a number recog-\nnition problem. Based on these samples the system will learn \nclassification criteria for the new unknown samples. \nIn unsupervised learning the system will learn classification \ncriteria directly from the data. Usually this is called clustering.  \nA major part of today’s applications employ supervised learning.  \nTogether with the supervised and unsupervised learning, the \nthird principle called reinforcement learning is also introduced \nin Chapter 4. \nSearch methods play a central role in symbolic AI. Many prob-\nlems can be represented with simple directed graphs (Figure 2.5) \nor decision trees, which are composed of nodes that are con-\nnected to other nodes with links. An example search problem \nSupervised feature learning \nL1 256x256 \nL2 128x128 \nL3 64x64 \n     F5 \nL4 32x32 \n     F6 \n\n22 \n \ncould be to find a route from a city to another by representing \ncities with nodes, connected with links. We could search for any \nroute from Oulu to Helsinki or for the shortest route. \nWhen the number of nodes in a network increases the search \nspace grows, often making the search computationally heavy. \nThere are various heuristic methods which can be used to reduce \nthe search space (i.e. the number of nodes to be traversed) in a \ngiven application.  However, the computational complexity is a \ncentral reason why it has not been possible in AI applications to \ngo ahead from “toy-world” problems to realistic situations. \n \nFigure 2.5. A directed search network.  \n2.3 \nCentral Areas of AI \nFigure 2.6 illustrates areas that are central to artificial intelli-\ngence.  These are needed for implementing rational agents de-\npicted in Figure 2.2. \n \nFigure 2.6. Central areas of AI.  (© 123RF) \nIn addition to machine learning an intelligent system needs, as \nhumans do, abilities for natural language processing and inter-\npretation of sensory data using computer vision and speech \nrecognition. The machine should also plan and schedule its ac-\ntions. For achieving best possible results, the whole system and \nits different tasks should be optimized. With robotics the ma-\nchine can execute different actions in the real world. There are \nalso software robots in addition to mechanical robots. Expert sys-\ntems (Figure 2.3), typically based on rule-based reasoning, are \n\n23 \n \nsystems designed for solving some specific application prob-\nlems.  \n2.4 \nWeak and Strong AI – or Super AI? \nWhen discussing about artificial intelligence, it is often divided \ninto three different levels of strength: weak, strong, or super AI. \nAll current applications of AI, including those presented in this \nbook, represent weak AI. Only solutions for specific problems in \nchosen applications are possible. Human-like consciousness \ncannot be achieved. Examples of current weak AI applications \ninclude text recognition, speech recognition, language transla-\ntion, recognition of humans, their faces, expressions and gestures \nfrom images and videos, playing chess and other games. \nIn strong AI the machine is approaching human intelligence, \nhaving at least some kind of consciousness about itself. It can \nuse different types of background information in planning and \nmaking decisions. A fully autonomous car moving in a continu-\nously changing environment would need already partially strong \nAI, at least for making decisions for handling conflict situations. \nMany lower level decisions, such as recognizing other cars, traf-\nfic signs or people, changing lane or avoiding crash, could be \ndone with weak AI.  \nStrong AI is necessary, for example, for natural dialogue be-\ntween humans and machines. The machine should be able to un-\nderstand the contents of the dialogue, but this cannot be achieved \nwith weak AI. Chapter 10 considers weaknesses of current arti-\nficial intelligence and how could we make progress towards \nstrong AI. \nA machine would have super AI, if its intelligence is higher than \nthe sharpest and most talented human beings have. It could be \nborn through “intelligence explosion” or “technological singu-\nlarity”. Some scientists believe that super intelligence will be \nborn soon after we have developed strong AI that resembles hu-\nman intelligence with an ability to actively acquire new \nknowledge and experiences. The singularity is achieved when a \nstrong AI can develop independently new even stronger solu-\ntions. Chapter 10 deals with super AI and discusses reasons why, \naccording to our current knowledge, achieving it seems impos-\nsible. \n2.5 \nHistory of Artificial Intelligence \nIn this section we will introduce a short history of AI, starting \nfrom some early related work in the 19th century. We focus on \nthe progress since the birth of AI in the 1950s, and end in 2012 \nwhen the breakthrough in deep learning research took place. In-\nformation and original references for our presentation can be \nfound, for example, from the history surveys of  the textbooks \n\n24 \n \nby (Russell & Norvig, 2010) and (Negnevitsky, 2011).  Addi-\ntional information is given in the AI history article by Wikipedia \n(Wiki-History1), and in other articles presented in Internet, for \nexample (Web-History2) and (Web-History3).  \nSome background for convolutional neural networks (CNN) was \nobtained from the ICPR 2018 keynote speech of Prof. Zhi-Hua \nZhou titled ”An exploration to non-NN style deep learning” \n(Zhou, 2018). For the AI-related history of robotics and its ap-\nplications we found pointers from an article in Finnish newspa-\nper Helsingin Sanomat (Paukku, 2017).  \nIn addition, some of the information for this survey has been bor-\nrowed from the professorship’s inaugural lecture given by the \nfirst author of this book (Pietikäinen, 1992). Interesting addi-\ntional information on some early projects of AI can be found in  \n(Knight, 2006).  \nThe progress in many fields of science during the past few cen-\nturies had influence on the birth of artificial intelligence. Russell \nand Norvig (2010) examined this progress from the points of \nview of philosophy, mathematics, economics, neural sciences, \ncomputer engineering, control theory and cybernetics, and lin-\nguistics, respectively. \n19th century – 1956: Birth of AI. There has been interest on \nintelligent machines since those days when the first computers \nwere developed. British Charles Babbage, who designed the An-\nalytical Engine based on mechanical calculations in the middle \nof 19th century, and his partner Ada Lovelace saw that this kind \nof programmable machine might be useful for intelligent opera-\ntions like playing chess or composing music.  Lord Byron’s \ndaughter Ada Lovelace has been called as the world’s first com-\nputer programmer. Konrad Zuse from Germany, who in 1941 \nfinished his Z-3 computer that is regarded as the word’s first pro-\ngrammable computer, applied Z-3 to the chess playing problem. \nIn 1872 Charles Darwin published the book ”The Expression of \nEmotions in Man and Animals”, in which he presented that facial \nexpressions can be described as discrete categories related to \nemotions. \nAlready during the first years of computing history some scien-\ntists from different fields started to discuss about possibilities to \ndevelop “artificial brains”. A foundation for this was created by \nthe theoretical work of British mathematician Alan Turing and \nthe computer architecture based on it developed by John von \nNeumann. \nEarliest ideas in research on intelligent machines were inspired \nby \n1) research in neurology showing that brains include an elec-\ntronic network composed of neurons,  \n\n25 \n \n2) Norbert Wiener’s cybernetics dealing with control and sta-\nbility  in electronic networks,  \n3) Claude Shannon’s information theory dealing with digital \nsignals,  and  \n4) Alan Turing’s  theory of computation, which showed that \nany computation can be done digitally. \nThe paper by Warren McCulloch and Walter Pitts on ”A logical \ncalculus of the ideas immanent to nervous activity” is regarded \nas the first actual work related to artificial intelligence. They pro-\nposed an artificial neural network model, in which each neuron \nis supposed to be in a binary state - on or off (McCulloch & Pitts, \n1943). They also showed that this kind of network is able to \nlearn. \nThe most notable person in creating the foundation for AI was \nAlan Turing. In his paper ”Computing machinery and intelli-\ngence” published in 1950 he suggested many fundamental re-\nsearch questions of the coming years, including playing games, \nnatural language understanding and translation (e.g., from Eng-\nlish to French), theorem proving, and breaking codes (Turing, \n1950). He also presented his widely referred definition for eval-\nuating machine intelligence, i.e., the Turing test  introduced in \nSection 2.1.  \nNorbert Wiener, the pioneer of feedback-based cybernetics, \nmathematician and philosopher (Wiki-Wiener) presented that all \nintelligent activities are based on feedback mechanisms. In a \nfeedback all earlier information produced by the system will \nhave an effect on all later outputs (Wiki-Feedback). He sug-\ngested that it might be possible to simulate this kind of mecha-\nnisms with machines (Wiener, 1948). \nMathematician Claude Shannon had also significant contribu-\ntions to the birth of AI with his pioneering research on infor-\nmation theory and foundations of digital signals (Wiki-Shan-\nnon). In 1950 he published an article \"Programming a computer \nfor playing chess\". He presented that if all possible move com-\nbinations of chess pieces would be completely examined, then a \ntypical chess game would include about 10120 possible moves – \ni.e. an enormous number of moves. With this Shannon demon-\nstrated that it is necessary to use heuristics  (“rules of thumb”) \nfor finding the best possible solution.   \nAlready in the early 1950s the first computer programs for AI \nproblems were written. Among the best known are ”Logic The-\norist” (Wiki-Logic) dealing with the theory of logic and the game \nprogram for checkers (Samuel, 1959).  The first one introduced \nby Newell, Simon and Shaw in 1956 was using tree search in \nproblem solving and was able to find proofs of theorems for sim-\nple proposition logic. Logic Theorist is considered as the first \nreal AI program. In his publication on checkers Arthur Samuel \nwas the first one to use the term machine learning. \n\n26 \n \nIn robotics area the science writer Isaac Asimov published three \nlaws of robotics in 1950: 1) a robot cannot hurt people, or when \nresting it does not allow any person to make harm, 2) robot must \nobey orders given by a human, if they are not in conflict with the \nfirst law, and 3) robot must protect its own existence as long as \nthis is not in conflict with rules 1 and 2. These laws of Asimov \nhave not prevented developing robots for military purposes. \n1956 - end of 1960s: Time of great expectations. The meeting \nheld in 1956 at Dartmouth College, USA, is considered as the \nbeginning of AI as a scientific field.   Many future  pioneers of \nAI research attended. When proposing this meeting in 1955, cog-\nnitive scientist John McCarthy used the term artificial intelli-\ngence for the first time. The objective of the meeting was to find \nout how to create a machine that would think like a human, \nwould be capable of abstract thinking, problem solving and im-\nproving itself. \nWith the name Artificial Intelligence McCarthy wanted to em-\nphasize the neutrality of this new research field and its differ-\nences to the narrow automata theory.  He also wanted to avoid \nmixing AI to feedback-based cybernetics known from analog \ncontrol theory. It is also speculated that one reason for choosing \nthis name was that McCarthy wanted to avoid the acceptance of \nself-confident Norbert Wiener as a guru of AI, or having to argue \nwith him. \nIn his article published in 2011 Ronald R. Kline introduces new, \nunpublished information about the birth of Dartmouth meeting \nand complex interactions between cybernetics, automation and \nartificial intelligence in the 1950s (Kline, 2011). History of cy-\nbernetics, as well as connections between AI and war history are \ncovered in his book ”Machines: A Cybernetic History” (Kline, \n2016). \nWe consider that McCarthy’s  interpretation about AI as a new \nindependent research field, strongly supported by computer sci-\nence, is correct.  The later progress of AI, its emphasis in soft-\nware, huge investments to computing research and wide poten-\ntial for applications support this choice. \nIn 1958 Prof. McCarthy developed LISP language which sup-\nports computing with symbols. For a long time it was the most \nimportant programming language in AI. Currently the most im-\nportant one is Python developed in the Netherlands in the late \n1980s by Guido van Rossum. \nIn the same year McCarthy published an article about programs \nwith common sense (McCarthy, 1958), introducing Advice \nTaker program, which tackled general problems in the world. \nFor example, it was capable of planning how to drive to the air-\nport based on a few simple logical axioms. The program could \naccept new axioms, i.e. new knowledge about different tasks \n\n27 \n \nwithout re-programming. Therefore, it can be considered as the \nfirst knowledge-based system, which includes the central ele-\nments of knowledge representation and reasoning (Negnevitsky, \n2011). \nAt that time is was often presented that after 25 years, around \n1981, people can focus on free time activities, because machines \nwill do most of the work.  It was believed that intelligent activi-\nties are mainly based on smart reasoning, which could be without \nmajor problems implemented as computer programs. This kind \nof optimism continued until the end of 1960s.  \nMcCarthy predicted that a breakthrough will be achieved in 5-\n500 years. He never retreated from this opinion (Web-McCar-\nthy). \nIn 1957, Herbert A. Simon,  an economist and later a Nobel lau-\nreate, predicted that machines will win humans in the game of \nchess in ten years – but this took 40 years (Wiki-Simon). Cogni-\ntive scientist Marvin Minsky predicted in 1967 that during one \ngeneration the problems of AI have been largely solved (Wiki-\nMinsky).  Minsky, McCarthy and Simon were leading pioneers \nduring the first decades of AI research. \nAllen Newell and Herbert A. Simon (1961, 1972) developed \nGeneral Problem Solver (GPS), a computer program that imi-\ntated human problem solving. It was the first program that tried \nto separate problem solving method from the data by using so \ncalled means-ends analysis. The given problem was defined as a \nset of states.  In analysis, the difference between the current state \nand goal state was computed and  the most suitable operator was \nthen used for the next step. GPS was based on formal logic and \nsearch, which made it computationally very complex, and im-\npractical for real world problems.   \nIn 1969 Herbert A. Simon published his book ”The Sciences of \nthe Artificial”, which emphasized the importance of representa-\ntions (Simon, 1969). \nFrom the beginning AI has been applied to solving  mathematical \nproblems that include symbolic computations. In the  early 1960s \nthe first computer program for calculus was introduced.  Based \non it, the MACSYMA software system for professional use was \nreleased in 1978. It could be used for solving many types of \nmathematical problems. With it, or corresponding newer soft-\nware packages such as Maple (1984-) or Mathematica (1988-), \nthe user only needs to define the mathematical problem to be \nsolved in symbolic form.  This technology is no longer consid-\nered as AI as it has been in routine use by mathematicians and \nengineers for a long time. \nAs an indication that AI can solve tasks requiring some form of \nintelligence was the ANALOGY program introduced in 1963. It \n\n28 \n \ncould solve pattern recognition tests used when estimating hu-\nman intelligence. Its  principle was to go through by search dif-\nferent changes in the patterns such as addition, deletion and ro-\ntation. \nFrank Rosenblatt introduced a neural network called Perceptron \n(Figure 2.7) (Rosenblatt, 1958). Following the optimism of that \ntime he predicted that Perceptron will soon enable machines to \nwalk, talk, make decisions and even do language translations.  \n  \nFigure 2.7. Perceptron neural network. \nThis principle was studied actively nearly the whole 1960s. \nHowever, Minsky and Papert (1969) showed in their book Per-\nceptrons that the method has serious limitations: it can only use \nlinear discriminants to separate features describing different ob-\njects. Therefore, the great expectations were far too optimistic. \nMinsky and Papert concluded that the data representations ob-\ntained with neural networks  are not enough for intelligent ac-\ntions. They knew that these limitations did not apply to multi-\nlayer networks, but there was no learning algorithm available for \nthis purpose. This led to the end of nearly all neural network re-\nsearch for about ten years.  \nAn interesting note about the progress in 1960s is that in 1965 \nProf. Lotfi Zadeh published an article on  ”Fuzzy sets”, which \nbecame very famous about twenty years later by creating foun-\ndation for numerous applications of fuzzy logic to different types \nof intelligent devices and systems (Zadeh, 1965).  \nIn 1961, the first mass produced industrial robot manipulator, \nUnimate 1900, was put in operation. It  was assembling cars at a \nGeneral Motors plant (Paukku, 2017). \nAlso some computer vision related research was carried out in \n1960s. A famous example of the early work, and poor technol-\nogy prediction, is a summer project at Massachusetts Institute of \nTechnology (MIT) in 1966. The key problems of computer vi-\nsion were supposed to be largely solved in a summer project of \na PhD student. Research results obtained in 1960s dealt, for ex-\nample, with methods for analyzing 2-D images. \nClosely related to the activities of our group, research on image \ntexture analysis, dealing with gray scale variations caused by \n\n29 \n \nproperties of objects’ surfaces,  began in the 1960s. Bela Julesz \npresented his research on texture discrimination based on second \norder statistics. A significant milestone in computer vision was \nthe PhD dissertation of Larry Roberts finished in 1960 at MIT \ntitled ”Machine Perception of Three-Dimensional Solids”. In his \nwork he developed methods for detecting 3-D geometric infor-\nmation from 2-D scene images.  \nFace recognition research was also started during this decade, \nand continues today as one of the central application domains of \ncomputer vision and AI.  First research was initiated in 1964 by \nWoodrow Bledshoe and the first PhD thesis was finished in 1972 \nby Takeo Kanade (Jain, 2013). Kanade  from Japan became later \na world-renowned scientist in computer vision and robotics  at \nthe Carnegie Mellon University in USA. \nEnd of 1960s – beginning of  1970s: Time of disappointments \n– first AI winter. During this period much critique was pre-\nsented against AI. The researchers had not been able to predict \nhow difficult it would be to develop real applications. The too \noptimistic promises were not fulfilled, and the funding for re-\nsearch collapsed.  This is called the first AI winter. Among the \nreasons for this winter were, for example, too small capacity of \nthe computers and exponential growth of computational com-\nplexity when moving from ”toy problems” to real problems.  \nResearchers mainly focused on general large-scale problems, in \nwhich only little, or no knowledge at all about the problem was \nused. Different search methods were mostly used in problem \nsolving. This led to the explosion of computational  complexity \nin real world problems, for example, in automatic translation \nfrom one language to another. \nIn the 1960s and 1970s, however, first programs for understand-\ning natural  languages, having very limited vocabulary  and lan-\nguage structure, were developed. In 1964-66 the ELIZA program \ndeveloped by Joseph Weizenbaum at MIT simulated  discussion \nin English by using a simple pattern (a word, part of text) match-\ning and replacement method. With ELIZA a user might  believe \nthat the machine understands something about the discussion. \nOther attempts included the STUDENT program introduced by \nDaniel Bobrow in 1967 aimed at solving high-school algebra \nproblems described with a natural language. In 1982 Terry \nWinograd developed SHRDLU for describing tasks in a simu-\nlated blocks world, and Warren ja Pereira’s CHAT-80 for an-\nswering questions dealing with geography. \nIn the late 1960s Roger Schank, one of the leading AI research-\ners, developed a model for natural language understanding called \n”conceptual dependency theory” (Schank & Abelson, 1977). He \nwas also a pioneer in case-based reasoning, in which the solution \n\n30 \n \nto a new problem is based on solutions developed for earlier  re-\nsembling problems. \nA foundation for genetic algorithms was created already in the \nearly 1970s. John Holland developed an algorithm for handling \nartificial chromosomes with operations for selection, crossover \nand mutation. (Holland, 1975). At around the same time (begin-\nning already in the1960s) the basis for evolutionary computing \nwas invented, first by Ingo Rechenberg and later also by Hans-\nPaul Schwefel (Rechenberg, 1973), (Schwefel, 1995). Both ge-\nnetic algorithms and evolutionary computing can be applied to \nmany, earlier unsolved complex problems that need nonlinear \nsearch and optimization.   \nStanley Kubrick’s science fiction film ”2001: A Space Odys-\nsey”, based Arthur C. Clarke’s book, introduced the HAL 9000 \ncomputer, which inspired research on intelligent human-com-\nputer interfaces in the early 2000s.  HAL was able to understand \nnatural language, even by reading from lips, could speak, and \ninterpret human actions and emotions. \nIn machine vision, research included methods for analyzing 2-D \nimages, for example, to detect edges and segmenting images into \nregions. Among the first applications was automatic recognition \nof characters from printed text.   \n1970 - end of 1980s: Era of knowledge engineering. Research \non knowledge engineering and representing application-specific \nnarrow knowledge with rules began in 1970s.  The implementa-\ntion of a rule-based expert system includes separating applica-\ntion domain knowledge and rules used for problem solving \nthrough inference (Figure 2.3). Normally these kinds of systems \nshould be able to give justification for the decisions. \nIn Marvin Minsky’s article \"A framework for representing \nknowledge\" an important knowledge representation principle \ncalled frame was proposed, in which knowledge is divided into \nsub-structures called stereotypic situations (Minsky, 1975).  The \nframes, originally developed from semantic networks, also  be-\nlong to called structural knowledge representations. They were \nregularly used in the knowledge-based systems of the 1970s. The \nstructural systems collect facts from chosen object or action \ntypes into  taxonomic hierarchies, resembling taxonomies in bi-\nology (Russell & Norvig, 2010).  \nAmong \nthe \nbest \nknown \nfirst \nexpert \nsystems \nwere \nPROSPECTOR (Hart and Duda 1977) - a tool supporting min-\neral exploration, DENDRAL developed for structural analysis of \norganic chemical structures in mass spectroscopy (Buchanan and \nFeigenbaum 1978), and MYCIN - a system developed  for the \ndiagnosis of infection diseases (Buchanan and Shortliffe 1984). \nThe development of expert systems was commercialized in the \nearly 1980s, with too optimistic expectations of rapid success. \n\n31 \n \nThe goal was to implement computer programs imitating  human \nreasoning to solve  dedicated problems. The areas of application \nincluded medical diagnosis, exploration of soil minerals, study-\ning oil wells, fault diagnosis of various machines, and tools for \ninvestigating credit standing of customers applying for loans. \nThe first commercially successful expert system was R1 (also \ncalled XCON) developed by Digital Equipment Corporation \n(DEC), at the time known for its VAX and PDP computers. R1 \nhelped to configure computer systems according to the custom-\ners’ orders, providing apparently significant savings for DEC.  \nNearly every major company in USA had an AI team to investi-\ngate expert systems (Russell & Norvig, 2010) – resembling to-\nday’s AI hype! \nIn 1984 Douglas Lenat started his Cyc project dealing with mod-\neling common sense knowledge. It is currently known as the \nworld’s longest AI project (Wiki-Cyc) with its first stable ver-\nsion 6.1 released in November 2017! \nIn 1982 Japan started a ”Fifth Generation” project, with an aim \nto develop in ten years massively parallel intelligent computers \nthat would support the use of Prolog logic programming lan-\nguage. Following this, USA and UK started their own AI pro-\ngrams: MCC (Microelectronics and Computer Consortium) and \nAlvey (1983-87), but none of these achieved their ambitious \ngoals.  \nThe basic research carried out by Matti Pietikäinen at the Uni-\nversity of Maryland in 1984-85 was supported by the Autono-\nmous Land Vehicle Project, which belonged to DARPA’s (De-\nfence Advanced Research Project Agency) Strategic Computing \nInitiative (SCI, 1983-1993). The SCI program focused on devel-\noping advanced computing devices and artificial intelligence. \nThe objective was to achieve complete machine intelligence in \nten years, allowing computers to execute ten billion instructions \nper second with an ability to see, hear, talk and think like humans \ndo! Integrating multiple technologies, a machine would compete \nwith the human brain (Wiki-SCI).  These very ambitious goals \nwere not achieved, and in part this contributed  to the beginning \nof the next AI winter. \nAt the same time the German Bundeswehr University achieved \nbetter results in autonomous driving than the DARPA program. \nIn 1987, the robotic car developed by Professor Dickmanns and \nhis team was able to drive at a maximum speed of 96 kilome-\nters/hour on an empty road with intersections. His solution was \nbased on advanced control engineering, and in a way honored \nNorbert Wiener’s ideas that intelligent behaviors are based on \nfeedbacks (Dickmanns & Graefe, 1988).  \nHowever, as a ”side product” of DARPA’s program an AI-based  \ntool was developed for planning logistics. It has been estimated \n\n32 \n \nthat this tool helped save billions of dollars for planning the lo-\ngistics for vehicles, freight and people during the Iraq War in \n1991. This was more than all DARPA’s funding for AI before \nthat. In fact, this kind of situation is typical for the AI research. \nHighly ambitious goals are set, which means that much better \nsoftware development tools and devices than existing ones are \nrequired. In this way the AI research has had a great influence \non the progress of computing field in general, but it has not been \ngiven much credit for such developments. For a future-oriented  \nresearch like AI, very powerful computing  facilities and soft-\nware are needed, and in this way the research helps develop new \ntools and computing environments for general use. \nIn the 1970s, statistical pattern recognition took the leading role \nin object classification (Duda & Hart, 1973), and remained as \nsuch until recently. Neural networks can be viewed as a mas-\nsively parallel computing architecture for statistical pattern \nrecognition. \nNeural networks research experienced a renaissance in the1980s. \nNew types of networks were introduced, removing problems of \nthe earlier schemes. Among the best-known ones were Gross-\nberg’s network based on self-organizing adaptive resonance the-\nory (1980), Hopfield’s network (1982), multilayer-perceptron  \nbased on backpropagation (Rumelhart et al., 1986), and Teuvo \nKohonen’s self-organizing network (SOM) from 1982  for unsu-\npervised  classification (Kohonen, 2001). From today’s view-\npoint,  the multilayer-perceptron was of special importance, be-\ncause is laid foundation for more recent deep learning networks.   \nInterestingly, the first modern version of backpropagation algo-\nrithm (i.e., automatic differentiation) used for training multilayer \nneural networks was proposed as early as 1970 by Seppo Lin-\nnainmaa in his Master’s thesis for University of Helsinki. Paul \nWerbos was the first one to apply backpropagation algorithm for \nneural network training in 1974.  \nKunihiko Fukushima introduced the use of convolution opera-\ntors in his paper on Neocognitron published in 1982 (Fukushima \n& Miyake, 1982). This was inspired by the research of David \nHubel and Torsten Wiesel (1962) dealing with the structure of \nthe visual cortex of mammals. Later Hubel and Wiesel were \nawarded with a Nobel Prize.  Yann LeCun et al. (1989) applied \nbackpropagation principle to the convolution layers of a neural \nnetwork, with an application in character recognition. This \nmethod created basis for the current convolutional neural net-\nworks. \nThe roots of reinforcement learning are also in the 1980s, be-\ncause Barto et al. (1983) introduced a method based on this prin-\nciple for challenging control engineering problems. In reinforce-\n\n33 \n \nment learning a system works in its environment receiving posi-\ntive or negative feedback from its actions, and in this way learns \nlittle by little a suitable strategy for the actions. \nThe first AI boom in Finland began in the 1980s. In 1984 the \nTechnology Development Center of Finland (Tekes) started its \nFINPRINT technology program on information technology. Its \nobjective was to reach and preserve Finland’s international com-\npetitiveness, especially in hardware and software. From its five \nsub-programs two were related to AI: 1) Artificial intelligence \nand 2) Applications of pattern recognition. The first one focused \non knowledge engineering and expert systems, and the second \none on speech communications, digital image processing and \nmachine vision, and applications of medical engineering. Our re-\nsearch group participated in the second sub-program.  \nResearch on speech recognition has been done already since \n1950s, but more significant research started in the1970s. In USA, \nthe research agency DARPA funded a speech understanding re-\nsearch program from 1971. One of its goals was to recognize \nspeech from a corpus of at least 1000 words.  DARPA was un-\nhappy with the results and ceased funding the program. \nIn the late1970s, a team led by James Baker  from Carnegie \nMellon University, which had participated  in the speech under-\nstanding program,  was first to apply Hidden Markov Models \n(HMM) to speech recognition. HMM is based on Markov chains \nproposed in the 1960s by Lennard Baum. With HMM, \nknowledge based on acoustic, language and syntax information \nof the speech can be combined into a uniform model based on \nprobabilities. The use of HMM models revolutionized speech \nrecognition for decades  (Wiki-Speech). \nPaul Ekman introduced in 1978 a Facial Action Coding System \n(FACS), which had a great impact on facial expression analysis \nresearch  (Ekman & Friesen, 1978).  Later he presented signifi-\ncant improvements to the FACS (Ekman et al., 2002). \nComputer vision research was getting wider and deeper in the \n1980s. New methods were developed for analyzing images, im-\nage sequences (videos) and three-dimensional (3-D) images. Ap-\nplications of machine vision in industrial automation were in-\ncreasingly studied. Among the first applications were visual in-\nspection, product sorting and assembly tasks, for example, in car \nmanufacturing and electronics industries. In his book Vision Da-\nvid Marr from MIT proposed a model on how a description of \n3D environment is created in human visual system through three \nphases: the primal sketch (2-D), intermediate (2.5-D) descrip-\ntion, and the 3-D view-independent description (Marr, 1982). \nThis model had a great influence on later computer vison re-\nsearch. \n\n34 \n \n1988 - 1993: The second AI winter.  During this period the \nfunding sources for AI research and development were largely \nclosed for several years due to the earlier major setbacks. The \ngreat expectations on expert systems failed and only very few \nproductive systems were developed. It was easy to implement \nsimple systems working in a “toy world”, but generalization to \nreal-world problems was very hard. Furthermore, the computa-\ntional complexity of larger systems was overwhelming.  \nMost profits from the expert systems were obtained by the pro-\nducers of development tools. One such company was Symbolics, \nInc,  developing computers specialized  for processing symbolic \ninformation and the LISP language. We also got such a computer \nfor our research and teaching. \nThe AI pioneer Marvin Minsky proposed that in the develop-\nment of intelligent systems one should utilize both connectionist \nneural networks and symbolic processing (Minsky, 1990). \nEnd of 1980s - beginning of 2000s: Establishment as a re-\nsearch field. Artificial intelligence started to establish its posi-\ntion as a field of science.  The hypotheses created had to be tested \ncarefully,  the results had to be analyzed with statistical methods, \nand it was necessary to compare results to the others in the sci-\nentific community. The use of models based on probabilities in-\ncreased, including Bayesian statistics and Bayesian networks. \nRodney Brooks (MIT) was the frontrunner in the so called   \n“Nouvelle AI”, in which, for example, some intelligence for a \nrobot can be built by combining, over time, simple behaviors (for \nexample, ”move forward”, ”avoid obstacles”)  to more complex \nactions  (for example, how to behave with moving objects).  \nMethods based on soft computing were also investigated. In ad-\ndition to neural networks, there was also growing interest on \nfuzzy logic introduced already in 1965 by Professor Lotfi Zadeh, \nas well as on genetic algorithms (Figure 2.8), and  evolutional \ncomputing roughly imitating biological evolution. \n \nFigure 2.8. Genetic algorithms are using a simplified model from \nbiological evolution. (© 123RF) \nIn deep neural networks, LeCun and Bengio (1995) presented a \ncomplete description of the convolutional neural network \n\n35 \n \n(CNN). LeCun et al. (1998) applied CNN to the problem of rec-\nognizing handwritten characters.  \nIn 1997, IBM’s program on Deep Blue computer won the \nworld’s best chess player Gary Kasparov. This achievement re-\nceived huge publicity and showed that in limited tasks a machine \ncan beat humans. \nThe first world-championship competition of simulated soccer \nrobots (RoboCup) was arranged in 1997. Jukka Riekki’s team \nfrom the University of Oulu ranked 13th among 29 participants \n(Wiki-Robocup). In 1998 Sony introduced the prototype of a \nwalking robot companion (dog) named AIBO, and its commer-\ncial version was released in 1999 (Wiki-AIBO).  \nRosalind Picard published book ”Affective Computing”, creat-\ning the basis for the new scientific field also known as emotion \nAI (Picard, 1997). \nIn computer vision, the research was moving from methods \nworking in controlled conditions, for example under uniform \nlighting,  to solutions aimed for uncontrolled indoor or outdoor \nconditions. The eigenface method developed by Matthew Turk \nand Alex Pentland in 1991 was the most widely used method for \nface recognition.  \nIn speech recognition, research was moving from ad hoc meth-\nods without any theoretical foundation to Hidden Markov Mod-\nels (HMM) based on a strong mathematical theory. Many AI \nproblems were approached from an agent-based viewpoint out-\nlined in Section 2.1.  \nThe milestones of our own research included inventing the basic \nLocal Binary Pattern method (Ojala et al., 1996) and the first \nsteps of its further development, and the method for geometric \ncamera calibration for 3-dimensional (3-D) computer vision \n(Heikkilä & Silvén, 1997). \nThe Machine Vision Technology Programme 1992-96 funded by \nTekes and industry was very important for developing Finnish \nmachine vision applications in industry - and for our own re-\nsearch  (Pau & Savisalo, 1996). \nEarly 2000s - 2012: Intelligent agents, big data, new applica-\ntion areas.  Research on intelligent agents was increasing.  \nAmong the goals was to get rid of focusing on single problems \nand move towards intelligent systems composed of several parts. \nInternet has played a key role in the development of intelligent \nagents. AI technologies can be found, for example, in chatbots, \nsearch engines, and recommender systems advertising different \ncommercial products. \nIn 2005 and 2006, the DARPA Grand Challenge and  DARPA \nUrban Challenge competitions for self-driving vehicles were ar-\nranged. The winner of the first competition was the STANLEY \n\n36 \n \nrobotic vehicle built at Stanford University.  It was driving au-\ntonomously on a route of 132 miles in the desert at the speed of \n22 miles per hour.  In the latter competition, the winning BOSS \nvehicle developed at Carnegie Mellon University drove safely in \nthe traffic at an air force base, following the traffic rules and \navoiding pedestrians and other vehicles. Motivated by these re-\nsults, Google started the development of a self-driving car in \n2009. \nIn 2002,  iRobot company introduced its Roomba robot vacuum \ncleaner, which was autonomously able to clean a whole apart-\nment. Already in 1996 Electrolux had started marketing its own \nautonomous vacuum cleaner, but it was not capable of perform-\ning equally demanding tasks.   In 2004 NASA’s robot Mars rov-\ners Spirit and Opportunity started to work independently  on the \nsurface of Mars  (Wiki-Mars).  \nDuring the whole history of computing research, the main em-\nphasis had been in algorithm development. However, already in \nthe beginning of 2000s it was realized that in many problems the \namount of data available  is more important than the algorithms \n(Russell & Norvig, 2010). At the same time the capacity and \nspeed of computers was continuously growing, making it possi-\nble to use more and more data.  \nWith Internet is was possible  to easily get big masses of data. \nThe technology leaders of Internet, at that time especially \nGoogle and Microsoft, started significant investments into ma-\nchine learning, computer vision, and their applications. \nThe Support Vector Machine (SVM) proposed already in the \n1990s became a leading approach in statistical classification \n(Cortes & Vapnik, 1995). Its key idea is to project a feature vec-\ntor to a higher dimensional feature space, in which the discrimi-\nnation of different classes is easier. \nGeoffrey Hinton et al. (2006) introduced a principle for unsuper-\nvised layer-wise training for a deep model and Honglak Lee et \nal (2009) presented how to use this kind of layerwise training for \na CNN network. These were among the last steps towards mak-\ning a breakthrough in deep learning in 2012 by Hinton’s team \n(Krizhevsky et al., 2012). \nThe central figure in the research on causalities (i.e., the relation-\nship between cause and effect) is Judea Pearl. In 2000 he pub-\nlished the first edition of his book dealing with modeling and use \nof causalities in reasoning (the second edition in 2009) (Pearl, \n2009). He is also regarded as a key person in artificial intelli-\ngence based on probabilities and in developing Bayesian net-\nworks often used in reasoning. \nIn 2011, i.e. before the breakthrough in deep learning, IBM’s \nWatson AI engine was able to win humans in the demanding  TV \nquiz show Jeopardy. \n\n37 \n \nResearch on computer vision became wider and deeper. The Vi-\nola & Jones method proposed in 2001 was a milestone in real-\ntime face detection from images. New effective methods for \nmeasuring image properties were developed, including SIFT, \nLBP and HOG, which were widely used in different types of ap-\nplications.  So-called bag-of-words (BoW) principle became the \nstate-of-the-art approach for representing textured images.  The \nLBP histogram (see Chapter 7) is a simple example of BoW rep-\nresentation (Liu et al., 2019).   \nRecognition of faces and human actions became an increasingly \nimportant research area. These are central for many applications \nwhen computing transforms from machine-centered to more hu-\nman-centered. The importance of machine learning increased \nwhen it was possible to use big amounts of data. Computer vision \nstarted to be used in natural environments in our everyday lives, \nsuch as smart phones, biometric recognition, video surveillance, \nand Internet search engines. \nVery significant scientific breakthroughs related to AI were \nachieved in Finland in the late 1990s and early 2000s. Perhaps \nthe best known of these are given below. \nProfessor Erkki Oja’s team developed methodology for inde-\npendent component analysis (ICA), in which a multidimensional \nsignal is divided into its additive sub-components (Hyvärinen et \nal., 2001). ICA is a special case of the blind source separation, \nfor example in the so called “cocktail party” problem we could \ntry to hear a person’s speech in a noisy room. The Local Binary \nPattern method and its application to face recognition led to ma-\njor breakthroughs in the early 2000s (Chapter 7) and to the first \nmethod for recognizing spontaneous facial micro-expressions in \n2011 (Chapter 9).  Professor Samuel Kaski’s team developed \nvarious dimensionality reduction methods for data visualization \n(Venna et al., 2010).  The frequently cited image noise reduction \nmethod developed by Professor Karen Egiazarian’s team can \nalso be considered as an AI method (Dabov et al., 2007). \n2.6 \nA Summary of AI History \nTable  2.2. AI from its birth to early 2000s \nBirth of AI  \n(- 1956) \nBeginning of neural networks: McCulloch & \nPitts (1943) A logical calculus of the ideas \nimmanent in nervous activity \n \nNorbert Wiener considered importance of \nfeedback  in intelligent actions (1948). \n \nFoundations for AI: Turing (1950) \nComputing machinery and intelligence \n \nIsaac Asimov presented three laws of \nrobotics (1950) \nTime of great \nexpectations (1956 – \nend of 1960s) \nDartmouth College AI meeting (1956) \nLISP language (McCarthy, 1958) \n\n38 \n \n \nAdvice Taker – a reasoning program \n(McCarthy, 1958) \n \nPerceptron neural network  (Rosenblatt, \n1958)   \n \nGeneral Problem Solver (GPS) (Newell & \nSimon, 1961) \n \nFace recognition research begins (1964-)  \n \nFuzzy sets (Zadeh, 1965)  \nTime of \ndisappointments – first \nAI winter (end of 1960s \n– beginning of 1970s) \nToo generic problems, methods not suitable \nfor real-world problems, mainly search \nmethods – no domain knowledge employed \nNeural network research almost ends: Minsky \n& Papert (1969) Perceptrons \n \nFirst steps towards natural language analysis: \nELIZA, STUDENT, SHRDLU, CHAT-80  \n \nStanley Kubrick’s film ”2001: A Space \nOdyssey” introduced intelligent HAL 9000 \ncomputer  (1968) \nPeriod of knowledge \nengineering (1970 – \nend of 1980s) \nMinsky (1975) A framework for representing \nknowledge \n \nFirst rule-based expert systems: \nPROSPECTOR, DENDRAL, MYCIN, \nXCON etc. \n \nThe Cyc project modeling common sense \nknowledge begins (1984-) \n \nProlog language for logic programming \n \nStatistical pattern recognition  comes to \nmajor role in object classification  \n \nReturn of neural networks: Self-organizing \nadaptive resonance theory (Grossberg), \nHopfield’s network (Hopfield),  self-\norganizing map (Kohonen) \n \nMultilayer perceptron using back-propagation \n(Rumelhart et al., 1986), convolution in  \nneural networks (Fukushima, 1982), (LeCun \net al., 1989) \n \nReinforcement learning for control \nengineering problems (Barto et al., 1983) \n \nGenetic algorithms and  evolutionary \ncomputation (Holland, Schwefel and \nRechenberg) \n \nFacial action coding system FACS (Ekman & \nFriesen, 1978) \n \nModel of human visual system for \ninterpretation of  3-D scene images (Marr, \n1982) \n \nProgress in speech recognition: E.g., use of \nHidden Markov Models (HMM) \nSecond AI winter \n(1988-1993) \nGreat expectations on expert systems failed: \nreal-world problems are too difficult  \n \nIn intelligent systems both connectionist \nneural networks and symbolic computing is \nneeded (Minsky, 1990) \nEstablishment as a \nscientific discipline \n(end of 1980s – \nbeginning of 2000s) \nBayesian statistics an Bayes networks (Pearl \netc.), ”nouvelle” AI  (Brooks), fuzzy logic \n(Zadeh), artificial life and genetic algorithm \n\n39 \n \n \nProgress in deep neural networks (LeCun & \nBengio, 1995), (LeCun et al., 1998) \n \nIBM’s  Deep Blue wins Gary Kasparov in \nchess (1997) \n \nSony’s  autonomously walking robot dog \nAIBO (1998, 1999) \n \nCreating foundations for Affective computing \n(Picard, 1997) \nIntelligent agents, big \ndata, new application \nareas  (beginning of \n2000s – 2012) \nResearch on intelligent agents broadens:  \nInternet gets widely used, AI technologies \ne.g. in   chatbots,  search engines,  and \nproduct recommendation systems \n \nDemonstrations with self-driving vehicles: \nDARPA Grand Challenge and DARPA \nUrban Challenge; Google’s vehicle \ndevelopment starts \n \nData comes to central role instead of \nalgorithms \n \nDeep neural networks progress: \nUnsupervised layer-wise training (Hinton et \nal., 2006), (Lee et al., 2009) \n \nSupport vector machine (SVM) has leading \nrole in statistical classification \n \nProgress in analyzing cause-effect (causality) \nproblems (Pearl, 2009) \n \nSignificant AI results from Finland: \nIndependent component analysis (Hyvärinen \net al., 2001); Local Binary Pattern and its \napplication to face recognition (Ojala et al., \n2002), Ahonen et al. (2004, 2006); \nDimensionality reduction methods (Venna et \nal., 2010); Image noise removal (Dabov et al., \n2007); Recognition of spontaneous micro-\nexpressions (Pfister et al., 2011) \n \nBag-of-words principle becomes mainstream \nis representing images with textures  \n \nIBM’s Watson AI wins humans  in TV quiz \nshow Jeopardy (2011) \n \nBreakthrough in deep learning: (Krizhevsky \net al., 2012) \n2.7 \nReferences \nBarto AG, Sutton RS & Anderson CW (1983) Neurolike adap-\ntive elements that can solve difficult learning control problems. \nIEEE Transactions on Systems, Man and Cybernetics 13:834-\n846. \nBishop CM (2006) Pattern Recognition and Machine Learning.  \nSpringer, 738 p. \nCortes C & Vapnik VN (1995) Support vector networks. Ma-\nchine Learning 20 (3):273-297. \nDabov K, Foi A, Katkovnik V & Egiazarian K (2007) Image de-\nnoising by sparse 3-D transform-domain collaborative filtering. \nIEEE Transactions on Image Processing 16 (8):2080-2095. \nDickmanns E & Graefe V (1988) Dynamic monocular machine \nvision. Machine Vision and Applications 1:223-240. \n\n40 \n \nDuda RO & Hart PE (1973) Pattern Classification and Scene \nAnalysis. Wiley-Interscience, 482 p. \nDuda RO, Hart PE & Stork DG (2001) Pattern Classification, 2nd \nEdition. Wiley Interscience, 654 p. \nEkman P & Friesen W (1978) Facial Action Coding System: A \nTechnique for the Measurement of Facial Movement. Consult-\ning Psychologists Press, Palo Alto. \nEkman P, Friesen WV & Hager JC (2002) Facial Action Coding \nSystem: The Manual on CD ROM. A Human Face, Salt Lake \nCity. \nFukushima K & Miyake S (1982) Neocognitron: A  new algo-\nrithm for pattern recognition tolerant of deformations and sifts in \nposition. Pattern Recognition 15(6):455-469. \nHeikkilä J & Silvén O (1997) A four-step camera calibration pro-\ncedure with implicit image correction. Proc. IEEE Conference \non Computer Vision and Pattern Recognition, June 17-19, San \nJuan, Puerto Rico, 1:1106-1112. \nHinton GE, Osindero S & Teh YW (2006) A fast learning algo-\nrithm for deep nets. Neural Computation 18 (7):1527-1554. \nHolland JH (1975) Adaptation in Natural and Artificial Systems. \nUniversity of Michigan Press, Ann Arbor. \nHyvärinen A, Karhunen J & Oja E (2001) Independent Compo-\nnent Analysis. John Wiley & Sons, 506 p. \nJain AK (2013) 50 years of Biometric Research. Almost The \nSolved, The Unsolved, and The Unexplored. Keynote lecture. \nInternational Conference on Biometrics, 2013. \nKline RR (2011) Cybernetics, automata studies, and the Dart-\nmouth conference on artificial intelligence. IEEE Annals of the \nHistory of Computing 33:5-16. \nKline RR (2016) Machines: A Cybernetic History. WW Norton \n& Company, 432 p. \nKnight H  (ed.) (2006) Early artificial intelligence projects: A \nstudent perspective.  \nKohonen T (2001) Self-Organizing Maps, Third Edition, \nSpringer. \nKrizhevsky A, Sutskever I &, Hinton GE (2012)  Imagenet clas-\nsification with deep convolutional neural networks. Advances in \nNeural Information Processing Systems, 1097-1105. \nLeCun Y, Boser B, Denker JS, Henderson D, Howard RE, Hub-\nbard W & Jackel  LD (1989)      Backpropagation applied to  \nhand-written zip code recognition. Neural Computation \n1(4):541-551. \nLeCun Y & Bengio Y (1995) Convolutional networks for im-\nages, speech and time series. The Handbook of Brain Theory and \nNeural Networks (ed. MA Arbib), MIT Press. \n\n41 \n \nLeCun Y, Bottou L, Bengio Y & Haffner P (1998) Gradient-\nbased learning applied to document recognition, Proceedings of \nthe IEEE 86(11):2278-2324. \nLee H, Grosse R,  Ranganath R & Ng AY (2009) Convolutional \ndeep belief networks for scalable unsupervised learning of hier-\narchical representations.  ICML '09 Proceedings of the 26th An-\nnual International Conference on Machine Learning, 609-616. \nLiu L, Chen J, Fieguth P, Zhao G, Chellappa R & Pietikäinen M \n(2019) From BoW to CNN: Two decades of texture representa-\ntion for texture classification. International Journal of Computer \nVision 127(1):74-109. \nMarr D (1982) Vision: A Computational Investigation into the \nHuman Representation and Processing of Visual Information. \nSan Francisco: W. H. Freeman and Company. \nMcCarthy J (1958) Programs with common sense. Proceedings \nof the Symposium on Mechanisation of Thought Processes, vol. \n1, London, 77-84. \nMcCulloch WS & Pitts W (1943) A logical calculus of the ideas \nimmanent to nervous activity. Bulletin of Mathematical Bio-\nphysics 5, 115-137. \nMinsky ML & Papert SA (1969) Perceptrons. MIT Press, Cam-\nbridge, MA. \nMinsky ML (1975) A framework for representing knowledge. \nThe Psychology of Computer Vision (ed. P Winston), McGraw-\nHill, New York, 211-277. \nMinsky ML (1990) Logical vs. analogical or symbolic vs. con-\nnectionist or neat vs. scruffy, In Artificial Intelligence at MIT, \nExpanding Frontiers, Patrick H. Winston (Ed.), Vol.1. MIT \nPress, 1990. Reprinted in AI Magazine, Summer 1991. \nNegnevitsky M (2011) Artificial Intelligence – A Guide to Intel-\nligent Systems, Third Edition. Pearson Education Limited, 479 \np. \nNewell A & Simon HA (1961) GPS, a program that simulates \nhuman thought. Lernende Automatten (ed. H Billing), R Olden-\nburg, Munich, 109-124. \nNewell A & Simon HA (1972) Human Problem Solving, Eng-\nlewood Cliffs, NJ: Prentice-Hall. \nOjala T, Pietikäinen M & Harwood D (1996) A comparative \nstudy of texture measures with classification based on feature \ndistributions. Pattern Recognition 29(1):51-59. \nPau LF & Savisalo H (1996) Machine Vision Technology Pro-\ngramme 1992-1996 – Evaluation report. TEKES Technology \nProgramme Report 16/96, 34 p. \nPaukku T (2017) Tekoälyn viisasten kivi on superäly (The phi-\nlosopher’s stone is super AI). Helsingin Sanomat 20.6.2017. \n\n42 \n \nPearl J (2009) Causality: Models, Reasoning and Inference. \nCambridge University Press, 484 p. \nPicard R (1997) Affective Computing. MIT Press. \nPietikäinen M (1992) Tekoälyn kehittäjillä mittavia haasteita \n(Developers of AI face major challenges). AKTUUMI 4:23-28. \nRechenberg I (1973) Evolutionsstrategien – Optimisieriung \nTechnischer Systeme Nach Prinzipien der Biologischen Infor-\nmation. Frommann- Holzbook-Verlag. Stuttgart. \nRosenblatt F (1958) The perceptron: A probabilistic model for \ninformation storage and organization in the brain. Psychological \nReview 65(6):386-408. \nRumelhart DE, Hinton GE & Williams RJ (1986) Learning in-\nternal representations by error-propagation. Parallel Distributed \nProcessing: Explorations in the Microstructure of Cognition \n(eds. DE Rumelhart & JL McClelland) Volume 1, Issue 6088. \nMIT Press, Cambridge, 318-362. \nRussell S & Norvig P (2010) Artificial Intelligence: A Modern \nApproach, 3rd  Edition. Pearson, 1152 p.  \nSamuel A (1959) Some studies in machine learning using the \ngame of checkers. IBM Journal of Research and Development \n44(1.2). \nSchank RC & Abelson RP (1977) Scripts, Plans, Goals, and Un-\nderstanding: An Inquiry into Human Knowledge Structures. \nHillsdale, NJ : Lawrence Erlbaum Associates, 256 p. \nSchwefel H-P (1995) Evolution and Optimum Seeking. John \nWiley, New York. \nSimon HA (1969) The Sciences of the Artificial. The MIT Press, \n1969. \nTuring AM (1950) Computing machinery and intelligence. Mind \n59:33-46. \nVenna J, Peltonen J, Nybo K, Aidos H & Kaski S (2010) Infor-\nmation retrieval perspective to nonlinear dimensionality reduc-\ntion for data visualization. Journal of Machine Learning Re-\nsearch 11:451-490. \nWiener N (1948) Cybernetics: Or Control and Communication \nin the Animal and the Machine. Hermann & Cie & MIT Press; \n2nd revised ed. 1961. \nZadeh L (1965) Fuzzy sets. Information and Control 8(3):338-\n353. \nZhou Z-H (2018) An Exploration to Non-NN Style Deep Learn-\ning. Keynote lecture, ICPR 2018, Beijing. \nWeb-History2: The History of Artificial Intelligence, Harvard \nUniversity \nWeb-History3:The History of Artificial Intelligence, University \nof Washington  \n\n43 \n \nWeb-McCarthy: John McCarthy: Computer scientist known as \nthe father of AI, Independent 1.11.2011 \nWiki-AIBO: AIBO  \nWiki-Cyc: Cyc  \nWiki-History1: History of Artificial Intelligence  \nWiki-Logic: Logic Theorist \nWiki-Mars: Mars Exploration Rover   \nWiki-Minsky: Marvin Minsky  \nWiki-Robocup: Robocup 2D  Soccer Simulation League \nWiki-SCI: Strategic Computing Initiative   \nWiki-Simon: Herbert A. Simon   \nWiki-Shannon: Claude Shannon  \nWiki-Speech: Speech Recognition  \nWiki-Wiener: Norbert Wiener  \nWiki-Feedback: Feedback  \nWiki-Shannon: https://en.wikipedia.org/wiki/Claude_Shannon \n \n \n \n \n \n \n\n44 \n \n3 Artificial Intelligence Representation Methods  \n3.1 \nIntroduction \nHerbert A. Simon (1916-2001), a Nobel laureate in economics \nwho studied problem solving processes in human beings and ar-\ntificial intelligence, emphasized in his book “The Sciences of the \nArtificial” (1969) that “solving a problem simply means repre-\nsenting it so as to make the solution transparent”. Similarly, Al-\nbert Einstein has been claimed to have said \"if I had an hour to \nsolve a problem, I would spend 55 minutes to diagnose it and \nfive minutes to solve it\". \nA major challenge in implementing systems that perform func-\ntions that are considered intelligent is to represent problems and \ntheir parts in such forms from which they can be automatically \nsolved. The task can be, for example, a medical diagnosis, car \nlane keeping, language translation, or home robotics. Suitable \nrepresentations have been sought, e.g., from neuroscience, math-\nematics, formal logic, and imitated human intelligence. The \nchoice of a proper representation is thought to lead to an easier \nsolution. For example, a writing is a representation that substan-\ntially facilitates communication between people: the phonemes, \nsyllables, or whole words are coded by letters. The ability to read \nand write are central to human learning, so it is natural to look \nfor similar solutions for learning capable artificial intelligence. \nKey issues in implementing an intelligent lane guard or robot \ninclude actively collecting data from the environment, trans-\nforming it into meaningful information, and appropriate action \nbased on its interpretation. This problem of information repre-\nsentation and modeling has been solved by both symbolic and \ndata-driven methods (Russell & Norvig, 2010). The latter, usu-\nally implemented by connectionist neural networks, represents \nthe current mainstream of artificial intelligence - with a primary \ninterest in developing learning algorithms and handling data \nmasses. One explanation for the popularity of data-driven meth-\nods is the available easy-to-use tools that allow even for persons \nnot familiar with statistical methods to go forward with their own \ndata. These are offered by, among others, by Google, Microsoft, \nFacebook and Amazon. \nRepresentations still play a significant role. Boundaries can be \ndrawn based on whether a representation is understandable for \nhumans, or only suitable for automatic processing. Ideally, an \nartificial intelligence application is built on data and knowledge \nas well as application-independent algorithms based on them \n(Figure 3.1). However, to date, the algorithms and ways of rep-\nresenting knowledge have not been independent. This is due to \nthe gap between the representations and algorithms of symbolic \nand data driven solutions. This is a major obstacle to the devel-\nopment of man-made versatile artificial intelligence. \n\n45 \n \n \n \n \n \n \nFigure 3.1. A typical artificial intelligence application. \n3.2 \nSymbolic Artificial Intelligence \nSymbolic Artificial Intelligence seeks to present knowledge as \ntangible elements, such as edges, angles, objects, their interrela-\ntionships, and rules that describe the conditions and effects of \nactions. The information is typically represented as text strings. \nIf the presentation of data is successful, functionality that can be \nconsidered intelligent can be implemented, for example, by logic \nprogramming. This can be considered to mimic the correspond-\ning human deductive problem solving. \nLet's look at a simple example that finds the relationship between \ngenerations, when the following direct parents are known: Alan \nis Ann's father, Elizabeth is Ann's mother and Ann is Eric's \nmother. In Prolog (Programmed Logic) (Wiki-Prolog) this could \nbe expressed \nfather (Alan, Ann) \nmother (Elizabeth, Ann) \nmother (Ann, Eric) \nwhere the words “father” and “mother” are so called predicates. \nWe are still defining parenting relationships with conditional \nstatements, which are the rules that underlie reasoning. Here the \ncapital letters A, B and X represent variables that can be replaced \nby any fact \n     grandparent (A; B) :- parent (A, X), parent (X, B) \n     parent (A, B) :- father (A, B) \n     parent (A, B) :- mother (A, B) \nNow the Prolog interpreter can be asked \"?-grandparent (Z, \nEric)\", and the obvious answer is given to the person by auto-\nmatic reasoning. In the process the Prolog interpreter matches \nthe predicates to the conditional statements, finding all the re-\nsults that meet the conditions: \n     Z = Elizabeth \n     Z = Alan \nThe challenge of symbolic artificial intelligence is to acquire and \nbuild the necessary knowledge base. In our example, the infor-\nmation could have come from the population register, or from \ndata collected by a genealogist. In a more general case, the learn-\ning process of the rules should be learned. \napplication independent algorithms \ndata and/or knowledge \nartificial intelligence application \n\n46 \n \nDue to shortcomings in automatic learning, symbolic artificial \nintelligence still requires manual work to gather information and \nprepare rules. Douglas Lenat's Cyc project modeling common \nsense knowledge, started in 1984, is an example of the chal-\nlenges of this solution. It has so far required over 1,000 man-\nyears to implement over one million rules, according to some \nsources more than 20 million (Wiki-Cyc). This has not been \nenough to make the system capable of self-directed learning. \nCompared to the estimated 40,000 person-year development ef-\nfort of Linux kernel, the 200,000 person-years consumed by the \nManhattan project to create nuclear bomb, or the construction of \nthe Kheops pyramid, which needed an estimated 3 million per-\nson-years, the Cyc project is not huge. Nevertheless, more in-\nvestments are unlikely, since no one can say how many rules \nshould be built before Cyc starts to produce rules on its own and \ndevelops into super-intelligence, if ever. \nIn the early days of artificial intelligence, efforts were made to \nrepresent knowledge with natural language for logic program-\nming. Cyc is the only one of those developments, which has not \nremained a small-scale demonstration or a narrow single appli-\ncation focused realization. It has consistently been one of the \nmost controversial developments in artificial intelligence re-\nsearch, seen not only as a great opportunity, but also as a com-\nplete disaster. Depending on the observer, either too much has \nbeen invested into a dead-end, or too little to an important service \nfor the humanity. In any case, symbolic representations may turn \ninvaluable if machines need to justify their decisions. \nAdvances in machine perception capabilities may, in the future, \nallow the acquisition of the symbolic information needed by sys-\ntems like Cyc. Developers expect future computer vision meth-\nods will be able to extract accurate depictions of everyday situa-\ntions and spatial relationships from the pixels in the images. In \nthat case, thanks to Cyc's existing rule base, genuinely smart \ncooking and cleaning home robotics could be quickly made pos-\nsible. \nAn example of the difficulty of predicting the technological fu-\nture over short to medium term is the \"object profile\" introduced \nin the 1999 MPEG-4 video encoding standard. It took advantage \nof the predicted “soon to be reached breakthroughs\" of artificial \nintelligence and pattern recognition. The idea was to encode the \nEssential aspects of presenting knowledge symbolically and im-\nplementing knowledge systems are \nsyntax: the rules of human and machine-understandable ways \n                  to create descriptions \nsemantics: meanings defined according to syntactic rules \nontology: A knowledge structure that describes concepts and \n                  their semantic relationships. \n\n47 \n \nmoving objects and related changes separately from the un-\nchanged background. However, it is only now 20 years later that \nthe necessary knowhow is available. At the same time other \nvideo coding methods have improved, and the \"object profile\" is \nnot computationally viable. \nA significant strength of symbolic artificial intelligence is that \nthe representations, reasoning chains and results are in a form \nthat can be understood by humans. Thus, erroneous operations \ncan be traced and corrected. The inability of the inference ma-\nchine to understand meanings is a side issue here. \nSymbolic artificial intelligence has been criticized based on the \nfamous Chinese room argument (Wiki-Searle), since it is not \nconsidered to have  an understanding of the meanings: a message \nis sent to a person under the door in Finnish and must be trans-\nlated into Chinese. If he doesn't know Chinese, or Finnish, or \nneither language, he uses Google Translate to find his answer, \nprint it out on paper, and slip it under the door to the questioner. \n3.3 \nData-driven Artificial Intelligence \nData driven artificial intelligence is easier for application devel-\nopers, because it does not refine data into semantically meaning-\nful descriptions. Instead, the system builds and optimizes its own \nrepresentation, for example, based on input images and recog-\nnizes the objects in new images. This is very attractive because \ntraining can be automated. \nUnfortunately, this comes at a price: the built-in representation \nmay be incomprehensible to humans, which can make it ex-\ntremely difficult to find explanations for system functions and \nerrors. For example, one layer of a translation machine's neural \nnetwork can have millions of coefficients, each of which has \nsome meaning to the whole. The Chinese room argument justi-\nfies not to consider such  technology as artificial intelligence. On \nthe other hand, how many bilingual  Finnish and Chinese speak-\ners can explain how they make quick translations? \nIn data-driven artificial intelligence, reliability is pursued by \nproviding huge amounts of data during the learning phase so that \nall options are covered. Similarly, learning Chinese (or Finnish) \nis a long and laborious process. \nAlthough artificial neural networks are often claimed to repre-\nsent inductive reasoning that builds structures, i.e. symbols, from \ntheir observations, their capacity is still quite limited. For exam-\nple, making three dimensional interpretations from two dimen-\nsional images fed to a neural network is an unsolved challenge. \nThis alone is a barrier to numerous everyday applications that \nare deceptively easy for humans. Importing physical knowledge \nappears to be often easier by symbolic means, in practice, by \nmathematical models of reality measured by sensors. \n\n48 \n \n3.4 \nSymbolic + Data-driven Artificial Intelligence \nThere is still a significant gap between symbolic and data driven \nsolutions that has been investigated over decades. Based on bio-\nlogical findings, David Marr (1945-1980), in a book posthu-\nmously completed by his fellow researchers (Marr, 1982), out-\nlined the procedure depicted in Figure 3.2 for constructing three-\ndimensional models from two-dimensional images.  It is a com-\nbination of data-driven solutions and symbolic representations.  \n \n \n \n \nFigure 3.2. Progress of analysis from primal sketch to three-di-\nmensional model. (© Tuomas Holmberg) \n1. Creating a primal sketch consisting of a view with recog-\nnized edges, areas, corners, etc., reminiscent of the nature of \nthe view produced quickly by the artist. \n2. Proceed with producing a 2.5-D sketch, including depth cues \nprovided by analysis of texture and shadows in the primal \nsketch. \n3. Produce a three-dimensional, view-independent model of the \nview. \nTo accomplish this, Marr proposed a three-level solution con-\nsisting of \n1. implementation level, such as the camera and the computer, \nthat mimic the neural system. Current understanding sug-\ngests that artificial neural networks can play a role in this. \n2. algorithm level that controls and modifies presentation, for \nexample, based on e.g. reasoning rules and physical \nknowledge; and \n3. computational level to select the tasks to be solved and guide \nthe activities. This makes the system work for some purpose. \nDecades later, with advances in machine learning based on neu-\nral networks triggering the latest excitement on artificial intelli-\ngence, renowned neuroscientist Tomaso Poggio (2010) proposed \nto add to Marr’s framework  \n4. learning to get solutions without detailed programming. \nInput image    \nPrimal sketch \n2.5-D sketch \nView independent \n3-D model \n\n49 \n \nThis addition has not, at least so far, led to the capability to create  \nthree-dimensional models that are independent of the viewer’s \nposition. Representation issues are therefore still core challenges \nin creating intelligent systems. The current field of neural com-\nputation is probably only at the level of creating Marr’s primal \nsketch, and it is difficult to estimate what the next truly signifi-\ncant step could be. The late introduction of machine learning into \nthe canonical model may be a sign that other essential compo-\nnents may also be missing. \nAI systems have regularly been built starting from zero \nknowledge. It has been hypothesized that based on human pro-\nvided basic knowledge and preliminary algorithms the systems \nwill at some point get  ability to learn by themselves to use  ob-\nservations, questions, actuators -  and information from the In-\nternet. In these scenarios for more than half a century the re-\nsearchers have believed that “the solution is around the corner”. \nOne potentially fruitful research path is Bayesian program learn-\ning, which automatically learns to construct an algorithm that \ncan produce input data even based on a single sample (Lake et \nal., 2015). The method has been demonstrated to learn handwrit-\nten characters, but could also work with speech signals. The key \nprerequisite is modeling of application knowledge and uncer-\ntainty. From the same basis, symbolic methods based on logic \nprogramming and grammars have failed to create artificial intel-\nligence that learn from the examples. Employing neural compu-\nting and massive amounts of training data has been a faster route \nto practical applications. \nIt would be most natural if machine intelligence used the same \nrepresentations and concepts as humans, that is, employed the \nsame semantics. Communication with machines would then be \nin natural language and with the same meanings. Symbolic arti-\nficial intelligence has therefore an undeniable role when dealing \nwith people in their environments. On the other hand, data-\ndriven artificial intelligence suits to recognition tasks, acting as \neyes and ears, and processing signals produced by the other \nsenses. Together the symbolic and data-driven approaches  allow \nfor higher levels of functionality. \nData-driven connectionist machine intelligence has some ability \nto recognize objects on the dining table in the kitchen, such as \nspoons, forks, plates, beverage glasses, napkins, etc., contrib-\nuting to the creation of  a symbolic representation. Based on this \ninformation, a home robot based on symbolic knowledge and \nreasoning rules could generate an action sequence to first gather \nthe cutlery from the plates, always proceeding to unobstructed \nobjects to be picked-up and put to the dishwasher. \nCombining of multiple sources of information and elementary \nactions into goal-oriented behavior is overwhelmingly challeng-\n\n50 \n \ning without “understanding” their relationships and dependen-\ncies; pattern recognition alone is not enough. Thus, artificial in-\ntelligence is not (at least not yet) able to compete with humans \nin acting in everyday environments. No current artificial intelli-\ngence implementation can read the instructions in the dishwasher \nmanual,  and then act accordingly. \nAlmost all the everyday problems involve the need for good un-\nderstanding of three-dimensionality and practical uncertainties, \nwhich are modeling challenges for both representations and \nmethodology. People use invariant representational techniques \nthat enable recognizing the same object from multiple view-\npoints, even when partially occluded, although it has been seen \nonly once. Unfortunately, we don’t know how we do it.  \n3.5 \nRepresentation of Information \nThe successes of data-driven connectionist approach have at-\ntracted developers and researchers to focus almost exclusively \non the application of deep neural networks. This solution is well \nsuited to situations where large amounts of data are available as \ncategorized raw observations, such as images and speech signals. \nIn other cases, however, it may be highly justified to consider \nthe use of other representations and methods. \nIn light of current understanding,  procedural program code is \nnot an optimal way of representing knowledge already due to the \nmanual maintenance effort. In addition, system developers, data \nand knowledge holders are typically different individuals who \nneed to  communicate with concepts that all parties understand. \n3.5.1 Physical knowledge \nFor centuries, mankind’s brightest individuals have built under-\nstanding of the laws of nature. Examples of the results include \nNewton’s basic mechanics, Einstein’s theory of relativity, Max-\nwell’s equations, etc. The experimental particle physics work \ncontinues, e.g., by researchers working at  CERN. \nSuch scientific knowledge is independent of the mainstream \ntechnology of the time but has enabled its continuous renewal. It \nis probably unrealistic to assume that we have arrived at the end \nof scientific development with artificial intelligence and every-\nthing we have learned before can be rejected? The key to future \nbetter artificial intelligence can well be in the utilization of  pre-\nvious, proven knowledge with new automatic learning methods. \nSimulations based on physical knowledge imitate reality and \ncan  provide data to a learning system. For example, simulations \nhelp collaborating robots  to learn to avoid collisions without de-\nstructive experimentation, or large numbers of virtual photoreal-\nistic kitchens could  be created to teach neural networks variants \nof everyday reality. Together, physical models and simulations \nhave significantly speeded up the  digital revolution (Figure 3.3). \n\n51 \n \n  \n       ARCHITECTURE Behavior OF Sensor IS  \n       BEGIN \n       PROCESS(SensorReading) \n          BEGIN \n             CASE SensorReading IS \n                 WHEN “00” => s <= y; \n                 WHEN “11” => s <= y; \n                 WHEN OTHERS => s <= z; \n          END CASE; \n       END PROCESS; \nKuva 3.3. Maxwell’s equations and part of an integrated circuit’s \nbehavior model written in  VHDL language. (© 123RF) \nBehavioral models that accelerate the design of integrated cir-\ncuits are mathematical descriptions of their properties. Because \nthe models can be produced in arbitrary quantities, they can be \nused through simulations to learn whether a solution is feasible, \nand to predict the performance of the design. Such advanced \nfunctionalities that could be considered artificial intelligence \nhave been extensively incorporated in design automation in all \nfields of technology. \n3.5.2 State representation \nSymbolic information is often modeled as a state representation, \nwhere the solution to the problem is found through search. \nRoughly, the principle is to establish the states and possible state \ntransitions or actions in the problem, and then find the path from \nthe initial state to the desired end state by using the allowed ac-\ntions. Each operation changes the state of the state space. Below \nwe consider a small warehouse where pallet A needs to be \nmoved to the loading dock (Figure 3.4).  \nThe pallets A, B, and C can only be moved at right angles and at \na time only to the next position. Each possible pallet location is \nlabeled by numbers 1-5, and the initial state is ABC00, where 0 \nrepresents the empty space, A, B and C occupying positions 1, \n2, and 3, respectively.  \nInitially, position transfers 2-> 4 or 3-> 4  are possible, resulting \nin respective new states A0CB0 or AB0C0. A human is able to \nsee the solution to this simple transfer problem directly, but au-\ntomated implementation requires either a ready-made search al-\ngorithm or logic programming. \nThe A* algorithm is probably the most widely known heuristic \nsearch algorithm. Powerful and under certain conditions optimal, \nA* is very popular in a variety of route search problems. The \nexistence of this algorithm, which was originally developed for \nmobile robot guidance for environments containing obstacles, is \noften a motive for modeling problems into graph representations. \n\n52 \n \n \nFigure 3.4. Example of modeling a pallet transfer task. \nIn the A* algorithm, each state A, B, etc., is described as a node \nas shown below. The number at each state transition is the effort \nof reaching the target node, e.g., the cost of moving to a new \nlocation. The idea behind the algorithm is following: \n4. At each moment, we con-\nsider moving to every \npossible target node xi \n5.  the heuristic function \nf (xi)  = g (xi) + h (xi) eval-\nuates the work  to the tar-\nget node \n6. h(xi) is an estimate of the \nwork from node xi to the \ntarget node and \n• \ng(xi) known effort so far \nrequired to move to xi  \n• \nnext, move to the node \nthrough which f(xi) gives \nthe shortest route \nA* search is optimal if h(xi) never overestimates the effort to \nreach the target node, so the estimate must be optimistic.  \nIn case of the graph above we search for the shortest route from \nnode A to the destination node, in this case xi = K. We assume \nthat as the search progresses, the distance to the destination al-\nways decreases by at least step 1. Thus, at the first four search \nlevels our prediction for the distance to the target node as h(xi) = \n4,3,2,1, respectively. \nAt node A: can expand to nodes C and B, h (xi) = 4 \n• for node C, f (xi) = 4 + 4 = 8 \n• for node B, f (xi) = 3 + 4 = 7 \n       → select B, because of shorter distance prediction \n\n53 \n \nAt node B: can expand to nodes C and D, now h (xi) = 3 \n• for node C, f (xi) = (3 + 5) + 3 = 11 \n• for node D, f (xi) = (3 + 5) + 3 = 11 \n       →select  D at random as there is a tie \nAt node D: can expand to node E, h (xi) = 2 \n• for node E, f (xi) = (3 + 5 + 3) + 2 = 13 \n• the forecast of the route through earlier node C is shorter, so \n        →select C next \nAt node C: can expand to node H, h (xi) = 3 (notice search level!) \n• for node H, f (xi) = (4 + 7) + 3 = 14 \n   but this is longer than the prediction through node E, so \n         → select E next \nAt node E: can expand to nodes G and F, h (xi) = 1 \n• for node G, f (xi) = (3 + 5 + 3 + 6) + 1 = 18 \n• for node F, f (xi) = (3 + 5 + 3 + 5) + 1 = 17 \n          → select H next because it provides route forecast of 14 \nAt node H: can expand to nodes K and G \n• for node G, f (xi) = (4 + 7 + 2) + 2 = 15 \n• for node K, f (xi) = (4 + 7 + 5) + 2 = 18 \n       → but now we find that target node K has been achieved! \n• the distance from departure node is 16. As the nodes G and  \n    F have an optimistic route length prediction of 18, they can’t  \n    be on a shorter route if the heuristic function is optimistic \n3.5.3 Modeling games as state representations \nThe goal of game participants is to beat their opponents. Most \ngames can be modeled as game trees that are graphs in which the \nnodes are game situations (states) and the transitions between the \nstates are player actions such as moves.  \nThe presentation of game states varies, for example, from dis-\ncrete chess board situations to statistical models. In case of sim-\nple games the entire game trees from the initial situation to the \nfinal solution could be modeled. Then, the player starting the \ngame could be able win every time or ensuring at least a draw. \nHowever, in many games, e.g.,  chess and poker, the state space \nis very large. As a result, simulations are of great importance in \nteaching artificial intelligence to play such games. An automated \nsystem can learn winning strategies with simulation producing \nsituations at tremendous speed, enabling to go through large \nnumbers of entire game sessions with the neural network serving \nas a modeler.  \nIn two-player games both players try to maximize their own and \nminimize the opponent's advantage. This is called the minimax \nstrategy, where in the max node of the game, player 1 tries to \nmaximize his or her advantage and in the min node, player 2, in \nturn, tries to minimize the advantage of player 1. \n\n54 \n \nConsider the minimax strategy using the game tree in Figure 3.5, \nwhere it is possible to reach a draw (D = 0), lose (L = -1), or win \n(W = +1). Each node is marked with the minimum or maximum \navailable, depending on the level involved in the game tree. \n  \nFigure 3.5. A minimax game tree. \nThe beginner (player 1) has modeled the entire game tree all the \nway down to the leaf nodes and traced the game from its last \nnodes backwards, maximizing at the max nodes and minimizing \nat the min nodes. Generally, the entire search tree cannot be pro-\nduced due to computational complexity or game-related random-\nness, so it may be truncated, for example, by merely searching a \nfew layers down from the current state. \nThe beginner of the game notices that by choosing the rightmost \nbranch of the tree, he or she can at most lose, since at the min \nlevel the opponent can from the available two branches choose \nthe alternative leading to the loss. The same applies to the center \nbranch. From the left branch player 2 can steer the game to a path \nleading to a possible loss, but at the last max level the player 1 \ncan  select a draw. \nIn the minimax strategy, the values of the end nodes can be set \nin an arbitrary, though still a rational, way. In world politics we \nhave witnessed a game in which the president of a big nation has \nsought to force others to play according to his unilaterally de-\nfined rules.  \nIn the following game tree, the numerical values represent the \nDJT's \"tis-for-tat\" emotional reward values, while the minimiz-\ning player aims at financial stability. The starting party,  DJT, is \nthe maximizing player (Figure 3.6). \nDJT states that there is no point in joining the TTIP transatlantic \nagreement presented in the right branch because the minimizing \nplayer (EU) will not later accept dictation agreements. Instead, \nthe best outcome is to increase customs duties, as it can try to \nforce individual EU countries into bilateral trade agreements. \nSuch real-world games, involving unpredictable or augmented \ninformation, are dynamically shaped by changing situations. On \nthe winning path of this tree, too, DJT has forgotten that \n\n55 \n \nindividual EU countries have no authority to negotiate trade \nagreements. \n   \nFigure 3.6. A global politics minimax example. \n3.5.4 Feature representation \nFeatures are computationally extracted information from data, \nand are most versatile  representations and popular especially for \ninterpreting data from sensors. For instance, speech features can \nbe spectrograms, while features extracted from images might be \nbe texture and color histograms. \n Typical feature representation is a table in which each data \nsample is described by, for example, 10 features. In that case, the \ndimensionality of the data is 10. \nIn the past, a significant part of pattern recognition research \nconcentrated on “feature engineering”, that is, designing features \nto be extracted, e.g.,  from financial data, medical images, or any \nother samples that are  in digital form. The objective has been to \nfind as few features as possible to efficiently and accurately \ndescribe the target phenomena. \nHowever, extraction of features from data requires strong \nassumptions. For instance, image preprocessing algorithms must \noften cope with the problem of segmenting numbers apart from \nmanually filled official forms. This is often complicated by \npatterned backgrounds that are irrelevant for reading the content.  \nConsequently, lots of of research on image processing has been \ncarried out, resulting in a large number of feature detectors with \nincreasing discrimination capabilities. An example is the Local \nBinary Pattern (LBP) method presented in Chapter 7. \nFor example, information about corners, edges, contrasts, object \ncircumference, number of holes, etc. can be extracted from the \nimage. Sometimes syntactic or structural methods are needed. \nOne possible such description of number 4 with  links connecting \nterminal, branch, and corner points is in Figure 3.7. \nThe attractiveness of structural representations is in the provided \ncapability to (at least roughly) reconstruct the original target. \n\n56 \n \nThis facilitates the development of further recognition and anal-\nysis algorithms, since the presentation is easily understood by \nhumans. As such, syntactic and structural methods are a step in \nthe direction of symbolic artificial intelligence. \nfeature points: [[A, terminal, 6, 7], [B, corner, 6, 14],   \n                          [C, branch, 16, 14], [D, terminal, 14, 24],   \n                          [E, terminal, 18, 8]] \n links:           [[A,B], [B,C], [C,D], [C,E]]  \nFigure 3.7. A structural description. \nNeural computing methods and machine learning have dramati-\ncally changed the attitude toward features. Essentially, low-level \nfeatures can be learned automatically, and no interpretations that \na human can understand are needed. This, in turn, has been a step \ntoward data-driven artificial intelligence.  \nFor example, each pixel in an input image can be considered to  \nbe a feature. In the case of samples of  handwritten numbers ex-\ntracted from the MNIST database, the dimension of the vector is \nthen 784  (see Figure 3.8) as the images consist of 28-by-28 pix-\nels. The feature values ranges can be from 0 to 1, or from 0 to \n255, if 1 or 8 bit pixels are used, respectively.  \n28x28 pixel 8-bit grayscale image \nfeature vector: [230 225 ... 15 17 ... 220 204 ...] \nAlternatively \n28x28 pixel 1-bit binary image; \nfeature vector: [1 1 1 ... 0 0 0 ... 1 1 ...] \nFigure 3.8. A feature vector representation of an image. \nWe may realize that as a single HDTV image has 2,073,600 pix-\nels, each video has a dimension of over two million multiplied \nby the number of frames. Indeed, in related machine learning \nproblems the dimensionality is enormous. \nIn the case of images, convolutions have been found to be effec-\ntive feature extractors. The principle is to multiply the pixels in \nsmall neighborhoods in the image  by corresponding elements in \nthe convolution template and summing the results.  \nIn images the closely-spaced pixels are highly correlated, which \ninformation is utilized by convolutional neural networks (CNN). \nThe CNNs aim at learning automatically the convolution tem-\nplates that most efficiently characterize inputs or differentiate \nbetween different categories of input data. In such cases, the pur-\npose is often to identify objects, for example, to find people, cars \nand animals in images. The recognition systems are trained by \npre-classified samples that represent the target categories. \nIn Figure 3.9 the convolution operation has resulted in feature \nvalue -10 at the upper left corner, somehow characterizing the \nlocal gradient in the input image.  \nA \nB \nC \nD \nE \n\n57 \n \n \nKuva 3.9. Example of computing convolutions. \nAs the result of learning, it is generally observed that convolu-\ntions tend to produce feature information related specifically to \nedges, ridges, and corners. In multilevel neural networks the fol-\nlowing levels combine these observations. For example, after be-\ning trained a CNN might provide specialized recognizers for \nhandwritten numbers. \nMuch of the research in the field is conducted using standard-\nized, very large test databases, such as ImageNet (Russakovsky \net al., 2015) and MNIST (LeCun & Cortes, 2010). If the availa-\nble data is more limited, the development of a new application \nmay result in a significantly lower recognition accuracy, despite \nusing state-of-the-art methodology. \n3.5.5 Feature representation enabling reconstruction \nAuto-encoder is a neural network category capable of building a \nfeature representation from which the inputs can be recon-\nstructed (Rumelhart et al., 1986). For example, below in Figure \n3.10 images are fed to the network with the aim of finding a rep-\nresentation that minimizes the reconstruction error. \n \n \n \n \n \nFigure 3.10. Principle of auto-encoder. \nThe auto-encoder consists of encoding and decoding blocks, \nwith a compressed representation layer in between. That hidden \nlayer can also be rightly called a \"feature layer\". The encoder \nseeks to learn a representation from which the decoder can pro-\nduce a good approximation of the original input. Once the net-\nwork has been trained, the decoder is removed, and the encoder \nis used to calculate the features. \nAuto-encoders are often used as part of deep learning convolu-\ntional neural networks, but they also have applications as such. \nOne of them is the synthesis of face images. By teaching an auto-\nencoder with a large number of faces, suitable inputs can be used \nencoder \ndecoder \ninputs                                                                               reconstructions \nhidden layer  \n\n58 \n \nto produce entirely new ones that represent the interpretation of \nthe inputs. \nAlthough auto-encoder is an unsupervised learning scheme, it \ndoes not achieve the capability to reconstruct everything. For in-\nstance, if images of hands are used as inputs, feeding a face im-\nage will result in a hand-like result. Only balanced training with \nboth categories will produce the desired results. They are far \nfrom being able to automatically - and perhaps spontaneously -\nlearn meanings from the environment. \nTraining of neural networks often requires their parameters to be \nmodified and proper performance metrics to be used. This also \napplies to auto-encoders, and poses substantial challenges in \nbuilding practical applications, e.g., for medical imaging in \nwhich unbalanced training samples are common, only a small \nminority representing cases to be recognized. \n3.5.6 Dimensionality reduction and visualization of feature \nspace \nIn the processing of multidimensional data, support is often \nsought from visualizations that make the structure of the data and \nits possible imbalance easier to see by humans. A typical objec-\ntive is to produce a two-dimensional view of data from which \nthe human can make conclusions about its possible categoriza-\ntion (Venna et al., 2010). \nIn addition, the performance of many machine learning algo-\nrithms degrades with the increasing number of dimensions un-\nless the amount of training samples is significantly increased. \nThis phenomenon is known as the \"curse of dimensionality,\" \nwhich is due to the sparsening of data samples in the feature \nspace due to additional dimensions. As a result, the accuracy of \nthe classification may suffer (Figure 3.11). \n \n \n \n \n \nKuva 3.11. Curse of dimensionality. \nThere is  a growing number of dimensionality reduction methods \nto meet the human capability to judge data from two or at most \nthree-dimensional representations. Typically, such mappings are \nintended to keep the relative distances or topology of the neigh-\nborhoods in large-scale data. An auto-encoder can also be con-\nsidered as a method for reducing dimensionality, although it does \nnot seek to maintain any single property. \nnumber of dimensions (features) \nmäärä \n0\n0 \n100% \naccuracy  of \nclassification \n\n59 \n \nThe simplest dimensionality reduction scheme is identifying the \nfeatures that best distinguish categories of data. For example, out \nof ten features, the two or three that lead to the smallest recogni-\ntion error are selected. However, this procedure is only applica-\nble to supervised learning situations, in which the sample cate-\ngories are known in advance. \nIn the absence of category information, a suitable linear or non-\nlinear projection or mapping algorithm may be used to compress \nthe high-dimensional data into lower dimensions. This proce-\ndure can also be employed with supervised learning cases. \nThe manifold concept is associated with dimensionality reduc-\ntions. For example, while standing in a parking lot, we observe  \nthat our immediate environment is flat, even though we actual \nstand on the round earth. In other words, we percept earth as two-\ndimensional, but we are still on the surface of a three-dimen-\nsional sphere. Thus, our easy-to-understand two-dimensional \nmanifold is in three-dimensional space. \nWe can concretize this by drawing on the paper a two-dimen-\nsional xy-coordinate system, marking arbitrary data points in it, \nand folding the sheet into a paper ship. As a result, the data points \nare now in three dimensions. By dismantling the ship back into \na flat sheet, we reduce dimensionality.  \nFor dimensionality reduction both linear and non-linear methods \nexist. The idea of the linear schemes is to find such projections \nof data that expose the variations of the data from largest to \nsmallest.    \nAn example of non-linear dimensionality reduction is in Figure \n3.12 that demonstrates the Isometric Mapping (IsoMap) method \n(Tenenbaum et al., 2000).  The colored samples help to see the \nmapping of  3-D data representation on the left onto a 2-D man-\nifold on the right.   \nMathematically, the dimension of a manifold is the number of independ-\nent parameters needed to determine a point on it: \n• \nin one-dimensional case, manifolds are straight and curved, such as \ncircles, ellipses, hyperbolas, that is, any curves. Also, space curves \nwhose parametric equations have the form [x, y, z] = [f (t), g (t), h \n(t)] are one-dimensional, since t is the only independent parameter. \n• \ntwo-dimensional manifolds are surfaces such as planes, cylinders, \nellipsoids, toroids. These include only surfaces, not their possible in-\nsides. \n• \nthree-dimensional manifold, which locally appear as three-dimen-\nsional Euclidean space, is significantly more difficult for a human to \nperceive, let alone a four-dimensional manifold, which is a concep-\ntual framework of relativity. \n\n60 \n \n \n \n \n \n \n \n \nKuva 3.12. Three-dimensional “coil spring data” and its two-di-\nmensional description. (© Tuomas Holmberg) \nPrincipal Components Analysis (PCA), also known by names \nHotelling or Karhunen-Loève Transform (Wiki-PCA) is the \nmost popular linear dimensionality reduction method. It is usu-\nally used as the first experiment for unknown data before moving \nto non-linear dimensionality reduction. \nThe principle of PCA is to determine such orthogonal base vec-\ntors for multidimensional data that the data can be reconstructed \nwithout major information loss using just the most significant \nones of the vectors. The method has often been used for reducing \nthe number of features as classification becomes cheaper, and \nthe results can improve, despite the loss of information, as the \ndata becomes denser in the feature space! \nFigure 3.13 on the left shows a two-dimensional feature space in \nwhich the data samples are located as elongated structure. After \ndetermining directions for optimal viewing of the maximum and \nthe minor variations,  those can be set as new coordinate axes of \nthe feature space. \n \n \n \n \nKuva 3.13. Principle of principal component analysis (PCA). \nIn the above case, the number of dimensions didn’t drop. How-\never, it is easy to see that the clusters in the data could probably \nbe discriminated by just selecting suitable value ranges from the \nbiggest variation axis.  \nSuccessful use of PCA requires linear correlations in the sample \ndata. As a simple method, it is popular and often gives convinc-\ning visualizations. Independent Component Analysis (ICA) is \nanother method that can uncover hidden data dependencies. \nHowever, its application to reducing dimensions is not easy. \n   \n   \nbiggest \nvariation \nsmaller  \nvariation \nsmaller \nvariation \nbiggest \nvariation \n\n61 \n \nIn many cases, machine learning applications need to deal with \nvery high dimensional data. For example, the handwritten num-\nber samples contained in the MNIST database are small 28x28 \npixel images, but the dimensionality is already 784. PCA is sel-\ndomly powerful with this kind of problems. Reducing the dimen-\nsionality by using higher-level features instead of pixels can be \nmore effective, but from the human point of view too many of \nthem may be needed. \nNonlinear dimensionality reduction techniques aim to produce \nvisualizations that are easy to understand for humans. These are \njust one-way methods: unlike with PCA, the original data can’t \nbe reconstructed from the results. On the other hand, they seek \nto bring the neighborhoods and densities of the high-dimensional \nrepresentation for human viewing based on of similarity \nmeasures. \nFigure 3.14 shows 2-D and 3-D visualizations of  MNIST hand-\nwritten number image data produced using t-SNE method (van \nder Maaten & Hinton, 2008).  The points corresponding to the \nnumerical values have been colored after the dimensionality \ndrop. It is interesting to note that 3-D visualization in this case \ndoes not appear to bring additional information for a human an-\nalyst. Two dimensions suffice, and the clusters could be separa-\nble even without coloring. However, now we may notice that \nsome data samples fall into incorrect apparent clusters.  \n \n \n \n \n \n \n \nFigure 3.14. 2-D and 3-D descriptions of MNIST data using the \nt-SNE method. (© Tuomas Holmberg) \nMulti-Dimensional Scaling (MDS) is one of the oldest methods \nfor dimensionality reduction (Torgerson, 1958). Its input data are \nsimilarities between all possible pairs of sample data calculated, \ne.g., as Euclidean distances from the features. The result is a sim-\nilarity matrix, each row representing the distance of a sample to \nevery other one in the sample set. Usually a two-dimensional \nprojection is then computed, maintaining the distances between \nthe sample pairs as close to the original ones as possible. \nFigure 3.15 shows defects of lumber mapped into a two-dimen-\nsional representation using the MDS method (Niskanen, 2003). \n\n62 \n \nIn this case, we notice that it is difficult to see distinct  structure. \nThis is explained by the principle of MDS to compute the dis-\ntance from each data sample to  all others. Depending on the in-\ntended use, this is either a desired or undesirable feature. \nAt its simplest, MDS is produced by performing PCA to the sim-\nilarity matrix. In practice, PCA can be considered as one variant \nof MDS. The difference is that PCA is a method of reducing di-\nmensionality, while MDS is a mapping technique. \n \nKuva 3.15. Multidimensional scaling. (© Acta Univ. Oul.) \nNiskanen M (2003) A Visual Training Based Approach to Surface Inspection. \nActa Univ. Oul. C 186, 125 s. http://jultika.oulu.fi/files/isbn9514270673.pdf \nIt is often more useful to uncover structure of data by using meth-\nods that consider neighborhoods. Among the best known of these \nare Isomap (Isometric mapping) (Tenenbaum et al., 2000) and \nLLE (Roweis & Saul, 2000). Recently, t-SNE (t-distributed Sto-\nchastic Neighbor Embedding), based on neighborhood density \nfunctions and information theoretic minimization of target func-\ntion (van der Maaten & Hinton, 2008), and UMAP (Uniform \nManifold Approximation and Projection) that views manifolds \nas fuzzy topological structures (McInnes et al. 2018), have \ngained popularity.  \nMany problems with high dimensionality do not have a clear cat-\negory structure. In such a case, even a human can’t completely \nclassify samples. For example, in many quality control applica-\ntions, changes from flawless material to defects or another qual-\nity class are continuous. Similarly, for example, changes in a per-\nson's facial posture and emotional states may be continuous-val-\nued.  \nNon-linear dimensionality reduction methods provide an oppor-\ntunity to analyze even in such cases. In Figure 3.16 LLE method \nhas been used for wood samples (Kayo, 2006) representing a \ncontinuum of appearances. \n\n63 \n \nThe self-organizing map (SOM) can also be considered as a \nmethod for dimensionality reduction (Kohonen, 2001). The prin-\nciple is that vectors in a two-dimensional map learn the charac-\nteristics of input data. A practical advantage of SOM is the op-\nportunity to produce rectangular visualizations that are conven-\nient for various user interfaces. \n \nFigure 3.16. Continuity of wood samples visualized by the LLE \nmethod. (© Acta Univ. Oul.) \nKayo O (2006) Locally Linear Embedding Algorithm. Acta Univ. Oul. C 237, \n120 s. http://jultika.oulu.fi/files/isbn9514280415.pdf \nFigure 3.17 depicts  the material variation of wood in a SOM. \nThis kind of visualization enables a human to define and modify \nboundaries for categories in a graphical manner. \n \nFigure 3.17. Visualization of wood material variation using a \nself-organizing map. (© Acta Univ. Oul.) \nNiskanen M (2003) A Visual Training Based Approach to Surface Inspection. \nActa Univ. Oul. C 186, 125 s. http://jultika.oulu.fi/files/isbn9514270673.pdf \nAn all-round dimensionality reduction method that fits every \npurpose  has not yet been developed. The current methods have \ntheir own drawbacks, but also strengths that can be utilized when \nthe nature of data is understood. For example, self-organizing \nmap models the multidimensional probability density. As such, \nthe method leaves little space for the rare categories when trained \n\n64 \n \nwith unbalanced material. However, it can be very useful in ex-\nposing the variation in the sample material. This challenge is  \ndemonstrated  in Figure 3.18 (Niskanen, 2003).  \n \nFigure 3.18. SOM and Isomap visualizations of unbalanced data. \n(© Acta Univ. Oul.) \nNiskanen M (2003) A Visual Training Based Approach to Surface Inspection. \nActa Univ. Oul. C 186, 125 s. http://jultika.oulu.fi/files/isbn9514270673.pdf \nOn the  left, the SOM has learned the probability density of wood \nsamples, allocating very few nodes for rare \"classes\". Only a few \nnodes are left for the knots and modeling their variation, alt-\nhough they are of interest. On the right,  Isomap shows knots as \ndistinct outliers. Obviously, it is better suited to uncover data im-\nbalances, and can be used for data exploration to produce more \nbalanced training sample sets. \n3.6 \nWhat Matters: Presentation, Data, or Algorithms? \nThe focus of artificial intelligence application designers and re-\nsearchers has changed. From an application point of view, it is \nsecondary how a problem is solved. The total effort required to \nachieve the solution is much more important for the developers. \nFeature engineering as human effort was laborious and resulted \nin extensive manual algorithm tuning. Now, with neural net-\nworks, the focus is on acquiring data and finding the parameters \nthat give the best performance. However, the algorithms may \nstill take a crucial role if data is limited, it is expensive to acquire, \nor other knowledge of the problem area is available, such as \nphysical models. \n3.7 \nReferences \nKayo O (2006) Locally Linear Embedding Algorithm. Acta \nUniv. Oul. C 237, 120 p.  \nKohonen T (2001) Self-Organizing Maps, Third Edition, \nSpringer. \n\n65 \n \nLake BM, Salakhutdinov R & Tenenbaum JB (2015) Human-\nlevel concept learning through probabilistic program induction. \nScience 350(6266):1332-1338 1332.  \nLeCun Y & Cortes C (2010) MNIST handwritten digit database.  \nMarr D (1982) Vision: A Computational Investigation into the \nHuman Representation and Processing of Visual Information. \nSan Francisco: WH Freeman and Company. \nMcInnes L, Healy J & Melville J (2018) UMAP: Uniform man-\nifold approximation and projection for dimension reduction. \narXiv: 1802.03426v2, 51 p. \nNiskanen M (2003) A Visual Training Based Approach to Sur-\nface Inspection. Acta Univ. Oul. C 186, 125 p.  \nPoggio T (2010) Afterword to Marr’s Vision and Computational \nNeuroscience. The MIT Press.  \nRoweis ST & Saul LK (2000) Nonlinear dimensionality reduc-\ntion by locally linear embedding. Science 290(5500):2323-2326. \nRumelhart D, Hinton G & Williams R (1986) Learning represen-\ntations by back-propagating errors. Nature 323:533-536. \nRussakovsky O, Deng J, Su K, Karause J, Sathees S, Ma S, \nHuang Z, Karpathy A, Khoslta A, Bernstein M, Berg AC & Li \nF-F (2015) ImageNet large scale visual recognition challenge. \nInternational Journal of Computer Vision 115(3):211-252). \nRussell S & Norvig P (2010) Artificial Intelligence: A Modern \nApproach, 3rd Edition. Pearson, 1152 p.  \nSimon HA (1969) The Sciences of the Artificial. The MIT Press, \n1969. \nTenenbaum JB, de Silva V & Langford JC (2000) A global geo-\nmetric framework for nonlinear dimensionality reduction. Sci-\nence 290(5500):2319-2323. \nTorgerson, WS (1958) Theory & Methods of Scaling. New \nYork: Wiley. \nvan der Maaten, LJP & Hinton GE. (2008) Visualizing data us-\ning t-SNE. Journal of Machine Learning Research. 9:2579-2605. \nVenna J, Peltonen J, Nybo K, Aidos H & Kaski S (2010) Infor-\nmation retrieval perspective to nonlinear dimensionality reduc-\ntion for data visualization. Journal of Machine Learning Re-\nsearch 11:451-490. \nWiki-Cyc: Cyc  \nWiki-PCA: PCA  \nWiki-Prolog: Prolog \nWiki-Searle: Chinese room  \n \n \n\n66 \n \n4 Machine Learning \n4.1 \nIntroduction to Data-driven Machine Learning \nThe most significant recent advances in artificial intelligence \nhave been achieved through machine learning (Goodfellow et \nal., 2015), (Duda et al., 2001), (Bishop, 2006). A popular strat-\negy is to feed large amounts of raw data into neural networks in \na \"brute force\" style. In this scheme, the role of algorithms as the \nbasis of  “intelligence” shrinks, as shown in Figure 4.1, and de-\nvelopers are more interested in modeling the data and related so-\nlutions. Based on the modeled data, it is possible to conclude its \nmost probable categories or to make predictions. For example, \nthe contents of input images can be categorized as cats or dogs, \nwhile the control parameters of the autonomous car are adjusted \nbased on the location of the roadside. \n \n \n \n \n \nFigure 4.1. Machine learning focuses on modeling the data. \nThe success of the data-driven approach has undoubtedly under-\nmined faith in presentations and algorithms and may have sur-\nprised many pioneers in the field. Especially, success has been \nachieved with problems where finding purely algorithmic solu-\ntions has been difficult, such as speech and face recognition. In \nmany cases, machine learning is close to statistical modeling, \ndata mining, optimization or retrieval. The manual development  \nof features and models by humans can be characterized as search \nor optimization that can now be automated by machine learning. \nThe popularity of data-driven machine learning stems from the \nflood of multidimensional data following digitalization and the \nwidespread emergence of problems that are difficult for people \nto understand. One can somehow visualize problems of two or \nat most three variables. For example, in information modeled for \nsymbolic artificial intelligence, this is manifested as laborious \ndeterminations of simple cause-effect and spatial relationships. \nData-driven machine learning and its easy-to-use tools available \nhave brought many previously difficult problems solvable by al-\nmost anyone. \nCar lane guards, speed limit sign recognition, and Internet image \nsearch engines are evidence of the power of this solution. They \nall have the same methodological core behind them, but are \ntrained with different image materials. The purpose of machine \nlearning algorithms \nmodeled data \nMachine learning system \nquery input \nprediction/class \ntraining data \n\n67 \n \nlearning is to avoid writing algorithms or rules for each applica-\ntion individually. However, the architectures of neural system \nimplementations are often different (e.g., the number of layers, \nconnections of neurons, activation functions), depending  on the \nrequirements of the given application problem. As shown in Fig-\nure 4.2, machine learning algorithms can be roughly divided into \nthree methodology classes, each of which will depend on the na-\nture of the data and the problem. \n \n \n \n \n \n \nFigure 4.2. Categorization of machine learning methods. \nIn supervised learning, learning takes place with inputs of known \ncategories (Duda et al., 2001). After learning, new feeds should \nbe able to be categorized into those categories. So training is \ndone by examples. For example, a text translation solution can \nbe taught using different language versions of the same materi-\nals, that is, through human supplied examples. In the same style, \none can learn how to correct spelling and grammatical errors in \nhuman typing. Learning can continuously improve performance \nby entering new data. \nThe problem with supervised learning can be misclassified train-\ning samples that drop accuracy. This problem is not present in \nunsupervised learning, where categories are not known in ad-\nvance, and may not even exist in the human-recognized sense \n(Duda et al., 2001). The principle is to construct, based on the \ninputs, a description of the data structures where the similar in-\nputs are located close to each other. Dimensionality reduction \nmethods and auto-encoders discussed in Chapter 3 are methods \nof unsupervised learning. \nIn reinforcement learning, the learning machine explores the \noperating environment, where each action receives positive or \nnegative feedback, for example, through situational analysis \nbased on new information generated by sensors (Sutton & Bar-\nto, 1998). The goal is to find the solution with the most positive \nfeedback. It is also possible to implement forgetting in reinforce-\nment learning, which is often difficult in other learning methods. \nContinuous reinforcement learning can mean continuing after \nthe first solution is found, seeking new, possibly better, solutions \nwith ever-increasing feedback. \nunsupervised \nlearning \noppiminen \nprior knowledge \nabout data categories or \nphenomena \navailable \nmachine learning \nproblem \nno prior knowledge \nabout data categories \n \nsupervised \nlearning  \nreinforcement \nlearning  \ndata obtai-\nned by ac-\nting \n\n68 \n \nIn addition to the above, there is semi-supervised learning \n(Chapelle et al., 2006), where training takes place through a \ncombination of unsupervised and supervised learning. In this \ncase, the methods of reducing the dimensionality can give an \nidea of the structure of the data and identify possible categories. \nThereafter, machine learning can ensure human categorization \nof interpreted data samples that fall close to the expected class \nboundaries. \nSemi-supervised learning is supported by the challenge of pro-\nducing a large amount of pre-classified training material. In ad-\ndition, when made by man, it is also prone to error. In addition \nto occasional mistakes, man is prone to systematic errors. Cor-\nrecting the latter is later difficult or even impossible without la-\nborious re-examination of the entire material. Hence, semi-su-\npervised learning aims to reduce human work. \nTypical useful data is always somehow structured. The task of \nmachine learning is to model the data to find structures and fi-\nnally act upon them when identifying objects, producing predic-\ntions or measures. Often, the strategy is to seek simpler struc-\ntures first and then more complex ones. As a result, the boundary \nbetween supervised and unsupervised learning is a line drawn in \nwater. \n4.2 \nProcessing of Data \nThe development of machine learning applications is based on \ndata and must be handled with careful scientific work practices. \nNamely, errors made with data sets can easily lead to solutions \nthat work with the original data, reaching, for example, 95% ac-\ncuracy, or even higher. In practice, however, accuracy may drop \nbelow 80%. \nIn the case of supervised learning, data samples are typically di-\nvided into three parts (Duda et al., 2001): \nTraining samples are material that is used to train the selected \nregression model or classifier. \nValidation samples are data that measure the prediction error of \na trained solution. This indicates the suitability of the regression \nmodel and the classifier, as well as the quality of the training, \nwhich depends on, e.g., the size of the training material. Tests \nperformed with validation samples can lead to changes in regres-\nsion models and classifiers. At the same time parameters are op-\ntimized. \nThe test samples are completely segregated data that is eventu-\nally added to the game when the expected optimum has been \nreached during the training and validation steps. The test set is \nintended to represent use in the actual application. However, \nthere is a risk in the pre-selected materials that the actual appli-\ncation may deviate from the conception given by it. \n\n69 \n \nThe sharing of available data depends on the application. If the \nregression model is already known, it is often done in 50:25:25 \nor 25:50:25 ratios. If the model to be used is already known (e.g. \nlinear regression has already been selected), the data can be di-\nvided into  randomly repeating training and test sets, for exam-\nple, in the ratios 50:50, 70:30, 90:10, or even 99:1. \nIn practice, sample data is always multidimensional and the \nvalue ranges of its various features may differ. In turn, learning \nthe structures of data often requires, depending on the methods, \ndistance computing in the feature space. As a result, the features \nmay need to be normalized so that the general distance norms \nwould function appropriately. \nFor example, in the case of the data samples in Figure 4.3, when \nusing Euclidean or block distance, the feature x1 dominates the \nlarger value range. This may not be appropriate. It may be rea-\nsonable to assume that the smaller value range is more signifi-\ncant in relation to the larger differences. \n \n \n \n \n \n \n \n \nFigure 4.3. Space spanned by features of different value ranges. \nCommon normalization methods are to set the mean of each fea-\nture to zero and variance to 1. This is necessary, e.g., in neural \ncomputation and perceptrons, and useful in certain regression \ntechniques and classification using support vector machines \n(SVM). \nA common big mistake is to normalize the entire sample set at \nthe beginning of the design process before dividing it into train-\ning, validation and test sets. The correct procedure would be to \ndetermine the normalizing factors from the training data alone \nand to use this information before dividing into the validation \nand test sets. \n4.3 \nSupervised Learning \nIn the case of supervised learning, there is either a regression or \na classification problem as shown in Figure 4.4. The regression \nproblem predicts the value of a continuous variable, for example, \n1.27, 478.67, 34576.4, etc. The classification problem, in turn, \npredicts the value of a discrete variable, e.g., 1, 2, 4, cat, dog.  \n  x1 \n  x2 \n20 \n1.5 \n25 \n0.0 \nC=(23.4,  1.5) \nB= (23.2,  0.8) \nA= (22.3,  0.8) \n\n70 \n \nBoth are predicted to be dependent on the input variables X = \n(x0, x2, x3,…) that explain the value of the dependent variable Y. \nIn each case, the inputs X may be discrete or continuous. In the \ncase of a regression problem, a continuous variable can be pre-\ndicted from the discrete inputs. \n \n \n \n \n \n \nFigure 4.4. Methods of supervised learning. \nRegression and classification are closely related. The key differ-\nence is that the regression identifies a model for the data struc-\nture and the classification identifies the structure to which the \ndata in the model belongs. Similar methods are used in both. If \nthe model and the structures are not understood, then it is a prob-\nlem of unsupervised learning. \nTypical regression problems include, e.g., determining the price \nof a used car. Inputs at that time are make, year model, mileage, \nand price as a dependent variable. One regression model created \nfor this purpose with construction descriptions can be found, for \nexample, in the reference (Matikainen, 2017). Predicting the re-\nmaining distance of an electric car is clearly a regression prob-\nlem, as is archaeological sample’s the so-called radio-carbon \ntiming based on C-14 isotope concentration. \nA frequently occurring special case is logistic regression in \nwhich the dependent variable is the natural logarithm of the risk \nof an event Y, which results in the analysis situation becoming a \nnormal regression model (Peng et al., 2002). In a linear case, \nsuch a model has the form \nln [P (Y = 1) / (1-P (Y = 1))] = aX + b. \nHere, Y can only get two values: either Y happens or it does not. \nThe probability of the occurrence is P (Y = 1) and the opposite \nis 1-P (Y = 1). Explanatory variables X can be anything, discrete \nor continuous variables that somehow influence the probability \nof an event. In everyday life, applications of logistic regression \nare encountered, for example in bettings organized by Veikkaus \nin Finland. \nMany medical diagnoses, on the other hand, are classification \nproblems where the patient's symptoms, physician findings and \nlaboratory test results are the explanatory variables. Face recog-\nsupervised \nlearning  \nclassification problem \nregression problem \nclassified \nsamples  \navailable \nmeasurements rep-\nresenting inputs \navailable \nvastaavia mittauksia\n\n71 \n \nnition in images is also a problem of classification. After learn-\ning the pre-categorized samples, the system is able to identify \ncategories of new samples based on their feature information. \nBig Internet companies like Google and Facebook have suc-\nceeded in giving classification of training materials as a volun-\ntary service unknowingly done by their users. At the same time \nusers often reveal their own interests. \n4.3.1 Regression models: learning to predict \nAfter recognizing the regression problem, the first attempt is \nusually a linear model \nE (Y|X) = f (X, β) = aX + b, \nwhere a is a parameter vector, b is a scalar, and β = [a, b]. In \nlinear regression between two scalars x and y, the model has the \nform \nE (y|x) = f (x, β) = ax + b, \nwhere a and b are parameters and (x, y) = [(x0, y0)... (xn, yn)] \npairs (explanatory variable, dependent variable). \nThe error criteria used to estimate the parameters β between the \nmodel prediction and the measured variable are usually either the \nsquared sum of the error (L2 norm) or the sum of the absolute \nvalues of the errors (L1 norm). The linear regression of the two \nscalars using the L2 norm gives the parameters \na = covariance (x;y) / variance (x) and \nb = mean (y) - a * mean (x) \nAn example of linear regression in Figure 4.5 is a model for the \ndetermination of the strength of lumber from modulus of elastic-\nity  obtained by bending tests leading to fracture.  \n \n \n \n \n \n \n \n \n \n \nFigure 4.5. Predicting the breaking strength of lumber through a \nlinear regression model. \nStrength of lumber against \nmodulus of elasticity \n\n72 \n \nWe note that the data points do not obediently hit the regression \nline, so the strength predictions carry the risk of classifying the \nmaterial as too strong or weak. The latter means selling good \ntimber at a lower price, the former can dangerously weaken the \nstructures. \nWe do not see clear class categories in the picture, although the \nboards are sold in strength classes such as C18, C24, etc. This \ncontradiction stems from the design rules and the strict human \nclassification criteria that were once followed. Many other actual \nregression problems have been interpreted as categorization for \nhuman use. \nWe find that linear regression is not necessarily the best predic-\ntive model for sawn timber strength. Often a better procedure, \nwhen the variables Y to be described are continuous or ordered \ndiscrete values, is to use the so-called regression trees for learn-\ning the prediction model (Breiman et al., 1984). Then, the model \nis built by recursively splitting the data space into parts. \nFigure 4.6 shows an example of a simple regression tree in which \nthe input variables x1 and x2 span the feature space. A simple \nregression model is fitted to the data by dividing the value range \nof the dependent variable Y, which is explained in pieces. Split-\nting ends when the desired error criterion is met. The value \nranges of Y are color coded and the red lines in the right figure \nrepresent their respective ranges of variables x1 and x2. \n \nFigure 4.6. Regression tree and corresponding feature space.  \nEach leaf node in the regression tree corresponds to one part of \nthe regression model. In the case of a new sample, the values of \nthe declarative variables x1 and x2 proceed from the root to the \ncorresponding leaf node and calculate the value of Y using the \nregression model it contains. Regression trees do not require nor-\nmalization of input data, which in itself is a significant practical \nreason for the popularity of the method. \nRandom forests are popular solutions for supervised learning in \nregression and classification, because of the accuracy achieved. \nTheir principle is to randomly take samples from training data \n\n73 \n \nand generate a large number of regression trees. The prediction \ngiven by each tree to the explanatory variable is combined with \nthe final result. When using regression trees, it is essential to en-\nsure sufficient training material. \nNeural networks are capable of modeling non-linearities, so their \napplication to regression models is very attractive. Because of \ntheir large number of internal parameters, there has to be a large \namount of data, regularly more than for regression trees. For \nsmall amounts of data, even linear regression due to its small \nnumber of parameters can lead to a better model than that pro-\nvided by neural networks. \nBoth regression and classification carry the risk of over- and \nunderlearning (also called over- and underfitting) (Bishop, \n2006). If the model has too many parameters, it may work cor-\nrectly for the training data but will fail to predict with other sam-\nples. For example, the regression tree suffers from overlearning \nif the data space is too fragmented. Then, each leaf node regres-\nsion model may predict on the basis of only one training sample \nand give good results only on data identical to the training sam-\nples. \nFigure 4.7 illustrates the problems. In overlearning, the model \nfits too tightly into the training data. In the case of underlearning, \nhowever, the training data does not represent the actual use of \nthe model. \n \n \n \n \nFigure 4.7. Over- and underlearning. \nBeyond regression trees, overlearning is also a particular prob-\nlem when using neural networks if there is too little training data. \nThe random forest method does not suffer from overlearning, \nwhich is another reason for its popularity. \nUnderlearning means that the resulting model is not sufficient to \nmimic the structure of the data. In a typical underlearning situa-\ntion, linear regression is chosen as the technique, but the rela-\ntionship between the input and dependent variables is non-linear. \nAs a result, the accuracy of the predictions remain poor. \nUsually, both over-and underlearning is caused by too little train-\ning data or has represented only part of the actual data space. In \npractice, each model performs worse in reality than with the ma-\nterial used during development. \n  Y \n  X \ntraining material \n used material \noverlearning \n  Y \n  X \ntraining material \nused material \nunderlearning \n\n74 \n \n4.4 \nLearning Classification \nIn classification problems, classes of training samples are \nknown, with the minimum number of classes being two. Mem-\nbers within each class are similar by some measure. Typical clas-\nsification problems include, for example, heart rate recognition \nfrom an ECG or PPG signal and junk e-mail recognition. There \nare a number of classification algorithms, the most popular of \nwhich are k-nearest neighbors (kNN), naive Bayes, combination \nclassifiers, gradient boosting, support vector machines (SVM), \nneural networks, and random forests (Duda et al., 2001), \n(Bishop, 2006). \n4.4.1 Random forest classification \nRandom forest classification is one of the best classification \nmethods. In it, the classification tree is constructed in a root-to-\nleaf style by dividing data samples into similar subsets (Liaw & \nWiener, 2002). Thus, more than one leaf node can represent one \nclass. The random forest procedure is an excellent compromise \nin the classification between sample size requirements and the \nperformance to be achieved. Above, the goal of random forest \nregression was to have a continuous value, in which the model \nwas adapted to the explanatory variable step by step with each \ndeclarative variable. \n4.4.2 Naïve Bayes classification \nThe Naïve Bayes classification is a simple yet performative \nmethod of supervised learning (Bishop, 2006). It is also suitable \nfor use with many features. It only needs a priori probabilities \nfor each class and conditional probabilities for features xi to get \neach of its possible values for a given class. \nExample of naive Bayes classification \nConsider simplified spam detection. You select the repetitive \nphrases in the emails in Table 4.1 below, some of which relate \nto elections, as the training material.  \nTable 4.1. Phrases in emails \n \n \n \n \n \n \n \nThe requisite background information is often obtained from hu-\nman-graded training samples such as the above. \nPhrase \nClass \nApply for loan immediately  \nGarbage = G \nGet a loan immediately \nGarbage \nLoan \nGarbage \nFirst loan without interest \nGarbage \nUnite the population \nElection matter = E \nChange immediately! \nElection matter \n\n75 \n \nIn the case of an unknown sample, the a posteriori probabilities \nof a feature vector X consisting of its features are calculated for \neach category. The new sample is then classified into its highest \nprobability class. Assuming that the occurrence of spam and \nelection phrases represents the actual frequencies of the corre-\nsponding messages, a priori probabilities are obtained \nfor garbage P (G) = 4/6 = 2/3 and \nfor election matter P (E) = 2/6 = 1/3. \nWe decide to choose the words that appear in the phrases of  G \nand E categories. There are four junk phrases, each with the word \n\"loan\" in it. So the probability of the word \"loan\" in spam is \nP (“loan” | G) = 4/4 = 1 \nThe word \"immediately\" appears in two junk phrases, so we get  \nP (“immediately” | G) = 2/4 = 1/2 \nStill counting the number of words we find \nP (\"first\" | G) = P (\"get\" | G) = P (\"apply\" | G) = \n               P (“without” | G) = P (“interest” | G) = 1/4 and \nP (“unite” | E) = P (“population” | E) = \n                     P (“change” | E) = P (“immediately” | E) = 1/2. \nNow the email comes with a clear troll content, \"population \nchange immediately!\". The posteriori probability of interpreting \nthis phrase as spam is \nP (class = G | X = \"population\" \"change” “immediately\") = \nP (category = G) * [P (\"population\" | G) * \nP (\"change\" | G) * P (\"immediately\" | G) = \n                         2/3 * (0/4 * 0/4 * 1/2) = 0 \nWe find the interpretation to be an election message because it \nhas a higher posteriori probability: \nP (class = E | X = \"population\" “change\" \" immediately \") =  \nP (class = E) * [P (\" population\"| E) * \n                   P (\"change\" | E) * P (\"immediately\" | E) = \n1/3 * (1/2 * 1/2 / * 1/2) = 1/24 \nWe see the 0-coefficients above in cases where there was no ob-\nservation in the training materials, that is \nP (“population” | G) = P (“change” | G) = 0/4. \nThis wasn’t a problem this particular time. But the next email \ncontains the message “Change immediately! Vote!”, where the \nword “vote” is not in the training material. \nNow our classifier concludes \nP (class = G | X = \"change\" \"immediately\" “vote \") = \nP (category = G) * [P (\"change\" | G) * P (\"immediately\" | G) * \n      P (\"vote\" | G)] = 2/3 * (0/4 * 0/4 * 0/4) = 0 and \nP (category = E | X = \"change\" \"immediately\" \"vote\") = P (class \n= E) * [P (\"change\" | E) * P (\"immediately\" | E) * \n     P (\"vote\" | E)] = 1/3 * (1/2 * 1/2 * 0/2) = 0 \n\n76 \n \nBoth options, garbage and election content, had posterior proba-\nbilities of 0! This by no means can be a correct conclusion.  \nThis problem could be solved by the so-called Laplacian \nsmoothing, whereby 1 is added to each number and to the divi-\nsors the number of possible features (different words in our case) \nin order to avoid with certainty the rise of values over 1 (Russell \n& Norvig, 2010). \nWe now count the number of different words in category G \n(seven) and category E (four). In the feed “Change immediately! \nVote!”, the word “vote” is additional word, but it has not been \nused in training. \nWe now obtain the conditional probabilities for the words used \nin the teaching, as shown in Table 4.2, which, for the sake of \nclarity, are presented as calculations. \nTable 4.2. Conditional probabilities of phrase words when using \nLaplacian smoothing \n \n \n \n \n \n \n \n \n \n \n \nWe are now repeating previous calculations. Of course, the a pri-\nori probabilities are the same as in the first example: \nP (G) = 4/6 = 2/3 and \nP (E) = 2/6 = 1/3. \nFor the previously unseen word “vote”, we now get the follow-\ning non-zero conditional probabilities \nP (\"vote\" | G) = (0 + 1) / (4 + 7) and \nP (\"vote\" | E) = (0 + 1) / (2 + 4), \nso the posterior probabilities interpret the phrase as part of the \nelection data, since it is larger for the latter in the following cal-\nculation:  \nWord \nP(word |G) \nP(word |E) \napply \n(1+1)/(4+7) \n(0+1)/(2+4) \nget \n(1+1)/(4+7) \n(0+1)/(2+4) \nimmediately \n(2+1)/(4+7) \n(1+1)/(2+4) \nwithout \n(1+1)/(4+7) \n(0+1)/(2+4) \nloan \n(4+1)/(4+7) \n(0+1)/(2+4) \nfirst  \n(1+1)/(4+7) \n(0+1)/(2+4) \ninterest \n(1+1)/(4+7) \n(0+1)/(2+4) \nunite \n(0+1)/(4+7) \n(1+1)/(2+4) \npopulation \n(0+1)/(4+7) \n(1+1)/(2+4) \nchange \n(0+1)/(4+7) \n(1+1)/(2+4) \n\n77 \n \nP (G | X = \"change\" \"immediately\" \"vote\") = P (G) * [P \n(\"change\" | G) * P (\"immediately\" | G) * P (\"vote\" | G) =  2/3 * \n(1/11 * 3/11 * 1/11) = 1.5 * 10-3 \nP (E | X = \"change\" \"immediately\" \"vote\") = \nP (E) * [P (\"change\" | E) * P (\"immediately\" | E)] * P (\"vote\" | \nE)  = 2/6 * (2/6 * 2/6 * 1/6) = 6.2 * 10-3 \nThe method is called naive Bayes, as it assumes that each feature \nis independent of the others. In this case, each feature  individu-\nally affects the posterior probability. For example, when a store's \n\"smart scale\" identifies the vegetables and fruits,  shape, size and \ncolor each contribute their own in classifying the produce as cu-\ncumber, banana or orange. \nDue to the assumption of independence, probabilities can be cal-\nculated for each feature  separately, and do not require normali-\nzation. The naïve Bayes classifier can be shaped to operate with \niterative training, making it also suitable for applications requir-\ning ever-growing number of training samples. \nThe naïve Bayes classification has been found to work well in \nmany applications where the features are not independent. How-\never, this is not true for regression problems (Frank et al., 2000). \n4.4.3 kNN classification \nThe kNN classifier is popular because of the ease of adding new \ntraining samples. Below in Figure 4.8 the value k=5 is used. \n \n \n \n \n \n \nFigure 4.8. The rough principle of kNN classification. \nThe principle is to find the closest match to the training samples \nfor each class to be classified, from which the most frequently \noccurring class is selected (Duda et al., 2001). The challenge in \nkNN classification is the normalization of features and the selec-\ntion of a suitable distance measure, for example, in the case of \nthe words that were features in the previous naive Bayes exam-\nple. In addition, it suffers from problems with unbalanced teach-\ning materials where some classes are underrepresented. \n4.4.4 Ensemble classifiers \nEnsemble classifiers, principle in Figure 4.9, are one solution to \nunbalanced training sets. Their original purpose has been to use \nmore or less parallel learning algorithms (Boosting) to achieve \n  x1 \n  x2 \n   \n   \ntraining samples \nsamples to be \nclassified \n\n78 \n \nbetter results than the individual learner. A random forest classi-\nfier can be interpreted as a special case of an ensemble classifier \nwhere all classifiers are of the same type. \n \n \n \n \n \n \nKuva 4.9. Principle of ensemble classifier. \nThe concept associated with ensemble classification is \"bag-\nging\" (“bootstrap aggregation”, Breiman, 1996). Its principle is \nillustrated in simplified form in Figure 4.10. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 4.10. Ensemble classifier with ”bagging”. \nThe idea is to make random sampling of the training data so that \nselected samples can be selected also in other sample sets. In the \npicture, the red boundaries are the class boundaries for each clas-\nsification result. \nA classifier is trained for each sample set and the final decision \nis obtained by combining the classifier results. When necessary, \nimbalanced training data can be at least partially balanced by \nsampling proportionally smaller shares from the majority class. \nThe method is also applicable when different features have been \ncalculated for some samples. \ninput data \nclassifier 1       \nclassifier 2     \nclassifier N-1 \nclassifier N      \nsampling \nclassification result \ncombining \n   \n   \n   \n   \n   \n   \n   \nClassifier 3     \n   \n   \n   \n   \n   \nClassifier 2  \nClassifier 1  \n   \n   \n   \n   \n   \n   \nEnsemble classifier  \n  training samples left     \n  out from the sample    \n  set \nopetusnäytteet \nt training samples   \n\n79 \n \n4.4.5 Gradient boosting \nThe accuracy of many composite classifiers can be improved by \nusing advanced machine learning methods. The solutions based \non gradient boosting have been very successful in various appli-\ncations. (Wiki-Gradient). \nThe boosting is based on the assumption that the so-called weak \nlearner in classification or regression can be modified to be better \n(Kurama, 2020). The first solution of this type was the AdaBoost \nthat was used in  Viola & Jones algorithm to detect faces in im-\nages in real-time  (Viola & Jones, 2004). AdaBoost is based on \na statistical solution developed by Leo Breiman (1997). \nGradient boosting is an algorithm that minimizes the value of a \nloss function by iteratively selecting a function that points to-\nward a negative gradient. \nGradient boosting consists of three parts (Kurama, 2020): \n1. The purpose of the Loss Function is to estimate how well the \nmodel is able to make predictions for a given data. In the case \nof regression problems, the loss function can be used to find \nthe difference between the predicted and observed values \n(e.g., predicting the strength of sawn timber, Figure 4.5). In \nclassification problems, the loss function must help to under-\nstand how good that model is in the classification problem \nunder consideration. \n2. A Weak Learner classifies that data, but does so poorly, per-\nhaps not even better than in a random guess. Typically, weak \nlearners are  implemented with simple decision trees. \n3. The Additive Model is an iterative and sequential way to add \nnew trees (weak learners) step by step. Each iteration should \nget closer to the final model, i.e. reduce the value of the loss \nfunction. \nGradient boosting has proven to be a very good technique for \nbuilding predictive models suitable for both classification and \nregression. In addition, various constraints or regularization \nmethods can be used to prevent possible over-matching and to \nimprove performance, \nXGBoost is a gradient boosting program library (Wiki-\nXGBoost) developed by Tianqi Chen that is widely used in ap-\nplications, optimized and distributed. It can be used in different \nprogramming languages and in different distributed hardware \nenvironments for regression, classification, ranking, and user-\ndefined prediction problems. \nThe problems with gradient boosting (and XGBoost) are mainly \ndue to the growing number of parameters that require user tuning \nthrough which performance improvements are achieved. At the \nsame time, the number of training samples required also in-\ncreases compared to, for example, the random forest-based \n\n80 \n \nmethod. On the other hand, gradient boosting methods then \nachieve better results because the random forest parameteriza-\ntion options are smaller. \n4.4.6  Classification with neural computing  \nArtificial, computationally implemented neural networks are \nalso used as classifiers when sufficient teaching material is avail-\nable. Neural computing is implemented with a series of intercon-\nnected layers of neurons, each with optimizable parameters \nthrough learning. The computation performed by the individual \nneurons is very straightforward and the potential of the networks \nis only fully revealed in massive applications. \nTraining is done by, for example, importing images of numbers \nand letters into the network input layer. Next, the data goes to \nthe hidden layer and finally to the output layer that handles it, \nproviding a response to the input. If the response deviates from \nthe desired response, back-propagation algorithm is used to \nmodify the weights used by the network in its calculation. In the \ncase of deep convolutional neural networks (CNN) presented in \nSection 4.5, the weights are coefficients of convolutional opera-\ntions. \nLearning requires information on the correct response to the \nfeed, for example, whether a cat or dog is in the picture. So it's \nabout supervised learning. The more training samples and \nrounds, the better the network will learn. Because the search con-\nverges slowly, much data is needed, and increasing the amount \nof data generally improves the accuracy that can be achieved. \nExample of how a Perceptron neuron works: \nWe consider the following simple Perceptron in Figure 4.11.  \n \n \nKuva 4.11. Simple Perceptron. \nThe parts of the perceptron are the following: \ninput: X = (x0, x1) and \nweight factors: W = (w0, w1),  \n      which are all real numbers and \noutput: Y which is binary   \n                             Y = 1, if wk*xk  >= T,  and \n                             Y = 0, if wk*xk  <  T,  where k=0,1    \nPerceptron learns the weight factors W when presented with the \noutputs it should produce for the inputs.  \n \nx1 \nx0 \nw0 \nw1\n \nY \nT \n \n\n81 \n \nThe algorithm is as follows: \n1. For the input  X = (x0, x1)  calculate the output Y \n       Y = 1, if wk*xk  >= T,  and \n       Y = 0, if wk*xk  <  T, where k=0,1 \n2.  Action options: \n• If Y = 0 , but it should be 1, increase the weight factors \nW = (w0, w1),  because the sum wk*xk  is not large \nenough, also lower the threshold T \n• If Y = 1 , but it should be 0, the reduce the weight factors \nW = (w0, w1), because the sum wk*xk  is too large, also \nincrease the threshold T. \n• If Y is correct, nothing is done.  \n• Note: only the weight coefficients of the input lines with  \nxk = 1, need to be modified, so if X= (1,0),  only weight \nw0 needs to be changed \n• The weights are updated using equations \n                     wk = wk + learning speed * (right_loutput-Y)*xk and   \n               the threshold is updated using the equation \n                      T = T – learning speed*(right_output - Y). \n            If Y is corrrect, no change in values wk  and T \n3. Return to step 1 \nOur interest focuses on the calculation of sum terms and thresh-\nold comparisons: \nw0*x0 + w1*x1 >= T  and \n      \n w0*x0 + w1*x1  < T \nThis pair of equations means that in a 2-dimensional case with \nfeatures x0 ja x1 the Perceptron divides the feature space by the \nline w0*x0 + w1*x1 = T. During learning in our two dimensional \ncase the Perceptron checks on which side of this line each sample \nfalls, and changes the equation of the line respectively. \nThe weight factors W and the threshold value T are updated in a \nmanner that the line moves toward incorrectly classified sam-\nples. In a three-dimensional case the feature space is divided by  \na plane, and in multi-dimensional situations by a hyper plane. \nIn the coordinate system of Figure 4.12 below is a line \n       w0*x0 + w1*x1  = T, when w0 = 0.5,   w1= 0.5  and   T = 0.5.  \n \n \n \n \n \nKuva 4.12. Initial situation of Perceptron learning. \nw\n0 \nw\n1 \n(1,1) \n(-1,1) \n0.5*x0 + 0.5*x1 = 0.5 \n\n82 \n \nStarting from this initial  situation we consider the impacts from \nnew training samples (1,1) and (-1,1). We assume that the re-\nspective correct categories for the output are “0” and “1”. The \nsame inputs are usually required to be repeated several times. \nWe choose learning speed = 0.1 and apply the update equations \n      wk = wk + learning speed* (right_output - Y)*xk \n      T = T – learning speed*(ríght_output - Y) \nStep 1: Get training sample (1,1) for which we know the right  \n              output  category  '0'.  \n              The perceptron equation gives \n               w0*x0 + w1*x1 = 0.5*1+0.5*1 = 1 > T= 0.5,  \n               according to which the output is Y = 1,  \n               but it should be “0”.  \n              As a result, the parameters W and T are updated \n                w0 = w0 + 0.1* (0-1)*x0 = 0.5 - 0.1 = 0.4 \n                w1 = w1 + 0.1* (0-1)*x1  = 0.5 - 0.1 = 0.4 \n                T = T - 0.1*(0-1) = 0.5 + 0.1 =0.6 \n              The new discriminant line is \n              0.4*x0 + 0.4*x1 = 0.6,   \n             which we see in Figure 4.13 to be closer \n             to sample (1,1) than  the original discriminant \n             0.5*x0 + 0.5*x1 = 0.5  \nStep 2: we get a new training sample (-1,1) for which the correct \n              output is known to be “1”. But according to equation \n               w0*x0 + w1*x1 = 0.4*(-1)+0.4*1 = 0  < T= 0.6  \n             Y = 0.  The result is the update \n              w0 = w0 + 0.1* (1-0)*x0 = 0.4+0.1*(1)*(-1) = 0.3 \n               w1 = w1 + 0.1* (1-0)*x1  = 0.4+0.1*(1)*1 = 0.5 \n               T = T - 0.1*(1-0) = 0.6-0.1 =0.5,   \n              \n            The new discriminant line becomes \n             0.3*x0 + 0.5*x1 = 0.5,  \n             which we now see in Figure 4.13 to have turned  \n             toward sample (-1.1) \nStep 3: We get the sample (1,1) again knowing that the correct \n            output is \"0\". The Perceptron equation now gives \n              w0*x0 + w1*x1 = 0.3*1+0.4*1 = 0.7  > T= 0.5, on the basis                  \n            of which Y = 1, but it should be \"0\". As a result \n            the weights W are updated \n\n83 \n \n            w0 = w0 + 0.1* (0-1)*x0 = 0.3+0.1*(-1)*1 = 0.2 \n             w1 = w1 + 0.1* (0-1)*x1  = 0.5+0.1*(-1)*1 = 0.4 \n             T = T - 0.1*(0-1) = 0.5+0.1 =0.6,  giving new     \n           discriminant line is 0.2*x0 + 0.4*x1 = 0.6, that \n           has increasingly shifted towards the sample (1,1) and now  \n           passes through it as illustrated in Figure  4.13. \n  \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 4.13. Effects of Perceptron's learning steps on the discri-\nminant line. \nThe ability of a single-layer neural network is limited to learning \nlinear discriminants. Instead, a multilayer network is capable of \nlearning nonlinear cases. Both are trained by entering data sam-\nples and comparing the outputs to known classes of samples or \nother correct values. \nIn multilayer implementations, the weight coefficients of the \nneurons in each layer are modified by the so-called back-propa-\ngation algorithm and the data samples are again passed through. \nThe training is terminated when the result no longer improves or \nthe desired error rate  is achieved. \n4.5 \nDeep Learning and Convolutional Neural Networks  \nWith the multilayer perceptron neural network it is possible to \nobtain non-linear discriminant functions (Figure 4.14). This dif-\nfers from Rosenblatt's perceptron.  \n \n \n \n \n \n \nFigure 4.14. A non-linear discriminant. \nw\n0 \nw\n1 \n(1,1) \n(-1,1) \n0.4*x0 + 0.4*x1 = 0.6 \n0.5*x0 + 0.5*x1 = 0.5 \n0.3*x0 + 0.5*x1 = 0.5 \n0.2*x0 + 0.4*x1 = 0.6 \nP \nB \nP B \n\n84 \n \nNeural networks have a layer of input units, including, for exam-\nple, pixels of the image or words of speech (or features thereof), \nhidden layers (neurons, nodes) and output units. There are con-\nnections or links between neurons. The more layers there are, the \ndeeper the network is called (Goodfellow et al., 2015).  \nFigure 4.15 shows a fully connected neural network with two \nhidden layers. A network, or one of its layers, is called fully con-\nnected when each of its neurons is connected to each of the next \nlayer's neurons. Suppose you want to identify which of the two \nobjects is a cat or a dog. The input of the network is a set of \nfeatures measured from the object, which can describe, for ex-\nample, the color and shape of the object. There are two classes \nin the output, \"cat\" and \"dog\", and as many neurons as there are \nclasses. For example, if one wanted to recognize handwritten \nnumbers 0-9, there would be ten neurons in the output. \n \nFigure 4.15. Fully connected neural network. \nIn Figure 4.15, the squares represent the input layer to which the \nfeatures to be measured are fed, and the circular nodes are artifi-\ncial neurons in two hidden layers and outputs. The neurons in-\nterconnecting links each have their own weight factor. The coef-\nficients express the strength or importance of the neuron in ques-\ntion. The value of the signal transmitted by each neuron is mul-\ntiplied by the weight coefficient of that link and the adding unit \ncalculates the sum of the weighted signals arriving at a particular \nneuron.  \nAs shown in Figure 4.16, from the result of the addition unit a \nnon-linear mapping is calculated using so-called activation func-\ntion f, allowing approximation of an arbitrary function. Typical \nactivation functions are the sigmoid (f (x) = 1 / (1 + exp (-x)) or \nthe step function. \n \n \n \n \n \n \nFigure 4.16. Neuron with a non-linear activation function f. \nw3 \nx2 \nx3 \nw1 \nw2 \nx1 \nY \nf(wixi) \n\n85 \n \n \nFigure 4.17 shows the general structure of a deep convolutional \nneural network.Most current deep networks use the convolution \nfamiliar to image and signal processing (see Section 3.5.4), \nwhich refers to convolutional neural networks (CNN) (LeCun et \nal., 1989).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 4.17. Deep  convolutional neural network. \nHere, the connections between neurons are limited so that the \nnetwork is made independent of shifts. In this case, the same \nsubject may be in different locations in the image and still be \nidentified as the same. Convolution also reduces the number of \nrequired parameters compared to a fully connected network. \n In the hidden layers of the deep network, gradually more global \nintermediate representations  can be found from the objects to be \ninput image \nconvolution \nlayer \ndifferent \nconvolutions \npooling, in which outputs \nof several neurons of pre-\nvious layer combined with \nsome logic \nconvolution layer  \n4 feature images \nsub-sampling layer \nsub-sampling layer \nfully connected layer \noutput  layer \nrrlayer \n\n86 \n \nrecognized. For example, at lower levels edges and lines of re-\ngions, and at upper levels more complex parts of the structure of \na trained object. \nInitially, as described in Section 3.5.4, the convolution for the \nimage fed into the network is calculated. The activation function \nmentioned above is then applied to the convolution result.  \nThe subsampling pooling operation \"diminishes\" the resulting \nfeature image after convolution. For example, four adjacent pix-\nels can be replaced by the maximum value of the pixels in a 2x2 \nwindow, i.e. each new pixel represents the four previous values \nas in Figure 4.18. The same operation is performed on all non-\noverlapping windows in the feature image. Pooling can reduce \ncomputational load and also provide coarse-grained information \nfrom  the feature image. Depending on the implementation, in \naddition to computational efficiency, pooling can provide, e.g., \ninvariance to shifts in the image. \n \n \n \n \n \n \nFigure 4.18. Max pooling operation. \nConvolution is performed on different layers repeatedly, starting \nfrom fine-grained image data to coarser information at the higher \nlevels of the network. Convolution filters are trained to minimize \nthe classification error by the back-propagation algorithm. \nThe back-propagation algorithm based on gradient descent for \ndetermining coefficients has proved to be particularly useful. \nCurrent deep learning methods are largely based on it (Ru-\nmelhart et al., 1986). The method adjusts the neural links of the \nnetwork during training so that each input sample (e.g., features \nmeasured from cat) produces the correct response at output \n(class \"cat\"). \nThe name back-propagation comes from starting the process on \nthe output end neurons (two in the above example), finding out \nthe errors in their weighting factors, then looking at the effect of \nthe previous layer neurons on the error, etc. Finally, it is known \nhow each neuron in the network effects on the total error, and \nthen each weighting factor is changed so that the total error   de-\ncreases most. \nmax-pooling: biggest  responses of feature detection \nare collected from partial images to a single  \nlower-resolution image \n1      9      2     8 \n3      7      4     5 \n4      2      5     3 \n2      1      7     2 \n9    8 \n4    7 \nmax(1,9,3,7) \n\n87 \n \nBy using a large number of training samples from each object to \nbe recognized, the system is learning, i.e., finding the appropri-\nate weighting factors. \nThe relationship between input and output of a neural network \ncan be described by the term \"mapping\", meaning that neural \nnetworks, and in particular deep networks, learn very well non-\nlinear input-output mappings. \nA breakthrough in machine learning was achieved in 2012, when \nKrizhevsky et al. (2012) demonstrated that by training a suffi-\nciently multilayer CNN neural network with massive amounts of \ndata, it is possible to achieve significantly better classification \nresults than before. They studied the categorization of 1,000 dif-\nferent categories of images using supervised learning with 1.2 \nmillion images in the ImageNet database. The so-called AlexNet \nneural network they used consisted of eight learned layers, the \nfirst five of which were convolutional layers and the last three \nfully connected layers. \nThe number of training rounds required can be reduced by nor-\nmalizing the sample data prior to input to the neural network by \nat least zeroing the mean, or by normalizing the distribution of \neach feature to mean 0 and variance 1. The correlation between \nthe various features can be reduced for example with Principal \nComponents Analysis (Section 3.5.6). \nOne of the major benefits of deep networks over traditional \nmethods is that the features and data representation can be \nlearned at many scales directly from the data. Networks also al-\nlow for so-called. End-to-end training, whereby all parameters \nof the recognition system can be calculated as a single entity, not \nstep by step. An example would be teaching the CNN network \nso that the system is able to directly map the information pro-\nvided by the camera in the direction of travel into self-driving \ncar’s control commands. \nIt has been found that network performance can be enhanced by \nimplementing deeper networks than before, although the limits \nfor this phenomenon are now clearly visible. The 16-layer VGG-\nNet and the 22-layer of GoogLeNet already achieved much bet-\nter results than eight-layer AlexNet  in the classification error \n(Liu et al., 2020).  \nSome recent networks already have over 100 layers (for exam-\nple, ResNet and DenseNet). In the GoogLeNet architecture, the \nnumber of parameters was reduced to four million compared to \nAlexNet's 60 million, while the VGGNet, which is publicly \navailable and widely used by the research community, has as \nmany as 139 million parameters. With a small set of parameters, \nthe network can be taught faster and is not as sensitive to over-\nfitting \n\n88 \n \nThe number of samples available for teaching can be increased \nusing the so-called augmentation. This means artificially ma-\nnipulating existing samples, for example, calculating versions of \ndifferent scales, cutting, turning around and rotating. \nA deep neural network trained for a particular task can be fine-\ntuned for another task of the same type. For example, in recog-\nnizing \"cats\" and \"dogs\", the network may have initially been \ntrained to recognize 1000 different classes in the ImageNet da-\ntabase. Now the top layer of the network can be removed and \nchanged to correspond to the two classes, but the lower layers \nalready trained do not need to be interfered, but are marked as \nnon-trainable. After that, the model is easily adapted to the new \nproblem. Section 8.5 provides an example of using a CNN neural \nnetwork, training sample augmentation, and fine tuning to clas-\nsify X-ray images. \nResearch on deep neural networks continues to be intense and \nnumerous new solutions have been developed for a variety of \nproblems and applications. The reference (Liu et al., 2020) pro-\nvides a comprehensive review of  deep learning based methods \nand system architectures from the perspective of one challenging \nkey application problem, generic object detection.  \nHow can you then find the most suitable network solution for \neach application problem? This requires experience with differ-\nent alternatives, evaluation of alternatives - and plenty of exper-\nimentation. Indeed, we might speak of “handcrafted” architec-\ntures in the same style as traditional features are often referred to \nas “handcrafted”. \nWhat then were the reasons why most of the solutions developed \nmuch earlier did not lead to a breakthrough in machine learning \nuntil the 2010s? The availability of digitized data is perhaps the \nmost important factor. In the past, computers were not as widely \nused as they are today and there was no need for large amounts \nof data. It has been said that up to 90% of the available data has \nbeen created in the last couple of years. New data comes from \nmusic, movies, photos, videos, smart mobile phone cameras and \nother sensors, medical imaging equipment, video surveillance \nsystems, social media, etc. recorded in digital form (Brynjolfs-\nson & McAfee, 2017). \nAnother major factor is the huge progress in hardware develop-\nment. Deep neural network training can take weeks, even with \nefficient GPU (Graphical Processing Unit) originally designed \nfor computer graphics. Previously, this was not possible. Shane \nLegg, co-founder of Google's DeepMind unit, said that in 2017, \na task that took one day with a hardware device equipped with \nGoogle's machine learning TPU (Tensor Processing Unit) would \nhave taken 250,000 years with an Intel 80486 microprocessor in \n1990 (Brynjolfsson & McAfee, 2017). \n\n89 \n \nIn addition, open availability of systems development tools, such \nas TensorFlow (Google), Keras, PyTorch, Caffe, and Cognitive \nToolkit (Microsoft), has greatly enhanced the use of deep learn-\ning. A comparison of the most common tools is presented, for \nexample. in (Opala, 2019), (Wiki-Deepsoft). \nAn increasing number of deep learning AI applications are being \nimplemented using remote services such as those provided by \nGoogle, Amazon, and Microsoft, providing  much  profits for the \ncompanies.  There is not enough computing power on users' or-\ndinary laptops and smart phones for training. GPUs designed for \nhigh-performance computing can be accessed through cloud ser-\nvices, allowing many smart phones to successfully run applica-\ntions such as voice recognition and machine vision. The disad-\nvantage, however, is often the need for a continuous Internet \nconnection. For local  computing on the user’s device, simpler \nand consequently less accurate solutions are needed. For Nvidia, \nthe market leader in GPUs originally designed for graphical data \nprocessing, the immense popularity of deep learning has created \na wealth of new markets.  \nThe practical application of deep learning involves a number of \nrisks that companies investing in this technology should take into \naccount. A “white paper” by a team from Peltarion, “Deep learn-\ning challenge: Lessons from the field” (Peltarion, 2018), de-\nscribes various practical problems. Technology challenges in-\nclude limited transparency, troubleshooting, resource con-\nstraints, e.g., due to the lack of AI experts, and testing. \nHuman challenges include cultural differences, privacy and se-\ncurity, and unintentional feedback loops, allowing the system to \nadapt to a user model instead of data, for example. Process chal-\nlenges include evaluating development efforts, managing soft-\nware and hardware dependencies, monitoring system perfor-\nmance, for example, when incoming data changes, code and sup-\nport systems needed to \"glue\" to another system, such as cloud \nservices, and managing experiments required to develop an arti-\nficial intelligence system. \nThe most critical aspect of business impact is the assessment of \ndevelopment effort and resource constraints. Next come the \nproblems related to privacy and security and gluing to other sys-\ntems. \nCNNs are often claimed to function by imitating the information \nof biological nerves, as feature detectors specialized in details of \nthe trained samples have been found in artificial neural networks. \nFor example, the eye may have its own detector. Similar have \nbeen found in the nervous systems of both insects and mammals, \nwhich have evolved over millions of years. Now, this kind of \nevolution is said to take place inside computers within minutes. \n\n90 \n \nThis is a very limited view because the human nervous system is \na system of specialized parts where the senses and the brain in-\nteract. Producing such an entity has so far proved to be quite a \ndemanding challenge. For example, a banana fly has about \n100,000 neurons (Zheng et al., 2010) whose “intelligence (?)” \ngives it the ability to move, get food, and communicate. The abil-\nity of man-made artificial neural network based solutions has \nbeen significantly weaker, at least so far. Everyone is also famil-\niar with the fact that the fly seems to be learning more cautiously \nfrom the first failed swat. Artificial neural networks have not yet \nbeen able to do so. \n4.6 \nUnsupervised Learning \nOften there is no pre-classified data available for applications \nthat could be used for supervised learning. Then, the sample data \nmodel is formed by so-called unsupervised learning methods. As \nshown in Figure 4.19, the solution is then to reduce the dimen-\nsionality or clustering, depending on the available prior infor-\nmation. The basis for using both is the observation that high di-\nmensional data associated with the applications are not randomly \nlocated in the data space if the feature selection is at least some-\nhow successful.  \n \n \n \n \n \n \n \nFigure 4.19. Methodological division of unsupervised learning. \nTypical applications of unsupervised learning include: video \ncontent recommendation solutions, and consumer behavioral \ndata analytics that shape marketing, product mix, and product \nplacement. \nInsurance companies analyze their customers with dimensional-\nity reduction and clustering methods for risk analysis and pric-\ning, industrial logistics group orders for transportation by the \nsame means, etc. Unsupervised learning is also used to detect \nrare deviations from data, e.g., when analyzing medical images \nand identifying credit card fraud in the financial sector.  \nThe dimensionality reductions presented in Section 3.5.6 pro-\nvide an estimate of the structure of the data. In turn, clustering \ncan be an effective solution if the number of categories is known \nat least roughly. Reducing dimensionality is therefore often a \nprecursor step. \nunsupervised \nlearning  \ndimensionality  reduc-\ntion problem \nclustering \nproblem \nno knowledge \nabout catego-\nries \nknowledge about  the \nnumber of categories \navailable \n \n\n91 \n \nTo reduce the dimensionality, it is possible to use neural net-\nworks connected as auto-encoders (Section 3.5.5), which are ex-\ncellent for that purpose. However, in clustering the solutions \nbased on them have not so far been successful. Thus, more con-\nventional methods are still used in clustering. \n4.6.1 Clustering methods \nThe principle of clustering methods is to divide the sample data \ninto groups where the samples in each are more similar in terms \nof selected criteria than between groups (Duda et al., 2001). \nTherefore, in the solution of the clustering problem, there is a \nchoice of representation, for example, features describing sam-\nple data as well as a distance measure to estimate similarity of \nsamples.  \nIn this sense, the clustering and its challenges resemble the kNN \nclassifier in Section 4.4.3: the result may be significantly de-\npendent on the choice of distance measure and features and nor-\nmalizations. \nIn addition, there is a need for a clustering criterion that some-\nhow corresponds to our understanding of the structure of the data \nand a success measure to automate the iteration related to the \nsolution. Initially, the one best suited to the problem is chosen as \nthe clustering method. The first choice is often the so-called clus-\nter-center method, in which the similarity of samples is com-\npared with the cluster center. \nFigure 4.20 shows examples of potentially useful clues for hu-\nman interpretation in four cases of two features. Sample data of-\nten has stripe and ring structures, the nature of which depends on \nthe features selected. \n \n \n \n \n \n \n \n \n \n \n \n \nKuva 4.20. Three different clustering problems.  \n   \n  x1 \n  x2 \n   \n  x1 \n  x2 \n  x1 \n  x2 \n   \n  x1 \n  x2 \n\n92 \n \nThe popular k-means clustering starts from randomly selected  \ninitial k cluster centers, iterating in the following steps: \n1. Each data sample is placed in the cluster with the closest av-\nerage value \n2. The average of each cluster shall be recalculated \n3. Return to step 1 if the average of even one cluster changed, \notherwise the result is complete \nThe method does not always produce a human-pleasing result, \nas Figure 4.21 illustrates for the previous samples when k = 4.  \n \n \n \n \n \n \n \n \n \n \n \nFigure 4.21. Sketched results of k-means clustering. \nThe number of clusters is an important source of information, as \nthe k-means method always finds k clusters – even if there were \nmore or less in the human mind - as the figure shows. Hierar-\nchical connectivity methods sometimes work better than k-\nmeans clustering. Figure 4.22 shows some possible results. \n \n \n \n \n \n \n \n \n \n \n \nFigure 4.22. Results for hierarchical clustering. \n   \n  x1 \n  x2 \n   \n  x1 \n  x2 \n  x1 \n  x2 \n   \n  x1 \n  x2 \n   \n  x1 \n  x2 \n  x1 \n  x2 \n   \n  x1 \n  x2 \n   \n  x1 \n  x2 \n\n93 \n \nIn hierarchical methods, cluster construction proceeds either by \nsplitting data space or starting from individual samples. The data \nsamples located close to one another are assumed to be more \nsimilar to those further away.  The hierarchical approach has the \nadvantage of being easy to interpret, but the methods are poorly \nsuited to large data samples due to computational costs.  \nWe note that neither the k-means nor the hierarchical method \nalways give clusters that fit the human expectations. At times, \neven single abnormal samples, or sets of a few data samples, can \nsignificantly affect the clustering result, as illustrated in Figure \n4.23. The abnormal samples are in the upper right and k = 3 for \nthe k-means clustering.  \n \n \n \n \n \n \n \nFigure 4.23 Effect of abnormal samples on clustering. \nSuch a situation can be encountered when the categories con-\ntained in the sample data are unbalanced or measurement errors \nhave been included. The discrepancy may also be affected by \nsome lack in representation and may be corrected by finding a \nsuitable new feature. \nDivergent samples can lead to problems if the clustering results \nare used as an input for supervised learning . In the case of Figure \n4.23, some of the samples in the cluster on the lower left appear \nto be categorized by the effect of abnormal samples. Often, the \ntemptation is to remove such ones from the training samples, but \nsimilar cases may come up in use cases. \nClustering results are easy to misinterpret. For example, Figure \n4.24 shows a k-means clustering (k = 2) for two-car data in win-\nter 2017-18. The data is projected into a 2-D coordinate system.  \n \nFigure 4.24. Sample data describing the use of two cars.  \n  x1 \n  x2 \nTo which cluster should these \nsamples be placed? For a human \nthis could be a simple case, unlike \nfor k-means method. \n\n94 \n \nInitially, there were four features: average fuel consumption, \noutdoor temperature at departure, travel time, and average speed. \nIt is easy to make the mistake of assuming that clusters represent \ndifferent cars. In reality, they tell the most about using an engine \nblock heater in the mornings and cold starts in the afternoons. \nSample data is often very large and, with high dimensions it can \nbe difficult to interpret for humans. The results obtained by any \nclustering method may then be assimilated to pure guesses. \nThus, after clustering, the following reviews are always needed \nto anchor the analytical results into the application: \n• are the resulting clusters perhaps a result of chance or do they \nrepresent actual data structures? \n• is the number of clusters reasonable for the application? \n• could the clustering result be any better?  \n4.7 \nReinforcement Learning \nMany applications do not offer category information or prior \ndata. Instead, they may offer positive and negative feedback on \nsolutions made, so that learning can be based on trial and error. \nReinforcement learning is suitable for such applications to seek \nthe action strategy or solution that receives the most positive \nfeedback (Sutton & Barto, 1998) The goal is continuous learn-\ning, also forgetting, which allows coping with changing situa-\ntions. In Figure 4.25, the agent is an artificial intelligence oper-\nating in its environment that can navigate and change its envi-\nronment, receiving measurement data and feedback on its ac-\ntions. \n \n \n \n \n \n \n \nFigure 4.25. Basic reinforcement learning. (© 123RF) \nReinforcement learning lies in the midst of supervised and unsu-\npervised learning, and requires applications that can automati-\ncally serve its feedback hunger. The problem is, of course, the \nlarge amount of feedback needed and slow learning.  \nIn games, large feedback needs can be satisfied by simulations, \nwhich procedure has been used, e.g., in Google DeepMind's Al-\nphaGo program, a combination of Monte Carlo simulation based \nreinforcement learning and deep neural networks (Section 5.3). \nagent \naction \npositive or negative \nfeedback \nenviron-\nment \nstate data or perception \n\n95 \n \nQ-learning is a popular reinforcement learning method (Wat-\nkins & Dayan, 1992). It is so-called model-free, not modeling its \nenvironment as such, but treating it as a state machine where the \nagent is always in some state. Each state contains everything \nabout the environment.  \nThe Q function returns the expected feedback for a specific op-\neration when the status information and that operation are en-\ntered. Initially, the Q function returns a constant value, such as \n0, for all states and operations. \nLater, as the agent acquires more information, the Q function in \neach mode provides better estimates of possible action feedback \nvalues. In practice, the Q value is feedback on a longer-term \ngoal, that is, guides you to choose an action toward it. Reinforce-\nment learning observations and actions, in turn, produce Q val-\nues. \nConsider reinforcement learning in a simplified case in which an \nandroid unexpectedly achieves singularity at night in a labora-\ntory. It sets off to search the front door to the stairwell using Q-\nlearning. \nThe lab layout shown in Figure 4.26 is initially unknown to An-\ndroid. We also present the problem as a graph where the rooms \ncorrespond to the states of Q-learning. The stairwell is one of the \nstates. The door can go in either direction. \n \n \n \n \n \n \n \nFigure 4.26. Simple application problem for Q-learning.  \nTransitions through doors from room to room are actions. The \naccess to the stairwell has a feedback value of R = 10 and the \naccess to other rooms is R = 0. The cost for staying in the room \nand the stairway is R = -1. All Q values are initialized to -1. In \npractice, the selection of feedback values is arbitrary, as long as \nthe destination has the highest values. \nIn each of its current states, the android selects one possible ac-\ntion and determines the highest achievable Q value through each \npossible next state based on the data acquired so far. It updates \nthe Q values with a simple equation \nQ (state, action) = Reward (state, action) + \n                 parameter * Max (Q (next state, possible actions)) \n1 \n2 \n3 \nstairwell \nroom 2 \nroom 1 \nroom 3 \nstairwell \n\n96 \n \nWe set the parameter (approximate) arbitrarily to 0.5. \nThe transition from room 1 to room 2 is now evaluated as \nQ (1,2) = R (1,2) + 0.5 * Max (Q (2,2), Q (2,1),…)), \nwhere R (1,2) is the reward for entering the room 2 through the \ndoor. The Q values for transitions from room 2 to the rest are all \nassumed to be initialized to -1. \nThe android is not yet fully aware of the potential, but it doesn't \nmatter because of initialization assumptions. For example, ini-\ntializing Q (2,2) = -1 means that one possible action in room 2 is \nto stay there. \nSince R (1,2) = 0 and all Q values are -1, so \nQ (1,2) = 0 +0.5 * (- 1) = -0.5 \nOf course, at this stage we would have been able to speed-up \nlearning by concluding that if you can go from room 1 to room \n2 then you can go also vice versa and Q (2,1) = 0. However, our \nAndroid is just beginning to learn. We are now only updating Q \nvalues in each state, that is, for room 2, only there. \nIf the Android stays in room 1, then R (1,1) = -1, Q (1,1) = -1, \nand Q (1,2) = 0 \nQ (1,1) = R (1,1) + 0.5 * Max (Q (1,2) = -1 + 0.5 * 0 = -1 \nThe android finds now \nQ (1,2)> Q (1,1), \nso it moves to room 2. We find that Q (1,2) = -0.5 and Q (1,1) = \n-1. The latter value has not changed since initialization. Now in \nroom 2, the android detects three doors, and those are associated \nwith the following Q-value updates: \nQ (2,2) = R (2,2) + 0.5 * Max (Q (2,1), Q (2,3), Q (2, P)) = \n -1+ 0.5 * Max (0, -1, 10)) = 4 \nQ (2,1) = R (2,1) + 0.5 * Max (Q (1,1), Q (1,2)) = \n        \n \n  0+ 0.5 * Max (-1, -0.5)) = -0.25 \nQ (2,3) = R (2,3) + 0.5 * Max (Q (3,3), Q (3,2), ...) = \n                                           0 + 0.5 * Max (-1,…)) = -0.5 \nQ (2, P) = R (2, P) + 0.5 * Max (Q (P, P),…) = \n                                         10 + 0.5 * Max (-1,…) = +9.5 \nAndroid now finds that Q (2, P) is the largest of its options, so it \nmoves to the stairwell (P). There, it calculates the following Q \nvalues where we use the results calculated above: \nQ (P, 2) = \n     R (P, 2) + 0.5 * Max (Q (2,2), Q (2,1), Q (2, P), Q (2,3)) = \n                             0+ 0.5 * Max (4, -0.25, 9.5, -0.5)) = 4.75 \nQ (P, 3) = R (P, 3) + 0.5 * Max (Q (3,3), Q (3,2), Q (3, P) = \n                                          0 + 0.5 * Max (-1, -1, -1)) = -0.5 \nQ (P, P) = R (P, P) + 0.5 * Max (Q (P, P), Q (P, 2), Q (P, 3)) = \n                                          -1 + 0.5 * Max (-1, 0, 0) = -1 \n\n97 \n \nSince Q (P, 2) is the highest, the Android moves back to room 2. \nThere, the Q values are updated again \nQ (2,2) = R (2,2) + 0.5 * Max (Q (2,1), Q (2,3), Q (2, P)) = \n                              -1+ 0.5 * Max (-0.25, -0.5, +9.5) = 3.75 \nQ (2,1) = R (2,1) + 0.5 * Max (Q (1,1), Q (1,2)) = \n                                 0+ 0.5 * Max (-1, -0.25)) = -0.125 \nQ (2,3) = R (2,3) + 0.5 * Max (Q (3,3), Q (3,2), ...) = \n                                0 + 0.5 * Max (-1,…)) = -0.5 \nQ (2, P) = R (2, P) + 0.5 * Max (Q (P, P), Q (P, 3), Q (P, 2)) = \n                                 10 + 0.5 * Max (-1, 0.5,4.75) = +12.375 \nWe now note that the Android has updated a number of Q values, \nsome of them twice, and iteratively continues the update within \na simple algorithm. We can find the route by following the high-\nest Q values. \nGenerally, the applied update equations are slightly more ad-\nvanced than those used here. In addition, there are loose applica-\ntion-specific control mechanisms for directing the learning. \nThere are applications for reinforcement learning in financial ap-\nplications for continuous improvement of stock trading strate-\ngies, logistics, Internet services and robotics. For example, the \ntechnology behind robots learning to walk is partially based on \nreinforcement learning. This technique has been used to learn \nhow to play console games with the information provided by the \ncamera, without first knowing the rules, and developing so-\ncalled chatbots that are able to keep people engaged all the time. \n4.8 \nRecurrent Neural Networks (RNN) \nDeep neural networks, as such, are unable to learn the temporal \nor sequential dependencies of data samples fed at a time. This is \nproblematic, for example, in the development of language-based \napplications, since interpretations of the following words in the \ntext may depend on the preceding one. In the same way, for ex-\nample, the following choices of chatbots used in automated cus-\ntomer service depend on previous steps. In addition, in these ex-\namples, a single input data must sometimes produce multiple \nconsecutive outputs, or sometimes only a single response may \nbe required from the input sequence.  \nSuch needs for analyzing natural written and spoken language or \ncontinuous signals often involve the use of Recurrent Neural \nNetworks (RNN) (Rumelhart, 1986). They can model data with \ntemporal interdependencies, for example, to detect abnormal sit-\nuations, such as exceptional situations from condition monitor-\ning data produced by industrial rotary machines.  \nThe principle of feedback neural network is shown in simplified \nform in Figure 4.27. The structure is based on a conventional \ndeep neural network with an added connection from the output \nlayer to the hidden layer and also between the hidden layers. As \n\n98 \n \na result, the neurons in the output layer influence their own in-\nputs through feedback. As a result, the neural network can in \nprinciple include information from all previous inputs in its \nweights, so that it can learn temporally dependent features. This \nenables time-dependent data to be processed and predicted. \n \n \n \n \n \nKuva 4.27. Recurrent neural network. \nIn their basic form, recurrent neural networks are not capable of \nmodeling data beyond short time series. Unfortunately, the prob-\nlem is exacerbated by deep neural networks, the capacity of \nwhich would in itself be needed for more complex and larger \nproblems.  \nFor the purpose of longer sequences, so-called Long Short-Term \nMemory (LSTM) networks have been developed (Hochreiter & \nSchmidhuber, 1997). The term refers to a person's working \nmemory of a few seconds into which information comes from \nthe sensory memory. Working memory data can be stored in \nlong-term memory - or forgotten. \nAt the core of the LSTM implementation is the so-called node \nstate maintained in the hidden layers to model longer-term de-\npendencies. This allows the RNN to recognize the essential data \nand to control it with feedback to be remembered. Similarly, less \nrelevant data can be overlooked. \nThe great advancements in speech recognition are largely the re-\nsult of LSTM research. Developing such an application requires \nsupervised training, that is, categorized speech samples that are \nfed to the network by teaching a phoneme or word at a time until \nthe desired recognition ability is achieved. Due to network feed-\nback, a modified version of the back-propagation algorithm \n(BPTT, Back-Propagation Through Time) is used to modify the \nneural weights. \nThe predictive ability of the LSTM method has been demon-\nstrated, e.g., in the automated generation of compositions and \nhandwritten text, in the production of textual descriptions of \nvideo content, in the analysis of stock market trends, etc. In prac-\ntice, the LSTM method or deep convolutional neural networks \n(CNN) are used as combinations for implementing applications. \nFor example, CNN methods can be used for initial processing, \nLSTM is used in the intermediate stage, and finally multi-layer \nperceptron networks. \ninput layer \noutput layer \nhidden layers \nfeedbacks \n\n99 \n \n4.9 \nGAN – Generative Adversarial Network  \nThe General Adversarial Network (GAN), developed by Ian \nGoodfellow with colleagues, has been of great interest in recent \nyears (Goodfellow et al., 2015), (Wiki-GAN). Figure 4.28 shows \nthe general structure of a GAN (Web-GAN). The principle is that \ntwo neural networks (generator and discriminator) compete with \neach other, most often in a zero-sum game, where one’s win is \nthe other’s loss.  \nFor a given training set, the GAN learns to generate samples with \nthe same statistical properties as it has. They are  used as nega-\ntive training samples for the discriminator. The discriminator \nlearns to distinguish the wrong data generated by the generator \nfrom the right one and punishes it for producing inappropriate \nresults. At the start of training, the generator produces false data \nand the discriminator quickly learns it to be false. As training \nprogresses, the generator produces more and more false data that \nthe discriminator is no longer able to detect, but begins to clas-\nsify the false data as true. \n \nFigure 4.28. Generative Adversarial Network. \nGAN trained with photographs is able to create new images that \nlook real to the human eye. In this case, the task of the generator \nis to generate credible content (images that look natural) and the \ndiscriminator evaluates the content (whether the generated im-\nage looks natural). Nvidia has used technology based on the \nGANs  to generate new, non-real face images (Paukku, 2018). \nThe basic idea of the GAN method is based on indirect training \nusing a discriminator, which is also updated dynamically. In this \ncase, the generator is not trained to minimize the distance to a \nparticular image, but to deceive the discriminator. GAN was \noriginally designed as a generative model for unsupervised \nlearning, but it has also proven useful in semi-supervised learn-\ning, supervised learning, and reinforcement learning.  \n4.10  Measuring Machine Learning Outcomes \nThe performance of most machine learning methods deviates \nfrom the desires if the training data used is not balanced (Davis \n& Goadrich, 2006). This means that approximately the same \n\n100 \n \namount training samples should be available for all classes to be \nidentified.  \nFor example, in many medical-related categorization problems, \nmost of the samples available may be normal due to rare occur-\nrences of deviations, in the financial industry there are relatively \nfew credit card frauds for a huge amount of payment transac-\ntions, etc. \nThus, most of the data may be so-called negative cases, but an \nunnoticed problem can be fatal or very expensive. Thus, the cost \nof misclassification is not the same in all cases. \nWhile access to raw data has become easier with digitalization, \ndata imbalances have become a growing problem. Unbalanced \ntraining data is often attempted to be balanced by either under- \nor oversampling. \nIn undersampling, a random sample of 10% of the majority clas-\nses in the training material is selected for use. If the imbalance is \ninitially in the order of 1:100, balancing can achieve the situation \n1:10, but a problem may be the loss of information needed to \nmodel the essential data. \nOversampling is used to duplicate randomly selected samples of \nminority groups, for example in the case of images, by mirroring \nand rotating, but this may result in so-called over-fitting and \nover-optimistic impression about the performance of the learned \nmodel. Often, for training samples 99% classification accuracy \nis then achieved, but only for them. With new material, the ac-\ncuracy may collapse. \nNext, assume the problem of classification into positive vs. neg-\native categories, where the positive cases are rare. In a typical \napplication it is not possible to achieve a situation, where the \ncategories are completely separated. In many cases, however, we \nare able to adjust the decision threshold for the category distri-\nbutions as illustrated in Figure 4.28. \n \n \n \n \n \n \nFigure 4.29. Errors in a two category classification problem. \nFor each value of the decision threshold, we get the \ndecision threshold \n1.0 \n0.0 \ntrue \nnegatives \nfalse ne-\ngatuives \nfalse \npositives \ntrue \npositives \n\n101 \n \n• \n\"true negatives\", which are negative samples to the left of the \ndecision threshold; \n• \n\"false negatives\", which are positive samples but are not \nclassified as negative because they have the features to the \nleft of the decision threshold, and \n• \n“false positives” and “true positives”, which are to the right \nof the threshold, respectively. \nIn a balanced case, the result is often represented by a so-called \nROC (Receiver-Operating Characteristics) curve, whose name \nderives from World War II's method of measuring the accuracy \nof radar observations. Figure 4.30 shows a typical ROC plot. The \nmore area under the curve, the better the result. \nThe ROC curve measures the proportion of \"true positives\" to \nthe right of the decision threshold as a function of \"false posi-\ntives\" expressed on the same side. The diagonal line represents \nthe result obtained by classifying randomly. \n \n \n \n \n \n \nFigure 4.30.Typical  ROC curve. \nPR (Precision-recall) graphs are often more illuminating in un-\nbalanced situations where positive samples have a lower propor-\ntion of material. Figure 4.31 illustrates the precision-recall re-\nsults for three different classifiers. \n \n \n \n \n \n \n \n \n \nFigure 4.31. Precision-recall curves for three classifiers.. \nAccuracy measures how much of the results obtained by a given \nclassification algorithm are meaningful, so that relevant infor-\nmation is not buried in the results (Precision).  Recall indicates \nhow much of the relevant information was found in the search. \n1.0 \n0.0\n00 \n1.0 \nshare of \ntrue positi-\nves \n share of false positives \n1.0 \n0.0 \n1.0 \n \nprecision \nrecall \n\n102 \n \nBecause the focus is on the minority category, the \"true nega-\ntives\" representing the majority are not considered.  \nIn the figure the category threshold of each classifier has been \nlowered to finally obtain all the positive samples. At the same \ntime, however, the accuracy has fallen as the proportion of  “false \npositives” increases. Of course, the lowest of the curves indicates \nthe weakest performance. \nDepending on the balance situation, both ROC and PR curves \nprovide important information about the classification perfor-\nmance. Typically, developing an application, you are particu-\nlarly looking for information on whether the classification is se-\nriously breaking down in any given situation. Alongside this, in-\ndividual \"error\" or \"accuracy\" figures are often less interesting \nand misleading imbalanced case. \n4.11 References \nBishop CM (2006) Pattern Recognition and Machine Learning.  \nSpringer, 738 p. \nBreiman L, Friedman J H, Olshen R A & Stone C J (1984). Clas-\nsification and Regression Trees, Wadsworth & Brooks/Cole Ad-\nvanced Books & Software, Monterey, CA. \nBreiman L (1996) Bagging predictors. Machine Learning 24 \n(2):123-140 \nBreiman L (1997) Arcing the edge. Technical Report 486, Sta-\ntistics  Department, University of California, Berkeley CA., 14 \np. \nBrynjolfsson E & McAfee A (2017) What’s driving the machine \nlearning explosion. Harvard Business Review, 18.7.2017.  \nChapelle O,  Schölkopf B & Zien A (2006). Semi-supervised \nLearning. Cambridge, Mass.: MIT Press.  \nDavis J & Goadrich M (2006). The relationship between preci-\nsion-recall and ROC curves. Proc. 23rd ICML, 233-240. \nDuda RO, Hart PE & Stork DG (2001) Pattern Classification, 2nd \nEdition. Wiley Interscience, 654 p. \nFrank E, Trigg L, Holmes G & Witten IH (2000) Technical note: \nNaive Bayes for regression. Machine Learning 41:5-25.  \nGoodfellow I, Bengio Y & Courville A (2015) Deep Learning. \nThe MIT Press.   \nHochreiter S & Schmidhuber J (1997) Long Short-Term \nMemory. Neural Computation 9 (8):1735-1780. \nKrizhevsky A, Sutskever I &, Hinton GE (2012) Imagenet clas-\nsification with deep convolutional neural networks. Advances in \nNeural Information Processing Systems, 1097-1105. \nKurama  V (2020) Gradient boosting in classification: Not a \nblack box anymore!  \n\n103 \n \nLeCun Y,  Boser B, Denker JS, Henderson D, Howard RE, Hub-\nbard W & Jackel  LD (1989)    Backpropagation applied to  hand-\nwritten zip code recognition. Neural Computation 1(4):541-551. \nLiaw A & Wiener M (2002) Classification and regression by ran-\ndomForest. R News 2:18-22. \nLiu L, Ouyang W, Wang X, Fieguth P, Liu X & Pietikäinen M \n(2020) Deep learning for generic object detection: A survey. In-\nternational Journal of Computer Vision 128:261–318. ar-\nXiv:1809.02165v4 \nMatikainen N (2017) Auton arvon aleneminen iän ja käytön \nmyötä. (The decrease of a car’s value as a function of it’s age \nand use). MS Thesis, Tampere University, 40 p.  \nOpala M (2019) Deep learning frameworks comparison – Ten-\nsorflow, PyTorch, Keras, MXNet, The Microsoft Cognitive \nToolkit, Caffe, Deeplearning4j, Chainer. 10.9.2019.  \nPaukku T (2018) Kuvan ihmistä ei ole olemassa (The person \nshown in the picture does not exist). Helsingin Sanomat \n27.6.2018. \nPeltarion (2018) Deep learning  challenge: Lessons from the \nfield, 12 p.  \nPeng C-Y J, Lee K L & Ingersoll GM (2002) An introduction to \nlogistic regression analysis and reporting. The Journal of Educa-\ntional Research 96(1):3-14, Taylor & Francis. \nRumelhart D E, Hinton G E & Williams R J (1986) Learning \nrepresentations by back-propagating errors. Nature 323:533-\n536. \nRussell SJ & Norvig P (2010) Artificial Intelligence: A Modern \nApproach, Third Edition, Pearson. \nSutton RS & Barto, AG (1998). Reinforcement Learning: An In-\ntroduction. MIT Press.  \nViola P & Jones M (2004) Robust real-time face detection. In-\nternational Journal of Computer Vision 57(2):137-154. \nWatkins CJCH & Dayan P (1992). Q-learning. Machine Learn-\ning 8 (3):279-292. \nZheng Z, Lauritzen JS, Perlman E, Robinson CG, Nichols M, \nMilkie D et al. (2018) A complete electron microscopy volume \nof the brain of adult Drosophila melanogaster. Cell, 26:730- 743.  \nWeb-GAN: Overview of GAN \nWiki-Deepsoft: Comparison of deep-learning software  \nWiki-GAN: Generative adversarial network  \nWiki-XGBoost: XGBoost \nWiki-Gradient: Gradient Boosting.  \n \n \n \n \n\n104 \n \n5 Artificial Intelligence Applications \nThere are very many types of AI applications.  A significant part \nby this time has been associated with machine perception, which \nallows for the application of pattern recognition and machine \nlearning methods. Speech and image recognition are typical ex-\namples.  \nIn various games such as chess and Go (Figure 5.1), artificial \nintelligence programs have won the best human players. Games \nusually have a limited number of moving options, randomness \nplays no or only a minor role, and the operating environment re-\nmains unchanged. \nMachine learning brings new tools to the analysis of massive \ndata, complementing traditional statistical methods. Areas of ap-\nplication include analysis of the data contained in medical data-\nbases and population registers, as well as in business applica-\ntions.  \n \nFigure 5.1. In the game Go area is demarcated from the oppo-\nnent. (© 123RF) \nFully autonomous vehicles are an example of a very challenging \nsituation. The operating environment is only partially observable \nand constantly changing, the result is also influenced by the ac-\ntions of other drivers and pedestrians, randomness plays a major \nrole and the number of possible situations is unlimited. \nAccording to Tables 5.1 and 5.2, Russell and Norvig (2010) di-\nvide application task environments and their properties into dif-\nferent types using the agent-related principle presented in Chap-\nter 2. However, in some cases, the proposed division is open to \ninterpretation depending on the individual application problem \nand its solution. \nThe information produced by the sensor may be wholly or par-\ntially observable by the agent performing the task. In chess, it is \ncompletely discernible, autonomous cars can only partially ob-\nserve the current operating environment with their sensors. \n\n105 \n \nThere is one agent performing some tasks, for example, in a \ncrossword puzzle, in image classification, and in speech recog-\nnition. There are two players in chess, but in an autonomous car \nthere are many agents considering other traffic and pedestrian \nactivities. The same is true for multidirectional dialogue, in \nwhich the machine strives for an almost natural conversation \nwith another person or several people. \nIf the next state of the operating environment is completely de-\npendent on the present state and the next operation, then it is a \ndeterministic environment. Chess, as well as image classifica-\ntion or speech recognition by the neural network method, are ex-\namples of this. There is randomness in poker, backgammon and \nespecially autonomous cars. Table 5.1 illustrates this aspect of \ncategorization. \nTable 5.1. Task environments viewed in terms of observability, \nnumber of agents and determinism  \nTask environment \nObservable \nAgents \nDeterminism \nCrossword puzzle \nFully \nOne \nDeterministic. \nChess with a clock \nFully \nMany \nDeterministic \nPoker \nPartly \nMany \nRandom \nBackgammon \nFully \nMany \nRandom \nSpeech recognition \nFully \nOne \nDeterministic \nImage classification \nFully \nOne \nDeterministic \nPart-picking robot \nPartly \nOne \nRandom \nAutonomous car \nPartly \nMany \nRandom \nMultidir.l dialogue \nPartly \nMany \nRandom \nData analysis \nFully \nOne \nDeterministic \nMicro-expressions \nPartly \nOne \nRandom \nEmotional state \nPartly \nMany \nRandom \nThe task environment also involves the dynamism of the tasks, \nthe nature of the observations and the periodicity. This is dis-\ncussed in Table 5.2. \nIn an episodic task environment, the agent's activity can be di-\nvided into sequences, each of which comprises detection (per-\nception) and subsequent operation. Image and speech recogni-\ntion by the classification method are good examples of this. In a \nsequential environment, the current decision can affect all future \ndecisions. Chess, multidirectional dialogue and autonomous cars \nare good examples. \nIn a static environment, such as a crossword puzzle, an agent can \nperform a current operation without changing the environment \nduring it. In a dynamic environment, the situation is constantly \nchanging, for example in autonomous cars or in multidirectional \ndialogue. In a semi-dynamic environment, the environment does \n\n106 \n \nnot change, but the measure of agent performance changes. \nChess is clearly semi-dynamic. \nTable 5.2. Task environments viewed in terms of episodic, dy-\nnamism, and continuity \nTask environment \nEpisodic \nDynamism \nContinuity \nCrossword puzzle \nSequential \nStatic \nDiscrete \nChess with a clock \nSequential  \nHalf-dynamic Discrete \nPoker \nSequential \nStatic \nDiscrete \nBackgammon \nSequential \nStatic \nDiscrete \nSpeech recognition \nEpisodic \nStatic \nContinuous \nImage classification \nEpisodic \nHalf-dynamic Continuous \nPart-picking robot \nEpisodic \nDynamic \nContinuous \nAutonomous car \nSequential \nDynamic \nContinuous \nMultidir.  dialogue \nSequential \nDynamic \nContinuous \nData analysis \nEpisodic \nStatic \nDiscrete \nMicro-expressions \nEpisodic \nHalf-dynamic Continuous \nEmotional state \nEpisodic \nDynamic \nContinuous \nAn environment is discrete when a finite number of observa-\ntions and operations are required to complete the task. Chess and \nmost games are like this. Driving a car is a continuous activity. \nThe speeds and locations of both you and other vehicles are con-\nstantly changing over time. Also, many of the driver's (agent's) \nfunctions are continuous, such as steering wheel and brake posi-\ntions. \nThe most difficult applications are those that are partially ob-\nservable, with multiple agents, random, sequential, dynamic, \nand continuous. Autonomous cars (Section 5.4) and multidirec-\ntional dialogue (Section 5.2) are very difficult applications for \nartificial intelligence based on these features. Also, reliable iden-\ntification and monitoring of the human emotional state is very \nchallenging (Chapter 9). \nThis chapter briefly introduces some of the key applications of \ntoday's artificial intelligence, except for machine vision, which \nis covered in Chapters 6-9. \n5.1 \nSpeech Recognition and Personal Assistants \nSignificant advances in artificial intelligence and machine learn-\ning in recent years have been seen especially in speech recogni-\ntion. In the past, recognition was too unreliable and background \nnoise made identification impossible. Professor Andrew Ng, a \nguru of machine learning, has predicted that after raising 95% \nrecognition accuracy to 99%, voice recognition will become our \nmain way of communicating with computers. \nThis four percent is the difference between disturbingly unrelia-\nble and highly usable. Thanks to massive training data and deep \n\n107 \n \nlearning methods, this distinction is now almost closed. For ex-\nample, speech recognition on a smartphone has become so reli-\nable over the years that it can be used, e.g., for Google searches. \nFinnish-language text can be translated into English so well that \nit is already understandable, although complete translation \nwould require an understanding of the language content. How-\never, there is still considerable room for improvement in transla-\ntions. \nAutomatic speech recognition system consists of three main \nsources of knowledge: 1) acoustic model, 2) phonetic vocabulary \nmodel and 3) language model (Fohr et al., 2017). The acoustic \nmodel characterizes language sounds, mainly speech phonemes \nand extra sounds (pauses, breathing, background noise, etc.). \nThe phonetic vocabulary model contains words that the system \ncan recognize with different pronunciation styles. The language \nmodel contains information about possible sequences of consec-\nutive words in the language. \nAcoustic models include so-called Hidden Markov Models \n(HMM), which have been the standard method to account for \ndynamic speech variations. Deep neural networks can be used in \nconjunction with HMM in acoustic modeling and in the language \nmodel to replace the traditional so-called n-gram model, which \nestimates the next word of a speech or text based on some of the \nprevious words (Figure 5.2). \n \n \n \n \n \n \n \n \n \nFigure 5.2. Principle of a speech recognition method (n-gram). \nIn current systems, statistical acoustic models and language \nmodels as well as, to some extent, vocabulary and utterance \nmodels are estimated using huge audio and text databases. As a \nresult, big Internet companies have had an advantage in devel-\nopment. \nRecently, there has been increasing attention to the so-called se-\nquence-to-sequence models. For example, Recurrent Neural \nfeature \nextraction \n \nspeech signal: \n”challenges of AI” \n.. \n.. \nfeature vectors of  \nspeech samples \nhidden Markov model \nbased recognizer \nacoustic model \nphonemic model \nlanguage model \nrecognition result: \n”challenges of AI” \nphonemes \nwords \nword se-\nquences \nfor feature calculation a variant \nof  cosine transform is often \nused; feature vectors are often \ncalculated for partly overlap-\nping  samples of 10 milliseconds \n\n108 \n \nNetworks (RNNs) have been used, which are particularly suita-\nble for generating new data or predicting the future state of the \nsystem based on past events (see Chapter 4). \nThe goal is to have fully neural models to replace the three dif-\nferent steps of the conventional method. Training such a system \nis simpler than the aforementioned three-step method. LSTM \n(Long Short-Term Memory) models inspired by RNNs use net-\nwork-based memory cells for temporary storage of data, which \nmakes them better than RNNs for modeling longer sequential \ndata, such as speech or text, because they allow taking into ac-\ncount both short and long term data. \nSpeech and sound control will have numerous applications, for \nexample, in customer service (Aittokoski, 2018), which is al-\nready familiar to us with bank telephone services in relation to \nwhat a customer is concerned with. According to Hannes Heikin-\nheimo, CEO of Speechgrinder, a Finnish company that develops \nFinnish-speaking voice recognition, voice-enhanced customer \nservice applications will include airport check-in, ATMs, gro-\ncery shopping, hotel check-in. Also, in cars, voice control is ex-\npected to become standard on various functions such as heating \nor navigation, freeing the driver to concentrate on driving itself. \nThanks to strong advances in speech recognition technology, \nleading artificial intelligence technology companies such as Am-\nazon, Apple, Google, and Microsoft have developed systems and \ntools for human-machine voice interaction. The respective prod-\nucts of these and some other companies compete with each other \nand are often also offered to third parties for their product devel-\nopment. \nAlexa is Amazon's cloud-based voice service, which is likely to \nbe in use in over 100 million properties. With its tools, applica-\ntion interfaces (APIs), reference solutions and documentation, it \nis easy to develop voice recognition interfaces for different \nneeds. The Amazon Echo is a very popular voice-controlled \nspeaker that connects to a smartphone via Bluetooth. Other man-\nufacturers have also introduced similar products. The smart \nspeaker allows you to bring home a variety of services with voice \ncontrol over the cloud and the Internet. \nSiri is a virtual assistant developed by Apple for its own products \nthat uses voice queries and its natural language user interface to \nanswer questions, make recommendations, and perform various \nactions via the Internet. Google Assistant is a virtual assistant \navailable for mobile devices, smart homes and cars. It can also \nbe used by third parties in their own products. In addition to the \nnatural sound, it is also possible to use the keyboard. The system \nis capable of searching the Internet, scheduling events and \nalarms, adjusting a user's device settings, and displaying infor-\nmation from their Google Account. Recent features include cap-\nturing and recognizing images taken by the camera of the device, \n\n109 \n \nsupporting purchases of products and sending money - and song \nrecognition. \nCortana is a virtual assistant developed by Microsoft for both \nMicrosoft operating systems and, in part, other operating sys-\ntems and devices. Cortana can send reminders, recognize speech, \nand answer questions using Microsoft's Bing search engine. \nHowever, the current assistants still have major shortcomings. \nThe content of the conversation with the machine is very limited, \nfar from normal human-to-human conversation. Emotions also \nplay an important role in human interaction, as noted in Chapter \n9. Current personal assistants do not take emotions into account. \nIt is expected that with the development of emotional intelli-\ngence, the next generation of assistants will recognize the user's \nemotional state and take it into account in their responses. \nProject Debater, developed by IBM since 2012, gives an indi-\ncation of what is going on. The system is able to argue with an \nunspecified subject with a master human debater. To do this, it \nuses a huge amount of articles previously read by the system. It \nis able to write and speak text-driven data, give a brief descrip-\ntion of a given discussion topic, formulate and present a well-\nconstructed speech, even with humor. \nThe system is also capable of listening to long speech and rec-\nognizing the main topics and statements. In addition, it is capable \nof modeling human-made disputes and dialects (puzzles), and of \nproviding counter-arguments when needed (Wiki-Debater). \nIn the last demonstration in February 2019, IBM Debater lost to \nan award-winning human debater on \"Should Preschools Be \nSupported in the United States\" (Shankland, 2019). As an ad-\nvantage over the human debater, the system had access to around \n10 billion sentences from news and academic research articles. \nThe weakness was, in addition to the monotone voice, the exces-\nsive focus on the system's opening remarks, rather than the op-\nponent's claims, though the listener was left with a real argument. \nSystem’s computing and hardware requirements are far from to-\nday's applications. In the future, this technology is intended to be \nused, for example, to complement human skills and to create \nmore sophisticated human-machine interaction. \nImplementations of commercial voice services are built on anal-\nysis made in service link centers. They are provided with addi-\ntional training material by allowing people to interpret unclear \ncases, which in some cases may violate the privacy of the end \nuser. \n5.2 \nNatural Language Processing \nUnderstanding and using spoken and written language, the natu-\nral language, is an essential part of human intelligence. People \n\n110 \n \nlearn a huge amount of new things from childhood through lis-\ntening to speech, reading texts, and chatting. Natural conversa-\ntion with the machine should also take place using speech and \nlanguage - regardless of language. Most Finns would like to talk \nto the machine in their mother tongue - not English. Translating \nfrom one language to another is also a key application area (Fig-\nure 5.3). \n \n \nFigure 5.3. Machine translation. (© 123RF) \nNatural language processing can be divided into five different \ntasks: 1) classification, 2) matching, 3) translation, 4) structural \nprediction, and 5) sequential decision-making (Li, 2017). \nIn classification, the text is categorized according to its content. \nCategories can also be opinions, for example, \"positive\", \"nega-\ntive\", \"neutral\". In matching, strings of texts are matched to see \nhow close they are to each other. This can be applied, for exam-\nple, in retrieving specific text, answering questions, and search-\nbased one-way dialogue, in which the machine searches the da-\ntabase for the most query-like answers. \nIn translation, the string is converted to another. This can be ap-\nplied to language translation, speech recognition, and generic \none-way dialogue, where the machine tends to produce new \nkinds of answers (which may be meaningless!). In structural pre-\ndiction, a string is described as a structure. For example, the goal \nmay be to find a part of a given sentence, segment individual \nwords, or divide a sentence into semantic parts based on their \nmeaning \nThe fifth task, the sequential decision-making process, is clearly \nthe most difficult task: it requires actions in the context of a dy-\nnamically changing environment. Multidirectional dialogue is \none of these. That is, how can we, for example, be able to chat \nwith a personal assistant or an intelligent robot so that the ma-\nchine understands the content of the conversation and is able to \nactively participate in it. \nCurrent artificial intelligence based on machine learning is \nmainly capable of pattern recognition and prediction, but not of \nabstract or common sense thinking and thus of understanding the \nmeaning of what it recognizes. However, deep learning and the \nuse of massive data have significantly contributed to the study \nGrammar algorithms \nVocabulary \nMachine translator \n\n111 \n \nand applications of natural language. Considerable success has \nbeen achieved in the above tasks 1-4. \nIn our daily work, this can be seen especially in machine trans-\nlators. Google Translate, for example, covers over 100 languages \nand is already capable of surprisingly good translations when \ncompared to results from a few years ago. Indeed, it is regularly \nused by foreign researchers in our research group to understand \nthe Finnish text, which is still widely used by university admin-\nistrators and others. Google’s program also helped us in translat-\ning this edition of our book from Finnish to English. Complete \ntranslation would require an understanding of the content of the \ntext, as would Task 5 in the list above. \n5.3 \nPlaying Games \nThe skill of a machine to play chess has been considered as one \nof the benchmarks when evaluating if a machine is intelligent  in \nsolving problems. Machine and human game strategies, espe-\ncially in the early days of chess development, differed greatly. \nThe machine's game has been based on evaluating the goodness \nof the various move options in each game situation (that is, \nwhere your own and your opponent's pieces are at that time) by \nlooking through the search tree for the various moving options. \nThe minimax algorithm (see Chapter 3) and pruning away poor-\nperforming transitions are  used to reduce the huge search space. \nThe average search tree branching factor is about 35, meaning \nthe player has as many as 35 options for the next move. \nIn 1997, IBM’s DeepBlue winning the world's best player, Gary \nKasparov, was able to rate an average of 14 of its own and op-\nponent's move options, ahead of the human players to select the \nbest move. The supercomputer developed by IBM for this pur-\npose was able to estimate 200 million positions per second and \nits best move estimator already used information from previous \ngames of the Grand Masters. \nThe game of the best human players, on the other hand, relies \nheavily on pattern recognition, meaning that the best players re-\nmember a large number of previous game openings and game \nsituations, and are able to find the best move without having to \ngo through a wide range of options. \nAccording to an article in Nature magazine (Amidzic et al., \n2001), chess grandmasters have learned to remember around \n100,000 piece placements on the board, and this is the main rea-\nson that sets them apart from regular players. Of course, the best \nresult can be achieved by combining these two strategies. Using \ndeep learning in machine play to take advantage of situations in \nprevious games has been a natural next step. \n\n112 \n \nIn 2011, IBM's Watson Artificial Intelligence program won peo-\nple in the popular TV Jeopardy quiz. This achievement was con-\nsidered a milestone in artificial intelligence even before the deep \nlearning breakthrough.  \nIn 2017, DeepMind's Alpha Zero program, founded by Google, \nwon the best chess computer software of the time, Stockfish 8 \n(Paukku, 2017). \nIn 2016, the same company’s AlphaGo Zero won the best human \nplayers in the Go board game (Paukku, 2018). Before this, arti-\nficial intelligence textbooks (Russell & Norvig, 2010) reported \nthat machines do so poorly in the Go game that the best human \nplayers don't bother playing against the machines. The slightly \nmore general-purpose AlphaZero of the same company was able \nto control chess and Japanese-style shogi, along with Go (Figure \n5.4). \n \nFigure 5.4. Japanese shogi, or general’s game. (© 123RF) \nThe algorithm used by AlphaGo includes machine learning and \ntree searching. It has been developed through training against \nboth human and machine players. The method is based on Monte \nCarlo tree search, which is guided by an \"evaluation network\" \nand an \"operating model network\". The latter recommends dif-\nferent game modes, the following of which are evaluated by the \nrating network. Ultimately, AlphaGo chooses the game mode \nthat is most successful in the simulation. \nDeepMind's machines are highly specialized and require a huge \namount of computing and training, and their use in real-world \napplications has not yet been demonstrated. Developed in 2017 \nat the University of Alberta, Canada, the DeepStack program \nwins a human in poker, where coincidence plays a huge role (Ri-\nley, 2017). \n\n113 \n \n5.4 \nSelf-driving Vehicles \nThe development of self-driving vehicles has been a long time \ncoming. At the time of Matti Pietikäinen's one-year postdoc visit \nto the University of Maryland in the mid-1980s, there was an \nAutonomous Land Vehicle project underway on the large \nDARPA (Defense Advanced Research Agency) strategic com-\nputing research program. The aim of the project, coordinated by \nMartin Marietta, was to make the (military) vehicle run inde-\npendently, for example on the highway. utilizing for example \ncomputer vision (Ake, 1986). \nThe difficulty of the problem became clear, as already monitor-\ning the roadside in changing circumstances was very challeng-\ning, not to mention more complicated tasks. A clear improve-\nment was made a little later when German professor Ernst Dick-\nmanns applied the Kalman filtering, familiar from control the-\nory, to roadside tracking (Wiki-Dickmanns). \nToday, self-driving cars can be considered as one of the flagship \nprojects of artificial intelligence (Figure 5.5). Huge sums are be-\ning invested in them and it is believed that in the coming years \nsuch will be driving in normal traffic. \n \nFigure 5.5. Self-driving vehicle. (© 123RF) \nExperiences of Google, Uber, Tesla and many automakers have \nled to successful test drives in limited conditions. Human assis-\ntive technology has been developed to stay on the highway and \nprevent crashes. Inside car cameras can monitor the driver's fa-\ntigue. Navigators help you find your desired destination. Road \nenvironments have been imaged, e.g., with Lidar radars (Light \nDetection and Ranging). \nHowever, there are enormous challenges. Fluctuations in the en-\nvironment and lighting cause major problems in obtaining relia-\nble sensor data. Solutions developed do not necessarily work \nvery reliably in a changing environment, such as in Finland. \nHow do we get cars to reliably detect pedestrians or animals \ncoming in, predict their actions,  and react quickly? How to make \n\n114 \n \nautonomous and people-driven cars work flexibly in one traffic? \nHow can such a highly complex technical system be operated \nwith sufficient reliability? \nAlongside the technical challenges, there are ethical issues. Who \nis responsible in the event of an accident? The limits of deep \nlearning are well reflected in this application. How can a system \nbe taught so that it can respond correctly under all possible cir-\ncumstances? How can it's reliability be  guaranteed? \nThe big problems with machine sensing are well illustrated by \nan Iltalehti news report from a March 2019, concerning a report \nfrom the Tencent Keen Security Lab, which investigated the re-\nliability of the Tesla autopilot by applying unobtrusive labels to \nthe road surface. They made the car turn to the oncoming lane! \n“According to researchers, Tesla's  lane detection works well un-\nder normal conditions, but dazzling light, rain, snowstorm or \nother distractions such as sand and dust cause difficulties” \n(Känsälä, 2019), (Tencent, 2019). \nIn August 2017, Professor Rodney Brooks from the Massachu-\nsetts Institute of Technology, a pioneer in the development of \nintelligent robots, wrote an interesting article in the IEEE Spec-\ntrum magazine, \"The Self-driving Car's People Problem\". He \nlooks at problems ahead and predicts how a complete autonomy \nmay be reached sometimes, but only through five different levels \nof difficulty (Brooks, 2017). \nAmong the most difficult problems he sees are: understanding \nthe actions of pedestrians, including their abnormal behavior in \npoor weather conditions such as snow-covered roads, and the \nfact that a self-driving car can, in its own interest, cause harm to \nhuman-driven cars. Another reason for his skepticism is that if \nautomation of mass transport such as trains is not yet fully auto-\nmated to date, then how is it possible to automate the much more \ndifficult car traffic? \nAccording to Brooks, the five different levels of difficulty are:  \n1. People still do most of the car's functions, but some functions \nlike steering or acceleration can be done automatically. \n2. At least one driver assist system is automated, eliminating \nthe need for the driver to physically control the car (hands \noff steering wheel and feet from pedals simultaneously). \n3. The driver transfers some safety-critical functions to the cars \nin certain traffic or weather conditions.  \n4. Fully autonomous vehicles perform all safety critical func-\ntions in specified areas and in specified weather conditions. \n5. Only at this level full human replacement in all circum-\nstances may be achieved. \nEthical concerns have already emerged in a couple of recent \nevents that will surely slow down the development and deploy-\n\n115 \n \nment of technology, one of which has been the accident involv-\ning a Uber self-driving car in Arizona in which a pedestrian died \n(NTSB, 2018). The reason for this was a misinterpretation of the \ninformation related to the observations made by the radar and the \nLidar radar: first, the pedestrian who  was walking with a bicycle \nwas identified as a car and then as a bicycle, thereby incorrectly \npredicting the pedestrian's path. The system would eventually \nhave proposed emergency braking, but it was not allowed in au-\ntopilot, nor was it reported to the human operator in the car. \nOther manufacturers, such as Nvidia, Tesla, and possibly \nGoogle, are also known to have encountered problems. One so-\nlution is remote control from control rooms in case of problems, \nbut in this case it is no longer possible to speak of fully autono-\nmous driving cars. Nissan is said to have opted for this and others \nare rumored to be considering it (Davies, 2018). \nIn fact, we believe it is realistic to reach level 4 mentioned by \nBrooks over time, i.e. fully autonomous operation in confined \nenvironments where pedestrians and cars are sufficiently sepa-\nrated or otherwise safe. Level 5 seems impossible for long in the \nfuture. \n5.5 \nBig Data Analytics and Data Fusion \nDue to the enormous increase in data through digitalization, big \ndata has become a business-critical resource. A large amount of \ncomputing power and various tools for analyzing data are re-\nquired to utilize the data. Businesses can use data to improve \ntheir core business, but also to create completely new business \nmodels. \nMass data analytics is already a well-established technology for \nprocessing and retrieving such information. Necessary functions \ninclude: editing and refining raw data for analysis, visualizing \ndata for the user, and various statistical methods for extracting \nrelevant data and making predictions based on the data collected. \nArtificial intelligence tools aim to automate this process and en-\nable the analysis of massive amounts of data. \nData analysis methodologies can be divided into three types: \n1. Data analytics refers to evaluating data based on past events, \n2. Predictive analytics makes assumptions and tests based on \nhistorical data to predict future events, and \n3. Artificial intelligence / machine learning analyzes data, \nmakes assumptions and produces predictions on a scale that \nhuman analysis alone cannot achieve. \nOne advantage of computers over humans is the ability to re-\ntrieve and recall vast amounts of information that can be ac-\ncessed quickly, for example, via the Internet. The machine does \n\n116 \n \nnot get tired and can work 24 hours a day. If the data is of suffi-\ncient quality, the machine can outperform human performance \nin limited machine learning tasks. \nOften too little attention is paid to the collection, naming, or an-\nnotation, and modification of good quality data for data analysis \nor machine learning methods, although the performance of the \nmethods is largely dependent on it. You must be able to choose \nthe right tools for each application. Most of the time that goes \ninto data analysis takes time to edit and clean up the data for \nautomatic analysis. Typically, this takes at least 80% of the time \nof the entire analysis process (Maikkola, 2019). \nBusiness applications are an important application area for data \nanalysis and artificial intelligence. The problem with applying \nmachine learning to business databases is that most of them are \ntoo dirty or sparse in terms of machine learning. So, for the time \nbeing, there are few real machine learning applications com-\npared to normal business analytics. Prediction is not required in \nmany applications, as statistical reasoning and analysis of vari-\nances are sufficient in 80-90% of cases according to Dominic \nLigot (Ligot, 2018). \nIn addition, data interpretability is usually more important in \nbusiness applications than absolute accuracy. For this reason, \ntraditional statistical methods are still dominant compared to \nblack-box methods of neural networks. However, due to the \nhype of artificial intelligence, many methods implemented by \nconventional methods are referred in media as artificial intelli-\ngence, although they actually are not. The greatest benefit of ar-\ntificial intelligence in business applications may therefore come \nfrom intelligent assistants who only help the user to make a de-\ncision. \nDue to its speed and other capacity, the machine is also able to \ncombine data from different sources in an unprecedented way. A \ngood example is a recent article on a study published by Nature \nHuman Behaviour, which found that human happiness is dimin-\nished by air pollution (Junttila, 2019). This conclusion was \nreached by analyzing the air quality of 144 cities in China and \nthe number of emotion-related social media responses  in these \ncities. \nSina Weibo's Twitter-like social media tweeds were used to help \nthis research. The AI was used to analyze as many as 210 million \nsocial publications over a six-month period, in which the user \nhad allowed the use of location information. \nDaily human emotional expressions or likes are unreliable, but \nover a longer period of time they provide reliable information \nabout the user's average emotional state. It is unclear to the \n\n117 \n \nreader what is artificial intelligence here and what is simply com-\nbining huge amounts of data from different sources using very \nfast computation and data analysis. \nCountless applications of this kind can be found and the data \nused for either good or bad purposes. Internet giants in particular, \nsuch as Google, Facebook, Amazon and similar Chinese compa-\nnies, collect huge amounts of information from their customers \nbased on, for example, web, social media and shopping behavior, \nand can use this information to predict individual behavior, for \npersonalized marketing of products etc. If combined information \nincludes in addition to social media behavior, for example, a per-\nson's Internet searches, shopping and health information, it is \npossible to create dangerously accurate profiles of people. \nJaron Javier, a pioneer of the Internet, regards Facebook and \nGoogle's business models as shaping people's behavior, which \ngoes much further than ordinary advertising (Ahlroth, 2019). \n“They are pushing our free will and our happiness as well as our \nability to empathize. They are destroying the truth. In the end, \nthey also take our soul.” The algorithms developed by these \ncompanies have not been published. \nComputational models using advanced statistical mathematics \nand machine learning provide users with both “carrot” and some-\ntimes “stick” - thus gradually changing their behavior to the ben-\nefit of businesses. (Ahlroth, 2019). Javier has written his \nthoughts in a recent book, \"Ten Arguments For Deleting Your \nSocial Media Accounts Right Now” (Javier, 2018). \n5.6 \nMedical Applications \nThe application of artificial intelligence in medicine has aroused \ngreat interest and the potential applications are countless. A gen-\neral trend in research in the field over the past 30 years has been \nthe shift from knowledge-based approaches to data-driven meth-\nods (Peek et al., 2015). \nImproving the quality of services and increasing security are key \nissues that artificial intelligence is hoped to help (Karlen, 2018). \nProfessor Walter Karlen (ETH Zurich), in his article, gives an \nexample of a Chinese TV show in which 25 cancer doctors com-\npeted against an artificial intelligence program for cancer diag-\nnosis and prognosis based on brain analysis. Artificial Intelli-\ngence defeated the experts 2-0. \nIn his view, the Chinese have a clear lead in the use of artificial \nintelligence systems to support clinical decision-making, \nwhether in the form of diagnostic tests or the implementation of \nlarge-scale hospital-wide systems. \nAccording to Professor Karlen, doctors are bad at evaluating \nmultidimensional data at the same time, that is, combining infor-\nmation from different sources - and they often tend to interpret \n\n118 \n \nthings negatively. On the other hand, machines are bad for inter-\npreting contextual situations, or for dealing with situations of un-\ncertainty. Thus, at all times, machines are dependent on high \nquality and large amounts of data. \nBoth people and machines make mistakes! However, if well-\nfunctioning automated next generation artificial intelligence \nclinical decision support systems are to be put into practice, they \nmust meet high medical standards and performance require-\nments, as well as local cultural, ethical and regulatory issues, and \nbe cost effective and based on a sustainable business model (Kar-\nlen, 2018). \nInterpretation of images generated by imaging equipment and \nother measurement data has become central to many medical di-\nagnoses. For example, it may be the interpretation of images pro-\nduced by microscopy, X-ray equipment, ultrasound camera or \nmagnetic resonance imaging, or various physiological signals \n(ECG, EEG). For example, magnetic resonance imaging pro-\nduces increasing numbers of clip images each year (Figure 5.6). \n \n \n \n \n \n \n \n \n \nFigure 5.6. MRI scans of the human brain. (© 123RF) \nArtificial intelligence and machine learning are hoped to assist \nphysicians in interpreting such massive data - and perhaps even \nin the future - to automatically diagnose diseases and make drug \nrecommendations based on them. The development and popular-\nization of medical imaging techniques has led to a tremendous \nincrease in the amount of data. \nSection 8.5 outlines the problem of interpreting lung X-rays dis-\ncussed in our study: How to identify healthy lungs with poten-\ntially ill lung images using the CNN deep neural network \nmethod. This information could be used to distinguish suspicious \ncases already in the health center, before a detailed examination \nby a very busy radiologist in the hospital. About 80% accuracy \nwas achieved in the experiments, but raising it to an acceptable \nlevel would have required a much larger amount of training data. \n\n119 \n \nThis \"simple\" example demonstrated that the acquisition of an-\nnotated, i.e. named, training data is central to the application of \ndeep learning methods to highly variable image data. As tech-\nnology continues to evolve, imaging equipment is improving and \nold training data may not be very usable with new material. \nOn the other hand, creating annotated data is very laborious, as \nan example: which lung images are from a healthy person and \nwhich images may show symptoms of disease. There is not \nenough time for application experts such as radiologists in this \ncase. Another major challenge is that it is difficult in medical \napplications to accept machine diagnoses that cannot be substan-\ntiated by a neural network. Thus, we believe that the interpreta-\ntion of images based on machine vision and deep learning can \nonly assist a physician in making diagnoses, not substitute a phy-\nsician. \nAccording to Chief Physician Päivi Ruokoniemi, artificial intel-\nligence will bring added value to the automation of health care \nprocesses. Data mining in patient records can provide essential \ndiagnostic information from hundreds of pages of patient records \nfor use by the physician, as well as for other applications similar \nto normal physician practices (Ruokoniemi, 2018). She is very \nskeptical about the use of artificial intelligence based on deep \nneural networks in disease diagnosis and decision-making on \ndrug therapies. \"At its worst, artificial intelligence can recom-\nmend treatments that are unrelated to the patient's diagnostic sta-\ntus.\" This is related to the fact that current artificial intelligence \ncan only find correlations, not causal relationships between, for \nexample, a drug and its expected effects. \nHer suspicions are supported by a publication in the prestigious \nScience journal looking at the vulnerability of machine learning \nmethods to adversarial attacks containing false training data, and \ntheir relevance to medical applications (Finlayson, 2019). \nA significant problem in the application of machine learning, es-\npecially to medical problems, is also seen in the fact that the so-\nlutions presented in research publications have mostly been \ntested with incomplete data and their results cannot be replicated \nin a real application environment (Scudellari, 2021). For exam-\nple, according to an analysis by researchers at the University of \nToronto, 85% of the publications on machine learning for \nCOVID 19 detection from lung images did not meet reproduci-\nbility or quality requirements, and none of the presented machine \nlearning models were ready for clinical use! Three ways are pro-\nposed to improve the situation: 1) to form joint teams of machine \nlearning and medical experts, 2) to use high-quality data and \nknow its origin, 3) to adopt standards for scientific conference \ncommunities that require the use of high-quality data and suffi-\nciently comprehensive reporting in publications. \n\n120 \n \nAccording to Tapio Seppänen, professor of medical information \ntechnology at the University of Oulu, \"there are many products \nin the health industry that make data analysis and conclusions \nbased on this\". In practice, the development of such artificial in-\ntelligence is a long-term effort, as product compliance verifica-\ntion and medical validation take a long time. It is imperative to \nverify that the product is delivering what it promises and that it \nhas medical benefits in patients' care. \nFigure 5.7 shows the skin abnormality. It is ultimately necessary \nfor an expert to determine whether it is a harmless mole or, for \nexample, melanoma. However, the machine can make a prelim-\ninary assessment. \n \nFigure 5.7. A dark area to be diagnosed on the skin. (© 123RF) \nBecause of liability issues, such solutions do not automatically \nmake diagnostic decisions or suggest treatment measures, but \nserve as decision support systems for healthcare professionals. \nTheir job is not (at least for a long time) to replace the doctor, \nbut to act as his work tool. This also avoids the risk of making a \nlot of wrong decisions, because the machine is not perfect here, \nif not a human being. \nObviously, medical applications of artificial intelligence involve \nethical issues, for which recommendations are discussed, among \nothers, in the reference (Luxton, 2014). \n5.7 \nAudiovisual Video Content Retrieval  \nContent-based image retrieval has been studied since the 1990s. \nThe search system is given the desired query image. The system \nthen searches the database for the most resembling images re-\ntrieved from the database and arranges them according to how \nclose they are to the query image. For example, if a feed image \nshows Donald Trump, the system will search for images that re-\nsemble him the most. \nThe problem here is how well the content of the images can be \nrepresented by selected computationally simple features to allow \naccurate and fast retrieval. Typically, in the early days simple \nfeatures related to color and texture and to the structure of ob-\njects were used. In a content-based video retrieval, a desired \nvideo clip is fed to the system and then the system searches the \n\n121 \n \ndatabase for the most resembling ones. Instead of just showing \nimages, one must also be able to model motion, for example, \nwalking people, moving cars, etc. Deep learning solutions have \nmade it possible to find a much more accurate search for both \nimages and videos. \nIn many cases, audio provides significant additional information \nbeyond just image and video information. For example, look for \nplaces in a movie where a certain person talks. This is a search \nfor audio-visual video content. The rapid development of speech \nrecognition technology in recent years (see Section 5.1) allows \nus to reliably recognize speech in different languages with video \nand convert it to text if desired. \nAn exciting EU-funded H2020 research project, MeMAD \n(https://memad.eu), was underway in 2018-20 to develop com-\nputationally effective, reusable and multi-purpose methods for \nanalyzing multilingual audiovisual content. The aim was to rev-\nolutionize the processing of video collections and digital story-\ntelling in the production of television programs and other media \n(MeMAD, 2018). \nFor example, the method developed in the project enables the \naudio-visual content of the video to be converted into text - di-\nrectly into the desired language. This could revolutionize the \nway large video collections are handled by media companies, for \nexample, and allow for the reprocessing of previously produced \nmaterial and its application for new purposes. The solutions are \nplanned to make it easier for the general public, and especially \nthe hearing and sight-impaired, to find the material. \n “The new discovery, accessibility and personalized service ex-\nperience provided by artificial intelligence will continue to be \nvital success factors for the European media industry. Under-\nstanding content is one of the most promising areas of artificial \nintelligence at the moment,” says Anssi Komulainen, Senior \nVice President, Innovation Strategy at Yle (a Finnish public ser-\nvice media company) (MeMAD, 2018). The project involved \nfour actual research partners and four companies or similar: \nAalto University, University of Helsinki, University of Surrey, \nEURECOM, Yle, Lingsoft, Limecraft and INA. The project was \ncoordinated by Professor Mikko Kurimo, Department of Signal \nProcessing and Acoustics, Aalto University. \nAudiovisual video analysis is also the focus in the Oulu-based \ncompany Valossa, which has developed a platform and method-\nology \nfor \nadvanced \nvideo \ncontent \nanalytics \n(https://valossa.com). \n5.8 \nReferences \nAhlroth J (2019) Addiktion algoritmi hallitsee meitä (An addic-\ntion algorithm is ruling us). Helsingin Sanomat 24.1.2019. \n\n122 \n \nAittokoski H (2018) Pian puhut koko ajan koneille  (Soon you \nwill speak all the time to machines). Helsingin Sanomat \n23.9.2018. \nAke D (1986) Engineers at Martin Marietta put their $17-mil-\nlion experiment in UPI Archives 12.6.1986 \nAmidzic O, Riehle HJ, Fehr T, Wienbruch C & Elbert T (2001) \nPattern of focal gamma-bursts in chess players. Nature \n412(6847):603. \nBrooks B (2017) The self-driving car’s people problem. IEEE \nSpectrum, 32-35, 47-49. \nDavies A (2018) Self-driving cars have a secret weapon: Re-\nmote control,  Wired 2.1.2018.  \nFinlayson SG, Bowers JD, Ito J, Zittrain JL, Beam AL & Ko-\nhane IS (2019) Adversarial attacks on medical machine learn-\ning. Science 363 (6433):1287-1289. \nFohr D, Mellas O & Illina I (2017) New paradigm in speech \nrecognition: Deep neural networks. Proc. IEEE Int. Conference \non Information Systems and Economic Intelligence, 7 p. \nJavier J (2018) Ten Arguments for Deleting Your Social Media \nAccounts Right Now. Bodley Head, 160 p. \nJunttila J (2019) Puhdas ilma lisää onnellisuutta (Clean air will \nincrease happiness). Helsingin Sanomat 24.1.2019. \nKarlen W (2018) Is medicine ready for artificial intelligence? \nMedicalXpress, 6.9.2018. \nKänsälä S (2019) Vaarallinen tarratemppu paljastui - voi ohjata \nauton vastaantulevien kaistalle (A dangerous sticker trick was \nfound – it can drive a car to the oncoming lane). Iltalehti \n3.4.2019.  \nLi H (2017) Deep learning for natural language processing: Ad-\nvantages and challenges. National Science Review, 6 p. \nLigot D (2018) What is the brutal truth about machine learning? \nQuora Digest, September 2018. \nLuxton DD (2014) Recommendations for the ethical use and de-\nsign of artificial intelligent care providers. Artificial Intelligence \nin Medicine 62:1-10. \nMaikkola M (2019) Datayhteiskunta on täällä (Data society is \nhere). Kaleva 1.9.2019. \nMeMAD (2018) Tutkijat opettavat tekoälyn kuvailemaan vide-\noita  (Researchers teach  the AI to describe contents of  videos). \nhttps://memad.eu   \nNTSB (2018) Preliminary Report Released for Crash Involving \nPedestrian.  National Transportation Safety Board.  \nPaukku T (2017) Googlen tekoäly AlphaZero opetteli hetkessä \nshakkineroksi (Google’s AI AlphaZero learned quickly to be-\ncome a genius in chess). Helsingin Sanomat 14.12.2017.  \n\n123 \n \nPaukku T (2018) Ihmisen go-lautapelissä voittaneen tekoälyn \npiti olla totta ehkä vasta vuonna 2035 (The AI that won a human \nin the go board game was not supposed  be true before 2035). \nHelsingin Sanomat 18.10.2018.  \nPeek N, Combi C, Martin R & Bellazzi R (2015) Thirty years of \nartificial intelligence in medicine (AIME) conferences: A review \nof research themes. Artificial Intelligence in Medicine 65:61-73. \nRiley T (2017) Artificial intelligence goes deep to beat humans \nat poker. Science news 3.3.2017.  \nRuokoniemi P (2018) Tekoälyä on käytettävä harkiten \nlääketieteessä (AI should be used with care in medicine).  Hel-\nsingin Sanomat 28.10.2018. \nRussell S & Norvig P (2010) Artificial Intelligence: A Modern \nApproach, 3rd Edition. Pearson, 1152 p.  \nSchankland S (2019) IBM's AI loses to a human debater, but it's \nstill persuasive technology. Cnet News 11.2.2019.  \nScudellari M (2021) Machine learning faces a reckoning in \nhealth research. IEEE Spectrum 29.3.2021. \nTencent (2019) Experimental security research of Tesla autopi-\nlot. Tencent Keen Security Lab.  \nWiki-Debater: Project debater \nWiki-Dickmanns: Ernst Dickmanns  \n \n \n\n124 \n \n6 Computer Vision - The Engine for AI Research \n6.1 \nGeneral about Computer Vision \nThe use of sensory information is central to the development of \nmachines with similar intelligent properties as humans. Com-\npared to other senses, vision is particularly important: man re-\nceives most of the information about his environment through \nvisual perception. An estimated 30-50% of the brain is said to be \nused to process visual information. \nVision is influenced by a complex mechanism consisting of three \nmain components: the environment (or object) to be observed, \nthe lighting, and the observer. Three different schools of science \nstudy visual perception. Neurophysiologists seek to understand \nthe function of the sensory and neural mechanisms of biological \nsystems. Observational psychologists study psychological fac-\ntors related to perception. Computer vision scientists are explor-\ning computational, algorithmic, and technical problems associ-\nated with image acquisition, processing, and automatic interpre-\ntation. \nThe overall goal of computer vision is to make the machine see \nand understand what the view represented by the camera or other \nsensor contains and utilize this information in a variety of appli-\ncations (Ikeuchi, 2021). For example, the machine must be able \nto identify objects and determine their positions and orientations, \ncreate a three-dimensional model of objects or imaged environ-\nment, detect changes in objects, and interpret the significance of \ndifferent observations. The section on traditional machine vision \nfound in Sections 6.1 and 6.2 is largely borrowed from Matti Pi-\netikäinen's chapter in Encyclopedia of Artificial Intelligence \n(Tekoälyn ensyklopedia) or his other contributions (Pietikäinen, \n1993). \nUsually, automatic interpretation of the image is a very demand-\ning task. Each application has its own specific requirements and \nuniversal methods have not been successfully developed. \nChanges in lighting, viewing direction and background, as well \nas other variations in the operating environment generally cause \ngreat difficulty in interpreting the described scene. \nIn the simple case, the images to be analyzed are two-dimen-\nsional, so that no depth information is needed to interpret them. \nAnalyzing three-dimensional views is significantly more de-\nmanding because objects look different from different view-\npoints. They may also partially overlap. In addition, objects or \nthe camera, or both, can be in motion relative to one another, \nwhich not only causes additional problems but also facilitates the \nunderstanding of the content of the view. \nAs a discipline, computer vision is very challenging, interesting \nand multidisciplinary. Computer vision related problems are \n\n125 \n \nstudied by computer experts, mathematicians, physicists, elec-\ntronics and systems engineers, human vision psychology re-\nsearchers and more. \nIn the scientific community, this field is commonly referred to \nas computer vision. Here mathematical theory, algorithms, and \noften also the connections to human perception play a central \nrole. Machine vision is often referred to as vision for applica-\ntions. A system engineering approach that takes into account the \nrequirements and limitations of applications, imaging, algo-\nrithms, system architectures, hardware and software, interfaces, \netc. plays an important role in this. \nComputer vision issues are also being explored in many other \nareas. The closest related disciplines include digital image and \nsignal processing, pattern recognition - and recently machine \nlearning has played a very important role. \nImaging has a very important role for most applications. Figure \n6.1 shows examples of different cameras in different applica-\ntions. Cameras can operate like the human eye in visible light, \nbut also in the dark. Instead of using a standard image sensor, \nultrasound or X-rays familiar to medical applications - or radar \nfor terrain and cloud imaging - can be used for image acquisition. \n \nFigure 6.1. Examples of different cameras. (© 123RF) \n6.2 \nSteps of the Traditional Computer Vision Process \n6.2.1 Simplified image analysis process \nThe following describes the different steps of a typical image \nanalysis process used in the simplest machine vision applica-\ntions. In this context, it is assumed that the view to be analyzed \nis a two-dimensional single image, so that there is no depth in-\nformation or processing of video sequence to interpret the ob-\njects in the image. Figure 6.2 shows the main stages of the anal-\nysis in a block diagram (Pietikäinen 1993). When, for example, \n\n126 \n \nconvolutional neural networks are used for the same purpose, the \ndiagram becomes different (see Chapter 4). \n \n \n \n  \n                            \n  \n                                                                                     \n               Training \n                              \nFigure 6.2. Simplified image analysis process. \nThe first step is to create an image with an image source, such as \na standard digital camera or documentary scanner. In many ap-\nplications, image analysis can be crucially facilitated if lighting \nand other imaging arrangements are carefully designed. \nDepending on the application, a digitized image may have a very \nvariable number of pixels. Typically, there are 512 x 512 to 2048 \nx 2048 pixels. Often grayscale images are quantized, for exam-\nple, the tone scale is quantized to 256 levels. Similarly, a color \nimage often uses 3 x 256 quantization levels, or 256 levels for \neach color component (e.g., RGB, red, green, and blue) to deter-\nmine the pixel color. \nA video image sequence consists of sequential images, i.e. \nframes, typically taken at 25 frames per second, but in many \ncases a higher speed may be required. For example, the micro-\nexpression recognition in Chapter 9 required a speed of 100 \nframes per second for best results. \nThe next step is image preprocessing, whereby the image is con-\nverted into a format that is more advantageous for analysis by \ndigital image processing. For example, the image can be normal-\nized so that fluctuations in lighting and other environmental fac-\ntors do not unduly influence the final result. Many times, the im-\nage is designed to filter out noise or other gray-level changes that \ninterfere with the analysis, and to highlight features of interest. \nIn addition, geometric correction of the image may be required, \nfor example, due to distortion caused by the camera lens or to \nmatch images taken at different times. \nNext, the image is segmented: the goal is to separate the objects \nand parts of objects from each other and their background. Tra-\nditionally, two alternative principles have been used for segmen-\ntation: region-based methods divide an image into homogeneous \nregions of gray scale, color, etc., and in edge detection sharp \nchanges in color, i.e., the edges of regions, are detected. \nFigure 6.3 shows an example of character segmentation by a \nmethod based on the use of adaptive grayscale threshold (Sau-\nvola & Pietikäinen, 2000). \nImage ac-\nquisition \nPrepro-\ncessing \nSegmen-\ntation \nDescrip-\ntion of con-\ntents \nMat-\nching \nMo-\ndels \nRecogni-\ntion \n\n127 \n \n \nFigure 6.3. Character segmentation by adaptive threshold \nmethod. (© Elsevier) \nReprinted, with permission, from Elsevier [Sauvola J & Pietikäinen M (2000) \nAdaptive document image binarization. Pattern Recognition 33:225-236.] \nGenerally, segmentation is one of the most critical steps in image \nanalysis, and segmentation methods vary depending on the ap-\nplication. Poor segmentation complicates the analysis and may \neven render it impossible, for example, adjacent characters might \nnot have been separated in the image above. \nAfter that, features describing the properties of the segmented \nareas, edges, etc., are computed, on the basis of which different \nobjects can be distinguished. Such features include, e.g., shape, \ncolor, and texture describing the gray-level properties of regions. \nFrequently, the object to be recognized consists of multiple seg-\nmented regions or edge segments. In this case, in addition to the \nproperties of the regions (edges), information on the interrela-\ntionships between the regions (edges) is needed in describing the \nstructure of the object. For example, networks (graphs) are used \nto describe a structure, whose nodes represent areas (edges) and \nlinks their interdependencies. \nThe generated representations are compared with the prototype \ntarget models taught to the system, thereby seeking to identify \nobjects in the image or to detect deviations from the models. The \nobjects in Figure 6.3 are typed letters, numbers, and other char-\nacters. \nIn the simplest case, the objects can be described with sufficient \nprecision by global features describing the shape of the individ-\nual segmented regions or other properties (e.g., average gray \nlevel of regions, gray level variance, area, circumference, shape \ncomplexity). Different objects can then be identified using these \nfeatures by pattern recognition methods or a neural network. \nGenerally, however, objects consist of multiple regions or edge \nsegments, whereby, for example, they need to be grouped to-\ngether to obtain features suitable for the classifier or to use so-\ncalled structural pattern recognition, such as a graph representa-\ntion (see Chapter 3), to describe the properties of different re-\ngions and their location relative to each other. \n6.2.2 Acquisition of three-dimensional information \nAnalyzing three-dimensional views is considerably more diffi-\ncult than two-dimensional cases. Feature detection and segmen-\ntation are complicated by, e.g., variations in illumination due to \n\n128 \n \nshadows and dependence of surface brightness on surface orien-\ntation. \nIt is difficult to calculate the properties used for recognition be-\ncause objects look different in different directions and many \nthings measured in the image are dependent on the viewing di-\nrection. It is also difficult to identify if there is only one side of \nthe objects visible or the objects may partially overlap. \nAnalyzing three-dimensional surfaces usually requires infor-\nmation about the topography of the surfaces in the image. For \nexample, information about the normal orientation of the surface \ncorresponding to each visible point is useful. This kind of orien-\ntation information makes it possible to indicate important orien-\ntation edges, i.e., points at which the surfaces change direction \nrapidly. This then facilitates image segmentation so that the re-\nsult is consistently smooth surfaces. \nIn order to determine the orientation of 3-D surfaces, so-called. \nshape from X technologies have been developed. They deter-\nmine the shape of the surfaces (that is, the orientation of the sur-\nface at different pixels) by using different types of shape cues. \nThese include, e.g., methods based on the use of shape from \nshading, shape from texture, and shape from contour / shape. \nGenerally, it is not possible to uniquely determine the orientation \nof surfaces using only one image. The problem can be alleviated \nby using two or more cameras in known locations, i.e., so-called \nstereo imaging. By finding matching points in different places in \ndifferent images, the distances of these points from the camera \nsystem can be determined by the triangular measurement princi-\nple. \nDepth information can also be obtained from motion by looking \nat the sequence of video images formed by several consecutive \nimages as the camera moves, even if there is no accurate \ninformation about the locations of the camera at different times. \nAlong with the depth, you get information about the motion that \nhappened. Such methods based on the use of a normal camcorder \nare called passive because they do not transmit energy to the \nscene to be analyzed.  \nActive distance acquisition methods can often greatly facilitate \nanalysis. Such solutions have already long been available, e.g., \nmethods based on laser pulse travel time measurement and the \nuse of structural light. It is possible to obtain depth information \ndirectly from objects by forming a so-called range image (depth \nmap), where each visible point is valued by the distance of the \npoint from the camera. An example of a widely used distance-\nmeasuring device in machine vision is a Kinect camera based on \nthe use of active infrared light (Wiki-Kinect). \nFigure 6.4 shows an example of a range image taken with a \nKinect camera and a color image of the same subject (Herrera \n\n129 \n \nCastro et al., 2011). In the range image, different distances from \nthe camera are shown in different colors. \n \nFigure 6.4. A range image and a normal color image. (© \nSpringer) \nReprinted, with permission from Springer [Herrera Castro D, Kannala J & \nHeikkilä J (2011) Accurate and practical calibration of a depth and color cam-\nera pair. In: Computer Analysis of Images and Patterns, Proceedings, Lecture \nNotes in Computer Science 6855] \nDepth cameras have greatly facilitated the analysis of 3-D im-\nages. They are now also coming to mobile devices. Google's \nTango has been the first mobile platform to incorporate a range \ncamera (Intel RealSense) and other sensors. It produces both \ndepth maps and color images (RGB-D). It also has pretty good \nodometry, the ability to calculate distance based on information \nfrom motion sensors. \n6.2.3 Analyzing 3-D views \nIt is generally assumed that man organizes his knowledge of the \nenvironment as abstract concepts, for example, \"house\", \"wall\", \n\"animal\", \"bear\". There is an enormous gap in the interpretation \nof the image between such abstract concepts and the camera im-\nage’s iconic presentation. The transition from image data to sym-\nbolic representation must be accomplished through intermediate \nsteps. \nFigure 6.5 shows a traditional approach consisting of a lower, \nintermediate and upper levels. This is partly based on Professor \nDavid Marr's conception of the three steps that human beings use \nwhen analyzing 3-D scene images (Marr, 1982), Section 3.4. \nAt the lower level, the image is preprocessed, segmented, and \ntwo-dimensional (2-D) features depicting target areas or edge \nsegments are computed. This sub-system is called \"low-level vi-\nsion\" or \"early vision\". \nThe primary function of the intermediate-level system is to de-\ntect and analyze three-dimensional (3-D) features. Three-dimen-\nsional information can be derived from the features computed at \nthe lower level, or obtained directly by the methods developed \nfor the acquisition of the 3-D information mentioned above. \n\n130 \n \n \nFigure 6.5. 3D view analysis process. \nThe task of a high-level vision system is often to find the models \nof previously known or learned objects that best fit with the \nstructures represented in the image. Problems are caused by the \nappearance of the 3-D objects depending on the viewing location \nand the lack of two-dimensional image data, especially if the ob-\njects overlap. In addition, objects belonging to a particular cate-\ngory (e.g., \"house\") can vary greatly in appearance \n6.3 \nCurrent Research Areas \nDespite the numerous applications implemented, the field of \ncomputer vision is still research-focused. The solutions used in \nthe applications have been largely customized. So far, there are \nonly a few universal methods and solutions. \nMathematical modeling of visual information in real-world \nproblems is often overwhelmingly difficult. It is particularly dif-\nficult to develop methods that work under changing conditions, \nfor example, when lighting and camera positions vary. The high-\nspeed requirements of applications also often impose special re-\nquirements on the methods being developed.  \nFigure 6.6 presents the major challenges associated with identi-\nfying objects in natural environments. The  partial problems in-\nclude (a) illumination, (b) deformation, (c) scale and viewpoint, \n(d) size and pose, (e) clutter and occlusion, (f) blur, (g) motion, \n(h) different instances of the same category, and (i) small inter-\nclass variations (Liu et al., 2020). \n\n131 \n \n \nFigure  6.6. Challenges of object identification. (© CC BY 4.0)  \nFrom [Liu L, Ouyang W, Wang X, Fieguth P, Liu X & Pietikäinen M (2020) \nDeep learning for generic object detection: A survey. International Journal of \nComputer Vision, 58 p.], arXiv:1809.02165v4. This work is licensed under a \nCC BY 4.0. http://creativecommons.org/licenses/by/4.0/.  \nIn order to achieve good classification accuracy, a huge amount \nof training samples is required to account for any variations that \nmay occur. One way to reduce these fluctuations (and thus the \nnumber of training samples required) is to develop object repre-\nsentations that can withstand a wide range of variations, such as \nbeing reasonably invariant with respect to illumination and ob-\nject size and position variations. \nSince 2012, there has been a clear paradigm shift in computer \nvision research. The simplified solution models presented in \nSection 6.2 were often replaced, at least in part, by models based \non deep neural networks.  \nIndeed, the application of deep convolutional neural networks \nhas produced excellent results in many computer vision prob-\nlems, such as character recognition, object detection and classi-\nfication, face recognition, vehicle and pedestrian location, and so \non. Solutions based on deep learning have been as the main-\nstream in scientific conferences - and due to the results obtained \nthe interest on machine vision applications in industry has \nclearly grown. \nHowever, the need for massive training data and computational \ncomplexity often limit the application of deep neural networks \nin practice. For example, for applications in industrial visual in-\nspection, medical image interpretation, and micro-expression \nrecognition it may be very difficult or impossible to find a suffi-\nciently comprehensive range of training samples. Typically, the \n\n132 \n \nmaterial available or readily available is unbalanced, with the \nmost interesting rare deviations being underrepresented. \nInterpreting three-dimensional information with deep neural net-\nworks is also particularly difficult, as obtaining sufficient train-\ning material is very difficult. This can be concluded from the \nmany factors affecting interpretive data presented in Section 6.2.  \nOf special concern are applications that require very compact \nhardware implementation and low power consumption. These \ninclude smartphones, wearables, smart watches and glasses. \nIn scientific publications, classification accuracy or some related \nmeasure are often the most important and almost the only crite-\nrion for the performance of a new computer vision method. \nHowever, there are many other factors to consider when imple-\nmenting applications and choosing methods.  \nFor instance: What are the requirements for the given applica-\ntion? How many training samples are available and at what cost? \nWhat is the cost, size and power consumption of the system be-\ning developed? How user-friendly the system is? How can the \nsystem be updated and adapted to new environments? \nListed below are some timely key topics in a leading computer \nvision conference (ICCV 2017): \n1. 3-D computer vision \n2. Identification of actions \n3. Big data and large scale methods \n4. Biometrics: face and gestures \n5. Analysis of biomedical images \n6. Computational photography, photometry, object shape from \nvarious clues \n7. Deep learning \n8. Low level computer vision and image processing \n9. Motion and tracking \n10. Optimization methods \n11. Identification: detection, categorization, indexing and \nmatching \n12. Robotic vision \n13. Segmentation, grouping and representation of shapes \n14. Statistical learning \n15. Video: events, activities and video surveillance \n16. Computer vision for something (X) \nThe following are typical problems that have recently been ad-\ndressed in basic computer vision research. \nFigure 6.7 illustrates the identification of objects (human, car) \nand segmentation of their instances by a convolutional network \n\n133 \n \n.  \nFigure 6.7. Identification of objects and segmentation of their \ninstances. (© 123RF) \nThe following Figure 6.8 relates to computational photography \n(Pedone & Heikkilä, 2011). It removes the haze from the original \nphotos above. \n \n \nFigure 6.8. Computational removal of haze in an image. (© \nIEEE) \n© [2011] IEEE. Reprinted, with permission, from [Pedone M & Heikkilä J \n(2011) Robust Airlight Estimation for Haze Removal from a Single Image. \nProc. IEEE Conference on Computer Vision and Pattern Recognition \nWorkshops] \nFigure 6.9 illustrates using a machine learning method to identify \nand locate cars and motorcycles in the image.  \n\n134 \n \n \nFigure 6.9. Object recognition using machine learning. (© \n123RF) \nBackground removal and object tracking play a central role in \nvarious video surveillance applications. Figure 6.10 removes the \nmotionless parts of the background from the video image and \ntracks the paths and activities of those persons who meet each \nother (Takala & Pietikäinen, 2007). However, removing the \nbackground may make it difficult to interpret human-\nenvironment interactions. \n \nFigure 6.10. Background removal and tracking of moving \nobjects. (© IEEE) \n © [2007] IEEE. Reprinted, with permission, from [Takala V & Pietikäinen \nM (2007) Multi-object tracking using color, texture and motion. Proc. IEEE \nConference on Pattern Recognition and Computer Vision] \nBiometric identification is a key area of research in machine \nvision, such as using face and iris (Figure 6.11 on the left). The \nhuman gait style is individual and can be used for biometric \nidentification remotely. It might also be used to assess a person's \nemotional state (Figure 6.11 on the right). \n \n\n135 \n \n \nFigure 6.11. Biometric face recognition (© 123RF) and assess-\nment of emotional state based on walking style. (© CMVS) \nBelow Figure 6.12 uses the distance and color image data gener-\nated by the Google Tango hardware mentioned in Section 6.2 to \ncreate a three-dimensional model of our laboratory space. \n \nFigure 6.12. Created with Google Tango, a 3-D model of our \nresearch unit facilities (© CMVS). \n6.4 \nComputer Vision Changing our Everyday Lives \nUntil recent years, machine vision has been largely in the back-\nground. It has been applied successfully in controlled conditions, \nsuch as visual quality control of industrial products, assembly \nand sorting tasks in industry, reading text from scanned docu-\nments, medical instruments such as cell counting, target detec-\ntion and tracking in military applications, and environmental \nstate analysis from satellite and aerial photographs. In stores, re-\nverse vending machines for recycling cans and bottles have long \nused 3-dimensional machine vision. \nIn recent years, machine vision has become part of our daily \nlives. Biometric identification based on fingerprints, eye iris and \nface is already widely used, for example, at airports and for ac-\ncess control - and increasingly also on smartphones. They often \n\n136 \n \ninclude smile recognition as the first step in recognizing emo-\ntions. Internet searches based on image content have become \nmuch more accurate than before. \nIn order to prevent the growth of crime and terrorism, surveil-\nlance cameras have been installed everywhere in our environ-\nment. More and more efforts are being made to add automatic \ninterpretation, for example, face or even behavioral recognition. \nThe new cars have machine vision based lane guards and traffic \nsign detectors. Machine vision has also been used in art. For ex-\nample, DeepArtEffects software can convert user-uploaded im-\nages to a selected painting style, https://www.deepar-\nteffects.com. \nAs we move through our environment in the near future, \nsmartphones will be able to identify different objects, plants and \nbirds and provide information to the user. While abroad, we are \nable to recognize foreign language text from ads and restaurant \nmenus, as well as view customer reviews of the restaurant in \nquestion. Machine vision plays a key role in automatic shops, as \nalready mentioned in Chapter 1 in relation to the system devel-\noped by Amazon. \nWe will see tremendous progress in technology for people with \ndisabilities. Visually impaired people are able to read magazines \nand other documents. With the help of smart glasses, they are \nable to get information about their environment and even get in-\nformation about the emotional state of their chat partner. \nMachine vision plays a key role in autonomous or semi-autono-\nmous vehicles, which are coming in confined and sufficiently \nsafe environments. In medicine, imaging has come to play a cen-\ntral role in the diagnosis of diseases. Machine vision plays a sig-\nnificant role in helping doctors interpret images. \nThe development of imaging technologies opens up entirely new \npossibilities. For example, it is already possible today, even with \nprinting technology, to make thin multi-lens cameras onto an im-\nage sensor. Figure 6.13 shows an image obtained with a thin \nmulti-lens camera, from which it is also possible to make a three-\ndimensional interpretation based on the partial images. \n \n \n \n \n \n \nFigure 6.13. Picture taken with a lenslet camera. (© Sami Varjo) \n\n137 \n \nIn the future, these kinds of solutions can be embedded in the \nenvironment and, for example, on payment cards and, through \nthem, implement novel human machine interfaces to intelligent \nenvironments with very little energy consumption (Varjo, 2016). \n6.5 \nCenter for Machine Vision and Signal Analysis   \nThe Machine Vision Group of the University of Oulu was \nfounded in late 1981 after Matti Pietikäinen returned from his \nresearch visit to the University of Maryland. Initially, the team's \nresearch was very application-oriented, with a focus on machine \nvision applications in visual quality control and robotics. Quality \ncontrol, in particular, was already a very important field of ap-\nplication at that time, which made it possible to obtain external \nfunding for research. \nSince then, the group's research has expanded and deepened sig-\nnificantly, encompassing both internationally advanced basic re-\nsearch and applied research. The research and activities of the \ngroup for the first 25 years are discussed in the book \"From Al-\ngorithms to Vision Systems - Machine Vision Group 25 Years\" \n(Pietikäinen et al., 2006) and in the annual reports 1997-2015 \n(Pietikäinen et al., 2016). For 2016, see the Annual Report at \nhttp://www.oulu.fi/infotech/annual_report/2016/cmv. So far, \nmachine vision research has led to the establishment of about 25 \nstart-up companies, founded by earlier members of our group, \nand also new research teams have been spun off. \nIn the early 1990s the group returned to the texture analysis re-\nsearch started at the University of Maryland in 1980-81, which \nled to a very significant invention later: the Generalized Local \nBinary Pattern (LBP) and its application in face recognition \n(Chapter 7). In addition to texture and facial analysis (Section \n8.2), the group has conducted world-renowned research in other \nareas, including: three-dimensional computer vision (Section \n8.3), emotion recognition (Chapter 9), biometric identification \n(Section 8.2), intelligent human-machine interfaces (Section \n8.4), industrial visual quality control (Section 8.1), and medical \nimage analysis (Section 8.5). \nThe Center for Machine Vision and Signal Analysis (CMVS), \nwhich began operations in January 2016, combined the Univer-\nsity's strong expertise in machine vision and biosignal analysis. \nIn the Spring 2021 , the Center consisted of four professors (Olli \nSilvén, Guoying Zhao, Janne Heikkilä and Tapio Seppänen), one \nemeritus professor (Matti Pietikäinen), one associate professor \n(Mourad Oussalah) and three tenure track assistant professors \n(Li Liu, Miguel Bordallo Lopez, and Xiaobai Li). About 80% of \nthe unit's staff of over 70 researchers and research assistants are \nfrom abroad. The Center is currently headed by Professor Olli \nSilvén. \n\n138 \n \nThe unit has played a key role in the development of artificial \nintelligence education at the University of Oulu since the 1980s. \nIn the autumn of 2018, a new field of study in Artificial Intelli-\ngence was launched in the Information Technology Degree Pro-\ngram (Appendix L1). \nCMVS's current research can be divided into five areas: \nMultimodal emotional user interfaces: The overall goal of the \nstudy is to bring human-machine interaction closer to human-\nhuman interaction by considering the emotional state. A strong \nfoundation is the group's research on passive imaging-based so-\nlutions, such as micro-expression recognition related to hidden \nemotions, dynamic facial expression and gesture recognition, \nanalysis of physiological signals, and heart rate measurement \nfrom facial videos. Combining multi-modal data, masking a per-\nson’s identity, and solutions that utilize machine learning are \namong ongoing research problems. Potential applications in-\nclude e.g. human well-being monitoring, computer-assisted \nteaching, telemedicine and security technology. \n3-dimensional computer vision: Advanced machine vision sys-\ntems based on deep learning lack an ability to interpret 3-D \nviews like humans do, making them difficult to use in many \npractical applications. The aim of the unit's research is to develop \nmuch more general solutions for the interpretation of 3-D views \nby combining data generated by multiple sensors (e.g. video and \nrange cameras) and using modern machine learning methods to \ncreate a higher level semantic description to facilitate the inter-\npretation of the given views. Potential application areas include \nautonomous robots and vehicles, augmented reality, and inter-\npretation of views captured on mobile devices. The research is \nbased on the group's solid experience in geometric calibration of \ncameras, 3-D reconstruction and machine learning. \nToward resource-efficient AI: Machine learning and statistical \npattern recognition have been part of the unit's machine vision \nresearch since the 1980s. In recent years, deep learning has be-\ncome central, but it has many weaknesses, such as the massive \nneed for training samples, the need for high-performance com-\nputers, vulnerability to hostile attacks, and the inability to justify \nthe reasons for classification decisions. The unit investigates \ncomputationally light, compact, and low-energy image, video, \nand 3-D data representations and classification methods that can \nbe used in, for example, wearable devices, smart glasses, and \nembedded smart sensors. Efforts are being made to overcome the \nweaknesses of deep neural networks with both new representa-\ntion methods and machine learning solutions. \nMedical signal analysis and biometrics: The analysis of vari-\nous physiological signals and biomedical images has been stud-\nied within the CMVS since the 1990s. The research focuses on \nthe analysis of physiological signals in health assessment, the use \n\n139 \n \nof machine learning methods in biomedical applications, remote \npatient monitoring, and solutions related to privacy and infor-\nmation security. Recently, for example, the early detection of \natrial fibrillation by remote measurement from facial videos has \nbeen studied (Section 8.2), as well as advanced brain signal anal-\nysis methods related to Alzheimer’s disease research. Experts in \nboth medicine and life sciences have been partners in the unit's \nresearch. \nEnergy-efficient embedded machine vision systems: CMVS \nhas extensive experience in research and various applications of \nmachine vision technology to support application development. \nThe aim of the current research is to create knowledge for the \ndesign of distributed intelligent sensor systems and very low en-\nergy consumption high-performance computing solutions. The \nfocus will be on the methods and technologies needed for large-\nscale, non-power-consuming sensing interfaces, using optical \ncameras for imaging or, for example, sensors operating on dif-\nferent radio waves. Potential applications include human-ma-\nchine interfaces embedded in the environment and health moni-\ntoring devices. \n6.6 \nReferences \nHerrera Castro D, Kannala J & Heikkilä J (2011) Accurate and \npractical calibration of a depth and color camera pair. In: Com-\nputer Analysis of Images and Patterns, CAIP 2011 Proceedings, \nLecture Notes in Computer Science, 6855:437-445. \nIkeuchi K, ed. (2021) Computer Vision: A Reference Guide, \nSecond Edition. Springer, 1450 p. \nLiu L, Ouyang W, Wang X, Fieguth P, Liu X & Pietikäinen M \n(2020) Deep learning for generic object detection: A survey. In-\nternational Journal of Computer Vision 128: 261-318. \nMarr D (1982) Vision: A Computational Investigation into the \nHuman Representation and Processing of Visual Information. \nSan Francisco: W. H. Freeman and Company. \nPedone M & Heikkilä J (2011) Robust airlight estimation for \nhaze removal from a single image. Proc. CVPR 2011 Work-\nshops, DOI: 10.1109/CVPRW.2011.5981822. \nPietikäinen M (1993) Konenäkö. Tekoälyn ensyklopedia (Ma-\nchine Vision, Encyclopedia of Artificial Intelligence) (eds. Hy-\nvönen E, Karanta I & Syrjänen M), 104-114. \nPietikäinen M, Aikio H & Karppinen K, eds. (2006) From Algo-\nrithms to Vision Systems – Machine Vision Group 25 years. \nUniversity of Oulu, 254 p.  \nPietikäinen M, Heikkilä J, Silvén O et al. (2016) Machine Vision \nGroup – Annual Reports 1997-2015. University of Oulu. \nSauvola J & Pietikäinen M (2000) Adaptive document image bi-\nnarization. Pattern Recognition 33:225-236. \n\n140 \n \nTakala V & Pietikäinen M (2007) Multi-object tracking using \ncolor, texture and motion. Proc. IEEE Conference on Pattern \nRecognition and Computer Vision, 7 p. \nVarjo S (2016) A Direct Microlens Array Imaging System for \nMicroscopy. Acta Univ. Oul. C 588, 2016, 124 p.  \nWiki-Kinect Kinect. \n \n.  \n \n \n \n\n141 \n \n7 Local Binary Pattern – a Breakthrough  \n7.1 \nLocal Binary Pattern Method \nThe main scientific achievement of the research group is the in-\nvention of the Local Binary Pattern (LBP) method based on the \nanalysis of local binary patterns, and the development of its var-\nious variants and applications (Pietikäinen et al., 2011), (Pie-\ntikäinen, 2010). \nOriginally developed for the analysis of the surface textures in \nan image or portions thereof, it later developed into a general-\npurpose method for capturing the content of images and videos \nfor identification. The textures are very diverse, with almost reg-\nular patterns or very irregular surface texture variations. It was \nlater found that the method can also be applied to untraditional \ntextures, such as images of human faces. Figure 7.1 (Liu et al., \n2019) shows examples of images with very different textures. \n \nFigure 7.1. Examples of images with very different textures. (© \nCC BY 4.0) \nFrom [Liu L, Chen J, Fieguth P, Zhao G, Chellappa R & Pietikäinen M (2019) \nFrom BoW to CNN: Two decades of texture representation for texture clas-\nsification. International Journal of Computer Vision 127(1):74-109]. Li-\ncensed under a CC BY 4.0. http://creativecommons.org/licenses/by/4.0/  \nThe original basic LBP shown in Figure 7.2 was created as early \nas 1992-93 by co-operation of David Harwood, a visiting re-\nsearcher from the University of Maryland, Matti Pietikäinen, and \nhis postgraduate student Timo Ojala who is currently a professor. \nAt that time and in the late 1990s LBP did not receive much at-\ntention in the scientific community. \nIn the early 2000s, a theoretical foundation was laid, which in \nturn led to the first real breakthrough (Figure 7.3). LBP was not \nof much interest to many top scientists before it was applied to \nface recognition (2004-2006), which can be used to identify a \nperson's identity, facial expressions, and gender, for example \n(Figure 7.7).  \nThe fourth major step was the generalization of the LBP method \nto video image sequences (Figure 7.6), whereby, for example, \n\n142 \n \nchanging facial expressions or words and phrases spoken in the \nvideo can be recognized from the video images. \nLBP is an excellent example of the importance of long-term, \nwell-focused research. The approach has deviated from the \nmainstream of research, and so it took ten years for the process \nto be truly breakthrough and accepted by the scientific commu-\nnity. Today, this highly cited method and its widespread appli-\ncation in various fields can be considered as one of the greatest \nsuccess stories in Finnish computer science research. \nThe LBP method measures the texture content on the surfaces of \nobjects in an image. The method is computationally simple and \nattractive to use as such. \nAn image converted to grayscale is processed pixel by pixel, for \nexample, from top left to bottom right. For each pixel, its LBP \ncode is computed in a selected size neighborhood, for example \n3x3 or 5x5. Figure 7.2 shows an example of calculating the LBP \ncode in a 3x3 pixel neighborhood (Ojala et al., 1996). \n \nFigure 7.2. Example of calculating LBP code in a  3x3 neighbor-\nhood. (© Springer) \nReprinted, with permission, from Springer [Pietikäinen M, Hadid A, Zhao G \n& Ahonen T (2011) Computer Vision Using Local Binary Patterns] \nIn the left part of the figure, the numbers represent the gray scale, \nwhich is thresholded by the gray level of the center pixel in ques-\ntion (6). Neighbors with a tone greater than or equal to 6 are as-\nsigned a binary value of 1 and smaller values of 0, as shown in \nthe center figure. Each location is assigned a weighting factor of \n1 ... 128 (i.e. 20 ... 27) in a 3x3 environment, as shown at right. \nThis allows the LBP code (241) to be calculated for the middle \npixel under consideration. Using the eight neighbors of the mid-\npoint, there are a total of 256 possible values, i.e., the length of \nthe feature vector is 256. Similarly, the texture contrast (C) or \nstrength (4.7) can be calculated by subtracting the sum of the \nshades of gray of pixels labeled with “0” from those labeled with  \n“1”. \nThis same calculation is done for all pixels in the image or image \narea, for example from left to top to bottom right. By calculating \nthe distribution of the number of times each LBP code occurs in \n\n143 \n \na given region, the so-called LBP histogram is obtained to rep-\nresent the texture of the region in question. When using contrast, \na separate histogram is calculated for it. \nSince then, the method has been improved and generalized. An \nimportant milestone in 2002 was the method published in the \ntop-tier journal of computer vision and artificial intelligence, \nIEEE Transactions on Pattern Analysis and Machine Intelligence \n(PAMI). The computing neighborhood (3x3) was generalized to \narbitrary distance (for example 5x5, 7x7, etc.) and a rotation tol-\nerant version of the method was developed (Ojala et al., 2002). \nIn contrast computing, the aforementioned generalized LBP \nmethod employs a statistical variance of the differences between \nthe selected samples and the gray scale of the center under con-\nsideration. \nFigure 7.3 shows an example in which different number of sam-\nples (P) are taken for the gray scale of an image at different dis-\ntances (R) (Ojala et al., 2002). For each sample whose position \nin the horizontal and vertical directions is not an integer (1, 2, 3, \netc.), a value is calculated by bilinear interpolation of the pixels \nof the original image in the neighborhood in question. As the \nnumber of sample pixels increases, the feature vector becomes \nlonger, for example, in the case of eight neighbors (P), the fea-\nture vector has a length of 256, but with a value of 16, the length \nis already 216, or 65,536. \n \nFigure 7.3. Generalized LBP. (© Springer) \nReprinted, with permission, from Springer [Pietikäinen M, Hadid A, Zhao G \n& Ahonen T (2011) Computer Vision Using Local Binary Patterns] \nHowever, our study found that the vast majority of information \nis in the so-called “uniform patterns”. Therefore, the number of \ncodes generated by the method can be significantly reduced, i.e. \nto shorten the feature vector. This was an important observation, \nfor example, when developing the face recognition method. \nLBP can be interpreted as an operator analyzing the fine struc-\nture of an image, expressing in each pixel a micro-pattern, such \nas point, flat area, end of line, edge or corner (Figure 7.4) (Pie-\ntikäinen et al., 2011). \nThe histogram over the selected region depicts the number of \ntimes each pattern occurs in that region, i.e., gives information \nabout the micro-texture of the region. This is a very simple ver-\nsion of the so-called Bag-of-Words (BoW) representation of the \n\n144 \n \ncontents of an image area where the \"words\" correspond to dif-\nferent LBP codes (patterns) in the histogram. \n \nFigure 7.4. Micro-patterns detected by LBP operator. (© \nSpringer) \nReprinted, with permission, from Springer [Pietikäinen M, Hadid A, Zhao G \n& Ahonen T (2011) Computer Vision Using Local Binary Patterns] \nThe BoW principle has been widely used in computer vision in \na wide variety of problems and applications, especially prior to \nthe current AI using CNN deep neural networks. For a compre-\nhensive overview of the various BoW and CNN methods for rep-\nresenting textures, see (Liu et al., 2019). \nIn Figure 7.5, the LBP method is applied to a face image. The \nvalue of each pixel in the center image has the LBP code calcu-\nlated for it. It can be deduced from the figure that the method is \nquite insensitive to variations in illumination, since the LBP op-\nerator is independent of locally monotonically increasing or de-\ncreasing greyscales. The histogram to the right shows the num-\nber of occurrences of each LBP code over the entire image. \n \n \nFigure 7.5. Application of LBP to a facial image. (© Springer) \nReprinted, with permission, from Springer [Pietikäinen M, Hadid A, Zhao G \n& Ahonen T (2011) Computer Vision Using Local Binary Patterns] \nDue to its computational simplicity, the LBP method is applica-\nble to the real-time analysis and automatic interpretation of many \ntypes of digital image material. Because the operator is inde-\npendent of monotonic (incremental or decremental) shades of \ngray in its computing neighborhood, the method is quite resistant \nto variations in lighting. For these reasons, the method has be-\ncome very widespread in the scientific community and in a wide \nvariety of applications (Pietikäinen et al., 2011). \nA young doctor Guoying Zhao (now a professor) who came to \nOulu from China in 2005, generalized the LBP method for dy-\nnamic textures, enabling the analysis of facial expressions, mov-\n\n145 \n \ning objects and actions (Zhao & Pietikäinen, 2007). A major in-\nnovation in the LBP-TOP method is to do 2-D analysis in three \northogonal planes, one of which corresponds to the normal im-\nage plane (XY) and the two to the place-time planes (XT, YT). \nThe distributions of the different directions are combined to rep-\nresent the dynamic texture as shown in Figure 7.6. \n \nFigure 7.6. LBP-TOP in dynamic texture analysis. (© Guoying \nZhao) \nThis method or its modifications have been extensively used in \nmany problems, such as the recognition of ordinary facial ex-\npressions and micro-expressions (Chapter 9), visual speech anal-\nysis based on mouth movements (Section 8.2), anti-spoofing for \nface recognition (Section 8.2), human action recognition (Sec-\ntion 8.4), and biometric identification based on gait (walking \nstyle) analysis. \n7.2 \nLBP in Face Recognition \nFacial image analysis has been one of the major challenges in \ncomputer vision research in recent years, and our discovery of a \nsuitable method has proven to be a major success (Ahonen et al., \n2004, 2006). Figure 7.7 illustrates the principle of the method \npresented in simplified form. \n \nFigure 7.7. Face analysis with LBP. (© Springer) \nReprinted, with permission, from Springer [Pietikäinen M, Hadid A, Zhao G \n& Ahonen T (2011) Computer Vision Using Local Binary Patterns] \nInitially, the face is located with a face detection method, for ex-\nample (Viola & Jones, 2004), and normalized to the same size \n\n146 \n \nand location by first searching key points, for example, the eyes \nand some other easily identifiable features in the area of the face. \nThe LBP feature image is then calculated on the face area and \nthe feature distributions for each window in the selected grid are \ncalculated. \nThe LBP distribution represents the grayscale variations of the \nface, i.e. the texture, within the window in question. The location \nof the window gives information about the geometry of the face, \ni.e. where there is on the face texture and what kind of texture. \nBy combining the distributions of all the windows into a com-\nmon feature distribution over the entire face area, a LBP repre-\nsentation of the face content is obtained. \nIn the system training step, models are calculated for each indi-\nvidual to be recognized, generally using multiple facial images \nand the resulting feature distributions for each individual. Then, \nto identify who the unknown person is, compare their LBP de-\nscription to the different person models taught and identify who \nit is if they find someone close enough. This case is a so-called \n1:n recognition, that is to say whose face is in question from the \nn persons trained for the system. \nFace authentication, or 1:1 authentication, is intended to verify \nthat the person is one whose model is stored on the device during \nthe training phase. Such a procedure based on the comparison of \nthe described and the stored model is used, for example, to check \nthe passport and identify the user when opening the smartphone. \nThe third main method of face recognition is to use the so-called \nwatch list to find the faces of people searched for in a large da-\ntabase, such as certain criminals. \nIn Section 8.2, the method has been used to detect spoofing at-\ntacks in a biometric identification application. \nLBP and the resulting face recognition method became very pop-\nular in research and industry. References to publications are the \nmost important measure of the scientific impact of research. Pub-\nlications about LBP and the facial recognition method based on \nit are the most cited Finnish publications in the field of artificial \nintelligence in the 21st century. Several leading research groups \nhave developed customized versions of our method. \nAt the European Conference on Computer Vision (ECCV 2014), \nthe first LBP-based face recognition publication (Ahonen et al., \n2004) presented at the same conference ten years earlier, was \nawarded a major award titled Koenderink Prize for Fundamental \nContributions in Computer Vision that has withstood the test of \ntime. \n7.3 \nLBP: Present and Future \nThe above first versions of LBP have shortcomings, and research \nto improve them is still ongoing within the research community. \n\n147 \n \nOne of the biggest problems has been the sensitivity of the \nmethod to noise and other disturbances in the image. The LBP \nmethod has also encountered difficulties in dealing with so-\ncalled macro textures, where the elements of the texture pattern \nare large, several pixels in size. \nPerhaps the best current method is the MRELBP (Median Ro-\nbust Extended LBP), published in 2016, which has operator \ncomputation done in a larger local environment (from 9x9 - \n17x17 pixels) and used to calculate median instead of average in \nlocal sample point neighborhoods (Liu et al., 2016).  \nIn the calculation of the median, the pixels of the selected pixel \nneighborhood are in gray scale order and the middle one is se-\nlected. For example, the gray levels of the pixels in Figure 7.2 \nare (9 8 7 7 6 6 5 2 1) and their median is 6. Most LBP methods \nare such that the determination of a suitable LBP operator and its \ncomputing environment is largely application-specific. \nFigure 7.8 summarizes the evolution of the LBP method over \ntwo decades, including the most well-known LBP variants (Liu \net al., 2019). \nKuva 7.8. Milestones in LBP research. (@ CC BY 4.0) \nReprinted from [Liu L, Chen J, Fieguth P, Zhao G, Chellappa R & Pietikäinen \nM (2019) From BoW to CNN: Two decades of texture representation for tex-\nture classification. International Journal of Computer Vision 127(1):74-109.] \nLicensed under a CC BY 4.0. http://creativecommons.org/licenses/by/4.0/  \nThe use of the LBP method in face recognition has been further \nexplored and very competitive results have been achieved. The \nfocus has been e.g. better utilization of the facial structure and \ndevelopment of methods more tolerant to the effects of illumina-\ntion and other variations than the above-mentioned method - \nwhile still preserving the computational simplicity of the original \nmethod. These new LBP methods are best suited for applications \nthat require simple implementation and low power consumption, \nand massive amounts of training samples are not available. \n\n148 \n \nHowever, methods based on sophisticated face positioning tech-\nniques, CNN neural networks, and enormous training material \nhave been at the forefront of the latest breakthroughs in face \nrecognition in natural environments (“in-the-wild”). Perhaps the \nmost well-known example is DeepFace, developed by Facebook, \nwhich has used a three-dimensional face alignment method and \na nine-layer neural network with 120 million weight factors \n(Taigman et al., 2014). Four million photos of Facebook users \nhave been used for training. Another very significant develop-\nment is the Google’s FaceNet, which directly learns description \nof faces in a compact, so-called Euclidean space, where dis-\ntances correspond directly to a measure of the similarity of faces \nto be compared (Schroff et al., 2015). \nConvolution-based operators have been used for years in texture \nanalysis, including their application in face analysis. In this con-\ntext, much of the recent use of the word \"handcrafted\" can be \ncriticized because convolution-type filters, such as Gabor filters, \nfound in the human visual system are often imitated in operator \ndesign. The operation of the LBP operator can also be seen as a \ncombination of simple convolutions. For these reasons, the \nlearning convolutional neural networks (CNN) presented in \nChapter 4 can also be considered as texture methods (Liu et al., \n2019). \nUnlike basic LBP, CNN methods also perform very well in \nmacro-textures with large variations. They are also able to learn \ndirectly from the training data a multi-scale representation, and \nenable them to learn the entire computing chain from convolu-\ntional filters to classification. The major problems for the appli-\ncations are computational complexity, which requires special \nprocessors capable for high-performance computing, and the \nneed for a very large number of training samples. \nIn our extensive comparisons, we also found that CNN-based \nmethods are less resistant to noise, image blur, and small varia-\ntions in viewing direction than the best modern LBP methods, \nespecially the MRLBP operator (Liu et al., 2017).  For these rea-\nsons, the applicability of CNN methods in most texture analysis \napplications is still very limited. In contrast, LBP operators are \nused in a very wide variety of applications. \nAmong the major challenges of coming years  is to combine the \nbest properties of LBP-type and CNN-based solutions, such as \n1. compactness and computational lightness, allowing methods \nto be used in low power systems such as smartphones, smart \nglasses and clocks, embedded devices \n2. tolerance to various image transformations and disturbances  \n3. ability to recognize macro textures and textures with large \nvariations in appearance \n4. ability to learn from data multiple-scale image representa-\ntions \n\n149 \n \n5. ability to learn like a human with a small amount of training \ndata \nThe research community has already begun to tackle these prob-\nlems, and a number of related publications have already been \npublished. Our team has been active in promoting research in \nthis field in the scientific community by organizing workshops \nat the conferences and by providing special issues to IEEE \nTransactions on Pattern Analysis and Machine Intelligence and \nthe International Journal of Computer Vision. \n7.4 \nReferences \nAhonen T, Hadid A & Pietikäinen M (2004) Face recognition \nwith local binary patterns. Computer Vision, ECCV 2004 Pro-\nceedings, Lecture Notes in Computer Science, Springer, \n3021:469-481. \nAhonen T, Hadid A & Pietikäinen M (2006) Face description \nwith local binary patterns: Application to face recognition. IEEE \nTransactions on Pattern Analysis and Machine Intelligence \n28(12):2037-2041. \nLiu L, Chen J, Fieguth P, Zhao G, Chellappa R & Pietikäinen M \n(2019) From BoW to CNN: Two decades of texture representa-\ntion for texture classification. International Journal of Computer \nVision 127(1):74-109.  \nLiu L, Fieguth P, Guo Y, Wang X & Pietikäinen M (2017) Local \nbinary features for texture classification: Taxonomy and experi-\nmental study. Pattern Recognition 62:135-160.  \nLiu L, Lao S, Fieguth P, Guo Y, Wang X. & Pietikäinen, M. \n(2016) Median robust extended local binary pattern for texture \nclassification. IEEE Transactions on Image Processing \n25(3):1368-1381. \nOjala T, Pietikäinen M & Harwood D (1996) A comparative \nstudy of texture measures with classification based on feature \ndistributions. Pattern Recognition 29(1):51-59. \nOjala T, Pietikäinen M & Mäenpää T (2002) Multiresolution \ngray-scale and rotation invariant texture classification with Lo-\ncal Binary Patterns. IEEE Transactions on Pattern Analysis and \nMachine Intelligence 24(7):971-987. \nPietikäinen M (2010) Local binary patterns. Scholarpedia \n5(3):9775.  \nPietikäinen M, Hadid A, Zhao G & Ahonen T (2011) Computer \nVision Using Local Binary Patterns, Springer, 207 p.   \nSchroff F, Kalenichenko D & Philbin J (2015) FaceNet: A uni-\nfied embedding for face recognition and clustering. arXiv: \n1503.03832v3. \nTaigman Y, Yang M, Ranzato MA & Wolf L (2014) DeepFace: \nClosing the gap to human-level performance in face verification. \n\n150 \n \nProc. IEEE Conference on Computer Vision and Pattern Recog-\nnition (CVPR). \nViola P & Jones M (2004) Robust real-time face detection, In-\nternational Journal on Computer Vision 57(2): 137-154. \nZhao G & Pietikäinen M (2007) Dynamic texture recognition \nusing local binary patterns with an application to facial expres-\nsions. IEEE Transactions on Pattern Analysis and Machine In-\ntelligence 29(6):915-928. \n \n \n\n151 \n \n8 Towards Machine Vision Applications \nApplied research on computer vision  has gone hand in hand with \nadvances in methodology and hardware. In the 1980s, the em-\nphasis was on problems where the imaging conditions could be \ncontrolled, such as lighting and camera location to be kept con-\nstant. Because of the low computing capacity of computers, ma-\nchine vision methods had to be computationally simple enough \nto access real-time operations. In our own group, in the 1980s, \nwe focused on visual quality control of industrial products, as it \nhad a large number of applications in Finnish industry and thus \nmade it possible to obtain external funding for research (Section \n8.1). \nIn the 1990s, methodological research and equipment had \nevolved so much that research began to focus on consumer-ori-\nented applications, where people are often at the center, that is, \nthe need to detect and identify people and their activities through \nimages. The operating environment is changing and often re-\nquires analysis of video sequences rather than single images. The \nfocus of the study was on facial image analysis: first, face detec-\ntion based on skin color and, in the 2000s, facial recognition \n(Sections 7.2 and 8.2). \nBiometric identification is a very important application, and our \nrelated research started as part of two large-scale European re-\nsearch projects. Later in the 2000s, research expanded to recog-\nnize facial expressions and emotions (Chapter 9) and speech \nrecognition from mouth movements (Section 8.2). In face anal-\nysis, a study on heart rate measurement from videos was started \nin the 2010s (Section 8.2) \nOur research into 3-D machine vision also began in the 1990s. \nThe first milestone achieved was a method and tool for geomet-\nric calibration of the camera, receiving many citations and prac-\ntical applications (Section 8.3). More recently, techniques re-\nlated to 3-D modeling of the environment and methods to sup-\nport augmented reality applications have been studied. \nOur research into intelligent robots began in the 1980s (Section \n8.4). Typical for applications is the three-dimensional infor-\nmation needed to analyze the robot environment, which can be \nobtained, e.g., by stereo vision systems, or 3-D cameras that pro-\nvide direct distance information. In the 1990s, a major focus in \nour research was the so-called Machine of the Future project, \nwith an application of a paper roll manipulator operating in a \nharbor environment.  \nIn the 2000s, our research focused on the use of machine percep-\ntion and machine vision methods in the control of moving robots. \nA demonstration system called Minotaurus was developed to op-\n\n152 \n \nerate a robot working in the laboratory environment.  In this con-\ntext, a study of human-robot / machine interaction based on the \nuse of machine perception information was also initiated. \nMedical image analysis research began in the Machine Vision \nGroup in the 1990s, dealing, e.g., with magnetic resonance im-\naging (MRI) in surgery and analysis of skin images to identify \nmelanoma. In the 2000s,  use of functional MRI (fMRI) in brain \nimaging began to be explored. In recent years, major subjects \nhave included the analysis of many types of microscope images \nand videos, chest X-ray, and fundus images (Section 8.5). \n8.1 \nVisual Quality Control \nIndustrial and machine automation has been one of the most sig-\nnificant applications of machine vision since the 1970s. Visual \nquality control and sorting play an important role in applications \nin the electronics, metal, wood processing and food industries, \nfor example. With automatic inspection it is possible to achieve \nbetter product quality and lower production costs. The machine \nis capable of performing visual inspection without tiring or tak-\ning breaks. Inspection and quality classification of wood sur-\nfaces and inspection of metal surfaces in industry are examples \nof key Finnish applications. \nVisual quality control of industrial products was the most im-\nportant application of machine vision in the 1980s. In Oulu we \ninitially invested in the inspection of printed circuit boards and \nmetal surfaces, but later the inspection of lumber became a key \nissue. In connection with the inspection of printed circuit boards, \nOlli Silvén, M.Sc. (who became later a professor), developed in \nhis Ph.D. thesis a novel approach that compared the data meas-\nured from an image with the CAD model used to design that \nboard, and recognized deviations from the model (e.g. breaks or \ntoo broad  conducting wires)  (Silvén et al., 1989). The approach \nwas ahead of its time and did not lead to industrial exploitation \nat that stage. In connection with the inspection of metal surfaces, \nwe investigated real-time defects detection from a moving metal \nstrip in steel manufacturing (Piironen et al., 1990). \nLumber quality grading is a significant application where the use \nof image color and texture information clearly increases accu-\nracy and product value (Silvén et al., 2003). Typical defects to \nbe sought are knots, but the material may have only blue-tinged \nand spotty discoloration, as well as fully wood-colored knots, \nwhich can only be distinguished by their grain pattern. \nThe example in Figure 8.1 illustrates how faults in the same clas-\nses may vary greatly in appearance (Pietikäinen & Silvén, 2002). \nThe so-called sound knot is firmly fixed to its surroundings and \nthe dead knot is not. With the help of color and texture features \nand the developed unsupervised classification method, the rela-\n\n153 \n \ntive proportions of undetected faults and false alarms were re-\nduced to less than 5%, which was less than half of the usual in-\ndustrial level. The developed methodology was also applied to \nother industrial applications, e.g., sorting coffee beans. \n \n \n \n \n \n \n \n Figure 8.1. Variations in two different types of knots. \n8.1.1 Training surface inspection \nThere are two basic problems with surface quality checks: a dis-\ntinction must be made between defects and defective areas, and \nthen defects found must be classified for quality purposes. For \nexample, defects in the steel surface must be able to be catego-\nrized at least into 2-D and 3-D categories, and the lumber inspec-\ntion must be able to categorize the knots into different classes. \nIn many quality control tasks, there are even dozens of fault clas-\nses, and distinguishing them from one another requires even hu-\nman sophistication. Often there are deviations from the ideal \nquality on the surface, but only cases that violate the given crite-\nria are to be interpreted as defects. \nDefect detection and imaging solutions for inspection equipment \nare generally designed according to the typical failure character-\nistics of each application. On this basis, the system can be trained \nfor defect detection and recognition. For example, the appear-\nance of sawn timber depends on the site and the quality control \nequipment must be adapted to these natural changes. \nTraditionally, pattern recognition systems are trained through \nhuman-selected samples of defects and flawless material as \nshown in Figure 8.2 (Pietikäinen & Silvén, 2002).  \n \nFigure 8.2. Training of classifier with human classified samples. \n\n154 \n \nHowever, human selection is prone to error, so many of the sam-\nples are labeled incorrectly. In addition, exhibiting the training \nwith samples is laborious and the training has to be repeated as \nthe appearance of the material varies. This procedure is therefore \nrare in industrial systems. \nTypically, industrial quality control systems are not really \ntrained, but the classification parameters used by them are ad-\njusted based on the result of the inspection. Figure 8.3 illustrates \nthis principle, which addresses the function of a rule-based clas-\nsifier. The problem is that the adjuster has to be familiar with the \nclassifier's solutions, because the parameters do not always have \nan easily understood connection with the test result. \n \n \n \n \n \n \n \nFigure 8.3. Rule-based classifier tuning by adjusting parameters. \nThe third option is the use of unsupervised training, whereby in-\ndividual samples need not be named. The idea is to cluster sam-\nples isolated from the teaching material and visualize the result-\ning groups to the operator of the inspection system to determine \nclass boundaries, as shown by the diagram in Figure 8.4. \n \n \n \n \n \n \n \n \n \nFigure 8.4.  Training based on visualized clustering. \n8.1.2 Focus on visualization \nFor example, a self-organizing map can be used for visualiza-\ntion. Re-training is easy, as is changing class boundaries. This \nsolution has been found to significantly improve the accuracy of \nsawn lumber and steel inspection. \nFigure 8.5 shows a grouping of different types of knots using a \nself-organizing SOM map developed by late Professor Teuvo \nKohonen (Niskanen, 2003), (Kohonen, 2001). The solution laid \nthe foundations for systems of leading wood surface inspection \nrule-based    clas-\nsifier \nparameter \nadjustment \nperceived flaws \nfects \nclassified \nmaterial \n detected \nflaws \nfeature \nextraction \nunsupervised  \nclustering and   \nvisualization of \nsamples \n  \n material to be \ninspected \nnaming sample  \ngroups \nobservations \nfrom sample \ngroupings \nryhmittymisestä \nclassified \nmaterial \nfeature ex-\ntraction \n\n155 \n \nequipment developers and has worked well for Nordic wood spe-\ncies. Thus, the interest of Finnish system suppliers focused on \nmachine vision based wood strength assessment techniques, for \nwhich our group has also developed new solutions (Hietaniemi \net al., 2014). \n \n \n \n \n \n \n \nFigure 8.5. Grouping of knots with the SOM method. (© Acta \nUniv. Oul.) \nNiskanen M (2003) A Visual Training Based Approach to Surface Inspection. \nActa Univ. Oul. C 186, 125 p. http://jultika.oulu.fi/files/isbn9514270673.pdf \nHowever, our recent collaboration with Brazilian scientists has \nshown that wood species in the south are different from those in \nthe Nordic countries, sawmills handle more species and contain \nmore habitat variations, which means that the SOM-based solu-\ntion does not work. \nTherefore, the selection of training samples must be made \nsmarter and adequately matched to the wood material to be \ntaught with a smaller number of training samples. Deep neural \nnetworks are clearly not suited to this problem as such. Partially \nsupervised and active learning methods seem to be a good start-\ning point. Newer tools, better than SOM, must be used to group \nand visualize non-linear unbalanced data (see Chapter 3) \n8.2 \nFace Analysis and Biometric Identification  \nFace recognition and analysis is one of the most important abil-\nities of a person in everyday life. Face analysis is used for differ-\nent tasks. We can recognize other people in their faces, whether \nthey are old or young, male or female, European or Asian. We \ncan also see from the face whether a person is happy or sad, tired \nor nervous, whether he or she is speaking true or possibly lying. \nFaces are very important in social communication between peo-\nple. Emotional expressions communicate both emotional state \nand intentions related to behavior. Mouth movements are im-\nportant clues in recognizing speech in distracted conditions and \nhearing impaired people can even read from lips. The position of \nthe head and the direction of the gaze tell what the person is pay-\ning attention to at each moment. \n\n156 \n \nFaces also tell about human health. For example, people with \nautism have difficulty understanding and expressing emotions, \nor pain can often be recognized by facial expressions. Facial in-\nformation can also be used to find information that cannot be \nseen by humans, such as involuntary, very rapid micro-expres-\nsions and the measurement of heart rate from color video based \non small variations in the color of the face. \nOur own research on facial analysis began as early as the late \n1990s. The first step in face analysis is usually so-called face \ndetection, that is, to first find where in the image there is a face \nor faces. Thereafter, the processing can be applied to that image \narea and, for example, attempt to identify that person. \nWe developed a method for detecting skin pixels from a video \nimage, using so-called skin locus. The solution takes advantage \nof the knowledge that the pixels on the skin are close to each \nother in a suitable color coordinate system. For this and other \nfacial analysis research, we collected a Physics-based Face Da-\ntabase of 111 individuals under different lighting conditions. \nThis database has since been used by numerous research groups \naround the world. \nThe actual breakthrough was presented in the previous section, \ni.e. an LBP-based method for facial representation and its appli-\ncations to various problems, such face recognition, face detec-\ntion, facial expression recognition, gender identification,  age es-\ntimation, identification of spoken phrases from mouth move-\nments, face anti-spoofing, and micro-expression recognition. \nThe following describes the application of the LBP method for \nfraud prevention (anti-spoofing) in biometric identification. In \naddition, we look at heart rate measurements from facial color \nvariations, face analysis in human-machine interfaces, and visual \nspeech recognition from mouth movements. Identification of mi-\ncro-expressions by the LBP method is discussed in Chapter 9. \n8.2.1 Biometric identification and spoofing prevention \nBiometric identity verification and recognition  are important ap-\nplications in artificial intelligence. Verification or authentication \nrefers to whether the person in question is who he or she claims \nto be. Recognition means who or if any of the many individuals \nstored in the database are concerned. We want to get rid of user \nnames and hard-to-remember codes. \nBiometric identification offers solutions to this. Identification \nusing physical properties may be based, for example, on a per-\nson's face, iris, fingerprints, blood vessels, or DNA. Person-\nbased behavioral solutions use, for example, a person's way of \ninteracting with a device, voice, or walking style (gait). \nPeople recognize each other mainly on the basis of their faces. \nIndeed, face recognition is the most natural and widely used \n\n157 \n \nmethod for biometric authentication and identification, for ex-\nample in checking passports at airports or controlling access to \nconfined spaces or computers. In recent years, it has proven to \nbe a major problem, both in face recognition and in other solu-\ntions, that biometric systems can be fooled in different ways. \nFace recognition can be spoofed by showing to the system other \npeople's pictures, video clips, or natural-looking masks. Figure \n8.6 shows examples of the use of a photograph and a mask to \ngain unauthorized access to our group's research laboratory. A \nvideo demonstration of presentation attack detection is available \n(Web-Antispoofing). \n \nFigure 8.6. Cheating on identity verification. (© CMVS) \nIn 2011, we introduced an LBP-based solution for blocking face-\nbased spoofing attempts. The rationale for this solution is that \nthe faces captured by the camera are images of three-dimen-\nsional subjects, whereas photographs are two-dimensional sub-\njects. The photo used for the scam features glosses, variations in \nthe texture of the image, etc., which are not seen directly in the \nface. Figure 8.7 shows our original method (Määttä et al., 2011).  \n \nFigure  8.7. Spoofing detection with LBP method. (© IEEE)  \n© [2011] IEEE. Reprinted, with permission, from [Määttä J, Hadid A & Pie-\ntikäinen M (2011) Face spoofing detection from single images using micro-\ntexture analysis. Proc. International Joint Conference on Biometrics] \n\n158 \n \nThe facial image under consideration is processed by LBP oper-\nators using different scaling and sampling modes, and their fea-\nture distributions are then combined. The system is taught be-\nforehand with samples of true and false faces. The recognition \nuses a Support Vector Machine (SVM) to determine whether it \nis a true or a false face. \nThe method proved to be a major breakthrough. Several other \nresearch groups began to apply modifications to the aforemen-\ntioned LBP method for both fraud prevention in photographs and \nvideo. Our publications presenting the method received two \nawards: the IET Biometrics Premium Award 2013 (Määttä et al., \n2012) and the BTAS 2016 Five Year Highest Impact Award \n(Määttä et al., 2011). The method we have presented also moti-\nvated the use of LBP for anti-spoofing in connection with other \nbiometric identifiers such as eye iris, fingerprints, gait, and even \naudio speech. \nThe use of masks has proven to be a very difficult problem, and \nthe previous solutions suitable  for photos and videos are not suf-\nficient. For this problem, in 2016, we presented a method based \non the application of a method based on applying the heart rate \nmeasurement method to be described below. A heart rate pulse \ncan be detected from the real color variations of the face, but it \ncannot be detected through masks (Li et al., 2016). \n8.2.2 Detection of heart rate from face video \nTraditionally, heart rate measurement requires devices that come \ninto contact with a person. When measuring the cardiac electrical \ncurve, electrodes, usually ten, are attached to human skin to help \nmeasure electrical potentials produced by the heart. Heart rate \ncan be measured with sensors mounted on the chest or other parts \nof the body such as the wrist, finger or earlobe. \nThe interest in measuring heart rate remotely using a video cam-\nera started in the research community around 2010. The motiva-\ntion was to develop a device that allows people to conveniently \nsee their heart rate at home from the “health mirror” alongside \ntheir daily routine or, for example, when working at a terminal. \nThe first solutions were based on detecting very slight color var-\niations of the face or on muscle movements (Li et al., 2014). The \nmethods are based on the fact that the heart pumps blood at a rate \nof heart rate to the head, causing minor color changes and muscle \nmovements on the face. A similar principle can also be applied \nto measure the respiratory rate through small color changes \ncaused by variations in blood oxygen levels. \nThe problem with these solutions was that the methods devel-\noped worked well only under near ideal conditions. The illumi-\nnation variations and the subject's movements hampered the \nmeasurement. \n\n159 \n \nIn 2014, we introduced at the IEEE Conference on Pattern \nRecognition and Computer Vision (CVPR), the leading com-\nputer vision conference, a method based on detecting tiny color \nchanges which largely eliminated the shortcomings of the earlier \nattempts and was thus much closer to practical applications (Li \net al., 2014). The principle of the method is shown in Figure 8.8. \nInitially, in step 1, the Viola-Jones face detection method finds a \nface in the video image of a face (the area with yellow box). \nThere are 66 landmarks highlighted in red, nine of which are \nused to find a region of interest (ROI) colored in blue. The area \nis well suited for detecting minor color variations. As faces \nmove, landmarks are followed to monitor changes in the area of \ninterest. \nThe RGB (Red-Green-Blue) camera's green channel is used to \ndetect color changes, as it was found to be the best for this pur-\npose in experiments. Step 2 compensates for ambient light vari-\nations by comparing face color variations with average back-\nground color variations. In step 3, elastic movements within the \nregion of interest, such as those caused by changes in facial ex-\npressions, are eliminated. In step 4,  e.g., the frequencies outside \nthe normal heart rate range are filtered out from the signal (in our \nsystem, the heart rate is assumed to be between 42 and 240 beats \nper minute). The heart rate value is obtained by calculating the \nso-called power spectrum of the signal using Fourier transform. \nIn the example of Figure 8.8, the heart rate is 67.2 beats per mi-\nnute (Li et al., 2014). \n \nFigure 8.8. Heart rate measurement from face video. (© IEEE) \n© [2014] IEEE. Reprinted, with permission, from [Li X, Chen J, Zhao G & \nPietikäinen M (2014) Remote heart rate measurement from face videos under \nrealistic situations. Proc. IEEE Conference on Computer Vision and Pattern \nRecognition] \n\n160 \n \nThe developed method worked better in the tests performed than \nthe corresponding previous methods. This was particularly no-\nticeable with the use of the multimodal MAHNOB-HCI data-\nbase, images under conditions of varying ambient lighting and \nsome movement of the faces of the subjects. \nThe performance of the reference methods collapsed, but our \nown method still worked quite well. We also conducted interest-\ning experiments for future applications, where we monitored the \nheart rate change of a test person playing a game on a tablet com-\nputer and compared the result with the estimates of a commercial \nheart rate monitor. \nIn addition to the aforementioned face mask scam prevention \nmethod, our unit is investigating the use of our method in tele-\nmedicine, with an area of application in early detection of atrial \nfibrillation. For this study, the Oulu Bio-Face Test Database \n(OBF Database) has been collected in collaboration with experts \nfrom the University of Oulu’s Medical Research Center and \nOulu University Hospital (Figure 8.9) (Li et al., 2018). \n \nKuva 8.9. Collection of OBF test database. (© IEEE) \n© [2018] IEEE. Reprinted, with permission, from [Li X, Alikhani I, Shi J, \nSeppänen T, Junttila J, Majamaa-Voltti K, Tulppo M & Zhao G (2018)The \nOBF database: A large face video database for remote physiological signal \nmeasurement and for Atrial Fibrillation detection. Proc. IEEE International \nConference on Face and Gesture] \nFrom videos we are interested in measuring the heart rate (HR), \nheart rate variations (HRV), and respiratory rate (HF) of the sub-\njects images (Li et al., 2018). In addition, reference measure-\nments of these physiological signals have been made by conven-\ntional methods. Preliminary tests have shown promising results \non video with measured HRV features - for the first time in the \nworld. The above physiological signals are also important in an-\nalyzing the human emotional state. Emotional intelligence is dis-\ncussed in Chapter 9. \n8.2.3 Face analysis in human-machine interfaces \nIn Figure 8.10, face analysis methods have been applied to the \nreal-time human-machine interface developed by us (with Jukka \n\n161 \n \nHolappa as the lead implementer). The system recognizes per-\nsons and their gender by the LBP method. \n \nFigure 8.10. Facial analysis for human-machine interface. \nIn the picture, the machine is 94.6% sure a male is in the view. \nHis heart rate is 63 beats per second, and the expressions de-\ntected from the movements of the landmarks on his face reveal \nthat he has a neutral mind. \nThe system has been in continuous operation in the entry lobby \nof the research group, and was presented at various exhibitions \nand during so-called Abi-days for high-school students of North-\nern Finland. A real-time demonstration of the system being ap-\nplied to Donald Trump and Hillary Clinton's election debate \nvideo can be found in the reference (Web-TrumpClinton). \nThe use of face analysis in smart glasses is also an interesting \napplication. For example, a doctor could use facial information \nto aid in the diagnosis. Devices for aiding blind and other visu-\nally impaired people is another major application area. Intelli-\ngent glasses can be used to identify nearby people and gain in-\nsight into their emotions (Section 9.3). In Figure 8.11, the user \n(Jukka Holappa) wears Vuzix M100 smart glasses and is shown \na measured facial view of what he sees.These glasses feature an \nAndroid operating system familiar to smartphones, a 1.2-giga-\nhertz processor, a camera, a microphone, a speaker, a display, \nand a gesture interface. We implemented in the device the basic \noperations of facial image analysis, including face detection, \ntracking of a moving face, face recognition, gender identifica-\ntion, facial landmark detection, and facial expression recogni-\ntion.  \nAll computing was done on the smart glass's own processor, \nwithout wirelessly transferring images to external devices. Low \nimage resolution achieved real-time operation, but due to the \nhigh CPU usage, the battery lasted only about an hour. This \n\n162 \n \ndemonstrates the importance of developing machine vision or \nother methods of low power consumption in portable devices. \n \nFigure 8.11. Face analysis with smart glasses. (© CMVS) \n8.2.4 Visual speech recognition from mouth movements \nHuman speech can also be read from the movements of the \nmouth and lips. This is often referred to as lip reading. For those \nwho are hearing impaired, reading from the lips is a very im-\nportant skill, and even under very disturbing conditions, it can \nimprove audio-only recognition. \nIn the renowned science fiction novel and movie “2001: A Space \nOdyssey”,  the HAL 9000 robot was able to read from the lips of \npeople on a spaceship. This subject has also been studied in com-\nputer vision. Initially, the goal has been to identify individual \nwords or phrases. \nMotivated by the excellent success of LBP-based face recogni-\ntion, in 2006 we began to investigate visual speech recognition \nby applying the LBP-TOP method developed at that time to this \nproblem. Figure 8.12 is a block diagram of our first system (Zhao \net al., 2009). \n \nFigure 8.12. Visual speech recognition with LBP method. (© \nIEEE)  \n© [2009] IEEE. Reprinted, with permission, from [Zhao G, Barnard M & \nPietikäinen M (2009) Lipreading with local spatiotemporal descriptors. IEEE \nTransactions on Multimedia] \n\n163 \n \nAt first, the face is detected in the image and then the eyes in the \nface. Using this information, it is estimated where the mouth is \nlocated, assuming a close-up front view of the face. From the \nmouth area, the LBP-TOP feature distribution is calculated from \nthe selected length of speech, Figure 8.13. \nFigure 8.13. Description of mouth movements with the LBP-TOP \nmethod. (© IEEE)  \n© [2009] IEEE. Reprinted, with permission, from [Zhao G, Barnard M & \nPietikäinen M (2009) Lipreading with local spatiotemporal descriptors. IEEE \nTransactions on Multimedia] \nThe system is taught by phrases spoken by multiple speakers, for \nexample, our original OuluVS database had a total of 817 video \nclips out of the phrases in Table 8.1, with 20 speakers pronounc-\ning them one to five times. \nTable 8.1. Phrases to be recognized (© IEEE) \n © [2009] IEEE. Reprinted, with permission, from [Zhao G, Barnard M & \nPietikäinen M (2009) Lipreading with local spatiotemporal descriptors. IEEE \nTransactions on Multimedia] \nC1 \n“Excuse me” \nC6 \n“See you” \nC2 \n“Good bye” \nC7 \n“I am sorry” \nC3 \n“Hello” \nC8 \n“Thank you” \nC4 \n“How are you” \nC9 \n“Have a good time” \nC5 \n“Nice to meet you” \nC10 \n“You are welcome” \nThe original method achieved 60% recognition accuracy with \nthis database (Zhao et al., 2009). Later, it was investigated how \nspeech variations between phrase lengths and between different \nspeakers can be better unified, resulting in more than 20% better \nresults for this database and the best results published by then for \nother test databases. The results of our study were published in \n2014 in the top-tier journal IEEE Transactions on Pattern Anal-\nysis and Machine Intelligence (Zhou et al., 2014). \nRecently, motivated by deep learning research, recognition of \ncomplete sentences has been successful, for example through \ncollaboration between Oxford University and Google Deep-\n\n164 \n \nMind. One of the reasons for this success is that, due to a signif-\nicant improvement in the accuracy of speech recognition, the \nmassive collection of training material from mouth movements \nis straightforward from video footage of audiovisual faces. \nTraining end-to-end phrases in the same way as in acoustic \nspeech recognition (see Chapter 5) has also greatly helped (Fer-\nnandez-Lopez & Sukno, 2018). However, there is still a long \nway to recognize continuous speech from mouth movements. \n8.3 \n3-D Computer Vision and Augmented Reality \nMuch of the computer vision research has focused on analyzing \ntwo-dimensional images. However, we live in a three-dimen-\nsional world. Thus, machine vision must be able to analyze and \ninterpret three-dimensional information: how far the obstacles \nare from a moving robot, what is the robot's location on the map, \nhow to recognize objects from different angles, what is the three-\ndimensional structure of the object or environment.  \nAugmented reality represents real and artificial objects in the \nsame 3-D environment. Wearable computers, such as smart \nglasses, have created a great need for such technology. \nOur 3-D computer vision research began in the 1990s and was \nhighlighted by the development of a new method and Matlab tool \nfor precise geometric calibration of the camera. One of the most \nimportant subjects of the research led by Professor Janne Heik-\nkilä is  precise location of the user in relation to the operating \nenvironment. Other key research problems include estimating \nthe structure of the 3-D view and creating a dense 3-D model \nusing multiple images. \n8.3.1 Camera calibration \nGeometry plays an important role in machine vision. The laws \nof geometry and optics determine how a three-dimensional en-\nvironment is mapped to a camera's two-dimensional sensor. Un-\nderstanding imaging geometry is thus important in developing \nimage analysis methods. Geometric camera calibration is im-\nportant because it is a prerequisite for accurate 3-D image meas-\nurements. \nCalibration eliminates lens distortion in the image and provides \na geometric match between the environment and the image (Fig-\nure 8.14). For this purpose, our group developed a highly precise \ncamera calibration method and implemented a tool freely avail-\nable on the Internet (Heikkilä & Silvén, 1997), (Heikkilä, 2000). \nThe method has been widely cited and used by both the research \ncommunity and industry. \nThe general principle is that the camera to be calibrated takes \nimages from a test pattern or object whose pattern positions are \nwell known. The information obtained can be used to determine \n\n165 \n \na method that corrects geometric distortion in each pixel of an \nimage. \n \n \n \n \nFigure 8.14. Geometric camera calibration. (© Janne Heikkilä) \nLater, the group developed other new and widely used methods \nfor calibrating cameras, the best known example being the \nmethod for calibrating a three-dimensional Kinect camera (Her-\nrera et al., 2012). Kinect became known as the game controller \nfor Microsoft's Xbox 360 system, and since then it and its later \nversions have been widely used in 3-D machine vision research. \n8.3.2 Creating a 3-D model \nCreating a three-dimensional model of multiple-camera images \nor a moving-camera image sequence has been one of the major \nproblems with 3-D computer vision. Figure 8.15 takes standard \nimages of the subject from different viewing points and creates \na three-dimensional model of the subject using multi-camera ste-\nreo techniques (Ylimäki et al., 2015). \nA well-known example using this type of technology is the pub-\nlication “Building Rome in one day”. It describes how to create \na three-dimensional model of a city in a single day, with the help \nof numerous photographs taken by travelers from different loca-\ntions. \n \n \n \n \n \n \n \nFigure 8.15. Creating a 3-D model using the multi-camera stereo \nmethod. (© Janne Heikkilä) \nimage rectifi-\ncation \nparameter \nestimation \n\n166 \n \nBy searching for similar features in sequential images of a video \nsequence, it is also possible to create a three-dimensional model \nof the subject to be imaged, referred to herein as \"structure from \nmotion\". However, using similar points, it is not possible to get \na dense 3-D model, but a sparse model. \nOne of Professor Heikkilä's recent research interests has been the  \nuse of a sparse model produced by a moving camcorder and a \ndistance-based range camera to create an accurate 3-D model. \nAn example of using Google's Tango system for this was shown \nin Figure 6.12. \nIn addition to the traditional geometric machine vision, methods \nbased on deep learning have recently been introduced for deter-\nmining the position of  the camera and for 3-D reconstruction. A \nkey benefit is their greater reliability in situations where the view \nhas little point-to-point correspondences as required by conven-\ntional methods. These new types of methods are also actively \nexplored in our unit. \n8.3.3 Towards augmented reality applications \nAugmented reality is a significant application area for 3-D vi-\nsion. Figure 8.16 shows an example of adding textual infor-\nmation about the environment the viewer sees in the scene cap-\ntured by the camcorder. \nAugmented reality combines artificial, or virtual, reality with a \nreal-life camera view. Our  team has in recent years focused on \n3-D machine vision techniques that provide even better features \nfor augmented reality applications. \nA well-known example of augmented reality is Pokemon Go. \nHowever, so far, application development in games has been \nlimited by the lack of user experience and the limitations of dis-\nplay technology. \n \nFigure 8.16. An example of augmented reality. (© 123RF) \n\n167 \n \nThe HoloLens glasses introduced by Microsoft are a new step \nforward, enabling the inclusion of three-dimensional holograms \nin the user's field of vision. According to Janne Heikkilä, such \ntechnology can be utilized in, for example, maintenance. If there \nis an exact three-dimensional model of the item being serviced, \nsuch as a building, the location of the hidden structures, such as \npipes or wires, can be visualized by the repairman. \nAs another augmented reality application in the near future, he \nmentions in-vehicle aids for adding virtual objects to the wind-\nshield, such as signage and weather or driving information. \n8.4 \nMachine Perception in Human-robot Interaction \nIn robotics, computer vision can be applied to various materials \nhandling, sorting and assembly tasks, for example in the auto-\nmotive industry. An ordinary robot must be carefully pro-\ngrammed in advance for selected tasks, as unexpected changes \nin the working environment cause malfunction. Visual and other \nsenses make robots more adaptable, resilient and more independ-\nent. There are many such applications that utilize relatively sim-\nple machine vision. \nThe use of machine vision in the navigation of mobile machines \nand robots has also been the subject of much research. Potential \napplications include, for example, mining and forestry machines, \nas well as machines that are usually used in hazardous or un-\npleasant conditions (underground, underwater or in space). Fu-\nture cars will also increasingly use machine vision to help the \ndriver. \nThe development of more intelligent robots requires the combi-\nnation of many artificial intelligence technologies. The machine \nmust be able to percept its environment using, for example, vis-\nual and tactile senses, interpret sensory information, design free \npaths for movement of the hand or entire machine, perform the \nnecessary mechanical movements, react quickly to unexpected \nsituations, etc. \nOur research group has been doing research on intelligent and \nautonomous robotics since the 1980s. Initially, the focus was on \nthe development of robot platforms and solutions utilizing sim-\nple machine vision and other sensory information. In the 2000s, \nthe focus shifted to human-robot interaction. \n8.4.1 Intelligent robots \nThe development of autonomous mobile robots began in the \n1960s. The first independent mobile robot was the \"Shakey\" ro-\nbot developed at SRI's Artificial Intelligence Center in 1966-72, \nwhich was able to sense its environment and make decisions \nbased on sensed information. Significantly influencing on mod-\nern robotics, this robot was able to perform tasks in a laboratory \n\n168 \n \nenvironment that required planning, route searching, and reposi-\ntioning simple objects in the environment. \nIn our group, in the early 1980s there were enthusiastic graduate \nstudents who developed as their \"hobbies\"  a micro mouse, a me-\nchanical miniature robot looking for its path in the middle of the \nmaze. They used a simple ultrasonic radar and light sensors to \nsense the environment. National and international competitions \nwere held on the topic, with the current professors Olli Silvén \nand Juha Röning and their teams doing well. \nBased on this hobby-based background, we began to develop au-\ntonomously moving vehicles as a part of Juha Röning's disserta-\ntion work. The project developed a Controlled Test Vehicle \n(CAT) robot that was able to move and avoid obstacles in a la-\nboratory environment using the three-camera stereo method de-\nveloped by us at the University of Maryland to acquire three-\ndimensional information about the environment (Figure 8.17). \n \n \n \n \n \n \n \n \n \n \n \nFigure 8.17. CAT mobile robot.  \nSignificant applied research in the field of intelligent machines \nwas carried out in Oulu already in the early 1990s in connection \nwith the VTT-University co-operation project “Machine of the \nFuture”, funded by Tekes and the industry. It sought to increase \nautonomy by applying advanced senses and reasoning tech-\nniques. \nThe industrial pilot was to increase the autonomy of a paper roll \nloading manipulator operating in the harbor environment. The \nsystem utilized 3-D modeling of the environment based on ad-\nvanced sensors, such as laser depth measurements, and a design-\nexecution-monitoring principle to control the system. The inten-\ntion was not to replace the manipulator's supervisor, but to make \nhis or her work easier and more efficient. One of the significant \n\n169 \n \nresults of the project was education. The research related to this \nproject involved several young researchers who later made a sig-\nnificant career: current professors Visa Koivunen, Jukka Riekki \nand Juha Röning, as well as docents (adjunct professors) Tapio \nHeikkilä and Kari Pulli. Later Dr. Pulli created an excellent ca-\nreer in Silicon Valley. \nToday, a paper roll manipulator could be much more advanced \nthan nearly 30 years ago. Machine senses are now much better \nand more reliable, providing a much more accurate description \nof the 3-D environment. \nThe machine could now navigate autonomously in its operating \nenvironment, avoid obstacles, and handle the loading task inde-\npendently. However, people would need to make sure that eve-\nrything goes according to plan and deal with problem situations \n- possibly with multiple manipulators operating simultaneously. \n8.4.2  Human-robot interaction \nDeveloping intelligent machines and robots that interact with hu-\nmans has been one of the great challenges of artificial intelli-\ngence research. Inspiration for this research came from the 1968 \nscience fiction film “2001: A Space Odyssey”, directed by Stan-\nley Kubrick, based on the book by Arthur C. Clarke. It intro-\nduced the HAL 9000 computer, which was able to hear, speak, \ndesign activities, recognize faces, see, evaluate facial expres-\nsions, give artistic judgments, and even read speech from lips. \nMachine vision plays a key role in the development of natural \nhuman-machine interfaces resembling this (Figure 8.18). One \nimportant application is the various service robots that are com-\ning into our daily lives. Such robots would cope with many of \nthe routine tasks previously performed by humans. Because they \noperate in the same environment as humans, humans and robots \nneed to be able to interact in the same way that humans interact \nwith each other - this  is often called natural human-machine in-\nteraction. For example, a service robot could guide visitors to the \nmuseum or help the elderly at home. \n \nFigure 8.18. Human-robot interaction should be easy and natu-\nral. (© Jukka Kontinen) \n\n170 \n \nSuch a service robot must be able to find and preferably also \nidentify its user. In this way, it could safely provide personalized \nservice to its user and should recognize the user's emotional state \nin order to be able to have an affective, emotionally responsive \ninteraction. \nThe robot should also be able to communicate with its user and \nunderstand the given commands by recognizing speech and ges-\ntures. Simple gestures can also be used to communicate re-\nmotely. \nThe robot must also maintain a natural response based on the \ninformation provided by its observations, for example by means \nof an avatar display resembling a human face. The robot must be \nable to learn its behavior and the tasks it is supposed to do. \nIn line with these principles, in the early 2010s, with the support \nof the Academy of Finland and the European Regional Fund, we \nrealized a mobile robot called Minotaurus (Röning et al., 2014). \nWe collaborated with the robotics group led by Professor Juha \nRöning. \nFigure 8.19 shows the sensory system of the Minotaurus, which \nconsists of a standard camcorder, Kinect cameras providing dis-\ntance information, a microphone system, and an audio-visual \ndisplay. The robot was connected to the sensory network system \nof our laboratory in order to observe its movements in different \nlocations of our workspaces.  \nFigure 8.19. Minotaurus robot for investigating human-robot in-\nteraction. (© Springer) \nReprinted, with permission from Springer [Röning J, Holappa J, Kellokumpu \nV, Tikanmäki A & Pietikäinen M (2014) Minotaurus: A system for affective \nhuman-robot interaction in smart environments. Cognitive Computation] \nFigure 8.20 depicts communication with the Minotaurus in our \nlaboratory premises. The Kinect 3-D camera is located above the \nscreen. If possible, the identity of the person communicating \nwith the robot will be recognized from the face. This can be used \nto personalize the robot's services to the needs of that user. If the \nperson is unknown, in which case identification fails, it is still \n\n171 \n \npossible to measure from a facial image so-called soft biometrics \nsuch as gender, whether he or she is a child, young, middle-aged \nor old, whether he or she is European or Asian, etc. Such infor-\nmation can also be used to personalize the services of the robot \naccording to the user. For example, the response of a robot to a \nchild should be different from that of an adult. \n \nFigure 8.20. Testing human-robot interaction. (© Jukka \nKontinen) \nIn order to engage in an emotive interaction, the machine must \nbe capable of the same type of conversation as human interac-\ntion. For example, the robot should prefer to approach people \nwho are at good mood rather than those who do not seem to be \ninterested. \nThe Minotaurus used facial expressions for simple, albeit unre-\nliable emotion recognition, able to recognize, alongside a neutral \nlook, clearly stated prototypic expressions of \"happy\", \"sad\", \n\"surprised\", \"disgust\", \"angry\", or \"fear\". Better results would \nhave been achieved with the latest methods developed for spon-\ntaneous facial expressions and also taking into account the user's \nspeech and gestures. \nIt was also possible to talk to the robot with speech, gestures and \nactions. The first two were used in close-range and the third from \na distance. For speech recognition, we used the freely available \nPocketSphinx \n(https://github.com/cmusphinx/pocketsphinx) \nsystem, with support for both Finnish and English. Small micro-\nphones arranged in a matrix provided information on the direc-\ntion of the speaker. That way, it was known who the robot was \ntalking to, in front of the camcorder or the Kinect depth camera  \nfamiliar from Microsoft's Xbox 360 game controller. \nGesture recognition is a wide area of research in computer vi-\nsion, with significant application areas such as sign language \nrecognition for hearing impaired people. There is no common \n\n172 \n \nbody language and different gestures have different meanings in \ndifferent cultures. Our robot used simple shapes or movements \nas gestures, which were taught to the system beforehand by \n\"showing\" examples of each gesture. The user was able to select \nvarious gestures for the system by displaying them to the Kinect \ncamera during the training phase. Each of the taught gestures \ncould then be used as a simple control command for the robot. \nPeople use their movements for a variety of communication in a \nvery natural way, for example, a stranger can be greeted re-\nmotely by waving hands. A similar type of function was devel-\noped for Minotaurus, which allowed, for example, human-robot \ninteraction to be initiated remotely. \nBecause the image produced by the camcorder was too inaccu-\nrate for further detailed action analysis, we used a very simple \nsolution based on the LBP method we had previously developed \n(Kellokumpu et al., 2011). Figure 8.21 clarifies this (Röning et \nal., 2014). \nThe person seen by the robot is searched for in the image and \nLBP-TOP histograms of motion are computed in four areas. \nThese can be used to identify the system's pre-taught actions, \nsuch as don't come or come here. \n \nFigure 8.21. Recognition of simple human actions with the LBP-\nTOP method. (© Springer) \nReprinted, with permission from Springer [Röning J, Holappa J, Kellokumpu \nV, Tikanmäki A & Pietikäinen M (2014) Minotaurus: A system for affective \nhuman-robot interaction in smart environments. Cognitive Computation] \nThe robot responds to the user with a talking avatar. Such ap-\nproach has been found to facilitate human-machine voice inter-\naction. We used a simple system developed by our research team \nthat associates the talking mouth region with a constant face \nbackground (Zhou et al., 2012). \nThe system, trained using a publicly available audiovisual video \ndatabase, is capable of producing normal-looking speech visual-\nization in the mouth area, be it Finnish or English (Figure 8.22).  \nFeature histogram of a bounding volume\n\n173 \n \n \nFigure 8.22. Audiovisual face animation. (© Springer) \nReprinted, with permission from Springer [Röning J, Holappa J, Kellokumpu \nV, Tikanmäki A & Pietikäinen M (2014) Minotaurus: A system for affective \nhuman-robot interaction in smart environments. Cognitive Computation] \nWe made various demonstrations with the system. Below is an \nexample of a conversation between a human and the Minotaurus \nrobot. A video demonstration of the communication can be \nfound at (Web-Minotaurus). \n \n<Human>  \nHello! \n<Minotaurus> Hi! \n<Human>  \n Are there any news? \n<Minotaurus> Yes, there are totally twenty feeds.  \n         \n Give the number you want to hear. \n<Human>  \n Nineteen \n<Minotaurus> OK, the topic of the news number nineteen goes like: \n Saudi Arabia to import Finnish education expertise. \n<Human>  \n What is the weather like? \n<Minotaurus> Oulu Finland weather: minus seven Celsius, overcast \n<Human> \n Bye! \n<Minotaurus> Bye! Have a nice day! \nThe system we developed contained most of the basic compo-\nnents that could be designed, for example, in a service robot op-\nerating in an intelligent environment. It would have the ability to \nmove around in an indoor environment. It could use its senses to \nrecognize people, their expression, their roughly defined age, \ntheir gender, gestures and actions. It could also recognize speech \nand have an ability to retrieve information from the Internet. \nThe latest version also had a hand that allows the robot to grab \nobjects and, for example, move them from one place to another. \nThe robot receives information about its environment through a \nsensory network. The environment could have embedded dis-\nplay devices that could be used to request services when the ro-\nbot is not nearby. Using this, the robot can provide a variety of \nservices. It can serve as a guide and take guests to meet the peo-\nple they have agreed to meet. \nThe robot can also act as a messenger to share some of the mes-\nsages it knows with people it knows. The robot may also provide \n\n174 \n \nthe ability to retrieve various information through discussion, \nsuch as on-line data or contact information of people working in \nthat environment. All of the above functions must be performed \nin the most natural way possible, utilizing the robot's ability to \nrecognize human facial expressions and then change its behavior \nbased on emotional state. \n8.5 \nMachine Vision in Medical Image Analysis \nInterpretation of images obtained with various imaging equip-\nment plays a central role in medicine. This may be, for example, \nexamination of the results of microscopy, X-ray equipment, ul-\ntrasound camera or magnetic resonance imaging. \nAlready in the 1990s, the Machine Vision Group studied use of \nmagnetic resonance imaging (MRI) in surgery, analyzing skin \nimages to identify melanoma, and measuring the area covered by \npsoriasis rash. In the early 2000s, the use of functional MRI \n(fMRI) in brain imaging was investigated. \nIn recent years, the main areas of focus have been microscopic \nimage and video analysis and pulmonary X-ray analysis. Figure \n8.23 shows an example of a microscopic image analysis study \nwith the University of Helsinki (docent Johan Lund), in which \nthe actual tissue of interest (stroma) was segmented from the ep-\nithelium by the LBP / C texture method and the support vector \nclassifier (Linder et al., 2012).  The main result of this collabo-\nration may be the development of a practical tool for the diagno-\nsis of malaria (Linder et al., 2014). \n \n \n \n \n \n \n \nFigure  8.23. Segmentation of a virtual microscope image. \nFrom [Linder N, Konsti J, Turkki R, Rahtu E, Lundin M, Nordling S, Ahonen \nT, Pietikäinen M & Lundin J (2012) Identification of tumor epithelium and \nstroma in tissue microarrays using texture analysis. Diagnostic Pathology].  \n8.5.1. Deep neural networks for classification of  chest X-ray \nimages \nThere is a great need for automatic interpretation of  chest X-ray \nimages, as they are produced in large quantities in hospitals \nevery day, and it is not possible for physicians specialized in X-\nEpithelium \n \nStroma \n \n•\n•\n•\n•\n•\n•\nL\n•\nL\n\n175 \n \nray interpretation to go through all the details. It would be ad-\nvantageous if a preliminary interpretation of the images could be \nmade already in health centers. \nMost of the pictures taken have lungs healthy. If hospital radiol-\nogists could only focus on cases where the lungs may have dis-\nease-related changes, their precious time for other tasks would \nbe saved. \nThe aim of our study was to be able to distinguish between im-\nages of healthy and potentially ill lungs, classifying of the image \nmaterial into two categories. Figures 8.24a and 8.24b show ex-\namples of healthy lungs, and Figure 8.24c shows a patient with \npneumonia (Chen et al., 2016). \nHowever, the automatic interpretation of the images is difficult \nbecause they exhibit considerable variations due to the imaging \nconditions, such as illumination, lung position and scale. Images \nmay include images taken by different hospitals, devices, and \ndifferent operators. In addition, it may be difficult for sick pa-\ntients to be in the best position during imaging. \n \n \n(a)                                 (b)                             (c) \nFigure 8.24.  X-ray images. (a) and (b) normal, (c) pneumonia. \n(© IEEE)  \n© [2016] IEEE. Reprinted, with permission, from [Chen J, Qi X, Tervonen \nO, Silvén O, Zhao G & Pietikäinen M (2016) Thorax disease diagnosis using \ndeep convolutional neural network. Proc. 38th Annual International Confer-\nence of the IEEE Engineering in Medicine and Biology Society] \nIn the developed method, the alignment of the images is first per-\nformed (Figure 8.25). The set of images is then digitally aug-\nmented for CNN deep network training with sample versions of \nthree different scales as well as cropping, mirroring, and rotating. \nFinally, a fine-tuned CNN model is used to classify unknown test \nimages. \nTwo image databases were collected for the study by the Oulu \nUniversity Hospital. The first consisted of 755,969 magnetic res-\nonance imaging (MRI) images of 512 x 512 pixels taken from \nthe brains of 1000 patients used for training. Each image was \nannotated by radiologists, either healthy or possibly diseased. \nBoth of these were nearly as many. The second set consisted of \n\n176 \n \n4,000  X-ray chest  images taken from 2,000 patients at a reso-\nlution of 2688 x 2688 pixels. Half of the pictures were of a \nhealthy person and half of them were possibly ill. \n \nFigure 8.25. Classification of X-ray images with a CNN neural \nnetwork method. \nThe MRI image set was used to teach the CNN neural network \nby first supplementing it with three different scales. Half of the \nlung images were used to fine-tune the CNN model by first \naligning, complementing with three different scales and adding \ncut, rotated, and rotated images. The other half of the lung im-\nages were used for testing with the fine-tuned CNN model by \nfirst performing only an alignment operation. \nThe developed method achieved over 80% classification accu-\nracy, clearly better than the conventional methods. However, this \nresult is not good enough for clinical use, as pictures of sick peo-\nple should not be included among the healthy pictures. Signifi-\ncantly more training samples would be required to create a good \nenough CNN model, but creating such a set of samples is a very \nlaborious and expensive operation. \n8.6 \nReferences \nChen J, Qi X, Tervonen O, Silvén O, Zhao G & Pietikäinen M \n(2016) Thorax disease diagnosis using deep convolutional neural \nnetwork. Proc. 38th Annual International Conference of the \nIEEE Engineering in Medicine and Biology Society (EMBC \n2016), 2287-2290. \nFernandez-Lopez A & Sukno FM (2018) Survey on automatic \nlip-reading in the era of deep learning. Image and Vision Com-\nputing 78:53-72. \nHeikkilä J & Silvén O (1997) A four-step camera calibration pro-\ncedure with implicit image correction. Proc. IEEE Conference \non Computer Vision and Pattern Recognition, June 17-19, San \nJuan, Puerto Rico, 1:1106-1112. \nHeikkilä J (2000) Geometric camera calibration using circular \ncontrol points. IEEE Transactions on Pattern Analysis and Ma-\nchine Intelligence 22(10):1066-1077. \nHerrera Castro D, Kannala J & Heikkilä J (2012) Joint depth and \ncolor camera calibration with distortion correction. IEEE Trans-\nactions on Pattern Analysis and Machine Intelligence \n34(10):2058-2064. \n\n177 \n \nHietaniemi R, Bordallo Lopez M, Hannuksela J & Silvén O \n(2014) Real-time imaging system for lumber strength prediction. \nForest Products Journal 64(3-4):126-133. \nKellokumpu V, Zhao G & Pietikäinen M (2011) Recognition of \nhuman actions using texture descriptors. Machine Vision and \nApplications 22(5):767-780. \nKohonen T (2001) Self-Organizing Maps, Third Edition, \nSpringer. \nLi X, Alikhani I, Shi J, Seppänen T, Junttila J, Majamaa-Voltti \nK, Tulppo M & Zhao G (2018) The OBF database: A large face \nvideo database for remote physiological signal measurement and \nfor Atrial Fibrillation detection. Proc. IEEE International Con-\nference on Face and Gesture (FG 2018). \nLi X, Chen J, Zhao G & Pietikäinen M (2014) Remote heart rate \nmeasurement from face videos under realistic situations. Proc. \nIEEE Conference on Computer Vision and Pattern Recognition \n(CVPR 2014), Columbus, Ohio, 4265-4271. \nLi X, Komulainen J, Zhao G, Yuen PC & Pietikäinen M (2016) \nGeneralized face anti-spoofing by detecting pulse from face vid-\neos. Proc. International Conference on Pattern Recognition \n(ICPR 2016), 4244-4249. \nLinder N, Konsti J, Turkki R, Rahtu E, Lundin M, Nordling S, \nAhonen T, Pietikäinen M & Lundin J (2012) Identification of \ntumor epithelium and stroma in tissue microarrays using texture \nanalysis. Diagnostic Pathology 2012, 7:22. \nLinder N, Turkki R, Walliander M, Mårtensson A, Diwan V, \nRahtu E, Pietikäinen M, Lundin M & Lundin M (2014) A ma-\nlaria diagnostic tool based on computer vision screening and vis-\nualization of plasmodium falciparum candidate areas in digitized \nblood smears. PLoS ONE  9(8):e104855. \nMäättä J, Hadid A & Pietikäinen M (2011) Face spoofing detec-\ntion from single images using micro-texture analysis. Proc. In-\nternational Joint Conference on Biometrics (IJCB 2011), Wash-\nington, D.C., USA, 7 p. \nMäättä J, Hadid A & Pietikäinen M (2012) Face spoofing detec-\ntion from single images using texture and local shape analy-\nsis. IET Biometrics 1(1):3-10. \nNiskanen M (2003) A Visual Training Based Approach to Sur-\nface Inspection. Acta Univ. Oul. C 186, 125 p.  \nPietikäinen M & Silven O (2002) Konenäkö (Computer vision). \n25th Anniversary Book of Pattern Recognition Research in Fin-\nland, Eds. Iivarinen J, Kaski S & Oja E, Pattern Recognition \nSociety of Finland, 74-85.  \nPiironen T, Silvén O, Pietikäinen M, Laitinen T & Strömmer E \n(1990) Automated visual inspection of rolled metal surfaces.  \nMachine Vision and Applications 3(4):247-254. \n\n178 \n \nRöning J, Holappa J, Kellokumpu V, Tikanmäki A & Pietikäinen \nM (2014) Minotaurus: A system for affective human-robot inter-\naction in smart environments. Cognitive Computation, 6(4):940-\n953. \nSilvén O, Niskanen M & Kauppinen H (2003) Wood inspection \nwith non-supervised clustering. Machine Vision and Applica-\ntions 13(5-6):275-285. \nSilvén O, Virtanen I, Westman T, Piironen T & Pietikäinen M \n(1989) A design data-based visual inspection system for printed \nwiring. In: Advances in Machine Vision, ed. JLC Sanz, \nSpringer-Verlag. \nZhao G, Barnard M & Pietikäinen M (2009) Lipreading with lo-\ncal spatiotemporal descriptors. IEEE Transactions on Multime-\ndia 11(7):1254-1265. \nZhou Z, Hong X, Zhao G & Pietikäinen M (2014) A compact \nrepresentation of visual speech data using latent variables. IEEE \nTransactions on Pattern Analysis and Machine Intelligence \n36(1):181-187. \nZhou Z, Zhao G, Guo Y & Pietikäinen M (2012) An image-\nbased visual speech animation system. IEEE Transactions on \nCircuits and Systems for Video Technology 22(10):1420-1432 \nYlimäki M, Kannala J, Holappa J, Brandt SS, Heikkilä J (2015) \nFast and accurate multi-view reconstruction by multi-stage pri-\noritized matching. IET Computer Vision 9(4):576-587. \nWeb-Antispoofing:  Anti-spoofing demonstration  \nWeb-Minotaurus: HRI demonstration   \nWeb-TrumpClinton: Trump-Clinton debate   \n \n \n\n179 \n \n9 Emotion AI – the Next Breakthrough? \n9.1 \nIntroduction \nThe purpose of emotions is to try to increase things that promote \nhuman well-being and avoid things that endanger life (Wiki-\nTunne), (Puttonen & Heikkinen, 2018). According to Lauri \nNummenmaa, Director of the Emotion Laboratory at University \nof  Turku, the feelings can be compared to a thermostat, which \nkeeps the room temperature normal and regulates the heating \nwhen deviating from the set value. The universal, culture-inde-\npendent basic feelings include happiness, sadness, disgust, an-\nger, fear and surprise. \nAccording to research by Nummenmaa’s group, the human body \nexperiences strong emotions, and the above-mentioned basic \nemotions can be located in the same places, regardless of cultural \nbackground. (Nummenmaa et al., 2014). After the pictures, vid-\neos and stories were presented to the test subjects, they were \nasked to color the drawing where and how intense the feelings \nof the material presented felt. Only the feeling of “happiness” \nspreads throughout the body (Figure 9.1). \n \n \nFigure 9.1. Locations of different emotions on the body map. (© \nPNAS) \nReprinted, with permission, from [Nummenmaa L, Glerean E, Hari R & \nHietanen JK (2014) Bodily maps of emotions. © PNAS 111(2):646-651].  \nHowever, caution should be exercised in generalizing the results \nof this body map to most real-world situations. The experiments \nhave been conducted in a typical laboratory environment and the \ninfluence of many key factors on the results has not been eluci-\ndated, for example with regard to the design of the experimental \nsetup to produce different emotional states. Section 9.7 intro-\nduces the challenges of emotional intelligence that need to be \n\n180 \n \nconsidered when designing practical applications. For example, \nvariations in imaging conditions will cause serious problems \nwhen applying machine vision to automated emotion analysis. \nFacial expressions have also been found to be similar throughout \nthe world, but due to cultural differences learned and individual \ndifferences, the use of expressions may differ. For example, \nAmericans smile and gesture more than East Asians or Finns, but \nthat doesn't mean they are happier. \nEmotions and intelligence are closely related. Emotions guide \nhuman activities alongside motives, goals, and data processing \nin the brain. They promote human adaptation to the environment \nand different situations. Emotions affect a person in many ways. \nThey may appear in facial expressions, speech tone, body move-\nments and gestures. Emotional state affects a variety of physio-\nlogical signals describing the internal state of the human being, \nwhich can be obtained, for example, from the brain's electrocar-\ndiogram, heart rate, skin temperature, skin conductivity, blood \npressure or respiratory rate. \nEmotions and empathy play a central role in human-to-human \ninteraction. Most of the communication between people is non-\nverbal communication: facial expressions, gaze, gestures, body \nmovements and postures, variations in voice tone, touch, etc.. \nEstimates of non-verbal communication vary. Albert Mehrabian, \nin his much quoted study, stated that 38 % of face-to-face com-\nmunication involves voice and tone, 55 %  non-verbal behavior \n(e.g., facial expressions), and only 7% words (Mehrabian, 1972). \nHowever, these results have been criticized. Indeed, in research, \nthey relate those to more communicative attitudes and feelings. \nOnly a small part of the human brain deals with verbal commu-\nnication. It is estimated that at least 60% of the brain is related \nto vision. However, perhaps only 20% of this is devoted solely \nto vision, the remainder deals with the sharing of more modali-\nties, e.g., vision and touch, vision and motor functions, sight and \nattention, vision and meaning. As babies, people learn non-ver-\nbal communication in their social and emotional interaction, \nwith face as the dominant channel of communication instead of \nvoice. After learning to speak, people use non-verbal communi-\ncation, such as facial expressions, voice tone, and other non-ver-\nbal communication, at least partly unconsciously. \nHuman emotional intelligence refers to the ability to recognize \nour own emotions and those of others and to use this knowledge \nto guide our own behavior and achieve our goals. The im-\nportance of emotional intelligence for different applications is \nclear. For example, when making shopping decisions, feeling of \na particular product is often more important than the details of \nthe product. Studies have shown that when it comes to deciding \nbetween several options, it is very difficult for a person to do so \n\n181 \n \nby mere logical reasoning. Salespeople who can read the cus-\ntomer's feelings are better salespeople. When a customer views \na product in a store or shop window, their feelings tell us what \nthey like and what they don't. \nAccording to Jussi Toivanen, Managing Director of Microsoft \nFinland, more empathy would be needed (Nalbantoglu, 2018). \nHe said people should become more human as technology ad-\nvances and machines become more intelligent. \nIn understanding emotions and social skills, man is superior to \nmachines, and this competitive advantage should be exploited. \nAccording to a study conducted by Microsoft, Finnish compa-\nnies are in the forefront of exploiting artificial intelligence tech-\nnology in Europe, but lagging behind in understanding the mean-\ning of emotional intelligence and empathy. In Finland, the focus \nis on process optimization and cost savings, but not on solutions \nthat understand people and their needs. \nNowadays, when interconnected intelligent devices control our \ncommunication and our daily lives, attention to emotions plays \na central role in artificial intelligence - we can talk about Emo-\ntion AI or Affective Computing (Picard, 1997). Communica-\ntion with technology is becoming more interactive, resembling \nthe interaction between people. Intelligent devices in our envi-\nronment are able to capture people's emotions and moods and \ncreate more personalized user experiences. Emotional intelli-\ngence is needed in systems being developed to read user emo-\ntions and use them to adapt actions. \nAccording to Rana el Kaliouby, director of Affectiva, a spin-off \ncompany launched by Rosalind Picard’s affective computing re-\nsearch at MIT, emotional intelligence will grow into a billion-\ndollar business in the next few years. It will revolutionize many \nindustries, such as market research, the automotive industry and \nhealth care. Many technology companies have begun to invest in \nthe emotional intelligence. Alongside Affectiva, Apple, Google, \nMicrosoft and Baidu, for example, see emotional intelligence as \na major component of their systems. Also in Finnish companies \nthe interest in recognizing emotions has clearly increased lately. \nHowever, automatic recognition of emotions is a very difficult \ntask. It is known that emotions depend on the context in which \nthey are attempted to be recognized. Factors affecting the evalu-\nation of the emotion state include: operating environment, body \nposture, sounds and words, and the cultural background of the \nindividual being assessed (Feldman Barret et al., 2011). In addi-\ntion to facial expressions, a number of different factors are \nneeded, so-called multi-modal approaches. Many times the tone \nand body movements already tell a lot about emotional states. \n\n182 \n \n9.2 \nCognition and Emotions Go Hand in Hand \nCognition refers to those phenomena of the human mind that can \nbe described or explained as information processing. Cognition \nand emotion are closely interrelated (Wiki-Emotion). \nAccording to cognitive explanations, humans use emotions to \nprocess information from both their bodies and their environ-\nment. The human mind is thought to function in that it constantly \nprocesses and directs its emotions. Feelings arise as a result of \njudgments and interpretations. Feeling creates motivation for ac-\ntion as well as repeating our behavior. Although cognitive expla-\nnations focus on exploring information processing, they also ac-\ncept that physiological state can alter emotion. \nStudies have shown the effect of the physiological states of the \nbody on the experience of feeling. In one study, subjects were \nasked to feel anger. One group was told to squeeze their hands \nat the same time, the other just \"felt angry\". The results showed \nthat people holding their hands in fists felt more angry than oth-\ners (Wiki-Tunne). \nA cognitive explanation for the emergence of emotions is given \nby the so-called appraisal theory. According to it, situational \nfactors and previous experiences create a feeling (Figure 9.2) \n(Scherer et al., 2001, Wiki-Appraisal). The person's own assess-\nment of the situation is important in feeling the feeling. Accord-\ning to the theory, emotions arise from evaluations of  events that \ncause certain reactions, or emotions, in different people. \n \nFigure 9.2. Cognitive appraisal theory. (e.g. Scherer et al., 2001). \nWikipedia, for example, describes going to a first date. If dating \nis successful, the person may feel happy, glad, excited, moved \nand/or be eagerly awaiting because this assessment can be ex-\npected to have positive long-term effects - starting a new rela-\ntionship, getting engaged or even getting married. \nConversely, when dating is negative, emotions can become de-\npressed, sad, empty or frightened (Wiki-Appraisal). The reason-\n\n183 \n \ning and understanding of these emotional reactions will also in-\nfluence future evaluations. Note that such an estimation theory, \nor variations thereof, allows for individual variations in the same \nevent in different people. \n9.3 \nApplications of Emotion AI \nEmotions play a central role in human-to-human interaction. \nWhen talking to a robot or chatbot, one finds \"machine-like\", in-\nsensitive speech disgusting. In particular, empathy that is the \nability to understand the feelings of the interlocutor, is seen to \nplay a significant role in good interpersonal communication. \nThe same flaw more generally applies to interaction in digital \nmedia, where we often do not see our interlocutor. Solutions to \nproblems have been sought, e.g. , in a project funded by Tekes \nand industry in 2018-19, “Quantifying Human Experience for \nIncreased Intelligence within Work Teams and in the Customer \nInterface”, coordinated by cognitive scientist Katri Saarikivi \nfrom the Cognitive Brain Research Unit, University of Helsinki \n(Web-Humex, 2017). \nThe role of our group was measuring the emotional state using \nmachine vision. Other participants were Aalto University re-\nsearch groups on Complex Systems and Learning Environments. \nThe companies involved in the project were interested in: utili-\nzation of emotional intelligence in computer-mediated interac-\ntion with clients, health services, and digital marketing. \nA good example of using today's emotional intelligence is the \nsales laboratory acquired for teaching purposes at Haaga-Helia \nUniversity of Applied Sciences, based on emotional analysis \nsoftware developed by MIT University's spin-off company Af-\nfectiva (Mielonen, 2018). It observes more than thirty points of \nmotion on its face, apparently using action units as defined by \nPaul Ekman. The system has been trained with over seven mil-\nlion faces. It classifies a person's face based on measured infor-\nmation into one of seven prototypic expressions. The Haaga-He-\nlia system describes how customers respond to a salesperson, \nand the aim is to get salespeople to change their behavior based \non the customer's emotional state. \nEmotional intelligence can be used in many ways in computer-\nassisted teaching. For example, if the subject to be taught has not \nbeen understood or the student is not attentive enough, it is read-\nily apparent from the student's expressions and changes in emo-\ntional state.  Professor Sanna Järvelä, investigating computer-as-\nsisted learning at the University of Oulu, explains that emotional \nintelligence can be utilized more widely in the future digital \nlearning environments, which should understand students' goals, \nassess performance, and provide active guidance to enable each \nstudent to achieve their learning goals in a natural way of inter-\nacting with the machine. \n\n184 \n \nIn particular, basic education - from pre-school to university - \nand lifelong learning have become increasingly important teach-\ning and learning environments. According to Järvelä, the basic \nproblem in current technology-assisted and/or virtual learning \nenvironments is that they do not provide the same social and \nemotional presence as face-to-face interaction. Emotional intel-\nligence can significantly improve this issue and make invisible \nissues related to emotions and cognitive learning processes visi-\nble. \nInterpreting emotions is also important in intercultural commu-\nnication. It is often difficult for unfamiliar Europeans to infer the \nface of Asian people and vice versa. In this way, emotional in-\ntelligence can support both parties in making judgments. \nThe lack of verbal communication with people is a major prob-\nlem for the visually impaired. The machine can help them iden-\ntify objects and people in the environment. Identifying a part-\nner's emotion state would be very important in natural interac-\ntion. Smart glasses like those in Section 8.2 could be helpful. The \nemotion state can be transmitted to the visually impaired by \nmeans of acoustic signals, artificial speech, or touch feedback \nwith  a device attached on the body.  \nEmotions also matter to our health. Very strong negative or pos-\nitive emotion can cause a heart attack or cerebral hemorrhage. \nDepression and other types of long-term negative emotion can \nincrease the risk of heart disease and diabetes. On the other hand, \nlong-term positive emotional state is known to have a positive \neffect on psychological and somatic, organic diseases. \nIn health and medicine, emotional intelligence can help monitor \nour mental state, identify pain conditions, or even help make a \nproactive diagnosis of Parkinson's disease or coronary heart dis-\nease. Emotional information can also be used in research and \ntherapy for such as depression, autism, traumatic stress disorder \nand bipolar disorder. \nIt is possible to see up to 30 medically relevant symptoms on \npeople's faces by machine vision, such as getting hints of pain or \nstates of mind (fatigue, depression, anxiety, mental strain, stress, \netc.) or detect facial changes and asymmetries, for example, \nwhen a cerebral hemorrhage might start (Thevenot et al., 2018). \nBy combining data from sensors that measure physiological sig-\nnals, it is possible to develop better devices, for example, on the \nwrist, for continuous monitoring of human health and well-be-\ning. By using intelligent glasses with machine vision capabili-\nties, the physician could obtain useful information about the pa-\ntient's face for diagnosis. \nEmotions also tell when a person is tired, frustrated, or nervous \nwhile driving a car - or when he or she is properly alert. The \ndisclosure of such information has been of increasing interest to \n\n185 \n \ncar manufacturers in improving both safety and the driver's user \nexperience. An example of a great need is the Kuopio bus acci-\ndent in late summer 2018, where detecting and alerting the driver \nof a change in his driving condition early enough could have pre-\nvented the accident. \nImportant potential applications for emotion recognition include \nanalyzing people's behavior and facial expressions during airport \nsecurity checks and revealing lies during interrogations. The ad-\nvantage of machine vision is that the person to be investigated \ndoes not need to be fitted with any measuring equipment that \ncould change his or her behavior. However, lie detection with a \nmachine is a very difficult task and cannot be reliably performed \non the basis of perceptual information alone. Emotional status \nanalysis may also be useful, for example, in job interviews (Fig-\nure 9.3) or in preparation for such. \n \nFigure 9.3. Emotions in a job interview. (© 123RF) \nCustomer profiling and user experience analysis are important \ncommercial applications. Facial expressions tell us how inter-\nested customers seem to be in certain products, etc. These types \nof applications are becoming more common among the first be-\ncause they usually do not require very high precision and can be \nvery important commercially. \nEmotional toys are much more natural playmates for kids than \nnon-emotional toys. Simple toys recognizing child's expression \nalready exist or are being developed (Web-Toys). A puppet rec-\nognizing an emotion state would be much better able to “com-\nmunicate” with a child. Communicating with toy robots would \nbe much more natural, in the same style as the other human-ma-\nchine interfaces mentioned earlier. Emotion recognition can also \nbe used to teach children to stay alert and, more generally, to use \nemotions and empathy in their interaction. \n\n186 \n \nEmotions can also be utilized in the game industry. Affectiva has \nintroduced features that utilize emotion mode in the Nevermind \nvideo game (Web-Affectiva). The system recognizes the player's \nemotion state and changes its behavior and user experience ac-\ncordingly. For example, if a player is under stress, the gaming \nworld will become darker and more distorted, but will calm \ndown as stress decreases. \nNevermind uses in its analysis multimodal data from a heart rate \nmonitor, Apple watch and eye movement measurement device, \nand in its latest version Affectiva's emotion recognition software, \nwhich analyzes players' actions on the video data produced by \ntheir web cameras. \n9.4 \nFacial Expressions in Emotion Recognition \nCharles Darwin was the first to study facial expressions and their \nrelationship to emotions, and in his 1872 book, “The Expression \nof Emotions in Man and Animals”, concluded that expressions \ncan be described as discrete categories of emotions (Ekman, \n2009). In addition, the set of expressions and persons he had ob-\nserved and studied were universal, that is, independent of the \nperson. \nThe six most common so called prototypic expressions on the \nface are happy, sad, disgust, angry, fear, and surprise. Contempt \nis also often included in basic expressions. In addition, the face \nmay look neutral. Depending on the application, there may also \nbe other interesting facial expressions, such as arrogance, driv-\ning fatigue, pain when experiencing pain, or nervousness when \ntense. \nThis approach is based on imagining emotions as separate clas-\nses, as Darwin suggests, because of their fundamentally different \nstructures. Figure 9.4 shows examples of seven commonly used \nprototype expressions and neutral expression taken from the \nwidely used Cohn-Kanade database. \n \nFigure  9.4.   Prototypic facial expressions. \n\n187 \n \nThe facial expressions can be created by the facial action coding \nsystem (FACS). It describes facial muscle movements to pro-\nduce various expressions (Ekman & Friesen, 1978). Figure 9.5 \nshows examples of action units (Martinez et al., 2017). \n \nFigure  9.5. Examples of action units. (© IEEE)  \n© [2017] IEEE. Reprinted, with permission, from [Martinez B, Valstar MF, \nJiang B & Pantic M (2017) Automatic analysis of facial actions: A survey. \nIEEE Transactions on Affective Computing] \nThe basic unit is the Action Unit (AU). FACS, the latest version \nof which was developed by the psychologist Paul Ekman in \n2002, is a commonly used standard for categorizing emotion ex-\npressions (Ekman et al., 2002). It is used in computer vision as \nwell as in psychological research and facial animation. \nThe advantage of FACS coding is that they can be used to de-\nscribe facial muscle movements for the majority of potential ex-\npressions. The big challenge for machine vision is to be able to \ndetect the various action  units automatically with sufficient re-\nliability. Laboratory conditions have provided quite good results \nfor most of them, but the problem is greatly exacerbated by nat-\nural variations in lighting, head pose changes, lower image res-\nolution, and so on. Figure 9.6 shows how the expressions \"joy\" \nand \"anger\" can be composed.  \n \nFigure 9.6. The expressions “joy” and “anger” were born as a \ncombination of movements. (© Henglin Shi and Zitong Yu) \n\n188 \n \nIn the above examples, two emotion AI researchers at the Center \nfor Machine Vision and Signal Analysis are present. Notice the  \ncombined effect of the movements of different action units.  \nAnother way to describe emotions is to group them by dimen-\nsion. The much used two-dimensional model assumes that there \nare always values for activation state (arousal) and emotional \nvalue (valence) associated with different emotional states as \nshown in Figure 9.7. For example, happy emotion is seen as both \na positive arousal and valence. \n \nFigure 9.7. Two-dimensional emotion model. \nFinding the valence reliably is much easier than arousal, so often \nit is only used, dividing emotions into positive ones on the right \n(like happiness, peacefulness), negative ones on the left (anger, \nsadness, nervousness) and almost neutral in the middle. \nFacial expressions can also be divided into two main categories \nbased on their speed and intensity: \n1) Macro-expressions are mostly clearly visible and have a du-\nration of about 0.5 to 5 seconds and \n2) Micro-expressions very fast (0.03-0.5 seconds) and low in \nintensity. \nMacro-expressions are voluntary expressions, meaning we can \neven pretend to smile or other expressions. Micro-expressions, \non the other hand, are involuntary. In Figure 9.8, the horizontal \naxis represents the duration of the image and the vertical axis the \nintensity. \nIn addition, there is often interest in the types and durations of \nthe individual expressions or their action units. For example, in \nthe initial phase (Onset) the expression may change from neutral \ntowards the smile, at the peak (Peak) the smile will be maximal \nand in the final phase the expression may return to neutral again. \n \n\n189 \n \n \nFigure  9.8. Micro- and  macro-expressions. (© CMVS) \n9.5 \nMicro-expressions and their Identification \nMicro expressions are very fast unconscious facial movements. \nThey also reveal emotions that the person does not want to ex-\npress (Figure 9.9).  \n \nKuva 9.9. Micro-expressions usually occur in the eyes and \nmouth regions. (© Jukka Kontinen). \nAs mentioned above, not only speed, but also the very low in-\ntensity of micro-expressions can be distinguished from ordinary \nexpressions. The micro-expression can also be one-sided so that \nit starts slower, but ends very quickly, because the whole expres-\nsion does not have time to come to the face. \nAccording to Dr. Xiaobai Li (STT October 14, 2017), for exam-\nple, in a happy normal feeling, corners of the mouth  will rise \nclearly, but in the micro-expression, only one may rise slightly, \nor sometimes both. In a micro-expression corresponding to a \nnegative feeling, the inner corners of the eyebrows are pressed \n\n190 \n \ndown for a short time, and with surprised faces both eyebrows, \nor just one, may rise slightly. This interpretation is not entirely \nincontrovertible, since there is no unambiguous knowledge of \nhow micro-expressions appear. \nMicro-expressions can occur, for example, when lying in border \ncontrol or police interrogations, hiding one's opinion in business \nnegotiations, computer-aided teaching when a student has not \nunderstood what he or she is teaching, in some psychiatric ill-\nnesses or in poker. It is very difficult to see them with the human \neyes. It has been found that even a well-trained  person can only \nrecognize less than 50% of micro-expressions. \nIn 1966, researchers Ernest Haggard and Kenneth Isaacs were \nthe first to detect such facial expressions when examining films \ntaken from therapy sessions of couples, noting that these \"micro-\nmomentary expressions\" flash so quickly that they are difficult \nto see except in slow motion filming (Li et al., 2018). \nSuch expressions later became known from the work of psy-\nchologist Paul Ekman, who also called them micro-expression. \nParticularly noteworthy was the case where Ekman and his col-\nleague were studying a video of a psychiatric patient. Later, the \npatient admitted that she had been about to commit suicide, even \nthough she seemed to be happy with the video all the time. How-\never, as the video was examined more picture-by-picture, a hid-\nden anxiety was found on the face that lasted for a period of two \nconsecutive frames (1/12 s). \nMicro-expressions are often confused with other fast expressions \nin public because of their apparently good “market value”. Even \nin Finland, a human personality test based mainly on micro-ex-\npressions has been marketed. However, an article in the Hel-\nsingin Sanomat newspaper dealing with it stated that these ex-\npressions could not be true micro-expressions, and that it is not \npossible to determine a person's personality mainly through \nvideo clips taken from the face (Tiainen, 2018). One of the rea-\nsons for the market value is probably the television series \"Lie \nto Me\", presented in 2009-2011, in which the main character was \none of the world's best lie detection experts, able  to analyze for \nexample micro-expressions. \nHowever, with over 40 years of practical experience in interpret-\ning human speechless communication, Joe Navarro (Navarro, \n2011) has warned against giving micro-expressions too much \nimportance. For example, lying cannot be revealed solely on the \nbasis of micro-expressions or other individual behaviors. They \nare indicators of stress, psychological distress, anxiety, aversion \nor tension - but not lying. In his view, more generally, more at-\ntention should be paid to everything the human body communi-\ncates, not just the face and the micro-expressions. \n\n191 \n \nIn the United States, TSA has a number of people trained at pas-\nsenger airports to examine the behavior of travelers, including \nmicro-expressions. Launched in 2007, the SPOT (Screening Pas-\nsengers by Observation Techniques) program aims to see if there \nare potential terrorists among travelers. \nHowever, recent leaks indicate that the result has been quite \npoor, with only 1% of the 30,000 checkpoint passengers being \narrested related to  cases involving drug use or unreported bag-\ngage imports. No terrorists found! (Web-TSA) \nTraining tools have been developed to improve the detection of \nmicro-expressions, for example by Paul Ekman. In Finland, too, \nit might have been considered to look at micro-expressions and \nother behaviors in border control, as mentor, magician and \ntrainer Jose Ahonen said he has been training Finavia security \ninspectors (Myynti & Markkinointi, 8.6.2016). According to \nhim, identifying micro-expressions is also useful in negotiations, \nsales situations or recruitment interviews. The article also refers \nto the famous Bill Clinton's claim that he had no sexual relation-\nship with Monica Lewinsky. Leaving in front of the camera, \nClinton is said to have a micro-expression related to arrogance, \nwhich revealed him lying. As an interesting detail, Ahonen says \nthat when he follows discussion programs for learning how to \nfind micro-expressions, he finds the contradictions between \nspeech, expression and gestures of particular interest. \nAnother Finnish mentalist specializing in micro-expressions is \nMr. Pete Poskiparta. In an article presented in YLE news \n(https://yle.fi/news/3-9912709, 12.11.2017), he says that many \ncar dealers are particularly good readers of micro-expressions. \nRapidly flashing expression of arrogance, a one-sided smile, can \nmean that the buyer is over-bidding and promising a very good \ndeal for the seller. In the micro-expression of a liar, he says that \nthere is an expression of supernaturalism and complacency, that \nis to say the person's face flashes one-sided smile immediately \nafter the lie. \nAccording to Professor Matsumoto, there are two nerve path-\nways that originate from different parts of the brain (Matsumoto \n& Hwang, 2011). The pyramidal pathway controls voluntary fa-\ncial movements, while the extrapyramidal pathway directs invol-\nuntary emotional activities. When people are in intense emo-\ntional situations but need to control their expressions, both of \nthese pathways become activated, causing a \"controversy\" in fa-\ncial regulation that allows for instantaneous leakage of micro-\nexpressions. \n9.5.1 Automatic recognition \nAutomatic real-time recognition of micro-expressions has long \nbeen considered a difficult task due to the extremely short dura-\ntion and low intensity of the expressions. The first studies were \n\n192 \n \nabout acted, not real spontaneous expressions. In 2010, we were \nthe first in the world to investigate natural or spontaneous micro-\nexpressions, and in 2011 we published the results at the Interna-\ntional Conference on Computer Vision (Pfister et al., 2011). \nA test database had to be created for the study, because such a \nstudy had not been done before. The principle behind our crea-\ntion of the SMIC (Spontaneous MICro-expression) database was \nthat viewers were shown video clips evoking heavily various \nemotional states and were asked to remain motionless and keep \ntheir faces expressionless. \nExamples of videos shown include Youtube cat videos (happy \nmicro-expression) and the movies Lion King (sadness), Shining \n(fear), Hellraiser (disgust) and Capricorn (surprised) (Li et al., \n2018). A total of 164 samples of micro-expressions were found \nby hand-crafting from the high-speed video footage taken with a \nfast 100 frames per second camera. Figure 9.10 shows the prin-\nciple of an improved version of the micro-expression recognition  \nmethod developed (Li et al., 2018). \n \nFigure 9.10. Improved version of the micro-expression recogni-\ntion method.  (© IEEE)  \n© [2018] IEEE. Reprinted, with permission, from [Li X, Hong X, Moilanen \nA, Huang X, Pfister T, Zhao G & Pietikäinen M (2018) Towards reading hid-\nden emotions: A comparative study of spontaneous micro-expression spotting \nand recognition methods. IEEE Transactions on Affective Computing] \nInitially, faces found on different videos are aligned at the same \nlocation in the face area using face alignment based on detected \nlandmarks, and then motion magnification utilizing the motion \nof a sequence of images, is used to bring out the details. Subse-\nquently, extra images are generated between two consecutive \nimages by a temporal interpolation (TIM) method to obtain more \nimages for ultra-fast micro-expressions and to make expressions \nof different lengths uniform in the feature extraction method. \nThen, the micro-expression features are described, for example, \n\n193 \n \nby the LBP-TOP method  (Zhao & Pietikäinen, 2007) (see Sec-\ntion 7.1). The classification algorithm uses the computed fea-\ntures to identify what the micro-expression is. \nIn order to speed up the discovery of micro-expressions, a spot-\nting method was developed which, prior to using the above-men-\ntioned method, searches the video for locations that exhibit ex-\ntremely rapid changes between successive images. Rapid \nchanges can be caused, for example, by micro-expressions or eye \nblinks. The spotting method allows to use computationally much \nmore laborious expression recognition only in those parts of the \nvideo sequence that may have a micro-expression. \nMicro-expressions have recently been studied in many groups, \nbut there are still many open research challenges as discussed by \nZhao & Li (2019). Among these are lack of comprehensive da-\ntasets, detecting action units for micro-expressions, working in \nrealistic uncontrolled situations, handling both micro- and \nmacro-expressions, using context clues and multi-modal learn-\ning, and analyzing multiple persons in interactions.  \n9.6 \nThreats and Practical Problems \nPublicly, there are often threats that technology will allow auto-\nmatic recognition of the emotional state of any street person - the \nsame style as face recognition can already be used to identify \none. However, emotions are a much more vague concept than \nidentity, and face images alone are not enough to recognize \nthem. \nThere are still many practical problems associated with emo-\ntional state recognition. Right now, we need good, almost direct \nfront-view photos with moderate resolution. Emotional expres-\nsion is partly cultural and perhaps also genetic in nature, which \nmay make it difficult to obtain a universal interpretation of the \nemotional features measured in each person's face and speech. \nManaging this problem involves a great deal of psycho-physio-\nlogical knowledge acquisition. \nIt is certain that countermeasures are also under development. \nTechnology has always been a race and it certainly is also here. \nFor example, if in video conferencing there is a suspicion that \nthe other party is trying to interpret emotions, solutions resem-\nbling the real-time beauty algorithms available for taking selfies \non some mobile devices may in the future hide emotions without \nthe recipient's knowledge. Now, video encoders hide reception \nerrors, so why not hide half the emotion in pictures and speech? \nAnd, in such cases, the detection of heart rate and respiratory rate \nfrom videos can be significantly impaired even by active illumi-\nnation, as long as such an analysis of physiological features and \nthe like is at the transmission end. \nBut does emotional intelligence technology lead to face-to-face \nmeetings for reasons of trust? Then the analysis or manipulation \n\n194 \n \nof the \"channel\" will not always be possible in real time by tech-\nnical means. \nAnd yet, all technology has both positive and negative sides. By \nproviding a person with constant feedback on emotional infor-\nmation that he unknowingly conveys, is it not possible for a per-\nson to be able to avoid at least the transmission of negative feel-\nings through practice? In job interviews, that can be good. Tech-\nnology will probably have to provide the tools for such condi-\ntioning, for example, by telling the practitioner about the emo-\ntions that he or she is unknowingly communicating. \n9.7 \nChallenges and Future Perspectives \nEmotional artificial intelligence research is still largely in its in-\nfancy. Much of the research, as well as the basic theories of emo-\ntion recognition, have been made for a small number people with  \nacted, non-natural expressions. The spontaneous natural expres-\nsions in our daily lives are very varied and different. The state-\nof-the-art technology is therefore most suitable for applications \nwhere emotion recognition accuracy is not critical. \nThe context greatly influences to expressions. Are we dressing \nup for weddings or funerals, are we resting or do some physical \nactivity, do we watch a pet or something more boring? It has also \nbeen found that our cultural background affects facial expres-\nsions. According to a large population survey, Americans have \nthe most smiles, Chinese and Japanese have the least smiles \n(McDuff, 2018). This does not mean that Americans are happi-\nest. \nThe result is believed to be influenced by the degree of individ-\nuality of the people and, above all, by the heterogeneity of the \npopulation. In a multicultural environment, people need to ges-\nture more to get their message across. And a smile does not nec-\nessarily mean that one is happy. Even the Finns are very low-\nprofile when discussing, southern Europeans express a lot and \nuse gestures. Social norms also affect feelings. Women generally \nsmile more than men and children look differently than adults. \nIn the morning, people's emotional state is at its most intense and \nfalls towards evening. \nAll of these types of factors affect facial expressions. In addition, \nmost current facial expression analysis methods work well only \nwith almost front-facing videos, head position should not vary \ngreatly, for example when speaking or gesturing, lighting should \nnot vary widely, and the face should not be covered too much. \nFurther research is needed to achieve reliable operations without \nthe limitations mentioned above (referred to as \"in the wild\"). \nRecognition of facial expressions during speech is also problem-\natic and we should be able to utilize both together, since speech \nand mouth movements also contain significant information \nabout the emotional state. \n\n195 \n \nThese issues are particularly difficult for recognizing very fast \nand hard-to-detect micro-expressions. Current methods only \nwork well under almost studio conditions. In addition, current \ntest databases (SMIC, CASME) have been imaged under such \nconditions (Li et al., 2018). This hampers the development of \nrecognition methods that are suitable for demanding conditions. \nOn the other hand, creating new databases is very tedious: micro-\nexpressions are rarely found, and searching for video for anno-\ntation and system training is largely manual. \nFacial expressions alone are not enough for most emotional AI \napplications. In addition, other modalities are needed, such as \ngestures, body movements, speech and gaze changes. Various \nphysiological signals provide intrinsic information about emo-\ntions such as heart rate and heart rate variations, respiratory rate, \nelectroencephalogram (EEG), skin conductivity. The role of \nspeech and language is particularly important in human-machine \ninteraction. \nBetter connections to human cognitive functions would also be \nimportant. Our thinking is related to emotions. In a futuristic \nbrain-to-vehicle project Nissan is investigating the use of a sim-\nple brain electricity headgear (EEG) to adapt to driver's driving \nstyle and predict movement patterns (Thubron, 2018). The pur-\npose is, for example, to predict the need for braking or turning \nand to perform the action 0.2-0.5 seconds faster than the driver, \nthereby preventing incidents with a small improvement in reac-\ntion speed. \nBy combining different modalities, it is possible to achieve bet-\nter results in emotional state assessment. Figure 9.11 (partially \nedited from Vinciarelli et al., 2009, Fig. 1) is an example of the \nuse of different modalities. A research problem of its own is how \nbest to combine and learn multiple modality data. \nAs an example of multimodal recognition, we have investigated \nthe use of facial expressions and EEG signals in emotion recog-\nnition (valence/arousal) for  virtually expressionless face videos \nfrom the multimodal MAHNOB test database (Huang et al., \n2016). Of the individual modalities, the EEG was clearly better \nthan the facial expressions due to the low expressions of the \nfaces, but when properly combined, the result continued to im-\nprove - well beyond what a person could rate based on those vid-\neos. \nIn addition, we investigated the determination of a group's  “av-\nerage” emotion state in a video by combining the facial expres-\nsion information of each individual with information obtained \nfrom the upper body and the imaged background scene (Huang \net al., 2018). Again, multimodal data yielded significantly better \nresults than data obtained from individual modalities. \n \n\n196 \n \n \n \nFigure 9.11. Multimodal emotion recognition. \n© [2009] IEEE. Reprinted, with permission, from [Vinciarelli A, Salamin H \n& Pantic M (2009). Social signal processing: Understanding social interac-\ntions through nonverbal behavior analysis. IEEE Conference on Computer \nVision and Pattern Recognition] \nThe best success in recognizing emotions can be achieved by \nlearning, if possible, personal emotion models for each person. \nThis is similar to what was the case with the much easier problem \nof speech recognition. Speaker-dependent, that is, speech recog-\nnition system trained individually by each person's speech sam-\nples is much easier than speaker-independent - and only after \nsignificant improvements through deep learning and massive \ntraining data can speaker-independent recognition be successful \nnowadays. \nThe ways in which people express their emotions vary enor-\nmously, so it is not possible to achieve sufficiently good results \nfor many applications using a common model. Focusing on only \none application can improve recognition. In fact, this has been \ntypical for most machine vision applications. Generally, in a \ngiven application, variations in the imaging conditions can be \nminimized and application-specific test data collected to the wid-\nest possible range of people, and these techniques facilitate anal-\nysis to obtain sufficiently high reliability. \n9.8 \nReferences \nEkman P (2009) Darwin's contributions to our understanding of \nemotional expressions. Philos Trans R Soc Lond B Biol Sci \n364(1535):3449-3451. \nEkman P & Friesen W (1978) Facial Action Coding System: A \nTechnique for the Measurement of Facial Movement. Consult-\ning Psychologists Press, Palo Alto. \nEkman P, Friesen WV & Hager JC (2002) Facial Action Coding \nSystem: The Manual on CD ROM. A Human Face, Salt Lake \nCity. \n\n197 \n \nFeldman Barret L, Mesquita B & Gendron M (2011) Context in \nemotion perception. Current Directions in Psychological Science \n20(5):286-290. \nHuang X, Dhall A, Goecke R, Pietikäinen M & Zhao G (2018) \nMultimodal framework for analyzing the affect of a group of \npeople. IEEE Transactions on Multimedia 20(10):2706-2721. \nHuang X, Kortelainen J, Zhao G, Li X, Moilanen A, Seppänen \nT & Pietikäinen M (2016) Multi-modal emotion analysis from \nfacial expressions and electroencephalogram. Computer Vision \nand Image Understanding 147:114-124. \nLi X, Hong X, Moilanen A, Huang X, Pfister T, Zhao G & Pie-\ntikäinen M (2018) Towards reading hidden emotions: A compar-\native study of spontaneous micro-expression spotting and recog-\nnition methods. IEEE Transactions on Affective Computing \n9(4):563-577. \nMartinez B, Valstar MF, Jiang B & Pantic M (2017) Automatic \nanalysis of facial actions: A survey. IEEE Transactions on Af-\nfective Computing 10(3):325-347. \nMatsumoto D & Hwang HS (2011) Evidence for training the \nability to read microexpressions of emotion. Motivation and \nEmotion 35(2):181-191. \nMehrabian A (1972) Nonverbal Communication. Aldine-Ather-\nton, Illinois: Chicago. \nMcDuff D (2018) Large-scale and longitudinal emotion analy-\nsis. Keynote speech, Workshop on Large Scale Emotion Recog-\nnition and Analysis, Xi’an, China. \nMielonen M (2018) Kaupan myyjä saattaa kohta tunnistaa, \noletko iloinen vai nyrpeä (A salesperson may soon recognize \nwhether you are happy or not). Helsingin Sanomat 29.10.2018.  \nNalbantoglu M (2018) Tulevaisuus tarvitsee lisää empatiaa \n(More empathy is needed in the future). Helsingin Sanomat \n6.11.2018. \nNavarro J (2011) Body language vs. micro-expressions. Psy-\nchology Today Dec. 24.  \nNummenmaa L, Glerean E, Hari R & Hietanen JK (2014) Bod-\nily maps of emotions. PNAS 111(2):646-651.  \nPfister T, Li X, Zhao G & Pietikäinen M (2011) Recognising \nspontaneous micro-expressions. In Proc. International Confer-\nence on Computer Vision, Barcelona, Spain. \nPicard R (1997) Affective Computing. MIT Press.   \nPuttonen M & Heikkinen K (2018) Tunteet tarttuvat herkästi \n(Feelings are contagious easily). Tiede (science) Magazine, \n2018. \nScherer KR, Shorr A & Johnstone T (Eds.) (2001) Appraisal Pro-\ncesses in Emotion: Theory, Methods, Research. Oxford Univer-\nsity Press. \n\n198 \n \nThevenot J, Bordallo López M, Hadid A (2018) A survey on \ncomputer vision for assistive medical diagnosis from faces. \nIEEE J. Biomedical and Health Informatics 22(5):1497-1511.  \nThubron R (2018) Nissan's mind-reading cars can predict driv-\ners' actions. Techspot News 4.1.2018.  \nTiainen A (2018) Mikroilmeet paljastavat tunteitamme, vaikka \nyrittäisimme peittää ne (Micro-expressions reveal our feelings, \neven if we try to hide them). Helsingin Sanomat 22.2.2018. \nVinciarelli A, Salamin H & Pantic M (2009). Social signal pro-\ncessing: Understanding social interactions through nonverbal \nbehavior analysis. IEEE Conference on Computer Vision and \nPattern Recognition, CVPR 2009.  \nZhao G & Li X (2019) Automatic micro-expression analysis: \nOpen challenges. Frontiers in Psychology, 07 August 2019. \nZhao G & Pietikäinen M (2007) Dynamic texture recognition \nusing local binary patterns with an application to facial expres-\nsions. IEEE Transactions on Pattern Analysis and Machine In-\ntelligence 29(6):915-928. \nWeb-Affectiva: This innovative video game can sense your emo-\ntions and respond accordingly \nWeb-Humex (2017) Uusi projekti tutkii tunteita ja vuorovai-\nkutusta työelämässä (A new project investigates emotions and \ninteractions in work life). Helsinki University 5.7.2017. \nWeb-Toys: Emotions at play: the potential for emotion enabled \ntoys, Affectiva \nWeb-TSA: Yes, the TSA is probably profiling you and it's sci-\nentifically bogus. Business Insider, 6.5.2015. \nWiki-Appraisal:Appraisal Theory  \nWiki-Emotion: Emotional Intelligence \nWiki-Tunne: Tunne (Emotion) \n \n \n \n\n199 \n \n \n10 Is Super-intelligence a Threat? \n10.1 Super-intelligence and Risks of AI \nSuper-intelligence refers to an imaginary “agent” that transcends \nthe intelligence of the sharpest and most talented people (Figure \n10.1). It can arise in the context of so-called explosion of intelli-\ngence or similar technological singularity. At that time, the de-\nvelopment of intelligence accelerates beyond the reach of human \nunderstanding (Wiki-Singularity).  \nSome researchers believe that singularity will soon follow the \ndevelopment of generic, human-like artificial intelligence, \nwhich in turn will develop new artificial intelligence solutions. \nDepending on the proposer, the prerequisites for this are some or \nall of the following: \n1. Computers become fast enough, in particular, quantum com-\nputers could contribute to achieving singularity. This think-\ning prevailed when artificial intelligence was seen primarily \nas a combinatorial search problem, and this assumption is \nstill not rare. The central justification is the huge parallel pro-\ncessing capacity of the brain. \n2. The memory capacity of computers becomes adequate, \nwhereby singularity occurs when a sufficient number of neu-\nrons can be realized. It is debatable whether one billion, or \none hundred billion, like in the human central nervous sys-\ntem, or over thousands of billions of neurons is needed. At \nthe same time, of course, the senses with neurons and motor \nabilities should be realized in order for the artificial intelli-\ngence to be able to independently acquire knowledge and ex-\nperience. \n3. Sufficient data and knowledge has been collected, after \nwhich artificial intelligence starts to learn more inde-\npendently. The Cyc project (Wiki-Cyc), which has compiled \na huge set of rules for everyday life, represents this direction. \nThis has been the longest project in the history of artificial \nintelligence. \n4. Significant breakthroughs in artificial intelligence theory are \nachieved for which researchers and developers are needed. \nThis is the \"give us enough money\" justification disliked by \nthe decision-makers. The challenge is that the research \nshould investigate significantly different approaches. The \ncurrent mainstream is to explore the potential of deep convo-\nlutional networks, where deadend can lead to funders' frus-\ntrations with oversized promises and a \"back-winter\" of re-\nsearch. \n\n200 \n \nProfessor Nick Bostrom of Oxford University (Wiki-Boström) \nhas written a bestselling book on super-intelligence called \"Su-\nperintelligence: Paths, Dangers, Strategies\" (Bostrom, 2014). In \nhis book, he wants to replace the sci-fi singularity term with an \nexplosion of intelligence. \n \nFigure 10.1. Do I sometimes get super-smart? (© 123RF) \nHowever, both terms represent a crossing point beyond which \nsociety can no longer be identified due to overwhelming ma-\nchine intelligence. Bostrom, as well as previous singularity pre-\ndictors, led by writer, entrepreneur, scientist, and futurist Ray-\nmond Kurzweil (Wiki-Kurz), Google's technical director, and \nVernor Vinge (Wiki-Vinge), a mathematician, computer expert \nand science writer, see the destiny of mankind to be in the hands \nof smarter machines. \nOne of the key justifications for the predictions has been the \nrapid development of computer components and computer sys-\ntems. Biological neurons operate at speeds of up to 200 Hz, tre-\nmendously slower than modern microcomputers, let alone mod-\nern supercomputers. In addition, human neurons transmit im-\npulse-like signals at a maximum rate of 120 meters per second, \nwhile electronic systems can communicate optically at the speed \nof light. \nComputer memory and computing capacity can be continuously \nincreased as technology advances. The latest quantum comput-\ners under development are believed to lead to the emergence of \nsuper-intelligence. However, along with super-intelligence, \nthere are strong doubts about the introduction of quantum com-\nputers in real life (Dyakonov, 2018). \nBelief in super-intelligence has strengthened with recent ad-\nvances in machine learning. Deep neural networks using massive \ndata have achieved better results in many tasks than with hu-\nmans, as discussed in Chapters 4-5. \n\n201 \n \nThe dangers of artificial intelligence have been the subject of \nmuch debate lately - from threat paintings by physicist Stephen \nHawking and entrepreneur Elon Musk. Bill Gates, too, has been \nconcerned about the result of the super-intelligence. \nThe late Stephen Hawking has argued (2017) that artificial intel-\nligence can replace humans after someone develops technology \nthat is capable of continuously improving themselves. The result \nis a new kind of life. He has argued that artificial intelligence \ncould even be the worst thing that has happened to our civiliza-\ntion throughout its history if we do not learn how to prepare for \nit and avoid potential risks. \nArtificial intelligence could bring threats such as powerful au-\ntonomous weapons or new ways for few to oppress many. It \ncould bring a major disruption to our economy. To prevent this, \n“best practices and efficient management” should be required \nfrom the creators of artificial intelligence. \nElon Musk has argued (2018) that artificial intelligence is more \ndangerous than nuclear weapons and that there should be a con-\ntrolling body watching the development of it. Previously, he has \nalso argued that artificial intelligence is much more dangerous \nthan North Korea and that developments in the industry should \nbe monitored. \nThe authors of this book suspect that the greatest risks of artifi-\ncial intelligence culminate in influencing human behavior. There \nis already evidence of the effectiveness of social media manipu-\nlation using artificial intelligence. \n10.2 Significant Limitations with Current AI \nHowever, it should be noted that most of the strongest critics are \nnot artificial intelligence researchers, meaning that they may not \nbe fully aware of how difficult it is to develop strong artificial \nintelligence in particular. \nIn 1956, it was predicted that after 25 years, people would be \nable to concentrate on leisure activities, as machines do much of \nthe work. However, the development of intelligent machines has \nproven to be much more difficult than we thought: success has \nbeen achieved only in well-defined tasks in weak artificial intel-\nligence - through a major investment in research and develop-\nment. The development of systems with general human-like in-\ntelligence is, according to most researchers, impossible. \nSome critics of artificial intelligence, led by Professor Hubert \nDreyfus already in the 1970s, concluded that it was generally \nimpossible to develop machine intelligence. Human reasoning is \nlargely based on intuition: the inexplicable realization of what \ncoding into a computer program is too difficult to do. It is diffi-\ncult for a machine to cope with tasks that require creativity, ex-\ntensive general knowledge or aesthetic evaluation, knowledge, \n\n202 \n \ncausal evaluation, emotion. He has also argued that because \ncomputers do not have a body, childhood, and cultural practices, \nthey cannot become intelligent (Moreno, 2021). \nProfessor Roger Schank, one of the pioneers of artificial intelli-\ngence research (related to understanding natural language and \ncase-based reasoning), said in October 2018 that artificial intel-\nligence does not even exist at this time. Recent developments in \nhis mind are only about very fast computing (CNN interview Oct \n18, 2018). Only when the machine is able to talk to people in the \nsame way as he talked to a journalist can artificial intelligence \nbe talked about. So, in his opinion, only the so-called strong ar-\ntificial intelligence is real AI. \nAccording to Helsingin Sanomat (Paukku, 2017), another pio-\nneer of artificial intelligence, Patrick Henry Winston (1943-\n2019), who was long the director of the artificial intelligence la-\nboratory at MIT, has said. “When people talk about artificial in-\ntelligence, they actually talk about the computer's raw computing \npower. A machine is not smart if it looks smart. Instead of arti-\nficial intelligence, we should talk about tricks that can be done \nwith a computer.” \nJudea Pearl, the winner of the Turing Prize for Information Tech-\nnology, a pioneer of probabilistic artificial intelligence and a pi-\noneer in causality research, believes that current artificial intelli-\ngence is only a sharpened version of old AI, being able to do \nwhat it has done already a generation ago,  that is, to find hidden \nregularities in a large amount of data (Hartnett, 2018). \n\"All of the convincing achievements of deep learning add up to \ncurve fitting,\" Pearl said. However, he has been impressed by \nhow many problems can be solved simply by fitting curves to \nthe data. \nThe human brain is known to have about 1011 (= 100 billion) \nneurons. Each of these can connect to up to 10,000 other neu-\nrons, carrying messages through up to 1015 synaptic interfaces \n(Web-Memory).  \nOne key factor for unmatched brain performance is their massive \nparallel processing of data with low power consumption (Di-\ncarld, 2018). The average adult power consumption is about 100 \nwatts, and the brain accounts for about 20%, or 20 watts. The \nIBM Watson computer that won the man in the Jeopardy quiz, a \nvery limited issue, claimed 20,000 watts. \nAchieving brain performance as a whole in human intelligence \nin similar tasks to the same power use would require that we be \nable to mimic the structure of the brain well enough with back \nmodeling, through reverse engineering. The development of \nsuch a computer is far in the future, if at all possible. \nNamely, the rest of the human body has a huge amount of neu-\nrons (Figure 10.2) in the senses  transmitting intracellular signals \n\n203 \n \nto the brain. This calls into question the idea of creating super-\nintelligence solely on the central nervous system. How to create \nan entity that can function in its environment? \n \n \n \n \n \n \n \n \n \n \nFigure 10.2. Human nervous system. (© 123RF) \nCurrently, artificial intelligence is mainly based on one algo-\nrithm, i.e. deep learning (Section 4.5) and its variations. In Fig-\nure 10.3. is an example of a typical deep learning convolutional \nneural network. \n \n \nFigure 10.3. Learning with a convolutional neural network. (© \nLi Liu)  \nProfessor Gary Marcus (New York University) has recently pub-\nlished a very interesting and eye-catching article, “Deep Learn-\ning: A Critical Appraisal,” on the limitations of deep learning \nand future challenges of AI (Marcus, 2018). He says deep learn-\ning has led to an undisputed development in many problems, \nsuch as speech recognition, image recognition, and game playing \n- and has aroused enormous interest in artificial intelligence in a \nvariety of media. \nHowever, we are very far from artificial intelligence like human \nintelligence. Expectations have risen too high, and there may be \na \"back winter\" of research again if the over-expectations are not \n\n204 \n \nmet. In his article, Professor Marcus presents ten concerns about \ncurrent deep learning methods (Marcus, 2018): \n1) Deep learning requires a lot of data. People are able to learn \nabstract relationships between objects with a few trials. For \nexample, the word \"teen\" refers to a person between the ages \nof 13 and 19. You can then immediately determine whether \nthere are any teens in your circle of friends.  \nThis learning does not require numerous examples, but the \nability to represent abstract relations with algebra-like varia-\nbles. Humans are able to learn such abstractions as early as \nseven months of age, in a few minutes, from a few examples. \nDeep learning methods lack the ability to learn abstractions \nbased on verbal definition. They work best when there is a \nhuge amount of teaching samples available. \n2) Deep learning is actually low learning and has a limited abil-\nity to move from one problem to another. The word \"deep\" \nprimarily refers to the structure of the neural network, that is, \nhow many hidden layers are used instead of the previously \nused one. Deep learning is in no way capable of handling \nabstract concepts such as \"right\" or \"democracy\", and even \nmore specific concepts such as \"ball\" and \"opponent\" can be \ndifficult to interpret. Transferring a trained deep learning \nmethod to a slightly different problem can be extremely dif-\nficult. \n3) Deep learning lacks a natural way of dealing with hierar-\nchical structures. For this reason, for example, the under-\nstanding of natural language by these methods has not yet \nreached very advanced levels. Most deep learning language \nmodels represent sentences as mere word sequences, \nwhereas in reality, language is largely a hierarchical struc-\nture, where larger structures can be recursively constructed \nfrom smaller components. At the lowest level are phonemes \nand then morphology or combinations of letters or pho-\nnemes. Next are single words and then combinations of \nwords, or syntax. Semantics describes the meaning of an ex-\npression already spoken or written. At the highest level is \npragmatism, which is related to the limitations of how to use \nthe words used and how to interpret the language in different \nsituations. \nProblems similar to those of automatic language interpreta-\ntion are encountered, for example, in routing, scheduling, \netc. tasks, and in robotics. \n4) Deep learning has difficulty with open-ended reasoning \nproblems. For example, Marcus exemplifies the inability of \na machine to distinguish between nuances of, say, \"John \npromised Mary to leave\" and \"John promised to leave Mary\". \n\n205 \n \nAs a result, the machine is unable to determine who is leav-\ning anyone or what happens next. Some progress on such \nproblems has been made recently, but is not even close to \nhuman ability. Reflections on these problems can be seen \nwhen examining, for example, machine translation problems \nfrom Finnish to English or vice versa. \n5) Deep learning is not transparent enough. The methods based \non neural networks work to a large extent as the so-called \n\"black boxes\". Systems contain millions or even billions of \nparameters, the importance of which cannot be well analyzed \nby developers. If deep learning systems work well enough \nand independently in the application, the issue is not very \nproblematic. But for example, in medical diagnoses or busi-\nness applications, the user wants to understand why the sys-\ntem came to a particular solution, or why a self-driving vehi-\ncle crashed. \n6) Deep learning is not integrated with prior knowledge. Cur-\nrent deep learning methods work independently without uti-\nlizing other potentially useful information to solve the prob-\nlem. On the other hand, people use a variety of prior infor-\nmation to solve problems. For example, the use of training \nsamples alone does not adequately solve problems where \nknowledge of the laws of physics is required. \n7) Deep learning lacks the natural ability to distinguish cause \nand effect relationships from correlation. The method is ca-\npable of learning the complex interdependencies between its \ninputs and outputs, but it has no natural way of presenting \ncause and effect relationships, for example, in medical diag-\nnoses of a disease and its symptoms. \n8) Deep learning assumes that the surrounding world is largely \nconstant. The method works best in stable ground conditions, \nsuch as table games where the rules of the game do not \nchange. On the other hand, for example, in politics and eco-\nnomics, the rules are constantly changing. \n9) Deep learning works well as an approximation, but the an-\nswers it gives cannot always be fully trusted. A number of \ncases have been reported, particularly in machine vision, \nwhere deep learning has yielded completely false results. A \nfamous example is where a speed limit traffic sign and a \nthree-dimensional printed turtle are identified as rifles. \n10) Deep learning is difficult to put into practice. It is relatively \neasy to make systems that operate under limited conditions, \nbut it is difficult to guarantee that they will operate under \ndifferent conditions with new data, which may not be remi-\nniscent of prior teaching data. Training, for its part, requires \nexamples where different cases are even in balance. \n\n206 \n \nAs a result of these problems, Professor Marcus suggests that \ndeep learning must be complemented by other techniques in or-\nder to access general artificial intelligence that resembles human \nintelligence. \nDeep neural networks and their variations are currently being re-\nsearched extensively, and at least partial solutions to many of \nthese shortcomings can be found. In any case, it is clear that cur-\nrent networks are very far from being used for deeper, strong \nartificial intelligence. Another major challenge of related re-\nsearch is how to solve computational problems related to deep \nlearning, leading to the need for massive training data, the use of \nultra-fast dedicated processors, and high power consumption. \nThese significantly limit the use of deep learning in, for example, \nmobile devices or smart sensors embedded in the environment, \nwhere the energy consumption must be very low. \nDeep learning works very well with limited problems when there \nis a very large and sufficiently comprehensive supply of natural \ntraining data. There are many such applications as well. How-\never, in many practical problems, huge amounts of training data \nare not available. However, deep learning systems should be able \nto generalize their activities to cases not included in the training \ndata. Even in infancy, people can learn what they see from single \nor a few images without the need for massive amounts of training \ndata. \nIn addition to these, current artificial intelligence is largely tied \nto a specific task or problem: to identify objects, to recognize \nspeech, to make stock price predictions, etc. The human brain is \ncapable of handling a huge variety of tasks, many of them sim-\nultaneously. Again, the artificial intelligence system must be \ntaught to each task individually with a massive amount of train-\ning data. A huge number of separate but cooperative deep learn-\ning networks would be needed to be able to perform tasks that \nresemble everyday human activities. \n10.3 Artificial vs. Human Intelligence \n In order for a machine to have strong artificial intelligence like \nhuman intelligence, the following capabilities would be needed: \n- \nHow do you make your machine think? Current artificial in-\ntelligence is at its best in machine sensing, but the machine \ncannot think. \n- \nHow do you get the machine to do many different tasks like \nmany people do, often at the same time? \n- \nHow do you make your machine learn and improve through \nexperience as people do? \n- \nHow do you get the machine to justify its decisions, which \nare necessary in many applications, such as medicine, busi-\nness applications - and self-driving vehicles? \n\n207 \n \n- \nHow do I make a machine work in a changing operating en-\nvironment without re-training it? How to make the machine \nwork even in simple everyday tasks (Figure 10.4)? \n \nFigure 10.4. Kitchen robots have been awaited. (© 123RF) \n- \nHow can the machine understand spoken and written lan-\nguage and learn with their help as people learn? \n- \nHow can you make the machine learn how to recognize ob-\njects from one or a few sample images, as little children can \ndo? The brain also uses cognitive functions of more general \nform than deep nets to interpret images. \n- \nHow does the machine gain the ability to understand causal-\nity, i.e. cause-effect relations? For example, why did the \nmedical diagnosis program end up with the reported result? \nWhy is the economy projected to evolve as predicted by an \nartificial intelligence program? \n- \nHow do I get the machine to design complex tasks and \nchange plans during execution? For example, to change the \nintended route of the car when the situation changes abruptly \nand prevent you from colliding with a reindeer that appears \nin front of the car. \n- \nHow to bring to the machine consciousness, which refers to \nthe totality of the senses, experiences, feelings, memories \nand thoughts that an individual experiences at any given mo-\nment, or the individual's awareness of themselves and their \nenvironment (Wiki-Consciousness).  \n- \nHow could you get an original human-like creativity on the \nmachine? \n- \nHow do you get the machine to feel? People are very sensi-\ntive and emotional, they see, hear, think and feel - and emo-\ntions guide their thoughts. \n- \nHow can you make a machine evaluate moral issues, for ex-\nample, what is right and wrong? \n- \nHow does the machine get the intuitive ability typical of the \nhuman brain? Intuition means knowing or understanding \nwhere information comes directly from an object or event - \nnot by reasoning. For example, for some reason, the path of \n\n208 \n \nthe walk is changed from normal and then something surpris-\ning happens, or think of a person and he or she will call. It is \noften referred to as the \"sixth sense\". \n- \nHow do you implement computers that use massive parallel \ncomputing with low power consumption like the human \nbrain? \nIt would be very expensive to develop and maintain systems with \nthe above features and sufficient reliability. From infancy, a per-\nson can identify new objects he or she has seen on the basis of \njust a few examples, learn the interdependencies between objects \nand things, learn to speak, read and understand language, walk, \ninteract with other people, etc. Artificial intelligence is far from \nthis! \nIn conclusion, the imagined super-intelligent systems in Figure \n10.5 seem impossible to implement based on current knowledge. \nWe believe that artificial intelligence is above all a human \nhelper, does not control him. Semi-autonomous vehicles facili-\ntate driving and traffic, search for suitable driving routes and pre-\nvent accidents. Artificial intelligence helps doctors diagnose dis-\neases, not replace them. It helps people in their daily lives and \nhelps them to interpret the massive amount of data, for example \nin corporate decision-making. \n \nFigure 10.5. Imagined super-intelligence. (© 123RF) \nMachines can also show primitive creativity, such as giving art-\nists new tools to help them work. Emotions play a central role in \nhuman-to-human communication. We will soon be able to utilize \nelementary “emotional intelligence” in human-machine interac-\ntion, and research on this is also being carried out in our own \nresearch unit. \nIn the words of Patrick Henry Winston, as mentioned earlier: “A \nmachine is not intelligent if it looks intelligent. Instead of talking \nabout AI, we should talk about the tricks that a computer can \n\n209 \n \ndo.” You can teach a machine good or bad things. If a person \ndisplays images of violence on the machine, the machine learns \nto recognize them. Weapons have used machine vision and other \nsensory information, for example, in the search for and tracking \nof targets long ago. Artificial intelligence techniques can also be \napplied to decision-making in \"smarter\" weapon systems, if de-\nsired. As technology advances, smart features will be added to a \nwide variety of applications and systems, but humans are their \ndevelopers, not artificial intelligence. \n10.4  How from Now on Towards Strong AI? \nDue to the shortcomings of current deep learning methods, there \nhas recently been a growing debate about what to do after deep \nlearning (Vorhies, 2018). In this regard, limitations of the back-\npropagation algorithm, for example, in relation to its requirement \nfor differentiation, have been disclosed. This means that the par-\ntial derivatives of the function being modeled are assumed to be \ncontinuous at each point. \nEven Geoffrey Hinton, a pioneer in deep learning, has taken part \nin this discussion and presented a solution called Capsule Net-\nworks (CapsNet), for such as image classification. The aim is, \nfor example, to reduce the enormous need for additional training \nmaterial for variations in the position, size, distortion, color, tex-\nture, etc. of objects in the image, particularly in the case of three-\ndimensional machine vision problems (see Chapter 6). The \nmethod adds new layers inside individual network layers to in-\ncrease invariance to the above image transformations and \nthereby significantly reduce the amount of training material \nneeded. By comparison, a person is often able to recognize an \nobject even if he has only seen it from one angle. \nAn interesting solution is the gcForest technology introduced by \nprofessor Zhi-Hua Zhou (Zhou & Feng, 2017). In his research, \nhe has shown that so-called gcForest, a method based on forest \nsearch, regularly wins CNN and RNN in both text and image \ncategorization tasks and has many significant advantages over \nthe above methods: \n- \nThe complexity of the model is adaptively determined by the \ndata, \n- \nrequires only a fraction of the training data needed by CNN \nand RNN, \n- \ncan be run only on a central processing unit (CPU) without \nGPU high-performance processors, \n- \nteaching is as fast or often faster and well adapted to distrib-\nuted computing, \n- \ncontains much less so-called hyperparameters and works \nwell with default settings, \n- \nis based on easy-to-understand random trees, as opposed to \ncompletely opaque neural networks. \n\n210 \n \nIn summary, gcForest (multigrained cascade forest) is a decision \ntree based ensemble classifier that preserves the sequential struc-\nture of deep networks but replaces opaque neurons with groups \nof random forests combined with fully random decision trees \n(see Section 4.3). \nHow, then, can the artificial intelligence system gain more hu-\nman-like features, expand its application capabilities, and move \ntoward strong artificial intelligence? You can get some guidance \non this by looking at some of the ideas of the artificial intelli-\ngence experts. \nAs early as 1990, late Marvin Minsky, one of the most prominent \nresearchers in the history of artificial intelligence, argued that in \norder to develop truly intelligent systems, it would be necessary \nto integrate neural or other massive parallel computing and sym-\nbolic data processing traditionally used in artificial intelligence \n(Minsky, 1990). \nNeural computing can cope well with, for example, pattern \nrecognition and knowledge gathering, but so-called symbolic \nsystems are needed for high-level thinking, such as goal-based \nreasoning, structuring things, and exploring cause and effect re-\nlationships. How to implement such an integrated system was, in \nMinsky's opinion, the greatest challenge for research. The con-\nclusion of the first author of this book, based on his experience, \nwas largely similar to that in his professorship’s inaugural \npresentation “Artificial intelligence developers are facing great \nchallenges” (Pietikäinen, 1992). \nZeeshan Zia, an artificial intelligence researcher working at Mi-\ncrosoft , has largely agreed with Minsky in his comments. In his \nview, the three main research themes for the coming decades are: \n1. Combining paradigms based on symbolic computation, \nprobabilities and deep learning. At the highest level of \nawareness, we think with symbols. How would you describe \na food recipe, for example? How do you communicate math? \nHow do you decide how to move from one place to another? \nSymbol processing is central to any general intelligence that \nresembles human intelligence. \n2. Sensors produce noisy data and our world models are noisy. \nGraphical likelihood models have been very useful in mod-\neling many practical problems, especially if there are few \nrandom variables or a large amount of domain knowledge is \navailable. In addition, such models are much easier to under-\nstand than deep learning models. Current causal modeling \ntools aiming for cause estimation are based on probabilities. \n3. Deep neural networks are particularly useful in lower level \npattern recognition problems, such as machine vision, speech \nrecognition and, increasingly, limited interpretation of natu-\nral language. Professor Andrew Ng, one of the leading re-\nsearchers in deep learning, has suggested that the intellectual \n\n211 \n \ntasks that a person can do in less than a second are ideal for \nneural networks. \nHowever, this is not entirely true. Deep learning works well \nwhen there is a very large and sufficiently wide range of natural \ntraining data available. In many practical problems, a huge \namount of instructional data is not available. Already in infancy, \npeople are able to learn what they see from single or a few pic-\ntures \nSridhar Mahadevan, who heads the Data Science Lab at the \nAdobe Research Center, says that artificial intelligence is now \ndominated by the data science / machine learning / deep learning \nparadigm. Everything starts with data and we should now get off \nit to the next paradigm. The data cannot provide an explanation \nof the events that would be necessary, especially in many critical \napplications, such as self-driving accidents or incorrect X-ray di-\nagnosis of cancer. Why did the system malfunction? \nIn his view, the necessary explanation cannot be obtained from \nmachine learning systems, but \n1. A combination of statistical and symbolic reasoning is \nneeded. \n2. Nor can statistical reasoning produce causal explanations, as \nhas been shown many years ago. Causal reasoning explores \n“what-if” type questions. For example, what happens if the \nUS raises steel tariffs? Data science cannot answer this, but \nneeds to know what the consequences of the operation are \nand the countermeasures of other countries. \n3. Data represents what has happened, that is old news. Many \napplications do not yet have all or sufficient data for learning, \nsuch as automatic car steering in all circumstances. Figure \n10.6 depicts multidimensional data, from which explanations \nare searched for phenomena. \n \nFigure 10.6. Visualized data structures. (© 123RF) \nProfessor Yoshua Bengio, a pioneer in deep learning, wants to \nbuild artificial intelligence at the heart of deep learning, but it \nshould be expanded to include reasoning, causal learning, and \nexploring the surrounding world for machine learning and intel-\nligence (Knight, 2018). “We would need to face the tough chal-\nlenges of artificial intelligence and not be content with short-\nterm incremental development. If you really want to approach \n\n212 \n \nthe level of human intelligence, this is a different game, and ac-\nademic research is better off carrying that torch.” \nFei-Fei Li, a Stanford University professor and also with \nGoogle,  known as the mother of the vast ImageNet image data-\nbase that provided a breakthrough in deep learning, has sug-\ngested that humans should now be brought more in the center of \nartificial intelligence (Knight, 2017). “The excellence of today's \nartificial intelligence is largely pattern recognition, which is very \ntask-oriented. It lacks awareness of contextuality (the connec-\ntions between things) and the flexible way people have to learn. \nWe want to create technology that makes people's lives better, \nour world safer, and our lives more productive and better. To \nachieve this requires understanding of contexts like human intel-\nligence, abstracting knowledge and reasoning.” \nProfessor Judea Pearl, a pioneer in causal cause-effect research, \nhas said that artificial intelligence has completely forgotten what \nintelligence really is (Hartnett, 2018). Only when the machine is \ncapable of analyzing cause-effect relationships and answering \nthe question Why?,  can real artificial intelligence be talked \nabout. \"Instead of finding only a correlation between malaria and \nfever, the machine should be able to conclude that malaria is \ncausing fever.\" \nCausal reasoning is at the heart of human intelligence and pro-\nvides the basis for scientific thinking and reasoning, but in sci-\nence it is largely forgotten - even if compared to statistics and \nprobabilities. Pearl has recently written a book entitled \"The \nBook of Why: The New Science of Cause and Effect\" (Pearl & \nMackenzie, 2018). \nBrent Oster, who has been for four years at Nvidia, a company \nspecializing in high-performance artificial intelligence hard-\nware, has worked on hardware architectures and methodologies \nrelated to deep learning implementations (more recently he has \nbeen heading ORBAI - Artificial Intelligence and Robotics com-\npany). He believes that we can get closer to strong AI only by \nimplementing systems much more resembling the structure and \nfunction of the human brain (Oster, 2018). \nOster has potential long-term solutions to this issue. Current ma-\nchine learning, often also referred to as artificial intelligence, is, \nin his view, merely a matter of adapting very large functions to \neven larger sets of data so that these functions can predict future \ndata. In his view, the word \"neural\" and even less the word \"ar-\ntificial intelligence\" should not be used in this context. Existing \n\"neural networks\" and \"neurons\" are in structure and function \nsimply a small subset of a much broader and richer family of \nsynthetic neurons, neural networks, and methods. \n\n213 \n \n10.5 References \nBostrom N (2014) Superintelligence: Paths, Dangers, Strategies. \nOxford University Press, 352 p. \nDicarld JJ (2018) To advance artificial intelligence, reverse-en-\ngineer the brain. Wired, 2.3.2018.  \nDyakonov M (2018) The case against quantum computing. IEEE \nSpectrum, November 2018.  \nHartnett K (2018) To build truly intelligent machines, teach them \ncause and effect. Quanta Magazine. \nKnight W (2017) Put humans at the center of AI. MIT Technol-\nogy Review, October 9, 2017. \nKnight W (2018) One of the fathers of AI is worried about its \nfuture. MIT Technology Review, November 17, 2018. \nMarcus G (2018) Deep learning: A critical appraisal. \narXiv:1801.00631 \nMinsky ML (1990) Logical vs. analogical or symbolic vs. con-\nnectionist or neat vs. scruffy, In Artificial Intelligence at MIT, \nExpanding Frontiers, Patrick H. Winston (Ed.), Vol.1. MIT \nPress, 1990. Reprinted in AI Magazine, Summer 1991. \nMoreno A (2021) 5 reasons why I left the AI industry. Towards \nData Science, April 5.  \nOster B (2018)   Is machine learning anything more than an au-\ntomated statistician? Quora blog, October 4, 2018.  \nPaukku T (2017) Tekoälyn viisasten kivi on superäly (The phi-\nlosopher’s stone of AI is super-intelligence).  Helsingin Sanomat \n20.6.2017. \nPearl J & Mackenzie D (2018) The Book of Why: The New Sci-\nence of Cause and Effect. Basic Books, 432 p. \nPietikäinen M (1992) Tekoälyn kehittäjillä mittavia haasteita \n(The developers of AI face major challenges). AKTUUMI, Uni-\nversity of Oulu  4:23-28. \nVorhies V (2018) What comes after deep learning. Data Science \nCentral blog.  \nZhou Z-H & Feng J (2018) Deep forest. arXiv:1702.08835v3. \nWeb-Memory: Human memory \nWiki-Boström: Nick Bostrom \nWiki-Consciousness: Consciousness \nWiki-Cyc: Cyc \nWiki-Kurz: Raymond Kurzweil \nWiki-Singularity: Singularity \nWiki-Vinge: Vernor Vinge \n \n\n214 \n \n11 Summary - Does the AI Hype Continue? \n11.1 Artificial Intelligence Today \nArtificial intelligence research has been promising big for over \n60 years. Numerous simulated and real-world toy demonstra-\ntions have been implemented in laboratories to demonstrate au-\ntomatic environment modeling and behavioral learning, but the \ndemonstrations have been scaled weakly to a larger scale, and \nrobots have been left unused. \nIn recent years, machine learning and artificial intelligence ap-\nplications have finally begun to come to the surface of everyday \nlife. The development is largely due to advances in computer \ntechnology. The Internet has provided the opportunity to acquire \nmassive data sets and thus supported the development of meth-\nodology, away from limited laboratory environments. At the \nsame time, there has been tremendous progress in the develop-\nment of hardware support for machine learning methods and the \nuse of masses of data. Chapters 5 and 6 included examples of \napplications, including real success stories. All related to the so-\ncalled weak artificial intelligence, that is, limited application \nproblems. \nOne advantage of computers over humans is the ability to re-\ntrieve and recall vast amounts of information that can be ac-\ncessed quickly, for example, via the Internet. The machine does \nnot get tired and can work 24 hours a day. If the data is of suffi-\ncient quality, the machine can outperform human performance \nin limited machine learning tasks. However, too little attention \nis often paid to gathering, naming, and modifying good quality \ndata for machine learning, although the performance of these \nmethods is largely dependent on it. Typically, such data pro-\ncessing requires up to 80% of the workload required to apply \nmachine learning. \nDue to its speed and other capacity, the machine is also able to \ncombine data from different sources in an unprecedented way. \nSection 5.5 provided an example of a study which found that hu-\nman happiness is reduced due to air pollution (Junttila, 2019). \nCountless applications of this kind can be found, and the data \nused for either good or bad purposes. If the information to be \ncombined is not only somebody's behavior, but also, for exam-\nple, a person's Internet searches, shopping purchases, health rec-\nords and bank information, it is possible to create dangerously \naccurate profiles of people. The biggest threat posed by artificial \nintelligence is probably people's own behavior, that is, how \nmuch we give our private information to everyone without pro-\ntection, for example through social media. \nMachine vision is an area for which numerous industrial appli-\ncations have been developed for a long time, beginning with the \nrecognition of machine-typed characters and the visual quality \n\n215 \n \ncontrol of  industrial products in the 1980s or earlier. Image or \nvideo search from databases, biometric identification, and video \nsurveillance are examples of major applications in recent years. \nNew and more demanding applications are constantly being \nfound, for example in intelligent human-machine interfaces. \nRobotics and automation are widespread applications where in-\ntelligent functions have been introduced for a long time, such as \nautomotive assembly tasks, which were already used in the \n1980s. With the recent advances in technology, artificial intelli-\ngence can be applied to more everyday tasks to replace routine \nwork or to create entirely new opportunities, such as improving \nthe quality of life of the elderly or disabled. \nEvolving technology, artificial intelligence, and robots cannot, \nof course, substitute for immediate human contact, but can bring \ntremendous benefits to the elderly or ill living alone at home, \nwhether through constant face-to-face communication with \nfriends and relatives, searching the Internet for other entertain-\nment, shopping, on-line health monitoring and telemedicine ser-\nvices, housekeeping and other assistive services, or virtual travel \naround the world. Artificial intelligence, machine senses and ro-\nbotics help the visually impaired see, the hearing impaired hear, \nwheelchair users to move semi-autonomously, and each person \nto constantly monitor their fitness and health. \nAn interesting example of the near future of autonomous \ntransport is the self-propelled container ship designed by Norwe-\ngian fertilizer giant Yara for fjord transport (Aittokoski, 2018a). \nThe loading system planned in Finland is also becoming auton-\nomous. The same article also mentions, e.g., an autonomous train \nin Australia to rail ore transportation. These are good examples \nof limited application areas where even full self-steering can be \nachieved, unlike unlimited road transport. The role of artificial \nintelligence in these is not the key, but part of automation solu-\ntions that have evolved over the years. \nParticularly significant progress has been made in speech recog-\nnition during the past decade. Until a few years ago, recognition \nwas too unreliable for most applications and sensitive to envi-\nronmental noise. Today, the point has been reached that speech \nrecognition is gaining a very central role in human-computer in-\nterfaces. One of the first examples of this development is already \nhaving a reliable Google search by voice, for example in Finnish \nor English. Leading artificial intelligence companies have in-\nvested tremendously in voice recognition technology and have \nlaunched personalized assistants based on it. An example of a \nnew Finnish application is the recognition of dictations of doc-\ntors directly to the text in the Hospital District  of Helsinki and \nUusimaa (Tammi, 2018). Considerable progress has also been \nmade in language translation, with Google Translate as a signif-\nicant example. \n\n216 \n \nSuccess has also been achieved in other applications where mass \ndata is inherently used. For example, information on a large pop-\nulation of symptoms of various diseases can be used to teach the \nsystem to make fairly good predictions based on symptoms. \nGoogle is said to have been able to make predictions based on \nsearch data for years, with reasonable accuracy, including the \nspread of the flu and other viruses. \nArtificial intelligence has also been successfully applied to real-\nlife music and poetry, in which there is a wealth of prior example \ndata. The article “Sibelius or Homo Deus?” shows readers how \nto make a computer compose like Jean Sibelius (Sirén, 2019). \nHowever, composing on the basis of artificial intelligence just \nimitates the style of the composers, said Esa-Pekka Salonen in \nan interview with Ykkösaamu on May 18, 2019. Independent, \nfrontier and offensive compositions that humans have not been \nable to do, machines have failed to create. \nAt its best, artificial intelligence is used in applications that do \nnot require accurate results and the machine does not have to \nmake an actual decision, create a new one or diagnose it. On the \nother hand, “at its worst, artificial intelligence can recommend, \nfor example, treatments that are unrelated to the patient's medical \ncondition in any way,” says Senior Physician Päivi Ruokoniemi \nin an article in Helsingin Sanomat (Ruokoniemi, 2018). \nArtificial intelligence has the ability to adapt machines to hu-\nmans more than humans to learn new technology. Impact could \neven extend to the evolution of the provision and delivery of so-\ncial and health services. This requires a growing role for users in \ndeveloping and adapting systems. Thus, for example in the field \nof public software procurement, learning artificial intelligence \ncan be one way of transforming non-recurring, delayed and out-\ndated solutions into continuous development. \nLike other technologies, artificial intelligence can also be inten-\ntionally misused by its practitioners. Machine learning works ac-\ncording to what kind of data is being fed to it. If learning is based \non false and untruthful data, the results can be misused. Another \nworrying example is the use of Facebook data for profiling peo-\nple by Cambridge Analytica, selling the information to outsiders, \nand thereby influencing the election with negative profile-spe-\ncific campaigns such as anti-immigration messages or undermin-\ning the political opponent. \nIt is also problematic to make false pictures and videos using \ncomputer vision and machine learning techniques. For example, \nthe face of a certain politician is made to speak naturally in a \nspeech by another person, such as an actor. In the Fall of 2018, \nthere was an incident leading to a temporary ban on a White \nHouse reporter for the CNN television station, whose video was \nartificially speeded up so that the reporter appeared to be grab-\nbing the person taking the microphone. \n\n217 \n \nFacial recognition is one of the most advanced artificial intelli-\ngence applications today. Due to the large number of applica-\ntions, a great deal of effort has been invested in research in this \nfield. Deep learning and easy access to mass data for developers \nof various services (e.g. Google, Facebook, Baidu) have signifi-\ncantly accelerated development in recent years. \nSection 8.2 looked at face analysis and its application to bio-\nmetric identification from the perspective of our own research. \nLike many other technologies, face recognition can also be mis-\nused. For example, large numbers of CCTV cameras have been \ninstalled across urban areas, and the misuse of the information \nthey provide clearly endangers privacy. This is also exacerbated \nby the fact that face recognition is not reliable enough in chang-\ning environmental and imaging conditions, so there is a high po-\ntential for misinterpretation. The greatest risk of error is in ap-\nplications that try to find criminals or other persons considered \nto be dangerous for the society in a watch list on videos taken by \na surveillance camera (Laperruque, 2018). \nInternational technology leaders in artificial intelligence have an \nenormous amount of data that they collect from their clients. \nThey also have huge computing resources and cloud services un-\nder their control. With their very large computing resources, \nthese companies are able to demonstrate impressive application \nexamples, which, however, may still be far from real real-world \napplicability. \nExamples include Go board game AlphaGo (Paukku, 2018a) de-\nveloped by DeepMind, winner of the human world champion, \nand Nvidia’s system generating unknown face images (Paukku, \n2018b). These achievements receive extraordinary attention in \nthe media, and thus increase the hype of artificial intelligence - \nand the market for companies that have developed them. The \nface-generating method is currently based on GANs (Generative \nAdversarial Networks) of high interest, which have two compet-\ning networks (see Section 4.9): one responsible for generating \n(images that look natural), and the other rating the content (does \nthe generated image look natural?) (Goodfellow et al., 2014). \nA significant part of the development of machine learning appli-\ncations currently being carried out in Finland relies on the ser-\nvices of technology leaders. However, their use may be rela-\ntively expensive and may involve security risks. Nor are they al-\nways available. The best chances for Finnish companies to suc-\nceed are in their own products, in new niche applications that \naren't of interest enough to AI technology leaders, and in various \nservices. \nHowever, artificial intelligence and machine learning are in \nthemselves massive problems: millions of years of evolution are \nbeing sought to be quickly automated. Sometimes disappoint-\nments will inevitably arise, as research is working on single-goal \n\n218 \n \ndevelopments, even though it is a multi-objective entity, which \nmay require evolutionary methods to combine, select, and un-\nderstand the features of solutions as humans become overwhelm-\ning. Technology developers usually have a horizon-biased style \nof \"total solution is around the corner\" and this is also true for \nmachine learning and artificial intelligence. \nThus, it would be better to focus on limited application problems \nwith weak artificial intelligence, where artificial intelligence is \nmore like a human assistant. not a ruler. The term augmented \nintelligence is often used in this context. The hype surrounding \nartificial intelligence could also be reduced by using a more ap-\nplication-oriented term machine intelligence instead of artificial \nintelligence, without even having to compare human intelli-\ngence. It can be expected that such machine intelligence will be \nmore and more normal in the future integrated with other tech-\nnology, improving the adaptability of applications to new situa-\ntions, functionality and usability. \nIn this sense, this is a normal phase of technology development, \nwith new solutions being introduced and no longer even talking \nabout artificial intelligence. With the advancement of research \nand technology, we can better respond to the great challenges of \nartificial intelligence, etc., and provide systems with more hu-\nman-like features. \n11.2 Prospects and Challenges for AI \nBy integrating various technologies related to artificial intelli-\ngence, such as masses of data, machine learning, speech, natural \nlanguage interpretation, machine vision, and robotics, very new \ntypes of applications can be created. A futuristic example is the \nsocial humanoid robots which imitate humans, receiving consid-\nerable attention from  the media, such as the Sophia robot devel-\noped by a Hong Kong company (Wiki-Sophia) (Figure 11.1).  \n \nFigure 11.1. Sophia robot. (© 123RF) \nCombining several types of weak artificial intelligence features \n(for example, vision, hearing, touch, speech, face animation) into \nthe same system and application may be an area where astonish-\ning results can be achieved as technology advances in the future. \n\n219 \n \nOur networked society could also allow to use so-called collec-\ntive intelligence provided by multiple weak artificial intelligence \ncomputers, possibly at different location, to solve highly \"com-\nplex\" AI problems (Wiki-Collective). \nFinland's success in artificial intelligence requires not only in-\nvesting in applications but also investing heavily in long-term \nresearch in the field in order to produce sufficiently original so-\nlutions. Education also plays a key role in success. There is a \nneed for both improving citizens' data literacy and training for \nartificial intelligence specialists. Those specializing in artificial \nintelligence should take a broad approach to the field, ranging \nfrom mathematics, programming skills, to both traditional and \nnew methods of artificial intelligence and data analysis. \nThe next big step in artificial intelligence requires a reassessment \nof existing methodological and implementation solutions. In \nmany applications, massive data is either unavailable or too ex-\npensive to obtain. Artificial intelligence focused on machine \nlearning, and deep learning in particular, is vulnerable to adver-\nsarial attacks in which the system is fed with incorrect teaching \ndata that does not resemble the right, unnoticed by the eyes or \nother senses (Heaven, 2019). \nThis is a major threat in many key applications, such as medi-\ncine, self-driving vehicles, and AI based weapon systems (Fin-\nlayson et al., 2019). Too much reliance on the services of tech-\nnology leaders is expensive and can put security at risk. There \nare also opportunities for small internationally networked econ-\nomies for new types of artificial intelligence based business \nmodels. \nThe widespread adoption of artificial intelligence in societies re-\nquires people to have confidence in this technology. The ethical \nissues of artificial intelligence related to this are beginning to re-\nceive increasing attention in various communities (Wiki-Ethics), \n(Web-ECStrategy). Confidence is diminished, for example, by \nthe fact that if a machine learning method is trained with incom-\nplete “biased” material, the results it gives may be incorrectly \nweighted. It has been observed, among other things, that some \nfacial recognition methods have not worked as reliably for the \ncolored population, as their share of the teaching material has \nbeen too small. Similar examples have also been found in medi-\ncal applications, for example. \nAccording to leading researcher Ilkka Tuomi (Tuomi, 2019), in-\ncreasing energy consumption means that only a few developers \nof artificial intelligence models can keep up with the develop-\nment. The energy consumed by the best (and deepest) deep \nlearning models has increased tenfold each year in the 2010s. \nGoogle, Facebook and other leading artificial intelligence com-\npanies are already the world's largest users of renewable energy \n\n220 \n \n- and as the trend continues, wind and solar power may not be \nenough for others in the near future. \nSweden has long been a trendsetter in the provision of global \nInternet services in the Nordic countries, not least thanks to \nSkype, Spotify and Klarna. The background is probably a well-\nestablished culture of international trade. Similarly, in Finland, \nshould we seek the foundation for artificial intelligence in our \nstrong communications and information technology skills? Ad-\nvances in information and communications technology and elec-\ntronics are, by and large, leading to ultra-dense networks. Such \ndevelopmental pathways include, for example, the increasing \nuse of proximity electronics such as activity and health bracelets \nand rings. Similarly, we see networked wireless technology in-\ncreasingly invading applications in buildings, machinery, equip-\nment, industrial production and pets, and so on. \nAs a result, the amount of data collected alone is increasing tre-\nmendously, with personal data protection issues being chal-\nlenged by the concentration of data and analytics on data centers. \nOn the other hand, information from technical sources is rarely \ncategorized, as opposed to, for example, images entered by peo-\nple into Internet services. This challenges the development of ar-\ntificial intelligence applications based on current machine learn-\ning. \nAccording to many estimates, artificial intelligence and machine \nlearning will increasingly shift to so-called edge and fog compu-\nting (Figure 11.2). At that time, services that require heavier \ncomputing and analytics are provided at wireless base stations or \neven in a decentralized collaboration between measurement \nnodes, mobile phones, vehicles, and other terminals.  \n \nFigure 11.2. Fog computing is highly distributed. (© 123RF) \nThis improves reactivity, robustness and data protection by drop-\nping the role of centralized resources, but challenges machine \nlearning: there is less data available, and procedures based on \ndeep neural networks are clearly in difficulty. \n\n221 \n \nThus, instead of using methods that require large classified data, \nresearchers should aim for solutions that learn from limited sam-\nple sizes. As a practical result, we can, for example, obtain dis-\ntributed dynamic data search engines from which we can ask \nabout information changes. \nOn the other hand, ultra-dense network terminals will increas-\ningly operate with help of their environment by collecting energy \nwithout needing batteries or external power supply. It should \nalso be possible to reduce energy consumption to curb climate \nchange. Thus, both computing and memory use must be energy \nefficient. Excessive power consumption prevents the develop-\nment of many applications, such as smart sensors embedded in \nmobile devices, smart glasses, smart watches, or intelligent sen-\nsors embedded in the environment. \nAchieving fast-learning and low-energy artificial intelligence re-\nquires investment in research into effective presentations. For \nexample, LBP-like or other neural network methods using bi-\nnary-formatted data could bring significant efficiency improve-\nments. Indeed, research funders need to understand the need to \nsupport both the development of energy-efficient learning algo-\nrithms using traditional information technology and solutions \nbased on new methods. \nA very hot area of near future research is machine learning with \none or at most a few training samples (so-called one or few shot \nlearning), as people learn many things. A simple example is the \nBayesian program learning mentioned in Section 3.4 (Lake et al., \n2015). With such methods, new wireless communication tech-\nnologies support the embedding of artificial intelligence in the \nhuman immediate environment instead of Internet giant data \ncenters. Indeed, the IT pendulum may swing once again from a \nfocus on decentralization. \nContinuous learning of the new without forgetting previously \nlearned knowledge is central to human intelligence, but artificial \nintelligence lacks such an ability. This topic is also a new, very \nimportant area of research in artificial intelligence. In this con-\ntext, the terms “continual learning” or  life-long learning” are \nused (Wiki-ContinualAI) (Jha 2020). \nArtificial intelligence systems must be able to justify to the user \nthe reasons for their decision, i.e. why, for example, it ends up \ndiagnosing a particular disease on the basis of the information \ntaught to it. Rationale for decisions is particularly important in, \nfor example, medical applications, self-driving vehicles and mil-\nitary applications. However, systems based on machine learning \nlack the ability to justify - for the user (or other programs) they \nappear as “black boxes”. Explainable AI is a very topical re-\nsearch area in this regard. For more information, see (Wiki-Ex-\nplainable AI) and (Web-DarpaXAI). \n\n222 \n \nThe ability to analyze cause-and-effect relationships (i.e., cau-\nsality) is also seen as one of the key elements in creating stronger \nartificial intelligence. Section 10.4 already mentions the state-\nments of the  pioneer, Professor Judea Pearl. An introduction to \nthe topic from the perspective of artificial intelligence and appli-\ncations can be found, for example, in references (Gontalonieri, \n2020) and (Dickinson, 2021).  \nStrong artificial intelligence resembling human intelligence is \nstill a long way off. Today's artificial intelligence is seen as a \nsharpened version of what artificial intelligence was long ago.  \nThe next step requires a re-evaluation of the fundamentals of ar-\ntificial intelligence and a combination of different approaches - \nfor example, combining neural network methods that use con-\nnectionist pattern recognition and methods that handle symbolic \ninformation. The Neuro-Symbol Concept Learner program, an-\nnounced by MIT, IBM and DeepMind in the spring of 2019, is \nan interesting step in this direction. It learns a greatly simplified \nversion of its surroundings in a child-like way, looking around \nand talking (Knight, 2019).  Artificial intelligence similar to hu-\nman intelligence would require much more brain-like systems in \nstructure and function to overcome enormous methodological, \ncomputational, and power consumption challenges (Ideami J, \n2021), (Oster, 2018). \nThe reference (Romero, 2021) examines the views of several AI \nexperts on how deep learning could be taken to the next level, \ntowards truly intelligent systems: Convolution networks (CNNs) \nand their limitations, as well as pre-labeled teaching data, should \nbe eliminated using unsupervised training instead of supervised; \nmove to hybrid models using symbolic processing and deep \nlearning; incorporate cognitive characteristics into systems; and \nleverage ideas and the latest findings from neuroscience and hu-\nman brain research. \n11.3 References \nAittokoski H (2018a) Norja seilaa itseohjautuvaan tulevaisuu-\nteen (Norway is sailing towards a self-guiding future).  Helsingin \nSanomat 19.9.2018. \nDickinson D (2021) Why machine learning struggles with cau-\nsality? TechTalks Blog 15.3. 2021.  \nFinlayson SG, Bowers JD, Ito J, Zittrain JL, Beam AL & Kohane \nIS (2019) Adversarial attacks on medical machine learning. Sci-\nence 363 (6433): 1287-1289. \nGoodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley \nD, Ozair S, Courville A & Bengio Y (2014). Generative adver-\nsarial networks. Proceedings of the International Conference on \nNeural Information Processing Systems (NIPS 2014), 2672-\n2680. \n\n223 \n \nGontalonieri (2020) Introduction to causality in machine learn-\ning. Towards Data Science, July 9, 2020. \nHeaven D (2019) Deep trouble for deep learning. Nature \n574:163-166, 10.10.2019. \nIdeami J (2021) Towards the end of deep learning and the begin-\nning of AGI. Towards Data Science. March 2021. \nJha S (2020) Continual learning - where are we? Towards Data \nScience 17.9.2020. \nJunttila J (2019) Puhdas ilma lisää onnellisuutta (Clean air in-\ncreases happiness). Helsingin Sanomat 24.1.2019. \nKnight W (2019) Two rival AI approaches combine to let ma-\nchines learn about the world like a child. MIT Technology Re-\nview, 8.4.2019. \nLake BM, Salakhutdinov R & Tenenbaum JB (2015) Human-\nlevel concept learning through probabilistic program induction. \nScience 350(6266):1332-1338 1332.  \nLaperruque J (2018) Unmasking the realities of facial recogni-\ntion. Project On Government Oversight POGO 5.12.2018.  \nOster B (2018) Is machine learning anything more than an auto-\nmated statistician? Quora blog, October 4, 2018.  \nPaukku T (2018a) Ihmisen go-lautapelissä voittaneen tekoälyn \npiti olla totta ehkä vasta vuonna 2035 (The AI that won a human \nin the go board game was not supposed  be true before 2035). \nHelsingin Sanomat 18.10.2018. \nPaukku T (2018b) Kuvan ihmistä ei ole olemassa (The person \nshown in the picture does not exist). Helsingin Sanomat \n27.6.2018. \nRomero A (2021) 5 deep learning trends leading artificial intel-\nligence to the next stage. Towards DataScience, April 26, 2021.  \nRuokoniemi P (2018) Tekoälyä on käytettävä harkiten \nlääketieteessä (AI should be used with care in medicine). Helsin-\ngin Sanomat 28.10.2018. \nSirén V (2019) Sibelius vai Homo Deus (Sibelius or Homo \nDeus). Helsingin Sanomat 28.4.2019. \nTammi S (2018) Lääkärin sanelut suoraan tekstiksi (Physician’s \ndictations direcly to text) . Helsingin Sanomat 25.6.2018 \nTuomi I (2019) Sähkönkulutus on tekoälyn kompastuskivi \n(Electricity consumption is an obstacle for AI). Helsingin Sano-\nmat 31.8.2019. \nWeb-ECStrategy: High-level expert group on artificial intelli-\ngence 10.3.2021 \nWeb-DarpaXAI:  Explainable artificial intelligence (XAI) \nWiki-ContinualAI: Continual AI \n\n224 \n \nWiki-Ethics: Ethics of artificial intelligence \nWiki-ExplainableAI: Explainable artificial intelligence \nWiki-Collective: Collective intelligence \nWiki-Sophia: Sophia robot \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n225 \n \nAppendix L1: What should be Taught about AI?  \nL1.1 General \nThe revolution brought by artificial intelligence poses major \nchallenges for the development of skills and the education sys-\ntem. Universities are facing problems, as many companies in \nOulu, for example, have started investing in artificial intelligence \nand recruited more than 15 doctoral researchers in two years \n(2016-2018). It is more and more difficult to recruit new top-\nlevel students and researchers anymore (Pietikäinen et al., 2017). \nStudents of information technology are mostly employed in \ncompanies from the very beginning of their studies. \nOn the other hand, the fragmentation and short-term nature of \nresearch funding is making it difficult for top-level research \nleading to original new innovations and \"deep know-how\" in ar-\ntificial intelligence. Finland's strength has always been innova-\ntive solutions, even various niche applications with a large global \nmarket. \nNow even areas with a long Finnish tradition of key technologies \nin artificial intelligence, such as machine learning, computer vi-\nsion, and automatic speech and language understanding, have \nbeen struggling. Fortunately, thanks to recent artificial intelli-\ngence hype, there has been some improvement - mainly in ma-\nchine learning. \nAn increasing number of doctoral students and researchers spe-\ncializing in artificial intelligence are coming from abroad. For \nexample, our university's machine vision research group has a \ndozen or so hard-working Chinese researchers and students, \nmany of them with Chinese grants. It is clear that paid interna-\ntional master's programs at universities should not be seen as an \nincome item, but that they can provide motivated top-level stu-\ndents for the needs of Finnish research and business. \nThe profound knowledge of artificial intelligence can only come \nfrom long-term research. In recent years, access to research \nfunding in Finland has become more difficult significantly, and \nthe Academy of Finland is increasingly funding projects of only \ntwo years' duration. The focus of Business Finland (formerly \nTekes) has now shifted, as its name suggests, to more and more \nbusiness-oriented research. While this kind of funding can \nachieve short-term gains, original results and innovations that \ngenerate new knowledge are created through basic research. In-\ndeed, many start-up companies related to artificial intelligence \nhave emerged as a result of university research. \nMathematics and programming skills form a central basis for ex-\npertise in artificial intelligence. The motivation to study mathe-\nmatics in schools has undoubtedly decreased, and the number of \napplicants for university studies in technical fields has dropped. \n\n226 \n \nThe problem begins already in elementary school, where moti-\nvated students cannot keep up with their abilities. The attitude \ntowards mathematics in homes and social institutions is also of-\nten disparaging. Is the high school subject structure correct? Are \nthere too many different topics in the long mathematics curricu-\nlum, and more profound knowledge and the learning skills suf-\nfer? However, we see recent efforts to strengthen the role of \nmathematics in high schools as a positive step. \nThe need for knowledge in mathematics and mathematical think-\ning is not limited to “hard” science and technology. Future med-\nical doctors will have to deal more and more with the immense \nmasses of images and information. They need to be able to un-\nderstand what this information can bring, to use new advanced \ntechnologies and tools in their daily work - and to collaborate \nwith experts in various fields to research and develop new tech-\nnology for monitoring human well-being, diagnosing and treat-\ning diseases. \nThe use and interpretation of large masses of data play a central \nrole in modern economics. One must, for example, be able to \nanalyze the current situation and forecast future trends based on \ncurrent and past knowledge. As early as the early 1990s, it was \nsaid that Wall Street was the largest employer of artificial intel-\nligence doctors in the United States. The state of the environment \ncan be monitored by collecting massive amounts of measure-\nment data from various influencing factors and interpreting this \ndata. New technologies incorporating artificial intelligence can \nhelp prevent climate change and its effects. \nEven human scientists, far from mathematics and technology, \nare increasingly using a variety of measurement data, as well as \nartificial intelligence related devices and tools, in their research. \nRegardless of the industry, most decision-makers should be able \nto understand what artificial intelligence is and does not, and \nwhat it allows to prevent them from being taken over by outside \n\"marketers”. \nFuture teachers need to know what digitalization, automation \nand artificial intelligence are all about, and thus be able to help \ntheir students to succeed and to be employed in the future. Au-\ntomation and artificial intelligence will undoubtedly eradicate \nroutine tasks, but the need for tasks that require analytical think-\ning, creativity, craftsmanship, and the ability to adapt to ever-\nchanging circumstances will surely increase. Giving a positive \nimage of mathematics and technology at an early stage, includ-\ning for girls and women, is important to help create a more equal \nsociety. \nThe ability to function in the modern information society is rel-\nevant to all citizens and jobs. Data literacy, and also knowing \nwhat the capabilities and limits of artificial intelligence are, are \n\n227 \n \nimportant. Fear of technological threats doesn't help, because ar-\ntificial intelligence is a human helper, not a ruler. The greatest \ndanger to the individual is probably the inability to utilize the \never-increasing and renewing tools of artificial intelligence and \nhow to protect his or her private information in information net-\nworks and social media. Figure L1.1 illustrates various perspec-\ntives that may need to be explored in research and application of \nartificial intelligence. \n \nFigure L1.1. Various perspectives to AI. (© 123RF)  \nThis appendix focuses on the core of artificial intelligence, \nknowledge of which is required in most applications. The teach-\ning of artificial intelligence will be examined from the perspec-\ntive of online teaching available through the Internet and the \ntraining of university-level artificial intelligence experts. The \nkey to developing good mathematics and mathematics skills at \nprimary and secondary level is that of all students. Knowledge \nof the basics of computer programming at this stage is also im-\nportant. \nL1.2 Online Learning in Artificial Intelligence \nThe teaching of artificial intelligence has begun to be delivered \nas online courses. Bernard Marr, on his Forbes site, presents ten \nof the best (mostly American) free online courses, see (Web-\nBernard). \nThe courses deal with e.g. machine learning basics, applications \nand practical implementations. Some of the courses are already \ndesigned for people with some technical skills to implement their \nown neural networks. Some of the courses are intended for the \ngeneral public, that is, for those who want to know how to apply \nthis technology to solving a variety of real problems. \n\n228 \n \nHowever, it should be noted that on-line courses provide a rather \nnarrow view of artificial intelligence, mostly focusing on deep \nlearning or its applications. Section L1.3 introduces a broad field \nof study designed for the training of artificial intelligence experts \nfor graduate students in Information Technology. The online \ncourses give the general public an appropriate introduction to the \nbasics of machine learning and can also complement the training \nof artificial intelligence specialists. \nBernard Marr considered the following to be the best free online \ncourses in 2020: Elements of AI - University of Helsinki; Learn \nwith Google AI; Intro to Artificial Intelligence - Udacity; Ma-\nchine Learning - Stanford University (Coursera); AI for Every-\none - Andrew Ng (Coursera); Data Science and Machine Learn-\ning Essentials - Microsoft (EdX); Machine Learning Crash \nCourse - Google; Learning from Data (Introductory Machine \nLearning) - Caltech (EdX); Artificial Intelligence A-Z: Learn \nHow to Build an AI - Udemy; Creative Applications of Deep \nLearning with Tensorflow - Kadenze (Class Central). \nFor Finns, perhaps the best-known of these, in addition to the \ncourse of University of Helsinki (Web-Helsinki), is Coursera's \nStanford University machine learning courses (Web-Coursera), \nwhich are lectured by Andrew Ng (Wiki-Ng), a world-renowned \nlecturer in the field. He has been founder of the Google Deep \nLearning Group (Deep Brain) and leader of artificial intelligence \nresearch at Baidu. \nOnline education provided by Coursera, founded by Ng, is free. \nOnly a certificate of completion of the course is required. The \ncourse covers a wide range of implementations of various ma-\nchine learning applications, such as speech recognition and more \nefficient Internet searches. Advanced courses go into the statis-\ntical basics of deep learning, deep neural networks, and some \ndevelopment tools. \nThe lecturers of the extensive Udacity Intro to Artifiical Intelli-\ngence course are well-known artificial intelligence researchers \nPeter Norvig and Sebastian Thrun. The former is another author \nof the classic book on artificial intelligence (Russel & Norvig, \n2010) and has recently served as Google’s director of research \n(Wiki-Norvig). \nThe Elements of AI online course for the general public offered \nby the University of Helsinki and Reaktor company has been \nwidely used in Finland and recently also elsewhere. Originally \nan English course is now also available in Finnish, cf. (Web-\nHelsinki). The course consists of six chapters: 1) What is artifi-\ncial intelligence? 2) Problem solving with artificial intelligence, \n3) Practical applications of artificial intelligence, 4) Machine \nlearning, 5) Neural networks, and 6) Effects of artificial intelli-\ngence. More detailed information on the contents of these chap-\nters can be found on the course website. \n\n229 \n \nThis book, and especially Chapters 3-4, is designed to serve a \nfairly wide readership, helping to understand the basics, possi-\nbilities, and limitations of artificial intelligence. \nL1.3 Degree Program in Artificial Intelligence at the Univer-\nsity of Oulu \nThe University of Oulu has been teaching computer science \ncourses since the early 1980s. Previous teaching included basic \ncourses in both artificial intelligence and machine learning (neu-\nral networks and pattern recognition). In addition, the basics of \ndigital image processing and machine vision were covered. From \nthe outset, research and teaching have been closely intertwined: \nnew courses have largely been created to meet the needs of re-\nsearch and have been taught by researchers and research assis-\ntants. On this basis, over the years, new research groups focused \non various fields of information technology have emerged along-\nside machine vision, all of whom have strong activities in the \nfield of artificial intelligence. These include research on medical \nsignal analysis, ubiquitous computing, data mining, and intelli-\ngent systems and robotics. This research has made a significant \ncontribution to curriculum development. \nIn 2016, a systematic renewal and expansion of the Artificial In-\ntelligence curriculum was started in the Computer Science and \nEngineering Degree Program. The starting point was that di-\nploma engineers (MSc) who are deepening into artificial intelli-\ngence must have a solid basic mathematical training, good pro-\ngramming skills, and a sufficiently broad vision of artificial in-\ntelligence, because now so hot topic machine learning is only \none part of artificial intelligence. A new field of study in artificial \nintelligence started in the Fall of 2018, but the new courses in-\ncluded in it were completed and held before that. The latest con-\ntent of the study guide for Computer Science and Engineering \nMSc students and course descriptions can be found in (Web-\nOulu). \nGraduate engineers specializing in artificial intelligence are \ngiven a strong basic education in mathematics, programming, \ncomputer engineering, human-computer interaction, digital sig-\nnal and image processing, and computer graphics. Basic studies \nin mathematics and computer science include: vector algebra, \ndifferential and integral calculus, linear algebra (matrix calcu-\nlus), complex analysis, statistical mathematics, computer math-\nematics, and data structures and algorithms. The normal training \nof diploma engineers in mathematics and mathematics is sup-\nported by additional courses on regression and variance analysis, \nand optimization, closely related to AI and machine learning. \nThe recent core courses Artificial Intelligence have been Intro-\nduction to Artificial Intelligence, Artificial Intelligence, Ma-\nchine Learning, Deep Learning, Computer Vision, Affective \nComputing, Natural Language Processing and Text Mining, and \n\n230 \n \nMultimodal Data Fusion. Courses related to massive data pro-\ncessing, or big data processing, are Journey to Data Mining and \nBig Data Processing and Applications. A modern course dealing \nwith information networks is an Introduction to Social Network \nAnalysis. In addition, it is possible to choose e.g. a course related \nto virtual reality VR systems and people; and Fundamentals of \nSensing, Tracking and Autonomy related to machine sensing.  \nIn addition to the above, at least audio and speech processing \nfocused teaching would be needed, but no teaching resources for \nthis have been found so far. Chapters 3 and 4 of this book are \nlargely based on material developed by Olli Silvén for the Intro-\nduction to Artificial Intelligence course. \nThe following is a brief introduction to the main courses in Ar-\ntificial Intelligence at the University of Oulu, based on course \npresentations. Our intent is to give the reader an idea of what \nkind of artificial intelligence studies are needed by knowledgea-\nble IT professionals. Courses in the Bachelor of Science  (Engi-\nneering) degree are marked with P (basic studies) or A (subject \nstudies) in the title of the course and advanced courses for the \nMaster's degree are marked with S. The code of each course is \ngiven in parenthesis. \nIntroduction to Artificial Intelligence (521160P) \nThe course is designed for students of all disciplines. It does not \nrequire theoretical knowledge of artificial intelligence, but fo-\ncuses on identifying and solving different types of artificial in-\ntelligence problems with existing tools. The course consists of \nlectures and exercises in groups of students from many different \nfields. Each group must have at least one student with program-\nming skills. \nAfter completing the course, the student will be able to identify \nany artificial intelligence techniques that may be applicable to \nproblem solving, able to distinguish between search, regression, \nclassification, and clustering problems, able to explain the use of \nsupervised and unsupervised learning, and performance meas-\nurement. This differs from the online course of the University of \nHelsinki and Reaktor, especially in that our own course is clearly \nmore data-driven. \nCourse contents: 1) Introduction: importance of artificial intelli-\ngence, 2) Search methods: AI of games, 3) Regression methods: \nlearning the causality, 4) Classification methods: identifying cat-\negories, 5) Clustering methods: identifying class structures, 6) \nSupervised learning, 7) Unsupervised learning. \nArtificial Intelligence (521495A) \nCourse based on Artificial Intelligence: A Modern Approach \n(Russell & Norvig, 2010), which is probably the most widely \nused textbook in the world for artificial intelligence teaching. \n\n231 \n \nAfter completing the course, the student will be able to identify \nthe types of problems that can be solved with artificial intelli-\ngence, know the basic concepts of intelligent agents, know the \nmost common search methods and principles of inference based \non logic. He or she can also apply simple methods for reasoning \ninvolving uncertainty and for machine learning based on obser-\nvations. In addition, the student will be able to program the most \ncommon search methods. The course includes two programming \nexercises. \nContent of the course: 1) Introduction, 2) Rational (intelligent) \nagents and uninformed search, 3) Informed search, 4) Adversar-\nial search (games), 5) Uncertainty, 6) Markov decision pro-\ncesses, 7) Reinforcement learning, 8) Bayesian networks, 9) \nLearning from samples, 10) Advanced applications. \nMachine Learning (21289S) \nAfter completing the course, the student will be able to design \nsimple optimal classifiers based on basic theory and evaluate \ntheir performance, be able to explain Bayesian decision theory \nand apply it to minimal error and minimum cost classifiers, apply \nbasic gradient search to linear nonlinear discriminant function, \nand apply regression methods to practical machine learning \nproblems. The course includes supervised laboratory work and \nindependent work. \nContent of the course: 1) Introduction, 2) Bayesian decision the-\nory, 3) Discriminant functions, 4) Parametric and non-paramet-\nric classifications, 5) Extraction of features, 6) Classifier design, \n7) Example classifiers, 8) Statistical regression methods. \nDeep Learning (521153S) \nAfter completing the course, students will become familiar with \ndeep learning and its basic methods and how to use them in a \nvariety of problems. The course consists of lectures, five assign-\nments and a final project. \nContent of the course: 1) Introduction to deep learning and \ncourse content, TensorFlow tutorial, 2) Fundamentals of deep \nlearning: linear regression, logistic regression, loss function, sto-\nchastic gradient search, simple practices for training basic mod-\nels, 3) Neural networks, deep networks, auto-encoders, 4) Con-\nvolutional neural networks (CNN), 5) Current CNN applications \nin computer vision, 6) Deep models for text and sequences (RNN \nand LSTM). \nComputer Vision (521466S) \nAfter completing the course, the student understands the basics \nof image formation, presentation and modeling. He or she is able \nto use basic machine vision techniques for image recognition \nproblems. In addition, the student is able to use two-dimensional \ntransformations for model fitting and image registration, and can \n\n232 \n \nexplain the basics of three-dimensional imaging and reconstruc-\ntion. The course includes homework. Prerequisites are required \nto complete the Digital Image Processing course or equivalent. \nContent of the course: 1) Introduction, 2) Imaging and represen-\ntation, 3) Color and shading, 4) Image features, 5) Identification, \n6) Texture, 7) Motion from 2-D image sequences, 8) 2-D models \nand transforms, 9) 3-D sensing of 2-D images, 10) 3-D transfor-\nmations and reconstruction. \nAffective Computing (521285S) \nAfter completing the course, the student will be able to explain \nthe theory and modeling of emotions, will be able to implement \nalgorithms related to the recognition of emotions from visual and \naudio signals or the combination of multiple modalities. He or \nshe also has a general view of applications of affective compu-\nting (emotion AI). \nContent of the course: 1) History and development of affective \ncomputing, 2) Psychology of emotion theory and modeling, 3) \nEmotion recognition from different modalities: facial expres-\nsions, speech, EEG, 4) Crowdsourcing, 5) Synthesis of emotive \nbehaviors, 6) Emotion recognition applications. \nNatural Language Processing and Text Mining (521158S) \nAfter completing the course, students will be able to understand, \ndesign and implement basic systems for searching and querying \ntext (on-line), taking into account linguistic factors and perform-\ning clarification of word meaning, performing (statistical) infer-\nences using corpus (language database), and editing (statistical) \nlanguage modeling tool kits, lexical on-line databases and vari-\nous natural language processing tools. \nContent of the course: 1) Basics of text retrieval systems, 2) \nGlossary ontologies, 3) Specifying the meaning of words, 4) \nText classification, 5) Language database based reasoning and \nnatural language processing tools. \nMultimodal Data Fusion (521161S) \nAfter completing the course, students are expected to understand \nthe problem of combining different types of data from different \nsources (such as images and audio). They should be able to im-\nplement basic solutions for the task that requires integration and \naggregation of the data provided. \nCourse Content: This course provides a comprehensive introduc-\ntion to the concepts and approaches to fusion of many data gen-\nerated by sensors. The course introduces several real world ex-\namples of different types of applications. The content is con-\nstructed so that no prior knowledge of data fusion is required. \nHowever, a basic understanding of related issues, such as image \nand signal processing, is useful. \n\n233 \n \nOn the Way to Data Mining (21156S) \nAfter completing the course, the student will be able to identify \nwhat kind of data he or she is going to study and what kind of \npre-processing it will require. The specific learning outcomes of \nthe course include: ability to design and implement data collec-\ntion, ability to combine data from various sources, normalize and \ntransform data, and process missing or incorrect data, ability to \ngeneralize results. \nContent of the course: 1) Data mining process in general, data \ncollection and different types of data, 2) Data quality and relia-\nbility, 3) Data preparation including missing values, outliers and \nprivacy processing, 4) Use of signals from multiple sources 5) \nUtilization of databases in the data mining process as well as data \nnormalization, transformation and interdependence and distribu-\ntion of observations; 6) Principles independent of modeling tech-\nniques ensuring generalization and data delivery of results, such \nas train-test-validate, cross-validation and leave-one-out meth-\nods. \nProcessing and Application of Big Data (521283S) \nAfter completing the course, the student will be able to explain \nthe mass data (big data), its challenges and opportunities. They \nwill also be able to explain the requirements and general princi-\nples for designing and implementing data intensive systems, as \nwell as evaluate the benefits, risks and limitations of possible so-\nlutions. In addition, the student knows the principles of mass data \nmanagement and processing technologies and can apply them at \nthe basic level. \nContent of the course: 1) Basics of mass data, 2) Data storage, \n3) Single or continuous data processing, 4) Data analysis, 5) Pri-\nvacy and security, 6) Mass data usage examples. \nIntroduction to Social Network Analysis (521157A) \nAfter completing the course, students are expected to understand \nthe social aspects of the web, gather, clean and present social \nmedia data, identify important features of social media, discover \nand analyze (online) network communities, understand the dif-\nfusion process within the social network, and analysis of work \ntools. \nContent of the course: The course describes the basics of social \nnetwork analysis: 1) Creates the ability to understand the struc-\nture and development of the network, 2) Enables the use of ap-\npropriate tools and techniques to draw conclusions from the net-\nwork and to find hidden patterns. Designed for students with a \nbackground in information technology, mathematics and social \nsciences, the course provides a basis for multidisciplinary re-\nsearch. \n\n234 \n \nSummary \nThe training provided will give the practitioner sufficient in-\ndepth knowledge in the field of artificial intelligence and infor-\nmation technology, as well as prepare them for doctoral studies \nin the field. In addition, courses are offered for training mathe-\nmatically-oriented data analysts and basic education for all fac-\nulties at the University. Such degree programs are also hoped to \nincrease the interest of high school students in pursuing univer-\nsity studies in technology and computer science. Unfortunately, \nthere is no shortcut to happiness: everything relies on mathemat-\nical thinking. \nL1.4 References \nRussell S & Norvig P (2010) Artificial Intelligence: A Modern \nApproach, 3rd Edition. Prentice Hall, 1152 p.  \nPietikäinen M, Silvén O & Pirttikangas S (2017) Tekoälyn ope-\ntusta on lisättävä ja syvennettävä (We  should have more and \ndeeper AI teaching in Finland). Helsingin Sanomat 20.4.2017. \nWeb-Bernard: The 10 Best Free Online Artificial Intelligence \nand Machine Learning Courses for 2020, Forbes, 16.3.2020 \nWeb-Coursera:    Machine Learning, Stanford University                           \nWeb-Helsinki: Elements of AI, University of Helsinki \nWeb-Oulu: CSE-MSc (Study guide for Computer Science and \nEngineering students). University of Oulu \nWiki-Ng: Andrew Ng  \n \n \n \n \n\n235 \n \n \n \n \nTable of Figures \n \nFigure 1.1. The roles of data and knowledge in artificial intelligence.8 \nFigure 1.2. AI hype cycles over time. (© 123RF) ............................... 14 \nFigure 2.1. The Turing test. (© 123RF) ............................................. 17 \nFigure 2.2. A rationally acting agent. (© 123RF) .............................. 19 \nFigure 2.3. A rule-based system. (© 123RF) ..................................... 20 \nFigure 2.4. Pattern recognition with a multi-layer neural network. (© \n123RF) ............................................................................................... 21 \nFigure 2.5. A directed search network. ............................................. 22 \nFigure 2.6. Central areas of AI.  (© 123RF) ....................................... 22 \nFigure 2.7. Perceptron neural network............................................. 28 \nFigure 2.8. Genetic algorithms are using a simplified model from \nbiological evolution. (© 123RF) ........................................................ 34 \nFigure 3.1. A typical artificial intelligence application. ..................... 45 \nFigure 3.2. Progress of analysis from primal sketch to three-\ndimensional model. (© Tuomas Holmberg) ..................................... 48 \nKuva 3.3. Maxwell’s equations and part of an integrated circuit’s \nbehavior model written in  VHDL language. (© 123RF) ................... 51 \nFigure 3.4. Example of modeling a pallet transfer task. ................... 52 \nFigure 3.5. A minimax game tree. ..................................................... 54 \nFigure 3.6. A global politics minimax example. ................................ 55 \nFigure 3.7. A structural description. ................................................. 56 \nFigure 3.8. A feature vector representation of an image. ................ 56 \nKuva 3.9. Example of computing convolutions. ................................ 57 \nFigure 3.10. Principle of auto-encoder. ............................................ 57 \nKuva 3.11. Curse of dimensionality. ................................................. 58 \nKuva 3.12. Three-dimensional “coil spring data” and its two-\ndimensional description. (© Tuomas Holmberg) ............................. 60 \nKuva 3.13. Principle of principal component analysis (PCA). ........... 60 \nFigure 3.14. 2-D and 3-D descriptions of MNIST data using the t-SNE \nmethod. (© Tuomas Holmberg) ....................................................... 61 \nKuva 3.15. Multidimensional scaling. (© Acta Univ. Oul.) ................ 62 \nFigure 3.16. Continuity of wood samples visualized by the LLE \nmethod. (© Acta Univ. Oul.) ............................................................. 63 \nFigure 3.17. Visualization of wood material variation using a self-\norganizing map. (© Acta Univ. Oul.) ................................................. 63 \nFigure 3.18. SOM and Isomap visualizations of unbalanced data. (© \nActa Univ. Oul.) ................................................................................. 64 \nFigure 4.1. Machine learning focuses on modeling the data............ 66 \nFigure 4.2. Categorization of machine learning methods. ................ 67 \nFigure 4.3. Space spanned by features of different value ranges. ... 69 \n\n236 \n \nFigure 4.4. Methods of supervised learning. .................................... 70 \nFigure 4.5. Predicting the breaking strength of lumber through a \nlinear regression model. ................................................................... 71 \nFigure 4.6. Regression tree and corresponding feature space. ........ 72 \nFigure 4.7. Over- and underlearning. ................................................ 73 \nFigure 4.8. The rough principle of kNN classification. ...................... 77 \nKuva 4.9. Principle of ensemble classifier. ........................................ 78 \nFigure 4.10. Ensemble classifier with ”bagging”. .............................. 78 \nKuva 4.11. Simple Perceptron. .......................................................... 80 \nKuva 4.12. Initial situation of Perceptron learning. .......................... 81 \nFigure 4.13. Effects of Perceptron's learning steps on the \ndiscriminant line. .............................................................................. 83 \nFigure 4.14. A non-linear discriminant. ............................................ 83 \nFigure 4.15. Fully connected neural network. .................................. 84 \nFigure 4.16. Neuron with a non-linear activation function f. ........... 84 \nFigure 4.17. Deep  convolutional neural network. ........................... 85 \nFigure 4.18. Max pooling operation.................................................. 86 \nFigure 4.19. Methodological division of unsupervised learning. ...... 90 \nKuva 4.20. Three different clustering problems. .............................. 91 \nFigure 4.21. Sketched results of k-means clustering. ....................... 92 \nFigure 4.22. Results for hierarchical clustering. ................................ 92 \nFigure 4.23 Effect of abnormal samples on clustering. .................... 93 \nFigure 4.24. Sample data describing the use of two cars. ................ 93 \nFigure 4.25. Basic reinforcement learning. (© 123RF) ..................... 94 \nFigure 4.26. Simple application problem for Q-learning. ................. 95 \nKuva 4.27. Recurrent neural network. .............................................. 98 \nFigure 4.28. Generative Adversarial Network. ................................. 99 \nFigure 4.29. Errors in a two category classification problem. ........ 100 \nFigure 4.30.Typical  ROC curve. ...................................................... 101 \nFigure 4.31. Precision-recall curves for three classifiers.. .............. 101 \nFigure 5.1. In the game Go area is demarcated from the opponent. \n(© 123RF) ........................................................................................ 104 \nFigure 5.2. Principle of a speech recognition method (n-gram). .... 107 \nFigure 5.3. Machine translation. (© 123RF) ................................... 110 \nFigure 5.4. Japanese shogi, or general’s game. (© 123RF) ............. 112 \nFigure 5.5. Self-driving vehicle. (© 123RF) ..................................... 113 \nFigure 5.6. MRI scans of the human brain. (© 123RF) ................... 118 \nFigure 5.7. A dark area to be diagnosed on the skin. (© 123RF) .... 120 \nFigure 6.1. Examples of different cameras. (© 123RF) ................... 125 \nFigure 6.2. Simplified image analysis process. ................................ 126 \nFigure 6.3. Character segmentation by adaptive threshold method. \n(© Elsevier) ..................................................................................... 127 \nFigure 6.4. A range image and a normal color image. (© Springer)\n ........................................................................................................ 129 \nFigure 6.5. 3D view analysis process. .............................................. 130 \nFigure  6.6. Challenges of object identification. (© CC BY 4.0) ....... 131 \nFigure 6.7. Identification of objects and segmentation of their \ninstances. (© 123RF) ....................................................................... 133 \n\n237 \n \nFigure 6.8. Computational removal of haze in an image. (© IEEE) 133 \nFigure 6.9. Object recognition using machine learning. (© 123RF) 134 \nFigure 6.10. Background removal and tracking of moving objects. (© \nIEEE) ................................................................................................ 134 \nFigure 6.11. Biometric face recognition (© 123RF) and assessment of \nemotional state based on walking style. (© CMVS) ....................... 135 \nFigure 6.12. Created with Google Tango, a 3-D model of our research \nunit facilities (© CMVS). ................................................................. 135 \nFigure 6.13. Picture taken with a lenslet camera. (© Sami Varjo) . 136 \nFigure 7.1. Examples of images with very different textures. (© CC \nBY 4.0) ............................................................................................. 141 \nFigure 7.2. Example of calculating LBP code in a  3x3 neighborhood. \n(© Springer) .................................................................................... 142 \nFigure 7.3. Generalized LBP. (© Springer) ...................................... 143 \nFigure 7.4. Micro-patterns detected by LBP operator. (© Springer)\n ........................................................................................................ 144 \nFigure 7.5. Application of LBP to a facial image. (© Springer)........ 144 \nFigure 7.6. LBP-TOP in dynamic texture analysis. (© Guoying Zhao)\n ........................................................................................................ 145 \nFigure 7.7. Face analysis with LBP. (© Springer) ............................ 145 \nKuva 7.8. Milestones in LBP research. (@ CC BY 4.0) ..................... 147 \nFigure 8.1. Variations in two different types of knots. ................... 153 \nFigure 8.2. Training of classifier with human classified samples. ... 153 \nFigure 8.3. Rule-based classifier tuning by adjusting parameters. . 154 \nFigure 8.4.  Training based on visualized clustering. ...................... 154 \nFigure 8.5. Grouping of knots with the SOM method. (© Acta Univ. \nOul.) ................................................................................................ 155 \nFigure 8.6. Cheating on identity verification. (© CMVS) ................ 157 \nFigure  8.7. Spoofing detection with LBP method. (© IEEE) ........... 157 \nFigure 8.8. Heart rate measurement from face video. (© IEEE)..... 159 \nKuva 8.9. Collection of OBF test database. (© IEEE) ...................... 160 \nFigure 8.10. Facial analysis for human-machine interface. ............ 161 \nFigure 8.11. Face analysis with smart glasses. (© CMVS) ............... 162 \nFigure 8.12. Visual speech recognition with LBP method. (© IEEE)\n ........................................................................................................ 162 \nFigure 8.14. Geometric camera calibration. (© Janne Heikkilä) ..... 165 \nFigure 8.15. Creating a 3-D model using the multi-camera stereo \nmethod. (© Janne Heikkilä) ............................................................ 165 \nFigure 8.16. An example of augmented reality. (© 123RF) ............ 166 \nFigure 8.17. CAT mobile robot. ....................................................... 168 \nFigure 8.18. Human-robot interaction should be easy and natural. \n(© Jukka Kontinen) ......................................................................... 169 \nFigure 8.19. Minotaurus robot for investigating human-robot \ninteraction. (© Springer) ................................................................ 170 \nFigure 8.20. Testing human-robot interaction. (© Jukka Kontinen)\n ........................................................................................................ 171 \nFigure 8.21. Recognition of simple human actions with the LBP-TOP \nmethod. (© Springer) ..................................................................... 172 \n\n238 \n \nFigure 8.22. Audiovisual face animation. (© Springer) .................. 173 \nFigure  8.23. Segmentation of a virtual microscope image. ........... 174 \nFigure 8.24.  X-ray images. (a) and (b) normal, (c) pneumonia. (© \nIEEE) ................................................................................................ 175 \nFigure 8.25. Classification of X-ray images with a CNN neural \nnetwork method. ............................................................................ 176 \nFigure 9.1. Locations of different emotions on the body map. (© \nPNAS) .............................................................................................. 179 \nFigure 9.2. Cognitive appraisal theory. (e.g. Scherer et al., 2001). . 182 \nFigure 9.3. Emotions in a job interview. (© 123RF) ........................ 185 \nFigure  9.4.   Prototypic facial expressions. ..................................... 186 \nFigure  9.5. Examples of action units. (© IEEE) ............................... 187 \nFigure 9.6. The expressions “joy” and “anger” were born as a \ncombination of movements. (© Henglin Shi and Zitong Yu) .......... 187 \nFigure 9.7. Two-dimensional emotion model. ................................ 188 \nFigure  9.8. Micro- and  macro-expressions. (© CMVS) ................. 189 \nKuva 9.9. Micro-expressions usually occur in the eyes and mouth \nregions. (© Jukka Kontinen). .......................................................... 189 \nFigure 9.10. Improved version of the micro-expression recognition \nmethod.  (© IEEE) ........................................................................... 192 \nFigure 9.11. Multimodal emotion recognition. .............................. 196 \nFigure 10.1. Do I sometimes get super-smart? (© 123RF) ............. 200 \nFigure 10.2. Human nervous system. (© 123RF) ............................ 203 \nFigure 10.3. Learning with a convolutional neural network. (© Li Liu)\n ........................................................................................................ 203 \nFigure 10.4. Kitchen robots have been awaited. (© 123RF) .......... 207 \nFigure 10.5. Imagined super-intelligence. (© 123RF) ..................... 208 \nFigure 10.6. Visualized data structures. (© 123RF) ........................ 211 \nFigure 11.1. Sophia robot. (© 123RF) ............................................. 218 \nFigure 11.2. Fog computing is highly distributed. (© 123RF) ......... 220 \n \n \n \n\n239 \n \n \nChallenges of Artificial Intelligence  –  From Machine \nLearning and  Computer Vision to Emotional Intelli-\ngence \n \nArtificial intelligence or machine intelligence is a technology ca-\npable for actions considered to be intelligent. We encounter ar-\ntificial intelligence in computer games, video services, product \nrecommendations, speech recognition capabilities of mobile \nphones, face-to-face payment points and, for example, lane \nguards of cars. As the development expertise and implementa-\ntions of such solutions become more common, the concept of \nartificial intelligence has shifted to increasingly sophisticated \ncapabilities. \nIf the recent expectations on artificial intelligence come true, \neveryone's everyday life and working life, as well as the future \nof humanity, will be revolutionized. This expert book is a realis-\ntic answer to the over marketing of artificial intelligence. \nSo far, the development of artificial intelligence has been a se-\nries of enthusiasm periods, over-sized promises, major efforts, \ndisappointments, and winters of AI research. However, techno-\nlogical advances have been significant at every step. \nThis book written for wide audience describes how artificial in-\ntelligence has evolved since the 1950s based on the most prom-\nising research findings. The most important advances in meth-\nodology and their impacts are considered. The hand-to-hand \napproach is to look “under the hood “ of the basic principles, \nimplementation challenges, and limitations of what is perceived \nto be intelligent. \nIn the future, in addition to current applications, the authors of \nthe book will see artificial intelligence transforming into an in-\nterpreter of human actions and emotions. Better anticipation of \nhuman procedures will facilitate the use of machinery and \nequipment and improve safety at home, at work and in traffic. \n \nISBN: 978-952-62-3199-0 (electronic publication) \nWWW: http://urn.fi/urn:isbn:9789526231990",
    "pdf_filename": "Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Intelligence.pdf"
}