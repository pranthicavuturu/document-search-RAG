{
    "title": "Neurosymbolic Graph Enrichment for Grounded World",
    "abstract": "The development of artificial intelligence systems capable of understanding and reasoning about complex real-world scenarios is a significant challenge. In this work we present a novel approach to enhance and exploit LLM re- active capability to address complex problems and interpret deeply contex- tual real-world meaning. We introduce a method and a tool for creating a multimodal, knowledge-augmented formal representation of meaning that combines the strengths of large language models with structured semantic representations. Our method begins with an image input, utilizing state- of-the-art large language models to generate a natural language description. tion (AMR) graph, which is formalized and enriched with logical design pat- terns, and layered semantics derived from linguistic and factual knowledge bases. The resulting graph is then fed back into the LLM to be extended with implicit knowledge activated by complex heuristic learning, including semantic implicatures, moral values, embodied cognition, and metaphorical representations. By bridging the gap between unstructured language models and formal semantic structures, our method opens new avenues for tackling intricate problems in natural language understanding and reasoning.",
    "body": "Neurosymbolic Graph Enrichment for Grounded World\nModels\nStefano De Giorgisa, Aldo Gangemia,b, Alessandro Russoa\naInstitute for Cognitive Sciences and Technologies - National Research Council\n(CNR-ISTC), Italy\nbDepartment of Philosophy - University of Bologna, Italy\nAbstract\nThe development of artificial intelligence systems capable of understanding\nand reasoning about complex real-world scenarios is a significant challenge.\nIn this work we present a novel approach to enhance and exploit LLM re-\nactive capability to address complex problems and interpret deeply contex-\ntual real-world meaning. We introduce a method and a tool for creating\na multimodal, knowledge-augmented formal representation of meaning that\ncombines the strengths of large language models with structured semantic\nrepresentations. Our method begins with an image input, utilizing state-\nof-the-art large language models to generate a natural language description.\nThis description is then transformed into an Abstract Meaning Representa-\ntion (AMR) graph, which is formalized and enriched with logical design pat-\nterns, and layered semantics derived from linguistic and factual knowledge\nbases. The resulting graph is then fed back into the LLM to be extended\nwith implicit knowledge activated by complex heuristic learning, including\nsemantic implicatures, moral values, embodied cognition, and metaphorical\nrepresentations. By bridging the gap between unstructured language models\nand formal semantic structures, our method opens new avenues for tackling\nintricate problems in natural language understanding and reasoning.\nKeywords: Neurosymbolic AI, Knowledge Representation, Knowledge\nExtraction, Large Language Models, Graph RAG, Hybrid Reasoning\n1. Introduction\nThe development of artificial intelligence systems capable of understand-\ning and reasoning about complex real-world scenarios remains a significant\n1\n4202\nvoN\n91\n]IA.sc[\n1v17621.1142:viXra\nchallenge in computer science. This challenge is particularly evident when\nconsidering the distinct paradigms of generative AI and knowledge-based AI.\nGenerativeAIs, includingLargeLanguageModels(LLMs), functionassignal\nprocessingmachines: theylearnactivationpatternsfrominputofanymodal-\nity and provide symbolic output at inference time. In contrast, knowledge-\nbased AIs operate as logical machines, extracting and designing symbolic\nrepresentation patterns of the world with model-theoretical interpretations\nto ensure correct inference.\nWhile both approaches have demonstrated remarkable capabilities, they\noften lack the comprehensive understanding necessary to build Grounded\nWorld Models (GWM) [62, 64], i.e., models of the world as experienced\nor constructed by humans (and other organisms). GWMs are multivaried,\nencompassing physical, neurocognitive, social, and cultural dimensions. This\nmultidimensional approach is intended to better mirror the complexity of\nhuman understanding.\nThis paper presents a novel neurosymbolic approach that aims to bridge\nthis gap by leveraging LLMs’ power of automated generation from latent\nknowledge, and the heuristic power of ontology-based knowledge graphs.\nAt the core of our approach is the assumption that human-like under-\nstanding requires the integration of multiple layers of knowledge, ranging\nfrom sensorimotor experiences to abstract conceptual structures. As argued\nby Lakoff and Johnson [53], human cognition is grounded in embodied ex-\nperiences, which give rise e.g. to image schemas and conceptual metaphors\nthat shape our understanding of more abstract domains. An interesting con-\nsequence, which was not noticed until the appearance of LLMs [65], is that\nabstract knowledge (as represented in natural language, logical and statisti-\ncal models, knowledge bases, sensor data) can work as a supramodal system\nthat bears correspondences to the physical, social, cognitive worlds.\nConsequentially, we propose a framework for developing GWMs trained\nwith, and capable of generating, knowledge graphs. Training includes ei-\nther in-context learning or fine-tuning of pre-trained (multimodal) LLMs\nreinforced to generate multilayered knowledge, including highly contextual\nimplicit knowledge. Implicit knowledge includes e.g. presuppositions, con-\nversational implicatures, factual impacts, image schemas, metonymic and\nsymbolic coercions, event sequences, causal relations, and moral value-driven\nreasoning.\nA key innovation in our approach is the use of LLMs not as expert sys-\ntems, but as reactive engines to extract implicit contextual knowledge. Be-\n2\nsides using heuristic rules and curated knowledge bases, we leverage the re-\nactive power embedded in LLMs to extract and formalize general knowledge\nacross multiple semantic dimensions.\nTo operationalize this vision, we introduce a novel method to create\nknowledge-augmented formal representations of multimodal meaning. For\nexample, starting from an image input, we reuse state-of-the-art LLMs to\ngenerateanaturallanguagedescription. Thisdescriptionisthentransformed\ninto Abstract Meaning Representation (AMR) graphs [16] which are then\nformalised as an ontology-based knowledge graph [42], and aligned to public\nknowledge bases, with the Text2AMR2FRED tool [15? , 63]. The resulting\ngraph is iteratively extended with implicit knowledge activated by heuristics\nfor presuppositions, coercions, impact, etc.\nOur approach implements a feedback loop that leverages multimodal,\nmultilayered GWMs. This iterative process enables continuous refinement\nand expansion of the knowledge graph, enhancing the system’s ability to\nadapt to new contexts and improve its understanding over time.\nThisneurosymbolicapproachmakestheprocessofknowledgebaseenrich-\nmentmoreagileandscalablecomparedtotraditionalmethods. Bycombining\nthe flexibility and generative power of LLMs with the structure and infer-\nential capabilities of symbolic knowledge representations, we enable rapid\nexpansion and refinement of knowledge graphs across diverse domains.\nThis hybrid architecture can be classified as a Type 2-3 neurosymbolic\nsystem in Kautz’ taxonomy [18].\nThe potential applications of this approach are far-reaching, spanning\nnatural language understanding, visual reasoning, and complex problem-\nsolving tasks. By providing a framework for grounding abstract language\nin embodied and commonsense knowledge, our method opens new avenues\nfor developing AI systems capable of human-like reasoning and contextual\nunderstanding.\nIn the following sections, we detail the technical architecture of our im-\nplemented system and a short introduction to a public demo, and present\nexperimental results demonstrating the efficacy of our approach across mul-\ntiple knowledge domains.\nThe paper is organised as follows: Section 2 provides state-of-the-art\npositioning, Section 3 details the methodology, Section 4 describes the three-\ntier evaluation of the method, Section 5 illustrates ongoing and future works,\nand finally Section 6 wraps up the paper.\n3\n2. Related Work\nOur approach is positioned in the quickly growing field of Large Language\nModels and Knowledge Graphs hybrid neurosymbolic methods. The synergy\nbetween neural and symbolic approaches has been extensively explored in\nmultiple surveys [26, 20, 21, 22, 24], some of them focusing explicitly on\ngraph neural networks and symbolic components [23], reasoning over graph\nstructures [27], dynamic knowledge graphs [31], and natural language infer-\nence [25], reflecting the growing interest in hybrid methodologies.\nWhile an exhaus-\ntive survey lies be-\nyond the scope of\nthis paper, we can\nposition our method\nwithin the broader\nlandscape of recent\nadvancements: (i)\nwithin the landscape\nof interactions be-\ntweenLLMsandKGs\nin joint methods ,\nand (ii) in relation to\npopular techniques\nsuch as Graph RAG\n(Retrieval-Augmented\nFigure1: RoadmapforLLMsandKGsinteractions,takenfrom Generation)thathave\n[41].\nrecentlygarneredsig-\nnificant attention.\nRegarding joint LLMs and KGs methods, according to [41], as shown in\nFigure 1, our approach would be both “LLM augmented KG” and “Syn-\nergized LLMs + KGs”, and in particular “LLMs - augmented KGs con-\nstruction” focusing on “End-to-end construction” and “Distilling KGs from\nLLMs”, as well as “LLMs-augmented KGs to text generation” focusing on\n“Leveraging knowledge from LLMs”, and partially “LLM-augmented KG for\nquestion answering” adopting “LLMs as entity/relations extractors”.\nConsideringKautz’taxonomyofneurosymbolicsystems[18],aswellasHamil-\nton contextualization in the domain of natural language understanding [17],\nour pipeline qualifies as Type 2 (“Symbolic[Neuro] (Nested)”) - Type 3\n4\n(“Neuro; Symbolic (Cooperative)”) architecture. Type 2 is defined as nested\narchitecture, where a symbolic reasoning system is the primary system with\nneural components driving certain internal decisions, while Type 3 covers\ncases in which a neural network focuses on one task, e.g. entity linking, word\nsense disambiguation, etc., and interacts via input/output with a symbolic\nreasoner specializing in a complementary task, in our case, building semantic\ntree dependencies in RDF format while aligning entities to Framester [19]\nhub of ontologies, maintaining correct OWL2 syntax.\nConsidering Graph RAG approaches, in recent years the integration of\nLLMs and knowledge graphs has gained significant traction [3], particularly\nusing models for knowledge graph completion [6], and through the devel-\nopment of Retrieval-Augmented Generation (RAG) and Graph RAG tech-\nniques. Different models (GPT, Llama, Claude, Gemini, etc.) have shown\ndifferent specific capabilities but similar structural limitations [1]. While\ntraditional RAG focuses on retrieving precise information from unstructured\nor vector-compressed resources, Graph RAG has demonstrated remarkable\nefficacy and compliance with graph-structured data [5]. The Graph RAG\napproach extends beyond mere text vectorisation, encompassing a two-fold\nprocess: entity recognition and relation extraction, culminating in the gen-\neration of semantic triples.\nClassic applications of Graph RAG have been in question-answering [4],\nstartingfromtextualinformationtransposedtoknowledgegraphembeddings\n[7], or summarization systems designed to retrieve specific information from\nestablished knowledge bases [5]. However, certain layers of meaning remain\nchallenging to capture and formalize, including moral reasoning, pragmatic\nimplicatures, and tacit knowledge derived from real-world experiences.\nThe topic of knowledge graph generation from text is of some relevance\nin several overlapping communities, such as the Semantic Web one [8], as\nwell as the broader knowledge-graph-oriented one1 [5].\nFor this reason, our research expands beyond Graph RAG. We leverage\nLLMs as latent reactors that can provide approximate, implicit, common-\nsense knowledge when activated with appropriate heuristics, rather than as\ntools for compressed information retrieval. Our approach, partially posi-\n1https://www.linkedin.com/posts/tonyseale_\nthe-microsoft-graphrag-library-has-recently-\nactivity-7230121112158830593-m8At?utm_source=share&utm_medium=\nmember_desktop\n5\ntioned as Knowledge Augmented Generation (KAG)2, enables us to extract\nand formalise implicit information that humans intuitively infer, especially\nin visual comprehension tasks.\nBy doing so, our work addresses a longstanding challenge in artificial in-\ntelligence – the Frame problem3 – which concerns the ability of AI systems to\ncontextualise information and make human-like inferences, massively reduc-\ning the combinatorial space of choices. Several past approaches, such as the\nwork of Brachman [28], Minsky [29], and Fillmore [30] attempted to tackle\nthis issue by using structured representation. Being able to faithfully capture\nthe nature of a domain without enumerating all the implicit knowledge that\nit assumes when discussing or performing practices is indeed a cognitive and\ncomputationally hard task.\nConcerning technical components, we include here some knowledge ex-\ntraction tools/methods that have paved the way to what we present in this\narticle.\nFRED4 [42] is a comprehensive tool for formal knowledge graph genera-\ntionfromnaturallanguage(usingtheOWL2descriptionlogic[68]), including\nadditional features such as entity recognition and entity linking, frame ex-\ntraction, semantic role labeling, and word sense disambiguation. FRED uses\nCategorical Grammar [66] and Boxer [67] to create a formal graph, which is\nthen aligned to WordNet, FrameNet, DBpedia, and other public resources.\nAbstract Meaning Representation (AMR) has been proposed long ago in\ncomputational linguistics as a solution for natural language representation\nthat can be pragmatically extracted from text. Recently, an efficient parser\n[16] based on transformer’s end-to-end technology has opened new ways to\nmake it scalable. AMR has a graph-based structure that informally en-\ncodes complex relationships and dependencies between concepts, facilitating\na more nuanced representation of linguistic meaning. Compared to prede-\ncessors like Categorical Grammars, AMR abstracts away from surface-level\nsyntactic variations, simplifying the application of logical and ontological\npatterns when creating knowledge graphs from text.\nAMR2FRED [? ], a deterministic, rule-based system, which applies the\nformal design patterns of FRED’s to AMR, and provides alignments reusing\n2For terminological reference, cf.: https://aidanhogan.com/talks/\n2024-09-04-wuwien-invited-talk.pdf\n3https://plato.stanford.edu/entries/frame-problem/\n4Available at http://wit.istc.cnr.it/stlab-tools/fred/demo/\n6\nFramester [19] as main hub of public resources. The Framester ontology\nhub [19, 32] provides a formal semantics to semantic frames [30] in a cu-\nrated linked data version of multiple linguistic resources (e.g. FrameNet\n[43], WordNet [33], VerbNet [34], PropBank [44], a cognitive layer includ-\ning MetaNet[35] and ImageSchemaNet [36], BabelNet [37], factual knowl-\nedge bases (e.g. DBpedia [38], YAGO [39], etc.), and ontology schemas (e.g.\nDOLCE-Zero [40]), with formal links between them, resulting in a strongly\nconnected RDF/OWL knowledge graph.\nConsidering LLMs, the modular method we present here is potentially\nagnostic to the LLMs used. Nevertheless, the current version of the tool\nimplementing the method, available for testing online5, uses GPT-4o and\nClaude Sonnet 3.5 APIs. The results, shown in Section 4, are therefore\nbased on these two top-scoring models.\n3. Methodology\nIn this section we describe our approach, detailing (i) the technical struc-\nture, and(ii)theknowledgelayerswehavechosentoincludeinourheuristics.\nIt is important to note that the selection of the heuristics is not exhaustive\nand can be incrementally expanded to incorporate additional knowledge ar-\neas as needed, as envisioned in Section 5.\nXKG Generation Pipeline. Our modular pipeline combines natural lan-\nguageprocessing,knowledgerepresentation,andlargelanguagemodels(LLMs)\ntoextractandenrichsemanticinformationfromtextualorvisualinputs. The\nwhole process is shown in Figure 2, and begins on the top left, with either\nuser-provided text or an LLM-generated description of an input image, using\na carefully crafted prompt.\nConsidering the case in which we provide a picture as starting input,\nfollowing Figure 2, this original content is passed to a Multimodal LLM\n(MLLM), prompted to provide a description of the picture in natural lan-\nguage.\nInourcurrentimplementation, afterseveraltests, weretrievedthatGPT-\n4o is the best model at providing a textual description when given as input\nan image. Therefore, starting from an image, we rely on GPT-4o to get as\noutput a textual description. In Section 4 we provide an example of input\n5https://arco.istc.cnr.it/itaf/\n7\nFigure 2: Hybrid knowledge enrichment pipeline.\nand output; furthermore, all the prompts are provided as additional material\non the GitHub repository6.\nThis textual representation is passed to the Text2AMR2FRED (TAF)\ntool [63], which transforms the input text into an Abstract Meaning Repre-\nsentation (AMR) graph using the SPRING parser [13]. As part of this step,\nentity linking is performed from the nodes of the AMR graph to Wikipedia\nentries using BLINK [14]. Due to the opaque nature of the Text-to-AMR\nconversion, which doesn’t explicitly map text segments to graph elements,\nentity linking is performed heuristically: BLINK identifies Wikipedia entity\nmentions in the text, and if AMR nodes are labeled with matching text\nsegments, they are linked to the corresponding Wikidata entities.\nThe AMR graph is subsequently converted to an OWL-RDF knowledge\ngraph relying on AMR2FRED [? 15] using FRED heuristics [42] and motifs\n[2]. The enrichment of this RDF graph through word sense disambiguation\n(WSD) is done using the eWiSeR tool [16]. Similar to the entity linking pro-\ncess, WSD is applied to the original text, linking text segments to WordNet\nsynsets (sets of contextual synonyms). In essence, when RDF graph entities\nhave names (roughly corresponding to the final part of their URIs) that\nmatch disambiguated text segments, an owl:equivalentClass triple\nlinking the entity to the WordNet synset is added to the graph. Leveraging\nFramester [19], we augment the graph with additional rdfs:subClassOf\ntriples for the disambiguated entities, connecting them to WordNet super-\n6https://github.com/StenDoipanni/XKG/tree/main/prompt\n8\nsenses and DOLCE types, derived from querying Framester with the identi-\nfied WordNet synsets. This RDF graph, the result of the text-to-AMR-to-\nFRED (TAF) pipeline, serves as our “Base Graph”, shown in Figure 2 as\n“Knowledge graph” in the middle of the pipeline.\nFrom here, we re-inject this Base Graph to LLM for knowledge enrich-\nment. For this step, after experimenting with a gold standard of formal\nknowledge graphs extracted from text [2], we found that Claude 3.5 Sonnet\nis the best model for the purpose. The “Knowledge Augmented prompting”\nstep of the pipeline calls Claude 3.5 Sonnet API, and takes as input a spe-\ncific base prompt, including the Base Graph expressed in Turtle syntax. This\nbase prompt is then refined in a specific prompt for each heuristic, shown as\nsalmon-colored boxes on the right of Figure 2.\nFor each predefined enrichment heuristic, we prompt Claude to generate\nadditional triples, expanding the implicit knowledge captured in the graph,\nanchoring the newly introduced triples to nodes of the Base Graph. Each\nheuristic produces a separate graph that combines the Base Graph with the\nheuristic’s specific additional triples. Finally, we construct a comprehensive\ngraph that merges the base graph with all the additional triples generated\nacross all heuristics, resulting in a richer, multi-faceted semantic representa-\ntion of the initial image or text input.\n3.1. Knowledge Heuristics\nWe describe here the 11 heuristics currently implemented in the imple-\nmented tool. These heuristics are chosen according to an analysis of the\nessential elements that constitute daily human understanding and sense-\nmaking activity in building and using Grounded World Models. The heuris-\ntics list includes: Presuppositions, based on previous background knowledge;\nConversational Implicatures, which often contributes in making sense of in-\ncomplete information in linguistic exchanges; Factual Impact, which grounds\nlinguistic entities to factual knowledge; Image Schemas, basic building blocks\nof cognition which grounds our way of conceiving the world in our sensori-\nmotor bodily perception (grounding e.g. cognitive metaphors and several\nother entities); Metonymic Coercions, which allows understand propositions\nwhosetruthvaluewouldbezero, butdifferfrommetaphoricalspeechground-\ningtherelationbetweenentitiesontheparthood-wholerelation; Moral Value\nDriven Coercion, applied everyday in appraisal and moral evaluative pro-\ncesses, values nudge our daily behavior; Symbolic Coercion, in Peirce termi-\nnology [60], used to anchor meaning to various entities of the world; Event\n9\nSequences, determinant in our plan-making capability and ability to design\nplausible scenarios and outcomes; Causal Relations, establishing relations of\ncause-effect between processes and events, to avoid either having only (i)\ntemporal sequences and (ii) statistical correlation; Implied Future Events, a\nspecification of Event Sequences, for temporal projection in the future; and\nImplied Non-Events, an infinite set of events, but, referring to the Frame\nproblem, focusing on those more closely related to a specific Event Sequence.\nPresuppositions. Presuppositions7 are implicit assumptions necessary for\nstatements to be meaningful [47, 46, 45]. They play a crucial role in hu-\nman cognition, enabling efficient communication through shared background\nknowledge. Innaturallanguage, presuppositionshelpinferunstatedinforma-\ntion and enhance contextual understanding. By formalizing and integrating\nthese implicit meanings into knowledge structures, the approach captures\nnuanced understandings often taken for granted in human communication.\nFor example, the statement “The athlete won the gold medal” presupposes\nthat there was a competition, possibly an Olympic one, illustrating how pre-\nsuppositions convey information beyond the explicit content of a sentence.\nConversational Implicatures. Conversational implicatures8 are implied\nmeanings that arise from the context of a conversation rather than literal in-\nterpretation. Defined in Grice’s pragmatics [48], they are essential to human\ncommunication, allowingspeakerstoconveymoreinformationthanexplicitly\nstated [49]. Byformalizing andintegrating theseimplicatures into knowledge\nstructures, the approach captures nuanced, context-dependent interpreta-\ntions that humans naturally derive from conversations. This enhances the\nsystem’s ability to understand and reason about complex linguistic phenom-\nena. For example, if someone asks “Is there a gas station nearby?” and\nreceives the answer “There’s one around the corner,” the implicature here is\nthat the gas station should be open and operational, even though this isn’t\nexplicitly stated.\nFactual Impact. Factual impact refers to the physical, social, and cog-\nnitive consequences of events on participants, including expected emotions,\nsensations, and changes in mental states [50]. This concept is crucial for\n7https://plato.stanford.edu/entries/presupposition/\n8https://plato.stanford.edu/entries/implicature/\n10\nunderstanding the full implications of human interactions and narratives.\nBy formalizing these impacts, the approach creates a comprehensive repre-\nsentation of how events affect individuals on multiple levels. This enriched\nrepresentation allows for inference and reasoning about e.g. the emotional\nand cognitive states of participants, adding human-like comprehension to the\nanalysis of social interactions. For example, in the event of “winning a com-\npetition,” the factual impact might include physical sensations (adrenaline\nrush), emotions (joy, pride), and cognitive changes (increased confidence,\nfuture goal-setting).\nImage Schemas. Imageschemasarefundamentalcognitivestructuresthat\nhelp humans organize and interpret their experiences of the world [51, 53].\nThese gestaltic schemas, such as container, path, balance, and force, underlie\nour perceptual understanding of sentences and situations [54]. By integrat-\ning these schemas into knowledge representation, the approach captures a\ncrucial aspect of human cognition and spatial reasoning [55]. This allows for\ninference and reasoning about underlying spatial and conceptual structures\nthat humans instinctively understand, also via cognitive metaphors [52], en-\nhancingthesystem’sabilitytorepresentcomplexnarrativesandinteractions.\nFor example, the container schema helps us understand phrases like “in the\ncompetition” or “out of the box,” while the path schema underlies our com-\nprehension of sentences describing movement or progress.\nMetonymic Coercion. Metonymic coercion is a linguistic phenomenon\nwhereaword’stypicalorliteralsenseisoverriddenbyaspecific, relatedsense\nwithin its extended semantics. This process is fundamental to human lan-\nguage comprehension, enabling more efficient and nuanced communication.\nBy formalizing metonymic coercions in knowledge representation [56], the\napproach captures implicit semantic shifts that occur in everyday language.\nThis allows the system to infer and reason about intended meanings behind\nmetonymic expressions, bridging the gap between literal interpretations and\ncontext-dependentunderstandings. Forexample, inthesentence“TheWhite\nHouse announced new policies,” “White House” undergoes metonymic coer-\ncion to represent the U.S. government or administration, rather than the\nphysical building.\n11\nMoral-Value-Driven Coercion. Moral-value-driven coercion9 is a lin-\nguistic phenomenon where the literal meaning of an action or statement\nis overridden by a morally or socially charged interpretation. This process\nreflects the underlying value systems [57, 59] that guide human behavior and\ndecision-making [58]. By formalizing these coercions in knowledge represen-\ntation, the approach captures implicit moral and social dynamics at play in\nhuman interactions. This allows the system to infer and reason about un-\nderlying ethical considerations and social norms that shape human behavior,\nadding depth to the understanding of complex narratives and interpersonal\ndynamics. For example, the statement “She always keeps her promises”\nmight be coerced from a literal description of behavior to a moral judgment\nabout the person’s integrity and trustworthiness within a social context.\nSymbolic Coercions. Symbolic coercions involve the transformation of lit-\neralmeaningsintosymbolicinterpretations10. Thisprocessisfundamentalto\nhuman cognition and communication [60], allowing for the anchoring of com-\nplex ideas to familiar concepts, objects, and imagery. By formalizing these\ncoercions in knowledge representation, the approach captures implicit sym-\nbolic meanings that permeate human language and thought. This enables\nthe system to recognize and reason about the underlying symbolic signifi-\ncance of actions and concepts, particularly in domains where abstract ideas\nare often expressed through concrete objective correlative [61]. For example,\nin sport events commentaries, the phrase “the cangaroos won the match” un-\ndergoes symbolic coercion from a literal description of marsupial mammals\nto representing Australia (including potential biases and stereotypes).\nEvent Sequences. Event sequences capture the chronological relationship\nbetween events mentioned in a text, providing crucial information about the\norderofactionsoroccurrences. Byformalizingthesesequences, theapproach\ncreates a rich representation of implicit chronological information in narra-\ntives. This enables the system to infer and reason about the temporal flow\nof events, even when not explicitly stated. Such temporal reasoning is essen-\ntial for understanding causality, narrative progression, and the logical flow\nof actions and reactions in complex scenarios. For example, in the sentence\n“After the flight, the athletes have two days before the competition,” the\n9https://plato.stanford.edu/entries/value-theory/\n10https://plato.stanford.edu/entries/peirce-semiotics/\n12\nsystem would recognize the sequence: flight → two days → competition,\nallowing for deeper comprehension of the narrative’s timeline and potential\ncausal relationships between events.\nCausal Relations. Causal relations capture the cause-and-effect relation-\nships between events or states mentioned in a text. By formalizing these\nrelationships the approach creates a rich representation of implicit causal\ninformation. This enables the system to infer and reason about under-\nlying causes and effects within complex scenarios, even when not explic-\nitly stated. Understanding causal relations is essential for comprehending\nmotivations, predicting outcomes, and constructing coherent mental mod-\nels of situations. For example, in the sentence “The heavy rain forced\nthe match to be postponed,” the system would recognize the causal chain:\nheavy rain → match postponing, allowing for deeper analysis of the event’s\nprogression and potential consequences.\nImplied Future Events. Implied future events involve inferring likely out-\ncomes or consequences based on given information. This concept captures\nthe human ability to anticipate future scenarios and make predictions based\non current contexts and interactions. By formalizing these implied future\nevents, we are able to reason about probable consequences of current ac-\ntions and statements, even when not explicitly mentioned in the text. Such\npredictive reasoning is essential for understanding long-term significance of\ninteractions. For example, in the sentence “The committee announced more\nstrict regulations,” the system might infer potential future events such as\nmore severe checks, increase in bureaucratic practices, increase in contro-\nversy, etc.\nImplied Potential Non-events. Implied potential non-events are events\nthat could have occurred but are prevented or made unlikely due to other\ncircumstances or decisions mentioned in the text. This concept captures the\nunderstanding of alternative scenarios and the implications of characters’\nchoices. Although this is an infinite set of entities, namely all the possible\nalternative scenarios that will never take place given a starting situation, we\nfocus on those implicit alternatives that humans naturally consider when in-\nterpreting narratives. This enables the system to reason about not just what\nhappens, but also what could have happened under different circumstances.\nSuch counterfactual reasoning is essential for understanding motivations, the\nsignificanceofdecisions,andthebroaderimplicationsofnarrativeevents. For\n13\nexample, in the sentence “She decided not to compete,” the system would\nrecognizetheimpliedpotentialnon-eventofparticipatingtothecompetition,\nallowing for analysis of the decision’s consequences and alternative outcomes.\nThe graphs produced from all these heuristics together form the set of Ex-\ntended Knowledge Graphs (XKGs).\n4. Experimental Evaluation\nIn this section we evaluate the output generated from the full pipeline de-\nscribed in Section 3: we provide an example of knowledge extension starting\nfrom an image to the complete XKGs extension with all 11 heuristics.\nWe adopt a comprehensive three-tiered\nevaluation framework designed to rigorously\nassess our model’s performance, and vali-\ndate the integrity of the XKGs. The evalua-\ntion process encompasses: (i) logical valida-\ntion of the triples, encompassing both syn-\ntactic correctness and proper anchoring to\npre-existing nodes in the Base Graph; (ii)\nevaluation of foundational ontology align-\nment adequacy, and (iii) human assessment\nFigure 3: Gold medal winner Julien\nof the plausibility and adequacy of asser- Alfred in the 100m female com-\ntions within the triples generated for each petition at Paris 2024 Olympic\nheuristic. games.(© Getty Images)\nTo further ensure the robustness of our\nevaluation, we perform graph extension using an image captured after May\n2024, shown in Figure 3. This temporal selection is significant as it postdates\nthe release of GPT-4o, thereby guaranteeing that the image is not part of\nthe model’s training dataset.\nDue to space constraints, we present a detailed analysis and evaluation\nof a single knowledge extension instance, utilizing the image shown in Figure\n3, from the “sport” domain. Additional examples of knowledge extension,\nparticularly focusing on “politics” and “everyday life” topics, are available in\nour dedicated GitHub repository11. We chose this image since it captures a\n11https://github.com/StenDoipanni/XKG/tree/main/additional_use_\ncases\n14\nmoment of high emotional intensity. The athlete’s expression clearly conveys\nwhat happened moments before and allows for informed speculation about\nsubsequent events based on commonsense knowledge.\nBase Graph. Following the pipeline shown in Figure 2, we give as input\nthe image shown in Figure 3 to GPT-4o, and we get the textual description\nshown in Box 1. To provide an example, highlighted in red is the anchoring\ntext for Factual Impact knowledge, while in blue is the anchoring text for\nMoral Value-driven coercions.\nBox 1 - GPT Textual Description\nJubilant female athlete celebrating victory on track,\nwearing Saint Lucia uniform with ‘‘ALFRED’’ on jersey,\narms outstretched in triumphant pose, beaming with joy and\nexhilaration, fellow competitors visible behind her still\nfinishing race, crowded stadium with cheering spectators\nin background, American flag visible, symbolic moment of\npersonal and national pride, representation of hard work\nand dedication paying off, embodiment of Olympic spirit and\ninternational competition, capturing raw emotion and thrill\nof athletic achievement at highest level, inspiring scene of\nhuman potential realized.\nThe textual description is then passed to Text2AMR2FRED to produce\nthe RDF graph, available as additional material on GitHub12.\nFigure 4 shows an excerpt of the RDF graph obtained, in which it is\npossibletoseethealignmentstoWordNetandPropBank, andtotheDOLCE\nfoundationalontology. Box2showsanexcerptoftheBaseGraph, inwhichit\nis possible to see how e.g. the individual node fred:athlete 1 is aligned\nto DOLCE dul:Person and WordNet wn:synset-athlete-noun-1.\nFurthermore, atthebottomofBox2thereisanaturallanguagetransposition\nofthetriplesabove. InredtheanchoringpointsforFactualImpactknowledge\n(amongothers), andinbluetheanchorforknowledgerelatedtoMoralValue-\ndriven coercion.\nThe Base Graph contains 293 OWL axioms (non-structural statements)\nas shown in Table 1, which correspond to 1436 RDF triples when serialized\n12Download and open in the browser this file: https://github.com/\nStenDoipanni/XKG/blob/main/resources/graphs/base-graph.html\n15\nFigure 4: An excerpt of the AMR2FRED RDF graph.\n(including type declaration, label annotations, etc.). Out of these axioms, 21\nare equivalence axioms, expressed via the owl:equivalentClass prop-\nerty.\nBox 2 - Base graph\nfred:Athlete rdfs:subClassOf dul:Person,\nwn30:supersense-noun person ;\nowl:equivalentClass wn30:synset-athlete-noun-1 .\nfred:celebrate 1 a pbrs:celebrate-01 ;\nvn.role:Location fred:track 1 ;\npblr:celebrate-01.honored fred:win 1 ;\npblr:celebrate-01.honorer fred:athlete 1 .\nThe athlete is a Person. The gesture of celebration takes\nplace on the track. The victory is what is celebrated, the\nathlete is the one celebrating.\nConsidering semantic web resources, the most retrieved are WordNet, Prop-\nBank and DOLCE: 33 entities from WordNet are retrieved, regarding both\nphysical entities such as wn:synset-flag-noun-1,\nwn:synset-uniform-noun-1andwn:synset-athlete-noun-1,and\nmore abstract ones such as wn:synset-joy-noun-1, and\n16\nwn:synset-international-adjective-1.\nGraph Axioms WordNet PB Roles PB Frames VN Roles D0 DUL\nBase Graph 293 33 23 20 1 4 10\nTable1TriplesgeneratedfortheBaseGraphdetailedwithoriginofthearchesandnodes.\nFrom PropBank we have 23 local roles, namely instantiations of specific\nroles of a PropBank frame, including triples like:\nfred:wear 1pblr:wear-01.clothingfred:uniform 1;\npblr:wear-01.wearer fred:athlete 1 .\nwhich means that the node “wear 1” (namely an occurrence of wear-\ning retrieved by FRED) takes as “clothing” role the node “uniform 1” and\nas “wearer” role, the node “athlete 1”. As for PropBank frames, we have\n20 distinct entities, among others: pbrs:win-01, pbrs:achieve-01,\nand pbrs:celebrate-01. Finally, we retrieve 4 entities from DOLCE\n0:d0:CognitiveEntity, d0:Event, d0:Characteristic, and\nd0:Activity; and 10 resources from DOLCE Ultralite, of which three are\nproperties: dul:associatedWith, dul:hasMember, and\ndul:hasQuality, and 7 are entities, such as dul:Person,\ndul:Situation,anddul:InformationEntity. AlltheSPARQLqueries\ntoinvestigatethegraphsareavailableasadditionalmaterialsontheGitHub13.\nExtended Knowledge Graphs. We summarize here some numbers about\nthe 11 XKGs generated with the heuristics; all the graphs are available on\nGitHub14.\nTable 2 omits the columns for D0 and DUL, since most of XKGs do\nnot declare alignments to DOLCE classes. Two notable exceptions are: the\ndul:precedes property, used to state sequential order of entities, which is\nextensively present in Presuppositions as well as Event Sequences, and Im-\nplied Future Events XKGs; and the Image Schema XKG, which presents 14\n13https://github.com/StenDoipanni/XKG/tree/main/resources/\nsparql-queries\n14https://github.com/StenDoipanni/XKG/tree/main/resources/\ngraphs\n17\nGraph Axioms WordNet PB Roles PB Entities OP DP\nPresuppositions 32 - - 3 - 11\nConversational Implicatures 36 6 - - 14 -\nFactual Impact 13 5 - - 3 -\nImage Schemas 63 11 - - 1 -\nMetonymic Coercion 26 - 5 5 7 -\nMoral Value-driven Coercion 12 - 2 1 3 -\nSymbolic Coercion 15 7 - - 1 -\nEvent Sequences 15 - - - 1 -\nCausal Relations 16 1 - - 1 -\nImplied Future Events 14 - 1 1 2 -\nPotential Non-events 23 - 5 4 5 -\nTable 2 Triples generated for the Base Graph and the 11 heuristics graphs, including\naxioms count, presence of WordNet entities, PropBank Roles, PropBank frames, and\nnewly introduced Object Properties or Data Properties.\nalignments of image schemas to DUL classes; among them: “Balance” sub-\nClass of dul:Quality, “Collection” subClass of dul:Collection, “Ci-\ncle” subClass of dul:Process, “Path” subClass of dul:SpaceRegion,\nand “Container” as subClass of dul:PhysicalObject.\nBox 3 shows and exceprt of triples generated in the Factual Impact XKG.\nWe discuss the plausibility and correctness of alignments and triples in the\nnext sections, via a three-tier evaluation.\nBox 3 - Factual Impact\nfred:athlete 1 impact:hasExpectedEmotion impact:Joy,\nimpact:Pride ;\nimpact:hasExpectedPhysicalState impact:Exhilaration ;\nimpact:hasExpectedSocialImpact impact:NationalRecognition.\nThe athlete is expected to feel joy and pride, it is\nexpected to be ecstatic, and to receive some form of national\nrecognition for winning.\nA particularly salient aspect of XKGs is the introduction of novel proper-\nties, asdelineatedinthefinaltwocolumnsofTable2. Thesecolumns, labeled\nOP and DP, represent newly introduced “Object Properties” and “Datatype\n18\nProperties” respectively, offering insight into the ontological expansion and\nsemantic extension of each knowledge graph.\nTable 2 presents an overview of the composition of XKGs. The graphs\nexhibit significant variation in their structural complexity and semantic rich-\nness, reflecting the diverse nature of the conceptual domains being modeled.\nThe “Axioms” column reveals considerable differences in the logical foun-\ndations of each graph, ranging from 12 axioms in the Moral Value-driven\nCoercion graph to a notable 63 in the Image Schemas graph. This substan-\ntial difference can be traced back to the nature of the reference image being\na sport scene, which likely fosters a richer generation of triples, and repre-\nsentation of knowledge related to spatial relations, bodily movements, and\nphysical interactions—concepts central to Image Schemas. The integration\nof external lexical-semantic resources is evident, with WordNet entities be-\ning prominently featured in several graphs, particularly in Conversational\nImplicatures (6) and Image Schemas (11). PropBank roles and entities are\nless frequently incorporated, with the Event Sequences graph showing the\nhighest utilization (5 PB Entities), possibly indicating a focus on action-\noriented semantics in depicting the sequential nature of plausible events.\nThe graphs also exhibit varying degrees of expressiveness, as indicated by\nthe introduction of new Object Properties (OP) and Datatype Properties\n(DP). The Conversational Implicatures graph stands out in this regard, in-\ntroducing 14 new Object Properties, among which we see :hasVictory,\n:hasEmotion, :hasNationality, and :hasSignificance, showing\nseveral semantic layers collapsed in the same XKG, including a huge amount\nof implicit knowledge that could be further unpacked. Similarly, the Presup-\npositions graph adds 11 new Data Properties. It is noteworthy the fact that\nall of them takes as object a boolean ‘True’ vs ‘False’, and all of them takes\nas value ‘True’, pointing in the direction that, in lack of a certain informa-\ntion, e.g. the exact date in which the stadium was built, it is still possible to\nrepresent on the graph this information introducing an axiom like:\nfred:stadium 1 fred:wasBuiltBefore true.\nThis heterogeneity in graph composition not only reflects the diverse re-\nquirements for semantic expressivity across different areas of knowledge rep-\nresentation but also underscores how different domain-related images e.g.\nsports-centric vs political, could influence the depth and breadth of implicit\nknowledge extraction.\n19\nLogical Integrity and Foundational Ontologies Compliance. To en-\nsure the structural integrity and logical consistency of all XKGs, we use the\nHermit 1.4.3.456 reasoner [11] as part of our evaluation framework, as well\nas OOPS! - OntOlogy Pitfall Scanner [9].\nThe reasoner’s check is meant to ver-\nify soundness and consistency of the newly\nintroduced LLM-generated triples, thereby\nensuring that the extended knowledge re-\nmains sound and usable for downstream ap-\nplications and inference tasks. In particular,\nwe use Hermit via Prot´eg´e 5.5.0 interface\nand OOPS! web interface15. Passing each\nand every XKG graph to OOPS!, the pitfall\nscanner yields minor issues for all of them,\nmainly related to the absence of metadata\nsuch as rdfs:comment describing entities.\nOccasionalinstancesofhallucinationcan\nFigure 5: Prot´eg´e vizualisation of\nbeen observed, particularly in the applica-\ninferences obtained running Hermit\n1.2.3.456 on the Event Sequences tion of prefixes. An example occurs in the\nextended graph. Metonymic coercion file, where the prefix\n“pbrs” (denoting PropBank Role Set, which\nPropBank utilized for frame-like structures) is erroneously employed instead\nof the correct prefix “pblr” (PropBank Local Role), which is the appropriate\ndesignation for occurrences of PropBank roles. Such inconsistencies, while\nminor, underscore the importance of rigorous post-processing and validation\nin ensuring the accuracy and reliability of the model’s semantic annotations,\nas described in Section 5.\nFor soundness validation, we checked each XKG importing both the Base\nGraph and DOLCE Zero, in order to ensure complete coherence with the\nAMR2FRED original graph, as well as the DOLCE foundational ontology.\nAn isolated instance of inconsistency is identified in the Metonymic Co-\nercions heuristic graph, suggesting the fact this XKG could present problems\non several sides. This anomaly manifested as a conflicting chain of subsump-\ntions (athlete 1 → Athlete → Person → Agent → Object) wherein a single\n15https://oeg.fi.upm.es/index.php/en/technologies/292-oops/\nindex.html\n20\nentity is erroneously classified as both an Object and an Event. Specifically,\n‘athlete 1’ is incorrectly categorized as an instance of ‘wn:cheer-01’, rather\nthan being appropriately designated as an agent of the cheering action. It\nis noteworthy that while the d0:Event class is deprecated, we have opted\nto retain it in our consistency verification process due to its relevance in\nidentifying misalignments.\nOther than checking for inconsistencies, found only in the Metonymic\nCoercion XKG, as mentioned above, reasoning over XKGs with the import\nof Base Graph and DOLCE 0, yields relevant inferences, as shown in Figure\n5. The Event Sequences XKG, in fact, making use of the d0:precedes\nproperty, allows to infer the order of events thanks to the transitivity of\nthe property, positioning them in sequential order not explicitly stated. In\nthis case, as shown in Figure 5, the occurrence of celebration is inferred as\nsequentiallyposteriortotheracingaction,thecompetitionevent,thewearing\naction, and the winning event.\nXKGs Human Evaluation. To ensure the quality and reliability of the\ngenerated triples, we conduct a comprehensive human evaluation process.\nThe validation was performed by 5 annotators, all of whom possess profi-\nciency in Resource Description Framework (RDF) and Turtle syntax, but\nare not domain experts across all 11 heuristics considered. Each triple pro-\nduced in our extension undergoes scrutiny and is labeled using a 5-point\nLikert scale, where 1 represents “Not at all plausible/adequate” and 5 indi-\ncates “Completely plausible/adequate”. This approach allows for a nuanced\nassessment of the triples’ validity and relevance within their respective do-\nmains. By employing annotators with RDF expertise but varying levels of\ndomain-specific knowledge, we aims to balance technical accuracy with a\ngeneralist perspective, mirroring real-world scenarios where RDF data may\nbe consumed by users with diverse backgrounds.\nFurthermore, to ensure the reliability and consistency of our ratings, we\nemploys multiple statistical measures. Inter-rater agreement is calculated to\nassess the overall concordance among raters. Krippendorff’s alpha is chosen\nfor its ability to handle ordinal data and accommodate multiple raters, pro-\nviding a robust measure of reliability. Cohen’s Kappa, while typically used\nfor binary ratings, is adapted to evaluate pairwise agreement between raters.\nMean ratings are computed to provide a central tendency measure of the\nperceived quality of the generated triples. Finally, we calculate the standard\ndeviation to quantify the dispersion of ratings, to get further insight into the\n21\nFigure 6: Mean Ratings and Standard Deviation per Heuristics.\nconsistency or variability of assessments across raters.\nMean Ratings and Standard Deviation. It is important to highlight\nthat, given the 5 point Likert scale, almost all the heuristics overall passed\nthe threshold of 3, with the exception of Implied Future Events, which still\nshows a rating of 2.94. This means that, overall, the XKGs present at least\n“fairly plausible” knowledge extension for all the domains. This is per se a\nremarkable achievement, given the disparity among the domains, which cou-\npled with symbolic reasoning inference regarding e.g. sequences of events,\nmentioned above, opens to very promising further neurosymbolic methodol-\nogy exploration.\nFurthermore, the analysis of mean ratings and standard deviations across\nvarious heuristics shown in Figure 6 reveals interesting patterns in the per-\nformance and consistency of different evaluation criteria. Factual Impact,\nConversational Implicatures, and Moral Value-driven Coercions emerge as\nthe top-performing heuristics, with mean ratings exceeding 4.29 on a 5-point\nscale. This suggests a high degree of plausibility or adequacy in these areas.\nConversely, Potential Non-Events and Image Schemas received the lowest\nmean ratings (2.94 and 3.64, respectively), indicating potential areas for im-\nprovement in the language model’s output. Notably, the standard deviations\nexhibit considerable variation, with Implied Future Events showing the high-\nest variability (SD = 1.57) and Moral Value-driven Coercions demonstrating\n22\nFigure 7: Mean Scores by Annotator for Each Heuristic.\nthemostconsistency(SD=0.47). Thisdisparityinstandarddeviationshigh-\nlights the varying levels of agreement among raters across different heuristics.\nThe data underscores the need for targeted refinements in certain aspects of\nthe language model’s performance, particularly in areas with lower mean rat-\nings or higher standard deviations, to enhance the overall quality and consis-\ntency of generated content, which is discussed in Section 5. There might be\na possible “remoteness effect” when users evaluate uncertain (as with future\nevents) or very abstract (as with image schemas) implicit knowledge, which\nshould be further investigated by involving field experts.\nMean Scores per Annotator. The analysis of mean scores by annota-\ntor for each heuristic, shown in Figure 7, reveals significant insights into the\nevaluation process and possibly the nature of the heuristics themselves. No-\ntably, there is considerable variation in scoring patterns across annotators,\nsuggesting potential differences in interpretation or application of the evalu-\nation criteria. Annotator 1 consistently provided higher scores across most\nheuristics, particularly for Conversational Implicatures (4.87) and Factual\nImpact (4.75), while Annotator 3 tended to score more conservatively, es-\npecially for Implied Future Events (1.43). The heuristics of Factual Impact\nand Causal Relations demonstrated relatively high consensus among anno-\ntators, with most scores clustering above 4.0, indicating their robustness and\nclarity. Conversely, Implied Future Events and Potential Non-events exhib-\n23\nited the widest disparity in scores, ranging from 1.43 to 3.86 and 3.19 to\n4.31 respectively, highlighting areas where the evaluation criteria may ben-\nefit from refinement. This variability underscores the subjective nature of\ncertain heuristics and emphasizes the importance of clear guidelines and cal-\nibration sessions in future annotation tasks to enhance inter-rater reliability\nand the overall validity of the evaluation process.\nFurthermore, the scoring patterns reveal distinct tendencies among the\nfive annotators, showcasing varying levels of “generosity” in their evalua-\ntions: Annotator 1 emerges as the most generous evaluator, consistently\nproviding the highest scores across most heuristics. This is particularly evi-\ndent in Conversational Implicatures (4.87), Factual Impact (4.75), and Moral\nValue-driven Coercions (4.57). Their scores are frequently at least 0.5 points\nhigher than the next highest annotator, suggesting a more lenient interpre-\ntation of the evaluation criteria. Annotator 5 appears to be the second most\ngenerous, often providing scores close to, but slightly below, Annotator 1.\nThey show particular generosity in Presuppositions (4.55) and Factual Im-\npact (4.75), matching Annotator 1 in the latter. Annotator 2 demonstrates\na more moderate approach, typically scoring in the middle range compared\nto other annotators. However, they show higher scores for Causal Relations\n(4.43) and Potential Non-Events (4.31), indicating possible areas of expertise\nor confidence. Annotator 4 tends to be more conservative in their scoring,\noften providing lower scores than Annotators 1, 2, and 5. This is particularly\nnoticeable in heuristics like Metonymic Coercions (3.44) and Implied Future\nEvents (3.00). However, they align more closely with others on some heuris-\ntics like Presuppositions (4.30). Annotator 3 emerges as the most stringent\nevaluator overall. They consistently provide the lowest scores across multiple\nheuristics, most notably in Implied Future Events (1.43) and Image Schemas\n(3.09). This suggests a more critical approach to the evaluation process or\npossibly a stricter interpretation of the scoring criteria.\nAgreement Measures. Figure 8 shows how Moral Value-driven Coercions\ndemonstrate the highest overall agreement, with an inter-rater agreement of\n0.75andaCohen’sKappaof0.51,suggestingstrongconsistencyamongraters\nfor this heuristic. Conversely, Implied Future Events show the lowest agree-\nment across all measures, indicating a potential need for refinement in its\ndefinition or evaluation criteria. Notably, Krippendorff’s Alpha consistently\nyields lower values compared to other measures, with several heuristics show-\ning negative values, particularly for Metonymic Coercions and Moral Value-\n24\nFigure 8: Agrement measures\ndriven Coercions. This discrepancy between Krippendorff’s Alpha and other\nmeasures warrants further investigation, as it may indicate sensitivity to spe-\ncific patterns in the data or potential limitations in applying this metric to\nthe current evaluation framework. The generally moderate to low agreement\nscores across most heuristics, especially for measures like Factual Impact and\nConversational Implicatures, underscore the challenges in achieving consis-\ntent evaluations for potentially conceptually complex phenomena.\nFollowing AAAI-20 talk by Henry Kautz16, these results confirm that the\nusage of LLMs in our hybrid pipeline moves significant steps not towards\nexpert reasoning, but mostly towards commonsense reasoning.\n5. Ongoing and Future Work\nIn our ongoing efforts to refine and enhance the generation of XKGs,\nseveral specific improvements are being explored. Prompt refinement for in-\ncontext learning has emerged as a crucial area for development, particularly\nin light of insights gained from image schemas. Our current approach utilizes\na standard template, but evidence suggests that more adapted heuristic-\nspecific prompts could yield superior results.\n16https://www.youtube.com/watch?v=_cQITY0SPiw\n25\nAnother area of focus is the refinement of property assignments. Cur-\nrently, many triples are generated using the broad dul:associatedWith\ntop property. Efforts are underway to specialize this property further, align-\ning newly introduced properties with DOLCE Zero. While this integration\nmay increase the risk of ontological inconsistencies, it also promises enhanced\ninferential capabilities.\nWe are also reevaluating our validation methodology. The current sys-\ntem17, which informs annotators of the heuristic definition they are validat-\ning, may be influencing results. An alternative approach, such as presenting\nuncontextualized triples for evaluation, could potentially yield different out-\ncomes in human assessment.\nLastly, we are exploring alignment with domain-specific ontologies, par-\nticularly those focused on Image Schemas [36], moral and cultural values\n[69], and other cognitive entities such as emotions. This could involve refin-\ning prompts to incorporate either complete ontology schemas (when feasible)\nor at least excerpts of top taxonomy classes, potentially leading to more nu-\nanced and domain-specific knowledge.\nFuture work will focus on several key areas to enhance the capabilities\nand applicability of our graph enrichment process. A primary objective is the\ntopicalization of enrichment when starting from images, which involves local-\nizing triples related to specific heuristics to particular portions of an image.\nThis can be achieved through the utilization of existing labeled repositories\nsuch as Visual Genome or ImageNet, or by implementing object-scene recog-\nnition algorithms that disambiguate to WordNet synsets before proceeding\nwith triple generation.\nAddressing the challenges of Wikidata entry alignment is another cru-\ncial area of development. While AMR2FRED proves reliable for the Base\nGraph, LLM-based alignment has shown significant inconsistencies, high-\nlighting issues with precise information retrieval and hallucinations. A pro-\nposed solution involves using the “wd:” prefix with entity labels, followed\nby script-based verification using SPARQL engines like Qlever [70]. This\nmethod, incorporating CamelCase string parsing, shows promise for specific\nnamed entities but may require further refinement for general conceptual\nentities.\n17Available here:https://github.com/StenDoipanni/XKG/blob/main/\nresources/XKG-human-validation-form.pdf\n26\nAlthough our method is model-agnostic, practical results vary across dif-\nferent LLMs. Current implementation relies on state-of-the-art models re-\nquiring proprietary APIs. Future efforts will focus on refining prompts and\nsegmenting processes to enable the use of smaller yet efficient models like Phi\n3.5, potentially broadening accessibility.\nLastly, we envision expanding our service to accommodate user-defined\nprompts, opening up a vast array of possibilities for knowledge graph exten-\nsion. This could include specialized applications such as e.g., color coercions\nfor environmental elements (we assume that if there is a portion of image\nwhich represents the sea, or a forest, or snow, etc. there could be a spe-\ncific color palette) or e.g. identifying potential safety hazards in images (this\ncould have relevant impact in social robotics). The potential applications are\ndiverse and hold significant relevance across various domains, underscoring\nthe expansive capabilities of our approach in knowledge representation and\nreasoning.\n6. Conclusions\nOur research presents a significant step forward in the development of\na hybrid neurosymbolic method for grounded world models that can effec-\ntively integrate multiple layers of knowledge, bridging the gap between the\npattern-matching reactivecapabilitiesofLLMs, andthestructuredreasoning\napplied on Knowledge Bases and traditional symbolic reasoning. By lever-\naging LLMs as repositories of implicit commonsense knowledge rather than\nexpert systems, we have demonstrated a novel approach to knowledge base\nextension that is both agile and comprehensive.\nThese results also add to a growing corpus of results about the hidden\ncorrespondence of massive linguistic knowledge to the structure of human\nenvironments, be them physical, social, cognitive or purely abstract.\nThe multi-tiered evaluation framework we employed, encompassing logi-\ncal validation, foundational ontology alignment, and human assessment, pro-\nvides strong evidence for the efficacy of our approach and future promising\nrefinements. The high plausibility ratings across most heuristics, particularly\nin areas such as Factual Impact, Conversational Implicatures, and Moral\nValue-driven Coercions, underscore the potential of our method to capture\nnuanced semantic information that goes beyond simple fact retrieval.\nHowever, the challenges revealed in our evaluation, particularly in areas\nlikeImpliedFutureEventsandImageSchemas, pointtoimportantdirections\n27\nfor future work. The variability in inter-rater agreement across different\nheuristics highlights the complexity of evaluating implicit knowledge and the\nneed for continued refinement of our methods and evaluation criteria, even\nif uncertainty (for future events) and abstractness (for image schemas) of\nimplicit knowledge are probably good reasons for lower agreement.\nThe neuro-symbolic nature of our approach, combining the strengths of\nneural networks and symbolic reasoning, opens up new possibilities for sys-\ntems that can flexibly adapt to novel contexts while maintaining the ability\nto perform structured inference. This hybrid architecture addresses long-\nstanding challenges in AI, such as the Frame problem, by providing a mech-\nanism for dynamically integrating diverse knowledge sources and reasoning\npatterns.\nLooking ahead, our work lays the foundation for several promising re-\nsearch directions. The potential for topicalization of enrichment on images,\nimproved alignment with domain-specific ontologies, and the exploration of\nuser-defined prompts for specialized applications all represent exciting av-\nenues for extending the capabilities of our system.\nIn conclusion, our research contributes to the broader goal of develop-\ning systems capable of human-like reasoning and contextual understanding\nrelevant in several areas ranging from natural language processing and com-\nputer vision to complex problem-solving and decision-making in real-world\nscenarios.\nAcknowledgements\nThis work was supported by the Future Artificial Intelligence Research\n(FAIR) project, code PE00000013 CUP 53C22003630006.\nReferences\n[1] Meyer, L.P., Stadler, C., Frey, J., Radtke, N., Junghanns, K., Meissner,\nR., Dziwis, G., Bulert, K., Martin, M., “LLM-assisted knowledge graph\nengineering: Experiments with ChatGPT,” in Working conference on\nArtificial Intelligence Development for a Resilient and Sustainable To-\nmorrow, pp. 103–115, 2023.\n[2] Gangemi, A., Recupero, D.R., Mongiov`ı, M., Nuzzolese, A.G., Presutti,\nV., “Identifying motifs for evaluating open knowledge extraction on the\nWeb,” Knowledge Based Systems, vol. 108, pp. 33–41, 2016.\n28\n[3] Zhu, Y., Wang, X., Chen, J., Qiao, S., Ou, Y., Yao, Y., Deng, S., Chen,\nH., Zhang, N., “LLMs for knowledge graph construction and reasoning:\nRecent capabilities and future opportunities,” World Wide Web, vol. 27,\nno. 5, pp. 58, 2024.\n[4] Sen, P., Mavadia, S., Saffari, A., “Knowledge graph-augmented lan-\nguage models for complex question answering,” in Proceedings of the\n1st Workshop on Natural Language Reasoning and Structured Expla-\nnations (NLRSE), pp. 1–8, 2023.\n[5] Edge, D., Trinh, H., Cheng, N., Bradley, J., Chao, A., Mody, A., Truitt,\nS., Larson, J., “From local to global: A graph rag approach to query-\nfocused summarization,” arXiv preprint arXiv:2404.16130, 2024.\n[6] Yao, L., Mao, C., Luo, Y., “KG-BERT: BERT for knowledge graph\ncompletion,” arXiv preprint arXiv:1909.03193, 2019.\n[7] Lu, F., Cong, P., Huang, X., “Utilizingtextualinformationinknowledge\ngraphembedding: Asurveyofmethodsandapplications,” IEEEAccess,\nvol. 8, pp. 92072–92088, 2020.\n[8] Tiwari, S., Mihindukulasooriya, N., Osborne, F., Kontokostas, D.,\nD’Souza, J., Kejriwal, M., et al., “Preface for the International Work-\nshop on Knowledge Graph Generation from Text,” in CEUR WORK-\nSHOP PROCEEDINGS, vol. 3184, 2022.\n[9] Poveda-Villalo´n, M., G´omez-P´erez, A., Sua´rez-Figueroa, M.C.,\n“Oops!(ontology pitfall scanner!): An on-line tool for ontology evalua-\ntion,” International Journal on Semantic Web and Information Systems\n(IJSWIS), vol. 10, no. 2, pp. 7–34, 2014.\n[10] Fathallah, N., Das, A., De Giorgis, S., Poltronieri, A., Haase,\nP., Kovriguina, L., “NeOn-GPT: A Large Language Model-Powered\nPipeline for Ontology Learning,” in The Extended Semantic Web Con-\nference, 2024.\n[11] Glimm, B., Horrocks, I., Motik, B., Stoilos, G., Wang, Z., “HermiT: an\nOWL 2 reasoner,” Journal of automated reasoning, vol. 53, pp. 245–269,\n2014.\n29\n[12] Paulheim, H., Gangemi, A., “Serving DBpedia with DOLCE–more than\njust adding a cherry on top,” in The Semantic Web-ISWC 2015: 14th\nInternational Semantic Web Conference, pp. 180–196, 2015.\n[13] Bevilacqua, M., Blloshmi, R., Navigli, R., “One SPRING to rule them\nboth: Symmetric AMR semantic parsing and generation without a com-\nplex pipeline,” in Proceedings of the AAAI Conference on Artificial In-\ntelligence, vol. 35, no. 14, pp. 12564–12573, 2021.\n[14] Wu, L., Petroni, F., Josifoski, M., Riedel, S., Zettlemoyer, L., “Scal-\nable zero-shot entity linking with dense entity retrieval,” arXiv preprint\narXiv:1911.03814, 2019.\n[15] Meloni,A.,ReforgiatoRecupero,D.,Gangemi,A.,“AMR2FRED,atool\nfor translating abstract meaning representation to motif-based linguistic\nknowledge graphs,” in The Semantic Web: ESWC 2017 Satellite Events,\npp. 43–47, 2017.\n[16] Bevilacqua, M., Navigli, R., “Breaking Through the 80% Glass Ceiling:\nRaising the State of the Art in Word Sense Disambiguation by Incor-\nporating Knowledge Graph Information,” in Proceedings of the 58th\nAnnual Meeting of the Association for Computational Linguistics, pp.\n2854–2864, 2020.\n[17] Hamilton, K., Nayak, A., Boˇzi´c, B., Longo, L., “Is neuro-symbolic ai\nmeeting its promises in natural language processing? a structured re-\nview,” Semantic Web, pp. 1–42, 2022.\n[18] Kautz, H., “The third ai summer: AAAI robert s. engelmore memorial\nlecture,” AI magazine, vol. 43, no. 1, pp. 105–125, 2022.\n[19] Gangemi, A., Alam, M., Asprino, L., Presutti, V., Recupero, D.R.,\n“Framester: A wide coverage linguistic linked data hub,” in Knowledge\nEngineering and Knowledge Management, pp. 239–254, 2016.\n[20] Belle, V., “Symbolic logic meets machine learning: A brief survey in\ninfinite domains,” in International conference on scalable uncertainty\nmanagement, pp. 3–16, 2020.\n[21] Besold, T.R., d’Avila Garcez, A., Bader, S., Bowman, H., Domingos, P.,\nHitzler, P., et al., “Neural-symbolic learning and reasoning: A survey\n30\nand interpretation 1,” in Neuro-Symbolic Artificial Intelligence: The\nState of the Art, pp. 1–51, 2021.\n[22] Garcez, A.d’A., Lamb, L.C., “Neurosymbolic AI: The 3rd wave,” Arti-\nficial Intelligence Review, vol. 56, no. 11, pp. 12387–12406, 2023.\n[23] Lamb, L.C., Garcez, A., Gori, M., Prates, M., Avelar, P., Vardi, M.,\n“Graph neural networks meet neural-symbolic computing: A survey and\nperspective,” arXiv preprint arXiv:2003.00330, 2020.\n[24] Sarker, M.K., Zhou, L., Eberhart, A., Hitzler, P., “Neuro-symbolic ar-\ntificial intelligence,” AI Communications, vol. 34, no. 3, pp. 197–209,\n2021.\n[25] Yao, Y., Xu, J., Shi, J., Xu, B., “Learning to activate logic rules for\ntextual reasoning,” Neural Networks, vol. 106, pp. 42–49, 2018.\n[26] Yu, D., Yang, B., Liu, D., Wang, H., Pan, S., “A survey on neural-\nsymbolic learning systems,” Neural Networks, 2023.\n[27] Zhang, J., Chen, B., Zhang, L., Ke, X., Ding, H., “Neural, symbolic and\nneural-symbolic reasoning on knowledge graphs,” AI Open, vol. 2, pp.\n14–35, 2021.\n[28] Brachman, R.J., “What’s in a concept: structural foundations for se-\nmantic networks,” International journal of man-machine studies, vol. 9,\nno. 2, pp. 127–152, 1977.\n[29] Minsky, M., et al., “A framework for representing knowledge,” Mas-\nsachusetts Institute of Technology AI Laboratory Cambridge, 1974.\n[30] Fillmore, C.J., et al., “Frame semantics,” Cognitive linguistics: Basic\nreadings, vol. 34, pp. 373–400, 2006.\n[31] Alam, M., Gesese, G.A., Paris, P.H., “Neurosymbolic Methods for Dy-\nnamic Knowledge Graphs,” arXiv preprint arXiv:2409.04572, 2024.\n[32] Gangemi, A., “Closing the Loop between knowledge patterns in cogni-\ntion and the Semantic Web,” Semantic Web, vol. 11, no. 1, pp. 139–151,\n2020.\n31\n[33] Miller, G.A., “WordNet: An electronic lexical database,” MIT press,\n1998.\n[34] Schuler, K.K., “VerbNet: A broad-coverage, comprehensive verb lexi-\ncon,” University of Pennsylvania, 2005.\n[35] Gangemi, A., Presutti, V., Alam, M., “Amnestic Forgery: An Ontology\nof Conceptual Metaphors,” in Formal Ontology in Information Systems,\n2018.\n[36] De Giorgis, S., Gangemi, A., Gromann, D., “Imageschemanet: Formal-\nizing embodied commonsense knowledge providing an imageschematic\nlayer to framester,” Semantic Web Journal, 2022.\n[37] Navigli, R., Ponzetto, S.P., “BabelNet: Building a very large multilin-\ngual semantic network,” in Proceedings of the 48th annual meeting of\nthe association for computational linguistics, pp. 216–225, 2010.\n[38] Auer, S., Bizer, C., Kobilarov, G., Lehmann, J., Cyganiak, R., Ives, Z.,\n“Dbpedia: A nucleus for a web of open data,” in The semantic web, pp.\n722–735, 2007.\n[39] Suchanek, F.M., Kasneci, G., Weikum, G., “Yago: a core of seman-\ntic knowledge,” in Proceedings of the 16th international conference on\nWorld Wide Web, pp. 697–706, 2007.\n[40] Gangemi, A., Guarino, N., Masolo, C., Oltramari, A., “Sweetening\nwordnet with dolce,” AI magazine, vol. 24, no. 3, pp. 13–13, 2003.\n[41] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., “Unifying large\nlanguage models and knowledge graphs: A roadmap,” IEEE Transac-\ntions on Knowledge and Data Engineering, 2024.\n[42] Gangemi, A., Presutti, V., Reforgiato Recupero, D., Nuzzolese, A.G.,\nDraicchio, F., Mongiov`ı, M., “Semantic web machine reading with\nFRED,” Semantic Web, vol. 8, no. 6, pp. 873–893, 2017.\n[43] Baker, C.F., Fillmore, C.J., Lowe, J.B., “The berkeley framenet\nproject,” in Proceedings of the 17th international conference on Com-\nputational linguistics, pp. 86–90, 1998.\n32\n[44] Kingsbury, P.R., Palmer, M., “From TreeBank to PropBank,” in LREC,\npp. 1989–1993, 2002.\n[45] Karttunen, L., “Presupposition: What went wrong?,” in Semantics and\nLinguistic Theory, pp. 705–731, 2016.\n[46] Frege, G., “On sense and reference,” 1892.\n[47] Strawson, P.F., “On referring,” Mind, vol. 59, no. 235, pp. 320–344,\n1950.\n[48] Grice, H.P., “Logic and conversation,” Syntax and semantics, vol. 3,\n1975.\n[49] Levinson, S.C., “Presumptive meanings: The theory of generalized con-\nversational implicature,” MIT press, 2000.\n[50] Kahneman, D., “Article commentary: Judgment and decision making:\nA personal view,” Psychological science, vol. 2, no. 3, pp. 142–145, 1991.\n[51] Johnson, M., “The Body in the Mind: The Bodily Basis of Meaning,\nImagination, and Reason,” The University of Chicago Press, 1987.\n[52] Lakoff, G., Johnson, M., “Metaphors we live by,” University of Chicago\npress, 1980.\n[53] Lakoff, G., Johnson, M., et al., “Philosophy in the flesh: The embodied\nmind and its challenge to western thought,” Basic books New York,\n1999.\n[54] Besold, T.R., Hedblom, M.M., Kutz, O., “A narrative in three acts:\nUsing combinations of image schemas to model events,” Biologically\ninspired cognitive architectures, vol. 19, pp. 10–20, 2017.\n[55] Hedblom, M.M., “Image schemas and concept invention: cognitive, log-\nical, and linguistic investigations,” Springer Nature, 2020.\n[56] Maudslay, R.H., Teufel, S., Bond, F., Pustejovsky, J., “ChainNet:\nStructured Metaphor and Metonymy in WordNet,” arXiv preprint\narXiv:2403.20308, 2024.\n33\n[57] Graham, J., Haidt, J., Koleva, S., Motyl, M., Iyer, R., Wojcik, S.P.,\nDitto, P.H., “Moralfoundationstheory: Thepragmaticvalidityofmoral\npluralism,” Advances in experimental social psychology, vol. 47, pp. 55–\n130, 2013.\n[58] Rozin, P., Lowery, L., Imada, S., Haidt, J., “The CAD triad hypothesis:\na mapping between three moral emotions (contempt, anger, disgust)\nand three moral codes (community, autonomy, divinity),” Journal of\npersonality and social psychology, vol. 76, no. 4, pp. 574, 1999.\n[59] Schwartz, S.H., Melech, G., Lehmann, A., Burgess, S., Harris, M.,\nOwens, V., “Extending the cross-cultural validity of the theory of ba-\nsic human values with a different method of measurement,” Journal of\ncross-cultural psychology, vol. 32, no. 5, pp. 519–542, 2001.\n[60] Peirce, C.S., Buchler, J., “Logicassemiotic: Thetheoryofsigns,” Philo-\nsophical Writings of Peirce, pp. 100, 1902.\n[61] Eliot, T.S., et al., “Hamlet and his problems,” The sacred wood: Essays\non poetry and criticism, vol. 4, pp. 95–104, 1920.\n[62] Forrester, J.W., “Counterintuitive behavior of social systems,” Theory\nand decision, vol. 2, no. 2, pp. 109–140, 1971.\n[63] Gangemi, A., Graciotti, A., Meloni, A., Nuzzolese, A.G., Presutti, V.,\nReforgiato Recupero, D., Russo, A., Tripodi, R., “Text2AMR2FRED,\na Tool for Transforming Text into RDF/OWL Knowledge Graphs via\nAbstract Meaning Representation,” in Proceedings of the ISWC 2023\nPosters, Demos and Industry Tracks, 2023.\n[64] Ha, D., Schmidhuber, J., “World models,” arXiv preprint\narXiv:1803.10122, 2018.\n[65] Nolfi, S., “On the unexpected abilities of large language models,” Adap-\ntive Behavior, 2023.\n[66] Lambek, J., “Categorialandcategoricalgrammars,” inCategorialgram-\nmars and natural language structures, pp. 297–317, 1988.\n[67] Bos, J., “Wide-coverage semantic analysis with boxer,” in Semantics in\ntext processing. STEP 2008 conference proceedings, pp. 277–286, 2008.\n34\n[68] Grau, B.C., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., Sat-\ntler, U., “OWL 2: The next step for OWL,” Journal of Web Semantics,\nvol. 6, no. 4, pp. 309–322, 2008.\n[69] De Giorgis, S., Gangemi, A., Damiano, R., “Basic human values and\nmoral foundations theory in valuenet ontology,” in International confer-\nence on knowledge engineering and knowledge management, pp. 3–18,\n2022.\n[70] Bast, H., Buchhold, B., “Qlever: A query engine for efficient sparql+\ntext search,” in Proceedings of the 2017 ACM on Conference on Infor-\nmation and Knowledge Management, pp. 647–656, 2017.\n35",
    "pdf_filename": "Neurosymbolic_Graph_Enrichment_for_Grounded_World_Models.pdf"
}