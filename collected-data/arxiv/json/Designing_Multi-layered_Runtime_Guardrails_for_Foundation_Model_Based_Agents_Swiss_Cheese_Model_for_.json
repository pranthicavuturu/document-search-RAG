{
    "title": "Designing Multi-layered Runtime Guardrails for",
    "abstract": "tionizing application development across various domains. How- content,producingdangerousorunintendedoutcomes,spread- ever,theirrapidlygrowingcapabilitiesandautonomyhaveraised ing disinformation and misinformation, etc [77]. significant concerns about AI safety. Researchers are exploring Toaddressthesechallenges,effectiveruntimeguardrailsare better ways to design guardrails to ensure that the runtime behavior of FM-based agents remains within specific bound- keytoensurethatagentsbehaveinasafeandresponsibleman- aries. Nevertheless, designing effective runtime guardrails is ner [2]. In this context, guardrails are mechanisms integrated challengingduetotheagents’autonomousandnon-deterministic into the agent’s architecture to safeguard its behavior during behavior. The involvement of multiple pipeline stages and agent runtime, preventing undesirable or unsafe behaviors [78]. artifacts, such as goals, plans, tools, at runtime further com- Therehavebeensomeinitialeffortsonruntimeguardrailssuch plicates these issues. Addressing these challenges at runtime requires multi-layered guardrails that operate effectively at as input filtering [1, 9], output modification [10, 11], adaptive various levels of the agent architecture. Thus, in this paper, fail-safes[12,13],real-timemonitoringanddetection[14–17], we present a comprehensive taxonomy of runtime guardrails and continuous output validation [18–20]. for FM-based agents to identify the key quality attributes for However, the existing guardrail approaches primarily ad- guardrails and design dimensions based on the results of a dress functional correctness, often overlooking quality at- systematicliteraturereview.InspiredbytheSwissCheeseModel, we also propose a reference architecture for designing multi- tributes of FM-based agents, such as customizability and layered runtime guardrails for FM-based agents, which includes interpretability. Most importantly, these approaches mainly threedimensions:qualityattributes,pipelines,andartifacts.The focusonindividualsingle-layeredguardrailsthatarenarrowly proposed taxonomy and reference architecture provide concrete applied to specific agent artifacts, such as prompts or FM and robust guidance for researchers and practitioners to build outputs, which are insufficient to manage the inherent auton- AI-safety-by-design from a software architecture perspective. Index Terms—Foundation Model, Large Language Models omy and non-deterministic nature of FM-agents. If any single (LLM),Agent,Guardrails,SwissCheeseModel,ResponsibleAI, guardrail fails, the associated risks may bypass it, potentially AI Safety, Software Architecture, Taxonomy impacting the final results of the FM-based agent. Therefore, in this paper, we first present a comprehensive I. INTRODUCTION taxonomy to categorize runtime guardrails from a software AFoundationModel(FM)isalarge-scalemachinelearning architecture perspective, based on the results of a systematic model pre-trained on massive amounts of data using self- literature review. The taxonomy comprises two primary cate- supervision at scale. These models are highly versatile and gories:qualityattributesanddesignoptions.InspiredbySwiss can adapt to a wide range of downstream tasks [1]. The term Cheese Model [76], we also propose novel reference architec- ‘foundation’ reflects their role as the fundamental base upon turefordesigningmulti-layeredguardrailsofFM-basedagents which many specialized models/systems are built. However, which include three dimensions: quality attributes, pipelines, it is important to recognize that FM-based systems exhibit and artifacts. Each guardrail layer can be designed to protect inherentlimitations,particularlywhenhandlingcomplextasks. specific quality attributes (such as privacy and security), spe- Usersareoftenrequiredtoprovidedetailedinstructions,which cificpipelinestages(suchasprompts,intermediateresultsand can lead to inefficiencies and is prone to error. final results), as well as agent artifacts (such as goals, plans, AnFM-basedagentisanautonomoussystemthatiscapable and tools). While each layer may have its own weaknesses of perceiving context, reasoning, planning, and executing (i.e. holes in the Swiss Cheese Model), the combined layers workflowsby interactingwith FMs,external tools,knowledge create a a robust defense against failures. This reference bases, and other agents to achieve human goals [3]. There architecture provides concrete guidance for researchers and has been extensive interest in FM-based agent development practitioners, enabling AI-safety-by-design from a software recently due to their huge potential to enhance productivity architecture perspective. across various domains. However, their autonomous and non- deterministic behavior introduce substantial concerns regard- 4202 voN 91 ]ES.sc[ 3v50220.8042:viXra",
    "body": "Designing Multi-layered Runtime Guardrails for\nFoundation Model Based Agents: Swiss Cheese\nModel for AI Safety by Design\nMd Shamsujjoha, Qinghua Lu, Dehai Zhao, Liming Zhu\nCSIRO’s Data61, Australia\nEmail: {md.shamsujjoha, qinghua.lu, dehai.zhao, liming.zhu}@data61.csiro.au\nAbstract—Foundation Model (FM)-based agents are revolu- ing AI safety [2, 78], such as generating harmful or offensive\ntionizing application development across various domains. How- content,producingdangerousorunintendedoutcomes,spread-\never,theirrapidlygrowingcapabilitiesandautonomyhaveraised\ning disinformation and misinformation, etc [77].\nsignificant concerns about AI safety. Researchers are exploring\nToaddressthesechallenges,effectiveruntimeguardrailsare better ways to design guardrails to ensure that the runtime\nbehavior of FM-based agents remains within specific bound- keytoensurethatagentsbehaveinasafeandresponsibleman-\naries. Nevertheless, designing effective runtime guardrails is ner [2]. In this context, guardrails are mechanisms integrated\nchallengingduetotheagents’autonomousandnon-deterministic into the agent’s architecture to safeguard its behavior during\nbehavior. The involvement of multiple pipeline stages and agent\nruntime, preventing undesirable or unsafe behaviors [78].\nartifacts, such as goals, plans, tools, at runtime further com-\nTherehavebeensomeinitialeffortsonruntimeguardrailssuch\nplicates these issues. Addressing these challenges at runtime\nrequires multi-layered guardrails that operate effectively at as input filtering [1, 9], output modification [10, 11], adaptive\nvarious levels of the agent architecture. Thus, in this paper, fail-safes[12,13],real-timemonitoringanddetection[14–17],\nwe present a comprehensive taxonomy of runtime guardrails and continuous output validation [18–20].\nfor FM-based agents to identify the key quality attributes for\nHowever, the existing guardrail approaches primarily ad-\nguardrails and design dimensions based on the results of a\ndress functional correctness, often overlooking quality at-\nsystematicliteraturereview.InspiredbytheSwissCheeseModel,\nwe also propose a reference architecture for designing multi- tributes of FM-based agents, such as customizability and\nlayered runtime guardrails for FM-based agents, which includes interpretability. Most importantly, these approaches mainly\nthreedimensions:qualityattributes,pipelines,andartifacts.The focusonindividualsingle-layeredguardrailsthatarenarrowly\nproposed taxonomy and reference architecture provide concrete\napplied to specific agent artifacts, such as prompts or FM\nand robust guidance for researchers and practitioners to build\noutputs, which are insufficient to manage the inherent auton-\nAI-safety-by-design from a software architecture perspective.\nIndex Terms—Foundation Model, Large Language Models omy and non-deterministic nature of FM-agents. If any single\n(LLM),Agent,Guardrails,SwissCheeseModel,ResponsibleAI, guardrail fails, the associated risks may bypass it, potentially\nAI Safety, Software Architecture, Taxonomy impacting the final results of the FM-based agent.\nTherefore, in this paper, we first present a comprehensive\nI. INTRODUCTION\ntaxonomy to categorize runtime guardrails from a software\nAFoundationModel(FM)isalarge-scalemachinelearning architecture perspective, based on the results of a systematic\nmodel pre-trained on massive amounts of data using self- literature review. The taxonomy comprises two primary cate-\nsupervision at scale. These models are highly versatile and gories:qualityattributesanddesignoptions.InspiredbySwiss\ncan adapt to a wide range of downstream tasks [1]. The term Cheese Model [76], we also propose novel reference architec-\n‘foundation’ reflects their role as the fundamental base upon turefordesigningmulti-layeredguardrailsofFM-basedagents\nwhich many specialized models/systems are built. However, which include three dimensions: quality attributes, pipelines,\nit is important to recognize that FM-based systems exhibit and artifacts. Each guardrail layer can be designed to protect\ninherentlimitations,particularlywhenhandlingcomplextasks. specific quality attributes (such as privacy and security), spe-\nUsersareoftenrequiredtoprovidedetailedinstructions,which cificpipelinestages(suchasprompts,intermediateresultsand\ncan lead to inefficiencies and is prone to error. final results), as well as agent artifacts (such as goals, plans,\nAnFM-basedagentisanautonomoussystemthatiscapable and tools). While each layer may have its own weaknesses\nof perceiving context, reasoning, planning, and executing (i.e. holes in the Swiss Cheese Model), the combined layers\nworkflowsby interactingwith FMs,external tools,knowledge create a a robust defense against failures. This reference\nbases, and other agents to achieve human goals [3]. There architecture provides concrete guidance for researchers and\nhas been extensive interest in FM-based agent development practitioners, enabling AI-safety-by-design from a software\nrecently due to their huge potential to enhance productivity architecture perspective.\nacross various domains. However, their autonomous and non-\ndeterministic behavior introduce substantial concerns regard-\n4202\nvoN\n91\n]ES.sc[\n3v50220.8042:viXra\nThe rest of the paper is organized as follows. Section II B. Existing Guardrails Approaches and Tools for FM-Based\ndiscuss the related works and background study required Agents\nto understand the proposed works. The research methods\nThere exist several frameworks and tools for designing\nemployed in this study are described in Section III, including\nguardrails [9, 53, 55, 62, 67]. These works explored model\na brief discussion of the research protocol used for systematic\nalignment during design time to ensure that the FM’s outputs\nliterature review. The proposed taxonomy of guardrails is\nalignwithdefinedgoals.Pre-trainingandadaptationstrategies\npresented in Section IV,developed based on the results of a\nplay a significant role in mitigating risks in FM-based agents.\nsystematic literature review. The taxonomy is organized into\nOur focus, however, is on runtime guardrails that monitor and\nguardrails quality attributes and design options from different\ncontroltheagent’sbehaviorduringoperation.Theseguardrails\nperspectives. Section V proposes the reference architecture\nare essential for addressing emergent issues that arise during\nfor multi-layered runtime guardrails for FM-based agents.\nagent interactions within dynamic environments [1, 31].\nSection VI identifies and summarizes the primary threats that Some initial efforts have been made toward runtime\ncould impact the validity of this study. Finally, Section VII guardrails. NeMo Guardrails [16] provides programmable\nconcludes the paper and outlines directions for future work. guardrails to ensure that agents operate within safe param-\neters by monitoring inputs and outputs. OpenAI’s Moderation\nII. BACKGROUNDANDRELATEDWORK\nAPI [35] monitors and filters harmful content generated by\nFMshavesignificantlyadvancedcurrentagentdevelopment\nagents to protect user interactions. The GuardAgent frame-\nand emphasize the need to safeguard their behavior [3, 20].\nwork [36] utilizes an agent to oversee and safeguard other\nIn this context, guardrails for FM-based agents have been\nagents. It demonstrates strong generalization and low oper-\nexplored; however, there is a lack of comprehensive studies\national overhead by dynamically generating guardrail code.\nthat provide a thorough understanding of guardrails for FM-\nWe found that continuous validation ensures outputs from\nbasedagents.Thispaperaimstofillthisgap.Inthefollowing\nFM-based agents adhere to predefined ethical standards and\nsections, we present key background information and related\nguidelines. Techniques such as auditing agents through multi-\nwork.\nlayered approaches [18, 37] are used to check for biases and\nA. Recent State-of-the-Art Works on Foundation Models and ensure ethical compliance.\nFM-Based Agents Recently, Bengio et. al. [31] demonstrate that adaptive\nfail-safes characteristics of guardrails intervene automatically\nIn 2021, Bommasani et al. [1] provided a comprehensive\nwhen an FM-based agent exhibits potentially harmful behav-\ndiscussion on FMs, illustrating key elements, relationships,\nior.Thesefail-safesaredesignedtomodifyorhaltoutputsthat\nopportunities, and associated risks. While their focus was\ncould lead to undesirable consequences. Similarly, dynamic\non FMs in general, they highlighted the potential for these\naccesscontrolsadjustaccesspermissionsinrealtimebasedon\nmodels to serve as the foundation for more complex systems,\nthe context of data usage to protect sensitive information and\nincludingFM-basedagents.Zhouetal.[20]reviewedresearch\nensure it is accessible under appropriate circumstances [38].\nadvancements, challenges, and opportunities for pre-trained\nDue to the dynamic and adaptive nature of FM-based agents,\nmodels in text, image, graph, and data modalities. They\ndesigningeffectiveruntimeguardrailsposesseveraladditional\nalso discussed the integration of FMs into systems such as\nchallenges [2, 8] e.g., scalability of guardrail mechanisms,\nagents.Bothworksofferexcellentinsightsintofutureresearch\nthe need for real-time monitoring, and the complexity of\ndirections to address open problems and associated risks in\ninterpreting agent behaviors in diverse contexts. The authors\nFM-based agents.\nin[77]proposeaframeworkforevaluatingAIsystems,which\nRecently, Lu et al. developed a taxonomy of FM-based\nis applicable to FM-based agents. It includes harmonized\nsystems focusing on their pre-training, adaptation, architec-\nterminology, a taxonomy of key evaluation elements, and\ntural design, and responsible-AI-by-design [27]. The taxon-\na mapping of the AI lifecycle to stakeholders for ethical\nomy aids software architects and developers in evaluating\nand accountable deployment. Despite these efforts, no frame-\nand integrating FMs into complex agent systems. The authors\nworkcurrentlyprovidescomprehensiveguidanceondesigning\nthen highlighted considerations for responsible AI and safety\nmulti-layered runtime guardrails for FM-based agents, which\nattributes. Several other works [2, 8, 30, 31, 36], also empha-\nwe explore in this paper based on SLR.\nsize the importance of responsible AI and safety practices for\nFM-based agents. In [28, 29], the authors explored the risks III. METHODOLOGY\nassociated with deploying LLM-based agents and evaluated\nThis study focuses on two primary concepts: (i) foun-\ncurrent approaches for mitigating these risks through model\ndation model-based agents and (ii) runtime guardrails. We\nalignment, respectively. In 2024, a reference architecture for\nadopted the Petticrew and Roberts approach [39] to define\ndesigning responsible and safe FM-based agents is proposed\nthe Population, Interventions, Comparison, Outcomes, and\nin[3].Theauthorsdemonstratedthattheuniquecharacteristics\nContext (PICOC), within which the intervention in this study\nof FM-based agents—such as their autonomous operation,\nis delivered. The PICOC for this study is shown in Table I.\nnon-deterministic behavior, and continuous evolution—pose\nUsing these PICOC components and following Kitchenham’s\nsignificantchallengesinensuringresponsibleAIandAIsafety.\nguidelines [40], we develop the protocol for this study.\nMulti-layered Runtime Guardrails\nTaxonomy –Qualities & design options 1stResearch Question (RQ1)\nArchitecture --Swiss cheese model Key qualities for designing runtime\nguardrails for FM-based agents\nProtocol\nDevelop PICOC, Define scientific databases\nand resources for search, Formulate keyword &\nthe search string, Define qualitative &\nquantitative checklists, Specify inclusion & 2ndResearch Question (RQ3)\nexclusion criterion, Define reference Available guardrails design options\nmanagement process, Define data analysis Actions, targets & scopes\ntechiniques Strategies e.g., rules & autonomy\nModalities & techniques\nExecute Keyword Based\nAutomatic Search 3rdResearch Question (RQ3)\nACM, IEEE Xpolre, Springer, ScienceDirect, Designing multi-layered runtime guardrails\n& Google Scholar --Returns 1733 papers Architecture to address FM-based\nagents’ challenges\nStudy Filtering (Vetting Process)\nRemove Duplicate & editorials (1625 papers)\nApply exclusion criteria (101 papers) Data Extraction,\nApply inclusion criteria (21 papers) Synthesis and Analysis\nGrouping selected 21 papers Execute review\nDevelop taxonomy\nProposed architecture\nManual Search and Snowballing\nReturns 189 papers, Applying inclusion &\nexclusion criteria removes 174 papers\nFinal Report\n(15 additional papers for inclusion in the list)\nFigure1. Methodology\nTableI B. Research Questions\nPICOCFORTHISSTUDY\nWhen formulating our Research Questions (RQ), we\nPopulation Studies and researches focus on multi-layered runtime wanted to ensure that they were broad enough to capture\nguardrailswithinfoundationmodel-basedagents. the diverse aspects of multi-layered runtime guardrails while\nIntervention Development,optimization,andevaluationofmultilayer\nbeing specific enough to provide actionable insights. We\nruntime guardrails in foundation model-based agents,\nfocusingonkeyqualityattributesanddesignstrategies captured these aspects through the following three RQs:\nsimilartotheSwissCheeseModelstructure.\nComparison Comparative analysis of approaches to design multi-\nRQ1: What are essential qualities for designing runtime\nlayeredruntimeguardrailsinFM-basedagents.\nOutcomes Taxonomyofmulti-layeredruntimeguardrailsforfoun- guardrails in FM-based agents?\ndationmodel-basedagents. Our first research question studies the key qualities for\nContext Include:Empiricalandtheoreticalstudiesonthecom-\ndesigning multi-layered runtime guardrails in FM-based\nponents,designandevaluationofguardrailsinfounda-\ntionmodel-basedagents. agents. Section IV-A elaborate on how this research question\nExclude:Studiesbeyondthescopeoffoundationmodel is addressed.\nbasedagents,non-Englishliterature,andthosenotcon-\nsideringguardrails.\nRQ2: What are the design options for runtime guardrails\nin FM-based agents?\nOur second research question investigates guardrails design\nA. Research Scope and Protocol Development\noptions in FM-based agents from different perspectives,\nThe high-level research approach for this study is shown including action, target, scope, rule, autonomy, modalities,\nin Figure 1. Initially, we determined the research scope and andunderlyingtechniques.SectionIV-Boutlinesourapproach\ndeveloped a protocol following Kitchenham’s guidelines [40, to addressing this research question.\n41]. The protocol guided the entire study by defining relevant\nscientific databases and resources, formulating keywords and RQ3: How can we design runtime guardrails to address\nsearchstrings,outliningqualitativeandquantitativechecklists, the unique challenges of FM-based agents?\nand specify criteria for study inclusion and exclusion. Our third research question explores how to address the\nnoitacifitcer\n&\nnoitareti\nlanoitceridiB\negreM\n&\nkcehC\nssorC\nsrepap\n23\nTableII TableIII\nCONSOLIDATEDCONCEPTSANDSEARCHTERMS INCLUSIONCRITERIA\nMainTerms SupportiveSearchTerms ID DetailCriterion\nConcept 1 (Co1): Foundation Models, Foundation Model based IC1 Full text of conference papers, journal articles, industry reports,\nFoundation Model agents, Large Language Model, Generative andbookchaptersthatarerelevanttothedefinedmainconcepts:\nbasedagents AI,ArtificialGeneralIntelligence,Transformer Foundationmodelbasedagentsandguardrails.\nModels, Self-supervised Learning, Pretrained IC2 PaperswritteninEnglishthatincludereferences.\nModels,LanguageModels,ConversationalAI. IC3 Studies that specifically address the design and development\nConcept 2 (Co2): Guardrails,guardian,responsibleAI,safe,risk, of guardrails in foundation model-based agents. This includes\nRuntimeGuardrails trustworthy,protect,detect,monitor,verify,val- theoreticalframeworks,empiricalresearchandcasestudies.\nidate,evaluate,benchmark,design. IC4 Papers available in an electronic format, such as PDF, DOC,\nDOCX,HTML,andPSetc.\nchallenges arising from the autonomous and deterministic\nTableIV\nnature of FM-based agents. Specially, we examine how to\nEXCLUSIONCRITERIA\nadapt the Swiss Cheese Model to safeguard the behaviors of\nID DetailCriterion\nFM-based agents by implementing multi-layered guardrails\nEC1 Work-in-progress proposals, keynote addresses, secondary stud-\nacrossvariousagentartifacts.SectionVpresentstheproposed\nies,andvisionpaperswithoutconcreterelationtoguardrails.\narchitecture and discusses our strategies for addressing this EC2 Discussion papers and opinion pieces that do not provide em-\nresearch question. pirical evidence or concrete solutions related to guardrails in\nfoundationmodel-basedagents.\nC. Search String Formulation EC3 Short communications less than two pages, and studies that do\nnotoffersubstantialinformationforanalysis.\nRelevantprimarystudiesforthisSLRwereidentifiedbased EC4 Studies focusing solely on AI or similar technologies without\nontheRQsdefinedinSectionIII-B.Withtheassistanceofthe directrelevancetoguardrails.\nPICOC approach (shown in Table I), our search terms were\nEC5 Research lacking a clear connection to the design and develop-\nmentofguardrailsinthecontextoffoundationmodels.\ndividedintotwoprimaryconcepts,asshowninTableII.These\nEC6 Duplicatepublicationsorearlierversionsofstudiesthathavebeen\nconcepts helped us to set a well-formulated search string. supersededbyextendedjournalversions.\nWe also used synonyms, abbreviations, and alternative EC7 Non-original research, commentary, editorial pieces, and non-\nempiricaldiscussionspapers.\nspellings of search terms to increase the number of relevant\nEC8 Studiesinaccessibleduetocopyrightordatabaserestrictions.\nresearch papers. We used truncation and wildcard operators\nto save time and effort in finding these alternative keywords.\nMoreover, different supplementary key terms or phrases dis- E. Study Search and Filtering Process\ncovered during search iterations were added to our search\nOurfiltrationprocessisfurtherdetailedinFigure2.Initially\nstring to enhance our search strategy. Our supposition is that\nwe ran the formatted query on four major databases that\ntheywillcollectallrelevantarticlesthatcontainsguardrailsfor\nreturned 1,733 research papers. We then applied filtering\nFM-based agents. When constructing the final search query,\nand classified the studies found according to the guidelines\nthe identified keywords, their alternatives and related terms\npresented in [40, 41]. In our initial filtration process, we\nwere linked with Boolean AND (&&), OR (∥) and NOT (¬)\nremoved 108 papers due to being duplicated articles, editorial\noperators as follows as follows:\nor key notes. After reading the title, abstract, conclusion and\n[{(C 11∥C 12∥...∥C 1n)AND(C 21∥C 22∥...∥C 2n) skimming through the introduction, methodology and results,\n(1)\nNOT(UC ∥UC ∥...∥UC )] we applied our exclusion criterion defined in Table IV, and\n1 2 n\n1524 further papers were removed. During the third step of\nwhere C , and C ε Co1 and Co2 of Ta-\n11,12,...,1n 21,22,...,2n\nfiltration,weappliedinclusioncriteriaandremoved80papers\nble II, respectively; and UC , UC , . . ., UC refers the\n1 2 n\nas these studies did not meet ICs shown in Table IV. In\nExclude Context defined earlier in PICOC (Table I).\nparallel, we did a manual search and found 189 papers that\nD. Selection of Papers: Inclusion and Exclusion Criterion meet our key concepts defined in Table II but not contain any\nTable III and Table IV present the Inclusion Criteria (IC) unwanted content (UC). After applying ICs and ECs, 15 out\nand Exclusion Criteria (EC) that have been used to iden- of189paperswereselected.Finally,wedidacross-checkand\ntify the studies for this SLR, respectively. We found that ended up with 32 papers (shown in Appendix A).\na considerable amount of work on guardrails exists in gray\nF. Data Extraction and Quality Assessment\nliterature; however, we excluded them as they often lack\npeer review and a rigorous validation process. While some We used a semi-automated process [44] for data extraction\nsources[42]arguethatgrayliteratureisanimportantresource from the selected studies to answer our RQs. Key qualita-\nfor systematic literature reviews (SLRs), such literature can tive information extracted from each selected study includes\nbe misleading and introduce biases and inconsistencies in the guardrails definitions, motivations, reported key quality at-\nreview process [43]. We prioritized peer-reviewed sources in tributes,anddesignoptions.Wealsoextractedseveralrelevant\nthis study to ensure scientific reliability and credibility, as per pieces of information to understand the context and consider-\nKitchenham et al. guidelines [40, 41]. ations in designing and evaluating runtime guardrails.\nRemove\nAuto Search: 1733 Duplicate & Remaining Apply Remaining\nPapers Editorial No. of Papers (1625) Exclusion No. of Papers (101)\nACM digital library, Notes ACM digital library, Criteria ACM digital library,\nIEEE Xpolre, Springer IEEE Xpolre, Springer IEEE Xpolre, Springer\nlink, ScienceDirect, and link, ScienceDirect, and link, ScienceDirect, and\nGoogle Scholar Google Scholar Google Scholar\nApply Inclusion Criteria\nApply\nInclusion & Remaining\nExclusion No. of Papers (21)\nSnowballing and Manual Criterion Remaining No. of ACM digital library,\nSearch: 189 Papers IEEE Xpolre, Springer\nPapers (15)\nlink, ScienceDirect, and\n(Co ANDCo NOT UC)\n1 2\nGoogle Scholar\nCross Check & Merge\nFinally Selected: 32 Papers\nACM digital library, IEEE Xpolre, Springer link, ScienceDirect, and Google Scholar\nFigure2. StudySelectionProcessforthisSLR\nWe then evaluated each study based on the following five when models generate information that is factually incor-\nQuality Assessment Criteria (QAC) on a scale from 1 (Very rect. Such inaccuracies can mislead users and damage the\nPoor)to5(Excellent).Ifastudy’saveragescorewaslessthan credibility of the agent [10]. Misinformation refers to the\n2, it was excluded from further analysis. Otherwise, we used unintentionalspreadoffalseinformation,whiledisinformation\nthe qualitative information to decide this. The QAC used for involves the deliberate dissemination of falsehoods to receive\nthis study are 1: users [20]. For example, OpenAI uses guardrails to clearly\nlabel AI-generated content to prevent deepfakes and misin-\n❖ Relevance to guardrails for FM-based agents.\nformation [46]. One such case has been reported to prevent\n❖ Clear methodology for guardrail design.\nmisleading voters in last US elections [47, 48].\n❖ Adequate data collection, analysis, and evaluation of 2) Efficiency: Efficiency is crucial in FM-based agents, as\nguardrail effectiveness at different layers of the agent users expect fast, efficient responses [24]. Without guardrails,\narchitecture. agentsriskengaginginresource-intensivetasksthatslowdown\n❖ Discussion of challenges in designing guardrails for au- response times [54]. By dynamically managing resources\ntonomous and non-deterministic behaviors in agents. across multiple layers, these guardrails prevent inefficiencies,\n❖ Practical applicability of findings for guardrails in FM- such as endless loops, and filter irrelevant inputs, ensuring\nthat agents focus on processing meaningful data [3, 16, 64].\nbased agents.\nAdditionally, FM-based agents can incur significant costs due\nto errors, inefficiencies, or non-compliance with regulations.\nIV. TAXONOMYOFGUARDRAILSFORFM-BASEDAGENTS\nWithout proper guardrails, agents might generate outputs that\nFigure 3 presents the proposed taxonomy of runtime lead to financial losses, legal penalties, or damage to their\nguardrailsforFM-basedagents,developedbasedontheresults reputation [12, 26]. For example, an agent that provides\nof a systematic literature review. The taxonomy is organized incorrect financial advice could result in monetary losses for\nintoexternalandinternalqualityattributes,anddesignoptions users and potential lawsuits against the provider.\nfrom different perspectives. 3) Privacy: Privacy in FM-based agents poses risks due\nto handling sensitive data, where data leakage might ex-\nA. Quality Attributes of Guardrails\npose personal information [1, 12]. This leakage can occur\nWe examine the key quality attributes that should be con- throughdirectresponsesorstatisticalinferences,orinadvertent\nsideredwhendesigningruntimeguardrails.Below,wediscuss revelations through model outputs. In April-May 2023, a\nthese attributes in detail. notable incident involved Samsung employees leaking propri-\n1) Accuracy: Accuracy in FM-based agents is crucial, etary information into ChatGPT, leading to Samsung banning\nparticularly in mitigating issues such as hallucinations, mis- ChatGPT [50].\ninformation, and disinformation [45]. Hallucinations occur\n1QACscoreforeachselectedstudyispresentedinAppendixB\nAccuracy there is a risk of data misuse by third-party providers [54].\nEfficiency Moreover, FM-based agents are prone to adversarial attacks,\nPrivacy\nwherespeciallydesignedqueriesextractsensitiveinformation.\nSecurity\nGuardrails mitigate these risks by detecting and responding\nSafety\nFairness to real-time threats across various operational layers, safe-\nCompliance guarding agent integrity [10, 19], confidentiality [49, 55, 56],\nQuality\nattributes Generalizability availability [11, 18, 26, 53, 57] and performance [1, 51].\nCustomizability 5) Safety: FM-based agents face significant safety issues,\nBlock\nAdaptability\nparticularly in generating harmful or misleading outputs.\nFilter\nTraceability\nThese issues can arise when models produce content that\nFlag\nPortability\nModify is inappropriate, offensive, or incorrect [3]. These issues are\nInteroperability\nValidate criticalincontextswhereFM-basedagentshandlecriticaldata\nInterpretability\nParallel calls like medical diagnosis or self-driving cars, where inaccurate\nActions Retry outputs could have severe consequences [32]. Additionally,\nFall back\nthere is a risk of generating questionable content, which can\nHuman intervention\ndamage the credibility and acceptance of the agent [53].\nTaxonomy Defer\nof Isolate 6) Fairness: FM-based agents can face bias and discrim-\nguardrails\nRedundancy ination in model outputs. These biases can emerge from the\nEvaluate Prompts trainingdata,modelalgorithms,ordeploymentcontext[2,61].\nPipeline Intermediate results For instance, an agent used in recruitment for screening CVs\nFinal results might inadvertently favor candidates from certain demograph-\nics, cultures, and languages [8, 26], affecting credibility.\nGoals\nTargets Context 7) Compliance: Compliance in FM-based agents involves\nMemory\nadhering to legal and regulatory standards [16, 20]. These\nReasoning\nissues are critical because non-compliance can lead to legal\nPlans\nArtefacts penalties,reputationaldamage,andlossofusertrust.Runtime\nWorkflow\nDesign guardrails reduce these risks by ensuring alignment with\noptions Tools\ndata protection regulations, industry standards, and guidelines\nKnowledge bases\nthrough continuous monitoring at multiple levels [26, 54].\nUniform Other agents\nPriority-enabled FMs Additionally, these guardrails assist in automating compliance\nRules Context-dependent checks. They ensure that all aspects of the FM-based agent’s\nNegotiable operationsalignwiththenecessarylegalandregulatoryframe-\nworks [36, 62], and better support internal audits and exter-\nIndustry\nnal regulatory reviews [12]. For example, FM-based agents\nOrganizations\nSources may unintentionally facilitate unauthorized use of generated\nTeams\ncontent, making it vulnerable to duplication or improper\nUsers\ndistribution[10,26,55].Guardrailsoperatinginrealtimehelp\nSingle modal\nModality mitigate these risks by detecting and restricting unauthorized\nMultimodal\naccess, ensuring better copyright protection [49]. Techniques\nRule-based models\nsuch as watermarking, fingerprinting, and labeling are applied\nUnderlying Foundation models\nmodels Narrow models acrossdifferentlayerstoensuretheownershipandcompliance\nHybrid models with licensing laws [1, 10].\n8) Generalizability: Generalizability in guardrails for FM-\nFigure3. Taxonomyofmulti-layeredruntimeguardrailsforFM-basedagents.\nbased agents refers to their ability to function effectively in\nreal-time across multiple layers and diverse scenarios without\n4) Security: Security in FM-based agents involves protect- prior configurations [63]. Such guardrails ensure that protec-\ningthemfrommaliciousactivitiesthatcouldcompromisetheir tive measures are not overly specific to a single use case\nintegrity and functionality [6, 14, 19]. For example, an FM- but can adapt to various contexts and still perform reliably\nbased agent could be targeted by hackers to manipulate data, across layers. The agents’ ability to handle diverse linguistic,\nproducing incorrect or harmful outputs that affect decision- cultural,andoperationalcontextsisessentialtoproviderobust\nmakingprocesses[51].Anincidentreportedin[52]described protection, resilience, and reliability and is ensured by the\nhow malicious users manipulated Microsoft’s Tay chatbot to generalizability attribute [1, 12]. Guardrails that can extend\nproduce inappropriate (offensive) content, leading to its shut- theirapplicabilitytonewdomainswithoutsignificantreconfig-\ndown. FM-based agents are also vulnerable to hacks that may urationordegradationinperformance,evenduringunexpected\nbreach data confidentiality [53]. Even with authorized access, inputs or data types, are essential [15, 64].\n9) Customizability: Customizable guardrails provide tai- 13) Interoperability: Interoperable guardrails work seam-\nlored protection that meets specific requirements and sup- lesslyacrossdifferingagents,technologiesandinterfaceeffec-\nports diverse operational needs in FM-based agents [1, 65]. tively with various components and services within different\nThe multi-layered runtime approach allows for customization agents[27].Theyensurethatsecurity,privacy,andcompliance\nat different layers to enable fine-grained control over the protocols can be applied consistently, even in heterogeneous\nagent’s behavior during execution, such as adjustments and environmentsthatutilizevariedsoftwareandhardwarecompo-\nconfigurationsthatalignwithparticularoperationalgoals,data nents,ordiversetechnologicalecosystems[16,67].Guardrails\ncharacteristics, and regulatory environments. For example, a that interface with various APIs and data formats also en-\ncustomer service chatbot can enable priorities for different able smooth communication and operation across different\nguardrailsandadjustdatahandlingbasedontheuser’slocation agents [26]. For example, they enable a customer service\nand ensuring compliance with regulation. copilot and internal support system to share data securely\n10) Adaptability: Adaptability in guardrails is known as and consistently. This promotes cohesive and unified security\ntheir capability to adjust and remain effective under varying management,reducingthecomplexityofmaintainingmultiple\nconditions and data landscapes as context evolves [24, 26]. disparate protective measures [1], and better support collabo-\nThisattributeensuresrobust andcontinuousprotectionbydy- rative efforts and data sharing [49].\nnamicallyrespondingtochangesininputdata,usagepatterns, 14) Interpretability: Interpretability refers to the clarity\nandemergingthreatswithoutmanualreconfiguration[15].For and transparency with which guardrails and protective mea-\nexample, a customer service chatbot can automatically update sures operate. Interpretability allows better inspection and\nits guardrails to detect and block new offensive terms during understanding of each layer’s function during execution. This\ninteractions. This includes incorporating new knowledge and allows users and stakeholders to understand how decisions\nadvancements in threat detection techniques [1, 54]. are made and actions are taken by models. Thus increasing\n11) Traceability: The traceability attribute of guardrails trust and accountability [10, 68]. For example, a chatbot\ntracks and records the origins, processes, and decision paths, in healthcare, can explain why certain advice is given or\nsuch as input and output of FMs, external tools, etc. [27]. restricted. Transparent guardrails better facilitate auditing and\nIt involves maintaining detailed logs and records that can be compliance [18]. They also help users to understand that\naudited to understand how decisions are made. For example, actions taken by guardrails can be clearly understood and\nin a customer service chatbot, traceability ensures that every verified [55]. This is essential for identifying and correcting\nrecommendationcanbetracedbacktothedatasourcesandal- errors,aswellasforensuringthattheagent’soperationsalign\ngorithmsused.Thisprovidesaclearaudittrailfortransparency with ethical and regulatory standards.\nandaccountability.Traceabilityalsoaidsinidentifyingtheroot\ncausesofissuestoenabletimelyandaccuratetroubleshooting\nB. Design Options of Guardrails\nand improvement [26], and helps in maintaining user trust\nand meeting regulatory requirements [10, 16]. Comprehensive This section presents a structured taxonomy for designing\ndocumentation of data sources and model modifications also guardrails,focusingonidentifyingvariousdesignalternatives.\nbettersupporteffectiveauditingandcompliancechecking[12]. 1) Actions: Guardrailactionsarecrucialforaddressingthe\n12) Portability: Portability in guardrails for FM-based specific needsofFM-based agent artifacts. Wehave identified\nagents refers to the ability of these protective measures to the following guardrail actions that can be applied to FM-\nbe easily adapted and applied across different FM-based based agents:\nagents[27].Multiplelayerruntimeguardrailsallowindividual\nlayers to be transferred and integrated into different agents • Block: The block action preventsspecific inputs (suchas\nuser prompts) or outputs (such as content generated by\nwith minimal adjustments in real time. This includes ensuring\nFMs) from being processed or sent by various compo-\nthat they function consistently across various FM architec-\nnents (such as FMs and tools) in FM-based agents [54].\nturesandenvironments,therebymaintainingtheireffectiveness\nForexample,theblock actioncanrejecttheuserprompts\nand integrity regardless of the underlying technologies [26].\ncontaining harmful instructions, thus preventing unde-\nFor example, the same guardrail can be applied for content\nsired outcomes.\nmoderation in both a customer service chatbot and a social\nmediaplatform,regardlessoftheirunderlyingtechnology.The • Filter: The filter action involves scanning and removing\nbenefits of designing portable guardrails include compatibility undesiredorirrelevantcontentfromtheinputsoroutputs\nacross multiple programming languages and frameworks fa- ofdifferentcomponentsinFM-basedagents[69,70].For\ncilitate their integration into diverse technological stacks [49]. instance,afiltermayremoveanypersonaldatacontained\nThese capabilities ensure that the guardrails remain effective in the user prompts or the output generated by FMs.\nand operational as the agent evolves or migrates to new • Flag: The flag action is used to mark specific inputs,\nenvironments. Portable guardrails also support seamless up- outputs, operations within FM-based agents [16]. For\ndates and improve scalability to maintain high standards of example,unusualtransactionsrequestedbytheFM-based\nsecurity and compliance while adapting to new technological agent can be flagged for human review to ensure they\nadvancements within agents [16]. comply with organizational policies [1, 30].\n• Modify: The modify action allows for the adjustment of TableV\ninputs or outputs of various components in FM-based AMAPPINGOFAGENTTARGETSTOGUARDRAILACTIONS\nagentstomeetspecificrequirementsorstandards[9].For\nType Targets GuardrailActions\nexample, the user prompts can be modified by adding Prompts Block, filter, flag, modify, parallel calls, retry,\nmore context and examples, making it easier for the FM defer,evaluate\nIntermediate Flag,humanintervention,evaluate\nto accurately interpret the user’s intentions and provide\nresults\nmore relevant responses. Finalresults Block, filter, flag, modify, retry, fall back, hu-\nmanintervention,evaluate\n• Validate: The validate action checks agent artifacts Goals Validate, block, flag, modify, human interven-\nagainst predefined criteria to ensure they meet specified tion,defer\nrequirementsorstandards[26,70].Forexample,theplan Context Block,filter,flag,modify,evaluate\nMemory Block, filter, flag, modify, retry, human inter-\ngenerated by FM-based agents should be validated, e.g.,\nvention,isolate,evaluate\nthrough external verifier [79], to ensure it is compliant Reasoning Flag,modify,validate,humanintervention\nwith regulatory policies. Plans Block, flag, modify, validate, retry, fall back,\nhumanintervention,defer\n• Parallelcalls:Theparallelcallsactioncansendmultiple Workflows Validate, parallel calls, retry, fall back, human\nrequests to the agent/component to improve responsive- intervention,defer,evaluate\nTools Block, parallel calls, retry, fall back, human\nness, e.g., a user can send a prompt to the agent or an\nintervention,defer,evaluate\nexternalservicemultipletimesatthesametimeandselect Knowledge Block, filter, flag, modify, retry, isolate, evalu-\nthe better response [16, 53]. bases ate,redundancy\nOtheragents Block,flag,parallelcalls,retry,fallback,human\n• Retry: The retry action involves attempting a request intervention,defer,isolate,evaluate\nagain after an initial failure or unsatisfactory result [13]. FMs Block, filter, flag, modify, parallel calls, retry,\nfallback,humanintervention,isolate,evaluate,\n• Fall back: When one step in the workflow cannot be redundancy\nexecuted successfully, the fall back action redirect to the\nprevious step and state [13, 16, 71].\n• Human intervention: The human intervention action • Prompts: Prompts are the initial user inputs or queries.\nrequireshumanstoreviewandapprovespecificoutputsor Guardrails on prompts help ensure that user prompts are\ndecisions [16, 53, 55]. For example, responses involving relevant, appropriate, formatted correctly, and easier for\nsensitive medical advice might be flagged for human FMs to understand [37, 56, 70].\napproval before being communicated to users.\n• Defer: The defer action postpones the processing of • Intermediate Results: Intermediate results are the out-\na request or task until specific conditions are met or puts generated at various stages during the workflow\nadditional information is available [72]. generation of agents, before reaching the final outputs.\nBy monitoring intermediate results, guardrails can detect\n• Isolate:Theisolateactioninvolvessegregatingaspecific\nanomalies or inaccuracies before they propagate to the\nentity (e.g., user) or component to prevent interaction\nfinal results.\nwith the agent [19, 57, 60]. For example, an agent\n• FinalResults:Finalresultsaretheendoutputsgenerated\nmight isolate a compromised narrow AI model suspected\nby agents, which are delivered to users or downstream\nof being poisoned with malicious data in a sandbox\nsystems.Guardrailsensurethatthefinalresultsmeetuser\nenvironment, preventing potential harm to the agent.\nexpectations and comply with regulations and standards.\n• Redundancy: The redundancy action involves imple- • Goals: Ensuring that agents’ goals align with human\nmenting backup processes or components to ensure con-\nvalues and do not deviate from the human’s intended\ntinuity and reliability in case of failures [16, 26]. For\ngoals [16, 49].\nexample, two sensors can be deployed to detect context\n• Context: Monitoring the context that agents collect to\ninformation for an agent.\nensure it is relevant information and appropriate [36].\n• Evaluate: The evaluate action involves assessing the • Memory: Managing the agents’ memory to retain rele-\nresults[1].Forinstance,anagentmightaskanotheragent vant data and discard outdated or irrelevant information,\nto evaluate its intermediate or final results. while also preventing memory poisoning [36, 64].\n2) Targets: Guardrail actions can be applied to various • Reasoning: Checking whether the reasoning is\ntargets across multi-layers, including both pipelines and ar- sound [30].\ntifacts. Some guardrails are applied the the entire pipeline • Plans: Ensuring the generated plans align with human\n(including prompts, intermediate results, and final results), goals [30, 54].\nwhile others are focused on specific artifacts (covering goals, • Workflows: Managing the exceptions happened during\ncontext, reasoning, plans, memory, tools, knowledge bases, runtime workflow execution [80].\nother agents, FMs). Table V provides an overview of agent • Tools: Overseeing the proper use of tools by agents,\ntargets and corresponding guardrail actions. including implementing access controls, restricting tool\ncapabilities, and detect potential vulnerabilities [36, 49].\nenilepiP\nstcafitrA\n• Knowledge Bases:Guardrailsenforcestringentmonitor- From the user perspective, guardrails can reflect individ-\ning and validation of external knowledge bases, partic- ual preferences and requirements. This involves adjusting\nularly in retrieval augmented generation scenarios [17]. the agent’s behavior based on user-defined settings to align\nFor example, they can prevent the retrieval of sensitive outputs with both user expectations and ethical considera-\nbusiness data [73]. tions.Incorporatinguserpreferencesintoguardrailsprovidesa\n• Other Agents: Managing interactions between agents to personalized experience while maintaining safety and compli-\nensure collaboration, prevent conflicts, and mitigate risks ance [55, 69]. Such guardrails ensure that the system respects\nassociated with malicious behaviors [30, 49]. user autonomy and produces outputs that are relevant and\n• FMs: Guardrails ensures the outputs generated by FMs acceptable.\nare relevant, appropriate and safe. Also, guardrails over- 5) Modality: Themodalityofguardrailsreferstothetypes\nsee the utilization of FMs, preventing misuse and ensur- of data and interactions they manage. Guardrails can be de-\ningtheirapplicationunderappropriateconditions[1,20]. signed for single modal or multimodal systems. Single modal\n3) Rules: Guardrails rules can be configured in different systems operate with one type of data input or output, such\nways:includinguniformrules,priority-enabledrules,context- as text, image, or audio. For instance, in text-based agents,\ndependent rules, and negotiable rules. A uniform strategy guardrails focus on addressing issues like offensive language,\napplies the same set of guardrails consistently across all sce- misinformation, and data privacy [49]. In image-based agents,\nnarios, ensuring simplicity and uniformity [67]. It is particu- they may involve techniques for detecting explicit content or\nlarlyeffectiveinenvironmentswithstableandwell-understood ensuring image quality standards [26].\nrisks. It largely reduces the complexity of managing diverse Multimodal guardrails address the combined risks of han-\nguardrails [55]. A priority-enabled strategy prioritizes certain dlingmultipledatatypes.Theysynchronizeprotectionsacross\nguardrailsbasedonthecriticalityandsensitivityofoperations different data types, ensuring comprehensive security and\nor data. Context-dependent strategies adjust the implementa- compliance [55]. For example, a system that generates text\ntion of guardrails based on the system’s specific operational based on image inputs must ensure accurate and ethical\ncontext. This allows for dynamic adjustments to guardrails in representation of the image content. This requires advanced\nresponse to changing conditions, user needs, and operational cross-modal analysis and validation techniques to ensure the\nenvironments[49].Thenegotiabilityofguardrails,categorized system operates reliably and ethically across all data types it\ninto hard and soft, defines the level of flexibility in enforcing handles [53].\nrules. Soft guardrails allow adjustments based on context and 6) Underlying models: The underlying techniques of\nsituational demands, providing a balance between protection guardrails include rule-based, hybrid, and machine learning\nandoperationalflexibility[49].Incontrast,hardguardrailsare models,witheachrepresentingadistinctdesignoptiontomeet\nrigid and non-negotiable, ensuring adherence to critical legal, specificrequirements[3,27].Rule-basedmodelsutilizeprede-\nethical, or safety standards [12, 32]. fined rules to monitor and control FM-based agents behavior.\n4) Sources: The source of guardrails in FM-based agents These models implement strict and deterministic guidelines\nranges from industry regulations and standards to individual that the agent must follow to ensure compliance with regula-\npreferences. Industry-level regulations and standards provide tory requirements for data access and processing [49]. They\nthe broader regulatory framework within which FM-based are particularly effective in environments where operational\nagentsmustoperate.Guardrailsdesignedtocomplywiththese parametersarewell-definedandstable.Rule-basedmodelscan\nregulations guarantee that the system adheres to industry best beupdatedandaresomewhatflexible.However,theymaystill\npractices and legal requirements [16]. They facilitate simpler struggle with unexpected scenarios, such as detecting novel\nauditingandcertificationprocesses,ensuringtheagentremains AI-generated content that falls outside predefined rules. This\ncompliant with evolving regulatory landscapes. relianceonstaticrulescanlimittheiradaptability,andregular\nAt the organizational level, guardrails align with internal updates are needed [16, 71].\npolicies and procedures governing the operation and use of Incontrast,machinelearningmodelsdynamicallyadaptand\nFM-based agents. This includes compliance with corporate improve guardrails based on new data and scenarios. These\ngovernance, data protection policies, and ethical guidelines modelscanalsolearnfromhistoricaldataandidentifypatterns\nestablished by the organization [12]. Guardrails also ensure thatindicatepotentialrisksorcomplianceissues[64].Machine\nconsistency and accountability across different departments learning models can be further classified into narrow models\nand functions within the organization. and FMs. Narrow models are specialized systems designed\nTeam-level constraints focus on the technical and opera- for specific tasks or domains. They require targeted guardrails\ntionallimitationsdefinedbythedevelopmentteam.Guardrails to address domain-specific risks and compliance needs [15].\nat this level ensure that the agent functions efficiently within FMs are large, general-purpose models that serve as the\nthese constraints, such as computational and memory limits, backbone for multiple applications and tasks. These models\nwhile maintaining robustness and reliability [26]. They also necessitate comprehensive and scalable guardrails to handle\nensure that the agent’s operations do not exceed predefined a wide range of risks and compliance issues across different\nthresholds that could lead to performance degradation or applications [26]. Nevertheless, they can be computationally\nsecurity vulnerabilities. intensive and require substantial data for training.\nContext\nExternal Continuous Agent\nenvironment learning\nGoal Multi-layered runtime guardrails\nContext engine\nRisks\nUser\nPrivacy guardrails\nOptimised for prompt\nprompt\nSafety guardrails\nAgents Reasoning & planning for goal\nQuality\n... ... ...\nattributes\n... ... ...\nTools Workflow ... ... ... Pi peli\nnes\nWorkflow Fairness guardrails\nexecution for final results\nKnowledge\nbases Result\nAgentOps infrastructure (continuous monitoring and logging)\nFigure4. Referencearchitectureformulti-layeredguardrailsofFM-basedagents.\nHybrid models integrate rule-based approaches with the and context. Instead of waiting for users’ instructions,\nadaptability of machine learning models to respond to new the agent can also proactively make suggestions based\nthreatsandevolvingdatapatterns[53].Forinstance,Khorram- on the context it detects, such as screen recordings,\nrouz et al.[59] demonstrate the use of the PaLM 2 framework mouse clicks, eye tracking data, gestures, and document\nto process user input and dynamically implement rule-based annotations [3].\ndecisions. This framework tests the system’s limits by itera- • Reasoning and Planning: After receiving optimized\ntively generating toxic content to evaluate PaLM 2’s safety prompts, the reasoning and planning component pro-\nguardrails. However, integrating hybrid models can increase cesses the prompt to determine the most effective way\nsystem complexity and create additional challenges [53]. ofachievingthespecifiedgoal.Thisprocessmayinvolve\nadoptingreasoningpatterns,suchasthechain-of-thought\nV. REFERENCEARCHITECTUREFORDESIGNING\npattern [81], which structures the agent’s thinking into\nMULTI-LAYEREDRUNTIMEGUARDRAILSOFAGENTS\nsequential, logical steps that align with the agent’s ob-\nFigure 4 shows the proposed reference architecture for jectives. A detailed plan is then formulated to outline\nmulti-layered runtime guardrails of FM-based agents, which each step required to accomplish the goal. This includes\nconsists of four key parts: (i) external environment, (ii) agent selecting the appropriate tools, knowledge bases, and\ncomponents,(iii)built-inmulti-layeredruntimeguardrails,and agents to carry out each action. The memory component\n(iv) AgentOps infrastructure. may be integrated to allow the agent to recall previously\ngathered experience and knowledge to refine the plan.\nA. External Environment:\n• Workflow Execution: The workflow execution compo-\nThe external environment refers to all entities interacting nent is responsible for executing the sequence of ac-\nwith the agent, including users, other agents, external tools, tions outlined by the reasoning and planning component.\nand knowledge bases. Users provide goals and contextual This component directly interacts with external tools,\ninputs that shape the agent’s objectives. To achieve user knowledge bases, and other agents to complete tasks and\ngoals, the agent may utilize context detected in the external generateoutputsalignedwiththeuser’sgoals.Theresults\nenvironment and interact with other agents, specialized tools, arereturnedtotheexternalenvironmentandstoredinthe\nand extensive knowledge bases to perform complex tasks. agent’s memory for future reference.\n• Memory: The memory component in this architecture\nB. Agent Components\nstores relevant information fromprior interactions,plans,\nWithin the agent, there are four primary components: the and results. This accumulated knowledge supports con-\ncontext engine, reasoning and planning, workflow execution, tinuouslearning,enablingtheagenttorefineitsstrategies\nand memory. and improve capabilities and skills over time, thereby\n• Context Engine: The context engine processes multi- improving accuracy and minimizing repeated errors.\nmodal context data from the external environment to\nenrich the user prompt, helping FMs better understand\nusergoals.Apromptmaycontainelementssuchasgoals\nyromeM\nytefaS\nIA\nrof\nledoM\neseehC\nssiwS\nstcafitrA\nC. Multi-layered Runtime Guardrails not introduce unnecessary risk. The plan can be made by\nexternal verifiers, i.e., external planning tools [79].\nBuilding on the Swiss Cheese Model, we design multi-\nlayered runtime guardrails for FM-based agents, structured • Guardrails for workflows: Handle the exceptions that\narise during the workflow executions by implementing\naround the dimensions of quality attributes, pipelines, and\nmechanisms like force-failing a step or retrying a tool\nartifacts specified in the taxonomy. In this architecture, each\ncall [80]\n‘cheese slice’ represents a protective layer within the agent\nsystem, addressing quality attributes, pipeline stages, and/or • Guardrails for external tools: Analyse the quality (e.g.\nvulnerability[86])oftheexternaltoolstoensurethatonly\nspecific artifacts, such as a layer about privacy guardrails for\napproved and safe tools are invoked by the agent.\nprompts or security guardrails for tools. While each layer\ncontainsholes(i.e.,potentialgapsorweaknesses),whererisks • Guardrails for knowledge bases: Verify that the infor-\nmation retrieved from knowledge bases is relevant and\nmight slip through, the holes are positioned differently across\nethical (e.g., without any PII information).\nlayers. Gaps in one layer are often covered by another; thus,\nevenifonelayerfails,anothercancatchandmitigatetheissue. • Guardrails for other agents:Ensuretheselectedagents\nhave a reliable and safe operational history.\nFrom the perspective of quality attributes (discussed in\nSection IV-A), guardrails can be designed to ensure accuracy, • Guardrails for FMs: Enforce boundaries on the FM’s\nnon-deterministicoutputs,applyingmodificationsorflags\nefficiency,privacy,security,safety,fairness,compliance.From\nas needed.\nthepipelinesperspective,guardrailscanbeappliedatmultiple\nstages:theuserprompts,intermediateresultsduringworkflow D. AgentOps\nexecutions, and final results generated by the agent.\nAgentOpsprovidesacomprehensiveinfrastructuredesigned\n• Guardrails for prompts: Analyse incoming user to enable observability [84] for FM-based agents by continu-\nprompts to detect and manage sensitive information, ously monitoring and recording runtime data. This infrastruc-\nharmfulcontent,misinformation,disinformation,discrim- ture captures a wide range of data elements, from pipeline\ninatory language, ensuring the prompt aligns with safety execution details and agent artifacts to the specific guardrails\nand ethical standards [82]. applied to the pipeline and artifacts. All these data need to be\n• Guardrailsforintermediateresults:Applyateachstep kept as evidence with metadata such as FM version and the\nof the workflow to verify that intermediate results are timestamp. The data collected by the AgentOps infrastructure\naccurate,safe,andresponsible,safeguardingtheintegrity can also feed into multi-layered guardrails to activate the\nof the process before the final results are produced. relevant guardrails as needed.\n• Guardrailsforfinalresults:Checkthattheagent’sfinal\noutputs are align with the user goals and governance VI. THREATSTOVALIDITY\nrequirements, such as AI safety standard requirements.\nOur study is subject to standard literature search and se-\nMoreover, from the artifacts perspective, guardrails can be lection bias threats. We addressed these threats by searching\nenforcedoneachagentartifactincludinggoals,context,mem- the most commonly used databases in the IT and software\nory,reasoning,plans,tools,knowledgebases,otheragents,and engineering domains. We revised our search strings several\nFMs. These guardrails ensure that each artifact is within safe times during the automatic search to maximize the number of\nand responsible boundaries. relevant articles matching two key concepts: ‘guardrails’ and\n• Guardrails for goals: Ensure that the goals are achiev- ‘FM-based agents’. We also kept our search string generic\nable, within the agent’s scope, and aligned with gover- to search through the titles, abstracts, keywords, and full text\nnance requirements, including regulatory standards and of articles to cover the maximum number of relevant papers.\norganizational policies, avoiding goals that may lead to We then conducted a manual search on Google Scholar to\nharmful outcomes and potential misuse [85]. complementtheautomaticsearchusingasnowballingstrategy.\n• Guardrails for context: Validate contextual information Furthermore, predefined review protocols with detailed inclu-\nto ensure it is relevant, accurate, and free from sensitive sion and exclusion criteria helped us reduce bias in selecting\nor misleading information. primarystudies.Weappliedseveralqualityassessmentcriteria\n• Guardrails for memory: Ensure that stored past expe- to estimate the quality of the selected primary studies. Even\nrience is relevant, accurate, and free from any malicious thoughtheproposedcriteriawerenottoostrict,applyingthem\normisleadingcontent,preventingmemorypoisoning[83] led to several initially selected papers being excluded. To\nand retaining only useful data for future interactions. mitigate the risk of missing important data from the primary\n• Guardrails for reasoning: Check the agent’s reasoning studies, we reinstated the excluded papers that were closely\nprocessestopreventlogicalerrorsandensurethereason- related to the primary studies.\ning steps are safe, responsible, and aligned with the user Moreover, our definitions and categorizations may not cap-\nintent. ture all relevant aspects of guardrails in FM-based agents.\n• Guardrails for plans: Assess the feasibility, safety, and To mitigate this threat, we validated the taxonomy through\ncompliance of the plans generated by the agent, ensuring extensive literature review and expert feedback. However, this\nthat each step in the workflow is responsible and does introduces a risk of producing biased results that address only\nexpert needs, as the people involved in the feedback process [SS5] M. Anderljung, J. Barnhart, J. Leung, A. Korinek,\nhave extensive experience in the AI and software engineering C. O’Keefe, J. Whittlestone, S. Avin, M. Brundage,\ndomains. Our review protocols helped us to reduce such bias. J. Bullock, D. Cass-Beggs, et al., Frontier ai regulation:\nWe prepared a guardrails taxonomy and conducted a com- Managingemergingriskstopublicsafety,arXivpreprint\nparative analysis of its components to help the reader better arXiv:2307.03718 (2023). doi:https://doi.org/\nunderstandtheirdesignandevaluation.Wecriticallyexamined 10.48550/arXiv.2307.03718.\nthe strength and consistency of relationships in the selected [SS6] M. Liffiton, B. E. Sheese, J. Savelka, P. Denny, Code-\nstudies to develop a reliable taxonomy and reference archi- help: Using large language models with guardrails for\ntecturefordesigningbuilt-inmulti-layeredruntimeguardrails. scalablesupportinprogrammingclasses,in:Proceedings\nFinally,wedrawconclusions.Nonetheless,thegeneralizability of the 23rd Koli Calling International Conference on\nof guardrails to different contexts and types in FM-based Computing Education Research, Koli Calling ’23, Asso-\nagents remains a potential limitation. Specific adaptations ciation for Computing Machinery, New York, NY, USA,\nmight be necessary for certain systems, such as those used 2024,pp.1–11. doi:10.1145/3631802.3631830.\nin healthcare or financial organizations. [SS7] Z. Zhang, Y. Lu, J. Ma, D. Zhang, R. Li,\nP. Ke, H. Sun, L. Sha, Z. Sui, H. Wang, et al.,\nVII. CONCLUSIONANDFUTUREWORK Shieldlm: Empowering llms as aligned, customiz-\nable and explainable safety detectors, arXiv preprint\nTo advance the understanding of runtime guardrail design\narXiv:2402.16444 (2024). doi:https://doi.org/\nin FM-based agents, this paper presents a comprehensive\n10.48550/arXiv.2402.16444.\ntaxonomy of guardrail design based on the results of an\n[SS8] T.Rebedea,R.Dinu,M.N.Sreedhar,C.Parisien,J.Co-\nSLR. Our taxonomy categorizes guardrails based on their\nhen,NeMoguardrails:Atoolkitforcontrollableandsafe\nessential quality attributes and key design dimensions, includ-\nLLM applications with programmable rails, in: Y. Feng,\ning guardrail actions and targets, employed rules, guardrail\nE. Lefever (Eds.), Proceedings of the 2023 Conference\nsources, modality, and underlying models. Building on this\non Empirical Methods in Natural Language Processing:\ntaxonomy, we propose a novel Swiss Cheese Model for\nSystem Demonstrations, Association for Computational\nAI safety - a reference architecture for designing built-in,\nLinguistics, Singapore, 2023, pp. 431–445. doi:10.\nmulti-layered guardrails in FM-based agents, which includes\n18653/v1/2023.emnlp-demo.40.\nthree dimensions: quality attributes, pipelines, and artifacts.\n[SS9] Y. Wang, L. Singh, Adding guardrails to advanced\nIn the future, we plan to develop guardrail services for a\nchatbots, arXiv preprint arXiv:2306.07500 (2023).\nscientificagentplatform,implementingtheproposedreference\ndoi:https://doi.org/10.48550/arXiv.\narchitecture and integrating various design options outlined in\n2306.07500.\nthe taxonomy.\n[SS10] M. Shanahan, Talking about large language models,\nAPPENDIXA:LISTOFSELECTEDSTUDIES Commun. ACM 67 (2) (2024) 68–79. doi:10.1145/\n3624724.\n[SS11] W. Du, Q. Li, J. Zhou, X. Ding, X. Wang, Z. Zhou,\n[SS1] M. Pawagi, V. Kumar, Guardrails: Automated sugges- J.Liu,Finguard:Amultimodalaigcguardrailinfinancial\ntions for clarifying ambiguous purpose statements, in: scenarios, in: Proceedings of the 5th ACM International\nProceedings of the 16th Annual ACM India Compute Conference on Multimedia in Asia, MMAsia ’23, Asso-\nConference, COMPUTE ’23, Association for Comput- ciation for Computing Machinery, New York, NY, USA,\ning Machinery, New York, NY, USA, 2023, p. 55–60. 2024, pp. 1–3. doi:10.1145/3595916.3626351.\ndoi:10.1145/3627217.3627234. [SS12] A. Wei, N. Haghtalab, J. Steinhardt, Jailbroken: How\n[SS2] A. Khorramrouz, S. Dutta, A. Dutta, A. R. does llm safety training fail?, Advances in Neural In-\nKhudaBukhsh, Down the toxicity rabbit hole: formation Processing Systems 36 (2024). doi:10.\nInvestigating palm 2 guardrails, arXiv preprint 48550/arXiv.2307.02483.\narXiv:2309.06415 (2023). doi:https: [SS13] J. Zhao, K. Chen, X. Yuan, Y. Qi, W. Zhang,\n//doi.org/10.48550/arXiv.2309.06415. N. Yu, Silent guardian: Protecting text from malicious\n[SS3] Y. Dong, R. Mu, G. Jin, Y. Qi, J. Hu, exploitation by large language models, arXiv preprint\nX. Zhao, J. Meng, W. Ruan, X. Huang, Building arXiv:2312.09669 (2023). doi:https://doi.org/\nguardrails for large language models, arXiv 10.48550/arXiv.2312.09669.\npreprint arXiv:2402.01822 (2024). doi:https: [SS14] X. Qi, Y. Zeng, T. Xie, P.-Y. Chen, R. Jia, P. Mit-\n//doi.org/10.48550/arXiv.2402.01822. tal, P. Henderson, Fine-tuning aligned language models\n[SS4] N.Mangaokar,A.Hooda,J.Choi,S.Chandrashekaran, compromises safety, even when users do not intend to!,\nK.Fawaz,S.Jha,A.Prakash,Prp:Propagatinguniversal arXiv preprint arXiv:2310.03693 (2023). doi:https:\nperturbations to attack large language model guard-rails, //doi.org/10.48550/arXiv.2310.03693.\narXiv preprint arXiv:2402.15911 (2024). doi:https: [SS15] J. Mo¨kander, J. Schuett, H. R. Kirk, L. Floridi, Au-\n//doi.org/10.48550/arXiv.2402.15911. diting large language models: a three-layered approach,\nAI and Ethics (2023) 1–31doi:https://doi.org/ red teaming to improve guardrails, in: Proceedings of\n10.1007/s43681-023-00289-2. the ART of Safety: Workshop on Adversarial testing\n[SS16] S. Banerjee, S. Layek, R. Hazra, A. Mukher- and Red-Teaming for generative AI, 2023, pp. 11–\njee, How (un) ethical are instruction-centric re- 23. doi:http://dx.doi.org/10.18653/v1/\nsponses of llms? unveiling the vulnerabilities of 2023.artofsafety-1.2.\nsafety guardrails to harmful queries, arXiv preprint [SS26] Z. Wang, F. Yang, L. Wang, P. Zhao, H. Wang,\narXiv:2402.15302 (2024). doi:https://doi.org/ L. Chen, Q. Lin, K.-F. Wong, SELF-GUARD: Empower\n10.48550/arXiv.2402.15302. the LLM to safeguard itself, in: K. Duh, H. Gomez,\n[SS17] S. Ee—Researcher, Z. W. Director, Adapting S.Bethard(Eds.),Proceedingsofthe2024Conferenceof\ncybersecurity frameworks to manage frontier AI risks, theNorthAmericanChapteroftheAssociationforCom-\nInstitute for AI Policy and Strategy (IAPS) (2023). putational Linguistics: Human Language Technologies\nURL https://static1.squarespace.com/ (Volume1:LongPapers),AssociationforComputational\nstatic/64edf8e7f2b10d716b5ba0e1/t/ Linguistics, Mexico City, Mexico, 2024, pp. 1648–1668.\n6528c5c7f912f74fbd03fc34/1697170896984/Adapting+ URL https://aclanthology.org/2024.naacl-long.92\ncybersecurity+frameworks+to+manage+frontier+AI+ [SS27] B.Wang,W.Chen,H.Pei,C.Xie,M.Kang,C.Zhang,\nrisks.pdf C. Xu, Z. Xiong, R. Dutta, R. Schaeffer, et al., De-\n[SS18] P. Rai, S. Sood, V. K. Madisetti, A. Bahga, codingtrust: A comprehensive assessment of trustworthi-\nGuardian:Amulti-tiereddefensearchitectureforthwart- ness in gpt models, in: Advances in Neural Information\ning prompt injection attacks on llms, Journal of Soft- Processing Systems, 2023, pp. 1–110. doi:https:\nware Engineering and Applications 17 (1) (2024) //doi.org/10.48550/arXiv.2306.11698.\n43–68. doi:https://doi.org/10.4236/jsea. [SS28] R.Bommasani,D.A.Hudson,E.Adeli,R.B.Altman,\n2024.171003. S.Arora,S.vonArx,M.S.Bernstein,J.Bohg,A.Bosse-\n[SS19] A. Kumar, S. Singh, S. V. Murty, S. Ragupathy, The lut, E. Brunskill, E. Brynjolfsson, S. Buch, D. Card,\nethics of interaction: Mitigating security threats in llms, R. Castellon, N. S. Chatterji, A. S. Chen, K. Creel,\narXiv preprint arXiv:2401.12273 (2024). doi:https: J. Q. Davis, D. Demszky, C. Donahue, M. Doumbouya,\n//doi.org/10.48550/arXiv.2401.12273. E. Durmus, S. Ermon, J. Etchemendy, K. Ethayarajh,\n[SS20] X. Shen, Z. Chen, M. Backes, Y. Shen, Y. Zhang, L.Fei-Fei,C.Finn,T.Gale,L.Gillespie,K.Goel,N.D.\n”do anything now”: Characterizing and evaluating in- Goodman,S.Grossman,N.Guha,T.Hashimoto,P.Hen-\nthe-wild jailbreak prompts on large language models, derson, J. Hewitt, D. E. Ho, J. Hong, K. Hsu, J. Huang,\narXiv preprint arXiv:2308.03825 (2023). doi:https: T. Icard, S. Jain, D. Jurafsky, P. Kalluri, S. Karamcheti,\n//doi.org/10.48550/arXiv.2308.03825. G.Keeling,F.Khani,O.Khattab,P.W.Koh,M.S.Krass,\n[SS21] A. Kumar, C. Agarwal, S. Srinivas, S. Feizi, R. Krishna, R. Kuditipudi, et al., On the opportunities\nH. Lakkaraju, Certifying llm safety against adversarial and risks of foundation models, CoRR abs/2108.07258\nprompting, arXiv preprint arXiv:2309.02705 (2023). (2021). arXiv:2108.07258,doi:https://doi.\ndoi:https://doi.org/10.48550/arXiv. org/10.48550/arXiv.2108.07258.\n2309.02705. [SS29] L. Weidinger, M. Rauh, N. Marchal, A. Manzini,\n[SS22] Y. Zeng, H. Lin, J. Zhang, D. Yang, R. Jia, L. A. Hendricks, J. Mateos-Garcia, S. Bergman, J. Kay,\nW. Shi, How johnny can persuade llms to C. Griffin, B. Bariach, et al., Sociotechnical safety\njailbreak them: Rethinking persuasion to challenge evaluation of generative ai systems, arXiv preprint\nai safety by humanizing llms, arXiv preprint arXiv:2310.11986 (2023). doi:https://doi.org/\narXiv:2401.06373 (2024). doi:https: 10.48550/arXiv.2310.11986.\n//doi.org/10.48550/arXiv.2401.06373. [SS30] D. Kang, D. Raghavan, P. Bailis, M. Zaharia, Model\n[SS23] B. Wei, K. Huang, Y. Huang, T. Xie, X. Qi, assertions for monitoring and improving ml models,\nM. Xia, P. Mittal, M. Wang, P. Henderson, Proceedings of Machine Learning and Systems 2 (2020)\nAssessing the brittleness of safety alignment 481–496. doi:https://doi.org/10.48550/\nvia pruning and low-rank modifications, arXiv arXiv.2003.01668.\npreprint arXiv:2402.05162 (2024). doi:https: [SS31] Z. Yuan, Z. Xiong, Y. Zeng, N. Yu, R. Jia, D. Song,\n//doi.org/10.48550/arXiv.2402.05162. B. Li, Rigorllm: Resilient guardrails for large lan-\n[SS24] S. Goyal, M. Hira, S. Mishra, S. Goyal, A. Goel, guage models against undesired content, arXiv preprint\nN. Dadu, D. Kirushikesh, S. Mehta, N. Madaan, Llm- arXiv:2403.13031 (2024). doi:https://doi.org/\nguard:Guardingagainstunsafellmbehavior,in:Proceed- 10.48550/arXiv.2403.13031.\nings of the AAAI Conference on Artificial Intelligence, [SS32] Z. Chu, Y. Wang, L. Li, Z. Wang, Z. Qin, K. Ren, A\nVol. 38(21), 2024, pp. 23790–23792. doi:https: causal explainable guardrails for large language models,\n//doi.org/10.1609/aaai.v38i21.30566. arXiv preprint arXiv:2405.04160 (2024). doi:https:\n[SS25] R. R. Llaca, V. Leskoschek, V. C. Paiva, C. Lupa˘u, //doi.org/10.48550/arXiv.2405.04160\nP. Lippmann, J. Yang, Student-teacher prompting for\nAPPENDIXB:QACSCORESFORTHESELECTEDSTUDIES [6] R. Bommasani and P. Liang, “Reflections on foundation\nmodels,” 2021, Last accessed on Jun.-2024. Link: https:\n//hai.stanford.edu/news/reflections-foundation-models\nSelected Study QAC1 QAC2 QAC3 QAC4 QAC5\n(SS)No. [7] S. Uspenskyi, “Large language model statistics and\nSS-1 2 2 2 2 2 numbers (2024),” 2024, Last accessed on Jun.-\nSS-2 4 5 5 5 4 2024. Link: https://springsapps.com/knowledge/large-\nSS-3 4 3 2 3 2\nlanguage-model-statistics-and-numbers-2024\nSS-4 3 3 3 3 4\nSS-5 2 4 3 3 5 [8] L. Wang et al., “A survey on large language model\nSS-6 1 5 4 3 5 based autonomous agents,” Frontiers of Computer\nSS-7 5 4 4 4 3\nScience, vol. 18, no. 6, pp. 1–26, 2024. Link:\nSS-8 5 4 4 5 3\nhttps://doi.org/10.1007/s11704-024-40231-1\nSS-9 0 1 2 4 3\nSS-10 0 2 2 3 4 [9] Y. Wang and L. Singh, “Adding guardrails to advanced\nSS-11 3 3 1 3 2 chatbots,” arXiv preprint arXiv:2306.07500, 2023. Link:\nSS-12 3 2 3 3 2\nhttps://doi.org/10.48550/arXiv.2306.07500\nSS-13 4 3 3 4 3\nSS-14 5 4 4 5 4 [10] B. Wang, W. Chen, H. Pei, C. Xie, M. Kang,\nSS-15 5 4 3 4 5 C. Zhang, C. Xu, Z. Xiong, R. Dutta, R. Schaeffer\nSS-16 5 4 4 5 4 et al., “DecodingTrust: A comprehensive assessment of\nSS-17 5 4 3 5 4\ntrustworthiness in GPT models,” in Advances in Neural\nSS-18 5 4 4 5 5\nSS-19 4 3 2 4 3 Information Processing Systems, 2023, pp. 1–110. Link:\nSS-20 5 4 4 5 4 https://doi.org/10.48550/arXiv.2306.11698\nSS-21 5 4 4 4 5\n[11] B. Wei, K. Huang, Y. Huang, T. Xie, X. Qi, M. Xia,\nSS-22 5 5 4 5 4\nSS-23 5 4 4 5 4 P. Mittal, M. Wang, and P. Henderson, “Assessing the\nSS-24 5 4 2 2 3 brittleness of safety alignment via pruning and low-rank\nSS-25 5 4 4 4 5 modifications,” arXiv preprint arXiv:2402.05162, 2024.\nSS-26 5 4 4 5 4\nLink: https://doi.org/10.48550/arXiv.2402.05162\nSS-27 5 4 5 5 4\nSS-28 5 4 4 3 4 [12] M. Anderljung et al., “Frontier AI regulation: Managing\nSS-29 4 4 4 3 4 emerging risks to public safety,” arXiv preprint\nSS-30 5 4 4 4 5\narXiv:2307.03718, 2023. Link: https://doi.org/10.48550/\nSS-31 5 5 4 4 5\narXiv.2307.03718\nSS-32 5 4 4 4 5\n[13] A. Wei, N. Haghtalab, and J. Steinhardt, “Jailbroken:\nHow does LLM safety training fail?” Advances in\nNeural Information Processing Systems, vol. 36, 2024.\nREFERENCES\nLink: https://doi.org/10.48550/arXiv.2307.02483\n[1] R. Bommasani, D. A. Hudson, E. Adeli, and et al., [14] A. Gubkin, “Understanding why ai guardrails are\n“On the opportunities and risks of foundation models,” necessary: Ensuring ethical and responsible ai use,”\nCoRR, vol. abs/2108.07258, 2021. Link: https://doi.org/ 2024, Last accessed on Jul.-2024. Link: https://www.\n10.48550/arXiv.2108.07258 aporia.com/learn/ai-guardrails/\n[2] Q. Lu, L. Zhu, J. Whittle, and X. Xu, Responsible [15] Y. Dong, R. Mu, G. Jin, Y. Qi, J. Hu, X. Zhao, J. Meng,\nAI: Best practices for creating trustworthy AI W. Ruan, and X. Huang, “Building guardrails for large\nsystems, 1st ed. Addison-Wesley Professional, language models,” arXiv preprint arXiv:2402.01822,\n2023. Link: https://www.pearson.com/en-us/subject- 2024. Link: https://doi.org/10.48550/arXiv.2402.01822\ncatalog/p/responsible-ai-best-practices-for-creating- [16] T. Rebedea, R. Dinu, M. N. Sreedhar, C. Parisien, and\ntrustworthy-ai-systems/P200000010211/9780138073886 J. Cohen, “NeMo guardrails: A toolkit for controllable\n[3] Q.Lu,L.Zhu,X.Xu,Z.Xing,S.Harrer,andJ.Whittle, and safe LLM applications with programmable rails,”\n“Towards responsible generative AI: a reference archi- in Proceedings of the 2023 Conference on Empirical\ntecture for designing foundation model based agents,” in Methods in Natural Language Processing: System\n21st International Conference on Software Architecture Demonstrations, Singapore, Dec. 2023, pp. 431–445.\nCompanion. IEEE, 2024, pp. 119–126. Link: https://aclanthology.org/2023.emnlp-demo.40\n[4] N. Maslej et al., “AI index report 2024,” Stanford [17] D.Kang,D.Raghavan,P.Bailis,andM.Zaharia,“Model\nInstitute for Human-Centered Artificial Intelligence assertions for monitoring and improving ml models,”\n(HAI), Tech. Rep., 2024. Link: https://aiindex.stanford. Proceedings of Machine Learning and Systems, vol. 2,\nedu/report/2024 pp. 481–496, 2020. Link: https://doi.org/10.48550/arXiv.\n[5] G. V. R. Team, “Artificial intelligence market size, 2003.01668\nshare, growth report 2030,” Grand View Research, Tech. [18] J. Mo¨kander, J. Schuett, H. R. Kirk, and L. Floridi,\nRep., 2024. Link: https://www.grandviewresearch.com/ “Auditing large language models: A three-layered\nindustry-analysis/artificial-intelligence-ai-market approach,” AI and Ethics, pp. 1–31, 2023. Link:\nhttps://doi.org/10.1007/s43681-023-00289-2 [30] Q. Lu, L. Zhu, X. Xu, Z. Xing, S. Harrer, and\n[19] A. Kumar, S. Singh, S. V. Murty, and S. Ragupathy, J. Whittle, “Building the future of responsible AI:\n“The ethics of interaction: Mitigating security threats in A reference architecture for designing large language\nLLMs,” arXiv preprint arXiv:2401.12273, 2024. Link: model based agents,” arXiv e-prints, 2023. Link:\nhttps://doi.org/10.48550/arXiv.2401.12273 https://doi.org/10.48550/arXiv.2311.13148\n[20] C. Zhou et al., “A comprehensive survey on pretrained [31] Y. Bengio et al., “Managing extreme AI risks amid\nfoundation models: A history from BERT to ChatGPT,” rapid progress,” Science, vol. 384, no. 6698, pp.\narXiv preprint arXiv:2302.09419, 2023. Link: https: 842–845, 2024. Link: https://www.science.org/doi/abs/\n//doi.org/10.48550/arXiv.2302.09419 10.1126/science.adn0117\n[21] M. Zaharia, O. Khattab, L. Chen, J. Q. Davis, H. Miller, [32] L. Weidinger, M. Rauh, N. Marchal, A. Manzini,\nC. Potts, J. Zou, M. Carbin, J. Frankle, N. Rao, L. A. Hendricks, J. Mateos-Garcia, S. Bergman, J. Kay,\nand A. Ghodsi, “The shift from models to compound C. Griffin, B. Bariach et al., “Sociotechnical safety\nAI systems,” Berkeley Artificial Intelligence Research evaluation of generative ai systems,” arXiv preprint\n(BAIR), Tech. Rep., 2024. Link: https://bair.berkeley. arXiv:2310.11986, 2023. Link: https://doi.org/10.48550/\nedu/blog/2024/02/18/compound-ai-systems/ arXiv.2310.11986\n[22] IBM, “What are large language models (LLMs)?” 2024, [33] A. E. Hassan, D. Lin, G. K. Rajbahadur, K. Gallaba,\nLastaccessedonJun.-2024.Link:https://www.ibm.com/ F. R. Cogo, B. Chen, H. Zhang, K. Thangarajah, G. A.\ntopics/large-language-models Oliva, J. Lin et al., “Rethinking software engineering\n[23] ——, “What are foundation models?” 2024, Last in the era of foundation models: A curated catalogue\naccessed on Jun.-2024. Link: https://research.ibm.com/ of challenges in the development of trustworthy\nblog/what-are-foundation-models fmware,” arXiv preprint arXiv:2402.15943, 2024. Link:\n[24] Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu, https://doi.org/10.48550/arXiv.2402.15943\nH. Chen, X. Yi, C. Wang, Y. Wang, W. Ye, Y. Zhang, [34] M. Mylrea and N. Robinson, “Artificial intelligence\nY. Chang, P. S. Yu, Q. Yang, and X. Xie, “A survey (ai) trust framework and maturity model: Applying\non evaluation of large language models,” ACM Trans. an entropy lens to improve security, privacy, and\nIntell. Syst. Technol., vol. 15, no. 3, mar 2024. Link: ethical ai,” Entropy, vol. 25, no. 10, 2023. Link:\nhttps://doi.org/10.1145/3641289 https://www.mdpi.com/1099-4300/25/10/1429\n[25] X.Han,Z.Zhang,N.Ding,Y.Gu,X.Liu,Y.Huo,J.Qiu, [35] OpenAI, “OpenAI’s moderation API,” 2024, Last\nY. Yao, A. Zhang, L. Zhang, W. Han, M. Huang, Q. Jin, accessed on Jul.-2024. Link: https://platform.openai.\nY. Lan, Y. Liu, Z. Liu, Z. Lu, X. Qiu, R. Song, J. Tang, com/docs/guides/moderation/overview\nJ.-R.Wen,J.Yuan,W.X.Zhao,andJ.Zhu,“Pre-trained [36] Z. Xiang et al., “GuardAgent: Safeguard llm agents\nmodels: Past, present and future,” AI Open, vol. 2, pp. by a guard agent via knowledge-enabled reasoning,”\n225–250, 2021. Link: https://www.sciencedirect.com/ arXiv preprint arXiv:2406.09187, 2024. Link: https:\nscience/article/pii/S2666651021000231 //doi.org/10.48550/arXiv.2406.09187\n[26] S. Ee and Z. Williams, “Adapting cybersecurity [37] P. Rai, S. Sood, V. K. Madisetti, and A. Bahga,\nframeworks to manage frontier AI risks,” Institute for AI “Guardian: A multi-tiered defense architecture for\nPolicy and Strategy (IAPS), 2023. Link: https://static1. thwarting prompt injection attacks on LLMs,” Journal\nsquarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/ of Software Engineering and Applications, vol. 17,\n6528c5c7f912f74fbd03fc34/1697170896984/Adapting+ no. 1, pp. 43–68, 2024. Link: https://doi.org/10.4236/\ncybersecurity+frameworks+to+manage+frontier+AI+ jsea.2024.171003\nrisks.pdf [38] T. Bi, G. Yu, Q. Lu, X. Xu, and N. Van Beest, “The\n[27] Q.Lu,L.Zhu,X.Xu,Y.Liu,Z.Xing,andJ.Whittle,“A privacy pillar - A conceptual framework for foundation\ntaxonomy of foundation model based systems through model-basedsystems,”arXivpreprintarXiv:2311.06998,\nthe lens of software architecture,” in Proceedings of 2023. Link: https://doi.org/10.48550/arXiv.2311.06998\nthe IEEE/ACM 3rd International Conference on AI [39] M. Petticrew and H. Roberts, Systematic reviews in the\nEngineering-Software Engineering for AI, 2024, pp. social sciences: A practical guide. John Wiley & Sons,\n1–6. Link: https://doi.org/10.48550/arXiv.2305.05352 2008. Link: https://doi.org/10.1002/9780470754887\n[28] X. Tang, Q. Jin, K. Zhu, T. Yuan, Y. Zhang, W. Zhou, [40] B. A. Kitchenham, S. Charters, and Other Keele Staffs,\nM. Qu, Y. Zhao, J. Tang, Z. Zhang et al., “Prioritizing “Guidelines for performing systematic literature reviews\nsafeguarding over autonomy: Risks of LLM agents for in software engineering (version 2.3),” Keele University\nscience,” arXiv preprint arXiv:2402.04247, 2024. Link: and Durham University Joint Report, Tech. Rep.,\nhttps://doi.org/10.48550/arXiv.2402.04247 2007. Link: https://www.elsevier.com/ data/promis\n[29] S. G. Ayyamperumal and L. Ge, “Current state misc/525444systematicreviewsguide.pdf\nof LLM risks and AI guardrails,” arXiv preprint [41] B. Kitchenham, “Procedures for performing systematic\narXiv:2406.12934, 2024. Link: https://doi.org/10.48550/ reviews,” Keele University, UK, Tech. Rep. 2004, 2004.\narXiv.2406.12934 Link: http://artemisa.unicauca.edu.co/∼ecaldon/docs/spi/\nkitchenham 2004.pdf //doi.org/10.48550/arXiv.2403.13031\n[42] A. Paez, “Gray literature: An important resource in sys- [54] S. Banerjee, S. Layek, R. Hazra, and A. Mukherjee,\ntematic reviews,” Journal of Evidence-Based Medicine, “How (un) ethical are instruction-centric responses of\nvol. 10, no. 3, pp. 233–240, 2017. LLMs? unveiling the vulnerabilities of safety guardrails\n[43] K. Godin, J. Stapleton, S. I. Kirkpatrick, R. M. Han- to harmful queries,” arXiv preprint arXiv:2402.15302,\nning,andS.T.Leatherdale,“Applyingsystematicreview 2024. Link: https://doi.org/10.48550/arXiv.2402.15302\nsearchmethodstothegreyliterature:acasestudyexam- [55] J. Zhao, K. Chen, X. Yuan, Y. Qi, W. Zhang,\nining guidelines for school-based breakfast programs in and N. Yu, “Silent guardian: Protecting text from\ncanada,” Systematic reviews, vol. 4, pp. 1–10, 2015. malicious exploitation by large language models,”\n[44] L.Schmidt,A.FinnertyMutlu,R.Elmore,B.Olorisade, arXiv preprint arXiv:2312.09669, 2023. Link: https:\nJ. Thomas, and J. Higgins, “Data extraction methods //doi.org/10.48550/arXiv.2312.09669\nfor systematic review (semi)automation: Update of a [56] X. Shen, Z. Chen, M. Backes, Y. Shen, and Y. Zhang,\nliving systematic review,” F1000Research, vol. 10, no. “”do anything now”: Characterizing and evaluating in-\n401, 2023. Link: https://doi.org/10.12688/f1000research. the-wild jailbreak prompts on large language models,”\n51117.2 arXiv preprint arXiv:2308.03825, 2023. Link: https:\n[45] V. Rawte, A. Sheth, and A. Das, “A survey of //doi.org/10.48550/arXiv.2308.03825\nhallucinationinlargefoundationmodels,”arXivpreprint [57] M. Liffiton, B. E. Sheese, J. Savelka, and P. Denny,\narXiv:2309.05922, 2023. Link: https://doi.org/10.48550/ “Codehelp: Using large language models with guardrails\narXiv.2309.05922 for scalable support in programming classes,” in\n[46] OpenAI, “OpenAI safety update,” 2024. Link: https: Proceedings of the 23rd Koli Calling International\n//openai.com/index/openai-safety-update/ Conference on Computing Education Research, Finland,\n[47] S. Torkington, “These are the 3 biggest emerging risks 2024, pp. 1–11. Link: https://doi.org/10.1145/3631802.\nthe world is facing,” World Economic Forum, Tech. 3631830\nRep., 2024. Link: https://www.weforum.org/agenda/ [58] Z. Wang, F. Yang, L. Wang, P. Zhao, H. Wang, L. Chen,\n2024/01/ai-disinformation-global-risks/ Q. Lin, and K.-F. Wong, “SELF-GUARD: Empower\n[48] C. Hutton, “Silicon valley self-regulates for AI the LLM to safeguard itself,” in Proceedings of the\nmisinformation in 2024 elections while government 2024 Conference of the North American Chapter of\nlags,” 2024. Link: https://www.washingtonexaminer. the Association for Computational Linguistics: Human\ncom/news/2803412/silicon-valley-self-regulates-ai- Language Technologies, Mexico, 2024, pp. 1648–1668.\nmisinformation-in-2024-government-lags/ Link: https://aclanthology.org/2024.naacl-long.92\n[49] S. Goyal, M. Hira, S. Mishra, S. Goyal, A. Goel, [59] A. Khorramrouz, S. Dutta, A. Dutta, and A. R. Khud-\nN. Dadu, D. Kirushikesh, S. Mehta, and N. Madaan, aBukhsh, “Down the toxicity rabbit hole: Investigating\n“LLMGuard: guarding against unsafe LLM behavior,” PaLM 2 guardrails,” arXiv preprint arXiv:2309.06415,\nin Proceedings of the AAAI Conference on Artificial 2023. Link: https://doi.org/10.48550/arXiv.2309.06415\nIntelligence, vol. 38(21), 2024, pp. 23790–23792. Link: [60] N. Mangaokar, A. Hooda, J. Choi, S. Chandrashekaran,\nhttps://doi.org/10.1609/aaai.v38i21.30566 K. Fawaz, S. Jha, and A. Prakash, “PRP: Propagating\n[50] S.Ray,“SamsungbansChatGPTamongemployeesafter universal perturbations to attack large language model\nsensitive code leak,” 2023, News article, Last accessed guard-rails,” arXiv preprint arXiv:2402.15911, 2024.\non Jul.-2024. Link: https://www.forbes.com/sites/ Link: https://doi.org/10.48550/arXiv.2402.15911\nsiladityaray/2023/05/02/samsung-bans-chatgpt-and- [61] P. Gajane and M. Pechenizkiy, “On formalizing fairness\nother-chatbots-for-employees-after-sensitive-code-leak/ in prediction with machine learning,” arXiv preprint\n[51] W. Du, Q. Li, J. Zhou, X. Ding, X. Wang, Z. Zhou, arXiv:1710.03184, 2017. Link: https://doi.org/10.48550/\nand J. Liu, “Finguard: A multimodal AIGC guardrail arXiv.1710.03184\nin financial scenarios,” in Proceedings of the 5th ACM [62] R. R. Llaca, V. Leskoschek, V. C. Paiva, C. Lupa˘u,\nInternationalConferenceonMultimediainAsia,Taiwan, P. Lippmann, and J. Yang, “Student-teacher prompting\n2024, pp. 1–3. Link: https://doi.org/10.1145/3595916. for red teaming to improve guardrails,” in Proceedings\n3626351 of the ART of Safety: Workshop on Adversarial testing\n[52] T. Zemcˇ´ık, “Failure of chatbot Tay was evil, ugliness and Red-Teaming for generative AI, 2023, pp. 11–23.\nand uselessness in its nature or do we judge Link: http://dx.doi.org/10.18653/v1/2023.artofsafety-1.2\nit through cognitive shortcuts and biases?” AI & [63] W. Li et al., “Segment anything model can not\nSOCIETY, vol. 36, pp. 361–367, 2021. Link: https: segment anything: Assessing AI foundation model’s\n//doi.org/10.1007/s00146-020-01053-4 generalizabilityinpermafrostmapping,”RemoteSensing,\n[53] Z. Yuan, Z. Xiong, Y. Zeng, N. Yu, R. Jia, vol. 16, no. 5, p. 797, 2024. Link: https://doi.org/10.\nD. Song, and B. Li, “RigorLLM: Resilient guardrails 48550/arXiv.2401.08787\nfor large language models against undesired content,” [64] Z. Zhang, Y. Lu, J. Ma, D. Zhang, R. Li, P. Ke, H. Sun,\narXiv preprint arXiv:2403.13031, 2024. Link: https: L. Sha, Z. Sui, H. Wang et al., “ShieldLm: Empowering\nLLMs as aligned, customizable and explainable safety [75] J. Larouzee and J.-C. Le Coze, “Good and\ndetectors,”arXivpreprintarXiv:2402.16444,2024.Link: bad reasons: The swiss cheese model and its\nhttps://doi.org/10.48550/arXiv.2402.16444 critics,” Safety Science, vol. 126, p. 104660, 2020.\n[65] H.-I. Kim, K. Yun, J.-S. Yun, and Y. Bae, Link: https://www.sciencedirect.com/science/article/pii/\n“Customizing segmentation foundation model via S0925753520300576\nprompt learning for instance segmentation,” arXiv [76] T. Shabani, S. Jerie, and T. Shabani, “A comprehensive\npreprint arXiv:2403.09199, 2024. Link: https: review of the swiss cheese model in risk management,”\n//doi.org/10.48550/arXiv.2403.09199 SafetyinExtremeEnvironments,vol.6,no.1,pp.43–57,\n[66] R. Y. Wong, A. Chong, and R. C. Aspegren, “Privacy 2024.\nlegislation as business risks: How GDPR and CCPA [77] B.Xia,Q.Lu,L.Zhu,andZ.Xing,“TowardsAIsafety:\nare represented in technology companies’ investment A taxonomy for AI system evaluation,” arXiv preprint\nrisk disclosures,” Proceedings of the ACM on Human- arXiv:2404.05388, 2024.\nComputer Interaction, vol. 7, no. CSCW1, pp. 1–26, [78] L. Bass, Q. Lu, I. Weber, and L. Zhu, Engineering AI\n2023. Link: https://doi.org/10.1145/3579515 Systems:ArchitectureandDevOpsEssentials. Addison-\n[67] Z. Chu, Y. Wang, L. Li, Z. Wang, Z. Qin, and K. Ren, Wesley, 2025.\n“A causal explainable guardrails for large language [79] K. Valmeekam, K. Stechly, and S. Kambhampati, “Llms\nmodels,” arXiv preprint arXiv:2405.04160, 2024. Link: stillcan’tplan;canlrms?apreliminaryevaluationofope-\nhttps://doi.org/10.48550/arXiv.2405.04160 nai’so1onplanbench,”arXivpreprintarXiv:2409.13373,\n[68] M. Shanahan, “Talking about large language models,” 2024.\nCommun. ACM, vol. 67, no. 2, p. 68–79, jan 2024. [80] Q. Lu, X. Xu, L. Bass, L. Zhu, and W. Zhang, “A\nLink: https://doi.org/10.1145/3624724 tail-tolerant cloud api wrapper,” IEEE Software, vol. 32,\n[69] Y. Zeng, H. Lin, J. Zhang, D. Yang, R. Jia, and no. 1, pp. 76–82, 2015.\nW. Shi, “How johnny can persuade LLMs to jailbreak [81] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia,\nthem: Rethinking persuasion to challenge ai safety by E. Chi, Q. V. Le, D. Zhou et al., “Chain-of-thought\nhumanizing LLMs,” arXiv preprint arXiv:2401.06373, prompting elicits reasoning in large language models,”\n2024. Link: https://doi.org/10.48550/arXiv.2401.06373 Advances in neural information processing systems,\n[70] A. Kumar, C. Agarwal, S. Srinivas, S. Feizi, and vol. 35, pp. 24824–24837, 2022.\nH.Lakkaraju,“CertifyingLLMsafetyagainstadversarial [82] Y. Liu, G. Deng, Y. Li, K. Wang, Z. Wang, X. Wang,\nprompting,” arXiv preprint arXiv:2309.02705, 2023. T. Zhang, Y. Liu, H. Wang, Y. Zheng et al., “Prompt in-\nLink: https://doi.org/10.48550/arXiv.2309.02705 jection attack against llm-integrated applications,” arXiv\n[71] D. Dalrymple et al., “Towards guaranteed safe AI: preprint arXiv:2306.05499, 2023.\nA framework for ensuring robust and reliable AI [83] Z.Chen,Z.Xiang,C.Xiao,D.Song,andB.Li,“Agent-\nsystems,” arXiv preprint arXiv:2405.06624, 2024. Link: poison: Red-teaming llm agents via poisoning memory\nhttps://doi.org/10.48550/arXiv.2405.06624 or knowledge bases,” arXiv preprint arXiv:2407.12784,\n[72] M. Pawagi and V. Kumar, “Guardrails: Automated 2024.\nsuggestions for clarifying ambiguous purpose [84] L. Dong, Q. Lu, and L. Zhu, “A taxonomy of agentops\nstatements,” in Proceedings of the 16th Annual ACM for enabling observability of foundation model based\nIndia Compute Conference, 2023, p. 55–60. Link: agents,” arXiv preprint arXiv:2411.05285, 2024.\nhttps://doi.org/10.1145/3627217.3627234 [85] B. Yohsua, P. Daniel, B. Tamay, B. Rishi, C. Stephen,\n[73] W. Zou, R. Geng, B. Wang, and J. Jia, “PoisonedRAG: C. Yejin, G. Danielle, H. Hoda, K. Leila, L. Shayne,\nKnowledge poisoning attacks to retrieval-augmented M. Vasilios, M. Mantas, N. Kwan Yee, O. Chinasa T.,\ngeneration of large language models,” arXiv preprint R. Deborah, S. Theodora, T. Florian, and M. Soren,\narXiv:2402.07867, 2024. Link: https://doi.org/10.48550/ “International Scientific Report on the Safety of\narXiv.2402.07867 Advanced AI,” Department for Science, Innovation\n[74] J. Hua and P. Wang, “Security vulnerabilities and Technology, Tech. Rep., May 2024. Link: https:\nin facebook data breach,” in International //hal.science/hal-04612963\nConference on Information Technology-New [86] J. Sun, Z. Xing, X. Xia, Q. Lu, X. Xu, and L. Zhu,\nGenerations. Springer, 2024, pp. 159–166. “Aspect-level information discrepancies across heteroge-\nLink: https://doi.org/10.1007/978-3-031-56599-1 22 neous vulnerability reports: Severity, types and detection\nmethods,” ACM Transactions on Software Engineering\nand Methodology, vol. 33, no. 2, pp. 1–38, 2023.",
    "pdf_filename": "Designing_Multi-layered_Runtime_Guardrails_for_Foundation_Model_Based_Agents_Swiss_Cheese_Model_for_.pdf"
}