{
    "title": "Frontiers in Collective Intelligence - A Workshop Report",
    "context": "intelligence as part of its Foundations of Intelligence project. This project seeks to advance the ﬁeld of artiﬁcial intelligence by promoting interdisciplinary research on the nature of intelligence. The workshop brought together computer scientists, biologists, philosophers, social scientists, and others to share their insights about how intelligence can emerge from interactions among multiple agents—whether those agents be ma- chines, animals, or human beings. In this report, we summarize each of the talks and the subsequent discussions. We also draw out a number of key themes and identify important frontiers for future research. 1",
    "body": "arXiv:2112.06864v2  [cs.AI]  10 Oct 2022\nFrontiers in Collective Intelligence:\nA Workshop Report\nTyler Millhouse\nSanta Fe Institute\ntyler.millhouse@santafe.edu\nMelanie Moses\nUniversity of New Mexico\nmelaniem@cs.unm.edu\nMelanie Mitchell\nSanta Fe Institute\nmm@santafe.edu\nAbstract: In August of 2021, the Santa Fe Institute hosted a workshop on collective\nintelligence as part of its Foundations of Intelligence project.\nThis project seeks to\nadvance the ﬁeld of artiﬁcial intelligence by promoting interdisciplinary research on the\nnature of intelligence. The workshop brought together computer scientists, biologists,\nphilosophers, social scientists, and others to share their insights about how intelligence\ncan emerge from interactions among multiple agents—whether those agents be ma-\nchines, animals, or human beings. In this report, we summarize each of the talks and\nthe subsequent discussions. We also draw out a number of key themes and identify\nimportant frontiers for future research.\n1\n\nContents\nOverview\n3\nSummaries of Talks and Discussions\n4\n“Collective Intelligence in a Computer Model of Analogy-Making” (Melanie Mitchell)\n. .\n4\n“Collective Intelligence: Future Directions” (Jessica Flack)\n. . . . . . . . . . . . . . . . .\n6\n“Collective Intelligence Within the Brain” (JeﬀHawkins)\n. . . . . . . . . . . . . . . . . .\n8\nGeneral Discussion: Day One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n“How Collective Behavior Unfolds from Individuals” (Cleotilde Gonzalez) . . . . . . . . .\n11\n“No-Bullshit Democracy” (Henry Farrell) . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n“Eﬃcient organization without too much overhead” (Anna Dornhaus) . . . . . . . . . . .\n14\nGeneral Discussion: Day Two\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n“When (and How) Crowds Can be Less Than Wise” (James Marshall) . . . . . . . . . . .\n19\n“Beyond Machines of Flesh and Blood” (Jacob Foster) . . . . . . . . . . . . . . . . . . . .\n21\n“Applied Collective Intelligence to Combat Online Misinformation” (Joe Bak-Coleman)\n.\n23\nGeneral Discussion: Day Three . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nConclusion\n27\nOptimization and Collectivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\nThe Beneﬁts (and Costs) of Communication . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nInstitutions, Norms, and Mechanisms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nLessons for Artiﬁcial Intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\nReferences\n31\n2\n\nOverview\nWhen building intelligent systems, the need to employ complex systems comprising a large num-\nber of more basic components seems inescapable. Brains are composed of billions of neurons, and\ndigital computers are composed of billions of transistors. It is the myriad interactions among these\ncomponents that give rise to the remarkable larger-scale phenomena of cognition and computation.\nIn this sense, there is no question of whether collective phenomena are relevant to understanding\nthe nature and emergence of intelligence. However, to characterize a system as exhibiting collective\nintelligence is not merely to say that it is composed of many interacting components. It is to say\n(i) that these components themselves possess a degree of agency, intelligence, or ability to react\nto their environment (including other agents) and (ii) that this fact is central to the emergence of\nintelligence in the system as a whole. As Levin and Dennett (2020) argue:\n“There is a profound diﬀerence between the ingenious mechanisms designed by human\nintelligent designers... and the mechanisms designed and assembled by natural selec-\ntion... Individual cells are not just building blocks, like the basic parts of a ratchet\nor pump; they have extra competences that turn them into... agents that, thanks to\ninformation they have on board, can assist in their own assembly into larger structures.”\nOn this view, intelligence is not merely an emergent high-level phenomenon but one that plays a\ncritical role at many levels of organization. To borrow Levin and Dennett’s turn of phrase, it’s\n“cognition all the way down.”\nIn this workshop, we gathered experts from computer science, biology, social science, and other\nﬁelds to explain their research and how it bears on larger questions about collective intelligence.\nFor example, which of the mechanisms that enable collective intelligence to emerge (e.g., in social\ninsects and swarm robotics) can inform collective AI? Which frontiers of AI research hold the\nmost promise for advancing large-scale scientiﬁc or social eﬀorts to address complex problems (e.g.,\nclimate change or epidemic control)? How can we facilitate productive interactions between humans\nand machines? What kinds of interfaces are best, and what kinds of algorithmic transparency or\nexplainability will most enhance collaborative intelligence between humans and machines? How\ncan we develop collaborative intelligence that promotes important values such as fairness, especially\nwhen dealing with collaboration on a large scale? In what follows, we summarize the insights oﬀered\nby our speakers and attempt to distill the larger themes present in the talks and discussions.\n3\n\nSummaries of Talks and Discussions\n“Collective Intelligence in a Computer Model of Analogy-Making”\nMelanie Mitchell is the Davis Professor of Complexity at the Santa Fe Institute. Her\nresearch focuses on conceptual abstraction, analogy-making, and visual recognition in\nAI systems.\nMelanie Mitchell presented her “Copycat” architecture as a model of collective intelligence. Copycat\nis a model of abstract perception and analogy making inspired by the kind of collective information\nprocessing found in natural systems (e.g., insect colonies, cells, or immune systems).\nCopycat\noperates on the domain of letter string analogies. Solving these analogies requires one to identify\nthe rule used to transform one string into another and apply that rule to a new string. For example,\nif one is shown ”abc→aabbcc” and asked to complete “def→”, one would complete the string with\n“ddeeﬀ”. Of course, the rules may also be applied to groups of characters and may include more\ncomplicated operations than duplication. For example, “abcdef→cbafed” requires one to realize\nthat the ﬁrst three and last three letters should be treated as separate sequences and individually\nreversed. This ﬂexibility with respect to grouping and rules makes solving letter string analogies a\nsurprisingly subtle and challenging task.\nTo solve these problems, Copycat begins with a network of concepts and employs a number of\nagents which work in parallel to identify instances of these concepts in the strings. For example,\nsome of the agents might attempt to identify structures (e.g., groups of characters), while other\nattempt to identify transformations (e.g., reversal) that ﬁt the example given. No single agent settles\non a solution, but rather the agents collectively settle on a working solution after a stochastic process\nof trial, error, and exploration inﬂuenced by a global variable “temperature” which is determined\nby the activity of individual agents and which feeds back into that activity by inﬂuencing the degree\nof stochasticity they exhibit. This architecture allows for both bottom up and top down inﬂuence;\nfor example, the identiﬁcation of a plausible group or a plausible rule will bias other agents to ﬁnd\nother rules or groups that are consistent with this identiﬁcation. Hence, the Copycat architecture\nis an excellent example of collective intelligence emerging from the interactions of many simpler\nagents.\n4\n\nAs Mitchell argues, Copycat incorporates several important ideas relevant to collective intel-\nligence. First, it models high-level cognition as a form of perception, where representations are\nactively built up over time and where top-down and bottom-up processes interact dynamically. It\nalso continually integrates prior knowledge (e.g., the concept network), and it exhibits an emergent\ntransition from bottom-up stochastic parallel processing to top-down serial deterministic attentive\nprocesses as the system settles on a particular coherent structure. This transition also reﬂects\nthe fact that the system incorporates both sub-symbolic elements (i.e., the stochastic competing\nagents) with symbolic processing (i.e., the identiﬁcation and application of symbol manipulation\nrules). Crucially, Mitchell suggests, these features all depend on the collective nature of the archi-\ntecture. Moreover, similar architectures (e.g., neuro-symbolic algorithms or probabalistic program\nsynthesis) might help us to address problems in other challenging domains, such as the Abstraction\nand Reasoning Corpus (or “ARC”) (Chollet, 2019) and visual situation recognition (Quinn et al.,\n2018).\nDiscussion:\nThe ﬁrst commenter asked whether the concept network of Copycat could be learned. Mitchell\nsuggested that probabilistic program synthesis might help in this area, but that further work was\nneeded, as this approach is currently limited and requires a great deal of search. The same com-\nmenter asked whether temperature worked diﬀerently in Copycat as opposed to other algorithms\nwhich use a temperature variable to balance exploration and exploitation. Mitchell noted that in\nCopycat, unlike in other algorithms, temperature is a feedback mechanism. She suggested that\none could think of Copycat as making a context-sensitive exploration/exploitation trade-oﬀusing\ntemperature. The next commenter asked what formal letter string analogies had in common with\nvisual situation recognition wherein people must recognize the same situation across many diﬀer-\nent contexts (e.g., that one can “walk” the dog while riding a skateboard and holding the leash).\nMitchell said that what matters in both cases is the ability to create transferable representations\nwhich re-represent past events in order to apply them to novel contexts.\n5\n\n“Collective Intelligence: Future Directions”\nJessica Flack is a professor at the Santa Fe Institute and the Director of SFI’s Collective\nComputation Group. Her research focuses on the role of collective computation in the\nemergence of robust structure and function in both nature and society.\nJessica Flack outlined the ﬁeld of collective computation and its relationship to the kinds of prob-\nlems discussed in collective intelligence. Most broadly, she contends, the study of collective phe-\nnomena is the study of pattern formation in many-body systems. This study encompasses many\ndisciplines, ranging from theoretical computer science, to biology, to statistical mechanics. Within\nthis larger area of research, the study of collective computation aims to (i) ﬁnd common princi-\nples underlying diverse examples of collective computation, (ii) provide an organizing framework\nfor relevant sciences, and (iii) develop a general theoretical formalism for characterizing collective\ncomputation.\nA key concept in collective computation is the connection between coarser- and ﬁner-grained\ndescriptions, and Flack argues that understanding this connection is central to understanding the\ncomputation that underlies collective intelligence.\nThe process of distilling relevant micro-scale\ninformation into a smaller set of macro-scale variables is known as “coarse-graining.” To take a\nmundane example, temperature can be understood as the average kinetic energy of the molecules in\na solution. Using temperature to represent the solution means that the ﬁne-grained details about\nthe energies of speciﬁc molecules are lost, but an important and informative statistic is preserved.\nIn much the same way, organisms and collectives of organisms can help to manage complexity\nand identify important regularities by distilling the information they receive from their senses\ninto coarser-grained variables of interest. For example, the brain’s visual system parses complex\nand highly detailed visual scenes into macro-scale objects and relationships between them. These\nhigher-level categories are invariant with respect to ﬁner-grained diﬀerences (e.g., diﬀerences in\nviewing angle, illumination, etc.) and help us to reliably track salient features of our environment.\nAs Flack argues, collective computation has an important role to play in this coarse-graining\nprocess. Individual agents have limited samples and limited computational resources. This means\nthat they might not reliably extract the value of a coarse-grained variable. For this reason, collec-\ntives can work to aggregate the judgments of individuals into a more accurate and robust estimate\nof the variable. For example, monkeys have an interest in knowing whether they could successfully\n6\n\nuse force to resolve a conﬂict with another monkey. They also have partial/imperfect access to a\nhistory of ﬁghts between diﬀerent monkeys, and they can use this history to estimate the relative\ndominance of diﬀerent individuals—a coarse-grained representation relative to the full ﬁght history.\nThey also reveal their estimate to others by giving publicly visible subordination signals to mon-\nkeys they perceive to be more dominant monkeys. Collectively, we can think of these signalling\nevents as expressing a directed graph of subordination signals that aggregate and communicate\neach monkey’s information about the history of ﬁghts.\nThe result is a more robust and accurate representation of relative dominance in the group. This\nrepresentation can be used to avoid needless (and often dangerous) ﬁghts between individuals—\na serious social problem. In addition, it supports the development of new behaviors that were\npreviously more diﬃcult. For example, if the signals reveal a few individuals that are markedly more\ndominant, those individuals can more conﬁdently intervene in conﬂicts between other monkeys since\ntheir own dominance is more reliably established. This “policing” behavior can beneﬁt a group\nof monkeys and allows them to solve (at least in part) an important social problem. As Flack\nargues, and this case illustrates, understanding how groups of individuals collectively compute and\naggregate coarse-grained information is central to understanding the kind of collective problem\nsolving of interest to those working in collective intelligence.\nDiscussion:\nThe discussion began with a request for clariﬁcation about the precise relationship between collec-\ntive intelligence and collective computation. Flack noted that collective computation is a component\nof collective intelligence, but not all collective computation constitutes collective intelligence. For\nexample, the framework of collective computation can just as easily investigate the role of collective\ncomputation in collective stupidity—or failures of collective intelligence. Another key issue that\narose was that of quantifying the degree of decomposability in collective computation. That is,\nwhat is the best way to identify and characterize the degree to which a collective computation can\nbe described in terms of the activity of intermediate scale components. Digital computers have a\nhigh-degree of modularity and, hence, decomposability, but it is far from clear whether the same\nis true of computing collectives of animals or neurons.\n7\n\n“Collective Intelligence Within the Brain, The Thousand Brains Theory”\nJeﬀHawkins is the Co-Founder of Numenta, which seeks to advance artiﬁcial intel-\nligence through a better understanding of the neocortex. Previously, he founded and\ndirected the Redwood Neuroscience Institute.\nJeﬀHawkins argued that the brain’s cortical columns are a striking example of collective intel-\nligence. These columns of neurons perform similar functions in parallel, resolving disagreements\nthrough a voting-like mechanism. The neural representations (i.e., ﬁring patterns) within these\ncolumns are sparse—that is, most of the neurons are not active at any given time. The content\nof these neural representations is encoded by which subset of neurons are ﬁring and how they are\nﬁring. This type of neural representation is called a “sparse distributed representation.”\nAccording to Hawkins, these representations are central to the operation of and communication\nbetween cortical columns. For example, uncertainty about which of two representations should be\nactive can be represented by activating the union of those representations. If it is a dark night,\nand one cannot tell whether a horse or a cow is standing far away in a ﬁeld, all the neurons will ﬁre\nthat would have ﬁred for either the cow or horse representation. Sparse distributed representations\nalso help to minimize the number of connections needed between columns. If one column would\nbeneﬁt from knowing whether another column thinks there might be a horse within its receptive\nﬁeld, it need not connect to all the neurons that ﬁre when other objects are detected. This would\nnot be the case if the ﬁring patterns were dense—that is, if diﬀerent neural representations (e.g.,\n“horse”) involved patterns of ﬁring that included most or all of the relevant neurons.\nEach cortical column is similar to the others in that each attempts to integrate lower-level\nsensory information into a model of what is in the world. That said, these models are situated within\ndiﬀerent reference frames for diﬀerent cortical columns. A reference frame provides a spatial and\nsensory context within which objects in the world are positioned and characterized. For example,\nconsider two cortical columns that are receiving visual and tactile information (respectively) about\na coﬀee cup. Both might represent the coﬀee cup as occupying a position in space, but they will\ndiﬀer in the kinds of surface properties (i.e., color or texture) they ascribe to the coﬀee cup. The\nsame goes for cortical columns which receive diﬀerent inputs from the same sensory modality (e.g.,\ntactile inputs from the tip of the right index ﬁnger and right ring ﬁnger). The resulting models will\n8\n\nbe similar but situated in reference frames that, as it were, provide an index ﬁnger’s view or ring\nﬁnger’s view of the world.\nThese diﬀering perspectives allow the columns to compare their individual models to collectively\nproduce accurate and robust judgments about the environment.\nAs mentioned earlier, cortical\ncolumns aggregate their individual models via a voting-like mechanism. The output of these votes,\nargues Hawkins, is what manifests in consciousness. For example, as one commenter pointed out,\nthis likely gives rise to Gestalt switches in perception like those seen in bi-stable images (e.g., the\nduck-rabbit). In this way, the cortical columns act as a collective intelligence of “miniature brains,”\naggregating their judgments about the environment, with diﬀerent cortical columns making those\njudgments from within a wide range of reference frames.\nDiscussion:\nThe discussion began with some clarifying questions about the voting mechanism described by\nHawkins. For example, does the mechanism require a large number of inhibitory connections to\nquiet the “losing” columns and allow a collection of columns to converge on a single model of\nthe world? Hawkins acknowledged the need for some inhibitory connections, but argued that the\nconvergence process is surprisingly quick and that sparsity means that fewer connections are needed\nto accomplish it than one might imagine. An important point of discussion was how Hawkins’s\nmodel related to the idea that a (or perhaps the) central goal of the brain is to predict future sensory\ninputs. Hawkins agreed that prediction is central to cortical columns but was not fully convinced of\nparticular interpretations of this fact (e.g., Bayesian interpretations). Other questions highlighted\nthe importance of attention mechanisms in coordinating columns and the general importance of\nbuilding appropriate reference frames for organizing knowledge.\nGeneral Discussion:\nMelanie Moses began the general discussion by highlighting some possible areas for further dis-\ncussion drawn from the day’s talks. These included further clarifying and disambiguating closely\nrelated topics like collective, distributed, and collaborative intelligence as well as models, represen-\ntations, and coarse-grainings. She also noted the importance of balancing top-down and bottom-up\ninﬂuences. Finally, she noted three more speciﬁc points: the importance of copying/sharing infor-\n9\n\nmation, the limitations of individual agents as a motivation for collective intelligence, and the\nimportance of persistent information (e.g., memory) in collective intelligence.\nThe ﬁrst attendee to comment asked JeﬀHawkins about how analogy might ﬁt into his model\nof cortical collective intelligence.\nHawkins replied that analogies between models amounted to\nthe kind and degree of overlap between parts of those models. To take a simple example, both\nstaplers and doors have hinges, and familiarity with hinges in either context might be a useful\nstarting point understanding how to interact with the other. The next commenter asked Hawkins\nand Jessica Flack to comment on Moses’s request for clariﬁcation on models, representations, and\ncoarse-grainings. Flack noted that coarse-graining is (in her work) a rigorous formal notion that,\ninformally, means a compressed representation of a system that is true to the relevant mechanism.\nThis notion is drawn from physics and connects work in that ﬁeld to work in cognitive science.\nModels, in turn, are compressed representations of regularities in systems. Hawkins, in contrast,\nnoted that “coarse-graining” is not a common term in his areas of research, but that a model is\nsomething quite speciﬁc: a neural recreation of the structure of the target system, paradigmatically,\na neural representation of an environment or object. How abstract reasoning (e.g., about fair voting\nlaws in democracies) works, he does not know, but he suspects there is a re-appropriation of the\nbasic machinery for more concrete reasoning.\nThe next commenter asked Hawkins what he might say about organisms that lack cortical\ncolumns. In some cases (e.g., the case of birds), Hawkins argued that neuroscientists have iden-\ntiﬁed analogous structures—that is, structures which seem to carry our similar modeling/learning\nfunctions. Hawkins argued that this kind functional similarity is really what matters. To engage\nand re-engage with objects in their environment, animals must have some means of building a\nreference frame within which their models of the objects are situated. In other words, its all about\ndiscovering/learning the structure of the world and using that structure to guide action. The ﬁnal\ncommenter concluded with some advice for beginning to resolve some of the semantic ambiguities\nencountered during the workshop and for learning from other ﬁelds. She suggested, in particular,\nthat researchers should listen when experts in other ﬁelds say that research in those ﬁelds might be\nrelevant to their own. Getting past semantic diﬀerences and learning from this research, however,\nmeans that researchers must roll up their sleeves and acquire a basic facility with scholarship in\nother ﬁelds.\n10\n\n“How Collective Behavior Unfolds from Individuals: Interdependence, Ag-\ngregation, and Strategy”\nCleotilde (Coty) Gonzalez is a Research Professor at Carnegie Mellon University. Her\nresearch focuses on human decision making in dynamic and complex environments.\nCleotilde Gonzalez discussed her work on how individuals interact in networks given diﬀerent net-\nwork structures and diﬀerent levels of knowledge about others in their network. For example, people\nin a network might be connected to a single other person, connected in a loop, connected to every\nother person, etc. Similarly, they might have no knowledge that the consequences of their choices\nare inﬂuenced by the choices of others or they might know that these choices matter, know what\nthese choices are, and know how those choices impact them (or anything in between). As Gonzalez\nargues, what we know about how our choices are entangled with the choices of others shapes what\nchoices we make. Consider, for example, the prisoner’s dilemma.1 Gonzalez has found that when\nindividuals know more about their interactions with others, they cooperate at higher rates in the\nprisoner’s dilemma. This matched the predictions made by formal models of reasoning. Natu-\nrally, the ability to appreciate the potential beneﬁts of cooperation requires enough information to\nunderstand or infer how the prisoner’s choices shape their payoﬀs.\nThese results assumed that individuals were paired oﬀwhen playing the prisoner’s dilemma,\nand it might be natural to think that adopting a more connected network of interactions would\nnot change the basic result.\nOn the contrary, Gonzalez found that the more individuals each\nperson interacted with, the less cooperation there was overall.\nThe explanation, she argues, is\nthat repeated interactions with the same individual reinforce the strategy of cooperation. However,\nwhen individuals switch between social partners, they might change their strategy only to switch\nanother social partner whose strategy has not been informed by their past interactions.\nThis\nlimits the ability of individuals to establish patterns of trust and mutual cooperation.\nGiven\nthat cooperation is desirable and given that humans typically interact with many individuals, an\n1In the dilemma, two prisoners being interrogated by the police must decide whether to defect and incriminate\neach other or to cooperate and keep quiet. Both prisoners would get less jail time if they both cooperate than if they\nboth defect. That said, they get the least jail time if they defect while their partner keeps silent and the most jail\ntime if they keep silent while their partner defects. Hence, whether one’s partner defects or cooperates, the choice\nthat minimizes jail time is defection. However, this is true for both prisoners and the result (should they adopt this\nstrategy) is that they will both defect and spend more time in jail than if they had both kept quiet. This dynamic\nchanges when we consider repeated interactions where individuals can build trust, punish others for defection, etc.\n11\n\nimportant next step for her research (she argues) is to ask what new mechanics must be introduced\nto reinforce cooperation in the context of complex social networks like our own.\nDiscussion:\nThe discussion participants suggested some interesting ways to extend Gonzalez’s work to new areas.\nFor example, might understanding these dynamics help us to develop better artiﬁcial collective\nintelligence or to explain our preference for interacting with individuals in our in-group? Others\nwondered whether we might understand the network itself as carrying important information.\nGonzalez suggested that this characterization might be more apt if individuals learned who it was\nbest to interact with over time. In this way, the connections in the network might encode helpful\ninformation (e.g., who should be avoided). Gonzalez identiﬁed this as an important area for further\nstudy. In addition to learning whom to interact with, another commenter suggested that memory\nfor past interactions with others might allow people to tailor their play to those interactions and\n(eﬀectively) reproduce the eﬀects of repeated interactions.\n“No-Bullshit Democracy”\nHenry Farrell is the Stavros Niarchos Foundation Agora Institute Professor of Inter-\nnational Aﬀairs at Johns Hopkins University. His work focuses on the relationship be-\ntween democracy and information, the security consequences of international economic\nnetworks, and international political economy\nHenry Farrell outlined an ambitious research program on the nature of democracy. Farrell argues\nthat current scholarly disputes about democracy fail to do justice to the subject. Pessimists about\ndemocracy as a collective problem-solving mechanism emphasize the irrationality of individuals in\ndemocracy, while optimists emphasize the fact that an aggregation of many diverse opinions can\noften outperform expert opinion.\nThe concerns of optimists and pessimists are not necessarily\nat odds—both could acknowledge that individual opinions are noisy, irrational, or error prone.\nThe question is whether the error-reducing eﬀects of aggregation or the error-inducing eﬀects of\nindividual irrationality tend to dominate. That said, Farrell argues that neither approach captures\nthe variation in democracy—sometimes democracy works well and sometimes it works poorly.\nResearch should attempt to understand what factors contribute to the successes and failures of\ndemocracy rather than arguing for or against democracy tout court.\n12\n\nTo gain this understanding, Farrell argues that we should investigate democracy as a form of\ncollective intelligence which aims to solve diﬃcult social problems (e.g., navigating disagreements\nabout core values in crafting eﬀective public policy).\nFarrell identiﬁes three areas of research\ncentral to this project, which he is currently exploring with collaborators. First, there is the issue\nof how democratic problem solving works on small scales and how group structure contributes to\n(or detracts from) collective problem solving. Of particular importance here are questions about\ndiversity within groups, including both the extent of common ground between members as well as\nthe comfort of members with dissent and disagreement. Once the contribution of such factors is\nunderstood at a small scale, researchers should investigate how these lessons scale with group size.\nThe next two research areas Farrell proposes take a macro-scale view of democracy.\nFirst,\nthere is the issue of how democratic institutions evolve over time.\nOf particular interest here\nare the opportunities for individuals to access and participate in these institutions and how this\nparticipation might shape the course of their evolution. Second, there is the issue of which factors\ncontribute to the stability or instability of democratic and non-democratic governments. These\nfactors might include everything from access to information, belief that elections are fair and\ncompetitive, norms supporting the peaceful transfer of power, etc.\nFarrell also proposes two hypotheses about what research in these areas might uncover. For\nexample, it seems likely that the democratic and non-democratic governments will fare diﬀerently\ngiven open access to information on the part of citizens—with the former being stabilized by\ngreater access to information and the latter being destabilized. Farrell also proposes that demo-\ncratic institutions whose participants exhibit greater ideological diversity and have greater access to\nparticipating in those institutions will tend to adopt new policies more readily as diversity fosters\ninnovation and access enables change.\nDiscussion:\nThe discussion began with the question of how to deﬁne democracy. Is voting on politicians or\npolicies enough? Farrell oﬀered a rough and ready deﬁnition of democracy that is more substan-\ntive.\nDemocracy is a system which is open to a variety of perspectives and is able to harness\ninformation from those perspectives in order to solve social problems.\nThis deﬁnition eschews\nthe details of voting, representative government, etc. and focuses on the core idea of integrating\ninformation from many perspectives to enhance decision-making. Another commenter suggested\n13\n\nthinking about democracy in terms of the norms that communities possess which enable fruitful\ncollective problem-solving. Farrell supported this idea and regarded it as complementary to his\nown. Another commenter wondered where a connection to truth and reality ﬁt into democracy,\ngiven its emphasis on integrated diverse views some of which are further from reality than others\n(especially with respect to individuals’ acceptance of well-supported science). Farrell suggested\nthat it would be hard, say, to return to a norm of deference to science, but that it might be better\nto communicate the messiness and uncertainty of science in a way that doesn’t make science seem\nbrittle and untrustworthy as scientists revise and reﬁne their conclusions. Finally, one commenter\nworried that democratic institutions might foster dissent-averse conformity, while another worried\nthat democracy might not be able to reconcile or integrate highly disparate values.\n“Eﬃcient organization without too much overhead: When to reduce commu-\nnication for better group ﬂexibility”\nAnna Dornhaus is a Professor at the University of Arizona, where she directs the Social\nInsect Lab.\nHer research focuses on collective problem-solving strategies as well as\neﬃciency, ﬂexibility, and robustness in complex systems.\nAnna Dornhaus summarized important lessons on communication in complex adaptive systems\ndrawn from her research on insect foraging behavior. In the context of this research, Dornhaus\nunderstands a complex adaptive system to be a system in which the behaviors of individual compo-\nnents have been selected for some collective outcome. For example, the behavior of cells in animal\nbodies has been modiﬁed by natural selection for the reproductive success of the organism. In\ncontrast, the behavior of economic agents might give rise to collective outcomes—even desirable\nones—despite the fact that the behavior of individual agents is selected for non-collective outcomes\n(e.g., the maximization of their own utility function).2\nTurning to the issue of communication, non-deceptive communication might seem like a form\nof cooperation that would beneﬁt collectives, but not all communication is actually selected for\n2For clarity, this evolutionary biological account of “complex adaptive systems” contrasts with how the term is\napplied in other areas of complex systems science. In the latter context, “adaptive” refers to the ability of a system\nto adapt to changing circumstances. This includes, but is not limited to, adaptation over evolutionary time due to\nselection. It also includes the ways that a system (e.g., a social group of humans) responds to changes within the\nlifetime of its members (e.g., moving to a more fertile location for farming) or within the lifetime of the system (e.g.,\nchanging social norms or methods of agriculture)(Gell-Mann, 1994). This is not to critique either account, but rather\nto highlight an important diﬀerence in emphasis.\n14\n\ncollective outcomes. For example, a peacock might communicate an honest signal about its ﬁtness\nby having a showy tail, and this information might beneﬁt potential mates. Nevertheless, this\nbehavior was not selected for any collective outcome, but rather because it beneﬁts the sender of the\nsignal. In contrast, the more modest waggle dance of a bee serves to convey important information\nabout the location of food sources to other members of the colony, and this behavior appears to\nhave been selected for the collective reproductive success of the hive. In general, Dornhaus argues,\nnon-cooperative signalling tends to be loud and showy, while cooperative communication tends to\nbe less showy but more information-rich.\nEven cooperative communication, however, may not be desirable in every context, and the\ncontexts in which it is beneﬁcial give us clues about the function of communication within a\ngiven system. For example, Dornhaus notes that larger bee colonies seem to beneﬁt more from\ncommunication than smaller colonies.\nThe reason for this seems to be related to the costs of\ncommunication.\nEach bee that forages faces a choice to go out and look for food or wait for\nanother bee to scout out food and report back. If food is easy to ﬁnd, then it might be worth\nﬁnding it yourself rather than waiting for another bee to go out, ﬁnd the food, ﬂy back, and report.\nThis waiting period will be less, however, when there are many bees to serve as scouts, since it is\nmore likely that at least one will stumble upon food very quickly and report back.\nOther insects tune their sensitivity to signals from others rather than merely waiting or not\nwaiting for those signals to arrive. For example, diﬀerent species of ants follow diﬀerent patterns in\nforaging for food: in some species, ants spread across multiple food sources while in others, many\nants converge on a single food source. The latter species tend to be more physically dominant,\nand by arriving in force, they can more easily drive oﬀother ants. Less dominant ants, naturally,\nbeneﬁt from having ready alternatives in case they are driven oﬀ. This behavior is modulated by\nhow ants respond to pheromone trails left by other ants. If this response is such that a slightly\nstronger trail is much more likely to be followed, then ants primarily follow this trail, adding their\nown pheromones as they do, thereby reinforcing the original signal. These ants quickly converge\non a single food source. In contrast, if ants are only somewhat more likely to follow a slightly\nstronger signal, then they tend to spread out to multiple food sources. Ultimately, the exact forms\nof communication that emerge in complex adaptive systems can tell us a great deal about the\n15\n\nnature of those systems (e.g., their population and foraging strategies) and how they are situated\nin particular contexts and environments (e.g., the presence of physically dominant competitors).\nDiscussion:\nThe discussion focused on another set of trade-oﬀs mentioned in the talk—those involving the\nproportion of specialists and generalists in the colony and the extent of the division of labor in\nthe colony. For example, in some of Dornhaus’ work, the costs of switching between tasks (e.g.,\ncaring for larvae versus scouting) favored the division of labor. That said, Dornhaus emphasized a\nbroader set of factors, any one of which could give rise to specialization and the division of labor.3\nThe diﬃculty, she argued, was in assessing these factors in a real-world system such that one could\nidentify the reasons for a particular level of specialization or division. For example, how might we\nmeasure the diﬃculty of reallocating generalists from one task to another? It is not clear. What is\nclearer is that there is a close connection between the size, structure, physiology, and environment\nof an organism and the trade-oﬀs it makes with respect to communication, specialization, and\ndivision of labor. Understanding these connections is an important area for future study.\nGeneral Discussion:\nMelanie Mitchell began the general discussion by highlighting some important open questions\nraised by the talks. For example, all the talks touched on the information possessed and shared by\nindividuals within groups and how this information facilitated problem solving. However, in some\ntalks (e.g., Cleotilde Gonzalez’s) emphasized the fact that the resulting solutions are realized in the\nknowledge and behavior of many individuals. Mitchell asked how much of what groups know or\nlearn is realized by, say, the pattern of connections between individuals or other aspects of group\nstructure. Further, how do speciﬁc variations in group structure aﬀect learning, problem solving,\nand cooperation? Access to information about others, degree of hierarchical organization, division\nof labor, and other factors might all play critical roles in the emergent behavior of the group.\nOne issue raised by Anna Dornhaus was the idea that complex adaptive systems, understood\nfrom the standpoint of an evolutionary biologist, are those systems whose individuals members have\n3Here we distinguish between specialization and division of labor, since specialization in insect colonies might\ninvolve signiﬁcant diﬀerences in morphology between specialists and generalists, rather than merely the specialization\nof individuals on particular tasks (as in human economies).\n16\n\nbeen adapted in some way for a collective outcome. It is controversial whether the course of human\nevolution has been shaped by selection for group-level outcomes, but Mitchell asked whether we\nmight ﬁnd that certain cognitive biases which seem detrimental to individuals (e.g., conﬁrmation\nbias) might be better explained if we consider how they facilitate cooperation or other desirable\ncollective outcomes. Turning to ideas raised by Henry Farrell, Mitchell suggested further discussion\nabout the factors that help to stabilize democracies and whether there might be analogs of these\nfactors in other collective intelligences. She also asked whether stabilizing inﬂuences of this sort\ncan be expected to scale from small human groups to large-scale human societies.\nThe broader discussion opened with a question about the centrality of consensus to collective\nintelligence. In the context of, say, democratic decision-making, there may often be times that call\nfor some form of consensus or, at least, some way of settling on a policy despite disagreement (e.g.,\nenacting either this or that tax policy but not both). However, it is less clear that we should want,\nsay, economic decision-making to have strong consensus-forming mechanisms. An economy might\nbe more robust if investors diversify and businesses explore a range of new products and services.\nFor this reason, the commenter suggested that we also consider how to optimize collectives for\nintelligent behavior that does not prioritize consensus.\nThe next commenter asked Farrell why politics is so diﬀerent from science and engineering.\nProblems in these areas are not solved by writing op-eds, garnering public support, or voting.\nGiven the rapid progress of these ﬁelds, what does this tell us about the comparative intelligence of\ncollective political decision-making? Farrell responded that the problems are importantly diﬀerent\nin politics. For example, values play a much larger role, are harder to formalize than the aims of\nscientiﬁc research, and are much more diﬃcult to reconcile when in conﬂict. Another commenter\nindirectly echoed these thoughts, noting that even with agents who are pre-disposed toward coop-\neration, there are hard design questions about how to channel cooperation in helpful ways (e.g.,\nby tuning response to pheromones). Another commenter suggested that the goals of individual\nhumans are shaped by biology, which was largely unconcerned by what modern people regard as\ndesirable social outcomes. This means that our individual goals might often be in tension with the\nsocial outcomes we (abstractly) endorse.\nThe next commenter spoke to the issue of where solutions are represented in collectives, and\nargued that the choice between the “in many individuals” and “in the connections between individ-\n17\n\nuals” views might be a false dichotomy. For example, collective outcomes are often the product of\nhuman action but not human design (Ferguson, 1782). This means that the goals behind individual\nhuman actions (e.g., making or saving money) may be orthogonal to the collective outcomes that\nresult (e.g., the reduced consumption of scarce goods without the need for rationing due to rising\nprices). This allows us to take a collective level view, evaluating the individual goals and actions\nas selected for (or not selected for) a particular collective outcome. That said, it also allows us\nto take an individual level view, evaluating how well optimized each individual’s actions are for\nachieving their goals. Both are valid and important perspectives to take. Nevertheless, another\ncommenter worried that whether actions or goals are optimal for bringing about some collective\neﬀect is a diﬀerent question from whether those actions or goals have been subject to a process\nof selection. The latter might be importantly diﬀerent in practice. For example, the hypothesis\nthat certain ant behaviors have been selected for a particular collective outcome might predict the\ndiscovery of other traits selected for that outcome. The claim that ant behaviors happen to give\nrise to certain collective outcomes as if those behaviors were selected for that outcome would not\nmake similar predictions.\nThe discussion next turned to the idea, proposed by a commenter, that many mechanisms of\ncollective intelligence might involve shifting group boundaries (e.g., the formation of political or\nneural coalitions). Another commenter noted that these kinds of coalitions are (in human societies)\noften goal-oriented (e.g., facing an external threat). Others, however, argued that this could not\nfully explain cooperation in these cases since the mutual perception of a threat already presupposes\na mechanism of consensus formation that may or may not be present. After all, the mere presence\nof an external threat does not guarantee that individuals in a society will be able to identify and\ncollectively agree upon its existence. For example, global warming is a threat to human society, but\nmany eﬀorts at uniﬁed action against it have failed because individuals disagree about the existence\nand severity of the threat. Also, the beneﬁts of a shared goal can be reduced by the fact that some\nwill beneﬁt more from accomplishing that goal than others and some will need to make greater\nsacriﬁces than others to accomplish the goal. Again, diﬀerent individuals, regions, and industries\nhave more or less to gain (and lose) from combating global warming.\n18\n\n“When (and How) Crowds Can be Less Than Wise”\nJames Marshall is the CSO and Co-Founder of Opteran Technologies and a Professor\nat the University of Sheﬃeld. His research focuses on biologically-inspired algorithms,\ndecision theory, social evolution, and social insect behavior.\nJames Marshall explored the ways natural and artiﬁcial populations of information-accumulating\nagents solve decision problems under diﬀering conditions and capabilities. Two salient points from\nhis talk are (i) that the misapplication of decision theory can lead to failed predictions or bad\ndecisions, and (ii) that the simple, elegant decision-making strategies of neurons, honey bees, and\ncollections of robots share important similarities and can enable eﬀective collective decisions in a\nvariety of real-world problems.\nThe talk started with an illustration of how collective decisions can be made by a population of\nneurons in a mammalian brain. A monkey or a human is shown a ﬁeld of moving dots on a screen.\nSome of the dots on the screen are moving in the same direction while the rest are moving randomly,\nsuch that the ﬁeld displays coherent but noisy motion. The population of neurons must then decide\nif the majority of dots are generally moving left or right. The statistically optimal solution to this\ndecision problem can be modeled simply and demonstrates a speed-accuracy trade-oﬀbased on\nBrownian motion toward each of the two possible events, with a decision made based on the log\nlikelihood of each event. An important component of the neural behavior in this system is mutual\ninhibition; neurons from one population (e.g., those voting for dots moving left) will proportionally\ninhibit neurons from the other population (voting for dots moving right).\nThis balanced mutual inhibition model also explains other collective decision-making processes,\nparticularly colonies of ants and bees that accumulate evidence and then make a collective decision\nthat all agents then follow. In a manner similar to neurons, honey bees make decisions as com-\npeting populations of evidence-accumulators. The theoretical framework suggested that in order\nto optimally trade oﬀspeed and accuracy in choosing a hive site, bees engaged in a waggle dance\nwould require a method of mutual inhibition. That “stop signal” was discovered empirically.\nThe talk then showed some shortcomings of “the wisdom of the crowd”.\nCondorcet’s Jury\nTheorem describes binary decisions in populations. The theorem states that under the assumption\nthat the opinions or individuals are independent and have equal positive decision accuracy, groups\nmake better decisions than individuals if individual accuracy is above one-half. Moreover, as group\n19\n\nsize increases, the accuracy of the decision approaches 1. Marshall shows that—in many if not most\nreal-world situations—these predictions are based on a false assumption that errors among agents\nare independent. Speciﬁcally, it fails to account for the tradeoﬀbetween false positives and false\nnegatives. He used as an example meerkats which collectively forage with sentinels that issue an\nalarm call when predators are present. False positives are less harmful than false negatives because\nfailure to detect a predator can be deadly while a false negative costs only a brief pause in foraging.\nMore generally, majority votes typically fail in two ways: ﬁrst, when the cost of false positives\nand false negatives are not equal, the majority vote does not converge to the optimal answer.\nAdditionally, in some cases, the accuracy of the group is lower than that of the average individual.\nMarshall showed that setting a quorum threshold (rather than simple majority vote) escapes the\nproblems introduced by the false positive/false negative trade-oﬀcurve so that the collective is at\nleast as good as the average individual. Marshall and colleagues extended this ﬁnding to explicitly\nstate the conditions under which quorums will perform better than majority voting and when\nmajority voting will perform worse than individuals.\nIn Marshall’s ﬁnal example, he considered the eﬀect of an unequal distribution of information\namong agents. Many natural systems, such as neurons and honey bees, make decisions with agents\nthat have incomplete and diﬀering access to accurate information. Marshall demonstrated decision-\nmaking capabilities of swarms of simple mobile robots. Small populations of randomly-moving and\ninformation-sharing Kilobots were able to collectively discover the ground truth about which home\nsite in their arena was best when robots were only allowed to communicate locally with other robots\nthey came into direct contact with. Additionally, they could accurately track changes in the ground\ntruth. However, the same robots given the same decision problems, but allowed to communicate\ninformation globally, were much less likely to reach an accurate decision. This is fundamentally\ndue to increasingly asymmetric interaction rates between diﬀerent types of agents as population\nsize increases.\nDiscussion:\nThe ﬁrst commenter asked how sensitive optimal policies (e.g., optimal quorum thresholds)\nwere to changes in context. Marshall was not sure, but argued that the kinds of policies chosen by\nevolution would, in addition other considerations, be optimized for robustness. The next commenter\nasked Marshall to say more about bees’ use of stop signals and the competitions among individuals\n20\n\nthat result in collective decisions. Marshall noted that his models had predicted that bees would\nuse some kind of behavior to encourage others to change their minds, but that the dynamics of this\nprocess were not as he initially expected. Marshall looked at cases where decisions were between\nequally good alternatives, hoping to see more protracted conﬂicts and more extensive use of the\nstop signal. However, in such cases, it is actually best to quickly identify the fact that the options\nare equally good and choose one at random. This led to reﬁned models of how bees arrives at\na consensus. The commenter followed up by asking what factors are relevant to predicting the\noptimal level of communication for a collective. Marshall noted that this was fairly easy in simple\ncases, but that matters were complicated by the fact that performance can fall oﬀquite rapidly\nwith relatively small increases in communication. The ﬁnal commenter asked whether the kinds of\ndynamics he studies would change when collectives comprise more sophisticated agents. Marshall\nnoted that pairs of humans can make better decisions when they communicate both their preferred\ndecision and their conﬁdence levels about it, suggesting that sophisticated agents could better\nleverage more complicated modes of communication.\n“Beyond Machines of Flesh and Blood: Toward New Paradigms for Human-\nCompatible Collective Intelligence”\nJacob Foster is an Associate Professor at the University of California Los Angeles.\nHis research focuses on social theory, computational social science, networks, complex\nsystems, and cognition and culture.\nJacob Foster outlined an ambitious proposal about how to re-frame the foundations of social theory\nin terms of collective intelligence. Foster argues that for many of the same reasons that AI engineers\nare seeking to create “human compatible” artiﬁcial intelligence (Russell, 2019), we should approach\nsocial theory as an exercise in creating human compatible collective intelligence. First, however,\nit is important to understand collective intelligence (and intelligence in general) before applying\nthese lessons to the particular kind of collective intelligence present in human societies. To this\nend, Foster and collaborators are seeking design principles that recur in collective intelligence, and\nhave begun to outline several of these principles.\nThe ﬁrst is that all intelligence is an emergent property of complex adaptive systems. Further,\nintelligent systems comprise diverse subsystems which (i) possess some degree of agency and in-\n21\n\ntelligence and (ii) are composed (and re-composed) to meet the demands of particular tasks. The\nactivity of these subsystems is coordinated by mechanisms which guide their collective behavior\ntoward adaptive outcomes. These mechanisms are engaged in a kind of “reverse game theory”\nwhereby they attempt (either in evolutionary or learning time) to construct circumstances wherein\nthe interaction of subsystems leads to maximally adaptive outcomes. The overall picture of intelli-\ngent systems, then, is one in which complex adaptive systems dynamically reallocate subsystems to\nmeet the demands of their circumstances. This means that particular conﬁgurations of subsystems\nmay be quite ephemeral. For example, the brain might recruit assemblies of neurons in order to\nsolve a particular problem, and never recruit the same assemblies in the exact same way again.\nIntelligence, on this view, is a kind of process rather than a static capacity.\nAs Foster argues, this suggests several plausible conjectures. For example, we should expect\nintelligent systems to have evolved in ways that make their subsystems composable. However, we\nshould also expect this compositionality of subsystems to have co-evolved with mechanism design,\nleading to important trade-oﬀs in the features of subsystems.\nFor example, there may be an\nimportant trade-oﬀbetween the price of anarchy and the repurposability of subsystems. The “price\nof anarchy” refers to the reduction in performance from not coordinating the activity of individual\nagents.4\nFor example, for every additional traﬃc sign that is posted, there will be a beneﬁt\nassociated with improved coordination of traﬃc (i.e., a reduction in the price of anarchy). The\ntrade-oﬀhere is with the cost of posting/maintaining traﬃc signs. Similarly, suppose an intelligent\nsystem’s subsystems have specialized via learning. The more competent those subsystems are the\nless costly it will be to coordinate their behavior within their domain of specialization. While this\nmakes it easier to reduce anarchy and its associated costs, it might also make the system less ﬂexible\nin adapting to novel circumstances. Hence, it may be worth paying (at least some of) the price of\nanarchy in order to secure this kind of ﬂexibility.\nHence, there are conﬂicting reasons to shape the individual subsystems to ﬁt a particular task\nand to promote diversity, generality, and ﬂexibility. As Foster argues, we should think carefully\nabout this trade-oﬀwhen designing social institutions. For ethical reasons, we should be hesitant to\ncreate institutions that re-shape individuals to achieve desirable outcomes, and we should be wary of\n4This concept originated in game theory, where it refers to diﬀerence between a worst case equilibrium and the\nmost socially desirable outcome (Koutsoupias & Papadimitriou, 2009).\n22\n\nhow existing social institutions (e.g., governments, social media, etc.) are already doing so. Instead,\nwe should ﬁnd ways of enhancing the capacity, diversity, and autonomy of individuals and engineer\nmechanisms for creating circumstances under which the interactions of these individuals result in\ndesirable outcomes. Human compatible collective intelligence, then, is collective intelligence that\nharnesses the autonomy and diversity of human beings to achieve desirable outcomes.\nDiscussion:\nThe discussion began by touching on two areas of Foster’s presentation—the idea that intelligent\nsystems are hierarchically composed of intelligent subsystems and that intelligent systems exhibit\n“cognition all the way down.” The commenter suggested that this form of “structure at all levels”\nmight be a middle ground between the kind of top-down, bottom-up dichotomy one might see in\nFoster’s presentation of the relevant policy alternatives. Foster largely agreed with the importance\nof this observation. Another commenter asked about what kinds of cases might demand a more\ntop-down approach. Foster replied that it would depend on the trade-oﬀs involved in each case,\nbut that in general he felt that too many of the costs of top-down approaches were hidden. For\nexample, suppose a social media company develops and implements a transparent and interpretable\ncontent recommendation algorithm. These selling points would not guarantee that the values judg-\nments made in the design and application of this algorithm (however transparent or interpretable)\nare actually good for the network or its members—much less when applied in a one-size-ﬁts all\nmethods to diverse individuals. Finally, others asked about the concept of human compatibility\nand whether Foster’s recommendations of bottom-up organization were needed correctives or an\nend in themselves. Foster argued that his primary concern is with developing a richer picture of\nhuman compatibility that reaches beyond human preferences to considerations of human capacity\nand human ﬂourishing. This perspective does not require that there be no top-down structure, but\nit does requires us to count any limitations it places on individual diversity and autonomy as a\nsigniﬁcant cost.\n“Applied Collective Intelligence to Combat Online Misinformation”\nJoe Bak-Coleman is a Postdoctoral Fellow at the University of Washington. His re-\nsearch focuses on how individual behavior gives rise to collective action and how this\nprocess is aﬀected by communication technology.\n23\n\nJoe Bak-Coleman surveyed some important factors contributing to online misinformation and\nthe strategies we might use to combat them.\nWhile complex systems are often thought of as\nadaptive and resilient to perturbations, this resilience is ﬁnite. For systems pushed beyond their\nbreaking point, failures can be catastrophic.\nFor example, during the record cold and snow in\nearly 2021, the Texas power grid collapsed under the unprecedented strain. The same holds for\nsystems that exhibit collective intelligence. For example, if the pheromone trails left by ants form\na loop, the ants can follow that loop in circles endlessly, leading in some cases to starvation. As\nBak-Coleman argues, the success of these complex systems is context dependent and large changes\nin context can lead to failure.\nHuman communication evolved in the context of small hunter-gatherer groups to solve local\nproblems using vocalization and gesture. As communication technologies improved, human beings\ncould communicate with greater ﬁdelity, but the ability to use mass communication to trans-\nmit one’s ideas to a wide audience (e.g., via broadcast television) remained inaccessible to most\nhumans—blocked by costs and gatekeeping mechanisms. This was still a radical departure from\nour environment of evolutionary adaptedness, but the full eﬀect of the changes was blunted by such\nbarriers. The internet allowed even greater ﬁdelity of transmission and even larger audiences, but\nit also rapidly dismantled the gatekeeping mechanisms that reduced the viral spread of misinfor-\nmation. Worse, these changes were accompanied by algorithms that tended to promote content in\nways that unintentionally encouraged the spread of misinformation, reinforced extremism, etc.\nGiven the consequences of misinformation and the questionable ability of human social networks\nto adapt to this shock, Bak-Coleman argues that we should seriously consider implementing some\nset of interventions to mitigate the spread of misinformation. He considers several strategies for\ndoing so: removing misleading content, slowing misleading content, banning the biggest spreaders\nof misleading content, and adding “nudges” to misleading content that warn users and direct them\nto authoritative information. Unfortunately, a clear picture of whether and how well these methods\nwork is still emerging. As Bak-Coleman describes, all of these methods (if pursued individually)\nwould likely require draconian levels of enforcement or unrealistic level of eﬀectiveness in order to\nwork as desired. Fortunately, a multi-strategy approach which combines a moderate amount of\neach strategy looks considerably more promising.\nDiscussion:\n24\n\nThe discussion began with a question about whether the attitudes, motives, etc. that drive\nthe spread of misinformation might be harnessed by the right sort of institutions. For example, in\na context where private property is protected, the drive to acquire wealth can be channelled into\nproductive activity that (however imperfectly) beneﬁts society at large. Bak-Coleman agreed that\ngetting the right incentives (e.g., reducing the proﬁtability of spreading misinformation) and the\nright network structure (e.g., encouraging local interactions where oﬄine relationships hold people\naccountable) could substantially help matters. Another commenter worried that the problem of\nmisinformation was, perhaps, more a problem of super-spreaders with huge audiences than ordinary\npeople on social networks. On this view, the problem is less about a truly collective eﬀect and really\na problem of a few bad actors within a social network. Bak-Coleman agreed to some extent, but\nnoted that the algorithms are designed to promote “engagement” and that this is assessed at\nthe level of individuals. Hence, the emergence of highly inﬂuential accounts is not unrelated to the\nactivity of individuals. Another commenter wondered whether the discussion was focusing too much\non technical problems to the exclusion of deeper political and social ones (e.g., voter suppression).\nBak-Coleman acknowledged the importance of these issues, but also noted that these are areas\nwhere real design decisions are being made by social media companies, and there is considerable\nvalue in ensuring that they make the right decisions.\nGeneral Discussion:\nTyler Millhouse began by outlining a few themes of the workshop as a whole and of the day’s\ntalks in particular. He ﬁrst noted several diﬀerent concepts that had been mentioned during the\nworkshop, including collective information sharing and aggregation, collective computing, collective\ndecision making, collective problem solving, etc. These all seem relevant to collective intelligence—\nas perspectives on what intelligent collectives are doing and as subjects of study in their own\nright. Millhouse asked to what extent these could be individually investigated and how participants\nthought they might need to be integrated into a general account of collective intelligence. Millhouse\nnext asked when collectives should be counted as intelligent and whether “intelligence” in this\nsense diﬀered from the sense in which it is attributed to individuals. These questions, of course,\nare complicated by the possibility of forms of collective intelligence that exist within individual\norganisms (e.g., between cortical columns). Finally, Millhouse asked about the connections between\n25\n\ncollective intelligence as discussed in the workshop and the kind of temporally-extended collective\nintelligence exhibited by evolving populations (discussed in the previous workshop).\nMillhouse, next advanced particular points of discussion for each of the talks.\nFor James\nMarshall’s talk, it seemed that a key point was how ﬁner or coarser grained analyses of success\ncould shape what we take to be the optimal organization for a group. For Jacob Foster’s talk, the\nhighlight was a substantive notion of intelligence applicable to collectives and the introduction of\nricher notions of success in navigating AI risk. Finally, for Joseph Bak-Coleman’s talk, the idea\nof mechanisms of accountability and the value of keeping interactions local stood out as possible\nstarting points for discussion.\nThe ﬁrst commenter noted that in human society (at least), overlapping collectives can inter-\nregulate. For example, if people are members of diﬀerent political parties but attend the same\nchurch, there will be increased social costs to disagreeing too acrimoniously about politics. The\ncommenter noted that for online social media, many of the regulatory diﬃculties we observe might\narise because divisions on these platforms are aligning with divisions oﬄine, resulting in little\ncommon ground and, hence, little shared interest in ﬁnding ways to constrain the worst excesses of\nonline disagreements.\nThe next commenter added some nuance to the notion of misinformation by suggesting that we\nshould be more concerned about whether public opinion is well-calibrated or not. There will always\nbe people whose guesses about the weight of the steer at the county fair are wildly oﬀ, but this is\nconsistent with the median guess being quite reliable. This is importantly diﬀerent from a system\nin which people in aggregate are consistently oﬀthe mark. For example, if online interactions are\ndriving political polarization, most individuals may be driven to extreme positions rather than\nconverging to some better calibrated moderate position.\nAnother commenter noted that much of the recent distrust of experts and expertise may result\nfrom the fact that scientiﬁc ﬁndings and the demands of policy-making interact in unproductive\nways. For example, it might occasionally be important to rapidly address some emergent situation\n(e.g., a pandemic). Not all the measures will be eﬀective or (in the ﬁnal analysis) advisable, but\nthe need to implement our best guess about the right response could lead scientists to oversell\ntheir certainty in the eﬀectiveness of any particular intervention. Another commenter added that\ncertainty is also a powerful rhetorical technique over and above any particular emergency. In any\n26\n\ncase, the primary worry was that when some of these conﬁdent recommendations are reversed,\ntrust in science is eroded.\nThat said, it remains unclear whether better presenting the reality of scientiﬁc uncertainty\nwould fully resolve the diﬃcult decisions we have to make as a society. Even where the science\nis in fact clear, there are deep disagreements about core values. Each individual has, during the\nCOVID pandemic, struck some balance between the risks of certain behaviors to themselves and\nothers and the beneﬁts they will have to forego to avoid these risks.\nMost would agree that\nshutting down the economy to save a single individual would not be worth the cost, and few would\ndisagree that shutting down the economy to save all but one individual would be worth the costs.\nSomewhere between these extremes, real disagreements about what is most valuable will come into\nplay. Nevertheless, there may be better or worse ways of navigating these disagreements, and (as\none commenter suggested) many strategies for productive disagreement have been proposed and\ntried by members of the “rationality movement” which seeks to shape individual reasoning and\nintellectual discourse in order to avoid cognitive biases and fallacious reasoning.\nConclusion\nWhile the workshop brought together researchers from a diverse range of ﬁelds, several key\nthemes and open questions emerged from the talks and discussions. Overall, the workshop rein-\nforced the idea that understanding collective intelligence is a key part of understanding intelligence\nin general. The speakers not only showed that collective intelligence is a plausible approach to\nsolving problems in AI and human communities, but also that collective problem-solving is a com-\nmon and highly successful feature of biological systems. That said, the interdisciplinary nature\nof the workshop also revealed the diversity of perspectives at play in the study of collective in-\ntelligence, ranging from diﬀerences in terminology to diﬀerences in subject matter and research\nmethods. Incorporating these diverse perspectives into a more uniﬁed framework will both advance\nour understanding of collective intelligence and facilitate interdisciplinary research on the subject.\n27\n\nOptimization and Collectivity\nOne of the principal themes of the workshop was that collective phenomena can arise in systems\nthat exhibit collectivity at diﬀerent levels of organization and whose components exhibit diﬀerent\ndegrees of optimization for those phenomena. For example, the talks illustrated that phenomenon\nof collective intelligence can emerge from the interactions of many individual agents (as in an\ninsect colony) and from the interactions of components within a larger cognitive system (as in the\ncortical columns of mammalian brains). The organization of these components and the components\nthemselves can also exhibit diﬀerent degrees of complexity. In many contexts, emergent phenomena\nin complex systems are characterized as emerging from the interactions of many simple components.\nWhile this kind of emergence is striking, Jessica Flack emphasized the complexity of individuals in\ncollectively intelligent systems. Humans, animals, and even individual cells are quite complex, and\nthey are often organized in non-trivial ways, with network structure playing an important roles (as\nemphasized by Coty Gonzalez).\nFurther, the components contributing to collective intelligence and other collective phenomena\ncan be optimized to diﬀerent degrees for the production of those phenomena. For example, there are\na number of interesting phenomena that emerge from interactions between humans and interactions\nbetween ants, but it seems clear that the individual behaviors of ants are more ﬁnely-tuned by\nnatural selection for the production of those phenomena than are the behaviors of humans. This\nproved to be a point of disagreement in the methodology of diﬀerent disciplines, with insect biologist\nAnna Dornhaus emphasizing the fact of natural selection acting on groups in the case of social insect\ncolonies. In contrast, some working in the social sciences were more interested in how (and how well)\nindividual behaviors produce some collective outcome than in whether those behaviors were selected\nfor those outcomes. Of course, as both Dornhaus and Jacob Foster noted, selection for speciﬁc\nindividual behaviors does not necessarily imply specialization, and the balance of generalists and\nspecialists is itself something that can be evolved or designed to meet particular goals. Considering\nall these perspectives, it seems fair to say that the question of whether and how the components\nof a collective intelligence have been shaped by selection is a substantive one that has important\nimplications for the analysis and function of collective intelligence. For this reason, the ﬁeld would\n28\n\nlikely beneﬁt from a more systematic framework for understanding the role of selection in designing\ncollective intelligences.\nThe Beneﬁts (and Costs) of Communication\nAnother major theme was the importance of tuning communication between the components\nof collective intelligences. For example, in the context of insect colonies, Anna Dornhaus explained\nthe importance of communication in spreading information about food sources among foragers.\nThe value of this information, however, must be balanced against the costs to waiting at the colony\nfor information rather than going out searching for food. Similarly, James Marshall noted cases\nin which local communication is beneﬁcial, but global communication is detrimental to foraging\nbehavior. In a much diﬀerent context, Joe Bak-Coleman noted that misinformation on Twitter\nis disproportionately spread by a relatively small group of serial oﬀenders with large followings,\nsuggesting that one vector for improving the quality of information on the internet would be to\ntarget the relatively small number of worst oﬀenders. Hence, while important, communication must\nbe ﬁnely tuned, both with respect to the amount of communication that occurs and the structure\nof communicative interactions.\nInstitutions, Norms, and Mechanisms\nAnother key idea from the workshop was the importance of mechanisms, broadly construed,\nwhich coordinate the activity of the components of collective intelligence.\nAs Jacob Foster de-\nscribed, mechanism design amounts to a kind of reverse game theory where the conditions of\ninteractions are engineered to produce desirable outcomes. In the context of cognitive systems,\nthese mechanisms are responsible (among other things) for the strategic re-allocation of cognitive\nresources. In the context of insect colonies, these mechanisms involve diﬀerent modes of communi-\ncation and diﬀerent processes for dividing labor among colony-members. In the context of the wider\ndiscussion about political systems and social networks, these mechanisms involve institutions, rules,\nnorms, and shared beliefs. In each case, modifying these mechanisms can make a big diﬀerence to\nthe collective outcomes produced.\n29\n\nLessons for Artiﬁcial Intelligence\nEach of the workshop’s major themes suggests an avenue of research for scientists developing\ncollective artiﬁcial intelligence.\nThe ﬁrst suggests approaching the design of individuals, com-\nponents, and subsystems as a kind of optimization problem—perhaps one to which evolutionary\nalgorithms or other methods might be applied. The second recommends careful attention to chan-\nnels of communication and cautions against the idea that unrestricted communication is desirable.\nThe last suggests greater attention to the factors that structure interactions, and it recommends\ncloser attention to the normative judgments that guide mechanism design. Taken together, these\nthemes highlight the expansive possibilities and promising frontiers for future research on collective\nintelligence.\n30\n\nAcknowledgments\nThe workshop was funded by a grant from the National Science Foundation (#2020103) as\npart of the Foundations of Intelligence in Natural and Artiﬁcial Systems project at the Santa Fe\nInstitute.\nReferences\nFerguson, A. (1782). An essay on the history of civil society. London: Caddell, Creech, & Bell.\nGell-Mann, M. (1994). Complex adaptive systems. In H. Morowitz and J.L. Singer (eds.) The\nmind, the brain, and complex adaptive systems. New York: Routlegde.\nKoutsoupias, E. and Papadimitriou, C. (2009). Worst-case equilibria. Computer science review,\n3(2). 65-69.\nLevin, M. and Dennett, D. (2020). Cognition all the way down. Aeon.\nhttps://aeon.co/essays/how-to-understand-cells-tissues-and-organisms-as-agents-with-agendas.\nQuinn, M. H., Conser, E., Witte, J. M., and Mitchell, M. (2018). Semantic image retrieval via\nactive grounding of visual situations . In Proceedings of the 12th International Conference on\nSemantic Computing. IEEE.\nRussell, S. (2019). Human compatible. New York: Viking.\n31",
    "pdf_filename": "Frontiers in Collective Intelligence - A Workshop Report.pdf"
}