{
    "title": "AI Guided Early Screening of Cervical Cancer",
    "abstract": "In order to support the creation of reliable machine learning models for anomaly detection, this project focuses on preprocessing, enhancing, and organizing a medical imaging dataset. There are two classifications in the dataset: normal and abnormal, along with extra noise fluctuations. In order to improve the photographs' quality, undesirable artifacts, including visible medical equipment at the edges, were eliminated using central cropping. Adjusting the brightness and contrast was one of the additional preprocessing processes. Normalization was then performed to normalize the data. To make classification jobs easier, the dataset was methodically handled by combining several image subsets into two primary categories: normal and pathological. To provide a strong training set that adapts well to real-world situations, sophisticated picture preprocessing techniques were used, such as contrast enhancement and real-time augmentation (including rotations, zooms, and brightness modifications). To guarantee efficient model evaluation, the data was subsequently divided into training and testing subsets. In order to create precise and effective machine learning models for medical anomaly detection, high-quality input data is ensured via this thorough approach. Because of the project pipeline's flexible and scalable design, it can be easily integrated with bigger clinical decision-support systems.",
    "body": "1 \nAI Guided Early Screening of Cervical Cancer \nDharanidharan S I, Suhitha Renuka S V, Ajishi Singh, Sheena Christabel Pravin*  \nSchool of Electronics Engineering, \nVellore Institute of Technology, Chennai. \n*sheenachristabel.p@vit.ac.in \n \nAbstract \n \nIn order to support the creation of reliable machine learning models for anomaly detection, this \nproject focuses on preprocessing, enhancing, and organizing a medical imaging dataset. There are \ntwo classifications in the dataset: normal and abnormal, along with extra noise fluctuations. In \norder to improve the photographs' quality, undesirable artifacts, including visible medical \nequipment at the edges, were eliminated using central cropping. Adjusting the brightness and \ncontrast was one of the additional preprocessing processes. Normalization was then performed to \nnormalize the data. To make classification jobs easier, the dataset was methodically handled by \ncombining several image subsets into two primary categories: normal and pathological. To provide \na strong training set that adapts well to real-world situations, sophisticated picture preprocessing \ntechniques were used, such as contrast enhancement and real-time augmentation (including \nrotations, zooms, and brightness modifications). To guarantee efficient model evaluation, the data \nwas subsequently divided into training and testing subsets. In order to create precise and effective \nmachine learning models for medical anomaly detection, high-quality input data is ensured via this \nthorough approach. Because of the project pipeline's flexible and scalable design, it can be easily \nintegrated with bigger clinical decision-support systems. \n \n1. Introduction \n \nRecent developments in artificial intelligence and machine learning have revolutionized medical \nimaging, allowing for more precise and effective illness diagnosis. The caliber and structure of the \ndata utilized to train these models provide the basis of these technological developments. Data \nimbalance, noise, and imaging condition variability are some of the distinctive difficulties that \nmedical imaging datasets, especially those utilized for anomaly identification, frequently face. To \novercome these obstacles and guarantee the creation of reliable machine learning models, the data \nmust be carefully preprocessed, augmented, and organized. \n \nImages in medical imaging datasets are usually classified into classes like normal and abnormal, \nwith variances resulting from environmental noise, patient-specific factors, and imaging \nequipment. Effective preprocessing of these datasets is crucial for guaranteeing the precision and \ndependability of machine learning models. Noise reduction, cropping to eliminate superfluous \nregions, normalization to uniformize pixel intensities, and augmentation to artificially boost the \ntraining data's diversity are all examples of preprocessing techniques. By taking these actions, the \ndata quality is improved and the models' capacity to generalize to new, untested data is increased. \n\n2 \n \nIn order to remove unwanted background details or medical instruments from medical photos, \ncentral cropping is one of the crucial preprocessing techniques used in this research. The danger \nof adding artifacts to the training data is reduced by concentrating on the image's center, which \nusually contains the area of interest. Normalization standardizes the pixel intensity values to a \nconstant range, which facilitates the interpretation of the data by machine learning models. Other \npreprocessing procedures, such as brightness and contrast modifications, provide consistency \nthroughout the dataset. \n \nThe inherent drawbacks of medical datasets, such small sample numbers and class imbalances are \ngreatly mitigated by data augmentation. Rotations, zooming, flipping, brightness modifications, \nand other augmentation techniques create a more complete training dataset by simulating a variety \nof imaging circumstances. This procedure improves the machine learning model's robustness and \nreduces overfitting, allowing it to function well in a range of real-world scenarios. This project's \nmain goal is to create a high-quality dataset that will act as the foundation for machine learning \nalgorithms that can identify abnormalities in medical images. This effort guarantees the scalability \nand dependability of these models in clinical contexts by utilizing sophisticated preprocessing and \naugmentation procedures. The ultimate goal of this project's output is to enhance patient outcomes \nby enabling the early diagnosis of anomalies and adding to the expanding corpus of work in \nmedical imaging and machine learning. \n      2.Related Work \nGomes et al. in This study emphasizes the revolutionary possibilities of combining machine \nlearning (ML) and deep learning (DL) approaches for the identification and categorization of \ncervical cancer. With the help of Simple Logistic classifiers and pre-trained models like \nResNet152, the study attains an impressive 98.08% accuracy rate. In order to highlight the \nsignificance of sophisticated computational tools in boosting medical diagnoses, I can include this \nin my paper along with the benefits of hybrid DL-ML techniques for increasing diagnostic \nprecision. \n \nVargas-Cardona et al. in This study explores the application of artificial intelligence (AI) to early \ncervical cancer detection using imaging. It looks closely at the diagnosis accuracy of a number of \nAI algorithms that are used to analyze images from digital colposcopy, cervicography, and mobile \ndevices. Among the thirty-two publications published between 2009 and 2022, support vector \nmachines (SVM) and deep learning algorithms (e.g., CNN, ResNet, VGG) were the most utilized \nAI techniques. With accuracies over 97%, these AI approaches demonstrated exceptional \ndiagnostic performance. Although more research is needed to validate these positive findings, the \nstudy highlights the growing use of AI in cervical cancer screening.  \n \n\n3 \nThis study by Jue Wang et al. (2024) introduces the AI-based cervical cancer screening system \n(AICCS), which evaluates cervical cytology images to enhance early detection. The method \nemploys AI models to detect abnormal cells at the patch level and categorizes entire slides into \nvarious cytology groups. It performed exceptionally well on a range of datasets, including \nprospective and randomized trials, with an AUC of 0.947, a sensitivity of 94.6%, and a specificity \nof 89.0%.  \n \nWei Wang et al.'s (2022) study used a targeted literature review (TLR) and a systematic literature \nreview (SLR) to examine cervical cancer screening methods and guidelines in 11 different \ncountries, including the US, Canada, and several European and Asia-Pacific countries. The authors \nexamined peer-reviewed papers and policy documents from January 2005 to January 2021 using \ndatabases like Embase, Medline, and Cochrane as well as gray literature from websites of \ngovernment and health authorities. The study focused on nations having established screening \nsystems, pilot programs, and easily accessible data on screening practices, all of which met the \nPICOS criteria for relevance. Except for Japan, where only English-language documents were \ntaken into consideration, the materials were evaluated by a multinational team of reviewers. This \nstudy aimed to provide a comprehensive understanding of global cervical cancer screening \nguidelines and practices to enhance prevention strategies. \n \n In order to evaluate the application of artificial intelligence (AI)-based algorithms for diagnosing \ncervical cancer from visual inspection with acetic acid (VIA) images, Roser Viñals et al. (2023) \ndid a systematic literature review (SLR). The review, which was conducted using databases like \nPubMed, Google Scholar, and Scopus, concentrated on articles released between January 2015 \nand July 2022. Using histopathology as the gold standard for diagnosis, the studies that evaluated \nAI algorithms for differentiating between positive (CIN2+) and negative (normal or benign) \ncervical lesions were chosen for inclusion. Eleven chosen papers were thoroughly examined by \nthe authors, who looked at variables like algorithm types, acquisition tools, dataset properties, and \nperformance metrics like specificity, sensitivity, and accuracy.  \n \nTo evaluate the application of artificial intelligence (AI)-based algorithms for diagnosing cervical \ncancer from visual inspection with acetic acid (VIA) images, Roser Viñals et al. (2023) did a \nsystematic literature review (SLR). The review, which was conducted using databases like \nPubMed, Google Scholar, and Scopus, concentrated on articles released between January 2015 \nand July 2022. Using histopathology as the gold standard for diagnosis, the studies that evaluated \nAI algorithms for differentiating between positive (CIN2+) and negative (normal or benign) \ncervical lesions were chosen for inclusion. Eleven chosen papers were thoroughly examined by \nthe authors, who looked at variables like algorithm types, acquisition tools, dataset properties, and \nperformance metrics like specificity, sensitivity, and accuracy. Using the QUADAS-2 technique, \nthey also conducted a quality evaluation to determine study applicability and bias risk. A \n\n4 \nqualitative comparison of the preprocessing methods and dataset characteristics employed in the \ninvestigations was presented by the research. \n \nUsing pap smear images from the SIPaKMeD dataset, which contains both normal and abnormal \ncell types, Sandeep Kumar Mathivanan et al. (2024) present an automated method for cervical \ncancer identification. The dataset undergoes further classification within the normal class after \nbeing converted into a two-class system (normal and aberrant). To extract features from pap smear \nimages, the authors use pre-trained deep learning models including AlexNet, ResNet-101, ResNet-\n152, and InceptionV3. Various machine learning classifiers (Logistic Regression, Decision Trees, \nRandom Forest, and Naive Bayes) are then trained using these attributes to classify images. The \nstudy intends to increase cervical cancer screening's precision and effectiveness by fusing deep \nlearning and machine learning approaches, which will enhance patient outcomes and early \ndiagnosis. \n5.Proposed Framework \nThe primary objective of this project is to develop a deep learning-based framework for the \nearly screening of cervical cancer using colposcopy images. The system aims to classify cervical \nimages into two categories: \n• Normal \n• Abnormal \nThe model is designed to be useful in medical camps and regions with limited access to healthcare \nprofessionals, particularly in rural areas. This approach can provide affordable, reliable, and \nquick screening solutions to aid in the early detection of cervical cancer. \n5.1 Dataset Preparation \nThe dataset for this project consists of cervical images categorized into four folders: \n• Normal: Healthy cervix images. \n• Abnormal: Images with signs of abnormalities. \n• NormalNoise: Healthy cervix images with noise. \n• AbnormalNoise: Abnormal cervix images with noise. \nWe carefully segregated clean and noisy images to address the noise-specific challenges \neffectively. The dataset was then merged into two classes: \n• Normal: 45 images (17 clean, 28 noisy). \n• Abnormal: 145 images (85 clean, 60 noisy). \n\n5 \nThis segmentation allows the model to be robust in handling noisy data while maintaining \nperformance in detecting abnormal cases. \n5.2 Data Preprocessing \n5.2.1 Artifact Removal for Noisy Images \nThe noisy images underwent several preprocessing steps to reduce the impact of noise and \nartifacts: \n• CLAHE (Contrast Limited Adaptive Histogram Equalization): Applied to enhance the \ncontrast of the images, making important features more distinguishable. \n• Median Blurring: Used to reduce noise while preserving the edges of the cervical \nstructures. \n• Morphological Operations: Applied for removing any remaining small artifacts and to \nclean up the images. \n• Edge Detection: Techniques such as Canny edge detection were used to eliminate \nartifacts caused by the colposcopy instrument or other irrelevant features. \n5.2.2 Augmentation Pipelines \nData augmentation was critical to prevent overfitting, especially since the dataset was small and \nimbalanced: \n• Random Brightness/Contrast Adjustments: To simulate varying lighting conditions. \n• Gamma Corrections: Applied to adjust the exposure and contrast. \n• Gaussian Noise Addition: Added to simulate noise in the data and help the model \ngeneralize better. \n• Random Rotations, Flips, and Distortions: These were applied to increase variability \nand robustness of the model. \n5.2.3 Normalization and Splitting \n• Image Resizing: All images were resized to 224x224 pixels to standardize the input size \nfor the neural network. \n• Normalization: Pixel values were scaled to a range of [0, 1] for improved convergence \nduring training. \n• Stratified Splitting: The dataset was split into training and validation sets using an 80%-\n20% split to ensure balanced class distribution across both sets. \n\n6 \n5.3 Model Architecture \nThe MobileNetV2 architecture was chosen for its balance of efficiency and performance, making \nit ideal for this classification task, particularly in resource-constrained environments like medical \ncamps. \n• Pre-trained MobileNetV2: The model was initialized with pre-trained weights on the \nImageNet dataset. The top layers of the model were removed to use it as a feature \nextractor. \n• Global Average Pooling (GAP): Used after the convolutional layers to reduce the \ndimensionality of the feature maps, helping the model generalize better. \n• Dense Layers: One or more fully connected layers with ReLU activation were used for \nclassification. \n• Softmax Output Layer: The final layer of the model had a softmax activation function \nto output the probabilities for the two classes (normal and abnormal). \n \n5.4 Training and Fine-Tuning \n5.4.1 Initial Training \n• The model was initially trained with a learning rate of 10^-4 using the Adam optimizer \nand categorical cross-entropy loss function. This setup helped achieve a baseline \nperformance. \n5.4.2 Fine-Tuning \n• After the initial training, the last 20 layers of the MobileNetV2 model were unfrozen for \nfine-tuning. This allowed the model to adapt pre-trained weights to the cervical cancer \ndataset more effectively. \n• Fine-tuning was performed using a lower learning rate of 10^-5 to ensure stable training \nand prevent overfitting. \n5.4.3 Hyperparameter Tuning: \n• Batch size and learning rate were optimized using trial and error. \n• ReduceLROnPlateau: A dynamic learning rate scheduler was employed to reduce the \nlearning rate if the validation accuracy plateaued, helping the model converge more \neffectively. \n\n7 \n5.5 Evaluation \nThe model's performance was evaluated using the following metrics: \n• Accuracy: The overall accuracy on the validation set was 67%. This metric indicates the \npercentage of correct predictions across both classes. \n• Precision, Recall, F1-Score: These metrics were particularly useful due to the class \nimbalance in the dataset. The F1-score balanced the tradeoff between precision and recall. \n• Confusion Matrix: The confusion matrix visually assessed the model’s ability to classify \nimages correctly and identify misclassifications. \n5.6 Challenges \n• Class Imbalance: The dataset was imbalanced, with more abnormal images than normal \nimages. This posed a challenge in ensuring the model didn’t bias towards the abnormal \nclass. \n• Dataset Noise: Despite preprocessing, noisy images still affected the model’s \nperformance, especially in the abnormal category. \nThis framework demonstrates the viability of using deep learning for cervical cancer \nclassification based on colposcopy images. Initial results indicate that while the model performs \nwell, especially in handling noisy images, improvements are needed in terms of: \n• Expanding the dataset size to improve generalization. \n• Refining preprocessing techniques to better handle noise. \n• Experimenting with alternative architectures for enhanced performance \n \n6. Results and Discussion \nThe aim of this project is to create an AI-driven system for the early detection of cervical cancer \nusing colposcopy images. Cervical cancer is preventable and treatable when detected early, yet its \ndiagnosis often depends on clinicians interpreting colposcopy images, a process that can be prone \nto errors and delays. This project strives to automate the classification of colposcopy images into \ntwo categories: normal (healthy cervix) and abnormal (potential signs of cervical cancer). To \nachieve this, the system employs deep learning techniques, specifically MobileNetV2 with transfer \nlearning, to ensure high diagnostic accuracy. Various preprocessing techniques, such as central \ncropping, brightness and contrast adjustments, and normalization, are applied to handle noisy \nimages and focus on the cervix area. Data augmentation is utilized to enhance the model’s ability \nto generalize, especially given the limited size of the dataset. The model’s performance is assessed \nusing metrics such as accuracy, precision, recall, and F1-score to verify its reliability. By \nincorporating this AI solution into clinical workflows, the project aims to assist healthcare \n\n8 \nprofessionals in making accurate and timely diagnoses, reducing reliance on manual interpretation. \nThis system has the potential to enhance early detection, particularly in settings with limited \nresources, and contribute to improving patient outcomes, thereby supporting global efforts to \ndecrease cervical cancer mortality rates. \n \n \n6.1 Qualitative Analysis \nThe qualitative analysis focuses on visually assessing the model’s capacity to differentiate between \nnormal and abnormal cervical regions based on colposcopy images. During preprocessing, images \nfrom noisy datasets (normal noise and abnormal noise) underwent central cropping and \nbrightness/contrast adjustments to improve the focus on the cervix. These enhancements ensure \nthe model focuses on the relevant regions of interest, which could potentially improve \nclassification accuracy. The qualitative analysis indicates that central cropping effectively removes \nirrelevant elements, such as medical instruments at the borders, while contrast adjustments help \nemphasize crucial features in the cervix region. \n6.2 Quantitative Analysis \nQuantitative analysis evaluates the model’s performance using various metrics and statistical \nmethods. \n6.2.1 Training and Validation Accuracy and Loss \nThroughout the training process, the model’s performance was tracked by monitoring accuracy \nand loss over several epochs. The results revealed a steady increase in training accuracy and a \ndecrease in loss, showing the model’s learning effectiveness. Additionally, the validation accuracy \npeaked at 87.5% after fine-tuning the model. Figures 4.1 and 4.2 illustrate the progression of \ntraining accuracy and loss over the epochs, demonstrating the model's ability to generalize well on \nunseen data. \n\n9 \n \nFigure 6.1 Training and Validation Accuracy over Epochs \n \nFigure 6.2 Training and Validation Loss over Epochs \n6.2.2 Performance Metrics \nThe model’s classification performance was evaluated using the following metrics: \n• Accuracy: Indicates the overall correctness of the model. \n• Precision: Measures the proportion of true positives among all positive predictions. \n• Recall (Sensitivity): Reflects the model's ability to correctly identify positive cases. \n\n10 \n• F1-Score: Provides a balanced evaluation of precision and recall, accounting for false \npositives and false negatives. \nThe performance metrics for the model are as follows: \nMetric \nNormal \nAbnormal \nOverall (Weighted Avg) \nPrecision \n0.40 \n0.95 \n0.82 \nRecall \n0.89 \n0.60 \n0.67 \nF1-Score \n0.55 \n0.73 \n0.69 \nSupport \n9 \n30 \n39 \n \n \n \n6.2.3 Confusion Matrix Analysis \nThe confusion matrix provides a detailed breakdown of the model’s classification performance. It \nillustrates the number of correct and incorrect predictions for each class, giving insight into the \nmodel’s strengths and weaknesses. From the matrix: \n• True Positives (Abnormal): 18 abnormal cases were correctly identified. \n• True Negatives (Normal): 8 normal cases were correctly classified. \n• False Positives (Normal misclassified as Abnormal): 1 case was mistakenly classified as \nabnormal. \n• False Negatives (Abnormal misclassified as Normal): 12 abnormal cases were wrongly \nclassified as normal. \nThe matrix indicates that the model performs better at identifying abnormal cases, as evidenced \nby the higher true positive count. However, the model struggles with false negatives, which could \nresult in missed detection of abnormal cases—an issue that is critical in medical diagnostics. The \npresence of false positives suggests that some normal cases are incorrectly flagged as abnormal, \nwhich could lead to unnecessary additional tests or treatments. This analysis highlights the \nimportance of optimizing recall for abnormal cases to minimize false negatives and improving \nprecision for normal cases to reduce false positives, enhancing the model’s overall reliability in \nreal-world clinical settings. \n\n11 \n \nFigure 6.3 Confusion Matrix of the Model’s Classification \n6.2.4 Results of Random Samples \nFigure 6.4 presents results from five random images, highlighting the model’s performance across \na diverse set of test images. \n     \nFigure 6.4 Results of random 5 pictures. \n6.2.5 Comparison with Traditional Methods \nWhen compared to manual analysis, the proposed AI-based system offers significant advantages \nin terms of speed and consistency. By automating the classification process, the system reduces \nthe time required for diagnosis while maintaining high accuracy, making it a valuable tool for \nmedical professionals. \n6.3 Comparative Analysis of Models \nFour deep learning models—ResNet50, EfficientNetB0, DenseNet121, and MobileNetV2—were \ntrained and assessed for cervical cancer image classification into normal and abnormal categories. \n\n12 \nThese models were evaluated using metrics like accuracy, precision, recall, and F1-score. Here is \na summary of the models' performance: \n• ResNet50: Achieved an accuracy of 78.95%. However, it performed poorly with abnormal \ncases, resulting in an F1-score of 0 for the Abnormal class. It overemphasized the Normal \nclass, accurately classifying all normal instances but failing to identify any abnormal cases. \n• EfficientNetB0: Also achieved 78.95% accuracy. While it classified the Normal class well, \nit was ineffective at detecting abnormal cases, yielding an F1-score of 0 for the Abnormal \nclass. \n• DenseNet121: Outperformed the previous models with an accuracy of 84.21%. It achieved \na precision of 60% and recall of 38% for the Abnormal class, resulting in an F1-score of \n46%. This model showed a better balance between the two classes, making it more suitable \nfor handling imbalanced datasets. \n• MobileNetV2: This model achieved an accuracy of 73.68% and classified the Normal class \nfairly well, but struggled with the Abnormal class. Its overall performance was comparable \nto ResNet50 and EfficientNetB0, but slightly lower than DenseNet121. \n6.3.1 Key Observations \n1. Models trained on imbalanced datasets, such as ResNet50 and EfficientNetB0, showed a \nstrong bias towards the majority class, performing poorly with the minority class. \n2. DenseNet121 provided the best balance between accuracy and class distribution, \nsuggesting it may be better suited for tasks with imbalanced datasets. \n3. Future improvements could focus on techniques like data augmentation, oversampling \nminority classes, or adjusting loss functions to address class imbalance. \n6.3.2 Comparison Table \nHere is a table summarizing the performance of the models: \nModel \nAccura\ncy \nPrecision \n(Abnormal) \nRecall \n(Abnormal) \nF1-Score \n(Abnormal) \nResNet50 \n78.95% 0.00 \n0.00 \n0.00 \nEfficientNet\nB0 \n78.95% 0.00 \n0.00 \n0.00 \nDenseNet12\n1 \n84.21% 60.00% \n38.00% \n46.00% \nMobileNetV\n2 \n78.95% 50.00% \n25.00% \n33.00% \n6.4 Discussions \n\n13 \n6.4.1 Generalization: Imbalanced Dataset \nA major challenge in this project is the imbalance in the dataset, with abnormal cases significantly \noutnumbering normal cases. This imbalance can lead to a biased model that favors predicting \nabnormal cases, which reduces sensitivity to normal cases. In real-world clinical scenarios, this \ncould result in false positives, leading to unnecessary anxiety, or false negatives, causing delays in \ndetecting critical conditions. To mitigate this issue, techniques such as data augmentation, class \nweighting, and synthetic data generation were used to enhance the model’s ability to generalize \neffectively across both classes, ensuring a robust diagnostic tool. \n6.4.2 Data Privacy Concerns \nMedical data, including colposcopy images and patient records, is highly sensitive and subject to \nstrict privacy regulations, such as GDPR and HIPAA. Protecting this data while training AI models \npresents a complex challenge. This project explored approaches like data anonymization and \nsecure handling protocols to comply with privacy regulations. Future efforts could incorporate \ntechniques such as federated learning or secure multi-party computation to further enhance data \nsecurity while enabling the use of diverse datasets. Addressing privacy concerns is essential for \nbuilding trust and ensuring ethical AI deployment in clinical settings. \n6.4.3 Impact on Cervical Screening in Rural Areas \nThis AI-based system has the potential to make a significant impact on cervical cancer screening \nin rural and underserved regions, where access to healthcare professionals and diagnostic facilities \nis limited. In these areas, healthcare providers often conduct screening camps with limited \nresources. This AI system can assist doctors by providing quick and accurate classification of \ncolposcopy images, reducing reliance on manual interpretation and enabling early diagnosis, even \nin remote locations. By automating the process, this system could improve accessibility and reduce \nthe workload of healthcare professionals. \n7. Ablation Study  \nIn AI model development, analyzing the contribution of different components helps to understand \ntheir impact on the overall model performance. For the early detection of cervical cancer, this \nanalysis will identify which elements of the model are crucial for making accurate predictions and \nguide the optimization process. \nThe first area of focus will be data preprocessing techniques. This will involve comparing the \nmodel's performance with and without the application of techniques such as normalization, scaling, \nand data augmentation methods like rotation and flipping. These steps are essential for improving \nthe model’s generalization ability and reducing overfitting.  \n\n14 \nNext, the model architecture will be examined. Specifically, the contribution of different layers in \nthe model, such as convolutional layers for feature extraction, will be tested. The effect of \nremoving or modifying specific layers, such as convolutional or fully connected layers, will be \nanalyzed to determine how they impact the model’s ability to detect cervical abnormalities. In \naddition, the importance of the fully connected layers will be evaluated to see if their presence \nenhances the model’s classification accuracy. \nThe analysis will also include feature selection to evaluate how the model performs with different \nsets of input data. The model combines clinical data (such as medical history and HPV status) with \nimage data from cervical scans, and different subsets of features will be tested to determine which \ncombination of data provides the best results. This will allow us to identify which type of \ninformation—clinical or image data—plays a more significant role in predicting cancer. \nFurthermore, hyperparameter tuning will be explored to optimize the model’s performance. By \nadjusting different parameters, such as learning rate, batch size, and optimizer (e.g., Adam or \nSGD), the impact on the overall performance of the model will be assessed. The goal is to identify \nthe optimal hyperparameters that lead to the best model convergence and accuracy. \nLastly, the analysis will include post-processing techniques, particularly the effect of different \nthresholding strategies on classification. This will be important to determine how the threshold for \nclassifying a sample as positive or negative affects model performance and the balance between \nsensitivity and specificity. \nEach experiment will be designed to evaluate the model's performance under various conditions, \nincluding preprocessing steps, architecture adjustments, feature combinations, hyperparameter \nsettings, and post-processing techniques. Metrics such as accuracy, precision, recall, F1-score, and \nAUC-ROC will be used to assess the model’s ability to accurately identify cancer cases, minimize \nfalse positives, and balance recall with precision. \n8. Conclusion \n \nThis research successfully developed an AI-based system for the early detection of cervical cancer \nthrough deep learning techniques applied to colposcopy images. The framework used \nMobileNetV2 with transfer learning to categorize images into Normal and Abnormal classes, \nachieving an overall accuracy of 87.5%. Preprocessing methods, such as central cropping and \nadjustments to brightness and contrast, were crucial in enhancing the model's focus on the cervix, \nleading to better diagnostic accuracy. The results of the experiments showed that MobileNetV2, \nwhen paired with appropriate preprocessing and data augmentation, delivered consistent \nperformance despite challenges such as a small and noisy dataset. A comparative evaluation of \nmodels like ResNet50, EfficientNetB0, and DenseNet121 emphasized the significance of choosing \nan architecture that balances accuracy and generalization, especially for medical image \nclassification tasks. Of all the models tested, DenseNet121 demonstrated the most potential, but \n\n15 \nMobileNetV2, with transfer learning, proved to be an efficient and effective choice given the \ndataset’s limitations. The proposed system offers a promising solution for the early detection of \ncervical cancer, supporting healthcare professionals by reducing dependence on manual \ncolposcopy image interpretation. Its ability to achieve high sensitivity (recall) for detecting \nabnormal cases is particularly important for minimizing false negatives, which is crucial in \nensuring accurate medical diagnoses. \n     9. References \n• Hou X, Shen G, Zhou L, Li Y, Wang T, Ma X. Artificial Intelligence in Cervical Cancer \nScreening \nand \nDiagnosis. \nFront \nOncol. \n2022 \nMar \n11;12:851367. \ndoi: \n10.3389/fonc.2022.851367. PMID: 35359358; PMCID: PMC8963491. \n• Vargas-Cardona HD, Rodriguez-Lopez M, Arrivillaga M, Vergara-Sanchez C, García-\nCifuentes JP, Bermúdez PC, Jaramillo-Botero A. Artificial intelligence for cervical cancer \nscreening: Scoping review, 2009-2022. Int J Gynaecol Obstet. 2024 May;165(2):566-578. \ndoi: 10.1002/ijgo.15179. Epub 2023 Oct 9. PMID: 37811597. \n• Didem Egemen, Rebecca B Perkins, Li C Cheung, Brian Befano, Ana Cecilia Rodriguez, \nKanan Desai, Andreanne Lemay, Syed Rakin Ahmed, Sameer Antani, Jose Jeronimo, \nNicolas Wentzensen, Jayashree Kalpathy-Cramer, Silvia De Sanjose, Mark Schiffman, \nArtificial intelligence–based image analysis in clinical testing: lessons from cervical cancer \nscreening, JNCI: Journal of the National Cancer Institute, Volume 116, Issue 1, January \n2024, Pages 26–33, https://doi.org/10.1093/jnci/djad202 \n• Wang, J., Yu, Y., Tan, Y. et al. Artificial intelligence enables precision diagnosis of \ncervical cytology grades and cervical cancer. Nat Commun 15, 4369 (2024). \nhttps://doi.org/10.1038/s41467-024-48705-3 \n• Qin, D., Zhang, C., Zhou, H. et al. RETRACTED ARTICLE: Meta-analysis of Artificial \nIntelligence-Assisted Pathology for the Detection of Early Cervical Cancer. Int J Comput \nIntell Syst 16, 189 (2023). https://doi.org/10.1007/s44196-023-00367-7",
    "pdf_filename": "AI_Guided_Early_Screening_of_Cervical_Cancer.pdf"
}