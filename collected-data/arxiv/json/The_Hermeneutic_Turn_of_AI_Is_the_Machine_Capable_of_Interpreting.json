{
    "title": "The Hermeneutic Turn of AI Is the Machine Capable of Interpreting",
    "abstract": "This article aims to demonstrate how the approach to computing is being disrupted by deep learning (artificial neural networks), not only in terms of techniques but also in our interactions with machines. It also addresses the philosophical tradition of hermeneutics (Don Ihde, Wilhelm Dilthey) to highlight a parallel with this movement and to demystify the idea of human-like AI.",
    "body": "1 \n \nThe Hermeneutic Turn of AI: \nIs the Machine Capable of Interpreting?  \nRémy Demichelis, PhD, \nVisiting Researcher, \nUniversity of Turin \n \nAbstract \nThis article aims to demonstrate how the approach to computing is being disrupted by deep \nlearning (artificial neural networks), not only in terms of techniques but also in our interactions \nwith machines. It also addresses the philosophical tradition of hermeneutics (Don Ihde, \nWilhelm Dilthey) to highlight a parallel with this movement and to demystify the idea of \nhuman-like AI. \nKeywords \nArtificial intelligence, AI ethics, Philosophy of technology, LLM \n \nIntroduction \nThe notion of interpretation is increasingly \npresent in the world of artificial intelligence \n(AI). For humans, it involves interpreting \nalgorithms that are difficult to explain \nmathematically. \nFor \nmachines, \nthe \nchallenge is to interpret data to draw \nconclusions. They must now also interpret \nbrief instructions in natural language: this is \nthe operational principle of ChatGPT and \nother chatbots grounded on generative AI \nwhich interacts verbally with unsettling \nfluidity. We can thus speak of a true \ninterpretive turning point in AI. \nThe art of interpretation, however, has \nbeen known for centuries under the term \n“hermeneutics”. It initially applied to the \nreading of poets or sacred texts before \nevolving into a philosophical current to \nsignify that interpretation is at the \nfoundation of understanding, or even that \nit represents the necessary activity of who \nwe are (Gadamer, 2004-1960; Heidegger, \n1962-1927; Nietzsche, 1954-1886/1887, \n2003-1887). Our access to the world is \nindeed always influenced by certain tones \nthat are not neutral but carry a cultural \ncharge. \nDoes \nthe \nresemblance \nstop \nhowever at the mere use of the term \ninterpretation? In other words, is AI doing \nhermeneutics? Should we use the art of \ninterpretation to understand machines? Or \nis it both? \n1. Direct Dialogue with the Machine \nin Our Language \nThe event that completes the interpretive \nturn of AI is undoubtedly the launch of \nChatGPT in November 2022. The essential \ninnovation of large language models, like its \nown, is that the machine is required to \ninterpret human instructions more than \never before. The user inputs a prompt to \nrequest what they want, and then the \nsystem provides a response, whether it's \ntext, an image, or spoken output.  \n\n2 \n \nWe no longer address the machine in \ncomputer language, in code, but in natural \nlanguage or what is called unstructured \ndata. Certainly, the “hallucinations” (errors \nof the machine in the form of plausible but \ndelusional statements) are countless, and \nthe results can still be improved, but \nsomething is happening. Interpretation, an \nactivity we long believed was reserved for \nhumans, is now being undertaken by digital \ntools. \nComputing has already long been an object \nof \ninterpretation, \nsince \nscience \nhas \nincreasingly relied on digital instruments \nand \nimaging \ntechniques \n(medical, \nnanometric, \nspectroscopic, \netc.). \nThe \nAmerican philosopher Don Ihde, who \npassed away this year, noticed this early on, \nfirst in his work “Technology and the \nLifeworld” (Ihde, 1990). \nUnfortunately, it is only after his death that \nhis relevance seems to leap out at us. “All \nimagery calls for interpretation”, he wrote \n(Ihde, 2021, Chapter 1). He goes on to \nexplain \nthat \nimagery \nis \n“materially \ntechnological \nin \nits \ninstrumental \nembodiment” because it requires the use \nof a sophisticated tool to produce it, reveal \nthe image, and thus the object being \nstudied.  \n[His] idea for a material hermeneutics is \nclosely tied to the 20th-21st shift to micro-\nprocessing \nimaging \ntechnologies \nthat \ntransform science practice and evidence \nproduction […] These technologies helped \nenhance the necessity for interpretation or \nhermeneutics practices in natural science. \n(Ihde, 2021, Chapter 4) \nFor Ihde, what characterizes this “necessity \nfor interpretation” is that we are no longer \nbeing in a direct relationship with things. \nWe must go through instruments or images \nin such a way that we construct the object \nthrough the medium, like a camera or a \nscientific \nmeasuring \ninstrument. \nOur \nunderstanding of the object is then \ninseparable from the medium without \nwhich we could not know it. The famous \nphotograph of a black hole (Collaboration \net al., 2019), which is not exactly a \nphotograph but a construction from data \nfrom eight different radio telescopes, \nprovides one of the best illustrations of \nthis. \n2. The Return of Ambiguity \nAccording to Ihde, the interpretive turn \nthat science has taken tends to bridge the \ngap \nbetween \n“explanation” \nand \n“understanding” (Dilthey, 1989-1883). It is \none thing to explain how a castle was built, \nwith what materials or techniques. It is \nanother to understand the reason for its \nexistence, why its builders decided to erect \nit in a particular place at a certain time. In \nthis latter case (that of understanding), it is \nnecessary to call upon interpretation, in \nlight of historical elements. However, \nscience \nincreasingly \nveers \ninto \ninterpretation in order not to merely \nexplain the objects it studies. This marks a \nrapprochement between the sciences and \nthe humanities (literature, philosophy, \nhistory...). \nAI further accentuates this rapprochement. \nAlready because the machine is asked to \ninterpret what is given to it, but also \nbecause \nhumans \nmust \nincreasingly \ninterpret the results produced by the \nmachine (Lundberg & Lee, 2017; Ribeiro et \nal., 2016). Ambiguity is taking on a growing \nrole in the world of computing, which, as an \nheir to mathematics, believed it was \npreserved from such things. And where \nthere \nis \nambiguity, \nthere \nis \nalso \ninterpretation. \nCurrent \nAI \nsystems, \n\n3 \n \nparticularly \nimage \nanalysis \nor \ntext \ngeneration, \nrely \non \nartificial \nneural \nnetworks. This “deep” learning technique, \nhowever, is not easily grasped, even by \nexperts. This is particularly damaging when \nwe \nrealize \nlater \nthat \nthe \nmachine \nreproduces discriminatory bias (Bernheim \n& Vincent, 2019; Buolamwini, 2023; \nBuolamwini & Gebru, 2018; Gebru, 2020; \nLowry & Macpherson, 1988; Noble, 2018; \nO’Neil, 2016). \nThe AI Act, a regulation on AI recently \nadopted \nby \nthe \nEuropean \nUnion \n(EU 2024/1689), however, stipulates that \nso-called “high-risk” systems must undergo \nthorough analyses (the nature of which \nremains to be defined). But it is impossible \nto determine exactly why the software \nproduces a particular result; we can only \n“interpret” its functioning. While there are \ntoday techniques of “explainability” to \nestimate the weight of each variable, it is \nindeed the term “interpretability” that \nshould be favored, as they only offer \nestimates, but no clear and distinct \nexplanation, the kind that mathematics \nrequires to eliminate any ambiguity. \nAI even invites us to go beyond quantitative \ninterpretations, since it is important to \nunderstand historically how AI models \nconstruct their sometimes biased or \ndiscriminatory interpretations:  \nEven \nif \nsomeone \ncould \nconvince \nthemselves that algorithms sometimes just \nspit out nonsense, the structure of the \nnonsense will tend vaguely toward the \nstructure \nof \nhistorical \nprejudices.  \n(Gebru, 2020)  \nWhile interpretability techniques will have \ntheir utility, it will also be necessary to \nanalyze the outputs of AI in a more \nsensitive way, considering that they are \nalso the product of a specific history and \nsociety (Kudina, 2023). \n3. Interpreting to Find Meaning \nIf AI is indeed capable of interpreting our \nstatements to some extent in order to \ngenerate an answer, understanding seems \nto be nevertheless a phenomenon that \ngoes beyond this. To understand something \nrequires a certain amount of imagination to \nconceive the object of our knowledge in its \nmultiple and new configurations, to grasp it \nin a way that is rarely formal but comes \nthrough feeling. Some pupils recite their \nlessons admirably without understanding \nanything, as they lack the necessary feeling \nto exclaim: “Got it!” or, as Archimedes is \nbelieved to have said, “Eureka!” This feeling \nis almost impossible to describe, but have \nyou \nnever \nmarveled \nat \nsuddenly \nunderstanding something that had resisted \nyou? If so, you know well what this feeling \nis, this sensory event of understanding. \nAnd this feeling is fertile, as it can produce \ninterpretation: new connections appear, \nnew configurations, new horizons that feed \nour imagination. We sometimes say: “that \nmakes sense” and it really does. It makes \nsense, literally, as I feel an interpretation to \nbe right. This is then an aspect of \ninterpretation \nthat \nseparates \nour \nunderstanding from what machines do, \nsince computer systems are unable to feel. \nThe imagination necessary for the art of \ninterpretation will always be for them an \nimpoverished \nversion \nof \nit, \nan \n“e-\nmagination” (Romele, 2020). \nThe interpretation produced by generative \nAI thus differs from ours in that it is \nincapable of understanding anything. \nNevertheless, it represents a decisive \naspect of the interpretive turn that unfolds \nin various ways in the world of sciences. \n\n4 \n \nThe machine interprets our requests in \nnatural language, and we interpret its \nresults \nor \nfunctioning. \nAI \nbrings \nhermeneutics back into fashion to the point \nthat we should speak not just of artificial \nintelligence, but of artificial interpretation. \n \nThis text was originally published in “The \nConversation”, June 3, 2024 (Demichelis, \n2024), under the Creative Commons CC BY-\nND 4.0 License. Read the original article.  \n \nBibliography \nBernheim, A., & Vincent, F. (with Villani, C.). (2019). \nL’intelligence artificielle, pas sans elles ! : \nFaire de l’IA un levier pour l’égalité. Belin - \nHumensis. \nBuolamwini, J. (2023). Unmasking AI: My Mission to \nProtect What Is Human in a World of \nMachines. Random House. \nBuolamwini, J., & Gebru, T. (2018). Gender Shades: \nIntersectional \nAccuracy \nDisparities \nin \nCommercial \nGender \nClassification. \nProceedings \nof \nMachine \nLearning \nResearch, 81, 15. \nCollaboration, et al. (2019). First M87 Event Horizon \nTelescope Results. I. The Shadow of the \nSupermassive \nBlack \nHole. \nThe \nAstrophysical Journal Letters, 875(1), L1.  \nDemichelis, R. (2024, June 3). L’IA est-elle capable \nd’interpréter ce qu’on lui demande ? The \nConversation.  \nDilthey, W. (1989-1883). Wilhelm Dilthey: Selected \nWorks, Volume I: Introduction to the \nHuman Sciences (R. A. Makkreel & F. Rodi, \nEds.). Princeton University Press. \nEuropean \nUnion. \n(2024). \nRegulation—EU \n- \n2024/1689.  \nGadamer, H.-G. (2004-1960). Truth and Method (J. \nWeinsheimer & D. G. Marshall, Trans.; 2nd \ned.). Continuum International Publishing \nGroup Ltd. \nGebru, T. (2020). 13. Race and Gender. In M. D. \nDubber, F. Pasquale, & S. Das (Eds.), The \nOxford Handbook of Ethics of AI, 253–269. \nOUP. \nHeidegger, M. (1962-1927). Being and Time (J. \nMacquarrie & E. Robinson, Trans.; Revised \nedition). Harper and Row Publishers. \nIhde, D. (1990). Technology and the Lifeworld: From \nGarden to Earth. Indiana University Press. \nIhde, D. (2021). Material Hermeneutics: Reversing \nthe Linguistic Turn. Routledge. \nKudina, O. (2023). Moral Hermeneutics and \nTechnology: Making Moral Sense through \nHuman-Technology-World Relations. The \nRowman & Littlefield Publishing Group.  \nLowry, S., & Macpherson, G. (1988). A blot on the \nprofession. \nBritish \nMedical \nJournal, \n296(6623), 657–658. \nLundberg, S. M., & Lee, S.-I. (2017). A Unified \nApproach \nto \nInterpreting \nModel \nPredictions. \nAdvances \nin \nNeural \nInformation Processing Systems, 30.  \nNietzsche, \nF. \n(1954-1886/1887). \nNotebooks, \nSummer 1886 – Fall 1887 (W. Kaufmann, \nTrans.). In The Portable Nietzsche (1988th \ned.). Penguin Books. \nNietzsche, F. (2003-1887). Beyond Good and Evil (M. \nTanner, Ed.; R. J. Hollingdale, Trans.; \nReissue edition). Penguin Classics. \nNoble, S. U. (2018). Algorithms of Oppression: How \nSearch Engines Reinforce Racism. NYU \nPress. \nO’Neil, C. (2016). Weapons of Math Destruction: \nHow Big Data Increases Inequality and \nThreatens Democracy. Crown. \nRibeiro, M., Singh, S., & Guestrin, C. (2016). “Why \nShould I Trust You?”: Explaining the \nPredictions of Any Classifier. Proceedings of \nthe 2016 Conference of the North American \nChapter \nof \nthe \nAssociation \nfor \nComputational \nLinguistics: \nDemonstrations, 97–101.  \nRomele, \nA. \n(2020). \nDigital \nhermeneutics: \nPhilosophical investigations in new media \nand technologies. Routledge.",
    "pdf_filename": "The_Hermeneutic_Turn_of_AI_Is_the_Machine_Capable_of_Interpreting.pdf"
}