{
    "title": "Monolingual alignment of word senses and definitions in lexicographical resources",
    "context": "",
    "body": "Doctoral Thesis\nMonolingual Alignment of Word Senses and\nDeﬁnitions in Lexicographical Resources\nSina Ahmadi\nM.Sc., Paris Descartes University, 2017\nM.A., Sorbonne Nouvelle University, 2016\nB.Eng., University of Kurdistan, 2014\nSupervisor\nDr. John P. McCrae\nExternal Examiner\nProf. Marie-Claude L’Homme\nInternal Examiner\nDr. James McDermott\nThesis Submitted in Partial Fulﬁllment of the Requirements for the Degree of\nDoctor of Philosophy\nin the\nSchool of Computer Science\nCollege of Science and Engineering\nNational University of Ireland Galway\nSpring 2022\n\n\nA B ST R A C T\nDictionaries are fundamental resources for people to learn and document languages\nas well as for computers to process natural languages. A dictionary provides a ﬁne-\ngrained structure and description of the vocabulary of a language. With decades of\nadvances in electronic lexicography, a signiﬁcant amount of lexicographical resources\nare currently available. Such resources are the fruits of elaborate and strenuous efforts\nof lexicographers and oftentimes, are costly projects to initiate and maintain. More-\nover, given the increasing number of lexical semantic resources thanks to community-\ndriven initiatives such as Wiktionary, the alignment of such resources is of impor-\ntance to promote interoperability and increase their exploitation more effectively. On\nthe other hand, the signiﬁcant progress in the ﬁeld of computer science, artiﬁcial\nintelligence and the semantic web has been tremendously beneﬁcial to various sci-\nentiﬁc ﬁelds, particularly language technology. Therefore, there is an opportunity to\nleverage the current techniques and resources to facilitate the automatic alignment,\nintegration and enrichment of lexicographical data.\nThe focus of this thesis is broadly on the alignment of lexicographical data, par-\nticularly dictionaries.\nIn order to tackle some of the challenges in this ﬁeld, two\nmain tasks of word sense alignment and translation inference are addressed. The\nﬁrst task aims to ﬁnd an optimal alignment given the sense deﬁnitions of a headword\nin two different monolingual dictionaries. This is a challenging task, especially due\nto differences in sense granularity, coverage and description in two resources. After\ndescribing the characteristics of various lexical semantic resources, we introduce a\nbenchmark containing 17 datasets of 15 languages where monolingual word senses\nand deﬁnitions are manually annotated across different resources by experts. In the\ncreation of the benchmark, lexicographers’ knowledge is incorporated through the an-\nnotations where a semantic relation, namely exact, narrower, broader, related or none,\nis selected for each sense pair. This benchmark can be used for evaluation purposes\nof word-sense alignment systems. The performance of a few alignment techniques\nbased on textual and non-textual semantic similarity detection and semantic relation\ninduction is evaluated using the benchmark. Finally, we extend this work to transla-\ntion inference where translation pairs are induced to generate bilingual lexicons in an\nunsupervised way using various approaches based on graph analysis. This task is of\nparticular interest for the creation of lexicographical resources for less-resourced and\nunder-represented languages and also, assists in increasing coverage of the existing\nresources. From a practical point of view, the techniques and methods that are de-\nveloped in this thesis are implemented within a tool that can facilitate the alignment\ntask.\ni\n\n\nC O N T E N T S\nDeclaration\nvii\nAcknowledgements\nix\nAcronyms\nxi\nList of Figures\nxv\nList of Tables\nxviii\n1\nIntroduction\n1\n1.1\nThe ELEXIS project . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.2\nMotivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\nResearch Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.4\nThesis Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.5\nPublications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2\nBackground\n13\n2.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.1.1\nLexical Semantic Resources . . . . . . . . . . . . . . . . . . . . . .\n15\n2.1.2\nPolysemy\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.2\nDictionaries\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.2.1\nLexicon vs. Dictionary . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n2.2.2\nContent\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\nHeadwords\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\nSenses\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\nDeﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n2.2.3\nElectronic Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n2.3\nNetwork-based Resources . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n2.3.1\nWordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n2.3.2\nFrameNet\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n2.3.3\nJeuxDeMots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n2.4\nExplanatory Combinatorial Dictionary . . . . . . . . . . . . . . . . . . . .\n29\n2.5\nGenerative Lexicon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n2.6\nNatural Semantic Metalanguage\n. . . . . . . . . . . . . . . . . . . . . . .\n34\n2.7\nTerminologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n2.8\nOntological Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n2.8.1\nLinguistic Linked Data . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n2.9\nKnowledge Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n2.10 Language Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n2.11 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n3\nSystematic Literature Review\n49\niii\n\niv\nCONTENTS\n3.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n3.2\nCreation and Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n3.3\nEnrichment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n3.3.1\nSemantic Similarity Detection . . . . . . . . . . . . . . . . . . . . .\n54\nCorpus-based approaches . . . . . . . . . . . . . . . . . . . . . . .\n55\nLSR-based approaches . . . . . . . . . . . . . . . . . . . . . . . . .\n55\nEmbeddings-based approaches . . . . . . . . . . . . . . . . . . . .\n55\nDatasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n3.3.2\nLanguage Resource Alignment . . . . . . . . . . . . . . . . . . . .\n57\n3.3.3\nTranslation Inference . . . . . . . . . . . . . . . . . . . . . . . . . .\n58\n3.4\nPublication and Storage\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n3.5\nDictionaries in NLP applications . . . . . . . . . . . . . . . . . . . . . . .\n62\n3.5.1\nWord Sense Disambiguation\n. . . . . . . . . . . . . . . . . . . . .\n62\n3.5.2\nSemantic Role Labeling . . . . . . . . . . . . . . . . . . . . . . . .\n62\n3.5.3\nReverse Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n3.6\nWhat is missing?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n64\n4\nLeveraging the graph structure of lexicographical resources\n65\n4.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n4.2\nRelated Work\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\n4.3\nLexicographical network . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n68\n4.3.1\nAnalysis of lexicographical networks\n. . . . . . . . . . . . . . . .\n69\n4.3.2\nExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n69\n4.4\nWeighted bipartite b-matching . . . . . . . . . . . . . . . . . . . . . . . .\n71\n4.4.1\nString-based Methods . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n4.4.2\nThe WBbM algorithm . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n4.4.3\nExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n76\n4.5\nTranslation Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\n4.5.1\nCycle-based approach . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n4.5.2\nPath-based approach . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n4.5.3\nExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n80\n4.6\nConclusion and Contributions\n. . . . . . . . . . . . . . . . . . . . . . . .\n81\n5\nA Benchmark for Monolingual Word Sense Alignment\n83\n5.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n83\n5.2\nRelated Work\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n86\n5.3\nMethodology\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n88\n5.3.1\nSemantic Relationships\n. . . . . . . . . . . . . . . . . . . . . . . .\n89\n5.3.2\nData Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n91\n5.3.3\nDictionaries used in the creation of the dataset . . . . . . . . . . .\n92\n5.3.4\nDataset Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n94\n5.4\nCase Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n94\n5.4.1\nDanish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n94\n\nCONTENTS\nv\nSense structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n95\nDeﬁnition content\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n95\nData structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n97\nManual annotation . . . . . . . . . . . . . . . . . . . . . . . . . . .\n98\n5.4.2\nItalian\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n5.4.3\nPortuguese\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nSense structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\nDeﬁnition content\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 102\nManual annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n5.5\nEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n5.5.1\nSense Granularity\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n5.5.2\nSense Alignments . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n5.5.3\nInter-annotator Agreement . . . . . . . . . . . . . . . . . . . . . . 109\n5.6\nConclusion and contributions . . . . . . . . . . . . . . . . . . . . . . . . . 113\n6\nMonolingual Word Sense Alignment\n115\n6.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n6.2\nRelated Work\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n6.3\nNaisc architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n6.4\nTextual Similarity Methods\n. . . . . . . . . . . . . . . . . . . . . . . . . . 124\n6.4.1\nString-based Methods . . . . . . . . . . . . . . . . . . . . . . . . . 124\n6.4.2\nBeyond String Similarity . . . . . . . . . . . . . . . . . . . . . . . . 124\n6.4.3\nWord Alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n6.4.4\nMonolingual Alignment . . . . . . . . . . . . . . . . . . . . . . . . 129\n6.5\nSemantic Relation Induction . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n6.5.1\nData Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n6.5.2\nFeature Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n6.6\nExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n6.6.1\nBaseline System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.6.2\nSystem 1: Classiﬁcation and Feature Learning . . . . . . . . . . . 137\n6.6.3\nSystem 2: Length-limited Alignment\n. . . . . . . . . . . . . . . . 143\n6.7\nELEXIS Monolingual Word Sense Alignment Task . . . . . . . . . . . . . 145\n6.8\nConclusion and contributions . . . . . . . . . . . . . . . . . . . . . . . . . 147\n7\nConclusions\n149\n7.1\nResearch Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n7.1.1\nBenchmarking Word Sense Alignment\n. . . . . . . . . . . . . . . 149\n7.1.2\nAlignment of dictionaries at the sense level . . . . . . . . . . . . . 152\n7.1.3\nAlignment of dictionaries at the entry level . . . . . . . . . . . . . 153\n7.1.4\nNaisc\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n7.2\nRevisiting the Research Questions\n. . . . . . . . . . . . . . . . . . . . . . 154\n7.3\nLimitations and Future directions\n. . . . . . . . . . . . . . . . . . . . . . 156\nBibliography\n159\n\n\nD E C L A R AT I O N\nI declare that this thesis, titled “Monolingual Alignment of Word Senses and Deﬁnitions\nin Lexicographical Resources”, is composed by myself, that the work contained herein\nis my own except where explicitly stated otherwise in the text, and that this work has\nnot been submitted for any other degree or professional qualiﬁcation.\nGalway, March 7, 2022\nSina Ahmadi\nvii\n\n\nA C K N O W L E D G E M E N T S\nWriting this section has inspired me since the very beginning. Perhaps because I was\nwondering how my Ph.D. journey would shape this text at the end. And here is how\nit goes.\nThis thesis is the result of my past four years of work as a Ph.D. researcher. Al-\nthough I am sure this work is not ﬂawless, I must say that ﬁnishing up my Ph.D. dur-\ning Covid-19 gave me immense satisfaction. Starting my Ph.D. on an exceptionally\nsunny day in April 2018 in Galway, I had a sweet episode of my life full of new ideas\nin research, rewarding experiences in engineering, papers, and conferences that were\ntypical of Ph.D. life at the time. To my surprise, I even rarely struggled with the type\nof challenges that some of my fellows complained about, such as making progress,\ncarrying out experiments, catching deadlines to submit papers, or having a life while\ndoing a Ph.D. However, the impact of the physical restrictions and psychological\nburden that Covid-19 imposed on everyone, including myself, were undeniable.\n2020 was a particularly harsh year for everyone but even worse for international\npostgraduate students living in Ireland. Doing a Ph.D. during Covid-19 did not only\nrequire taking care of regular activities but also learning to cope in the new mainly\nvirtual world while living in a shared house and dealing with the emerging mental\nhealth issues far away from the loved ones. Now that I look back, I feel that I should\nbe gleeful that those daunting days are gone, despite the long-lasting effects.\nRegardless of the problems, I enjoyed every single day of this journey and will\nalways remember it with sweet memories. Living in Ireland was not without chal-\nlenge, but at least, it taught me to be more grateful for having things that we usually\ntake for granted: the generous sun, more predictable weather, good food, fresh ar-\ntisan bread, decent accommodation, museums, and a more affordable place to live.\nNevertheless, I will miss this place for the friendly Irish people, the grasslands that\nmake running more joyful, the biodiversity and the wildlife, particularly those robins\nsinging at night!\nThis work could not have been accomplished without the help of many people.\nFirst and foremost, I would like to thank my esteemed supervisor, Dr. John McCrae,\nfor his invaluable supervision, wise pragmatism, support, tutelage, and kindness\nduring the course of my Ph.D. degree. My gratitude extends to the ELEXIS project for\nthe funding opportunity to undertake my studies at the School of Computer Science\nat NUI Galway. My sincere thanks also go to Dr. Mathieu d’Aquin and Dr. Paul\nBuitelaar who played an important role as my graduate research committee members,\nand to the examination committee members, Dr. Marie-Claude L’Homme and Dr.\nJames McDermott, for their constructive comments and invaluable insights.\nix\n\nx\nCONTENTS\nThis journey could not be this memorable without my friends at Insight: Tobias\nDaudert, Joana Barros, Omnia Zayed, Adrian Ó Dubhghaill, Oksana Dereza, Sarah\nCarter, Niki Pavlopoulou, and Brendan Smith. Many thanks to the administrative\nstaff at Insight and ELEXIS for their support: Hilda Fitzpatrick, Christiane Leahy-\nCoen, and Anna Woldrich. My Ph.D. experience would have certainly been different\nwithout the compassionate friends who helped me in many ways, especially by host-\ning me with open arms when I had difﬁculty ﬁnding accommodation: Housam Ziad\nand his lovely family, Aftab Alam and Dr. Theodorus Fransen. Likewise, thanks\nto Jalal Sajadi and Daban Q. Jaff for their true friendship over the years. Special\nthanks to Dr. Sanni Nimb who hosted me during my visit to the Society for Danish\nLanguage and Literature and the Centre for Language Technology in Copenhagen in\n2019 which was an enriching experience in many ways. I would also like to warmly\nthank Dr. Mathieu Constant for hosting me in Nancy in 2021. Throughout my visit, I\nhad a great time sharing my ofﬁce with Pauline Gillet and Charlène Weyh.\nThe accomplishment of my Ph.D. studies is important to me in two other ways\ntoo. First, it marks the end of my formal education which has been continuously\ngoing on since I remember. I partially owe this to France which provided me with\nfree education and unique, eye-opening, rich, and unforgettable experiences. Also, I\nam indebted to Dr. Kyumars S. Esmaili who encouraged me during my bachelor’s\nto follow my passion for languages, linguistics, and computer science by studying\nnatural language processing. Second, it ends as the fourth decade of my life begins,\nso do my plans to contribute to society and have a more signiﬁcant role “to make the\nworld a better place”, something that I whimsically told my parents when I left them\nand I am sometimes contemplative if ever it will be eventual! I will stay optimistic.\nThis brings me to the most important people in my life. There is no word to\nproperly express my gratitude to my family back in Kurdistan, particularly to my\nparents who always believed in me, endorsed me in my choices, and even sacriﬁced\nthemselves to make sure that their children have a fair chance to achieve their goals,\nmore than their own generation. I understand that pursuing my studies imposed\nthousands of kilometers of distance between us and years of untogetherness that\ncould not have passed this way without their support and unconditional love. Spas\nû xo¸sewîstî! I am also deeply grateful to my family in Greece who have always sup-\nported me, have given new meaning to my life with their kind hearts, positive vibes\nand love. ´Aπειρα ευχαριστ ´ω!\nFinally, I would like to thank the love of my life, Ioanna, from the bottom of my\nheart for being my best friend and companion and for her patience and encourage-\nment over the years. It is impossible to imagine this journey getting to an end without\nher unending support and love. To her, I would say: Je t’aime.\n\n\nA C R O N YM S\nBERT Bidirectional Encoder Representations from Transformers\nBLI Bilingual Lexicon Induction\nCL Computational Linguistics\nCNN Convolutional Neural Network\nECD Explanatory Combinatorial Dictionary\nFLN French Lexical Network\nIAA Inter-Annotator Agreement\nIC Inverse Consultation\nLLOD Linguistic Linked Open Data\nLSR Lexical Semantic Resource\nLSTM Long Short-Term Memory\nMRD Machine-Readable Dictionary\nMTT Meaning-Text Theory\nMWSA Monolingual Word-Sense Alignment\nMWE Multiword Expression\nNLP Natural Language Processing\nNSM Natural Semantic Metalanguage\nOED Oxford English Dictionary\nOWL Web Ontology Language\nRBM Restricted Boltzmann Machine\nRDF Resource Description Framework\nRNN Recurrent Neural Network\nSKOS Simple Knowledge Organization System\nSLR Sentence Length Ratio\nSTS Semantic Textual Similarity\nSVM Support Vector Machine\nTEI Text Encoding Initiative\nTIAD Translation Inference Across Dictionaries\nTLFi Trésor de la Langue Française informatisé\nWBM Weighted Bipartite Matching\nWSA Word Sense Alignment\nWSD Word Sense Disambiguation\n\n\nL I ST O F F I G U R E S\n1.1\nAn overview of the objectives of the ELEXIS project. Our focus\nof linking within this project is encircled in dashed red. . . . . .\n4\n1.2\nThe structure of the thesis . . . . . . . . . . . . . . . . . . . . . .\n8\n2.1\nDegree of polysemy of French, German and Italian lexicograph-\nical data on Wiktionary (dump of early 2022 using Dbnary\n(http://kaiko.getalp.org))\n. . . . . . . . . . . . . . . . . . . . . .\n17\n2.2\nThe relationship between lexicon and grammar according to\nLehmann (2020) . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.3\nThe micro-structure of the entry ‘beauty’ in the Longman Dic-\ntionary of American English . . . . . . . . . . . . . . . . . . . . .\n21\n2.4\nThe noun ‘afstand‘ (distance) in the Danish monolingual dic-\ntionaries, Den Danske Ordbog (https://ordnet.dk/ddo/ordbog?\nquery=afstand)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n2.5\nThe lexical network of ‘lion’ (noun) according to the Princeton\nWordNet 3.1 where its synsets (in green) and other semantic\nrelations are speciﬁed (Visualized using Lexical Graph: https:\n//github.com/aliiae/lexical-graph). . . . . . . . . . . . . . . . .\n27\n2.6\nThe frame of ‘cogitation’ (noun) in green along with its rela-\ntions with other frames, such as ‘memorization’ according to\nthe Berkeley FrameNet (Visualized using FrameGrapher: https:\n//framenet.icsi.berkeley.edu/fndrupal/FrameGrapher).\n. . . .\n28\n2.7\nThe network of ‘attention’ (noun, En. attention) in the French\nLexical Network (visualized using Spiderlex: https://spiderlex.\natilf.fr/fr/q/*attention***) . . . . . . . . . . . . . . . . . . . . . .\n31\n2.8\nThe Linguistic Linked Open Data Cloud (From https://linguistic-\nlod.org) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n2.9\nA simple ontology for Place, showing France, Ile-de-France\nand Paris as instances. This is created using Protégé (https:\n//protege.stanford.edu). . . . . . . . . . . . . . . . . . . . . . . .\n42\n2.10\nClosest words to the vector space of the word ‘wing’ (noun)\nin the MUSE embeddings of English along with the nearest\nwords in the mapped vector space in French . . . . . . . . . . .\n44\n2.11\nDistinction between senses of ‘wing’ (noun) using BERT . . . .\n45\n3.1\nA general description of the life cycle of a lexical semantic re-\nsource . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nxiii\n\nxiv\nLIST OF FIGURES\n3.2\nThe conversion of an example entry from a Kurdish-English\ndictionary into RDF Turtle based on the OntoLex-Lemon model\n(to the right) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n3.3\nA conceptual model proposed by Silva et al. (2016) to extract\nsemantic roles from sense deﬁnitions.\nDashes lines refer to\nrelationships between particles, such as a phrasal verb comple-\nment, in the deﬁnition. . . . . . . . . . . . . . . . . . . . . . . . .\n63\n4.1\nAn example of the use of non-textual features for linking. Here\nthe two senses of bank are distinguished by the hypernym\nlinks (1) and an inferred hapax legomenon link (2), so that the\ncorrect sense (3) can be selected.\n. . . . . . . . . . . . . . . . . .\n67\n4.2\nA set of dictionary entries (left) and the equivalent lexicograph-\nical network (right). . . . . . . . . . . . . . . . . . . . . . . . . . .\n68\n4.3\nSchema of the sense alignment system with a focus on the\ngraph matching component.\nIt should be noted that in re-\nsources R1 and R2, Ei refers to entry i with senses shown as S\nand S′. σ denotes the similarity function. . . . . . . . . . . . . .\n72\n4.4\nApertium RDF graph, with the target languages shown in green\nand bilingual dictionaries to be generated indicated in dashed\nlines.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\n4.5\nCycles found in the dictionary (solid lines) and inferred trans-\nlations (transparent lines). Some of the lines identify possible\nsame-language synonyms (e.g. ancient and antique in English),\nwhile others identify newly discovered possible translations\n(e.g. antiguo in Spanish and antikva in Esperanto). . . . . . . . .\n78\n4.6\nTranslation graph of spring (noun) (in red) resulting in Por-\ntuguese translations (in blue) using the pivot languages. . . . .\n79\n4.7\nPaths starting from ‘chaotique’ (adjective in French) in the Aper-\ntium translation data. Language codes and part-of-speech tags\nare respectively provided in subscript and superscript. . . . . .\n82\n4.8\nTo the left, Apertium RDF graph (version 2) where nodes refer\nto languages and edges the availability of translations. Nodes\nunconnected to the target languages French (FR), English (EN)\nand Portuguese (PT) are pruned. . . . . . . . . . . . . . . . . . .\n82\n5.1\nSense provided for clog (verb) in the English WordNet (R1) and\nthe Webster Dictionary (R2). Drop-down lists are created dy-\nnamically for semantic relationship annotation.\n. . . . . . . . .\n88\n5.2\nThe concept scheme of ‘economic cooperation’ as an RDF graph\nin the SKOS core vocabulary (source: https://www.w3.org/\nTR/2005/WD-swbp-skos-core-guide-20051102/)\n. . . . . . . .\n91\n\nLIST OF FIGURES\nxv\n5.3\nThe sense deﬁnition of the noun pyramide (‘pyramid’) in ODS\n(column 1 to the left) and DDO (column 4 to the right) in the\nannotation process. . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n5.4\n‘bandarilha’ ‘(banderilla’) in DLPC (above) and DA (below) . . . 104\n5.5\n‘tripeiro’ (‘tripe seller and native of Porto’) in DLPC (above) and\nDA (below) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n5.6\n‘praia’ (‘beach’) in DLPC (above) and DA (below)\n. . . . . . . . 104\n5.7\nFrequency of the number of senses in the datasets per language\nin the left resource\n. . . . . . . . . . . . . . . . . . . . . . . . . . 105\n5.8\nFrequency of the number of senses in the datasets per language\nin the right resource\n. . . . . . . . . . . . . . . . . . . . . . . . . 105\n5.9\nNumber of tokens per dataset. R1 and R2 respectively corre-\nspond to the resources in Table 5.7 from up to down. Danish\nis removed due to its larger size. . . . . . . . . . . . . . . . . . . 108\n6.1\nThe Architecture of the Naisc system for sense linking. Single\nthin arrows refer to the usage of SPARQL by a component. . . . 122\n6.2\nA screenshot of Naisc – the automated linking tool . . . . . . . 123\n6.3\nStructure of ‘entire’ (adjective) in the Princeton English Word-\nNet. Green nodes denote synonyms. . . . . . . . . . . . . . . . . 125\n6.4\nA few monolingual relations associated to ‘entire’ (adjective) in\nConceptNet (https://conceptnet.io/c/en/entire). Underlined\nitems refer to concepts. . . . . . . . . . . . . . . . . . . . . . . . . 126\n6.5\nOur approach where features are extracted from word senses\nand external semantic resources . . . . . . . . . . . . . . . . . . . 130\n6.6\nAn example of restricted Boltzmann Machine with a m latent\nunits and n visible units . . . . . . . . . . . . . . . . . . . . . . . 133\n6.7\nConfusion matrices of various classiﬁcation models evaluated\non the English test set\n. . . . . . . . . . . . . . . . . . . . . . . . 141\n6.8\nThe correlation of sense sizes in ODS with F-measure using\nvarious methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\n7.1\nAn alignment of sense deﬁnitions of domestication (noun, fem-\ninine) in the Trésor de la Langue Française (to the left) and Wik-\ntionnaire (to the right). Translations are provided in brackets. . . 151\n\n\nL I ST O F TA B L E S\n2.1\nA classiﬁcation of some of the best known deﬁnition paradigms\n24\n2.2\nLexical units deﬁned in the vocable of ‘improve’ based on ECD\n(Mel’ˇcuk, 2006, p. 19) . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n2.3\nA list of semantic primes grouped into related categories ac-\ncording to Goddard and Wierzbicka (2002) . . . . . . . . . . . .\n35\n3.1\nA summary of the previous studies in aligning resources . . . .\n58\n3.2\nAn overview of the approaches proposed in the previous TIAD\nshared tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n4.1\nEvaluation of lexicographical networks based on basic graph\nnotions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n70\n4.2\nBasic statistics of sense-aligned resources. The ﬁrst rows de-\nscribe the Apertium dictionaries (2018) with ISO 639-1 lan-\nguage codes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n4.3\nWBbM algorithm performance on alignment of WordNet and\nWiktionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\n4.4\nSizes of the extracted dictionaries in the cycle-based and path-\nbased approaches. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n80\n4.5\nResults of the evaluation with precision (P), recall (R), F-measure\n(F1), and coverage (C) for all the different thresholds (T). . . . .\n80\n5.1\nSemantic relationships according to SKOS used for WSA task .\n90\n5.2\nDeﬁnition of the same sense of the verb lukke (‘to close’) in\nDDO and ODS\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n96\n5.3\nDeﬁnition of the same sense of the noun standpunkt (‘view’) in\nDDO and ODS . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n97\n5.4\nDeﬁnition of the same sense of the noun standpunkt (‘view’) in\nDDO and ODS . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n97\n5.5\nDeﬁnition of the same sense of the noun sikre (‘to secure’) in\nDDO and ODS with overlaps . . . . . . . . . . . . . . . . . . . .\n98\n5.6\nThe statistics of the annotated data for Danish. The numbers\nin parentheses refer to the overall number of the tokens in the\nsenses.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n5.7\nStatistics of the datasets. This table shows the number of senses\nin the resources (the number of the words in the deﬁnitions are\nprovided in parentheses).\n. . . . . . . . . . . . . . . . . . . . . . 107\n5.8\nA description of the semantic relationship alignments using\nbasic graph measures . . . . . . . . . . . . . . . . . . . . . . . . . 109\nxvii\n\nxviii\nLIST OF TABLES\n5.9\nInter-annotator agreement using Krippendorff’s alpha. Num-\nber of annotators provided in parentheses.\n. . . . . . . . . . . . 111\n5.10\nA comparison of annotations for vulgar (adjective) in English\nby the two annotators . . . . . . . . . . . . . . . . . . . . . . . . . 112\n5.11\nA comparison of annotations for caora (‘sheep’, noun) in Irish\nby the two annotators . . . . . . . . . . . . . . . . . . . . . . . . . 112\n6.1\nSenses of entire (adjective) in various monolingual English\ndictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n6.2\nA comparison of three deﬁnitions of ‘entire’ (adjective) based\non various similarity detection methods. Deﬁnition 1 and 2\nrefer to the same sense, while Deﬁnition 3 is different.\n. . . . . 118\n6.3\nNumber of data instances extracted from the MWSA bench-\nmark for training purposes based on the type of semantic rela-\ntion. # refers to the number. . . . . . . . . . . . . . . . . . . . . . 131\n6.4\nManually extracted features for semantic classiﬁcation of sense\nrelationships (21 columns in total)\n. . . . . . . . . . . . . . . . . 132\n6.5\nThe baseline system using Jaccard similarity metric and Hun-\ngarian algorithm for alignment. . . . . . . . . . . . . . . . . . . . 136\n6.6\nResults of the experiments on semantic induction on binary,\nSKOS and all relations, namely exact, related, broader, nar-\nrower and none, with and without an RBM. The highest F-\nmeasure scores in binary, all and SKOS classiﬁcations per lan-\nguage are respectively indicated in cyan, green and violet. Darker\nshades indicate higher values. . . . . . . . . . . . . . . . . . . . . 140\n6.7\nA comparison of the output of various systems for aligning\nsense deﬁnitions of tube (verb). BERT refers to the shared task\nsystem submitted by Bajcetic and Yim (2020). . . . . . . . . . . . 142\n6.8\nA comparison of the output of various systems for aligning\nsense deﬁnitions of glow (verb). BERT refers to the shared\ntask system submitted by Bajcetic and Yim (2020). . . . . . . . . 142\n6.9\nThe performance of our similarity detection models for auto-\nmatic alignment of DDO and ODS within a speciﬁc limit of\nspace-separated tokens (15, 20, 25 and all tokens)\n. . . . . . . . 144\n6.10\nThe highest results reported by the participants of the MWSA\nshared task (2020) along with the highest results from System\n1. The highest values are indicated in bold. . . . . . . . . . . . . 146\n\n\n1\nI N T R O D U C T I O N\nDictionaries are treasure houses of\ndata on the uses of words.\nThey\nare also our best starting point for\nall questions regarding word sense\ndistinctions, in natural language pro-\ncessing, the humanities or lexicogra-\nphy.\nBut to reveal the dictionary’s\ntreasures in a systematic way is no\nsimple task.\nAdam Kilgarriff (1992a, p. 381)\n‘Apple’ used to refer to any type of fruit long before denoting what it means now.\n‘Welsh’ used to mean ‘foreigner’ or ‘slave’ and ‘Dutch’ does basically mean ‘German’.\nAnything stupid was ‘nice’ and sacred ‘silly’. Yet more shockingly, ‘Ethiopia’ means\n‘burnt-face’ and ‘cretin’ comes from ‘Christian’! With the hope that these words could\nprovoke your curiosity, I would like to highlight the importance of the broader topic\non which this thesis focuses: dictionaries.\nAs one of the major components of the structure of a language, words play an\nessential role in understanding the nature of our languages to convey meaning. De-\npending on the level of analysis, words can be analyzed based on their pronunciation\nas in phonology, on their formation as in morphology, on their structure within a\nphrase as in syntax, on their meaning as in semantics and more broadly, on the con-\ntext as in pragmatics. As the fundamental material of these linguistic ﬁelds, words\nare further studied, collected and maintained in a reliable and accurate way in dic-\ntionaries. Thanks to lexicography, we can argue about the etymology of words, like\nthose mentioned above, and track the changes that some words have gone through\nover time. We also understand how civilizations and societies have evolved and in-\nﬂuenced each other by examining the semantic changes that occur in some words as\nthe distinctions between ‘craft’ and ‘skill’ under the inﬂuence of Old Norse and ‘pig’\nand ‘pork’ under the inﬂuence of Old French on English.\nWith decades of advances in electronic lexicography, a signiﬁcant amount of lexi-\ncographical resources are currently available, particularly in Europe. Such resources\nare the fruits of elaborate and strenuous efforts of lexicographers and oftentimes are\ncostly projects to initiate and maintain. Therefore, there is an opportunity to leverage\n1\n\n2\nintroduction\nthe current progress in computer science and information technology to facilitate elec-\ntronic lexicography. On the other hand, the signiﬁcant progress in the ﬁeld of artiﬁcial\nintelligence has been tremendously beneﬁcial to various scientiﬁc ﬁelds, particularly\nlanguage technology and natural language processing (NLP). Despite the burgeoning\nadvances in creating efﬁcient methods with less reliance on manually-annotated data,\nvarious NLP applications are still heavily dependent on human-curated resources,\nsuch as dictionaries. Thus, current tools and applications can beneﬁt from such reli-\nable and systematic inventories of data to address data-driven approaches.\nThe focus of this thesis is broadly on the alignment of data of lexicographical\nnature, particularly expert-made ones such as dictionaries and lexical or conceptual\nresources such as WordNet (Miller, 1995), as well as collaboratively-curated ones such\nas Wikipedia1 or Wiktionary2. The alignment task aims to identify identical words in\nresources and link various pieces of information within the lexical or semantic con-\ntext. A dictionary provides a ﬁne-grained structure of information about words, in-\ncluding entries that are in lemma form as the lemma bring for ‘brought’ and ‘brings’,\ndeﬁnitions, senses, usage examples and more elaborate properties such as semantic\nrelationships between words. In a bilingual or multilingual context, such informa-\ntion can be found in a cross-lingual setup as well. Moreover, given the increasing\nnumber of lexico-semantic resources, thanks to community-driven initiatives such as\nWiktionary and Open Multilingual WordNet3, the alignment of such resources is of\nimportance to promote interoperability and to facilitate the integration of various re-\nsources in a viable manner. This will ultimately pave the way for lexicographers to\nanalyze lexical entries in various resources, verify the evolution of particular informa-\ntion, such as senses over time, and signiﬁcantly reduce the lengthy editorial period\nand data collection burden.\nAligned resources have been shown to improve word, knowledge and domain cov-\nerage and increase multilingualism by creating new lexical resources such as YAGO\n(Suchanek et al., 2007), BabelNet (Navigli and Ponzetto, 2012a) and ConceptNet\n(Speer et al., 2017). In addition, they can improve the performance of NLP tasks such\nas word sense disambiguation (Navigli and Ponzetto, 2012b), semantic role tagging\n(Xue and Palmer, 2004) and semantic relations extraction (Swier and Stevenson, 2005).\nDespite the previous works addressing the alignment task, various challenges in this\nﬁeld require further studies. Some of these challenges are due to the various con-\nceptual structures followed in different resources, e.g. network-based resources such\nas WordNet versus dictionary-based resources. Moreover, words have a non-static\nnature and their meanings may undergo changes over time as in old dictionaries of\ncenturies ago in comparison to modern ones. In addition, the microstructure of a dic-\ntionary may contain phrasal texts – “a linguistic composition or utterance” according\n1 https://www.wikipedia.org\n2 https://www.wiktionary.org\n3 http://compling.hss.ntu.edu.sg/omw\n\n1.1 the elexis project\n3\nto (Pettersson, 2017) – particularly in sense deﬁnition and usage examples causing\nfurther complications and variations in meaning, as in metaphors and idioms.\nDictionaries are valuable resources that document the life of words in a language\nfrom various points of view. Senses, or deﬁnitions, are important components of\ndictionaries where dictionary entries, i.e. lemmata, are described in plain language.\nTherefore, unlike other properties such as references, cross-references, synonyms and\nantonyms, senses are unique in the sense that they are more descriptive but also\nhighly contextualized. Moreover, unlike lemmata which remain identical through\nresources in the same language, except in spelling variations, sense deﬁnitions can\nundergo tremendous changes based on the choice of the editor, lexicographer and\npublication period, to mention but a few factors. Therefore, there is a need to create\nsystems to detect semantic similarity between given deﬁnitions and propose align-\nment of word senses. Accordingly, this will facilitate the integration of various re-\nsources and the creation of inter-linked language resources.\nDictionaries are not only vast systematic inventories of information on words, they\nare also important as cultural and historical artifacts. Elaborate efforts are put into\nthe development of lexicographic resources describing the languages of communities.\nAlthough confronted with similar problems relating to technologies for producing\nand making these resources available, cooperation on a larger European scale has\nlong been limited. Consequently, the lexicographic landscape in Europe is currently\nrather heterogeneous. Many lexicographic resources have different levels of structur-\ning and are not equally suitable for application in other ﬁelds. On the one hand, it\nis characterized by stand-alone lexicographic resources, which are typically encoded\nin incompatible data structures due to the isolation of efforts, prohibiting the reuse\nof this valuable data in other ﬁelds, such as NLP, linked open data and the seman-\ntic web, as well as in the context of digital humanities. On the other hand, there is\na signiﬁcant variation in the level of expertise and resources available to lexicogra-\nphers across Europe. This forms a major obstacle to more ambitious, innovative and\ntransnational approaches to dictionaries, both as tools and objects of research.\n1.1\nthe elexis project\nELEXIS – the European Lexicographic Infrastructure4 – proposes to integrate, extend\nand harmonize national and regional efforts in the ﬁeld of lexicography, both modern\nand historical, with the goal of creating a sustainable infrastructure that will enable\nefﬁcient access to high-quality lexical data in the digital age, and bridge the gap\nbetween more advanced and lesser-resourced scholarly communities working on lex-\nicographic resources. The need for such infrastructure has clearly emerged out of the\nlexicographic community within the European network of electronic lexicography.\n4 https://elex.is\n\n4\nintroduction\nThe project develops strategies, tools and standards for extracting, structuring and\nlinking lexicographic resources to unlock their full potential for language technology\nand linked open data, as well as in the context of digital humanities. The project also\nhelps researchers create, access, share, link, analyze, and interpret heterogeneous lex-\nicographic data across national borders, paving the way for ambitious, transnational,\ndata-driven advancements in the ﬁeld, while signiﬁcantly reducing duplication of\neffort across disciplinary boundaries.\nFigure 1.1: An overview of the objectives of the ELEXIS project. Our focus of linking within\nthis project is encircled in dashed red.\nELEXIS is carried out by a balanced consortium with distributed geographical\norigins. It is composed of content-holding institutions and researchers with comple-\nmentary backgrounds such as lexicography, digital humanities, language technology\nand standardization, a crucial feature required to address the multi-disciplinary ob-\njectives of the project. Figure 1.1 presents an overview of the objectives of the ELEXIS\nproject (to the left) along with the outcomes of the project (to the right). In cooper-\nation with CLARIN5 and DARIAH6, it also focuses on deﬁning and providing com-\nmon interoperability standards, workﬂows, conceptual models and data services as\nwell as training and education activities focusing on user needs and cross-disciplinary\nadvances.\nHaving the goal of making lexicographical data more accessible and processable,\nvarious research groups have come together within the ELEXIS project to address\nchallenges in creating a lexicographic infrastructure.\nThis PhD project is deﬁned\nwithin the tasks of the ELEXIS project in general, and in particular, on one of its 10\nwork packages focused on interoperability and linked open data. This work package\nconsists of the following tasks:\n• Common models and protocols for lexicon access\n• Semi-automatic linking of lexical resources\n• Cross-lingual mapping through shared conceptualization\n• Validation and quality assurance for lexical resources\n5 https://www.clarin.eu\n6 https://www.dariah.eu\n\n1.2 motivation\n5\nAmong these tasks, semi-automatic linking has been my topic of interest in this\nthesis. Therefore, my progress kept pace according to the objectives of ELEXIS.\n1.2\nmotivation\nIn order to tackle some of the challenges in the semi-automatic linking of lexical\nresources, we address two main tasks of word sense alignment and translation in-\nference, also referred to as bilingual lexicon induction, in a monolingual and cross-\nlingual setup, deﬁned as follows:\n• Word sense alignment (WSA): This is the task of ﬁnding the alignable senses\namong two entries with the same lemma and the same part-of-speech from two\ndifferent dictionaries. While there is an increasing number of lexical resources,\nparticularly expert-made ones such as WordNet (Miller, 1995) or FrameNet\n(Baker et al., 1998), as well as collaboratively-curated ones such as Wikipedia\nor Wiktionary, manual construction and maintenance of such resources is a\ncumbersome task. This can be efﬁciently addressed by NLP techniques. We\ndemonstrate that what is perceived as a word sense in a dictionary is not es-\nsentially the same in another dictionary, particularly when it comes to deﬁning\nsuch word senses. Therefore, we extend the alignment task to semantic rela-\ntionship detection as well. In this sub-task, we not only determine that two\nword senses should be aligned but also specify the type of semantic relation\nthat they would have. To this end, we use the following semantic relations be-\ntween senses: exact, broader, narrower and related. In the WSA task, the focus\nis on the alignment of monolingual data, a task that we refer to as monolingual\nword sense alignment (MWSA).\n• Translation inference: Given a set of words in two different dictionaries, the\ntranslation inference task aims to align dictionary headwords, regardless of\nspelling variations, that refer to the same senses or concepts in an unsuper-\nvised manner, i.e. without using any previously-aligned resource in the source\nand target languages or any bilingual dictionary.\nThis task is deemed non-\ntrivial and challenging due to the inconstant level of polysemy of words in a\nlanguage and different coverage of senses in various resources (Søgaard et al.,\n2018). To this end, we focus on the data provided by the translation inference\nacross dictionaries (TIAD) shared task (Gracia et al., 2019) and propose a few\ngraph-based approaches. Addressing this task is beneﬁcial not only to align ex-\nisting lexicographical data but also to create new dictionaries for less-resourced\nand under-represented languages that lack such resources. In addition, induc-\ning new translation pairs enables lexicographers to document words more efﬁ-\nciently and therefore, facilitates the dictionary compilation process. Ultimately,\n\n6\nintroduction\nby creating an integrated, linked and interlinked resource, a huge amount of\nhigh-quality lexical data will not only become available to the linguistic, NLP\nand the semantic web community, it will also facilitate cutting-edge research in\ndigital humanities.\n1.3\nresearch questions\nThis thesis attempts to answer the following research questions:\nRQ1. Do graph-based methods improve the performance of lexicographical alignment\nsystems?\nRQ1.1 What are the features in lexical and semantic data that can be effectively\nrepresented in the form of a graph?\nRQ1.2 Do path-based and cycle-based techniques in graph analysis capture poly-\nsemous items when inducing translations across bilingual dictionaries?\nGraphs are powerful structures that have been widely used in various methods\nto represent data and the dependency between data instances. Modeling problems\nas bipartite graphs and aligning such graphs has been previously of interest in many\nproblems where optimization of assignments within a task is required, as in the ef-\nﬁcient assignment of reviewers to manuscripts (Liu et al., 2014) and donor organs\nto patients (Bertsimas et al., 2020). In the same vein, we would like to know how\nlexical and semantic data can be modeled as a graph. To this end, a network struc-\nture, named lexicographic network, is deﬁned where nodes and edges respectively are\nlexicalized items and the relationship between them. This is then used for both of\nthe tasks of word sense alignment and translation inference. This research question\nis addressed in Chapter 4.\nRQ2. How can the output of a monolingual word sense alignment system be evalu-\nated in a multilingual context?\nRQ2.1 What are the characteristics of senses and sense deﬁnitions in modern and\nhistorical dictionaries?\nRQ2.2 How can lexicographers’ expertise be incorporated in the evaluation of\nalignment systems?\nOne of the conclusions of Chapter 4 where the ﬁrst research questions are an-\nswered is the limitation of datasets that can be used for evaluating the performance of\nvarious systems in word sense alignment. To tackle this, the creation of a benchmark\nis described in Chapter 5. This benchmark contains 17 datasets covering 15 languages\nwhere sense deﬁnitions of expert-made resources, such as Webster’s Dictionary, and\n\n1.4 thesis structure\n7\ncollaboratively-curated resources, such as Wiktionary, are manually aligned and an-\nnotated by lexicographers and language experts. The focus of the benchmark is on\nthe alignment of monolingual data of lexical semantic resources in such a way that\nsense deﬁnitions of identical lemmas with part-of-speech tags are aligned. We for-\nmalize linking as inferring links between pairs of senses as exact equivalents, partial\nequivalents, i.e. broader and narrower, or a more loose relation as related, or no rela-\ntion between the two senses. This formulates the problem as a ﬁve-class classiﬁcation\nfor each pair of senses between the two dictionary entries. Furthermore, Chapter 5\nsheds light on the major characteristics of sense deﬁnitions and the necessity to in-\nclude semantic relations, namely exact, broader, narrower and related, to effectively\ncapture the type of relationship that exists between sense deﬁnitions with nuances in\nmeaning.\nRQ3. What features in sense deﬁnitions can be used to create techniques for word\nsense alignment?\nRQ3.1 What similarity metrics perform more effectively to estimate the similarity\nof sense deﬁnitions?\nDo the textual features extracted from deﬁnitions\nperform sufﬁciently efﬁciently in word sense alignment?\nRQ3.2 What is the impact of additional information in sense deﬁnitions, such as\ncross-references or citations, on the alignment task? Does truncating sense\ndeﬁnitions improve the estimation of similarity between a deﬁnitions pair?\nThis research question along with the sub-questions is addressed in Chapter 6\nand concern more practical and experimental aspects of the alignment task. To this\nend, a set of similarity detection techniques based on textual and non-textual fea-\ntures are provided as well as linking constraints. These techniques are implemented\nand integrated in our data alignment tool—Naisc. Moreover, a few experiments are\ncarried out to analyze the performance of various alignment techniques, particularly\nconcerning semantic relation detection.\n1.4\nthesis structure\nFollowing this introduction, a background is presented in Chapter 2 where some of\nthe main lexical semantic resources are introduced. This chapter focuses on the chal-\nlenging issues in aligning various resources, particularly polysemy, and describes\ndifferent types of lexical semantic resources, such as dictionaries, network-based and\nontological ones, along with their characteristics.\nFollowing this, a systematic lit-\nerature review is provided in Chapter 3 where previous studies in linguistic data\nalignment in general, and monolingual word sense alignment, in particular, are re-\nviewed. This chapter also presents the applications of lexical semantic resources in\nNLP, and sheds light on the limitations and hurdles in the ﬁeld.\n\n8\nintroduction\nHaving set the scene in the ﬁrst three chapters, we proceed to the main contribu-\ntions of the thesis that aim to answer and clarify the research questions. To do so, each\nchapter consists of a few sections. Firstly, we sketch the topics on which the chapter\nfocuses where speciﬁc problems are deﬁned and accordingly, the related work is pro-\nvided. We then present our methodologies to address those problems along with the\nresults of experiments and insights based on analyzing the experiments. At the end\nof each chapter, the main contributions and major limitations are discussed. This way,\nreaders can beneﬁt from an in-depth and rapid understanding of the progress that\nhas been made and should be made in the future.\nFinally, the thesis is concluded in Chapter 7 where the limitations and ﬁndings of\nthe current work along with suggestions for future directions are discussed. Figure\n1.2 schematizes the structure of the thesis.\nIntroduction\nBackground\nSystematic Review\nIntroduction\nIntroduction and\nProblem Deﬁnition\nRelated Work\nMethodology\nExperiments\nChapters 4, 5 & 6\nContributions and\nConclusion\nConclusion\nContributions and\nConclusion\nDiscussion\nFigure 1.2: The structure of the thesis\nThe following summarizes the objectives of the remainder of this thesis:\nChapter 2 broadly presents the background knowledge required for the topic of the thesis.\nChapter 3 covers the previous studies in semantic similarity detection and induction with\nthe current applications of lexical semantic resources in NLP.\nChapter 4 entitled “leveraging the graph structure of lexicographical resources” provides\nsolutions based on graph analysis to align word senses and dictionary entries.\nChapter 5 presents a benchmark for monolingual word sense alignment.\nChapter 6 describes the experiments results for monolingual word sense alignment.\n1.5\npublications\nThis thesis is a manuscript-based document where every chapter is based on one\nor more peer-reviewed papers which were published during my Ph.D. Thanks to\n\n1.5 publications\n9\nELEXIS, I had the chance of collaborating closely with other partners, within ELEXIS\nor elsewhere, and address some of the research questions in collaboration with them.\nThis being said, this thesis only provides the contributions and experiments that were\ncarried out by myself. Where contributions of a collaborative nature are relevant to\nthe current work, references will be explicitly provided.\nThe following list provides the publications, ordered based on importance, and\nthe chapter where they appear:\nChapter 4\n– Sina Ahmadi, Mihael Arcan, and John McCrae. Lexical sense alignment us-\ning weighted bipartite b-matching. In Proceedings of the LDK 2019 Workshops.\n2nd Conference on Language, Data and Knowledge (LDK 2019), 2019a\n– Mihael Arcan, Daniel Torregrosa, Sina Ahmadi, and John P McCrae. TIAD\n2019 Shared Task: Leveraging knowledge graphs with neural machine trans-\nlation for automatic multilingual dictionary generation.\nShared Task on\nTranslation Inference Across Dictionaries, 2019b\n– Sina Ahmadi, Atul Kr. Ojha, Shubhanker Banerjee, and John P. McCrae.\nNUIG at TIAD 2021: Cross-lingual Word Embeddings for Translation Infer-\nence. Shared Task on Translation Inference Across Dictionaries, 2021b\nChapter 5\n– Sina Ahmadi, John P. McCrae, Sanni Nimb, Fahad Khan, Monica Mona-\nchini, Bolette S. Pedersen, Thierry Declerck, Tanja Wissik, Andrea Bellandi,\nIrene Pisani, Thomas Troelsgård, Sussi Olsen, Simon Krek, Veronika Lipp,\nTamás Váradi, László Simon, András Gy˝orffy, Carole Tiberius, Tanneke\nSchoonheim, Yifat Ben Moshe, Maya Rudich, Raya Abu Ahmad, Dorielle\nLonke, Kira Kovalenko, Margit Langemets, Jelena Kallas, Oksana Dereza,\nTheodorus Fransen, David Cillessen, David Lindemann, Mikel Alonso, Ana\nSalgado, José Luis Sancho, Rafael-J. Ureña-Ruiz, Kiril Simov, Petya Osen-\nova, Zara Kancheva, Ivaylo Radev, Ranka Stankovi´c, Andrej Perdih, and De-\njan Gabrovšek. A Multilingual Evaluation Dataset for Monolingual Word\nSense Alignment. In Proceedings of the 12th Language Resource and Evaluation\nConference (LREC 2020), Marseille, France, 2020a\n– Ana Salgado, Sina Ahmadi, Alberto Simões, John P. McCrae, and Rute\nCosta. Challenges of word sense alignment: Portuguese language resources.\nIn the 7th Workshop on Linked Data in Linguistics: Building tools and infrastruc-\nture at the 12th International Conference on Language Resources and Evaluation\n(LREC), Marseille, France, 2020\n– Patricia Martín-Chozas, Sina Ahmadi, and Elena Montiel-Ponsoda. Defy-\ning Wikidata: validation of terminological relations in the web of data. In\nProceedings of the 12th Language Resources and Evaluation Conference, pages\n5654–5659, 2020\n– Sina Ahmadi, Mathieu Constant, Karën Fort, Bruno Guillaume, and John P.\nMcCrae. Convertir le Trésor de la Langue Française en Ontolex-Lemon : un zeste\n\n10\nintroduction\nde données liées. LIFT 2021 : Journées scientiﬁques de linguistique informatique,\nformelle & de terrain, December 2021a\n– Sina Ahmadi, Mihael Arcan, and John McCrae. On lexicographical net-\nworks. In Workshop on eLexicography: Between Digital Humanities and Artiﬁcial\nIntelligence, 2018\nChapter 6\n– Sina Ahmadi and John P. McCrae. Monolingual word sense alignment as\na classiﬁcation problem. In Proceedings of the 11th Global Wordnet Conference,\nGWC 2021, University of South Africa (UNISA), Potchefstroom, South Africa,\nJanuary 18-21, 2021, pages 73–80. Global Wordnet Association, 2021. URL\nhttps://aclanthology.org/2021.gwc-1.9/\n– Sina Ahmadi, Sanni Nimb, John P. McCrae, and Nicolai H. Sørensen. To-\nwards Automatic Linking of Lexicographic Data: the case of a historical and\na modern Danish dictionary. In The XIX EURALEX International Congress of\nthe European Association for Lexicography, Alexandroupolis, Greece, 2020b\n– John P. McCrae, Sina Ahmadi, Seung-bin Yim, and Lenka Bajˇceti´c. The\nELEXIS system for monolingual sense linking in dictionaries. Proceedings\nof Seventh Biennial Conference on Electronic Lexicography (eLex 2021), 2021\n– Ilan Kernerman, Simon Krek, John P. McCrae, Jorge Gracia, Sina Ahmadi,\nand Besim Kabashi, editors. Globalex Workshop on Linked Lexicography, Lan-\nguage Resources and Evaluation LREC 2020, France, 2020b\nFurthermore, the following articles were published during my Ph.D. on a topic\nrelated to the thesis, even though not included in the thesis as they don’t address the\nresearch questions:\n• John P. McCrae, Theodorus Fransen, Sina Ahmadi, Paul Buitelaar, and Kous-\ntava Goswami. Toward an integrative approach for making sense distinctions.\nFrontiers in Artiﬁcial Intelligence, 5, 2022. ISSN 2624-8212. doi: 10.3389/frai.2022.\n745626. URL https://www.frontiersin.org/article/10.3389/frai.2022.745626\n• John P. McCrae, Carole Tiberius, Anas Fahad Khan, Ilan Kernerman, Thierry De-\nclerck, Simon Krek, Monica Monachini, and Sina Ahmadi. The ELEXIS interface\nfor interoperable lexical resources. In Proceedings of the sixth biennial conference\non electronic lexicography (eLex), pages 642–659, Sintra, Portugal, 10 2019b. URL\nhttps://elex.link/elex2019/wp-content/uploads/2019/09/eLex_2019_37.pdf\n• Mihael Arcan, Daniel Torregrosa, Sina Ahmadi, and John P McCrae. Inferring\ntranslation candidates for multilingual dictionary generation with multi-way\nneural machine translation. In Proceedings of the Translation Inference Across Dic-\ntionaries Workshop (TIAD 2019), 2019a\n• Sina Ahmadi, Hossein Hassani, and John P. McCrae. Towards electronic lexi-\ncography for the Kurdish language. In Proceedings of the sixth biennial conference\non electronic lexicography (eLex), pages 881–906, Sintra, Portugal, 10 2019b\n\n1.5 publications\n11\n• Giulia Speranza, Carola Carlino, and Sina Ahmadi. Creating a multilingual\nterminological resource using linked data: the case of archaeological domain in\nthe Italian language. In Proceedings of the Sixth Italian Conference on Computational\nLinguistics (CLiC-it), Bari, Italy, 11 2019\n\n\n\n2\nB A C KG R O U N D\n2.1\nintroduction\nLanguage and linguistic resources are important components of many applications in\nNLP and computational linguistics. Over the past few decades, there have been con-\nsiderable efforts in the development of language resources with a particular focus on\nincreasing the coverage of the resources and the precision of the lexical and semantic\ninformation. The followings are some of the main language resources:\n• Corpora, which are a digital collection of text, audio or multimedia\n• Language descriptions such as grammar and formal modeling\n• Lexical semantic resources which are curated following a lexical or conceptual\nparadigm such as dictionaries and network-based resources\n• Ontologies, terminological resources and semantic lexica\n• Language models which are trained on large corpora\n• Knowledge graphs and knowledge bases\nConsidering language resources available in electronic form, there are a few dis-\ntinctive properties that differentiate them. Such properties are mainly related to the\ncontent and the theoretical framework based on which the resource is conceptualized\nand created. In addition to conceptualization, resources vary in terms of the system-\natic coverage of lexical and semantic information. For instance, a dictionary does not\nsystematically provide synonyms of all entry words, while WordNet (Miller, 1995)\ndoes. Another example is dictionary and encyclopedia; while a dictionary focuses on\nthe linguistic properties of linguistic units represented by lemmas of any word class\ndescribing their use within a language, an encyclopedia provides the properties of\nobjects of world knowledge designated by lemmas. Consequently, it is necessary to\nassess various properties of language resources, especially lexical semantic resources\nwhich are created according to an underlying theoretical framework.\nCreating and maintaining language resources for a constantly changing phenomenon\nlike a natural language requires much time and effort. Therefore, many of the expert-\nmade resources have restrictions over open access and cannot be used within appli-\ncations that voraciously require data to be trained and evaluated. As such, beyond\nthe expert-made resources such as traditional dictionaries, thesauri and terminolo-\ngies, more collaboratively-curated resources are being created and enriched nowa-\ndays thanks to the advances in information technology. Perhaps the most prominent\n13\n\n14\nbackground\nexamples of such collaboratively-curated resources are Wikipedia1 as a free encyclo-\npedia and Wiktionary2 as a free dictionary. The extensive approach of describing\nentries in an encyclopedia makes it possible to translate them into other languages,\nwhile this may not be the case for all dictionary entries, and also act as a corpus for\nthe language. As such, encyclopedias such as Wikipedia can be beneﬁcial as a lex-\nical semantic resource (LSR) (Zesch et al., 2007) but also as a corpus (Ghaddar and\nLanglais, 2018) and have widely contributed to the advances in language technology.\nThis being said, encyclopedias encompass a vast range of encyclopaedic information\nbeyond lexical resources (Zock and Biemann, 2020).\nWith the expansion of collaboratively-curated resources such as Wiktionary, pro-\ncessing lexicographical resources automatically and efﬁciently is of high importance\nrecently in computational lexicography, computational linguistics and NLP. Nonethe-\nless, the utility of language resources, in general, and the extent to which they con-\ntribute to speciﬁc tasks in languages is yet to be fully explored (Mirkin et al., 2009).\nThis is partially due to the coverage of lexical and semantic information in a speciﬁc\nresource, but also the conceptualization that provides a more convenient structure\nfor the computer to process linguistic data. For instance, the network-based structure\nof WordNet as well as its semantic richness has made it a popular resource in many\nlanguage technology applications.\nOur primary goal in this chapter is to provide a necessarily brief but essential\nbackground of language and linguistic resources. Our focus is particularly on those\nresources which have been used in NLP applications, such as WordNet, or are virtu-\nally addressing a speciﬁc challenge of interest in computational semantics, such as\ngenerative lexicons. This being said, there are many other language resources such as\nVerbNet (Schuler, 2005), PropBank (Kingsbury and Palmer, 2002) or Treebank (Mar-\ncus et al., 1993) that are not discussed in the chapter due to either the common fea-\ntures that are covered in other resources or their irrelevance to the context of this\nthesis.\nTo do so, we ﬁrst introduce LSRs along with the crucial property of polysemy.\nThen, a few types of lexical semantic resources are described, namely dictionar-\nies, network-based resources, Explanatory Combinatorial Dictionary (Mel’ˇcuk, 2006),\nGenerative Lexicon (Pustejovsky, 1995) and Natural Semantic Metalanguage (Wierzbicka,\n1996). Moreover, a description of ontologies, terminologies, knowledge graphs and\nlanguage models is provided. We believe that these language resources are of im-\nportance, given their current widespread usage and promising future in many NLP\napplications. It is important to note that polysemy and sense deﬁnitions in dictionar-\nies are of particular interest to the context in which this thesis is deﬁned. Therefore,\nparticular attention is paid to those topics.\n1 https://www.wikipedia.org\n2 https://www.wiktionary.org\n\n2.1 introduction\n15\n2.1.1\nLexical Semantic Resources\nLexical semantic resources (LSRs) are knowledge repositories that provide the vocab-\nulary of a language in a descriptive, structured and conceptualized way. According\nto the literature, such resources are also often referred to as lexicosemantic resources.\nLexical semantics focuses on the representation of meanings of lexical units and their\nvariability based on the context. A lexical unit denotes a linguistic entity that can\nexpress a speciﬁc meaning either by lexemes, e.g. ‘window’, or non-compositional\nphrases as in idioms, e.g. “not someone’s ﬁrst rodeo”. LSRs are differentiated based\non the type of theory of lexicon, i.e. the theory that determines how to conceptual-\nize and structure meanings of words. Therefore, their applications within language\ntechnology depend on the conceptual structure and the lexical encoding, i.e. lexical-\nization.\nThe conceptualization of many of the previously proposed LSRs has been moti-\nvated by various lexical semantic theories inﬂuenced by linguistic, psychological and\ncognitive concepts (Geeraerts, 2010). Such cognitively and psychologically motivated\nconceptualizations have created a wide range of resources beyond traditional dictio-\nnaries that have been deemed beneﬁcial in many applications in language technology\nsuch as information retrieval (Shah and Croft, 2004), question answering (Pasca and\nHarabagiu, 2001), semantic role labeling (Zhou and Xu, 2015) and word-sense disam-\nbiguation (Pal and Saha, 2015).\nThe semantic analysis of LSRs can be carried out from various points of view,\nincluding cognitive, computational and philosophical. According to the structural-\nist tradition, two notions of paradigmatic and syntagmatic relations are taken into\naccount. In this approach, the paradigmatic analysis focuses on the paradigmatic\nrelation between words, such as synonymy, antonymy, meronymy, etc. On the other\nhand, syntagmatic relations consider syntactic collocations that are related to individ-\nual words as in “put someone on a pedestal”.\nSimilarly, computational methods have been used for semantic analysis (Bird et al.,\n1995). The main goal in applying NLP methods to semantic analysis is to improve\nmachine understanding and a wide range of related tasks, such as information re-\ntrieval, machine translation and human-machine interaction. To mention a few meth-\nods among the previously proposed ones, latent semantic analysis which uses sta-\ntistical co-occurrence information between words and phrases (Kou and Peng, 2015),\nexplicit semantic analysis which incorporates human knowledge, for instance using\nWikipedia, to represent semantic associations (Milne, 2007; Yeh et al., 2009) and con-\ntextual and word embeddings by language modeling (Vuli´c et al., 2020b).\nTo further clarify the notion of polysemy, which plays a pivotal role in lexical\nsemantics, we describe it in the following section.\n\n16\nbackground\n2.1.2\nPolysemy\nPolysemy is the characteristic of different and multiple meanings of a word. Unlike\nmonosemous words for which only a univocal meaning is available, polysemous lexi-\ncal items emerge in a nuance of semantically related meanings which are identiﬁable\nto the speaker within context. According to Rey-Debove (2012, p. 256), polysemy\nis the “the main subject of semantics”. Along with homonyms, polysemous items\nare considered as the major sources of lexical ambiguity. According to Lyons (1977),\nthe lexical ambiguity continuum is delimited to homonymy and polysemy. Unlike\nhomonyms which are often deﬁned as separated lexical entries in a dictionary, pol-\nysemous entries are represented as a single entry.\nFor example, in the following\nsentences based on the Collins Dictionary3, different meanings of ‘heart’ are deﬁned\nwithin one entry:\nheart (noun)\nA The bullet had passed less than an inch from Andrea’s heart.\nB The only sound inside was the beating of his heart.\nC Alik’s words ﬁlled her heart with pride.\nD The heart of the problem is supply and demand.\nEven though not available to the same extent for all words, polysemy is a com-\nmon phenomenon that has been traditionally deﬁned depending on the relatedness\nof various meanings, register, domain and historical considerations regarding the et-\nymology of word senses. The notion of relatedness in meaning has been the key to\ngroup word senses as polysemous. As such, homonyms are said to have a contrastive\npolysemy as they do not refer to the same concepts. Figure 2.1 shows the degree\nof polysemy in the French, German and Italian lexicographical data on Wiktionary4.\nBased on this analysis, multiword expressions (MWE) appear to be less polysemous\non average in comparison to the set of other types of lexical entries including words\nand afﬁxes. Similarly, among the grammatical categories of noun, adjective and verb,\nthe latter has the highest number of senses available. It is important to note that even\nthough Wiktionary is not a comprehensive dictionary and is being modiﬁed con-\nstantly by communities, it contains a considerable number of lexical entries making\nthis analysis suggestive.\nDeﬁning various types of polysemy has remained a matter of theoretical discus-\nsions with not essentially all of them providing distinctive characteristics to determine\npolysemy (Geeraerts, 1993; Lyons and John, 1995). One of the prevailing theories is\nthe classiﬁcation of polysemy into regular polysemy, also known as systematic poly-\nsemy5 (Dölling, 2020) and irregular polysemy. In regular polysemy (Apresjan, 1974),\n3 https://www.collinsdictionary.com/dictionary/english/heart\n4 https://www.wiktionary.org\n5 Systematic polysemy is also deﬁned on its own by Buitelaar (1998).\n\n2.1 introduction\n17\nFigure 2.1: Degree of polysemy of French, German and Italian lexicographical data on Wik-\ntionary (dump of early 2022 using Dbnary (http://kaiko.getalp.org))\npolysemous items share a common range of lexical items that are semantically and\nsystematically related. Regular polysemy is formally deﬁned as follows:\n“Polysemy of a word A with the meaning ai and aj is called regular if,\nin the given language, there exists at least one other word B with the\nmeaning bi and bj , which are semantically distinguished from each other\nin exactly the same way as ai and aj and if ai and bi, aj and bj are\nnon-synonymous.” (Apresjan, 1974, p. 16)\nIn other words, regular polysemy may be modeled based on lexical rules and\nextended based on patterns of sense extension. In this sense, metonyms can be highly\nsystematic, as in ‘animal’ for ‘meat of animal’, e.g. ‘rabbit’ and ‘armadillo’, ‘fruit’ for\n‘tree species’, e.g. ‘pear’ and ‘cherry’, and ‘ﬂower’ for ‘plant’, e.g. ‘rose’ and ‘daffodil’\n(Cruse, 2010). In the example above, ‘heart’ in all the sentences represents regular\npolysemy, despite sentence C being a metaphor and sentence D being a metonym, as\nthere is a word as ‘B’ in the deﬁnition like ‘core’ with two meanings of ‘the tough\ncentral part of fruits’ (bi) and ‘the part of something that is central to its existence’\n(bj). Unlike simple metaphors as ‘ﬁll one’s heart with something’ to refer to ‘making\nsomeone feel something’, metaphors have generally the least systematic polysemy\ndue to the unpredictable meaning of words, as in ‘wear your heart on your sleeve’\nto say ‘to openly display one’s emotions or sentiments’. Although such irregular\npolysemy can affect all words, metaphors are widely known to be idiosyncratic and\nthe most important type of irregular polysemy.\n\n18\nbackground\nIn the same vein, Cruse (2010, p. 110) describes two main relations between pol-\nysemes: linear and non-linear.\nIn the ﬁrst, there is a specialization-generalization\nrelation where one of the polysemes refers to a more specialized meaning, i.e. hy-\nponyms or meronyms, in comparison to the other one. For instance, the deﬁnitions\nof two senses of ‘demand’ (noun) in the Longman Dictionary of American English\n(Mayor, 2009) as ‘the need or desire that people have for particular goods and services’ and\n‘a very ﬁrm request for something that you believe you have the right to get’ refers to a\nlinear relation. This relation can be further divided into sub-categories according to\nsemantic overlap, namely autohyponymy, automeronymy, autosuperordination and\nautoholonymy. On the other hand, non-linear relations denote polysemes that have\na resemblance or relevance connection as in metaphors, e.g. ‘to run circles around\nsomeone’, and metonyms as in ‘the Pentagon’ to refer to the US military leadership.\nTherefore, metonymic polysemy seems to ﬁt the best into the deﬁnition of regular\npolysemy while metaphorically-motivated polysemy appears closer to homonymy in\nthe lexical ambiguity continuum (Klepousniotou and Baum, 2007, p. 11).\nPolysemy is one of the most important notions based on which various LSRs\nare deﬁned. In fact, lexical semantics has been driven by the compelling questions\nof how to deﬁne meaning to represent word senses in a systematic way, based on\npurely linguistic, cognitive, communicative notions or based on an interdisciplinary\nsetup.\nThis has motivated researchers to propose various theoretical frameworks\nwhere meanings may be considered as atomic concepts or of compositional nature,\ni.e. made of smaller parts. For instance, the enumerating approach of word senses\nin traditional dictionaries is called into question in the Generative Lexicon theory\n(Pustejovsky, 1995) by putting forward a compositional approach where senses can\nbe generated. Furthermore, dealing with polysemy has been one of the main chal-\nlenges in NLP, as demonstrated in word sense disambiguation (Stevenson and Wilks,\n2003) and delineating lexical ambiguity (Aina et al., 2019). We will see in more detail\nin the following sections how different resources model polysemy and sense represen-\ntation. Falkum and Vicente (2015); Vicente and Falkum (2017); Béjoint (1990) provide\nfurther discussions regarding the theoretical debates on polysemy and approaches to\ndistinguish between monosemy and different types of polysemy.\n2.2\ndictionaries\nOne of the best known LSRs are dictionaries which have been used as inventories\nfor documenting human language since ancient times.\nThere is a wide range of\ndictionaries that are published based on language, as in monolingual versus bilingual\ndictionaries, level of proﬁciency in the language, as in learner’s dictionary, the ﬁeld\nof expertise, such as the Oxford Dictionary of World Religions (Bowker, 1997), the\netymology of words, such as the Etymological Dictionary of Greek (Beekes, 2009), and\n\n2.2 dictionaries\n19\na speciﬁc period when the language was spoken, such as the Ordbog over det danske\nSprog6 (“Dictionary of the Danish Language”) that documents the Danish language\nfrom 1700 until 1955. Although information technology has facilitated lexicography\nin a vast number of ways, the drudgery of collecting words and compiling words\nseems to have remained the same nonetheless.\nAccording to Laporte (2013), there are two requirements for dictionaries to be used\nin NLP: readability of information and general architecture that facilities processing\nlexicographical content. We believe that these requirements can be generalized, to a\nlesser or greater extent, to all types of LSRs and are used as the leading factors in\ncreating relevant standards to access resources and publish them.\n2.2.1\nLexicon vs. Dictionary\nAlthough the two terms of lexicon and dictionary are sometimes informally used\ninterchangeably, the notion of lexicon refers to a different concept than that of a dic-\ntionary. According to (Ježek, 2016, p. 16),\nA dictionary is a concrete object, typically a book, in either printed or\nelectronic format, whereas the lexicon is an abstract object, that is, a set of\nwords with associated information, stored in our mind and described in\nthe dictionary.\nThe difference between lexicon and dictionary is analogous to grammar and gram-\nmar books. While the book provides information based on a topic or a consultation\nmethod, such as providing entries in alphabetical order, the concept of the lexicon is\nunderstood as any type of word or morpheme based on lexical structures. Such lexi-\ncal structures can be meaning associations such as plow, sow and plant, morphological\nproperties such as relate, relationship and unrelated, syntactical behavior such as nouns,\nverbs and prepositions and semantically related words such as ask, demand and inquire.\nTherefore, a dictionary is a reference book that tries to document and collect the body\nof language, i.e. vocabulary, which is used in a language and may not always be\ncomplete and comprehensive with respect to a language lexicon.\nFigure 2.2 provides an illustration created by Lehmann (2020) to highlight the\ndifferences between the aforementioned analogy. According to the same source, “the\nlexicon is that component of the signiﬁcative system of a language which represents\nthe relation between signiﬁer and signiﬁed of signs insofar as it is not subject to rules”.\nIn addition, there are two polar ways of accessing language signs. Holistic access is\nmade to idiosyncratic links between expression and content. Such idiosyncratic signs\nare inventoried in the lexicon. On the other hand, analytical access is made to regular\nlinks between expression and content and is formed in grammar. Furthermore, the\nhorizontal dimension of the diagram indicates the more or less holistic and analytical\n6 https://ordnet.dk/ods\n\n20\nbackground\naccess to linguistic signs in lexicon and grammar. Both lexicon and grammar are\ntraversed by levels of complexity, which form the vertical axis of the diagram, in\nparticular, the phrastic level and the word level.\nFigure 2.2: The relationship between lexicon and grammar according to Lehmann (2020)\nThis conceptual distinction between lexicon and grammar versus dictionary and\ngrammar book is of importance in the discussions in the upcoming sections.\n2.2.2\nContent\nThe content of a dictionary is usually thought of from two structural points of view:\nmacro-structure and micro-structure (Atkins and Rundell, 2008, p. 160). The ﬁrst notion\nfocuses on the organization of lexical items and the type of lemma headwords and\nvocabulary to be included in the body of the dictionary. Headwords can be simple\nwords e.g. ‘sacrilegious’, abbreviations e.g. ‘PDF’, bound afﬁxes e.g. -ment and multi-\nword expressions e.g. ‘pang of conscience’. Moreover, the vocabulary type may vary\nbased on domain, style, register, dialect, time and, etc. On the other hand, micro-\nstructure refers to the internal structure and content of each lexical entry. Oftentimes,\nlexicographers take morphological forms based on rules of word formation, seman-\ntics and syntax into account in designing both these structures. Figure 2.3 illustrates\nthe micro-structure of the entry ‘beauty’ in the Longman Dictionary of American En-\nglish (Mayor, 2009) containing pronunciation, grammatical information, etymology,\nphraseology, deﬁnitions, and example labels such as ‘old-fashioned’, ‘colloquial’ and\n‘informal’. It should be noted that the richness of such information and the compo-\nnents of the micro-structure depend on the entry, the type of dictionary (monolingual\nvs. bilingual) and the lexicographer’s approach.\nAlthough not equally provided for all entries, semantic relationships, including\nlexical relations such as synonymy and antonymy and conceptual relations such as\nhyponymy and meronymy, are occasionally provided in a dictionary as well. Such\n\n2.2 dictionaries\n21\ninformation is not systematic and may not come within a speciﬁc data structure. For\ninstance, synonyms or near-synonyms such as ‘mistake’ and ‘slip’ may be provided\nas cross-references, i.e. cf, or explicitly as synonyms. That said, there are other types\nof relationships that are usually not included in lexicographical resources; e.g. tem-\nporal relationships such as happens-before as in enroll-graduate, marry-divorce\nand detain-prosecute deﬁned in VerbOcean (Chklovski and Pantel, 2004), associa-\ntive relationships as in cat-purr, typical instrumentality as in nail-hammer, locative\nrelationships as in priest-church and causal relationships as in sand-snooze (Hirst,\n2009, p. 7).\nAkin to a dictionary in structure but chieﬂy focused on semantic relations, the-\nsauri are a speciﬁc type of dictionaries that provide words based on their semantic\nrelationship. The initial attempt to create such a semantic resource for English was\nRoget’s Thesaurus of English Words and Phrases (Roget, 2014). While Roget’s the-\nsaurus provides general-usage words, many other thesauri with controlled vocabular-\nies adopted for classiﬁcation of technical documents extend the relationships between\nterms to equivalent, broader, narrower and related, as well.\n2 very good, or giving you great pleasure: beautiful\nmusic | The weather was beautiful.\nbeau·ty /'byuÔi/ n. (plural beauties) 1 [U] a qual-\nity that people, places, or things have that makes\nthem very attractive to look at: a woman of great\nbeauty | the beauty of Yosemite 2 [U] a quality that\nsomething such as a poem, song, etc. has that gives\nyou pleasure: the beauty of Keats’s poetry 3 [C]\n(informal) something that is very good or impres-\nsive: His new car’s a beauty. 4 the beauty of sth\nis... used to explain why something is especially\ngood: The beauty of this exercise is that you can do\nit anywhere. 5 [C] (old-fashioned) a woman who is\nvery beautiful [ORIGIN: 1200—1300 Old French\nbiauté, from Latin bellus “pretty”]\n'beauty sa\"lon also 'beauty \"parlor n. [C] a\nSALON\nbea·ver /'bivø/ n. [C] a North American animal\nthat has thick fur, a wide flat tail, and cuts down\ntrees with its teeth   see picture at RODENT\nbe·bop /'bibAp/ n. [U] a style of JAZZ music\nbe·came /bI'keIm/ v. the past tense of BECOME\nbe·cause /bI'kOz, -'köz/ conjunction used when\nyou are giving the reason for something: You can’t\ngo because you’re too young. | We weren’t able to\nhave the picnic because of the rain. | They liked\nhim simply because he could play basketball. | He\nmoved to Florida partly/largely/mainly because he\nliked the weather. [ORIGIN: 1300—1400 by cause\n(that)]\nTHESAURUS\ndue to – used when giving the reason why\nsomething happened: The flight was delayed due\nto bad weather.\nsince – used when giving the reason why\nsomeone decides to do something: Since it was\ngetting late, we decided to go back home.\nthrough – because of something: They\nsucceeded through a combination of hard work\nand determination.\nout of – because of a feeling: I went there out of\ncuriosity.\nthanks to – because of what someone has\ndone, or because something exists: Today, thanks\nto the Internet, you can find out information about\nalmost anything. | We’re late, thanks to you.\n  just because ... (it) doesn’t mean ... at JUST1\nbeck·on /'bEk@n/ v. [I,T] to move your hand to\nshow that you want someone to move toward you:\nHe beckoned her to join him. | He beckoned to her.\nsomeone or something: Whatever became of\nGrandma’s dishes? | No one knows what will\nbecome of him when his mother dies.\nUSAGE\nBecome is used in both written and spoken\nEnglish: Their music has become very popular. |\nHe quickly became very rich.\nGet and go are less formal than become, and\nare used more often in spoken English: I’m getting\ntired. | Have you gone crazy?\nBecome can be used in front of an adjective or\na noun, but get and go are used only in front of\nan adjective: She wants to become a lawyer. |\nPeople are becoming worried about the future of\nour planet. | It’s getting dark. | Beethoven went\ndeaf when he was 40 years old.\nbe·com·ing /bI'kömIÎ/ adj. (old-fashioned) a\npiece of clothing, HAIRSTYLE, etc. that is becoming\nmakes you look attractive\nbed1 /bEd/ n. 1 [C,U] a piece of furniture for\nsleeping on: a double bed (=a bed for two people) |\na single bed (=a bed for one person) | I was lying in\nbed reading. | She looked like she had just gotten\nout of bed. | What time do you usually put the kids\nto bed? | Jamie usually goes to bed around seven\no’clock. | Sara, have you made your bed yet\n(=pulled the sheets, etc. into place)? | Come on, it’s\ntime for bed (=time to go to sleep). 2 go to bed\nwith sb (informal) to have sex with someone 3 [C]\nthe ground at the bottom of the ocean, a river, or a\nlake: a river bed 4 [C] an area of ground that has\nbeen prepared for plants to grow in: flower\nbeauty\n80\nB\nheadword (red color \nfor frequent words, \notherwise blue)\ndefinition\nplural inflection of noun\npart-of-speech tag\nuncountable (syntactic property)\nIPA pronunciation\nusage examples\netymology\ncollocations\nidiom\nFigure 2.3: The micro-structure of the entry ‘beauty’ in the Longman Dictionary of American\nEnglish\nHeadwords\nAs a general rule, the lemma form of word forms and lexemes are used as head-\nwords. Depending on the morphological complexity of a language, the identiﬁca-\ntion of headwords can be a challenging task.\nFor instance, retrieving the lemma\nof inﬂected word forms which are textually close to their lemma form is easier as in\n‘drinking’ vs. ‘drink’ than in some word forms that are inﬂected based on allomorphs,\nas in the Kurdish word bêje (say.imp.2sg) vs. gotin (say.inf). Furthermore, the domi-\nnance of the graphemic representation to access a word, described as “orthographic\nsupremacy” by (Lew, 2012, p. 346), further poses challenges in providing headwords\nin a dictionary. Akin to this, spelling variation is another challenge, particularly for\ndictionaries compiled in different time periods, as in the modern and old Danish\n\n22\nbackground\ndictionaries, Den Danske Ordbog7 and Ordbog over det danske Sprog. Moreover, there\nare different views and problems related to multi-word expressions and homographs\nas dictionary entries (Gantar et al., 2019). The latter is speciﬁed in both printed and\nelectronic dictionaries, for example by using a superscript number as in lead1.\nSenses\nWord senses, or simply senses, form the basic unit of the organization of the micro-\nstructure of a dictionary. Sense indicators are provided to distinguish between var-\nious senses of a headword. In some dictionaries, such as the Longman Dictionary\nof American English (Mayor, 2009) or the Trésor de la Langue Française8, senses are\nordered according to their frequency and time period (old to modern senses) in the\nlanguage.\nDespite efforts to extract senses automatically from large corpora (McCarthy et al.,\n2004), there is no decisive way to determine sense distinctions from a theoretical point\nof view to such an extent that many do not believe in the nature of senses even,\nas Kilgarriff (1997) states in his article entitled ‘I don’t believe in word senses’. A\nvery well-known example is the word ‘bank’ (noun) which has different meanings as\nin ‘river bank’ and ‘ﬁnancial institution’. This is referred to as the Bank Model by\nKilgarriff (1992b) to highlight the complexities in polysemy and determining various\nsenses of a word. Nonetheless, senses are a part of dictionaries and are listed using\nan enumerative approach (Lew, 2013). Traditionally, senses derived from the same\netymological source are considered polysemous in dictionaries; otherwise, separate\nentries are deﬁned.\nFurthermore, senses in some comprehensive dictionaries are typically organized\nin a hierarchy where semantically related concepts are provided as subsenses to a\nmain sense, as illustrated in Figure 2.4 in the monolingual modern Danish dictionary,\nDen Danske Ordbog. However, the sense granularity and the exact distinctions drawn\nbetween both main senses and subsenses of a lemma might differ quite a lot across\nmonolingual dictionaries. Closely related concepts, e.g. the many cases of regular\npolysemy in the language as discussed by Buitelaar (2000); Pustejovsky (2017) and\nMcCrae et al. (2022), might be expressed as separate subsenses, but might also be\nindirectly included in the main senses. This varies not only across dictionaries but\nalso within the same dictionary. Furthermore, the sense granularity of a dictionary is\ninﬂuenced by speciﬁc editorial guidelines, such as the cases where formatting takes\nprecedence over comprehensiveness considerations.\nThat being said, determining\nwhich senses are to be included follows the subjective and individual judgments\nmade by each lexicographer (Kilgarriff, 1997).\nIn a recent study, McCrae et al. (2022) shed light on sense distinction from a com-\nputational point of view where an approach for making such distinctions is proposed.\n7 https://ordnet.dk/ddo\n8 https://www.atilf.fr/ressources/tlﬁ\n\n2.2 dictionaries\n23\nBased on this approach, sense distinction can be facilitated by integrating various ap-\nproaches such as formal, cognitive, intercultural and distributional, among which\nthe last one is widely used in practice nowadays. Thanks to such an approach, lex-\nicographers can carry out quantitative and qualitative analyses of sense distinctions.\nMoreover, there are many techniques to distinguish and identify different senses of\na word using topic modeling (Lau et al., 2014), word sense induction (Cook et al.,\n2013) and contextualized word embeddings (Zhou and Bollegala, 2021; Gessler and\nSchneider, 2021), to mention but a few.\n1.\n1.a\n1.b\n1.c\n1.\n1.a\n1.\n1.a\nafstand substantiv, fælleskøn\nVis overblik\nBØJNING\n-en, -e, -ene\nUDTALE\n!\"#$%&'()*+,\nOPRINDELSE\nefter tysk Abstand\nBetydninger\nrumlig udstrækning der adskiller to punkter, linjer eller flader, målt som længden af en linje eller rute mellem dem\nSYNONYMER\ndistance\nsjældent frastand\nhul1\ngab2\nspring\nplads\ntom plads\nledig plads...vis mere\nGRAMMATIK\nafstand mellem NOGET/NOGEN og NOGET/NOGEN\n afstand af/på MÅL\n afstand fra/til NOGET\nEKSEMPLER\nindbyrdes afstand\n den geografiske afstand\n bedømme/måle afstanden\n på lang afstand\n i/på behørig afstand\n i/på passende\nafstand\n i/på sikker afstand\nVi passerede skibene i en afstand af ca. 40 meter HvidovA1989\nBrevduer kan finde hjem over lange afstande skoleb1991\ntidsmæssig udstrækning der adskiller to begivenheder\ntidsrum\ntidsinterval\ninterval\ntidsafstand\ntidsmargin...vis mere\nhan vidste at såret til trods for de tyve års afstand endnu ikke var lægt SvÅMad89\nOVERFØRT mangel på fortrolighed, kontakt eller personligt engagement\nSYNONYM\ndistance\nmodsætningsforhold\ndelte meninger\npåstand mod påstand\nen strid om ord\nordstrid\nuforenelighed...vis mere\nGRAMMATIK\nisær i singularis\nEKSEMPLER\nen vis afstand\nbrugen af fagsprog skaber en afstand mellem læge og patient fagb1992\nOVERFØRT forskel eller modsætningsforhold mellem to parter eller størrelser\nforskellighed\ndivergens\nskisma\nkløft\ngrøft\ngab2...vis mere\nafstanden mellem regeringen og oppositionen er mindsket BT1991\nDenne afstand mellem løfter og realiteter kalder jeg svindel BerlT1991\nFaste udtryk\nholde afstand\nholde sig passende langt væk\nfjerne sig\ngå afsides\ngå i en stor bue udenom...vis mere\nGRAMMATIK\nNOGEN holder afstand (til NOGET/NOGEN)\nså sneg de sig småløbende efter ham, mens de dukkede sig og hele tiden sørgede for at holde afstand til deres offer KiHols92\nOVERFØRT undgå for stor fortrolighed eller personligt engagement\nholde for sig selv\nbeholde for sig selv\nholde kortene tæt (ind) til kroppen\nikke ville være ved\nikke ville stå ved\nholde tand for\ntunge...vis mere\njeg havde en følelse af, at jeg skulle holde afstand, så hun ikke opslugte mig helt AltDam1992\ni miles omkreds\neller\npå miles afstand\ninden for stor afstand; langt væk\npå den ene led ...vis mere\ndenne radio er en ganske særlig radio, sagde far. – Den vil kunne høre alt, hvad politiet taler om i miles omkreds GrHolm89a\nlægge afstand til\nøge afstanden til\nDen 28-årige tidligere OL-svømmer lagde afstand til konkurrenten, og nåede først hjem BerlT1990\nOVERFØRT undgå følelsesmæssig eller holdningsmæssig forbindelse til\nSYNONYM\ndistancere sig fra\nignorere\nkøre sit eget løb\ndistancere sig\ntage afstand\nkøre friløb\nhytte sit eget skind...vis mere\nPå det seneste har LO også forsøgt at lægge afstand til Socialdemokratiet BT1991\nVis forkortet\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nORD I NÆRHEDEN\nafstand — Den Danske Ordbog\nhttps://ordnet.dk/ddo/ordbog?query=afstand\n1 of 2\n28/10/2021, 12:25\nFigure 2.4: The noun ‘afstand‘ (distance) in the Danish monolingual dictionaries, Den Danske\nOrdbog (https://ordnet.dk/ddo/ordbog?query=afstand)\nDeﬁnitions\nIn addition to senses, sense deﬁnitions are principal components of monolingual dic-\ntionaries describing various meanings of words in plain text. Since antiquity, there\nhave been many theories and discussions on how to deﬁne a concept, i.e. deﬁniendum,\nand the words and phrases which are used for this purpose, i.e. deﬁniens. Hanks\n(2016) provides a description of such theories from historical, logical, and lexico-\ngraphical points of view starting from Aristotle up to the latest theories, namely\nthose revolving around the generative lexicon. Nevertheless, deﬁnitions are one of\nthe major components of monolingual dictionaries.\n\n24\nbackground\nType\nParadigm\nDeﬁnition\nExample\nPurpose-based\nLexical\n“that sort of word-thing deﬁni-\ntion in which we are explaining\nthe actual way in which some ac-\ntual word has been used by some\nactual persons” (Robinson, 2003,\np. 35)\natmosphere (noun): the gaseous\nenvelope\nof\na\ncelestial\nbody\n(Merriam-Webster)\nStipulative\nattributes a meaning to a word\ndepending on the context and\nwhat one intends a word to mean,\nsometimes without taking com-\nmon usages into account (Bogacki\net al., 2015)\natmosphere (noun): J’ai besoin de\nchanger d’atmosphère, et mon atmo-\nsphère, c’est toi.9 (I need to change\natmosphere, and my atmosphere\nis you.)\nMethod-based\nOstensive\nexploiting learner’s knowledge to\ndeﬁne words through examples,\ndrawings and paintings (Kotarbin-\nska, 1960)\npointing out objects by color, as in\n‘white’ (adjective) for yogurt\nSynonymous\ndeﬁne words by synonyms\nmean\n(adjective):\npenurious,\nstingy (Merriam-Webster)\nAnalytical\na formal descriptive sentence con-\nsisting of four main components,\nnamely species, verb, genus, and\ndifferentia\nrodent (noun):\nany of an order\nof relatively small gnawing mam-\nmals that have in both jaws a sin-\ngle pair of incisors with a chisel-\nshaped edge (Merriam-Webster)\nRelational\nexplain the meaning of a word in\ncomparison to other entities\nextraneous (adjective):\nnot be-\nlonging to a thing (Webster 1913)\nExemplifying\nuse examples to illustrate words\nliving (adjective):\npeople,\nani-\nmals, and plants (Mayor, 2009)\nContextual\ndeﬁning a word by describing its\nproperties within a context\n“therefore, only those organisms\nthat can grow without oxygen —\nanaerobic organisms — were able\nto live.” (Spala et al., 2019)\nReference\nreferring to an external resource\nby quoting or relying on a per-\nsonal or historical belief\nvirtue\n(noun):\nAccording\nto\nSocrates, virtue is knowledge\nRule-giving\nproviding rules to deﬁne words,\ne.g. grammatical function words\nwhom (pronoun): used as an in-\nterrogative or relative, as object of\na verb or a preceding preposition\nCorpus-based\nIs-\ndeﬁnitions\nverb ‘to be’ is used as a connector\nvariable (noun):\n“a variable is\nany part of the experiment that\ncan vary or change during the ex-\nperiment.” (Spala et al., 2019)\nVerb-\ndeﬁnitions\na verbal connector is used to de-\nﬁne a word\npitch (noun): “the perception of\nfrequency is called pitch.” (Spala\net al., 2019)\nDeﬁnition modeling\nWord\nembeddings\ngenerating\na\ndeﬁnition\nusing\nstatic word embeddings\nreprint (noun):\n“a written or\nprinted version of a book or other\npublication”\n(Gadetsky et al.,\n2018)\nContextual\nembeddings\ngenerating a deﬁnition using con-\ntextual embeddings\nscoot (verb):\n“cause to move\nalong by pushing” (Bevilacqua\net al., 2020)\nTable 2.1: A classiﬁcation of some of the best known deﬁnition paradigms\n9 A famous replica in the ﬁlm Hôtel du Nord (1938)\n\n2.2 dictionaries\n25\nTable 2.1 summarizes some of the major paradigms in deﬁning the deﬁnition of a\nconcept inspired by the classiﬁcation of Westerhout (2010). Depending on the seman-\ntic complexity and the editorial choice, one or more of these deﬁnition paradigms\nare used by lexicographers in the micro-structure of a dictionary. For instance, while\nthe exemplifying paradigm has limited usage for words that may be described using\nmore representative examples, the analytical paradigm allows a more descriptive and\ntherefore detailed description of the entry without sacriﬁcing clarity to brevity. It is\nworth mentioning that deﬁnitions can not always cover all the senses of a word. In or-\nder to ﬁll semantic gaps, oftentimes dictionaries provide usage examples and glosses.\nThe latter are clearer descriptions of the deﬁnition and more elaborate explanations\nin bilingual dictionaries.\nFurthermore, extracting and generating deﬁnitions of a given word using compu-\ntational techniques has been previously studied (Westerhout, 2010; Silva et al., 2016).\nRecently, many methods have been proposed to generate deﬁnitions, a task called\ndeﬁnition modeling. The main idea in this approach is to explore distributed statistical\nrepresentations of words to generate deﬁnitions for words in context or as lemmas.\nAmong the explored methods, we can mention recurrent neural networks with word\nembeddings (Noraset et al., 2017), latent variable modeling and soft attention mech-\nanism with word embeddings (Gadetsky et al., 2018), and ultimately Generation-\nary (Bevilacqua et al., 2020) which uses a span-based encoding scheme to ﬁne-tune\nan English pre-trained Encoder-Decoder system to generate glosses using contextual\nembeddings.\n2.2.3\nElectronic Dictionaries\nWith the advent of information technology, electronic dictionaries have been exten-\nsively used where lexicographical data are available in an electronic form. In addition\nto electronic dictionaries, machine-readable dictionaries (MRDs) are created to specif-\nically represent data under a machine-readable format, such as XML. This being said,\nthe terms machine-readable dictionary, electronic dictionary and lexical database are\noften conﬂated and used interchangeably.\nIn addition to the electronic form and data format, researchers have been moti-\nvated to design LSRs in such a way that processing linguistic data would be facilitated\nby a computer. In this context, an electronic dictionary has been more speciﬁcally\ncalled a virtual dictionary (Selva et al., 2003; Polguère, 2012; Polguère, 2014) to be dif-\nferentiated from an electronic dictionary and an MRD, not only based on the format\nbut also the representation of data structures, such as graphs, that are more com-\npatible with computers. In the same vein, one of the main objectives of the ELEXIS\nproject is to provide the infrastructure to convert printed dictionaries into electronic\nform. For this, a service named ELEXIFIER10 has been created.\n10 https://elexiﬁer.elex.is\n\n26\nbackground\n2.3\nnetwork-based resources\nMoving away from the theoretical discussions regarding modeling and deﬁning vari-\nous aspects of lexical and semantic data in LSRs, a crucial issue is the representation\nof such data. A popular solution is to organize lexical and semantic data as networks.\nThis idea of representing dictionaries as lexical networks has received much atten-\ntion previously, mainly to facilitate the representation of lexicographical data and\nalso, leverage the structure of networks to create further associations and connections\nbetween words (Reuer, 2004; Gilquin, 2008).\nThe main characteristic of such resources is to provide lexical units in such a way\nthat a relationship can be assigned to the relation between lexical units. A lexical\nnetwork or lexical graph, as the name suggests, would refer to the network of word\nsenses connected by semantic links such as synonymy, antonymy, hyponymy and also\nmetonymic, metaphorical, and polysemy relations (Norvig, 1989). Therefore, many\nLSRs fall into the category of lexical networks to some extent, for instance, WordNet\nas a lexical network (Beckwith and Miller, 1990). Such networks are sometimes re-\nferred to as lexical systems, that is to say, resources modeled in the form of a graph\n(Polguere, 2009).\n2.3.1\nWordNet\nWordNet is a widely known and used lexical database and reference that groups\nwords based on linguistic and psychological accounts of the theory of lexical memory\n(Miller et al., 1988). The fundamental idea of WordNet is to represent a concept or\nword sense by its synonyms, also known as synsets. Beyond the vocabulary of a given\nlanguage, WordNet provides different types of lexical relations to enrich synsets, such\nas hyponymy and meronymy. The idea of WordNet was initially implemented for the\nEnglish language which is referred to as the Princeton WordNet (Miller, 1998).\nSince its conception, the Princeton WordNet has gone through a few improve-\nments and enrichment in information. For instance, some of the succeeding Word-\nNets are enriched with information such as pronunciations (Declerck et al., 2020),\nstrength of relationships (Boyd-Graber et al., 2006), marking semantic roles and causal-\nity of verbs (Dziob et al., 2017), sense deﬁnitions (Mihalcea and Moldovan, 2001),\nlogical form axioms (Moldovan and Rus, 2001) and increasing multilinguality. In\norder to facilitate the latter, many studies have focused on creating a centralized or\nshared database to connect synsets, such as inter-lingual-index (Ellman, 2003) and the\nCollaborative Interlingual Index (Bond et al., 2016).\nIn addition, new WordNets are created for other languages by following the same\ntheory of the original Princeton WordNet, as in Rudnicka et al. (2015); Sagot and Fišer\n(2012); Pedersen et al. (2009); Isahara et al. (2008), or by translating the Princeton\nWordNet, also known as the Expand Method (Vossen, 2002, p. 52), as for Sanskrit\n\n2.3 network-based resources\n27\nFigure 2.5: The lexical network of ‘lion’ (noun) according to the Princeton WordNet 3.1 where\nits synsets (in green) and other semantic relations are speciﬁed (Visualized using\nLexical Graph: https://github.com/aliiae/lexical-graph).\n(Kulkarni et al., 2010), Latin (Franzini et al., 2019), Kurdish (Aliabadi et al., 2014) and\nMongolian (Batsuren et al., 2019), or by merging existing ones based on domains, also\nknown as the Merge Method, as in Hanoka and Sagot (2012); Zafar (2012).\nFurthermore, other aspects are included in the WordNet such as the lexical rep-\nresentation of affective knowledge as in WordNet-Affect (Strapparava et al., 2004),\nintegrating subject ﬁelds as in WordNet Domains (Magnini and Cavaglia, 2000) and\nextending the Princeton WordNet with named entities (Toral and Monachini, 2008).\nWordNet has been one of the most important and ubiquitous resources in many NLP\napplications such as word sense disambiguation (Morato et al., 2004), information\nretrieval (Mandala et al., 1998) and semantic similarity detection (Varelas et al., 2005).\nMany surveys have addressed various aspects of WordNets as in Bond and Paik\n(2012); Lin and Sandkuhl (2008); Petrolito and Bond (2014).\nThe current version of the Princeton WordNet (version 3.0) contains 206,941 word-\nsense pairs and 117,659 synsets. Among the senses, 33.8% are polysemous (79,450)\nwith an average polysemy of 1.24 for nouns and 2.17 for verbs11. To further update\nthe Princeton WordNet under an open source paradigm, McCrae et al. (2020) created\nthe Open English WordNet recently. Despite the richness of WordNet in terms of\nsemantic relations, there have been challenges regarding its applications within NLP\napplications where detection of polysemy is required. There have been many studies\nthat focus on the description and detection of various types of polysemy, particularly\nregular polysemy (Barque and Chaumartin, 2009), systematic polysemy (Buitelaar,\n1998; Peters and Peters, 2000) and also, clustering of word senses based on metonymy,\nand diathesis alternation (Peters et al., 1998).\n11 According to https://wordnet.princeton.edu/documentation/wnstats7wn\n\n28\nbackground\n2.3.2\nFrameNet\nFrameNet (Baker et al., 1998; Fillmore et al., 2004; Fillmore, 2008) is a resource con-\ntaining words and their meanings, known as lexical units, provided according to the\nframe semantics which lays out “schematic representations of the conceptual struc-\ntures and patterns of beliefs, practices, institutions, images, etc. that provide a foun-\ndation for meaningful interaction in a given speech community.” (Fillmore et al., 2003,\np. 235). The frame is a conceptualization of knowledge in such a way that each frame\ncan be evoked by speciﬁc words, i.e. lemmata, based on their meaning. Figure 2.6\nillustrates the frame of ‘cogitation’ (noun) and the relations of this frame with other\nframes, i.e. frame-to-frame relations, such as ‘assessing’ and ‘mental activity’. In ad-\ndition to such semantic relations, FrameNet provides an analysis of words based on\ntheir syntactic properties in actual utterances taken from large corpora. For instance,\nthe frame ‘cogitation’ is evoked by ‘consideration’, ‘thought’ and ‘thoughts’ in the\nfollowing phrases12:\n(a) your application was submitted for consideration by the committee.\n(b) the teacher gave some thought to a career change.\n(c) your thoughts about art are not relevant.\nTherefore, one can argue that ‘thoughts’ and ‘consideration’ in the aforemen-\ntioned examples are related as they both evoke the same frame of ‘cogitation’. Un-\nlike WordNet which provides polysemous items based on their syntactic properties,\nFrameNet represents polysemy by associating different frames to a word. Addition-\nally, FrameNet provides other properties in both semantic and syntactic levels such as\nvalences, arguments and complements, which speciﬁes the structure based on which\nthe word, particularly verbs, can be used.\nFigure 2.6: The frame of ‘cogitation’ (noun) in green along with its relations with\nother frames, such as ‘memorization’ according to the Berkeley FrameNet\n(Visualized using FrameGrapher: https://framenet.icsi.berkeley.edu/fndrupal/\nFrameGrapher).\n12 From https://framenet2.icsi.berkeley.edu/fnReports/data/frameIndex.xml?frame=Cogitation\n\n2.4 explanatory combinatorial dictionary\n29\nUnlike WordNet which does not rely on examples extracted from corpus, FrameNet\nprovides annotated phrases based on corpora for each frame pattern (Boas, 2005).\nThis enables FrameNet to represent richer “syntagmatic information about the com-\nbinatorial possibilities of each lexical unit” (Baker and Fellbaum, 2009), despite the\nconsiderably smaller size of FrameNet which contains approximately 1,000 manually\ndeﬁned frames.\n2.3.3\nJeuxDeMots\nJeuxDeMots13 (Lafourcade, 2007) is a gamiﬁed platform to create a lexical network\nby collecting terms from players containing over 404 million relations, such as associ-\nated for association, pos for part-of-speech, isa for predicate, hypo for hyponyms and\nhas_part for meronyms, between over ﬁve million terms in French. The relationships\nwithin the network are labeled semantically, oriented and weighted, with possibly\nnegative relationships denoting false associations. New relations between terms can\nbe extracted by automatic induction and it has been enriched and aligned with exter-\nnal resources (Tchechmedjiev et al., 2017; Plu et al., 2018).\n2.4\nexplanatory combinatorial dictionary\nThe Explanatory Combinatorial Dictionary (ECD) (Mel’ˇcuk, 2006) is a type of dictio-\nnary that is compiled based on the Meaning-Text Theory. The Meaning-Text Theory\n(MTT) (Mel’ˇcuk, 1973, 1981) aims to formalize the correspondence between meaning\nand text by using lexical functions and categorizing lexical items according to lexical,\nsyntactic and semantic features. As such, lexical functions can be related to lexical\nunits, i.e. a lexeme, a morpheme or multi-word expression, to indicate the types of\nphrases that a given word can form with other words. The following table, based on\nLareau et al. (2012), provides the lexical functions associated with ‘attention’:\nattention [of X to Y]\nMagn\nclose/whole/complete/undivided ∼\nFunc2\nX’s ∼is on Y\nnonFunc0\nX’s ∼wanders\nOper12\nX gives his/pays ∼to Y\nOper2\nY attracts/receives/enjoys X’s ∼\nOper2+Magnquant−X\nY is the center of ∼(of many Xs)\nIncepOper12\nX turns his ∼to Y\nIncepOper2\nY gets X’s ∼\nContOper2\nY holds/keeps X’s ∼\nCausFunc2\nZ draws/calls/brings X’s ∼to Y\nLiquFunc2\nZ diverts/distracts/draws X’s ∼from Y\n13 JeuxDeMots (‘jeux de mots’ lit. games of words): http://www.jeuxdemots.org\n\n30\nbackground\nLexical functions of MTT aim to represent paradigmatic relations such as syn-\nonymy as in Syn(wealthy)=rich, antonymy as in Anti(dark)=bright and meronymy\nas in Mult(bee)=swarm, and syntagmatic links such as Magn (Lat. magnus, great, big) as\nintensiﬁer in Magn(rain)=heavily and IncepOper (Lat. incipere, to begin and operari,\noperate) showing the act of starting to do, make, or have as in IncepOper1(victory)\n= achieve, gain, score, win. There are originally 27 paradigmatic and 37 syntag-\nmatic lexical functions (Mel’ˇcuk, 1996). Therefore, an ECD does not focus on a limited\nnumber of semantic properties but a wider range of lexical data, such as synsets in\nWordNet or frames in FrameNet (Lux-Pogodalla and Polguère, 2011). The various\nparadigmatic and syntagmatic links are shown in the lexical unit of ‘attention’. In\naddition, not only the deﬁnition of attention as a lexeme is provided, but also col-\nlocations such as ‘complete attention’ or ‘whole attention’, and idioms such as ‘pay\nattention’ and ‘enjoy attention’ are deﬁnable. This demonstrates the ﬂexibility and\nstrength of the theoretical stance of MTT.\nimprove, verb\nimprove-i.1a\nX improves ≡‘The value of the quality of X becomes higher’\n[The weather suddenly improved; The system will improve over time]\nimprove-i.1b\nX improves Y ≡‘X causes-1 that Y improves-i.1a’\n[The most recent changes drastically improved the system]\nimprove-i.2\nX improves ≡‘The health of a sick person X improves-i.1a’\n[Jim is steadily improving]\nimprove-i.3\nX improves at Y ≡‘X’s execution of Y improves-i.1a, which is\ncaused1 by X’s having practiced or practicing Y’\n[Jim is steadily improving at algebra]\nimprove-ii\nX improves Y by Z-ing ≡‘X voluntarily causes-2 that the market\nvalue of a piece of real estate Y becomes higher by doing Z-ing to\nY’\n[Jim improved his house by installing indoor plumbing]\nimprove-iii\nX improves upon Y ≡‘X creates a new Y’ by improving-i.1b Y’\n[Jim has drastically improved upon Patrick’s translation]\nTable 2.2: Lexical units deﬁned in the vocable of ‘improve’ based on ECD (Mel’ˇcuk, 2006,\np. 19)\nThe descriptive approach of Explanatory and Combinatorial Lexicography has\nchieﬂy led to two types of lexical resources: dictionaries such as the Dictionnaire\nexplicatif et combinatoire du français contemporain (Combinatorial and Explanatory Dic-\ntionary of Contemporary French) (Mel’ˇcuk and Arbatchewsky-Jumarie, 1999) and\nlexical databases such as the DiCo (Polguere, 2000). Unlike dictionaries where lexi-\ncal entries are lemmas, an ECD is organized based on meaning by presenting lexical\nunits as lexical entries. Therefore, lexical entries in an ECD do not represent the same\nlevel of polysemy as in a traditional dictionary. In fact, it is possible to group multiple\nlexical entries together in an ECD as a vocable as long as they show an intersection\nin meaning, or are roughly synonyms. The relationship between such lexical units\n\n2.4 explanatory combinatorial dictionary\n31\nin the same vocable is referred to as co-polysemy by Polguère (2018). In this sense, a\nvocable corresponds more or less to the micro-structure of a dictionary.\nThe example in Table 2.2 further clariﬁes this by showing six lexical units with\nunique identiﬁers, e.g. i.1a, which are grouped in the vocable of ‘improve’ based\non Mel’ˇcuk (2006, p. 19). In this vocable, the semantic closeness of the lexical units\nis categorized based on Roman and Arabic numerals and letters, in order of close-\nness. So, improve-i.1a and improve-i.1b, for example, are semantically more related\nthan to improve-ii. This enumeration is analogous to sense numbers in a traditional\ndictionary. In addition, examples are provided in brackets.\nFigure 2.7: The network of ‘attention’ (noun, En. attention) in the French Lexical Network\n(visualized using Spiderlex: https://spiderlex.atilf.fr/fr/q/*attention***)\nA resource of interest that puts forward the theoretical and descriptive principles\nof ECD is the French Lexical Network (FLN, or “Réseau Lexical du Français”) (Polguère,\n2014). FLN is in fact a lexical system where the vertices of the graph are the lexical\nunits, i.e. senses not synsets as in WordNet, in the language and the edges denote the\nparadigmatic and syntagmatic links. These are standardized by means of the system\nof lexical functions in MTT. Akin to the Generative Lexicon, FLN aims to make lexical\ndatabases compatible with the computational processing of linguistic data by bring-\ning both MTT and ECD frameworks together. Figure 2.7 illustrates the lexical network\nof the vocable ‘attention’ in French in FLN where the coloring of nodes reﬂect various\nsenses of the lexeme which currently amount to six. attention i.1 is the basic lexical\nunit of the vocable which is associated to attention i, attention i.2, attention ii,\namabilité (kindness), distraction ii and générosité 2 (generosity). The internal\nedges within each cluster, i.e. nodes with identical colors, are tagged with lexical\nfunctions, such as Syn(attention i.2)= Gare ! (watch out) or Ant(inattention)= at-\ntention. Furthermore, the length of the edges represents the measure of proximity in\nsuch a way that nodes associated with shorter edges are more semantically close.\n\n32\nbackground\nIn addition to the linguistic application of both ECD and MTT being applied to\nother languages and even other types of resources such as FrameNet (Bouveret and\nFillmore, 2008; Coyne and Rambow, 2009) and data such as terminologies (L’Homme,\n2007) and collocations (Lareau et al., 2012), there have been efforts in a few language\ntechnology applications such as machine translation (Sasha, 2008), lexical and seman-\ntic disambiguation (Kolesnikova, 2020) and syntactic analysis (Mille et al., 2012) to\nleverage this conceptualization to assist in NLP tasks.\n2.5\ngenerative lexicon\nOne of the major limitations in sense inventories, as in dictionaries, is the restrictive\nnumber of senses, oftentimes enumerated, that are provided for a word. This ap-\nproach, which is referred to as ‘static’ or ‘frozen’ by Pustejovsky (2006, p. 4), limits\nthe number of senses for a word to a ﬁxed number and also impedes ﬁner distinc-\ntions between word senses and descriptions. As such, a dictionary user is coerced into\ncontext enforcing and matching the closest available sense. On the other hand, the\ntraditional approaches to word-sense disambiguation (WSD) would also rely heavily\non the limited number of senses listed for a word. More importantly, providing word\nsenses as an exhaustive list reduces the possibility to further generalize or extend\nexisting senses in a formal way.\nAs a solution, the Generative Lexicon (Pustejovsky, 1995) presents a lexical se-\nmantics theory that addresses the problem of polysemy and sense representation and\nattempts to provide compositional semantics for the contextual modulations in lan-\nguage. In other words, given a ﬁnite set of means, a generative lexicon allows creating\nand extending an indeﬁnite number of senses by means of a rich and expressive vo-\ncabulary that can be used as data structure associated with the lexical encoding of\nsemantic information. Initially motivated by compositional semantics and inspired by\nAristotelian foundations for deﬁning concepts based on genus-differentia (see Section\n2.2.2), the core idea of a generative lexicon revolves around the inference between\nwords and lays the theoretical foundation for the computational processing of word\nmeaning in a theoretical manner.\nFor a lexicon to be generative, Pustejovsky (1995) proposes the following four\nlevels:\n1. Lexical typing structure which identiﬁes how a lexical structure is related to\nother ones within the lexicon shaping the general world knowledge. For in-\nstance, knowing the structure of ‘wood’ (noun) being a material that inherits\nthe properties of its super-class artifact and then physical-object, the given\nword ‘rubber’ can be related to the same structure.\n2. Argument structure which speciﬁes the type and number of argument struc-\ntures, i.e. the relationship between words and functions, and their syntactic\n\n2.5 generative lexicon\n33\nrealizations (Grimshaw, 1990). For instance, the verb ‘build’ would have three\narguments: subject and two objects, as in “He builds the box with wood”. This\ncan be shown as follows:\n\n\nbuildverb\nargstr\n\n\narg1\nanimate_individual\narg2\nartifact\nd-arg1\nmaterial\n\n\n\n\nwhere d-arg1 refers to ‘wooden’ as a modiﬁer in the direct object and deﬁned\nas a default argument (Pustejovsky, 1995, p. 66).\n3. Event structure which refers to the event type of a verb or phrase. Three prim-\nitive types are deﬁned, that is state, process and transition.\nFor example, the\ninteraction between people denotes a transition event, while the state of things\nrefers to a state event.\n4. Qualia structure which is the most important component of a word sense, com-\nposed of the following four qualia roles:\n• The formal role which identiﬁes an entity and is roughly similar to a genus,\ne.g. a car is a physical object.\n• The constitutive role which identiﬁes the components of the entity, e.g. a\ncar is a physical object that has a body, a chassis and an engine.\n• The agentive role which provides information about the origin of the entity,\ne.g. a car is a physical object that has a body, a chassis and an engine that is an\nartifact and is constructed by an entity y.\n• The telic role which refers to the purpose of the entity, e.g. a car is a physical\nobject that has a body, a chassis and an engine that is an artifact and is constructed\nby an entity y and an individual, like y, can drive it. Driving is a process (P).\nThe qualia structure of the example ‘car’ can be summarized as follows:\n\n\ncar(x)\nformal\nphysical_object(x)\nconst\n\nbody, chassis, engine, ...\n\u000b\nagentive\nartifact(x), construct(y, x)\ntelic\ndrive(p, y, x)\n\n\nThe Generative Lexicon theory has received some attention in both language tech-\nnology and formal semantics as in Vikner and Jensen (2002). The Brandeis Seman-\ntic Ontology project (Pustejovsky et al., 2006), integrating Generative Lexicon event\nstructures into VerbNet (Brown et al., 2018), a toolkit to create Generative Lexicon\nresources (Henry and Bassac, 2008) and the application of the Generative Lexicon in\nnon-literal linguistic language resolution (Bergler, 2013) and the Semantic Web (Toral\n\n34\nbackground\net al., 2007) are a few of such efforts. Even though the Generative Lexicon initially\ncomes with the promise of enhancing the exploitation of information thanks to com-\npositions, the idea seems to have yet to become operational given that there are not\nmany resources or applications in NLP that rely on a generative lexicon. Moreover,\nquestions have been raised regarding the level of compositionality and lexical gener-\nativity of the Generative Lexicon theory (Fodor and Lepore, 2000).\n2.6\nnatural semantic metalanguage\nOne of the main characteristics of the previously mentioned LSRs is the theories\nbased on which lexical units are deﬁned in relation with other ones, as in ‘book’\nvs. ‘publishing house’. This process can be quite language-dependent given that\nessentially languages do not have the same vocabulary. One idea would be to deﬁne\nlexical units relative to a set of predeﬁned, small yet universal meanings. This is the\ncore idea of the Natural Semantic Metalanguage.\nThe Natural Semantic Metalanguage (NSM) approach (Wierzbicka, 1996) aims to\ndescribe complex meanings using simpler semantic primitives, called primes, such as\nI, BIG and NOW. Semantic primes are a set of basic meanings which are, arguably,\nuniversal to all languages and irreducible to smaller semantic cores (Goddard, 2008;\nGoddard and Wierzbicka, 2014). These primes are used to represent more complex\nlinguistic concepts. To do so, a conceptual syntax is followed in which various primes\ncan be combined together to form NSM clauses such as substantives and predicates,\ne.g. “SOMETHING HAPPENS TO SOMEONE/SOMETHING” to deﬁne undergoer frames. “Re-\nductive paraphrase” is the name given to this approach of semantic analysis, and\nthe results are known as “explications”. Since only primes are used in a reductive\nparaphrase, there are no terms, neologisms or abbreviations and also, no obfuscated\ndeﬁnitions such as “juridical (adjective): pertaining to a judge or to jurisprudence”\n(Princeton WordNet 3.1). The following example deﬁnes ‘amazement’ in the NSM\n(taken from (Wierzbicka, 1992, p. 549)) :\namazement\nX feels something\nsometimes a person thinks something like this:\nsomething happened now\nI didn’t know before now: this can happen\nif I thought about this I would have said: this cannot happen\nbecause of this, this person feels something\nX feels like this\n\n2.6 natural semantic metalanguage\n35\nMoreover, it is easier to develop cross-translatable semantics that is not essentially\nAnglocentric, using NSM. In addition to the primes which consist of 65 based on\nsigniﬁcant efforts to empirical investigation (Goddard and Wierzbicka, 2013), it is\npossible to create new semantic cores depending on the language. Table 2.3 provides\nthe list of primes in English deﬁned according to (Goddard and Wierzbicka, 2002). It\nis important to note that semantic primes are conceptually deﬁned and not lexically.\nThat means that, although there might be many meanings for a semantic prime, such\nas ‘move’, in a dictionary, the basic meaning of the words are meant to deﬁne a prime.\nTherefore, lexical ambiguity should not change the logical meaning of the word.\nSubstantives\nI, YOU, SOMEONE, PEOPLE, SOMETHING, THING,\nBODY\nRelational substantives\nKIND, PART\nDeterminers\nTHIS, THE SAME, OTHER ELSE\nQuantiﬁers\nONE, TWO, SOME, ALL, MUCH, MANY, LITTLE, FEW\nEvaluaters\nGOOD, BAD\nDescriptors\nBIG, SMALL\nMental predicates\nTHINK, KNOW, WANT, FEEL, SEE, HEAR\nSpeech\nSAY, WORDS, TRUE\nActions, events, movement\nDO, HAPPEN, MOVE\nLocation, existence, speciﬁ-\ncation\nBE (SOMEWHERE),THERE IS, BE\n(SOMEONE/SOMETHING)\nPossession\n(IS) MINE\nLife and death\nLIVE, DIE\nTime\nWHEN TIME, NOW, BEFORE, AFTER, A LONG TIME,\nA SHORT TIME, FOR SOME TIME, MOMENT\nSpace\nWHERE PLACE, HERE, ABOVE, BELOW, FAR, NEAR,\nSIDE, INSIDE, TOUCH\nLogical concepts\nNOT, MAYBE, CAN, BECAUSE, IF\nIntensiﬁer, augmenter\nVERY, MORE\nSimilarity\nLIKE AS WAY\nTable 2.3: A list of semantic primes grouped into related categories according to Goddard\nand Wierzbicka (2002)\nNSM also comes with the notion of semantic molecules. Semantic molecules refer\nto non-primitive semantic units that can be used within the semantic structure of\nanother more complex word. For instance, ‘bird’ in the clause “a KIND of bird”, as\nthe deﬁnition of the word ‘robin’, refers to a semantic molecule that may be used in\nthe explication of ‘eagle’ as well. This way, a taxonomic structure is created accord-\ning to explications which allows inducing semantic relationships between words. On\nthe other hand, explications provided to some words can reveal other types of se-\nmantic structures; for example, explications for ‘fork’, ‘spoon’ and ‘plate’ include the\nsemantic molecule ‘eat’, where the semantic relationship corresponds to the intended\npurpose or function (Goddard, 2010).\n\n36\nbackground\nEven though the NSM approach has been adapted to other languages such as\nItalian (Maher, 2002) and Spanish (Verdín-Armenta and Díaz-Rodríguez, 2017) and\nhas been demonstrated as a ﬂexible approach to tackle polysemy (Goddard, 2000),\nsome faults in the underlying assumptions of this approach, particularly concerning\nthe universality and untranslatability of culture-speciﬁc concepts (Blumczy´nski, 2013),\nhave been raised. Moreover, the integration of the NSM approach in NLP applications\nseems to be rather unexplored, with very few studies such as Zamblera (2010) and\nStock (2008).\n2.7\nterminologies\nTerminology is a set of specialized terms relating to a ﬁeld of activity, like the Uni-\nﬁed Medical Language System (Bodenreider, 2004) describing the terminology for\nmedicine. Terminology also designates the task of identifying, analyzing and, if nec-\nessary, coining neologisms for a given technique such as ‘cyber-attack’, in concrete\nsituations, in such a way as to meet the needs for expression of the notions and con-\ncepts of a domain. Terminology (or terminography) applies to specialized languages,\nanalogous to lexicography that relates to general language (Alberts, 2001; Costa, 2013).\nThe alphabetical list of technical terms in a particular domain of knowledge is also\nreferred to as a glossary.\nSimilar to dictionaries, terminologies provide linguistic descriptions such as mor-\nphosyntactic categories and deﬁnitions. However, this is of secondary importance as\nthe focus of terminology is on the organization of knowledge and concept modeling\nin lieu of the linguistic characteristics of terms. Therefore, semantic relations, such as\nmeronymy as in ‘car’ vs. ‘chassis’ and hyponymy as in ‘eagle’ vs ‘bird’, are widely\nused in terminologies that are rather taxonomic and more in line with ontological re-\nlationships. This being said, recent studies, as L’Homme (2020) states, tend to utilize\nlexical semantics in terminologies to better understand the nature of words and their\nrelationships.\nAs with language resources, terminologies have been used in many language tech-\nnology applications such as entity labeling (Ly et al., 2018) and recommender systems\n(Demner-Fushman et al., 2009). Moreover, terminologies are important resources to\nincrease coverage of other language resources, like dictionaries, for various other\ntasks such as machine translation.\nThe semantic enrichment of terminological re-\nsources using formalization of ontological information has also received attention\n(Speranza et al., 2020; Lamé et al., 2019). In addition, the automatic creation of con-\ntrolled terminologies (Sarica et al., 2020) and term extraction (Aubin and Hamon,\n2006) are other tasks in the same ﬁeld.\n\n2.8 ontological resources\n37\n2.8\nontological resources\nAn ontology provides a formal and explicit speciﬁcation of how the vocabulary in\na speciﬁc domain in a language is used with the actual occurrence of a speciﬁc sit-\nuation. According to Declerck et al. (2006), “the main goal of ontologies is to formalize\ndomain knowledge for ensuring a more compact description of it and a more efﬁcient access to\nit.”. To this end, a set of representational primitives are used to model a domain using\nclasses and relationships between them. In this regard, many LSRs can have a few\nontological features and can be categorized based on their “ontological precision”, i.e.\nthe precision of conveying the intended meaning of a situation based on the conceptu-\nalization in an ontology, as deﬁned by Guarino (2006). This way, catalogs, glossaries,\ntaxonomies, thesauri and axiomatic theories are ontological resources ordered from\nthe least ontological precision (catalogs) to the most precise one (axiomatic theories).\nThe parameter that varies the ontological precision of a resource within this range\nis the formalization that provides structure and constrained meaning. According to\nJarrar (2021), “ontologies are strictly formal, speciﬁed in some logical language with\nformal semantics” making it possible to reason over the concepts and entities and\ncarry out a logical analysis. This is also the case of WordNet which is sometimes\ncategorized as an ontological resource (Miller and Fellbaum, 2007). Finally, there are\nmany interpretations for an ontology as a philosophical discipline and as a concep-\ntual and formal system described in Guarino and Giaretta (1995). In this context, the\nlatter is meant.\nNevertheless, language resources are primarily created at the language level and\ndo not necessarily provide references to non-lexicalized ontological categories. For\ninstance, ‘marrke’ (noun, [mA:rkæ]) appears in a Kurdish lexicon to denote ‘the egg\nthat is put in a coop to encourage chickens to lay eggs’, while such a concept is not\nlexicalized in the English lexicon but can be formalized in an ontology. Furthermore,\nmany semantic relations available in a lexicon may not be similarly represented in an\nontology; for instance, near-synonyms such as hungry-peckish in a lexicon appear\nwith an overlapping word sense while in an ontology, they are deﬁned in a different\nhierarchy which is not essentially compatible with that of a lexicon. The lack of such\ndistinctions along with the presence of semantic relations such as semantic catego-\nrizations that are not required in an ontology increases the gap between these two\nresources. On the impact of linguistic categorizations on this gap, Hirst (2009) states\nthat:\n“Often, linguistic categorizations are not even a reliable reﬂection of the\nworld. For example, many languages distinguish in their syntax between\nobjects that are discrete and those that are not: countable and mass nouns.\nThis is also an important distinction for many ontologies; but one should\nnot look in the lexicon to ﬁnd the ontological data, for in practice, the ac-\ntual linguistic categorization is rather arbitrary and not a very accurate or\n\n38\nbackground\nconsistent reﬂection of discreteness and non-discreteness in the world. For\nexample, in English, spaghetti is a mass noun, but noodle is countable.”\nSince the late 1990s, signiﬁcant progress has been made in ontology engineer-\ning and creating standards for ontologies, with standards such as Resource Descrip-\ntion Framework (RDF), RDF Schema (Brickley, 2004) and Web Ontology Language\n(OWL) (Antoniou and Van Harmelen, 2004). In the same vein, given the potential\nof ontologies for representation and modeling of linguistic data and their semantic\ninteroperability, there has been much interest in creating resources to bring together\nthe ontological features of ontologies and lexical properties of lexicons, with many\ninitiating studies such as Knight and Luk (1994); Dahlgren (1995); Buitelaar (1998);\nFarrar et al. (2002); Farrar and Langendoen (2003). One of the important efforts in\nthis realm is LexInfo–linguistic grounding of ontologies (Buitelaar et al., 2009) which\ncombines necessary design aspects of previous models such as LingInfo (Buitelaar\net al., 2006) and LexOnto (Cimiano et al., 2007) to associate linguistic information and\ncomputational lexica with ontologies. Other prominent ontologies in linguistics are\nSUMO–Suggested Upper Merged Ontology (Niles and Pease, 2001), MCR–Meaning\nMultilingual Central Repository Atserias et al. (2004), Olia–ontologies of linguistic an-\nnotation (Chiarcos and Sukhareva, 2015) and Lemon–Lexicon Model for Ontologies\n(McCrae et al., 2011).\n2.8.1\nLinguistic Linked Data\nThe studies on representing linguistic data as ontologies have paved the way to a\nnew interdisciplinary branch called the Linguistic Linked Data (LLD) (Cimiano et al.,\n2020c). The concept of the Web of Linked Data, which makes RDF data available\nusing the HyperText Transfer Protocol (HTTP), has gained traction along with the\nWeb of data, also known as the Semantic Web, particularly in the NLP community\nas a standard for linguistic resource creation. According to the ofﬁcial deﬁnition of\nW3C14,\n“Linked Data lies at the heart of what Semantic Web is all about: large\nscale integration of, and reasoning on, data on the Web. Almost all applica-\ntions listed in, say collection of Semantic Web Case Studies and Use Cases\nare essentially based on the accessibility of, and integration of Linked Data\nat various level of complexities.”\nMoreover, the unique potential that the Semantic Web and Linked Data offer for\nelectronic lexicography enables interoperability across lexical resources by leveraging\nprinted or unstructured linguistic data to machine-readable semantic formats.\nTo\nthis end, linguistic linked open data aims to promote the creation, maintenance and\n14 https://www.w3.org/standards/semanticweb/data\n\n2.8 ontological resources\n39\npublication of language and linguistic data according to the principles of linked data\n(Berners-Lee, 2006) and openly. Figure 2.8 shows the resources which are available in\nlinked data according to the Linguistic Linked Open Data Cloud.\nLegend\nCorpora\nLexicons and Dictionaries\nTerminologies, Thesauri and Knowledge Bases\nLinguistic Resource Metadata\nLinguistic Data Categories\nTypological Databases\nOther\nCatala...\nlexinfo\nGeolog...\nDBpedia\nCLLD-S...\nCLLD-G...\nLexvo\nOLiA\nGenera...\nISOcat\nTDS\nUniver...\nItalWo...\nWordNe...\nGeoWor...\nWordNe...\nUniver...\nUniver...\nDBpedi...\nWikili...\nBabelNet\nlemonUby\nwiktio...\nLingui...\nAperti...\nUniver...\nNews-1...\nUniver...\nChines...\nUniver...\nCLLD-WOLD\nJapane...\nCLLD-A...\nKORE 5...\nSLI Ga...\nUniver...\nGemeen...\nDBpedi...\nDBpedi...\nAperti...\nAperti...\nBasque...\nUniver...\nietﬂang\nInterc...\nassoci...\nUniver...\nFinnWo...\nUniver...\nGalici...\nMLSA -...\nGreek ...\nWordNe...\nMultex...\nAutoma...\nZhishi.me\nsloWNe...\nLemonW...\nOLiA D...\nLinked...\nLODAC ...\nFAO ge...\nEuroSe...\nUniver...\nUniver...\nUniver...\nlinked...\nOpen W...\nAperti...\nUniver...\nLinked...\nUniver...\nSALDO-RDF\nPreMOn\nUniver...\nxLiD-L...\nUniver...\nRSS-50...\nISOcat...\nUniver...\nOpen D...\nWordne...\nGlobal...\nUniver...\nSlovak...\nOntos ...\nUniver...\nAperti...\nCornet...\nBiblio...\nUniver...\nFiESTA\nPDEV-L...\nUniver...\nDBpedi...\nSentim...\nUniver...\nOpenWN...\nAperti...\nArabic...\nUniver...\nReuter...\nSocial...\nUniver...\nCLLD-E...\nRomani...\nAperti...\nUniver...\nALPINO...\nAperti...\nAperti...\nFramester\nUniver...\nCopyri...\nIATE RDF\nJRC-Na...\nUniver...\nUniver...\nAperti...\nAperti...\nUniver...\nUniver...\nUniver...\nAperti...\nAperti...\nAperti...\nUniver...\nplWord...\nUniver...\nGEnera...\nUMTHES\nSweFN-RDF\nUniver...\nEARTh\nThIST\nPleiades\nUniver...\nUniver...\nDanNet...\nFrameB...\nUniver...\nGreek ...\nUniver...\nUniver...\nUniver...\nSALDOM...\nAperti...\nUniver...\nCLLD-WALS\nUniver...\nEMN\nAperti...\nCLLD-afbo\nSIMPLE\nUniver...\nMultiW...\nChines...\nChat G...\nAperti...\nAperti...\ngemet-...\nUniver...\nSTW Th...\nTheSoz...\nMASC-B...\nzhishi...\nOLAC M...\nCLLD-P...\nAtlant...\nUniver...\nMultil...\nAperti...\nUniver...\nLexico...\nAperti...\nUniver...\nBulTre...\nNorweg...\nMuninn...\nCroati...\nlingvo...\nWordne...\nThai W...\nUniver...\nPolyma...\nUniver...\nMetaSh...\nUniver...\nWOLF W...\nWordNe...\nParole...\nEURAXE...\nUniver...\nUniver...\nUniver...\nIWN\ndbnary\nBrown ...\nGlottolog\nWorld ...\nUniver...\nHebrew...\nAperti...\nUniver...\nOpen M...\nSwedis...\nUniver...\nManual...\nAperti...\nde-gaa...\nPersia...\nPhonet...\nEnglis...\nUniver...\nUniver...\nUniver...\nUniver...\nPanLex\nMExiCo\nAperti...\nUniver...\nUniver...\nUniver...\nIceWor...\nAlbane...\nPrince...\nOpen B...\nFirefox\n1 of 2\nFigure 2.8: The Linguistic Linked Open Data Cloud (From https://linguistic-lod.org)\nOver the recent years, the usage of LLD as a mechanism to create and publish\nhas gained much wider attention and recognition in the ﬁeld. This is thanks to the\ninteroperability and accessibility that LLD offers and further tendency towards more\nopen-access standards for community-based projects. One particular example that\ndistinctly focuses on inter-separability and accessibility of data is Ontolex-Lemon.\nBuilding upon a few data models, especially LexInfo (Cimiano et al., 2011), LIR\n\n40\nbackground\n(Montiel-Ponsoda et al., 2008) and LMF (Francopoulo et al., 2006), Ontolex-Lemon\nprovides an RDF native data model based on the Lemon (McCrae et al., 2011) that re-\nalizes the representation of linguistic data on the Semantic Web. This model provides\ncomprehensive linguistic descriptions such as information related to the representa-\ntion of morphological and syntactic properties of lexical entries.\nFurthermore, the current trend of applying digital technologies to disciplines of\nthe humanities, also known as Digital Humanities, has created a wider range of ap-\nplications in which LLD can be used, in addition to more traditional ﬁelds as compu-\ntational linguistics and NLP (Khan et al., 2021).\n2.9\nknowledge graphs\nA knowledge graph is a representation of knowledge about a domain in a machine-\nreadable form.\nThe representation of knowledge in the form of a graph is a key\nelement for the efﬁcient and contextual retrieval of rich information and knowledge.\nA knowledge graph is made up of three components: an ontology deﬁning a data\nmodel in the RDF, schemata or controlled vocabularies that can be linked and the\nresources covered by the graph (Ehrlinger and Wöß, 2016). Knowledge graphs were\ninitially introduced by Google as information boxes in response to the search queries\nand, are a speciﬁcation of knowledge base. The latter may refer to a wider range of\nknowledge resources, whether structured and unstructured information. In addition\nto Google’s original knowledge graph, there are many other services and platforms\nwhich are referred to as knowledge graphs.15.\nKnowledge graphs are critical to many domains.\nThey contain large amounts\nof information, used in applications as diverse as search, question-answering sys-\ntems, and conversational agents. They are the backbone of linked open data, helping\nconnect entities from different datasets. Finally, they create rich knowledge engineer-\ning ecosystems, making signiﬁcant, empirical contributions to our understanding of\nknowledge representation, engineering, and practices. Knowledge graphs have been\nwidely used in many knowledge-aware applications, in general in information re-\ntrieval (Reinanda et al., 2020) and artiﬁcial intelligence (Nicholson and Greene, 2020)\nand more speciﬁcally in NLP to exploit and extend lexical, ontological and termino-\nlogical resources for tasks such as language representation learning (Logan IV et al.,\n2019), question answering (Mohammed et al., 2018), relation extraction (Ristoski et al.,\n2020), terminology extraction (Speranza et al., 2019) and language resource enrich-\nment (Martín-Chozas et al., 2020).\nAnalogous to other language resources, there are two approaches to create, main-\ntain and publish knowledge graphs: open knowledge graphs and enterprise knowl-\n15 For further information regarding the deﬁnitions of knowledge base and knowledge graph and their\ndifferences according to the literature, see (Hogan et al., 2021, p. 111)\n\n2.9 knowledge graphs\n41\nedge graphs. Widely-known examples of open knowledge graphs are Wikidata16,\nDBpedia17 (Bizer et al., 2009), GeoNames18 and YAGO (Suchanek et al., 2007) which\nare accessible openly. Even though these knowledge graphs are not identical in ar-\nchitecture, technology and purpose, they try to promote the creation and publication\nof data in an open manner with the contribution of various communities online. On\nthe other hand, enterprise knowledge graphs are restricted to a company and are\nnot essentially openly accessible. Prominent examples of such knowledge graphs are\nsearch engines such as Microsoft’s Bing19, Microsoft’s Knowledge Mining API20 and\nGoogle’s search engine. In the same vein, there are knowledge graphs with the partic-\nular objective of representing and storing linguistic data such as ConceptNet (Speer\net al., 2017) and Wikidata’s Lexicographical Data21 which is built on Wiktionary and\nis compatible with Ontolex-Lemon.\nSince ontologies are one of the building components of knowledge graphs, it is\npossible to reason over the data using inference rules. This can be carried out thanks\nto the RDF data model implemented in each knowledge graph. RDF is a framework\nfor describing resources on the Web which was initially designed to represent meta-\ndata. However, nowadays RDF is the foundational data model for Semantic Web and\nknowledge graphs. In addition, RDF along with other technologies such as SPARQL,\nOWL, and SKOS empower Semantic Web and Linked Data. RDF expressions are\nin the form of subject–predicate–object expressions, i.e. subject predicate object\nknown as a semantic triple. A triple is the basic principle to deﬁne knowledge in\na data model where the subject should be a Uniform Resource Identiﬁer (URI) or a\nblank node, the predicate is a URI and the object can be a URI, a literal or a blank\nnode. Unlike traditional databases where data has to adhere to a ﬁxed schema, there\nis no prescribed schema for RDF documents. This is the reason that RDF is called\nsemi-structured. On the other hand, an RDF document includes schema information\nand can be described without additional information. Therefore, an RDF data model\nis self-describing too. The following snippet in RDF from DBpedia22 contains triplets\ndescribing France and Paris:\ndbr:France dbo:countryCode \"+33\" .\ndbr:France dbo:demonym\n\"French\"@en .\ndbr:France dbo:governmentType\ndbr:Unitary_state .\ndbr:France dbo:anthem dbr:La_Marseillaise .\ndbr:France dbo:capital dbr:Paris .\ndbr:Paris dbo:populationTotal \"2229621\"^^xsd:integer .\n16 https://www.wikidata.org\n17 https://www.dbpedia.org\n18 https://www.geonames.org\n19 https://www.bing.com\n20 https://www.microsoft.com/en-us/research/project/knowledge-mining-api\n21 https://www.wikidata.org/wiki/Wikidata:Lexicographical_data\n22 https://dbpedia.org/page/France\n\n42\nbackground\nwhere dbr and dbo are preﬁxes referring to DBpedia’s resource23 and DBpedia’s\nontology24, respectively. This way, dbr:France is equivalent to https://dbpedia.org/\npage/France. These triples deﬁne France as an entity with predicates such as capital,\ncountry code and anthem.\nEach triple is structured according to the data model\nused in the knowledge graph which is deﬁned by the four principals of RDF Schema,\ni.e., class hierarchy, property hierarchy, domain and range of properties. Figure 2.9\nshows a simple schema of the ontology of a place as a class derived from Thing (the\nhighest superclass), then Country being a sub-class of Place, County being a sub-\nclass of Country and City being a sub-class of County. The schema also shows our\nindividuals as France, Ile-de-France and Paris.\nFigure 2.9: A simple ontology for Place, showing France, Ile-de-France and Paris as in-\nstances. This is created using Protégé (https://protege.stanford.edu).\nIt should be noted that the name of the components of an RDF triple, e.g. dbr:France,\ndoes not necessarily correspond to the label or the alias of an entity but to the re-\nsource that describes that entity. Unlike DBpedia, in some knowledge graphs such as\nWikidata, entities are also deﬁned by unique identiﬁers. For instance, the same en-\ntity France is deﬁned as Q142 at https://www.wikidata.org/wiki/Q142 on Wikidata.\nThis being said, URI names, labels and descriptive data can sometimes be considered\nas linguistic information.\nWith the advances of neural network-based techniques and the growing size of\nknowledge graphs, there has been an increasing interest in learning knowledge graph\n23 http://dbpedia.org/resource\n24 http://dbpedia.org/ontology\n\n2.10 language models\n43\nrepresentations and creating graph embeddings (Wang et al., 2017).\nTo do so, a\nlow-dimensional distributional representation of data in a knowledge graph is cre-\nated based on the rich semantic information of entities and relations (Ji et al., 2021).\nThis embedded distributional representation is then used in various other tasks, such\nas semantic parsing (Heck and Huang, 2014), chatbots (Yoo and Jeong, 2020), ma-\nchine translation (Lu et al., 2018) and explainability in artiﬁcial intelligence (Xian\net al., 2019). Given the signiﬁcant size of the structured data in knowledge graphs,\nthey have been proved beneﬁcial for incorporating commonsense knowledge (Chang\net al., 2021) and increasing factual information in text-based applications (Zhu et al.,\n2020). Furthermore, many knowledge graphs come with query services, also known\nas SPARQL endpoint, that can facilitate their integration into NLP applications. For\ninstance, the following SPARQL query retrieves lexemes describing ‘book’ (noun) in\ndifferent languages via Wikidata’s SPARQL endpoint25:\nSELECT ?lemma ?languageLabel WHERE {\n?l a ontolex:LexicalEntry ;\nontolex:sense ?sense ;\ndct:language ?language ;\nwikibase:lemma ?lemma.\n?sense wdt:P5137 wd:Q571 .\nSERVICE wikibase:label {\nbd:serviceParam wikibase:language \"en\".\n}\n}\n2.10\nlanguage models\nThe fundamental idea of language modeling is based on the sequential nature of lan-\nguage production, that is the procedure of transforming meaning into speech or more\nimportantly for our case, into text (Garrett, 1989). This topic has been widely stud-\nied in the context of psycholinguistics under the connectionist models of language\nproduction (Dell et al., 1999). Similarly, many aspects of a language can be stud-\nied through statistical language modeling where information such as dependency\nbetween words, lexical variations and structural features, e.g. syntax and semantics,\nand pattern associations and various meanings of words based on context, e.g. pol-\nysemy, are modeled and analyzed based on Bayesian inference. In other words, the\nultimate goal is to estimate the probability of a given word wi or character, depending\n25 https://query.wikidata.org\n\n44\nbackground\non the level of modeling, given the n preceding and succeeding surrounding words\nor characters, i.e. the context, as follows:\nP(wi|wi−n...wi−1, wi+1...wi+n)\nPre-trained language models are an important kind of language resource which\nare trained on large corpora and represent relationships between words by means of\nvector space models. Pre-trained word representations, also known as word embed-\ndings, such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014),\nhave been heralded as major breakthroughs in NLP. Instead of representing words as\natomic units, word embeddings learn a distributional representation of words from\nlarge language data. As such, they are widely used in NLP pipelines and have been\ndemonstrated to be efﬁcient in many tasks such as part-of-speech tagging, machine\ntranslation and sentiment analysis (Naseem et al., 2021), word-sense disambiguation\n(Loureiro et al., 2020) and word-sense induction (Amrami and Goldberg, 2019).\n0.5\n0.0\n0.5\n1.0\n1.5\n2.0\n1.0\n0.5\n0.0\n0.5\n1.0\nwing\nwings\nwingtip\nwingtips\npoliticsist\nfuselage\ntailplane\nempennage\nailerons\nwinglets\nfuselages\nunswept\nbracedtailwheel\nplanform\nundercarriage\naileron\nnacelle\nairbrakes\nnosewheel\nrightwing\nairfoil\ninterplane\nunderwing\ntailskid\naile\nailes\nfuselage\nempennage\nempennages\nalaire\nvoilurefuselages\nbiréacteur\narrière\nvoilures\nailerons\nailier\nwinglets\nentoilée\nportance\ncostal\nfuselée\nradicalisé\ngauchiste\ncantilever\nquadriréacteur\naileron\nemplanture\nentoilé\nFigure 2.10: Closest words to the vector space of the word ‘wing’ (noun) in the MUSE em-\nbeddings of English along with the nearest words in the mapped vector space\nin French\nIt should be noted that language models differ from word embeddings in the\nsense that the latter create a distributed representation of a word and capture a more\n\n2.10 language models\n45\nlimited range of information, mainly based on word associations and without taking\ncontext into account. To remedy this, contextualized word embeddings have been\nproposed to incorporate context into word embeddings (Ethayarajh, 2019). In these\ntechniques, a ﬁner distinction can be drawn between word senses by capturing further\ninformation such as syntactic and semantic features (Mikolov et al., 2013b). There\nhave been tremendous efforts in this ﬁeld, from n-gram and tree-based models (Bahl\net al., 1989) to more robust neural-based models (Bengio et al., 2003), particularly\nELMO (Peters et al., 2018a), Bidirectional Encoder Representations from Transformer\n(BERT) (Devlin et al., 2018) and Generative Pre-trained Transformer 3 (GPT-3) (Brown\net al., 2020).\nFigure 2.11: Distinction between senses of ‘wing’ (noun) using BERT\nIn order to demonstrate the ability of language models to deal with polysemy,\nwe carry out a few experiments. Figure 2.10 illustrates words nearest to the vector\nspace of the word ‘wing’ (noun) in the MUSE embeddings26 using the t-Distributed\nStochastic Neighbor Embedding (t-SNE) plot (Van der Maaten and Hinton, 2008).\nConsidering the lemmata of these words, e.g. ‘wing’ and ‘winglet’ respectively for\n‘wings’ and ‘winglets’, this plot indicates that embeddings can retrieve some of the\nsemantically related words such as ‘rightwing’ with a political connotation, ‘under-\nwing’ as the hindwing of an insect and ‘empennage’ as the tail in aeronautics. In\naddition, the mapping of the monolingual word spaces of English and French results\nan approximate alignment of words in the two languages, with applications in un-\n26 https://github.com/facebookresearch/MUSE\n\n46\nbackground\nsupervised bilingual lexicon induction (Conneau et al., 2017). Interestingly, gauchiste\n(‘leftwing’) and radicalisé (radicalized) are among the words related to the political\nsense of ‘wing’.\nSimilarly, Figure 2.11 depicts various senses of ‘wing’ (noun) in\nBERT where our four targeted senses are retrieved.\nVarious studies have further demonstrated that word senses can be retrieved\nbased on language models (Athiwaratkun et al., 2018) or achieve state-of-the-art re-\nsults when used along with other LSRs (Levine et al., 2020). This being said, there\nis a sprawling literature on how word and contextual embeddings can be analyzed\n(Arora et al., 2020; Ji et al., 2022), evaluated (Nayak et al., 2016; Basta et al., 2019) and\nadapted to new domains and tasks (Merchant et al., 2020; Ueda et al., 2021). The\nlatter is also known as ‘ﬁne-tuning’.\nThe status of language models as language resources does not seem to be agreed\nupon. Certainly, language models do not ﬁt into the conventional deﬁnitions of LSRs,\nchieﬂy due to the lack of a structural representation of meaning. However, the fas-\ncinating ability of language models to capture contextual and semantic information\nusing unlabeled corpora is advancing the frontier in many NLP applications. As such,\namong the various lexical semantic theories, distributional semantics seem to provide\ncutting-edge solutions in language technology thanks to the multilingualism of the\nWeb and the availability of large corpora for many languages that do not necessarily\nneed human annotation.\n2.11\nconclusion\nIn this chapter, we shed light on various types of lexical semantic resources. Some of\nthe major concepts in lexical semantics are ﬁrst described, especially polysemy, that\nhave motivated different theories to represent word senses and shaped differences\nbetween many resources. After discussing the difference between a lexicon and a\ndictionary, we proceed with a thorough description of dictionaries based on their\ncontent and structure. Furthermore, we present a few resources as network-based\nas they employ common representation of data, for instance as networks or lexical\ngraphs. We also discuss how the structure of traditional electronic dictionaries is\ndeemed inefﬁcient for the computational processing of natural language; therefore,\na set of new resources are previously created with the primary goal of compatibil-\nity with technology. Among these resources, Explanatory Combinatorial Dictionary\n(Mel’ˇcuk, 2006), Generative Lexicon (Pustejovsky, 1995) and Natural Semantic Meta-\nlanguage (Wierzbicka, 1996) are presented. In the last part of the chapter a description\non terminologies, ontological resources and most importantly, knowledge graphs and\nlanguage models was provided. The latter two resources have led to much progress\nin language technology recently thanks to their coverage, convenient representations\nusing embeddings and easy integration within applications.\n\n2.11 conclusion\n47\nGiven the heterogeneity of lexical and semantic data and differences in struc-\nture and representation, important but challenging questions are raised regarding\nthe alignment and inter-operability of lexical semantic resources. As such, the focus\nof the next chapter is on providing a systematic review of methodologies for, and\napproaches to, working with LSRs – and particularly on aligning them. We will also\ngo through the major current tasks in NLP where LSRs play a central role.\n\n\n3\nSYST E M AT I C L I T E R AT U R E R E V I E W\n3.1\nintroduction\nIn the previous chapter, a background was provided on the different types of lan-\nguage resources, particularly lexical semantic resources. Given the diversity in types\nof resources as in dictionaries vs. wordnets, in coverage as in dictionaries vs. termi-\nnologies, in languages as in multilingual vs. monolingual resources and in creation\ntype as in expert-made vs. community-created resources, an important question is\nnaturally raised on how to model, create, enrich and publish language resources.\nAlthough there are many approaches to distinguish between these tasks, broadly\nreferred to as the life cycle of language resources (Rehm, 2016; Mattern, 2022), we\ncategorize the task related to managing language resources in these four components,\nas illustrated in Figure 3.1.\nThe components of Figure 3.1 are deﬁned as follows: the modeling phase focuses\non the way that lexicalized data are modeled, as in Ontolex-Lemon (McCrae et al.,\n2017b) vs. conventional dictionaries, in the creation phase, the curation method is\ndetermined, such as open collaborative, expert-made and semi-automatic methods,\nthe enrichment phase concerns tasks to maintain the resource and that increase the\ninter-operability and coverage of the resource, and ﬁnally, the publishing step regards\nplatforms, such as catalogs, and methods based on which a resource is published and\nmade accessible. The two last steps of enrichment and publishing are like a cycle that\na resource can visit many times.\nModeling\nCreation\nEnrichment\nPublishing\nFigure 3.1: A general description of the life cycle of a lexical semantic resource\nGoing beyond the characteristics of language resources, we shed light on the life\ncycle of language resources in this chapter. In line with the focus of this thesis on the\nalignment of lexicographical content, we delve more into the enrichment component,\nmostly from a monolingual perspective. To this end, the previous studies that explic-\nitly address the alignment task or implicitly solve a problem related to the alignment\ntask are reviewed. The alignment task consists of ﬁnding similar entities with dif-\nferent structures, as in ontologies, or content, as in sense deﬁnitions in dictionaries.\n49\n\n50\nsystematic literature review\nAs the topic of this thesis, the alignment of word senses and deﬁnitions aims to ﬁnd\npotentially alignable senses and deﬁnitions in two resources, and also, predict the\ntype of semantic relations that exist between the senses. This task can be implicitly\naddressed in tasks such as textual and non-textual similarity detection and semantic\nrelation induction which are relevant as underlying problems.\nSince the focus in this thesis is on monolingual resources, it is necessary to high-\nlight the distinction between monolinguality, multilinguality and cross-linguality, terms\nthat are widely used in the literature.\nA monolingual resource contains informa-\ntion in one language, regardless of the historical period that the language is docu-\nmented. A multilingual resource is characterized as one containing information in\nmore than one language. Multilinguality is thus the presence of content in at least\ntwo languages for a resource, such as a multilingual website or code-mixed corpora.\nThe characterization of an approach or tool as “multilingual” can indicate that it is\nlanguage-independent, i.e. can be applied to or used with more than one language.\nIn contrast, cross-linguality is typically applicable to tasks or operations in which\nitems expressed in one language are to be associated with items expressed in another\nlanguage. A cross-lingual resource is characterized by the presence of links or equiva-\nlences between data in different languages that allow navigation from information in\none language to information in another language. For example, cross-lingual informa-\ntion retrieval focuses on retrieving relevant documents that are written in a language\nother than the language in which the query is written. Other examples in NLP are\ncross-lingual word embeddings (Ruder et al., 2019), Universal Dependencies1 and\nmultilingual ontology mapping (Spohr et al., 2011).\nFurthermore, this chapter is extended to a summary of the utility of language\nresources in general, and dictionaries in particular, in language technology. To this\nend, some of the most important current applications of various language resources\nin computational linguistics and NLP are introduced. In addition, we focus on the\ncurrent standards and techniques for the creation, maintenance, enrichment and pub-\nlication of language resources. Motivated by the current advances in the semantic\nweb and linguistic linked open data, the most recent developments in these ﬁelds are\nsummarized as well.\n3.2\ncreation and modeling\nIn the creation and modeling step, a resource is to be implemented according to an\nencoding scheme. According to the Text Encoding Initiative (TEI) (TEI, 2020) guide-\nlines regarding dictionaries2, which can be used for a wide range of computational\nlexica, there are three views on modeling dictionary data, among many possible ones:\n1 https://universaldependencies.org\n2 http://web.uvic.ca/lancenrd/martin/guidelines/tei_DI.html\n\n3.2 creation and modeling\n51\n(i) a typographic view that focuses on the two-dimensional printed page, including\ninformation about the line and page breaks and other features of layout, (ii) an edi-\ntorial view that concerns the one-dimensional sequence of tokens which can be seen\nas the input to the typesetting process and (iii) a lexical view which includes the un-\nderlying information represented in a dictionary without concern for its exact textual\nform. In a print dictionary, the editorial and typographic views are addressed in\nan orderly way after the lexical view that may require extracting information from\na database. TEI provides a rich structure for modeling various types of resources\nand can be extended using other modules such as meta-data. Among the structured\nformats for lexicographical data, TEI is also the most widely used one. The following\nexample shows an example for an entry in a Kurdish dictionary. The entry in the\nprint dictionary is shown in Figure 3.2.\n<entry>\n<form>\n<orth>bend</orth>\n<pron>bænd</pron>\n</form>\n<gramGrp>\n<pos>n</pos>\n<gen>f</gen>\n</gramGrp>\n<sense n=\"1\">\n<cit type=\"translation\" xml:lang=\"en\">\n<quote>bond</quote>\n</cit>\n<cit type=\"example\">\n<quote>divê em êdî li benda sibehê ranewestin.</quote>\n<cit type=\"translation\" xml:lang=\"en\">\n<quote>we shouldn't stand around waiting for tomorrow.</quote>\n</cit>\n</cit>\n</sense>\n</entry>\nGiven the increasing importance of ﬁndable, accessible, interoperable and reusable\ndata, known as the FAIR principle (Wilkinson et al., 2016; Khan et al., 2021), the se-\nmantic web technologies are ideal for lexicographic data in comparison to XML-based\nor less semantic models such as TEI (Tchechmedjiev, 2016; Klimek and Brümmer,\n2015).\nIn this vein, one of the most important models for lexicographical data is\nOntolex-Lemon (McCrae et al., 2017b). This model, as brieﬂy described in Section\n2.8.1, is RDF-native and built in a modular way.\nBosque-Gil et al. (2017) extend\nOntolex-Lemon by adding a module for lexicography called lexicog. This module\nrepresents information, structures and annotations that are commonly found in lex-\nicography.\nThe lexicographic resource class in this module is used to represent the\n\n52\nsystematic literature review\noriginal printed entry structures. In addition, it is possible to add usage examples\nusing the UsageExample class.\nbelekî f water spring\nbelengaz poor, destitute; ~î f poverty,\ndestitution\nbélê yes\nbelg m leaf\nbelgih m suit, clothing; ~ girtin v.t. to\ngarb oneself\nbelkî maybe, perhaps\nben = bend\nbend f bond; li ~a for the sake of,\nchained to, waiting for: divê em êdî li\nbenda sibehê ranewestin we should-\nn’t stand around waiting for tomor-\nrow; ~ kirin v.t. to fetter, arrest; man\ndi ~a to wait for\nbenderuh creature\nbendewar bûn bi to love, be in love\nwith\nbenzîn f gasoline\nbeq m frog\nber1 m breast, fore; ber-dan see alpha-\nbetically; ~ bi hev hatin v.i. to coop-\nerate; ~ê (ve) (adv.) before; ~î ku\n(conj.) before; ji ~ kirin v.t. to mem-\norize; ji ~ jmartin v.t. to reel off from\nmemory; ji ~ ku because (conj.); ji ~\n… ve (ccmp.) before; ji ~ zanîn v.t.\nto memorize; li ~ (prep.) before, on\naccount of; li ~ (+ inf.) on the verge\nof: ew hêviya ku li ber geşbûnê bû\nçilmisî that hope, which was on the\nverge\nof\nblossoming,\nwithered;\nwek(e) ~ê as before\nber2 m yield, fruit; ~ wergirtin ji to de-\nrive a yield from\nberamber equal, equivalent; ~î f equal-\nity; ~î … kirin v.t. to compare to: wî\new beramberî Anton Çexov dikir he\nused to compare him to Anton Che-\nkhov\nberan m ram\nber-anîn (ber-în) v.t. to imagine\nberate f carcass\nberban m ceiling\nberberî f comparison\nberbêjî f prediction\nberbiçav conspicuous\nberbihevhatin f cooperation\nberbînî f imaginary image, vision\nbercênîk ???\nberçav visible, clear, before the eyes; ~\nanin v.t. to pay attention\nber-dan v.t. to release, let go; to put on\n(clothes); to close, stop, give up: dev\n~ ji to close the mouth to, stop, give\nup; ~ ser to direct toward; tiving ~ to\nﬁre a riﬂe at: xulamê wî ew da ber\ntiﬁngê his servant ﬁred the riﬂe at\nhim; xwe ~ ser to turn oneself to-\nward, direct oneself to\nberdest servant\nberdewam continual(ly), constant(ly); ~\nkirin v.t. to continue\nberdêl f equivalent; ji ~a instead of\nberdêlk = berdêl; bi ~ equivalent in\nvalue\nberebere more and more, ever more;\ngradually, little by little\nbereket m blessing; bi ~ luckily\nberev = berhev\nberf f snow\nberferih spacious; ~ kirin v.t. to open,\ninitiate\nbergeh f view, vista\nberhem m product, literary work; ~bar\nproductive\nberhev gathered, collected; ~ kirin v.t.\nto prepare, gather; xwe ~ kirin v.t. to\npull oneself together\nberhevok f collection\nberik f bullet\nberiqîn v.i. to glisten\nberizîn bi v.i. to ﬁght with, do battle\nwith\nberî f pocket\nberîde perplexed, lost\nberîk f pocket\nber-ketin v.i. to feel sad\nKURDISH-ENGLISH VOCABULARY\n199\n1\n:lexicon a lime:Lexicon;\n2\nlime:language\n<www.lexvo.org/page/iso639-3/kmr> ;\n3\nlime:entry :lex_bend .\n4\n5\n:lex_bend a ontolex:LexicalEntry,\nontolex:Word ;\n6\nontolex:canonicalForm :form_bend ;\n7\nrdfs:label \"bend\"@kmr-latn .\n8\nlexinfo:partOfSpeech lexinfo:noun ;\n9\nlexinfo:gender lexinfo:feminine ;\n10\nontolex:sense :bend_n_sense ;\n11\n:form_bend a ontolex:Form ;\n12\ndct:language\n<www.lexvo.org/page/iso639-3/kmr> ;\n13\nontolex:writtenRep \"bend\"@kmr-latn ;\n14\nlexinfo:number lexinfo:singular ;\n15\n:bend_n_sense a ontolex:LexicalSense ;\n16\nlexicog:usageExample :bend_n_sense_ex .\n17\n:en_bond a ontolex:LexicalEntry ;\n18\ndct:language\n<http://lexvo.org/id/iso639-1/en> ;\n19\nrdfs:label \"bond\"@en ;\n20\nontolex:sense :en_bond_sense .\n21\n:trans a vartrans:Translation ;\n22\nvartrans:source :bend_n_sense ;\n23\nvartrans:target :en_bond_sense .\n24\n:bend_n_sense_ex a lexicog:UsageExample;\n25\nrdf:value \"divê em êdî li benda sibehê\nranewestin.\"@kmr-latn .\n26\nrdf:value \"we shouldn't stand around\nwaiting for tomorrow.\"@en .\nFigure 3.2: The conversion of an example entry from a Kurdish-English dictionary into RDF\nTurtle based on the OntoLex-Lemon model (to the right)\nFigure 3.2 shows an example for the entry ‘bend’ (‘bond’ (noun)) in a print dictio-\nnary versus the transformation in RDF Turtle in Ontolex-Lemon. In this entry, the\nfollowing core modules of Ontolex-Lemon are used:\n• Linguistic Metadata module–lime that allows us to describe metadata at the\nlevel of the lexicon-ontology interface with information such as lexical entries\nand language (lines 1 to 3 in Figure 3.2).\n• Syntax and Semantics–synsem allows us to describe syntactic behavior. Syntactic\nframes are used to relate a lexical entry to one of its various syntactic roles, such\nas the canonical form of the word bend described in lines 5 to 7 in Figure 3.2).\n\n3.3 enrichment\n53\n• lexinfo (Cimiano et al., 2011) for describing relevant linguistic categories and\nproperties, particularly part-of-speech, gender and number (lines 9 to 15 in Fig-\nure 3.2).\n• Variation and Translation–vartrans is used to describe relations between lexical\nentries, particularly translations as shown in lines 17 to 19 in Figure 3.2.\nIt is worth emphasizing the extent to which data can be ﬁnely represented in this\nmodel; for instance, lexicalized data, i.e. literals in RDF, can be speciﬁed by language\ntags according to ISO 639-33 as well as scripts such as arab for Arabic and latn\nfor Latin. Furthermore, the micro-structure of a print dictionary is not necessarily\nidentical in terms of information when converted into Ontolex-Lemon as it requires\nadditional processing. For instance, compound forms ‘∼kirin’ (to arrest, to fetter) and\n‘man di ∼a’ (to wait for), where ∼refers to the lemma, are respectively replaced by\n‘bend kirin’ and ‘man di benda’ and deﬁned as separate entries.\nThe modeling phase requires an extensive study on the aspect of the lexicograph-\nical data, such as morphology (Klimek et al., 2019), phonology (Moran and McCloy,\n2019) and syntax (Corcoglioniti et al., 2016). Some of the other data models and vo-\ncabularies developed for lexicographic data are the lexical markup framework (Fran-\ncopoulo et al., 2006), ELEXIS Data Model (Tiberius et al.), TELIX (Rubiera et al., 2012),\nMLR model (Spohr, 2012), Lexfom (Fonseca et al., 2016), among others. Bosque-Gil\net al. (2018) provides a survey on such models.\nSimilarly, some of the the platforms for creating language dictionaries are LexO\n(Bellandi, 2021), FLEx (Butler and Van Volkinburg, 2007), Léacslann (Mˇechura, 2012),\nSooSL4, Lexique Pro (Guérin and Lacrampe, 2007) and ELEXIFIER5. On the other\nhand, Wiktionary6, Language Forge7, LEO8 and Reverso9, focus not only on dictio-\nnary creation, but also making the creation process accessible to a community.\n3.3\nenrichment\nAutomatic and semi-automatic enrichment of language resources has received much\nattention thanks to the advances in language technology and also, the expansion of\nmultilingualism and the plethora of electronic resources available. Inter-connected\nand inter-operable resources not only improve word, knowledge and domain cover-\nage and enhance multilinguality, it has been also shown that it is beneﬁcial to improve\nlanguage technology applications such as machine translation (Zhao et al., 2020) and\n3 https://iso639-3.sil.org/code_tables/639/\n4 https://www.soosl.net\n5 https://elexiﬁer.elex.is\n6 https://www.wiktionary.org\n7 https://languageforge.org\n8 https://www.leo.org\n9 https://www.reverso.net\n\n54\nsystematic literature review\nalso, create centralized repositories of data (Gurevych et al., 2012). However, linking\nconcepts and words across resources is challenging, especially due to the complex-\nity of the structure of LSRs which generally contain heterogeneous and multi-lingual\ndata.\nIn this section, among the many tasks to enrich language resources, we focus\non the tasks most related to the main topic of the thesis. The tasks are semantic\nsimilarity detection and language resource alignment in its broad scope. We will also\nsummarize the previous works in translation inference.\n3.3.1\nSemantic Similarity Detection\nThe objective of text similarity detection techniques is to estimate the level of sim-\nilarity of two text documents or strings in an automatic way. Given the usage of\nthis task in many applications, from a basic string-based text ﬁnder in text editors\nto more sophisticated semantic-based problems such as word sense disambiguation\n(Prior and Geffet, 2003), question answering (Jin et al., 2019), paraphrase identiﬁ-\ncation (Mohamed and Oussalah, 2020) and natural language inference (Lan and Xu,\n2018), semantic similarity detection has received much attention in NLP and has been\ninstrumental. Many surveys are available on the same topic, as in Vijaymeena and\nKavitha (2016); Sunilkumar and Shaji (2019); Chandrasekaran and Mago (2021).\nThis task has been widely studied in two major branches: lexical similarity de-\ntection and semantic similarity detection. While the ﬁrst task aims to evaluate the\nsimilarity of two strings at the string level, for instance ‘book’ and ‘books’ are simi-\nlar lexically, semantic-based approaches take the meaning of the words into account\nas well, as in ‘king’ and ‘queen’. To deﬁne what is meant by semantic or concep-\ntual similarity, there are different objectives such as association, relatedness or topical\nsimilarity, that can be indicative of the relationships. Furthermore, similarity can be\ncalculated at various levels, such as character-level, word-level and sentence-level. As\na basic method, the similarity at a higher level, i.e. sentence, can be calculated based\non the similarity at a lower level, i.e. word, meaning that words within two sentences\nare compared to determine the level of similarity. In embedding-based approaches,\nthe similarity of sentences can be estimated by merging the vector values of the com-\nposing words and averaging them. This being said, there are other techniques based\non convolutional neural networks (Yao et al., 2018), semantic networks (Li et al., 2006)\nand using syntactic and semantic features (Quan et al., 2019), to mention but a few.\nBeyond string-based similarity detection approaches, as discussed in Cohen et al.\n(2003), this section provides various methods that have been previously proposed for\nsimilarity detection. In addition to these approaches, there are hybrid approaches\nthat rely on the information extracted from various sources, as in Zhu and Iglesias\n(2016), Cai et al. (2018), Li et al. (2003) and Mohamed and Oussalah (2020).\n\n3.3 enrichment\n55\nCorpus-based approaches\nIn this approach, the similarity is calculated based on the information extracted from\nlarge corpora. The assumption of a word being known by “the company it keeps” is\nnot only foundational to corpus-based approaches in similarity detection, but also\nto many other advances in distributional semantics, especially word embeddings\n(Almeida and Xexéo, 2019). Previous studies have proposed co-occurrence extraction\n(Kolb, 2008), point-wise mutual information (Bouma, 2009; Islam and Inkpen, 2006),\nlatent semantic analysis (Hofmann, 1999; Islam and Hoque, 2010), hyperspace ana-\nlogue to language (Azzopardi et al., 2005), normalized Google distance (Cilibrasi and\nVitanyi, 2007), explicit semantic analysis (Egozi et al., 2011) and dependency-based\nmodels (Agirre et al., 2009).\nLSR-based approaches\nThese approaches incorporate knowledge about words, such as lexical and seman-\ntic relations, from LSRs to estimate the similarity. WordNet (Miller, 1995) as a rich\nsemantic network, for instance, has been widely used in the similarity task (Meng\net al., 2013). Various measures have been proposed to use the taxonomic and lexical\ninformation of WordNet and dictionaries. Leacock and Chodorow (1998) introduce\na similarity measure according to the path length between two words in WordNet.\nLesk (1986) proposes an algorithm to calculate the similarity based on the overlap of\nword deﬁnitions in dictionaries, with primary application in word sense disambigua-\ntion. Wu and Palmer (1994) uses depth of concepts in the WordNet to measure the\nstructural relations, i.e. how they are related in the hierarchy, for similarity detec-\ntion. Kubis (2015) creates a framework for similarity detection based on WordNets\nand various other resources such as Wikipedia. And, Jiang et al. (2015) employs a\nfeature-based technique using deﬁnitions of word extracted from Wikipedia.\nEmbeddings-based approaches\nWith the emergence of various frameworks in deep learning and the availability of\nlarge corpora for many languages, there have been many advances in utilizing distri-\nbutional semantics, particularly embeddings, for semantic similarity detection. Akin\nto corpus-based approaches, the surrounding words of a given word within a text\nare taken into account to create the embeddings of that speciﬁc word. By comparing\nthe embeddings of two words, which are in fact two vectors with the same dimen-\nsion, the level of similarity can be estimated by measuring the distance between the\nvectors. As it was discussed in Section 2.10, word embeddings were previously strug-\ngling to differentiate between different senses of a word in context, a problem known\nas meaning conﬂation deﬁciency (Camacho-Collados and Pilehvar, 2020). This has\nbeen addressed, to some extent, in contextual embeddings.\n\n56\nsystematic literature review\nCreating embeddings has been carried out at various levels such as word em-\nbeddings (Pennington et al., 2014), sense embeddings (Iacobacci et al., 2015), dictio-\nnary embeddings (Tissier et al., 2017), topic embeddings (Liu et al., 2015), context\nembeddings (Melamud et al., 2016), tweet embeddings (Vosoughi et al., 2016), meta-\nembeddings (Kiela et al., 2018) and sentence embeddings (Gao et al., 2021). Although\nthese embeddings are intended to perform differently and more effectively based on\nthe application, they follow the same principle of learning vector representations for\nwords.\nDatasets\nDespite the efforts in making machines understand words and sentences and capture\nmeaning from documents, estimating semantic similarity is a challenging task. A\nsolution would be to create datasets based on domain, application and language,\ninitially for evaluation purposes but ultimately, for training deep learning models\nand ﬁne-tuning pre-trained models. There are many datasets to train and evaluate\nsemantic similarity for different tasks. One of the most important initiatives in this\nﬁeld is the SemEval semantic textual similarity (STS) shared tasks (Agirre et al., 2013,\n2016b; Cer et al., 2017). STS shared tasks are organized based on a framework where\na pair of sentences are scored (Baudiš et al., 2016). Many datasets10 have been created\nfor STS in English and based on various sources such as news, captions and forum.\nIn the STS benchmark, the semantic similarity of independent pairs of texts, typically\nshort sentences, is determined and the similarity is rated as a number between 0 to 5\nto each pair denoting the level of similarity or entailment. In SemEval-2014 (Jurgens\net al., 2014), the cross-level semantic similarity was targeted where the similarity is\nto be estimated at four levels as paragraph to sentence, sentence to phrase, phrase to\nword and word to sense. The similarity score is categorically rated as very similar,\nsomewhat similar, somewhat related but not similar, slightly related and unrelated.\nFurthermore, there are other benchmarks focusing on speciﬁc techniques, such as\nthe evaluation of distributional semantic models as in (Marelli et al., 2014; Hill et al.,\n2015), or speciﬁc linguistic properties as in Verb-3500 (Gerz et al., 2016).\nIn the same vein, there are a few datasets for evaluation of semantic similarity in\nmonolingual setups such as for Russian (Panchenko et al., 2018), Finnish (Venekoski\nand Vankka, 2017) and Turkish (Ercan and Yıldız, 2018). This being said, there are\nnot many datasets for lesser-resourced languages with signiﬁcant coverage.\nIn a\nmultilingual context, Vuli´c et al. (2020a) introduce Multi-SimLex – a suite of 66 cross-\nlingual semantic similarity data sets of 12 languages. Barzegar et al. (2018) create\ndatasets for 11 languages for semantic similarity and relatedness detection. In the\ncontext of lexicography, (Li et al., 2006) carries out a relevant study to create an\nevaluation dataset for semantic similarity using word deﬁnitions extracted from a\ndictionary and containing 65 noun pairs.\n10 Available at http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\n\n3.3 enrichment\n57\n3.3.2\nLanguage Resource Alignment\nAccording to Gurevych et al. (2016), there are three main linking approaches applica-\nble to language resources in general, and electronic lexicography in particular: ontol-\nogy matching, schema matching and graph matching. As the basis of our analysis of\nthe previous work, we focus on these approaches as well as follows:\nOntology matching which aims to ﬁnd semantically-related entities across ontolo-\ngies. As described in Section 2.8, many language resources have ontological\nfeatures for which ontology matching can be beneﬁcial. This has been previ-\nously the case for aligning WordNet (Lin and Sandkuhl, 2008). In monolingual\nontology matching, entities in the source and target ontologies are compared by\ntheir labels which are in a single language. In multilingual ontology matching,\nthis comparison is carried out between at least two languages. On the other\nhand, in cross-lingual ontology matching, the process is done by translating la-\nbels between languages (Fu et al., 2009). Previously, many approaches have been\nproposed, particularly in the context of the Ontology Alignment Evaluation Ini-\ntiative11. The matching is carried out in two levels: terminological matching\nwhich focuses on the lexical comparison of ontologies and the semantic simi-\nlarity of lexicalized data, and structural matching which takes the conceptual\nproperties along with the structural information into account. SAMBO (Lam-\nbrix and Tan, 2006), OAANN (Huang et al., 2008) and Logmap (Jiménez-Ruiz\nand Cuenca Grau, 2011), are some of the many systems proposed for match-\ning. Surveys on the recent advances in this ﬁeld are provided by Shvaiko and\nEuzenat (2011); Khoudja et al. (2018); Ochieng and Kyanda (2018).\nGraph matching refers to a set of techniques that rely on structural properties of\nthe data where lexicalized data are considered as the nodes of a graph and\nthe semantic relation between them are the edges. This way, a range of graph\nmatching problems that have been historically of interest in mathematics, such\nas the PageRank algorithm (Xing and Ghorbani, 2004) and random walk (Lawler\nand Limic, 2010), are applicable to the problem. Furthermore, the current ad-\nvances in representing graphs using neural networks, also known as graph neu-\nral networks, have paved the way for more robust systems that are currently the\nstate-of-the-art (Ling et al., 2022).\nDatabase schema matching which is similar to the previous two approaches in the\nsense that the structural properties of linguistic data as in relational databases\nare used for the matching problem.\nThis approach is less of use given the\nemerging widespread usage of semantic technologies, like linked data, which\nare not dependent on relational data anymore.\n11 http://oaei.ontologymatching.org\n\n58\nsystematic literature review\nIt should be noted that multilingualism is an aspect that can exist in all the ap-\nproaches. Furthermore, the usage of a particular method for dictionary alignment\ndepends on the heterogeneity of the data caused by the structure or data model that\nthe two resources employ. For instance, aligning two dictionaries, one in Ontolex-\nLemon and the other in LMF, represents challenges different from aligning both of\nthem in the same form. As such, there are many hybrid techniques for the same\nproblem.\nTable 3.1 summarizes some of the previous contributions in resource alignment\nbased on approach, level (monolingual, cross-lingual), type of resource as described\nin Chapter 2 and type of linking (structural, conceptual, lexical).\nRegarding ap-\nproaches, “formalism” refers to any symbolic or axiomatic solution for matching\nresources that has been introduced in the literature.\nPaper\nApproach\nLevel\nType of resource\nType of linking\n(Caselli et al., 2014)\nsemantic similarity\nmonolingual\nlexical\nlexical\n(Bennett\nand\nFellbaum,\n2006; Kwong, 1998)\nformalisms\nmonolingual\nlexical\nontological\n(Niles and Pease, 2003)\nformalisms\nmonolingual\nlexical\nontological\n(Sánchez-Rada and Iglesias,\n2016)\nformalisms\nmonolingual\nontological\nstructural\n(Diosan et al., 2008)\nmachine learning\nmonolingual\nlexical\nlexical\n(Subirats and Sato, 2004)\ncorpus\nmonolingual\nlexical\nlexical\n(Bond and Foster, 2013)\nformalisms\nmultilingual\nlexical\nstructural\n(Caracciolo et al., 2012; Cimi-\nano\net\nal.,\n2020b;\nMous-\nsallem et al., 2018)\nstring similarity\nmultilingual\nlexical\nontological\n(Lesnikova, 2013; Lesnikova\net al., 2016)\nmachine translation\nmultilingual\nlexical\nstructural\n(Gracia, 2015; Gracia et al.,\n2018)\nformalisms\nmultilingual\nlexical\nstructural\n(Spohr et al., 2011)\nmachine learning\nmultilingual\nontological\nstructural\n(Damova et al., 2013)\nformalisms\nmultilingual\nlexical/ontological structural\n(Charles et al., 2018)\nformalisms\nmultilingual\nknowledge graph\nontological\n(Biemann et al., 2018)\ndistributional semantics\nmultilingual\nlexical\nlexical/ontological\n(Chen et al., 2016c)\ngraph neural networks\ncross-lingual\nknowledge graph\nstructural\n(Schuster et al., 2019)\nmapping of word spaces\ncross-lingual\ncontextual\nem-\nbeddings\nlexical\nTable 3.1: A summary of the previous studies in aligning resources\n3.3.3\nTranslation Inference\nOne particular task that can facilitate the usage of dictionaries across languages and\nfurther add to the content value is translation inference, also known as bilingual lexi-\ncon induction. In this section, we give an overview of methods to acquire multilingual\nlexicons.\nThe translation inference task aims to generate a new dictionary by inducing\nnew translations from the existing ones. For instance, the translation pair ‘pomme’\n(French) →‘sêw’ (Kurdish) can be induced from ‘pomme’ (French) →‘apple’, ‘ap-\nple’ →‘sêw’ (Kurdish). In this context, the Translation Inference Across Dictionaries\n\n3.3 enrichment\n59\n(TIAD) shared task aims to incentivize researchers to propose new techniques and\napproaches to translation inference in an unsupervised way. Table 3.2 summarizes\nthe previously proposed techniques in the TIAD shared tasks.\nAmong the previous techniques, pivot-based (Torregrosa et al., 2019), cycle-based\n(Donandt et al., 2017b) and one time inverse consultation approaches (Lanau-Coronas\nand Gracia, 2020) are applied. On the other hand, external resources are used in an\nunsupervised way to train multi-way machine translation models and cross-lingual\nword embedding mappings. Although these techniques align translations without\nbeing trained on parallel corpora, they face challenges in retrieving part-of-speech\ntags and lemmatizing various word forms (Arcan et al., 2019a).\nTanaka and Umemura (1994b) generate a bilingual dictionary using the structure\nof the source dictionaries. They introduced the inverse consultation approach which\nmeasures the semantic distance between two words based on the number of their com-\nmon words in the pivot language. Using this method, Schafer and Yarowsky (2002)\ncreated an English-Gujarati lexicon using Hindi as the pivot. Similarly, Tsunakawa\net al. (2009) used English as an intermediate language to create a Chinese-Japanese\nlexicon. The IC method was extended by taking more lexical and semantic informa-\ntion into account Kaji and Aizono (1996). For instance, Bond and Ogura (2008) used\npart-of-speech information and semantic classes to produce a Japanese-Malay dictio-\nnary with English as the pivot. Sjöbergh (2005) created a Japanese-Swedish dictionary\nby linking words based on the sense deﬁnitions, whereas Kaji et al. (2008) constructed\na Japanese-Chinese dictionary using a pivot English lexicon and co-occurrences infor-\nmation for more accurate alignment.\nThe high dependency of the inverse consultation method on one language as a\npivot has been shown to create limited translations with ambiguity and low recall\nShezaf and Rappoport (2010); Saralegi et al. (2011). One way to remedy this is to\nuse multiple pivot languages with additional resources.\nPaik et al. (2001) gener-\nated a Korean-Japanese dictionary using English and Chinese pivot languages and\nan English thesaurus.\nSoderland et al. (2009) described the automatic generation\nof a multilingual resource, called PanDictionary. In this work, the authors used\nprobabilistic inference over the translation graph. The construction of the dictionary\nconsisted of extracting knowledge from existing dictionaries and combining the ob-\ntained knowledge into a single resource. István and Shoichi (2009) took advantage\nof the semantic structure of WordNet as the pivot language for creating a new lex-\nicon for less-resourced languages. Mann and Yarowsky (2001) used string distance\nto create bilingual lexicons based on transduction models of cognates, as languages\nbelonging to a speciﬁc language family usually share many cognates.\nFurthermore, Paik et al. (2004) examines the impact of the translation direction\nin merging dictionaries. Mausam et al. (2009) describe the automatic generation of a\nmultilingual resource, called PanDictionary. In the proposed work, the authors use\nprobabilistic inference over the translation graph. The construction of the dictionary\n\n60\nsystematic literature review\nconsists of large-scale information extraction over the Web, i.e. extracting knowledge\nfrom existing dictionaries, and combining the obtained knowledge into a single re-\nsource. The ﬁnal step consists of performing automated reasoning over the graph.\nTanaka and Umemura (1994a) introduce a bilingual dictionary generation using the\nPrinceton WordNet of the pivot language to build a new bilingual dictionary. Instead\nof focusing on the lexical overlap, the authors calculate the semantic lexical overlap\nof the source-to-pivot and target-to-pivot translations.\nYear\nTarget dictionaries\nPaper\nApproach\nExternal\nre-\nsources\n2017\nGerman-Portuguese\nDanish-Spanish\nDutch-French\n(Alper, 2017b)\ngraph analysis\n-\n(Proisl\net\nal.,\n2017b)\ngraph\nanalysis\nand\ncollocation-based models\nEuroparl corpus\n(Donandt\net\nal.,\n2017b)\nSupport Vector Machine us-\ning features based on the\ntranslation graph and string\nsimilarity\n-\n2019\nEnglish\nFrench\nPortuguese\n(Arcan\net\nal.,\n2019a)\nmulti-way neural machine\ntranslation\ncorpora\nof\nlan-\nguages from the\nsame family and\nWiktionary\n(Torregrosa et al.,\n2019)\ngraph analysis and neural\nmachine translation\nDirectorate\nGeneral\nfor\nTranslation\ncor-\npus (Steinberger\net al., 2013)\n(Garcia et al., 2019)\npivot-based\nand\ncross-\nlingual word embeddings\nmonolingual cor-\npora\n(Donandt\nand\nChiarcos, 2019)\nmulti-lingual word embed-\nding\npretrained\nem-\nbedding model\n(McCrae, 2019)\nunsupervised document em-\nbedding using Orthonormal\nExplicit Topic Analysis\nWikipedia\ncor-\npora\n2020\nEnglish\nFrench\nPortuguese\n(McCrae and Ar-\ncan, 2020)\nunsupervised\nmulti-way\nneural\nmachine\ntransla-\ntion\nand\nunsupervised\ndocument embedding\nDirectorate\nGeneral\nfor\nTranslation\ncor-\npus (Steinberger\net al., 2013)\n(Chiarcos\net\nal.,\n2020)\npropagation\nof\nconcepts\nover a graph of intercon-\nnected\ndictionaries\nusing\nWordNet synsets and lexical\nentries as concepts\nWordNet\n(Lanau-Coronas\nand Gracia, 2020)\ngraph analysis and cross-\nlingual word embeddings\nmonolingual\ncorpora of Com-\nmon Crawl and\nWikipedia\n(Dranca, 2020)\ngraph analysis relying on\npaths,\nsynonyms,\nsimilari-\nties and cardinality in the\ntranslation graph\n-\nTable 3.2: An overview of the approaches proposed in the previous TIAD shared tasks\n\n3.4 publication and storage\n61\n3.4\npublication and storage\nGiven the increasing number of language and linguistic resources, providing sustain-\nable mechanisms for access and discovery of such resources is a challenging task.\nOnce a resource is released many issues are to be tackled, particularly sustainability,\nboth technical and organizational, availability and ﬁndability, selection and qualiﬁca-\ntion for long-term archiving, and legal issues (Georg et al., 2010). These factors have\nled to many initiatives to create catalogs, platforms, portals, and various linguistic\nresource metadata for linguistic data management.\nAlthough metadata schemata may be represented with many common features,\nsuch as name, language and license of the resource, they are usually different in cov-\nerage, features such as labels and datatypes, approach as collaborative or centralized\ncuration, format, e.g. XML or RDF, and standards. Recent schemata further empha-\nsize the ﬁndable, accessible, interoperable and reusable factors as well.\nOne of the well-known sources of publishing and maintaining language resources\nis META-SHARE (Piperidis, 2012). META-SHARE is a platform to document repos-\nitories of language data and tools from the production stage up to their usage. The\nschema used in this network is implemented in XML and XML Schema Deﬁnition. In\naddition to this, there are many other services for the same objective, such as SPLICR\n(Rehm et al., 2008), the European Language Resources Association12, the Linguistic\nData Consortium13, the Language Grid14, Open Language Archives Community15\nand CLARIN Virtual Language Observatory16. Moreover, there are several others\nwhich are created by crowd-sourcing and community efforts, such as LRE Map17,\nEUDAT18, OpenAire19, PHOIBLE (Moran and McCloy, 2019) and Datahub20. Meta-\ndata has received fair attention in the semantic web ﬁelds, as well. Notable examples\nare the metadata vocabularies such as the DCAT vocabularyMaali et al. (2014) and\nthe LInguistic MEtadata module of Ontolex-Lemon–lime (Fiorelli et al., 2015).\nOne of the main problems in dealing with these repositories and catalogs is\nthe lack of harmonization among them (Cimiano et al., 2020a). To this end, there\nhave been many initiatives such as the ISOcat data category registry (ISOcat DCR)\n(Kemps-Snijders et al., 2008), the General Ontology of Linguistic Description (Far-\nrar and Langendoen, 2010) and Ontologies of Linguistic Annotation–OLiA (Chiarcos\nand Sukhareva, 2015). Motivated to ensure more qualitative metadata and increas-\ning homogeneity, McCrae et al. (2015) develop an ontology in OWL to represent the\n12 www.elra.info\n13 https://www.ldc.upenn.edu\n14 https://langrid.org\n15 http://www.language-archives.org\n16 https://www.clarin.eu/content/virtual-language-observatory-vlo\n17 http://lremap.elra.info\n18 https://www.eudat.eu\n19 https://www.openaire.eu\n20 https://datahub.io\n\n62\nsystematic literature review\nmetadata schemes. The data model is also available through a platform called Yuzu21\n(McCrae, 2016) which enables running SPARQL queries on the aggregated datasets.\nSimilarly, the data model is represented in the Linguistic Metadata Hub – Linghub22\n(McCrae and Cimiano, 2015) and the IULA LOD catalogue23 as well.\n3.5\ndictionaries in nlp applications\nDictionaries have been historically an essential part of NLP applications such as spell\ncheckers and morphological analyzers (Ahmadi, 2021), word sense disambiguation\n(Krovetz and Croft, 1989), part-of-speech tagging (Täckström et al., 2013), syntactic\nanalysis (Gross, 1984) and co-reference resolution (Sleeman and Finin, 2013).\nIn this section, some of the most relevant tasks to the topic of the thesis are brieﬂy\ndiscussed. These tasks facilitate the alignment tasks in one way or another.\n3.5.1\nWord Sense Disambiguation\nWord Sense Disambiguation (WSD) is the task of identifying the meaning of a word\nin the context. For instance, in the bank model described in Section 2.2.2, WSD detects\n‘bank’ in the sentence ‘paid into a bank account’ as a ﬁnancial institution while ‘bank’\nin ‘the bank of the river Corrib’ refers to a riverbank. This task has been extensively\nstudied with many approaches ranging from knowledge bases (Scozzafava et al., 2020;\nBlevins and Zettlemoyer, 2020) to unsupervised methods (Navigli and Lapata, 2009;\nRaganato et al., 2017; Ustalov et al., 2018), with the former methods or hybrid ones\noutperforming the latter methods. Bevilacqua et al. (2021) provide a recent survey on\nthe current trends of this historical task in NLP.\nWSD is related to WSA as both of them focus on identifying the meaning of poly-\nsemous words; however, the reliance of WSD on the context makes it quite different\nfrom WSA, as deﬁned in this thesis, which only takes lexical and structural proper-\nties of words in language resources into account, regardless of the context in which\nthe word appears. This being said, merging WSA and WSD by incorporating word\nsense contexts based on corpora in the alignment task is a compelling task that can\nbe addressed.\n3.5.2\nSemantic Role Labeling\nSemantic role labeling aims to identify and label arguments and role-bearing con-\nstituents in a text. The primary goal of this task is to ﬁnd the semantic relations\n21 https://github.com/jmccrae/yuzu\n22 https://github.com/liderproject/linghub\n23 http://lod.iula.upf.edu\n\n3.5 dictionaries in nlp applications\n63\nbetween a predicate and its associated participants and properties (Màrquez et al.,\n2008). Such relations are predeﬁned based on the predicates, as in ‘whisper’ in the\nsentence ‘the girl whispered to the boy’ where ‘the girl’ is the agent and ‘the boy’ is\nthe recipient.\nSemantic role labeling is important to the alignment task as identifying semantic\nroles in sense deﬁnitions could be beneﬁcial to determine if two senses should be\nlinked. Employing semantic role labeling, however, has not received much attention\nfor WSA. One notable example is proposed by (Silva et al., 2016) where a rule-based\nframework is presented to extract semantic roles from deﬁnitions relying on syntactic\nand semantic features. These roles are to be labeled based on a genus-differentia\npattern which is further deﬁned at a ﬁner level as shown in Figure 3.3.\nFigure 3.3: A conceptual model proposed by Silva et al. (2016) to extract semantic roles from\nsense deﬁnitions. Dashes lines refer to relationships between particles, such as a\nphrasal verb complement, in the deﬁnition.\n3.5.3\nReverse Dictionary\nAnother interesting avenue of research is reverse dictionary or concept ﬁnder which\ngiven a deﬁnition, an associated concept is returned (Zock and Bilac, 2004). In an at-\ntempt to ﬁll the gap of representation of lexical and phrasal semantics, Hill et al. (2016)\npropose a neural language model technique to map between arbitrary-length phrases\nand ﬁxed-length continuous-valued word vectors using word deﬁnitions. This task\nis of interest, particularly as it provides a mechanism to explain the behavior and the\ntype of information that a neural model would learn in the embedding process. In\nother words, how a sense can be embedded differently or similarly through the word\nand the deﬁnition knowing that both the word and the deﬁnition are conceptually\nand semantically referring to the same meaning.\n\n64\nsystematic literature review\n3.6\nwhat is missing?\nIn this chapter, some of the most related tasks to word sense alignment are presented.\nWe started with an introduction into the life cycle of language resources at a broad\nscope as follows: modeling, creation, enrichment and publication. Even though the\nmodeling based on which a resource is created may remain the same, a resource can\nundergo various changes and be published in different versions. Given the focus of\nthe thesis, it made sense to focus on the enrichment step more than the other ones. To\nthis end, the most relevant tasks to word sense alignment are brieﬂy discussed. These\ntasks are semantic similarity detection, resource alignment and semantic resource\ninduction. Finally, the chapter ends with a summary of the applications of LSRs in\nNLP such as word sense disambiguation and translation inference.\nAs the survey indicates, there are two major limitations in the literature: (i) there\nis no multilingual benchmark for the evaluation for word sense alignment, (ii) de-\nspite the previous tasks in language resource alignment, there is not much focus on\nlexicographical data speciﬁcally. These hinder the progress in exploring, integrat-\ning and exploitation of dictionaries in language technology, linked data and various\napplications in NLP.\n\n\n4\nL E V E R A G I N G T H E G R A P H ST R U C T U R E\nO F L E X I C O G R A P H I C A L R E S O U R C E S\n4.1\nintroduction\nAs described in the previous chapters, some of the LSRs represent lexical items\nin a structural and conceptualized way. This structure can be leveraged for many\ntasks, particularly word sense alignment, by using graph-based methods. Employing\ngraphs has been of interest to many tasks in NLP (Nastase et al., 2015), such as fake\nnews detection (Hamid et al., 2020), document summarization (Wang et al., 2020),\nentity relation extraction (Fei et al., 2021) and named-entity recognition (Gui et al.,\n2019).\nIn this chapter, we shed light on the structure of lexicographical resources as a net-\nwork where lexical items are represented as nodes and the relation between words\nor deﬁnitions are represented as edges. Such relations can denote translations, as in\nbilingual dictionaries, semantic relations such as synonymy and antonymy or align-\nment of senses across resources. In the same vein, we provide a few techniques to\nleverage the graph structure of resources. To do so, a brief overview of graph-based\napproaches in the alignment of lexicographical resources is provided in Section 4.2.\nIn Section 4.3, we evaluate lexicographical networks of bilingual dictionaries based\non a few graph measuring metrics, such as average degree, density and clustering\ncoefﬁcient. Following this, in Section 4.4, we introduce an optimization algorithm,\ncalled the weighted bipartite b-matching, for alignment scenarios to model restric-\ntions over the number of links that can be established among different nodes, i.e.\nentries. This algorithm shows that assigning weights to an alignment problem can\nimprove the performance of a linking system, despite its complexity in tuning the\noptimal parameters. We also introduced a few string-based similarity measures to\nestimate the similarity of words or deﬁnitions.\nMoreover, we explore the usage of graphs in translation inference in Section 4.5.\nRelying on the paths and cycles between a source word in a language and a target\nword in another language, we show that the graph structure can be explored to gen-\nerate new translation pairs for two languages for which a bilingual dictionary is not\navailable. This task is of also of interest to create new bilingual dictionaries in an\nunsupervised way for under-resourced languages.\n65\n\n66\nleveraging the graph structure of lexicographical resources\nAt the end of the chapter, we discuss some of the limitations of graph-based meth-\nods, particularly those due to missing information in the data that requires exploring\nand incorporating external resources to improve the performance of linking. Our\nanalysis based on the limitations motivates the curation of a standard benchmark for\nevaluating the tasks of word sense alignment which will be discussed in the following\nsection.\n4.2\nrelated work\nRepresenting and formalizing language and linguistic data as a graph has been a com-\npelling and ubiquitous idea for a long time. Graphs represent mechanisms to extract\nfurther information regarding a speciﬁc node based on topological properties. Some\nof the graph analysis techniques applied to NLP tasks are random walk (Ethayarajh,\n2018; Arora et al., 2016; Hughes and Ramage, 2007), PageRank (Engström, 2016; Per-\nshina et al., 2015) and label propagation (Speriosu et al., 2011; Lin et al., 2013). Thanks\nto the advances in neural networks, graph neural networks have been demonstrated\nto effectively capture structural information and therefore, achieve state-of-the-art re-\nsults in many NLP tasks (Schlichtkrull et al., 2020; Wang et al., 2020). Surveys on NLP\nwith graph-based techniques and graph neural networks are respectively provided in\nNastase et al. (2015) and Wu et al. (2021).\nGraph-based approaches have been widely used for the WSA task. Matuschek and\nGurevych (2013) propose a graph-based approach, called Dijkstra-WSA, for aligning\nlexical semantic resources, namely WordNet, OmegaWiki, Wiktionary and Wikipedia.\nIn this approach, senses are represented as the nodes of a graph where the edges\nrepresent the semantic relation between them. Assuming that monosemous lemmata\nhave a more speciﬁc meaning and are therefore less ambiguous to match, a semantic\nrelation is created among the senses of such lemmata when they appear in a sense of\na polysemous lemma. Using Dijkstra’s shortest path algorithm along with semantic\nsimilarity scores and without requiring any external data or corpora, a set of possible\nsense matches are retrieved.\nMore related to the topic of this thesis, graph analysis has been addressed as pos-\nsible solutions for the WSA task (Matuschek, 2015, p. 67) and translation inference.\nIn the translation inference task, graph analysis techniques rely on the analysis of\ntranslation graphs to determine a possible connection between two words. Over the\npast few years, there has been an increasing usage of graph-based algorithms such as\nrandom walk and graph sampling techniques for multilingual dictionary generation\n(Andrieu et al., 2003; Villegas et al., 2016). Proisl et al. (2017a) proposed a system\nfor generating translation candidates using a graph-based approach with a weight-\ning scheme and a collocation-based model based on the parallel corpus Europarl. In\ncontrast, Alper (2017a) focused on ﬁnding cycles of translations in the graph. By ﬁnd-\n\n4.2 related work\n67\ning cycles of translations in the graph of all lexical entries with translations treated\nas undirected edges, the proposed approach was able to infer translations with rea-\nsonable accuracy. Donandt et al. (2017a) used supervised machine learning to pre-\ndict high-quality candidate translation pairs. They trained a support vector machine\n(SVM) for classifying valid or invalid translation candidates. For this, they used sev-\neral features, e.g. frequency of source word in a dictionary or minimum/maximum\npath length. Furthermore, string similarity leveraging, i.e. Levenshtein distance, was\nalso taken into consideration.\nIn addition to using textual similarity methods, a number of non-textual methods\ncan be used that are useful for linking dictionaries, introduced by McCrae and Cil-\nlessen (2021). This method is graph-based similarity, which relies on there being a\ngraph relating the senses of an entry and so is primarily used in the case of WordNet\nlinking. Naisc implements the FastPPR method (Lofgren et al., 2014) to ﬁnd graph\nsimilarity.\nIn the case of WordNet linking, graph similarity cannot be naively applied as\nthere are not generally links between the graphs of the two WordNets, instead, it is\npossible to rely on the hapax legomenon links, i.e. links that are created when there is\nonly one sense for the lemma in both dictionaries. These links allow us to create a\ngraph between the two graphs as shown in Figure 4.1.\nBank\n1. side of a river\n2. where money is kept\nMerchant\nbank\n1. credit card processing\nbank\nBank\n1. institution where one\ncan borrow\n2. sloping land\nMerchant\nbank\n1. A bank which\nprovides financial\nservices for businesses.\n1\n1\n2\n3\nFigure 4.1: An example of the use of non-textual features for linking. Here the two senses of\nbank are distinguished by the hypernym links (1) and an inferred hapax legomenon\nlink (2), so that the correct sense (3) can be selected.\nMcCrae and Cillessen (2021) explored this method in the context of linking English\nWordNet (McCrae et al., 2019a) with Wikidata1, where the Naisc system is used\nto ﬁnd equivalent senses of WordNet synsets and entities in the Wikidata database.\nThis study suggest that 67,569 (55.3%) of WordNet’s synsets have a matching lemma\nin Wikidata, of which 16,452 (19.5%) counted as hapax legomenon links. Therefore,\nthe accuracy of the hapax legomenon links was directly evaluated and consequently, it\nwas found that accuracy, when applying some simple ﬁlters, was 96.1% based on an\nevaluation of two annotators, who had a Cohen’s kappa agreement of 81.4%.\n1 https://www.wikidata.org\n\n68\nleveraging the graph structure of lexicographical resources\nOn the other hand, using the non-textual methods along with simple textual meth-\nods, similar to the ones described in Section 6.4, the Naisc system could achieve an\naccuracy of 65-66% in predicting links between WordNet and Wikidata. Divided by\nthe prediction scores, those links predicted with a conﬁdence of less than 60% by the\nsystem were all incorrect (0.0% accuracy), those with a 60-80% accuracy were correct\n23/39 times (59.0% accuracy) and those with a greater than 80% conﬁdence were\ncorrect 42/49 times (85.7% accuracy), indicating that the system’s conﬁdence was a\ngood predictor of the accuracy of links. Given the effectiveness of such non-textual\nlinking methods in a few kinds of dictionary linking tasks, especially with large-scale\nknowledge graphs such as Wikidata, they are also included in Naisc.\n4.3\nlexicographical network\nIn this section, we analyze lexicographical networks based on basic graph notions.\nWe deﬁne a lexicographical network as a network of two disjoint sets of vocabulary\nwhich are interconnected based on a sense relation. Analyzing the structure of such\nnetworks provide further information that may be of help in using alignment algo-\nrithms based on link prediction methods. Figure 4.2 illustrates a set of entries of a\nbilingual English-French dictionary and their lexicographical network schema.\nmine\nmine\n  extraire\nminer\nmineﬁeld\n  champ de mine\nterrain miné\nminer\nmineur\nminéral\nmineral\nminerai\nmineral water\neau minérale\nmingle\nse mêler à \nFigure 4.2: A set of dictionary entries (left) and the equivalent lexicographical network\n(right).\n(Gurevych et al., 2016) categorizes linking approaches applicable to lexical data as\nontology alignment, schema matching and graph matching. Despite the dependency\nof the two former ones on lexical semantic similarity, graph matching also relies on\nstructural properties. Therefore, the analysis of lexicographical networks elucidates\nthe employment of such methods.\n\n4.3 lexicographical network\n69\n4.3.1\nAnalysis of lexicographical networks\nWe assume that a graph G = ((U, V), E, W) is unweighted, undirected, and bipartite.\nIn other words, U and V are disjoint sets of vertices and the edge set E ⊆U × V\ncontains only edges between vertices in U (source entries) and vertices in V (target\nentries)2.\nWe use similar notions to Latapy et al. (2008) to deﬁne basic bipartite\nstatistics.\nGiven the bipartite graph G, we denote the number of right and left nodes by\nnU = |U| and nV = |V|. We also denote the number of links in the graph by m = |E|.\nThe average degree of each set of vertices is deﬁned as kU =\nm\nnU and kV =\nm\nnV .\nTherefore, the average degree of the whole graph G′ = (U ∪V, E, W) can be calculated\nas k =\n2m\nnU+nV = nU×kU+nV×kV\nnU+nV\n. Finally, we deﬁne the number of existing links\ndivided by the number of possible links as the bipartite density δ(G) =\nm\nnU×nV .\nIn order to capture a notion of overlap, we also deﬁne clustering coefﬁcient which\nmeasures the probability that two nodes are linked based on the common neighbors.\n(Borgatti and Everett, 1997) deﬁne the clustering coefﬁcient in bipartite graphs as the\nfollowing:\ncc(u) =\nP\nv∈N(N(u)) cc(u, v)\n|N(N(u))|\n(4.1)\nwhere cc(u, v) measures the overlap between neighbourhoods of u and v and\nN(u) refers to the neighbours of u. If there is no common neighbours between u and\nv, then cc(u, v) = 0. If they have the same common neighbours, cc(u, v) = 1. Therefore,\ncc(u, v) is deﬁned as:\ncc(u, v) = N(u) ∩N(v)\nN(u) ∪N(v)\n(4.2)\nFinally, we deﬁne the average clustering coefﬁcient in U (or in V) as the average\nof cc(u) (or cc(v)) over the whole number of nodes:\ncc(U) =\nP\nu∈U cc(u)\n|U|\n(4.3)\n4.3.2\nExperiments\nWe analyze the lexicographical network of the 10 largest multilingual dictionaries\nfreely-accessible on FreeDict3, Apertium dictionaries4, English WordNet-Wiktionary\nmapping dataset (McCrae, 2018) and Matuschek and Gurevych (2014)’s English Wik-\n2 This assumption may not be always correct as in a real-world dictionary an entry can refer to another\nentry in the same set, for instance, using see or cf. keywords.\n3 https://freedict.org/\n4 Data of the 1st edition of 2018\n\n70\nleveraging the graph structure of lexicographical resources\ntionary and Wikipedia sense-aligned dataset. The evaluation results of each network\nare shown in Table 4.1 and Table 4.2.\nRegarding Table 4.1, although the sizes of the dictionaries are not identical, their\nfeature values seem to be uniformly varying in a speciﬁc range. The average degree\nk changes in the range of [1, 2] indicating one-to-many relations between source\nentries and target entries. A higher degree in each side of the network, i.e., kU and\nkV, shows a higher number of edges connected to the nodes. Norwegian Nynorsk-\nNorwegian Bokmål and Dutch-English present the lowest and the highest average\ndegrees respectively. This range of degree is expected as in a dictionary, entries are\nmostly linked to other words. In most of the cases, there is a remarkable difference\nbetween the clustering coefﬁcients of U and V. ccU tending to zero suggests the\nscarcity of entries with common neighbors in U. On the other hand, the clustering\ncoefﬁcient in V, ccV, indicates a higher number of common neighbors. This metric is\nparticularly interesting as it may be used as a heuristic in link discovery algorithms.\nOn the other hand, Table 4.2 provides the results of the same metrics on a different\nset of dictionaries and datasets. Except in a few datasets such as English-Spanish (en-\nes) and English-Galician (en-gl), there is no signiﬁcant number of polysemous items.\nThis indicates that there is a one-to-one relation between almost all dictionary entries.\nMore interestingly, the bipartite density, i.e. δ, varies across the datasets showing that\nsome datasets are providing lexical entries less or more richly linked. For instance,\nMcCrae (2018)’s WordNet-Wikipedia dataset (wn-wp) provides a denser network in\ncomparison to Matuschek and Gurevych (2014)’s WordNet-Wiktionary dataset (wn-\nwkn) which contains less links.\nLanguage pairs\nnU\nnV\nm\nkU\nkV\nk\nδ\nccU\nccV\nGerman-English\n81540\n92982\n123490\n1.51\n1.32\n1.41\n1.62e-05\n2.86e-23\n0.0046\nEnglish-Arabic\n87424\n56410\n89028\n1.01\n1.57\n1.23\n1.80e-05\n0.0\n0.0001\nDutch-English\n22747\n15424\n45151\n1.98\n2.92\n2.36\n1.28e-4\n7.57e-14\n0.2694\nKurdish-German\n10562\n6374\n10562\n1.0\n1.65\n1.24\n1.56e-4\n0.0\n0.0012\nEnglish-Hindi\n22907\n49534\n55635\n2.42\n1.12\n1.53\n4.90e-05\n2.09e-20\n0.0001\nJapanese-French\n13233\n17869\n27692\n2.09\n1.54\n1.78\n1.17e-4\n0.0\n0.0\nBreton-French\n23109\n29141\n42730\n1.84\n1.46\n1.63\n6.34e-05\n6.44e-29\n0.0168\nHungarian-English\n139935\n89679\n254734\n1.82\n2.84\n2.21\n2.02e-05\n1.54e-78\n0.0143\nIcelandic-English\n8416\n6405\n8416\n1.0\n1.31\n1.13\n1.56e-4\n1.32e-05\n0.0344\nNorwegian Nynorsk\n-Norwegian Bokmål\n63509\n62103\n63509\n1.0\n1.02\n1.01\n1.61e-05\n7.87e-06\n0.9559\nTable 4.1: Evaluation of lexicographical networks based on basic graph notions\n\n4.4 weighted bipartite b-matching\n71\nDataset\nnU\nnV\nm\nkU\nkV\nk\nδ\noc-es\n14566\n14566\n14566\n1.0\n1.0\n1.0\n6.87e-05\nes-ro\n17320\n17320\n17320\n1.0\n1.0\n1.0\n5.77e-05\nes-gl\n8990\n8990\n8990\n1.0\n1.0\n1.0\n10.11e-5\neo-en\n31482\n31483\n31485\n≈1.0\n≈1.0\n≈1.0\n3.17e-05\npt-gl\n10148\n10148\n10148\n1.0\n1.0\n1.0\n9.85e-05\nfr-es\n21478\n21478\n21478\n1.0\n1.0\n1.0\n4.65e-05\nes-pt\n12060\n12059\n12060\n1.0\n≈1.0\n≈1.0\n8.29e-05\neu-es\n11883\n11882\n11883\n1.0\n≈1.0\n≈1.0\n8.41e-05\nes-ast\n36111\n36113\n36114\n≈1.0\n≈1.0\n≈1.0\n2.76e-05\nen-ca\n31861\n30538\n34879\n≈1.1\n≈1.1\n≈1.1\n3.58e-05\noc-ca\n15985\n15985\n15985\n1.0\n1.0\n1.0\n6.25e-05\neo-fr\n35799\n35803\n35803\n≈1.0\n1.0\n≈1.0\n2.79e-05\nca-it\n7871\n7875\n7875\n≈1.0\n1.0\n≈1.0\n10.27e-5\neo-ca\n19967\n19966\n19967\n1.0\n≈1.0\n≈1.0\n5.00e-05\nes-an\n3111\n3111\n3111\n1.0\n1.0\n1.0\n30.21e-5\nes-ca\n29991\n29821\n32918\n≈1.1\n≈1.1\n≈1.1\n3.68e-05\nfr-ca\n6550\n6550\n6550\n1.0\n1.0\n1.0\n10.52e-5\npt-ca\n7117\n7117\n7117\n1.0\n1.0\n1.0\n10.40e-5\neu-en\n13231\n13230\n13231\n1.0\n≈1.0\n≈1.0\n7.55e-05\neo-es\n17230\n17232\n17232\n≈1.0\n1.0\n≈1.0\n5.80e-05\nen-gl\n17913\n18273\n21863\n≈1.2\n≈1.1\n≈1.2\n6.67e-05\nen-es\n23900\n23789\n27220\n≈1.1\n≈1.1\n≈1.1\n4.78e-05\nwn-wkn\n(Matuschek\nand Gurevych, 2014)\n63851\n63708\n72747\n1.14\n1.14\n1.14\n1.8e-05\nwn-wp (McCrae, 2018)\n7667\n7523\n7687\n≈1.0\n1.02\n1.01\n10.33e-5\nTable 4.2: Basic statistics of sense-aligned resources. The ﬁrst rows describe the Apertium\ndictionaries (2018) with ISO 639-1 language codes.\n4.4\nweighted bipartite b-matching\nConsidering the task of word-sense alignment, linking is a task that cannot only be\nachieved by looking at pairs of deﬁnitions by themselves but instead a holistic ap-\nproach looks at all the links being generated and considers whether this leads to a\ngood overall linking. It is clear that mapping multiple senses to the same senses or\ngenerating many more or fewer links than the number of senses is not ideal. There-\nfore, we look at a method for solving the problem of sense linking holistically. To do\nso, we present a similarity-based approach for WSA in English WordNet and Wik-\ntionary with a focus on the polysemous items. Our approach, as illustrated in Figure\n4.3, relies on semantic and textual similarity using features such as string distance\nmetrics and word embeddings, and a graph matching algorithm. Transforming the\nalignment problem into a bipartite graph matching enables us to apply graph match-\ning algorithms, in particular, weighted bipartite b-matching (WBbM).\nTwo-mode networks contain two sets of units, such as authors and papers, which\nare connected based on their relation, for instance, citation. Such networks have been\nalready analyzed for various applications, such as actors-movies network (Newman\net al., 2001), authoring networks (Newman, 2001), occurrence networks (i Cancho and\nSolé, 2001) and peer-to-peer exchange networks (Le Fessant et al., 2004). As another\napplication, we are interested in applying the WBbM algorithm to the two-mode net-\n\n72\nleveraging the graph structure of lexicographical resources\nR1\nEi\nS1\nS2\nSn\nR2\nEi\nS′\n1\nS′\n2\nS′\nm\nGRAPH GENERATOR\nR1 : Ei : S1\nR1 : Ei : S2\nR1 : Ei : Sn\nR2 : Ei : S′\n1\nR2 : Ei : S′\n2\nR2 : Ei : S′\nm\n...\n...\n...\n...\nSim(R1 : Ei, R2 : Ei) =\nσS1S′\n1\nσS1S′\n2\n. . .\nσS2S′\n1\nσS2S′\n2\n. . .\n...\n...\n...\nσSnS′\n1\n. . .\nσSnS′m\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWBbM MATCHING\n[l, b]\n[l, b]\n...\n[l, b]\n[l′, b′]\n...\n[l′, b′]\n...\n[l′, b′]\n[l′, b′]\nFigure 4.3: Schema of the sense alignment system with a focus on the graph matching com-\nponent. It should be noted that in resources R1 and R2, Ei refers to entry i with\nsenses shown as S and S′. σ denotes the similarity function.\nwork of word-senses in two different resources. WBbM is one of the widely studied\nclassical problems in combinatorial optimization for modeling data management ap-\nplications, e-commerce and resource allocation systems (Ahmed et al., 2017; Chen\net al., 2016a,b).\n4.4.1\nString-based Methods\nIn order to estimate the similarity of two words or deﬁnitions, i.e. the function sim\nin Figure 4.3, we use string-based measures. Such measures rely on the resemblance\nof textual information in two texts regardless of lexical or semantic variations; for\ninstance, ‘was’ and ‘is’ in such measures are not detected to be similar due to the\nmorphological differences even though both are word forms of the same lemma ‘to\nbe’. Some of the well-known methods of this type use edit distance measures and\ncharacter-level comparisons. Gomaa et al. (2013) and Yu et al. (2016) provide surveys\non such methods.\nLet A and B be the set of words belonging to two senses or deﬁnitions in a dictio-\nnary. We calculate their similarity using the following methods:\nlongest common subsequence The longest subsequence of words (characters)\nthat match between the two strings as a ratio to the average length between\nthe two strings.\nlongest common prefix/suffix The longest subsequence of words (characters)\nfrom the start/end of each string, as a ratio to the average length.\n\n4.4 weighted bipartite b-matching\n73\nn-gram The number of matching subsequences of words (characters) of length n\nbetween the two strings as a ratio to the average maximum number of n-grams\nthat could match (e.g. length of string minus n plus one)\njaccard/dice/containment The match between the words of the two deﬁnitions\nusing the Jaccard and Dice coefﬁcients.\nJaccard = |A ∩B|\n|A ∪B|\n(4.4)\nDice =\n2|AB|\n|A| + |B|\n(4.5)\nContainment =\n|A ∩B|\nmin(|A|, |B|)\n(4.6)\nsmoothed jaccard This metric is an improved formulation of the Jaccard coefﬁ-\ncient that makes the optimization possible and can be adjusted using the pa-\nrameter α to distinguish matches on shorter texts (McCrae et al., 2017a). It is\ndeﬁned as follows:\nJσ(A, B) =\nσ(|A ∩B|)\nσ(|A|) + σ(|B|) −σ(|A| ∪|B|)\n(4.7)\nwhere σ(x) = 1–exp(–αx) and it tends to Jaccard as α →0.\nsentence length ratio (slr) The ratio of the length of the sentences as\nSLR(A, B) = 1 −min(|A|, |B|)\nmax(|A|, |B|)\n(4.8)\njaro-winkler, levenshtein The Jaro-Winkler (Jaro, 1989) and Levenshtein (Leven-\nshtein et al., 1966) distances, respectively dJaro and lev(a, b), are two standard\nstring similarity functions that are deﬁned as follows:\ndJaro =\n\u000e\n0\nm = 0\n1\n3\n\u0010\nm\n|A| + m\n|B| + m−t\nm\n\u0011\nm ̸= 0\n(4.9)\nlevA,B(i, j) =\n\n\n\n\n\n\n\n\n\n\n\nmax(i, j)\nif min(i, j) = 0\nmin\n\n\n\n\n\nlevA,B(i −1, j)) + 1\nlevA,B(i, j −1) + 1\nlevA,B(i −1, j −1) + 1(Ai̸=Bj)\notherwise.\n(4.10)\nwhere m and t are respectively the number of matching characters and half the\nnumber of transpositions, i and j are the terminal character position of strings\n\n74\nleveraging the graph structure of lexicographical resources\nA and B and 1(Ai̸=Bj) is the indicator function equal to 0 when Ai ̸= Bj and\nequal to 1 otherwise. We use the Apache Commons Text5 implementations for\nthese two functions.\nmonge-elkan This is deﬁned as follows where sim is a word similarity function\n(using either Jaro-Winkler or Levenshtein):\nME(A, B) = 1\n|A|\n|A|\nX\ni=1\nmax\nj=1,...t sim(Ai, Bj)\n(4.11)\naverage word length ratio The ratio of the average word length in each sentence\nnormalized to the range [0,1] as for SLR.\nnegation Whether either both sentences contain negation words or both don’t (1 if\ntrue, 0 if false).\nnumber If both sentences contain numbers do these numbers match (1 if all numbers\nmatch).\nbag-of-word This is a basic vector space model where the vocabulary of the lan-\nguage is mapped to hashed values. This way, a set of words can be transformed\ninto a vector of integers, from which the bag term comes, regardless of the\nposition where a speciﬁc word appears. Having the two bags of words corre-\nsponding to the deﬁnitions, it is then to calculate their similarity by applying a\nmetric such as Jaccard.\nIt should be noted that the aforementioned measures are all symmetric, meaning\nthat the similarity function returns the same value if A is compared to B or B is\ncompared to A.\n4.4.2\nThe WBbM algorithm\nWBbM is a variation of the weighted bipartite matching (WBM), also known as the\nassignment problem. In the assignment problem (Kuhn, 1955), the optimal matching\nonly contains one-to-one matchings with the highest sum of weights. This bijective\nmapping restriction is not realistic in the case of lexical resources where an entry\nmay be linked to more than one entry. Therefore, WBbM aims at providing a more\ndiversiﬁed matching where a node may be connected to a certain number of nodes.\nFormally, given G = ((U, V), E) with weights W and vertex-labelling functions L :\nU ∪V →N and B : U ∪V →N, WBbM ﬁnds a subgraph H = ((U, V), E′) which\nmaximizes P\ne∈E′ W(e) having u ∈[L(u), B(u)] and v ∈[L(v), B(v)]. In other words,\nthe number of edges that can be connected to a node is determined by the lower\n5 https://commons.apache.org/proper/commons-text/\n\n4.4 weighted bipartite b-matching\n75\nand upper bound functions L and B, respectively. Algorithm 4.1 presents the WBbM\nalgorithm with a greedy approach where an edge is selected under the condition that\nadding such an edge does not violate the condition over the lower and the upper\nbounds, i.e. L and B.\nAlgorithm 4.1: Greedy WBbM\nInput: G = ((U, V), E, W), lower bound L and upper bound B\nOutput: H = ((U, V)), E′, W) satisfying bound constraints with a\ngreedily-maximized score P\ne∈E′ W(e)\n1 E′ = ∅\n2 Sort E by descending W(e)\n3 for e to E do\n4\nif H = ((U, V)), E′ ∪{e}, W) does not violate B then\n5\nE′ = E′ ∪{e}\nend\nend\n6 if H = ((U, V)), E′, W) does not violate L then\n7\nreturn H = ((U, V)), E′, W)\nend\nelse\nPrint \"matching impossible\"\nend\nWe evaluate the performance of our approach on aligning sense deﬁnitions in\nWordNet and Wiktionary using an aligned resource presented by Meyer and Gurevych\n(2011). Given an identical entry in English WordNet and Wiktionary with the same\npart-of-speech tags, we ﬁrst convert the senses to a bipartite graph where each side of\nthe graph represents the senses belonging to one resource. Then, we extract the simi-\nlarity scores between those senses using a similarity function. The similarity function\nis a classiﬁer trained using support vector machine6 based on the similarity metrics\nmentioned in Section 4.4.1.\nOnce the semantic similarity scores are extracted and assigned as the weight of\nthe edges of our bipartite graph, the senses graph are matched by the WBbM algo-\nrithm. This process is illustrated in Figure 4.3 where senses of entry Ei in resource\nR1, {S1, S2, ..., Sn}, are aligned with the senses of the same entry in R2, {S\n′\n1, S\n′\n2, ..., S\n′\nn}.\nThe lower and upper bounds of the right side and left side of the graph, respectively\n[l, b] and [l′, b′], are the parameters to be tuned.\n6 LibSVM: https://github.com/cjlin1/libsvm\n\n76\nleveraging the graph structure of lexicographical resources\n4.4.3\nExperiments\nIn order to evaluate the performance of our alignment approach, we calculated macro\nprecision Pmacro, macro recall Rmacro, average F-measure Favg and average accu-\nracy Aavg as follows:\nP =\nTP\nTP + FP\n(4.12)\nPmacro = 1\n|E|\n|E|\nX\ni=1\nTPi\nTPi + FPi\n(4.13)\nR =\nTP\nTP + FN\n(4.14)\nRmacro = 1\n|E|\n|E|\nX\ni=1\nTPi\nTPi + FNi\n(4.15)\nF = 2 × P × R\nP + R\n(4.16)\nFavg = 1\n|E|\n|E|\nX\ni=1\nFi\n(4.17)\nAavg = 1\n|E|\n|E|\nX\ni=1\nTPi + TNi\nTPi + TNi + FPi + FNi\n(4.18)\nwhere E refers to the set of entries, TP, TN, FN and FP respectively refer to true\npositive, true negative, false negative and false positive.\nTable 4.3 provides the evaluation results using the WBbM algorithm with different\ncombinations of the matching bounds over the left side (WordNet senses) and the\nright side (Wiktionary senses) of the alignment graph.\nWe observe that a higher\nupper bound increases the recall. On the other hand, setting the lower bound to\n1 provides higher precision, while parameters with a lower bound of 0, e.g. [0, 3],\nlack precision. Note that [0, 1] parameter performs similarly as a bijective mapping\nalgorithm such as the assignment problem where a node can be only matched to one\nnode.\n\n4.5 translation inference\n77\nLeft bound, right bound\nPmacro\nRmacro\nFavg\nAavg\n[0, 1], [0, 1]\n81.86\n61.83\n68.51\n69.48\n[0, 2], [0, 1]\n78.13\n70.74\n73.28\n76.57\n[0, 3], [0, 1]\n77.88\n71.38\n73.59\n77.13\n[1, 2], [1, 2]\n81.21\n74.17\n76.59\n79.49\n[1, 3], [1, 3]\n81.26\n75.02\n77.12\n80.14\n[1, 5], [0, 1]\n81.25\n75.25\n77.28\n80.33\n[1, 5], [1, 2]\n81.25\n75.23\n77.26\n80.32\nTable 4.3: WBbM algorithm performance on alignment of WordNet and Wiktionary\n4.5\ntranslation inference\nIn addition to WSA, translation inference can also utilize a graph-based method to\ngenerate new translation pairs. In this vein, two methods are proposed based on\ngraph traversal heuristic: cycle-based and path-based translation inference. We apply\nthese approaches to the data of the Translation Inference Across Dictionaries 2019\nShared Task which focused on the automatic generation of dictionary entries in order\nto enrich knowledge graphs with multilingual knowledge. The task focused on the\ngeneration of French-English, Portuguese-English and French-Portuguese dictionar-\nies. We use the Apertium RDF dataset7 (Forcada et al., 2011) which is illustrated in\nFigure 4.4. It is worth mentioning that no external resource is used where a direct link\nbetween any of those target languages exists, with the exception being parallel data\nbetween the targeted languages. The datasets contain 44 languages and 53 language\npairs, with a total number of 1,540,996 translations between 1,750,917 lexical entries.\nES\nAN\nAST\nRO\nCA\nFR\nEO\nEN\nIT\nGL\nPT\nOC\nEU\nFigure 4.4: Apertium RDF graph, with the target languages shown in green and bilingual\ndictionaries to be generated indicated in dashed lines.\n7 linguistic.linkeddata.es/apertium/, version cfc5995c5369ddb158cd266fcb8d4b74ed8dbdd0.\n\n78\nleveraging the graph structure of lexicographical resources\n4.5.1\nCycle-based approach\nA heuristic is devised that focuses on producing high precision entries, even though\nthe recall might suffer. In this approach, loops of length four are searched in the\nApertium dictionaries in order to discover new translations.\nThe model builds a\ngraph with all the bilingual word-POS pairs in all the Apertium dictionaries that\ncan be used as a pivot between Portuguese, French and English; those are language\npairs that appear as an intermediate node between the source language and the target\nlanguage in Figure 4.4, like Spanish (es) or Catalan (ca). Whenever a cycle of length\n4 in the graph is retrieved, all the nodes in the cycle are assumed to be translations,\nthus are connected. All discovered edges for the respective language pair are used\nto generate a new dictionary. Figure 4.5 shows an example of discovered translations\nfor the word ‘antique’ (adjective).\nEN:antique\nEO:antikva\nEN:ancient\nEU:zahar\nFR:antique\nES:antiguo\nFigure 4.5: Cycles found in the dictionary (solid lines) and inferred translations (transparent\nlines). Some of the lines identify possible same-language synonyms (e.g. ancient\nand antique in English), while others identify newly discovered possible transla-\ntions (e.g. antiguo in Spanish and antikva in Esperanto).\n4.5.2\nPath-based approach\nSimilar to the cycle-based method, we use another heuristic technique that aims to\ncreate translation candidates by traversing the paths between the source and the tar-\nget languages in the Apertium language graph.\nThe candidate translations T are\nweighted with respect to the path length and the frequency. In this section, language\ngraph refers to the Apertium dictionary graph (Figure 4.4) and translation graph refers\nto a graph where vertices represent a word and edges represent the translations in\nother languages. Figure 4.6 illustrates the translation graph of the word spring as a\nnoun in English based on the following language path:\nEnglish→Basque→Spanish→French→Esperanto→Catalan→Portuguese.\nThe basic idea behind pivot-oriented translation inference is the transitivity as-\nsumption of translations. If wp, a pivot word in the dictionary Dp, has the translation\nequivalents wi and wj in dictionaries Dp→1 and Dp→2 respectively, then wi and wj\nmay be equivalents in the D1→2 dictionary. Although the pivot-oriented approach\ncan mostly create accurate translations for monosemous words (depending on the\nlexicon completeness), this oversimpliﬁes for polysemous words leading to incorrect\ntranslations (Saralegi et al., 2011).\n\n4.5 translation inference\n79\nspring\nmalguki\nmuelle\nudaberri\nprimavera\nprintemps\nprintempo\nprimavero\nprimavera\nprimavera\niturri\nfuente\nsource\nfonto\nbrollador\nfont\nfonte\norigen\norigem\nEnglish\nBasque\nSpanish\nFrench\nEsperanto\nCatalan Portuguese\nFigure 4.6: Translation graph of spring (noun) (in red) resulting in Portuguese translations (in\nblue) using the pivot languages.\nFor the current task, we have considered all the simple paths, i.e. paths without\nany repeating vertex, starting from and ending with the goal languages of the shared\ntask, of which there are 92, 67 and 58 simple paths between Portuguese→French,\nFrench→English and English→Portuguese, respectively. As the language graph is\nundirected, the paths between the vertices are identical in each direction. For in-\nstance, the dictionary paths from English to Portuguese are the same as those from\nPortuguese to English.\nIn order to describe the likelihood of a translation being correct, we introduce the\nfollowing weighting factor:\nwt = frequency(t) × αl\n(4.19)\nwhere wt is the weight of the translation candidate t ∈T, frequency(t) is the\nnumber of times translation t is reached, α ∈(0, 1) is a penalization constant and l\nis the length of the path leading to wt. αl penalizes the translation candidates in a\nway that paths of lower length and higher frequency get a lower weight. On the other\nhand, a longer translation path results in a lower weight factor. For instance, in the\ntranslation graph in Figure 4.6, the frequency of the words primavera, font and origem\nis respectively 2, 1 and 1 and the length of their translation path is 7. For the current\ntask, we set α = 0.5 and have included the part-of-speech tags in the inference.\nFinally, the weights are normalized such that P\nt∈T wt = 1. It is worth noting that\nthis method requires optimization, in the sense of rewriting codes, as it is computa-\ntionally expensive due to the high number of node combinations between a source\nand a target word.\n\n80\nleveraging the graph structure of lexicographical resources\n4.5.3\nExperiments\nTable 4.4 shows the size of the discovered dictionaries using both the cycle and path\napproaches. Unlike the cycle strategy which creates symmetric dictionaries, the path\nstrategy creates different translation pairs based on translation direction, i.e. travers-\ning nodes starting from English to French yields different translation pairs than start-\ning from French to English.\nEN-FR\nFR-EN\nEN-PT\nPT-EN\nFR-PT\nPT-FR\nCycle\n7041\n142\n100\nPath\n25 594\n26 492\n16 273\n22 195\n19 079\n27 678\nTable 4.4: Sizes of the extracted dictionaries in the cycle-based and path-based approaches.\nMoreover, the performance of each method are evaluated based on the manually\ncompiled pairs of K Dictionaries as a gold standard. The evaluation is carried out\naccording to precision, recall, f-measure and coverage where the latter refers to the\nnumber of entries in the source language for which a translation is generated. The\nevaluation results are provided in Table 4.5. In the generated translation, a conﬁdence\nscore is created as well. The impact of this score, normalized in [0-1] is evaluated\nusing a varying threshold.\nBaseline (OTIC)\nCycle-based\nPath-based\nT\nP\nR\nF1\nC\nP\nR\nF1\nC\nP\nR\nF1\nC\n0\n0.63\n0.27\n0.38\n0.46\n0.75\n0.07\n0.11\n0.13\n0.26\n0.28\n0.26\n0.45\n0.1\n0.63\n0.27\n0.38\n0.46\n0.75\n0.07\n0.11\n0.13\n0.4\n0.26\n0.31\n0.45\n0.2\n0.63\n0.27\n0.38\n0.46\n0.75\n0.07\n0.11\n0.13\n0.51\n0.24\n0.32\n0.44\n0.3\n0.63\n0.27\n0.38\n0.46\n0.75\n0.07\n0.11\n0.13\n0.59\n0.21\n0.31\n0.4\n0.4\n0.64\n0.27\n0.38\n0.46\n0.75\n0.07\n0.11\n0.13\n0.65\n0.19\n0.29\n0.36\n0.5\n0.64\n0.26\n0.37\n0.45\n0.75\n0.07\n0.11\n0.13\n0.68\n0.17\n0.26\n0.33\n0.6\n0.66\n0.24\n0.35\n0.43\n0.75\n0.07\n0.11\n0.13\n0.75\n0.14\n0.23\n0.27\n0.7\n0.71\n0.19\n0.29\n0.34\n0.75\n0.07\n0.11\n0.13\n0.76\n0.12\n0.21\n0.24\n0.8\n0.71\n0.19\n0.29\n0.34\n0.75\n0.07\n0.11\n0.13\n0.76\n0.11\n0.19\n0.22\n0.9\n0.71\n0.18\n0.29\n0.33\n0.75\n0.07\n0.11\n0.13\n0.76\n0.1\n0.18\n0.2\n1\n0.71\n0.18\n0.29\n0.33\n0.75\n0.07\n0.11\n0.13\n0.75\n0.09\n0.16\n0.18\nTable 4.5: Results of the evaluation with precision (P), recall (R), F-measure (F1), and cover-\nage (C) for all the different thresholds (T).\nThe evaluation results indicate that the path-based approach performs better than\nthe cycle-based one. Although both techniques generate translation pairs with higher\nprecision, they have a lower f-measure than the baseline system which is based on the\nOne Time Inverse Consultation (OTIC) method (Tanaka and Umemura, 1994b). This\nbeing said, none of the techniques outperforms the coverage of the baseline.\n\n4.6 conclusion and contributions\n81\n4.6\nconclusion and contributions\nIn this chapter, we revisited WordNet-Wiktionary alignment task and proposed an ap-\nproach that divides the alignment problem into two sub-tasks of retrieving similarity\nof sense pair based on textual and semantic similarity and aligning in a holistic way\nusing graph-based WBbM algorithm. We demonstrated that this approach is efﬁcient\nfor aligning resources in comparison to the baseline results thanks to the ﬂexibility of\nthe matching algorithm. However, tuning the parameters of the matching algorithm\nneeds further investigations of the resource and is not following a rule. Additional\nstudies propose further customization of the WBbM algorithm by considering con-\nﬂicts between potential links (Chen et al., 2016b), focusing on a smaller group of\ntarget nodes (Chen et al., 2016a) and increasing diversity (Ahmed et al., 2017). These\ncan be applied to the same linking setup that we described in this chapter. In addi-\ntion, our experiments can be extended to more resources in the future, such as the\nOAEI ontology alignment datasets8 and WordNet-Wikipedia mapping dataset (Mc-\nCrae, 2018).\nOn the other hand, we focused on the translation inference task and demonstrated\nthat graph-based methods can also be used for generating new translation pairs in\nan unsupervised way. To this end, we proposed cycle-based and path-based methods\nwhere the path length, i.e.\nnumber of edges between two nodes, determines the\nprobability that two words are translations.\nOne major limitation of graph-based\nmethods is the limited coverage of connectivity between certain translations. Figure\n4.7 illustrates some of the translations that can be retrieved for the word ‘chaotic’\n(adjective) in the Apertium translation graph (Goel et al., 2021) where the Portuguese\ntranslation ‘caótico’ (‘chaotic’) is not retrievable by traversing intermediate nodes. As\nfuture work, this can be addressed using external resources and more state-of-the-\nart techniques such as graph neural networks and unsupervised cross-lingual word\nembeddings (Sina Ahmadi et al., 2021b).\nThe latest version of the TIAD 2021 data9 include more bilingual dictionaries in\nother languages, such as Maltese (mt) and Arabic (ar). Although the translation\ngraph contains more languages, some of them are isolated nodes that can be pruned,\nsuch as mt-ar in Figure 4.8. Therefore, semi-supervised graph methods, in particular\nthose that focus on label propagation as described in (Talukdar and Crammer, 2009),\nwould also be another avenue of research. In this scenario, a seed dictionary, i.e. a\ndictionary that contains translation pairs as highlighted in Figure 4.8 to the right, is\nused to create a probability distribution over the unseen nodes that can be potential\ntranslations for a given word. In the same vein, identifying isomorphisms in lexico-\ngraphical networks in two dictionaries may be beneﬁcial to ﬁnd potentially identical\nlexical items in two resources.\n8 http://oaei.ontologymatching.org/\n9 https://tiad2021.unizar.es/task.html\n\n82\nleveraging the graph structure of lexicographical resources\nchaotiquefr\nadj\ncaóticoes\nadj\ncaòticca\nadj\ncaoticoc\nadj\nkaosaeo\nadj\ncaoticoan\nadj\nhaoticro\nadj\nchaoticen\nadj\nbordéliquefr\nadj\nˆhaosaeo\nadj\nастан-кестен болғанkk\nadj\ncaóticopt\nadj\nFigure 4.7: Paths starting from ‘chaotique’ (adjective in French) in the Apertium translation\ndata. Language codes and part-of-speech tags are respectively provided in sub-\nscript and superscript.\nBR\nES\nFR\nOC\nRO\nIT\nSC\nAN\nCA\nEN\nGL\nPT\nAST\nAR\nMT\nEU\nIS\nEO\nSV\nNO\nDA\nNN\nNB\nSE\nKK\nRU\nBE\nUK\nSZL\nPL\nSL\nCY\nSH\nMK\nBG\nZLM\nID\nNL\nAF\nTR\nCRH\nTT\nUR\nHI\nBR\nES\nFR\nOC\nRO\nIT\nSC\nAN\nCA\nEN\nGL\nPT\nAST\nAR\nMT\nEU\nIS\nEO\nSV\nNO\nDA\nNN\nNB\nSE\nKK\nRU\nBE\nUK\nSZL\nPL\nSL\nCY\nSH\nMK\nBG\nZLM\nID\nNL\nAF\nTR\nCRH\nTT\nUR\nHI\nFigure 4.8: To the left, Apertium RDF graph (version 2) where nodes refer to languages and\nedges the availability of translations. Nodes unconnected to the target languages\nFrench (FR), English (EN) and Portuguese (PT) are pruned.\n\n5\nA B E N C H M A R K F O R M O N O L I N G UA L\nW O R D S E N S E A L I G N M E N T\nIn the previous chapter, we introduced graph-based techniques for the alignment of\nlexicographical resources. As concluded, there is a lack of annotated datasets for\nthe task of word sense alignment for evaluation purposes. This chapter addresses\nthe task of word sense alignment and describes the manual annotation of various\nexpert-made dictionaries for 15 languages.\n5.1\nintroduction\nDifferent dictionaries and related resources such as Wordnets and encyclopedia have\nsigniﬁcant differences in structure and heterogeneity in content, which makes align-\ning information across resources and languages a challenging task. Word sense align-\nment (WSA) is a more speciﬁc task of linking dictionary content at sense level which\nhas been proved to be beneﬁcial in various NLP tasks, such as word-sense disam-\nbiguation (Navigli and Ponzetto, 2012a), semantic role labeling (Palmer, 2009) and\ninformation extraction (Moro et al., 2013). In a wider scope, combining LSRs can\nenhance domain coverage in terms of the number of lexical items and types of lexical\nsemantic information (Gurevych et al., 2012).\nGiven the current progress of artiﬁcial intelligence and the usage of data to train\nneural networks, annotated data with speciﬁc features play a crucial role in tack-\nling data-driven challenges, particularly in NLP. In recent years, a few efforts have\nbeen made to create gold-standard dataset, i.e., a dataset of instances used for learn-\ning and ﬁtting parameters, for aligning senses across monolingual resources includ-\ning collaboratively-curated ones such as Wiktionary1, and expert-made ones such as\nWordNet. However, the previous work is limited to a handful of languages and much\nof it is not on the core vocabulary of the language, but instead on named entities\nand specialist terminology. Moreover, despite the huge endeavor of lexicographers\nto compile dictionaries, proper lexicographic data are rarely openly accessible to re-\nsearchers. In addition, many of the resources are quite small and the extent to which\nthe mapping is reliable is unclear.\n1 https://www.wiktionary.org\n83\n\n84\na benchmark for monolingual word sense alignment\nLexicographical resources mainly vary in structure. WordNet (Miller, 1995), for\ninstance, is an LSR similar to a dictionary that provides lexical items with deﬁnitions\nand examples, but also conceptual, semantic and lexical relations such as meronymy,\nhypernymy, and hyponymy. Encyclopedias, on the other hand, have more descriptive\ncontent in comparison to other resources but limited semantic relationships between\nentries. In addition to structure, lexicographical resources vary in content as well.\nEven though the headwords in two monolingual dictionaries may be identical, ignor-\ning spelling variations, the more descriptive part of the content that is sense deﬁnition,\nalso known as gloss, can vary quite differently based on the lexicographer’s prefer-\nence, editorial decisions and more importantly, the paradigm followed to deﬁne a\nconcept (as discussed in Section 2.2.2). In the following examples, the various sense\ndeﬁnitions of ‘spring’ (noun) in a few monolingual English resources are provided:\nspring (noun) in Collins\n1. spring is the season between winter and summer when the weather becomes\nwarmer and plants start to grow again.\n2. a spring is a spiral of wire which returns to its original shape after it is pressed\nor pulled.\n3. a spring is a place where water comes up through the ground. It is also the\nwater that comes from that place.\nspring (noun) in Longman\n1. the season between winter and summer when leaves and ﬂowers appear\n2.\n(a) something, usually a twisted piece of metal, that will return to its previous\nshape after it has been pressed down\n(b) the ability of a chair, bed, etc to return to its normal shape after being\npressed down\n3. a place where water comes up naturally from the ground\n4. a sudden quick movement or jump in a particular direction\nspring (noun) in the Princeton WordNet:\n1. the season of growth\n2. a metal elastic device that returns to its shape or position when pushed or pulled\nor pressed\n3. a natural ﬂow of ground water\n4. a point at which water issues forth\n5. the elasticity of something that can be stretched and returns to its original length\n6. a light, self-propelled movement upwards or forwards\n\n5.1 introduction\n85\nspring (noun) in MacMillan\n1. the season of the year between winter and summer\n(a) happening in spring, or relating to spring\n2. water that ﬂows up from under the ground and forms a small stream or pool\n3. a long thin piece of metal in the shape of a coil that quickly gets its original\nshape again after you stop stretching it\n(a) the ability of something to get its original shape again after you stop stretch-\ning it\n4. a quick jump forward or up\nDifferences in structure as in sense-subsense differentiation and content are obvi-\nous in these examples. For instance, the deﬁnition of ‘spring’ as a water source varies\nbetween Collins2 (sense # 3), Longman3 (sense #3) and MacMillan4 (sense #2). In\nthe ﬁrst dictionary, the emphasis is on the water that comes up through the ground,\nwhile in the second, the ‘natural’ aspect of a water source is highlighted too and\nin the third one, the result of the water forming a small pool is mentioned as well.\nNevertheless, such speciﬁcations of a word sense in deﬁnition may seem less relevant\nwhen it comes to metaphorical senses, as in ‘therefore you will joyously draw water, from\nthe springs of salvation’ where ‘spring’ is considered as a source but not essentially that\nof water. Similarly, ‘spring’ as a season is deﬁned speciﬁcally as the season between\nwinter and summer in MacMillan, while the same sense is deﬁned as ‘the season of\ngrowth’ without further speciﬁcations.\nTherefore, the manual alignment of word sense involves searching for matching\nsenses within dictionary entries of different lexical resources and linking them, which\nposes signiﬁcant challenges. The lexicographic criteria are not always entirely consis-\ntent within individual dictionaries and even less so across different projects where\ndifferent options may have been assumed in terms of structure and especially word-\ning techniques of lexicographic glosses. Aligning senses across languages poses an\nextra challenge due to culture-speciﬁc differences in conceptualization and vocabu-\nlary. To remedy the nuances of meanings in deﬁnitions, we propose a framework\nwhere the alignment task is extended to semantic relations, namely exact, broader,\nnarrower and related. These relations are according to Simple Knowledge Organiza-\ntion System (SKOS) (Miles and Bechhofer, 2009) and enable a ﬁne-grained alignment\nat the sense level.\nIn this chapter, we present a set of datasets for the task of WSA containing\nmanually-annotated monolingual resources in 15 languages. The annotation is car-\nried out at sense level where semantic relations between deﬁnition pairs are also se-\n2 https://www.collinsdictionary.com\n3 https://www.ldoceonline.com\n4 https://www.macmillandictionary.com\n\n86\na benchmark for monolingual word sense alignment\nlected in the two resources by native lexicographers. Given the lexicographic context\nof this study, we have tried to provide lexicographic data from expert-made dictio-\nnaries. We believe that our datasets will pave the way for further developments in\nexploring statistical and neural methods, as well as for evaluation purposes. It will\nalso ﬁll the existing gap of lack of bench-marking for the WSA task.\nThe rest of the chapter is organized as follows: we ﬁrst describe the previous\nwork in Section 5.2.\nAfter having described our methodology in Section 5.3, we\nfurther elaborate on the challenges of sense annotation based on the experiences of\nthe annotators in Section 5.4.\nWe evaluate the datasets in Section 5.5 and ﬁnally,\nconclude the the chapter in Section 5.6.\n5.2\nrelated work\nAligning senses across lexical resources has been attempted in several lexicographical\nmilieus over recent years. Such resources mainly include open-source dictionaries,\nWordNet and collaboratively-curated resources, such as Wiktionary. The latter has\nbeen shown to be reliable resources to construct accurate sense classiﬁers (Dandala\net al., 2013).\nThere has been a signiﬁcant body of research in aligning English resources, par-\nticularly, the Princeton WordNet with Wikipedia as in Ruiz-Casado et al. (2005);\nPonzetto and Navigli (2010); Niemann and Gurevych (2011); McCrae (2018)), with\nthe Longman Dictionary of Contemporary English and with Roget’s thesaurus as\nin Kwong (1998), with Wiktionary5 as in Meyer and Gurevych (2011) and with the\nOxford Dictionary of English as in Navigli (2006). Meyer and Gurevych (2011) also\npresent a manually-annotated dataset for WSA between the English WordNet and\nWiktionary.\nOn the other hand, there are a fewer number of manually aligned monolingual\nresources in other languages. For instance, there have been considerable efforts in\naligning lexical semantic resources in German, particularly, the GermaNet–the Ger-\nman Wordnet (Hamp and Feldweg, 1997) with the German Wiktionary (Henrich et al.,\n2011), with the German Wikipedia (Henrich et al., 2012) and with the Digital Dictio-\nnary of the German Language (Digitales Wörterbuch der Deutschen Sprache (Klein and\nGeyken, 2010)) (Henrich et al., 2014) where 470 lemmas with 1,517 senses are aligned.\nGurevych et al. (2012) present UKB–a large-scale lexical semantic resource containing\npairwise sense alignments between a subset of nine resources in English and German\nwhich are mapped to a uniform representation. Although the datasets contain many\nresources in German and English, namely Wiktionary, Wikipedia and OmegaWiki6,\nthey lack multilingualism and expert-made data.\n5 https://www.wiktionary.org/\n6 http://www.omegawiki.org\n\n5.2 related work\n87\nFor Danish, aligning senses across modern lexical resources has been carried out\nin several projects in recent years, and a next natural step is to link these to historical\nDanish dictionaries (Pedersen et al., 2018). Pedersen et al. (2009) describe the semi-\nautomatic compilation of a WordNet for Danish, DanNet, based on a monolingual\ndictionary, the Danish Dictionary (Den Danske Ordbog (DDO)). Later, the semantic\nlinks between these two resources facilitated the compilation of a comprehensive the-\nsaurus (Den Danske Begrebsordbog) (Nimb et al., 2014). The semantic links between\nthesaurus and dictionary made it possible to combine verb groups and dictionary va-\nlency information, used as input for the compilation of the Danish FrameNet Lexicon\n(Nimb, 2018). Furthermore, they constitute the basis for the automatically integrated\ninformation on related words in the Danish dictionary, on the ﬂy for each dictionary\nsense (Nimb et al., 2018). Similarly, Simov et al. (2019) report the manual mapping of\nthe Bulgarian Word-Net BTB-WN with the Bulgarian Wikipedia.\nAligning word senses and the resolution of lexical ambiguity, a task also known\nas word sense disambiguation, are two tightly related tasks. For instance, Dandala\net al. (2013) provides a Wikipedia-based sense tagged corpus generated for four lan-\nguages and describes explorations in word sense disambiguation for sense alignment.\nAdditionally, a few other LSRs have been aligned, such as VerbNet with WordNet by\nKipper et al. (2006), VerbNet with FrameNet by Palmer (2009) and ﬁnally, FrameNet\nwith Wiktionary by Hartmann and Gurevych (2013).\nGiven the amount of effort required to construct and maintain expert-made re-\nsources, various solutions have been proposed to automatically link and merge ex-\nisting LSRs at different levels. LSRs being very diverse in domain coverage (Meyer,\n2010; Burgun and Bodenreider, 2001), previous works have focused on methods to\nincrease domain coverage, enrich sense representations and decrease sense granular-\nity Miller (2016). Miller and Gurevych (2014) describe a technique for constructing\nan n-way alignment of LSRs and applied it to the production of a three-way align-\nment of the English WordNet, Wikipedia and Wiktionary. Niemann and Gurevych\n(2011) propose a threshold-based Personalized PageRank method for extracting a set\nof Wikipedia articles as alignment candidates and automatically aligning them with\nWordNet synsets. This method yields a sense inventory of higher coverage in com-\nparison to taxonomy mapping techniques where Wikipedia categories are aligned\nto WordNet synsets Ponzetto and Navigli (2009). Matuschek and Gurevych (2013)\npresent the Dijkstra-WSA algorithm as a graph-based approach and a machine learn-\ning approach where features such as sense distances and gloss similarities are used\nfor the task of WSA Matuschek and Gurevych (2014). It should be noted that all\nof these approaches produce results that are of lower reliability than gold standard\ndatasets such as the ones presented in this paper.\nIn a recent study, Yao et al. (2021) present a methodology to align dictionary\ncontent where lexicographical data is used to train a neural network model for the\nautomatic alignment of word senses. However, one major obstacle in such studies\n\n88\na benchmark for monolingual word sense alignment\nis the copyright of the data.\nExpert-made dictionaries are oftentimes not openly\navailable. We believe that this major limitation can be addressed by our benchmark.\n5.3\nmethodology\nThe main goal of the current task in this chapter is to provide semantic relationships\nbetween two sets of senses for the same lemmas in two monolingual dictionaries.\nAs an example, Figure 5.1 illustrates the senses for the entry “clog\" (verb) in the\nEnglish WordNet Miller (1995) (to the left in the third column) and the Webster’s\nDictionary 1913 Webster and Slater (1828) (to the right in the sixth column).\nFor\nfurther clariﬁcation, we provide a few case studies in Section 5.4.\nHeadword (POS)\nR1-IDs\nR1 senses\nSemantic relation\nSense match\nR2 senses\nR2-IDs\nclog (verb)\nclog.v.02\ndance a clog dance\nto become clogged; to become \nloaded or encumbered, as with \nextraneous matter.\nclog.v.03\nimpede the motion of, as \nwith a chain or a burden\nto encumber or load, especially \nwith something that impedes \nmotion; to hamper.\nclog.v.01\nbecome or cause to \nbecome obstructed\nto coalesce or adhere; to unite in \na mass.\nclog.v.06\nfill to excess so that function \nis impaired\nto obstruct so as to hinder motion \nin or through; to choke up; .\nclog.v.04\nimpede with a clog or as if \nwith a clog\nto burden; to trammel; to \nembarrass; to perplex.\nclog.v.05\ncoalesce or unite in a mass\nFigure 5.1: Sense provided for clog (verb) in the English WordNet (R1) and the Webster Dic-\ntionary (R2). Drop-down lists are created dynamically for semantic relationship\nannotation.\nGiven the range of languages that were initially targeted, we invited all partners\nand observers of the ELEXIS project to join this task. According to the annotation\nguidelines, we asked participants to provide at least one expert-made resource for\ntheir language of interest. The annotation guidelines were ﬁnalized after a pilot study\nwhere various issues regarding the annotation framework and difﬁculties regarding\npolysemous items were raised and addressed.\nThe actual annotation was implemented by means of dynamic spreadsheets that\nprovide a simple but effective manner to complete the annotation. This also had the\nadded advantage that the annotation task could be easily completed from any device.\nIn order to collect the data that was required for the annotation, each of the participat-\ning institutes provided their data in some form. We asked them, where possible, to\norganize their two dictionaries either in OntoLex-Lemon (Cimiano et al., 2016), TEI-\nLex0 (Romary and Tasovac, 2018) or by following a simple TSV (tab-separated values)\nor Excel format providing the following data:\n• An entry identiﬁer, that locates the entry in the resource\n\n5.3 methodology\n89\n• A sense identiﬁer marking the sense in the resource, for example, the sense\nnumber\n• The lemma of the entry. Spelling variations and orthographies should be nor-\nmalized, as in the case of the old and modern Danish orthographies (“kjø →\nkø”).\n• The part-of-speech of the entry\n• The sense text, including the deﬁnition. If the senses are provided in a hierar-\nchical form to represent semantically-related concepts, they should be uniﬁed\nto bring all the senses along with subsenses at the same level.\nIn order to facilitate the task of annotation, we convert the initial data into spread-\nsheets similar to Figure 5.1. These spreadsheets provided an easy mapping and had\nthe following columns:\n• The headword and part of speech (given in parentheses after the headword);\n• The sense text (deﬁnition) in the ﬁrst resource;\n• An interactive drop-down to specify one of the 5 semantic relations (see below)\nfrom the sense in the ﬁrst resource;\n• The sense text (abbreviated) in a drop-down list from the second resource,\nwhich the ﬁrst resource is matched to;\n• The full sense text of the second resource.\nThe ﬁfth column played no technical role in the annotation, but was provided\nfor reference, however as it was formatted with text wrapping on, it allowed the\nannotators to see the full deﬁnition of the second resource. In general, we arranged\nthe spreadsheets such that there were more senses for the ﬁrst resource. In cases\nwhere the number of senses between the two resources was roughly equal, we created\ntwo spreadsheets based on which of the two datasets had more senses for those\nentries. In other cases, such as the English WordNet-Webster mapping where one\nresource (in this case WordNet) has many more senses, we used this as the ﬁrst\nresource. Even still, there were some cases where the resource with more senses may\ncontain a sense that corresponds to multiple senses in the second resource and in this\ncase, the annotators were instructed to simply use the “Insert Row Below” feature of\nthe spreadsheet, which also duplicated the drop-down lists.\n5.3.1\nSemantic Relationships\nOne of the challenges is that sense granularity between two dictionaries is rarely such\nthat we would expect one-to-one mapping between the senses of an entry. In this\nrespect, we followed a simple approach such as that in SKOS (Miles and Bechhofer,\n2009) providing different kinds of linking predicates, which are described in Table 5.1.\nWhile it is certainly not easy to decide which relationship is to be used, we found that\n\n90\na benchmark for monolingual word sense alignment\nexact\nsenses are the same, for example the deﬁnitions are simply para-\nphrases\nbroader\nsenses in the ﬁrst dictionary completely covers the meaning of the\nsense in the second dictionary and is applicable to further meanings\nnarrower\nsenses in the ﬁrst dictionary is entirely covered by the sense of the\nsecond dictionary, which is applicable to further meanings\nrelated\nThere are cases when the senses may be equal but the deﬁnitions in\nboth dictionaries differ in key aspects\nnone\nThere is no match for this sense\nTable 5.1: Semantic relationships according to SKOS used for WSA task\nthis methodology was broadly effective and we believe will simplify the development\nof machine-learning-based classiﬁers for sense alignment prediction.\nSKOS is a data model designed for knowledge organization systems such as rep-\nresentation of thesauri, classiﬁcation schemes, taxonomies and other types of con-\ntrolled vocabularies or documentary languages (Miles and Bechhofer, 2009). SKOS\ncreated based as an RDF data model, its main objective is to allow the easy publica-\ntion of structured vocabularies for their use within the framework of the Semantic\nWeb. SKOS supports relationships that are commonly found in thesauri as hierarchi-\ncal such as broader and narrower, associative as related and equivalence. Figure 5.2\nillustrates an example where the concept of ‘economic cooperation’ is schematized\nusing SKOS’s core vocabulary.\nAs we will later see in the case studies (Section 5.4), distinguishing the type of\nsemantic relation, particularly where it concerns exact and related, is deemed the\nmost challenging part of the project by annotators.\nThe ‘related’ relation is chieﬂy used when there are differences in ontological type\nbetween the two deﬁnitions, e.g. the property of ‘being able to sleep’, a sense of\nthe noun ‘søvn’ (‘sleep’) in Danish is considered to be ‘related’ to ‘the state of sleep-\ning’ sense in another resource. Often, such differences in ontological type across the\ntwo dictionaries are due to regular polysemy, as in act/result, semiotic artifact/con-\ntent, animal/food, organization/building (Pustejovsky, 1995). Two dictionaries will\noften differ in their descriptions in cases of regular polysemy, focusing on either one\nor the other sense leaving one of them under-speciﬁed, or describing both of them.\nFor instance, while the noun ‘afsked’ ‘farewell’ in Danish describes the act of saying\nfarewell, the corresponding sense deﬁnition in the other Danish resource focuses on\nthe result, namely the phrase ‘farewell’, therefore the senses are only related and not\nexact matches.\nMoreover, ‘related’ has also been used when the ontological type is, in fact, the\nsame for the two senses, but where other parts of the deﬁnitions differ slightly, e.g. in\nthe case of the noun bamse (‘bear, teddy bear’) in Danish where ‘fat, clumsy person,\nespecially a child’ is considered to be a related sense to the other sense of the same\nlemma ‘fat, good-natured person’.\n\n5.3 methodology\n91\nFigure 5.2: The concept scheme of ‘economic cooperation’ as an RDF graph in the SKOS core\nvocabulary (source: https://www.w3.org/TR/2005/WD-swbp-skos-core-guide-\n20051102/)\nRegarding the broader and narrower relations, there are two indications in sense\ndeﬁnitions that are of help to distinguish these two relations: i) using of speciﬁc words\nwith a broader or narrower sense as in taxonomy and ii) providing further details\nin one of the sense deﬁnitions, especially when the two deﬁnitions initially overlap\nconsiderably. For instance, in the case of the Danish noun ‘værge’ (guardian) deﬁned\nas ‘a guardian of anything or anybody’ in one of the dictionaries, a broader relation is\nselected in comparison to ‘a guardian in legal context’ (i.e. a guardian for a child not\nyet legally competent or for an incapacitated adult) due to the speciﬁcations provided\nin the latter gloss. Being the inverse relation of broader, a narrower relation reﬂects\nthe more ﬁne-grained semantic speciﬁcations in the ﬁrst sense in comparison to the\nsecond one, as in the Danish adjective spids (‘sharp’) where one of the dictionaries\ndeﬁnes two separate senses, one about sound and another one about the smell, while\nthe other dictionary merges the two senses into one as ‘pungent in an unpleasant way\n(about smell, taste or sound)’.\n5.3.2\nData Selection\nThe selection of the initial set of lemmas and senses to be aligned is guided by the\nfollowing criteria:\n\n92\na benchmark for monolingual word sense alignment\n• The lemmas should represent all open class words, namely nouns, verbs, adjec-\ntives and adverbs.\n• Another criterion was that the lemmas should represent different degrees of\npolysemy, i.e. both highly polysemous lemmas, as well as monosemous ones,\nshould be included.\n• The lemmas in the two resources have the same part-of-speech tags. Spelling\nvariations are normalized to a unique variation.\n5.3.3\nDictionaries used in the creation of the dataset\nFor alignment, we used the following dictionaries:\nbasque The Basque Wordnet (MCR 3.0) and the Basque Monolingual Dictionary\n\"Euskal Hiztegia\" (copyright by the author, Ibon Sarasola) were linked.\nbulgarian The BulTreeBank Wordnet (BTB-WN) (Osenova and Simov, 2017) and\nthe Bulgarian Wiktionary7 were used.\ndanish We used the Ordbog over det danske Sprog (ODS)8 (Dahlerup, 1918), a his-\ntorical dictionary covering 188,000 lemmas in Danish from 1700-1950, and Den\nDanske Ordbog (DDO) (Farø et al., 2003) a dictionary of modern Danish cover-\ning Danish from 1950 till today. One additional criterion in data selection was\nthat at least one of the senses in DDO should be linked to a base or core con-\ncept in the Princeton WordNet via the Danish WordNet (Pedersen et al., 2019).\nThis resulted in 4,500 DDO lemmas (of 97,500 in the dictionary). The lemma\nintersection (86%) with ODS was selected for our task.\ndutch We used the Woordenboek der Nederlandsche Taal (Dictionary of the Dutch Lan-\nguage, WNT) 9 and the Algemeen Nederlands Woordenboek (Dictionary of Contem-\nporary Dutch, ANW)10. The Dutch lemmas were selected based on the Danish\nlemma list due to the close relationship between the two languages, facilitated\nby the information on the English equivalents from the Princeton WordNet.\nenglish (kd) We used the Password and Global dictionary series provided by K\nDictionaries through Lexicala11. However, due to copyright limitations we are\nnot able to expand this benchmark.\n7 https://bg.wiktionary.org\n8 https://ordnet.dk/ods_en\n9 http://gtb.ivdnt.org/search\n10 http://anw.ivdnt.org/search\n11 https://www.lexicala.com/\n\n5.3 methodology\n93\nenglish (nuig) We developed a second English dataset using Princeton WordNet (Miller,\n1995) (Fellbaum, 2010) and the public domain version of Webster’s dictionary\nfrom 191312.\nestonian We used the EKS Dictionary of Estonian and the PSV Basic Estonian Dic-\ntionary (Kallas et al., 2014).\ngerman We used the German versions of OmegaWiki13 and Wiktionary14.\nhungarian We linked the Explanatory Dictionary of Hungarian (1959-1962)15 con-\ntaining 60,000 entries and, the Comprehensive Dictionary of Hungarian16 con-\ntaining 110,000 entries since 2006. Both are typical academic dictionaries.\nirish We used the Wiktionary data17 and An Foclóir Beag (Dónaill and Maoileoin,\n1991, ‘The Little Dictionary’), the only two monolingual dictionaries available\nfor this language.\nitalian We used ItalWordNet (Roventini et al., 2000) and SIMPLE (Lenci et al., 2000).\nserbian We used the Serbian WordNet (Krstev et al., 2004; Stankovi´c et al., 2018) and\nthe Reˇcnik Matice srpske I-VI: Reˇcnik srpskohrvatskog književnog jezika (Dictionary\nof the Serbo-Croatian Literary Language).\nslovene (jsi) Slovene WordNet (Erjavec and Fiser, 2006) and Slovene Lexical Database (Gan-\ntar and Krek, 2011) were used.\nslovene (isjfr) eSSKJ–Dictionary of the Slovenian Standard Language (3rd edition)\n(Gliha Komac et al., 2016) and the Kostelski slovar (Gregoriˇc, 2014) were aligned.\nspanish The Diccionario de la lengua española (2011 edition) (RAE, 2001) was linked\nwith the entries in the Spanish Wiktionary18 (backup dump of late August 2019)\nsharing the same lemmas.\nportuguese Dicionário da Língua Portuguesa Contemporânea (DLPC, (Academia das\nCiências de Lisboa, 2001)) and Dicionário Aberto (DA)19 were used.\nrussian Ozhegov and Shvedova’s \"The Dictionary of the Russian Language\" (Ozhe-\ngov and Shvedova, 1992) and the Dictionary of the Russian Language edited\nby A.P. Evgenyeva, or Maliy Akademicheskiy Slovar (Short Academic Dictio-\nnary) (Evgenyeva, 1999, MAS) were used.\n12 https://www.websters1913.com\n13 http://www.omegawiki.org\n14 https://de.wiktionary.org\n15 http://mek.oszk.hu/adatbazis/magyar-nyelv-ertelmezo-szotara\n16 http://nagyszotar.nytud.hu\n17 https://ga.wiktionary.org\n18 https://es.wiktionary.org\n19 https://dicionario-aberto.net\n\n94\na benchmark for monolingual word sense alignment\n5.3.4\nDataset Structure\nListing 1 presents the structure of the datasets in JSON format. External keys such\nas meta_ID and external_ID will enable future lexicographers to integrate the anno-\ntations in external resources. Given that some of the semantic relationships, such\nas narrower and broader, are not symmetric, sense_source and sense_target are\nimportant classes in determining the semantic relationship correctly.\n{\n\"lemma\": \"splenetic\",\n\"POS_tag\": \"adjective\",\n\"gender\": \"\",\n\"meta_ID\": \"\",\n\"resource_1_senses\": [\n{\n\"#text\": \"of or relating to the spleen\",\n\"external_ID\": \"splenic.a.01\"},\n{\n\"#text\": \"very irritable\",\n\"external_ID\": \"bristly.s.01\"}\n],\n\"resource_2_senses\": [\n{\n\"#text\": \"affected with spleen; malicious; spiteful; peevish; fretful.\",\n\"external_ID\": \"\"}\n],\n\"alignment\": [\n{\n\"sense_source\": \"very irritable\",\n\"sense_target\": \"affected with spleen; malicious; spiteful; peevish; fretful.\",\n\"semantic_relationship\": \"exact\"}\n]\n}\nListing 1: An example of the structure of senses and their alignments in the datasets\nFurthermore, the datasets are available in the resource description framework\n(RDF) and TSV at https://github.com/elexis-eu/mwsa.\n5.4\ncase studies\nIn this section, some of the dictionaries used in this task are described. Furthermore,\nsome of the challenges based on the qualitative experience of the annotation teams\nare reported.\n5.4.1\nDanish\nThe Den Danske Ordbog20 (‘The Danish Dictionary’, DDO) and Ordbog over det danske\nSprog (‘Dictionary of the Danish Language’, ODS) are two monolingual dictionaries\nof the Danish language.\nWhile DDO covers senses of more than 100,000 Danish\n20 https://ordnet.dk/ddo\n\n5.4 case studies\n95\nlemmas from 1955 until today, ODS is a retro-digitized historical dictionary covering\n220,000 Danish lemmas from 1700 until 1955. Both of the resources are considered to\nbe key lexical resources of the Danish language. The annotation of these resources\nwas carried out by Danish partners of the ELEXIS project at the Society for Danish\nLanguage and Literature21 and the Centre for Language Technology22.\nDespite the signiﬁcant overlaps of entries in the two resources, there are distinctive\nand unique features particular to any of one of them. Broadly, there are the following\nmajor differences between ODS and DDO:\nSense structure\nSenses in both dictionaries are provided in a hierarchy where semantically related\nconcepts are provided as subsenses to a main sense. However, the sense granular-\nity and the exact distinctions drawn between both main senses and subsenses of a\nlemma differ across the two monolingual dictionaries.\nThe order of main senses\nand subsenses in ODS is based on etymology while in DDO it is based on corpus\nfrequency. DDO establishes only main senses proved by concrete textual examples\nbefore the closely-related senses are listed in the form of subsenses. These might rep-\nresent either a broader, a narrower, or a ﬁgurative use to a higher degree of the main\nsense, and also have to be manifested in concrete examples in the language. On the\ncontrary, ODS operates with main senses in the structure which are rather a kind of\nheading or very broad summing up sense description for a series of subsenses to be\nlisted, which are then the only ones to be manifested in concrete language. Conse-\nquently, two main senses in ODS along with their subsenses are semantically related\nto the same one sense in DDO. Therefore, ODS splits in more senses than DDO does.\nWhen it comes to sense granularity, the two dictionaries also differ in other ways.\nFor instance, ODS often merges content that DDO would instead express as several\nsenses in the structure. This is carried out by using formulations like ‘også om’ (‘also\nabout’), ‘dels .., dels’ (‘both .. and’) and ‘også uegentl.’ (‘also ﬁgurative‘) in one sin-\ngle sense deﬁnition in ODS. Furthermore, limitations regarding material might have\ninﬂuenced the sense granularity of the two dictionaries. For instance, DDO editors\nwere often encouraged to rather lump the senses of the less frequent lemmas due to\nthe limited space in the printed edition; this particularly inﬂuences cases of regular\npolysemy.\nDeﬁnition content\nThe time span between the edition of the ﬁrst volumes of ODS and the most recent\nedition of lemmas in DDO is 100 years. This leads to many differences in lexico-\ngraphic description style making differences even more salient. The deﬁnition style\nof ODS is compact, aiming at presenting as many details as possible in one phrase.\n21 https://dsl.dk\n22 https://cst.ku.dk\n\n96\na benchmark for monolingual word sense alignment\nThe editors of DDO focused, instead, on the communicative qualities of a deﬁnition.\nWhere ODS uses many parentheses, additional words and phrases and a deep syntac-\ntic structure with many attributives and subordinate phrases in order to try to cover\nall aspects of a sense, DDO focuses on the prototypical aspects and prefers a more\nﬂat syntactic structure. In addition, when DDO makes use of supplementary explana-\ntions, these are easily identiﬁable as they are initiated by a semicolon in the deﬁnition\ntext, or being placed in two separate XML-ﬁelds, one for connotative and the other\nfor encyclopedic information. Table 5.2 shows an example in which the deﬁnition of\nthe same sense in DDO and ODS is provided.\nlukke (‘to close’)\nODS\nDA\ntrække, lægge, skyde hen for (over) en aabning, saaledes at\ndenne spærres, udfyldes, tilstoppes; især m. h. t. et dertil\nberegnet og anbragt (i aabningen passende) spærremiddel, fx.\nklap, lem, dør; m. h. t. dør olgn. ogs. undertiden: (trække til\nog) laase ell. stænge\nEN\n‘pull, place, shoot over (over) an opening so that it is\nblocked, ﬁlled out, clogged; in particular w.r.t.\na spe-\ncially designed and arranged (in the aperture) blocking\nmeans, e.g. a clap, limb, door; w.r.t. doors or the like\nalso sometimes: (pull and) lock or close’\nDDO\nDA\nbevæge noget dertil indrettet hen foran eller hen over en åbning\nså den spærres\nEN\n‘move something to the front of or across an opening to\nlock it’\nTable 5.2: Deﬁnition of the same sense of the verb lukke (‘to close’) in DDO and ODS\nSimilarly, when it comes to the content of the deﬁnition, many differences are\neither due to the time span between the edition of the two dictionaries or simply to\nthe lexicographer’s individual preference in each case. For instance, in the deﬁnition\nof the lemma standpunkt (noun, ‘view’) in Table 5.3, there is no word at all in common\nbetween the two deﬁnitions, even though they convey the same meaning:\nFurthermore, Table 5.4 illustrates that deﬁnitions might also focus on different\naspects of word meaning, i.e. different qualia roles (Pustejovsky, 1995, p. 76) (See Sec-\ntion 2.5). In ODS, honning (‘honey’) is described by focusing on how it is produced, i.e.\nthe agentive role: “factors involved in its origin or bringing it about”, while in DDO\nit is deﬁned mainly by focusing on how it is used, the telic role: “its purpose and func-\ntion” having as a consequence that the resulting deﬁnitions become different. That\nsaid, there are many parallel deﬁnitions in the two dictionaries, both with respect to\nthe syntactic style and lexical choice with some differences in morphology. Table 5.5\nshows one of such cases. It is important to note that there are some cases in ODS\nwhere meta-information in the form of precise sense references, such as numbers, are\nprovided for words in the deﬁnition text itself. This mostly concerns some morpho-\n\n5.4 case studies\n97\nstandpunkt (‘view’)\nODS\nDA\nom en persons åndelige stade som forudsætning ell. baggrund\nfor hans anskuelser, synsmåde ell. handlemåde; synspunkt; ogs.\nom den anskuelse, hvortil man er kommet, det grundsyn, man\nanlægger på noget, ell. (i videre anv.) om stadium ell. trin i en\npersons åndelige ell. sociale udvikling ell. i en sags, et forholds\nudvikling olgn.\nEN\n‘about a person’s spiritual state as a prerequisite or back-\nground to his views, mode of view or mode of action;\npoint of view. about the view to which one has come,\nthe basic view that one is applying to something, or (fur-\nther use) about the stage or step of a person’s spiritual\nor social development or the development of a case, a\nrelationship, etc.’\nDDO\nDA\nopfattelse af og holdning til et bestemt spørgsmål el. anliggende\nEN\n‘perception of and attitude to a particular issue or matter’\nTable 5.3: Deﬁnition of the same sense of the noun standpunkt (‘view’) in DDO and ODS\nlogical forms and semantic relations, such as synonyms. Moreover, some senses in\nODS are only provided with examples and no deﬁnitions.\nhonning (‘honey’)\nODS\nDA\nplantesaft, der er opsuget af bier, omdannet i deres tarmkanal\nog atter gylpet op\nEN\n‘sap/plant juice which is soaked up by bees, transformed\nin their intestinal tracts and regurgitated’\nDDO\nDA\nsød klæbrig masse som bier danner af blomsters nektar, og som\nfx spises på brød eller bruges som ingrediens i mad\nEN\n‘sweet sticky mass that bees form from the nectar of ﬂow-\ners and which for example is eaten on bread or used as\nan ingredient in food’\nTable 5.4: Deﬁnition of the same sense of the noun standpunkt (‘view’) in DDO and ODS\nFinally, there are some divergences in the orthography of the two dictionaries due\nto a Danish language spelling reform in 1948 where for example the letters ‘aa’ were\nreplaced by a new letter ‘å’. For example in Figure 5.2, the spelling of ‘aabning’ and\n‘laase’ are respectively changed into ‘åbning’ and ‘låse’. Many abbreviations are also\nspelled differently in the two dictionaries– for example, ‘p. gr. af’ (standing for ‘på\ngrund af’ meaning ‘because/due to’ in ODS is replaced with ‘pga.’ in DDO.\nData structure\nBoth DDO and ODS are available in XML. In the XML structure, ODS has been\nenriched using semi-automatic methods with links at the lemma level to a number\nof other historical dictionaries covering Danish before 1700 (Pedersen et al., 2009).\nOn the other hand, many other lexical resources for modern Danish are all linked\n\n98\na benchmark for monolingual word sense alignment\nsikre (‘to secure’)\nODS\nDA\nbeskytte en ell.\nnoget mod angreb, skade, overlast,\nforstyrrelse olgn. v. hj. af forebyggende foranstaltninger\nEN\n‘protect somebody or something from attack, injury, nui-\nsance, disruption, etc. using preventative measures’\nDDO\nDA\nbeskytte mod angreb, overlast, forringelser e.l. vha. fore-\nbyggende foranstaltninger\nEN\n‘protect against attack, nuisance, deterioration etc. using\npreventive measures’\nTable 5.5: Deﬁnition of the same sense of the noun sikre (‘to secure’) in DDO and ODS with\noverlaps\nwith DDO, not only at the lemma level, but also at the sense level.\nThis means\nthat DDO shares sense ID numbers with not only Den Danske Begrebsordbog–a Danish\nthesaurus (Nimb et al., 2014) but also with the Danish WordNet DanNet and the\nDanish FrameNet lexicon (Nimb, 2018).\nGiven the disparities between the content and the structure of the two resources,\nthe XML structures are not fully compatible. In fact, the two dictionaries highly differ\nwhen it comes to the number of markups in the XML structure. While DDO has been\ninitially created and edited in a ﬁne-grained XML structure with isolated content-\nnamed elements, e.g. one for the deﬁnition, another for the citation, etc., constituting\nthe perfect basis for the later online edition, ODS has been retro-digitized based on\nthe printed version in order to be published online and has yet to be fully transformed\ninto a well-deﬁned XML structure. The deﬁnition text from ODS is often initiated by\ndifferent types of meta-information such as frequency, chronology, domain, as well as\nusage, which is not part of the DDO deﬁnition text. Furthermore, meta-information\ncan even be part of the deﬁnition text itself, as described above.\nManual annotation\nRegarding the linking process between the senses of the two dictionaries, all senses\nand sub-senses within the sense hierarchy are brought together at the same level. This\nfacilitated the annotation task as all possibilities could be visually taken into account\neasily. However, such a relaxation over the hierarchy may result in semantically less-\nrepresentative senses.\nIn the manual annotation process, senses of lemmas of the same etymology were\nannotated. Such lemmas were picked out randomly among a selection of core con-\ncept lemmas, already having been identiﬁed in DDO, constituting a total of 4,646\nDDO lemmas of which at least one sense constitutes the Danish equivalent of one of\nthe 5000 base concept synsets in Princeton Wordnet (Pedersen et al., 2019). Approx-\nimately 75% of these DDO core concept lemmas are polysemous, and even though\nthey only constitute 5% of the total number of lemmas in the dictionary, they cover\nmore than 20% of its senses. The lemma selection thereby represents a high degree\n\n5.4 case studies\n99\nFigure 5.3: The sense deﬁnition of the noun pyramide (‘pyramid’) in ODS (column 1 to the\nleft) and DDO (column 4 to the right) in the annotation process.\nof polysemy which makes it highly suitable for our task. The DDO core concept\nlemmas cover both nouns, verbs, adjectives and adverbs, and 86% of them have a\nlemma match in ODS, conﬁrming that even though the DDO core concept lemmas\nwere selected via an English selection, they are in fact central lemmas also in the Dan-\nish language. We excluded senses from ﬁxed expressions in our dataset. Table 5.6\nsummarizes the sense statistics of the annotated data set.\nResource\nNouns\nVerbs\nAdjectives\nAdverbs\nOther\nAll\nODS\n2,176 (282,040)\n983 (119,163)\n436 (60,599)\n0 (0)\n0 (0)\n3595 (461,802)\nDDO\n1,036 (12,326)\n383 (4,045)\n248 (2,228)\n0 (0)\n0 (0)\n1667 (18,599)\nTable 5.6: The statistics of the annotated data for Danish. The numbers in parentheses refer\nto the overall number of the tokens in the senses.\nIn the manual annotation task, the hierarchical sense structure in ODS including\nthe main sense as well as subsense numbers is visible to the annotator while the\nDDO senses are presented in a random linear order with no information on the orig-\ninal sense numbers and hierarchical relations between senses. This facilitated the\nmanual linking process since cases of potentially very different hierarchies in the two\ndictionaries did not disturb the picture. Figure 5.3 shows the annotation environment\nwhere sense deﬁnitions of the noun pyramide (‘pyramid’) in ODS (column 1 to the left)\nand DDO (column 4 to the right) is carried out. The aligning values such as ‘exact’\nand sense numbers, e.g. ‘4’ are annotated in columns 2 and 3. Sense numbers in\nDDO are ad hoc, and the order does not correspond to the one in the dictionary.\nThe selection of semantic relations is carried out as follows (examples are trans-\nlated from Danish):\n• none: There is no match for this ODS sense in DDO\n• exact: The sense in ODS corresponds to the sense in DDO, for example, the\ndeﬁnitions are simply paraphrases, as seen in the examples in Figure 5.5, or\nthey describe the same concept in rather different ways, as seen in the examples\nin Figures 5.2, 5.3 and 5.4. Senses are also considered to be exact matches in\n\n100\na benchmark for monolingual word sense alignment\ncases where the only difference is due to the modernization of the society. For\ninstance, the ODS sense of the noun ‘passager’ (‘passenger’) ‘person traveling\nwith mail coach etc.’ was considered an exact match to the DDO sense ‘person\ntraveling with private or public means of transportation’.\n• broader: The sense in ODS completely covers the meaning of the sense in DDO\nbut is also applicable to further meanings. For instance, the ODS sense of the\nnoun ‘værge’ (‘guardian’): ‘a guardian of anything or anybody’ is a broader\nsense of the DDO sense restricted to ‘a guardian in legal context’ (i.e. a guardian\nfor a child not yet legally competent or for an incapacitated adult).\n• narrower: The sense in ODS is entirely covered by the sense of DDO and is also\napplicable to further meanings. In ODS the adjective ‘spids’ (‘sharp’) has, for\nexample, two speciﬁc senses, one about a sound and another one about a smell,\nwhere DDO covers both senses in one deﬁnition: ‘pungent in an unpleasant way\n(about smell, taste or sound)’. Therefore, both ODS senses are considered to be\nnarrower than the merged DDO sense.\n• related: Annotators found this relationship to be the vaguest one. There are\ncases when the senses may be related even though the deﬁnitions in ODS and\nDDO differ in key aspects. For example, the property of ‘being able to sleep’, a\nsense of the noun søvn (‘sleep’) in ODS is considered ‘related’ to ‘the state of\nsleeping’ sense in DDO, however not identical. The noun ‘bamse’ (‘teddy bear’)\nin ODS described as a ‘fat, clumsy person, especially a child’, is deﬁned as a\n‘fat, good-natured person’ in DDO. As such, these two senses are also consid-\nered to be related. Also, cases of regular polysemy are considered to be ‘related’\nmatches. For instance, ODS has only one sense for the noun ‘ambassade’ (‘em-\nbassy’), namely the organization sense, while DDO has two: the organization\nsense as well as the building sense. While the organization sense is an exact\nmatch to the sense in ODS, the building sense is considered to be only ‘related’\nto it.\n5.4.2\nItalian\nRegarding Italian, two Italian language lexical resources were selected: ItalWordNet\nand SIMPLE. The annotation task was carried out by ELEXIS partners at ILC-CNR23.\nItalWordNet (Roventini et al., 2002) is a lexical semantic network for Italian which\nis part of the WordNet family (Miller, 1995). As such, it is organized around the\nnotion of a synset of word senses and the network structure based on lexical seman-\ntic relations which hold between senses across synsets. The 50,000 Italian synsets\ncontained in ItalWordNet are linked to the Princeton Wordnet. On the other hand,\n23 http://www.ilc.cnr.it\n\n5.4 case studies\n101\nSIMPLE constitutes the semantic level of a quadripartite Italian lexicon: its structure\nis inspired by the Generative Lexicon theory (Pustejovsky, 1995) and in particular\nthe notion of qualia structure which is used to organize the semantic units which\nconstitute the basic structures representing word senses. SIMPLE contains 20,000 se-\nmantic units and we used the deﬁnitions of such semantic units for the task. Both\nlexicons share a set of common base concepts that provided the basis of a previous\nsemi-automatic mapping of the two lexicons on the basis of their respective ontolog-\nical organizations (Roventini et al., 2007; Roventini and Ruimy, 2008). Although this\nmapping did not make the ﬁve-fold distinction of semantic relations, i.e., exact, nar-\nrower, broader, related, and none, it did constitute a useful starting point and a basis\nfor comparison for the task.\nThe teams that had originally compiled ItalWordNet and SIMPLE shared many\nmembers in common and thus, the deﬁnitions for corresponding senses across the\ntwo lexicons are sometimes very similar or differ solely on the basis of an additional\nclause. This made it easy to determine, in many cases, if two senses were ‘exact’\nmatches or if one was ‘broader’ or ‘narrower’ than the other by just comparing strings.\nThe applicability of the ‘related’ category was less clear than the others but the anno-\ntator made use of it in cases where two senses referred to different concepts which\ndid not match but were semantically related, as well as in cases of metaphoric senses\nin which one sense refers to the concrete and the other to the metaphorical meaning.\nIt was also reported that the annotators found the most challenging aspect of the\ntask to lie in the necessity of having to choose the type of matching relationship from\nout of the ﬁve options available. This choice was not always an intuitive one and\nthe procedure often called for careful analysis in order to achieve as objective an\nassessment of the case under consideration as possible. The annotators also found it\nuseful to consult other lexical resources, in particular two online versions of the well\nknown Treccani24 and Garzanti25 reference dictionaries.\n5.4.3\nPortuguese\nFor the Portuguese language, two dictionaries are used: the Dicionário da Língua Por-\ntuguesa Contemporânea (Dictionary of Contemporary Portuguese Language, DLPC)\n(Academia das Ciências de Lisboa, 2001) which the ﬁrst complete edition of a Por-\ntuguese Academy dictionary containing around 70,000 entries, and the Dicionário\nAberto (DA) (Simões and Farinha, 2010), a retro-digitized Portuguese language dic-\ntionary based on the Novo Dicionário da Língua Portuguesa (‘New dictionary of the\nPortuguese language’) which is in the public domain (the 1913 edition). Over a few\nyears, the dictionary has expanded by including more entries. After the complete\ntranscription, the dictionary was subject to automatic orthography update and was\n24 http://www.treccani.it\n25 https://www.garzantilinguistica.it\n\n102\na benchmark for monolingual word sense alignment\nused for different experiments regarding NLP tasks, such as the automatic extraction\nof information for the creation of Wordnets or ontologies (Gonçalo Oliveira, 2018;\nOliveira and Gomes, 2014). The current version of DA contains 128,521 entries. Al-\nthough the number of entries seems high, it is necessary to bear in mind that this\nresource registers orthographic variants of the same entry. Concerning formats, both\nPortuguese language resources are available in printed editions and XML versions\nusing a slightly customized version of the P5 schema of the Text Encoding Initiative\n(TEI) (Simões et al., 2016).\nSense structure\nDLPC’s micro-structure is more complex than the DA’s having more structured and\nhierarchical information. Both dictionaries follow lexicographic conventions such as\nbold type in headwords. Nevertheless, comparing the sample of entries, we may\nobserve certain typographic differences as in initial lowercase entries in DLPC in\ncomparison to the capitalized entries of DA. Furthermore, only DLPC provides full\npronunciation information.\nThe DLPC etymological information ﬁgures after the\ngrammatical properties of the lexical item while, in DA such information, appears\nat the end of the entry. While DLPC indicates the part-of-speech and gender, DA\ndisplays the gender in the case of nouns. This is a common lexicographic practice\nwhere masculine is marked as m. and therefore, explicitly speciﬁed that the entry is\na noun.\nOne of the main features of DLPC is the organization of entries. Not only etymo-\nlogical homonyms are treated as independent entries, but also homonyms of the same\netymological family belonging to different part-of-speech classes are differentiated by\nnumeric superscripts to the right of the lemma in order to distinguish the respective\nentries. For instance, perfurador can function as an adjective meaning ‘perforating’, or\na noun meaning ‘punch’ so is deﬁned into two entries.\nDeﬁnition content\nSenses are enumerated in DLPC providing more organized and ﬁne-grained informa-\ntion while in DA, senses are speciﬁed by newlines. This is the result of the lack of\nmetadata added to the dictionary during the retro-digitization and transcription pro-\ncess. Nevertheless, the dictionary has the basic microstructure annotated including\ngrammatical information, deﬁnitions, quotations, usage examples and etymological\ninformation. DLPC is more comprehensive regarding semantic information such as\nsynonyms (preceded by ≈), examples (shown in italics), cross-reference to lexical\nunits that preferentially co-occur (shown by the symbol +), usage labeling, among\nother relevant features.\nOne of the main differences between sense deﬁnitions in these resources is due to\nthe time span between the two dictionaries: DLPC was published in 2001 and the DA\n\n5.4 case studies\n103\nin 1913. The Portuguese lexicon and language have undergone many transformations\nover that period of time, particularly the Portuguese spelling reform, e.g. ‘periphrás-\ntico’ vs ‘perifrástico’ (‘periphrastic’) respectively in the old and the modern orthogra-\nphies, and semantic changes of many lexical items such as ‘computador’ (‘computer’)\nwhich is not deﬁned as an electronic device in DA. Moreover, new terms have entered\ngeneral vocabulary such as ‘futebol’ (‘football’) which is not included in the DA.\nManual annotation\nA set of lemmas are selected in both dictionaries in a random way and alphabetically.\nThe randomness of the selection was conditioned by the fact that the same headwords\nalong with their part-of-speech tags, such as ‘banco’ (‘bank’) and ‘tripeiro’ (‘tripe seller\nand native of Porto’), appear in both dictionaries. The selection of entries took into\naccount some points previously deﬁned in the project, namely that words belonging\nto an open-class part-of-speech tag should be represented and also, monosemous and\npolysemous lemmas should appear.\nThere are several cases where there are exact relations. Of such cases are entries\nfor which only one sense is deﬁned. For instance, sense 1 of DLPC in Figure 5.4\nshows the sense of the word ‘banderilla’ in the bullﬁghting domain which can possi-\nbly correspond to the only sense of DA. On the other hand, sense 2 related to the\nbookbinding domain only appears in the DLPC and not DA. Nevertheless, the deﬁni-\ntion of identical senses is not similar in textual terms as they are described differently.\nDLPC also uses domain labels while in the DA, there is no label. In other cases, the\ncorrespondence of senses is evident but the lexicographic criteria adopted differ as\nshown in Figure 5.5. The structure of these lexicographic articles is different as DLPC\nhas two entries for tripeiro (‘tripeiro1’ (‘tripeman’) and tripeiro2, ‘of or pertaining to\nthe city of Oporto’) as an adjective and a noun, i.e. part-of-speech homonyms. On\nthe other hand, DA has only one entry and gender information. Between tripeiro2\n(DLPC) and tripeiro (DA), there is an exact match in the ﬁrst sense which is an obso-\nlete one. However, the technique of writing the gloss differs: ‘Pessoa que vende tripas’\n(‘Person who sells tripes’) in DLPC versus ‘Vendedor de tripas’ (‘Tripe seller’) in DA.\nGiven that sense deﬁnitions are not enumerated in DA, each paragraph is considered\nan independent sense. This way, the sense deﬁnition starting with ‘pop.’ (popular) in\nDLPC can be aligned with the one starting with ‘Deprec.’ (depreciative) in DA.\nOne of the challenging alignment cases happens when a sense deﬁnition may\ncorrespond to more than one sense deﬁnition in the other resource. For instance,\n‘praia’ (‘beach’) entry in the sense of ‘Beira-mar’ (‘seaside’) (Figure 5.6); in DA, the\nsenses ‘Beira-mar’ (‘seaside’) and ‘Região, banhada pelo mar; litoral; margem’ (‘Region,\nbathed by the sea; coast’) correspond to sense 2 of DLPC: ‘Zona banhada pelo mar;\nzona balnear’ (‘Zone bathed by the sea; bathing area’). In such cases, the annotator’s\nevaluation of the deﬁnition determines which relation is more likely to be selected.\n\n104\na benchmark for monolingual word sense alignment\nbandarilha [bBdBrÍÀB]. s. f (Do cast. banderilla). 1. Tau-\nrom. Haste munida de ponta de metal penetrante, enfei-\ntada com uma bandeira ou com fitas de papel de cores e \nque se espeta no cachaço dos touros, durante a corrida. =::: \nFARPA, FERRO. A elegância com que espetou o par de banda-\nrilhas no touro pôs a praça de pé. <<Abrem-se então as portas \ne a manada entra, esta que será toureada hoje consoante os \npreceitos inteiros da arte, passada à capa, espetada de banda-\nrilhas, castigada de varas>> (SA \nAGO, Levantado do \nChão, p. 165). Cravar, espetar as +s; um par de +s; tércio \nde +s. bandarilhas a quarteio, variedade de farpas em \nque o toureiro faz um quarto de volta ao espetá-la no \ntouro. bandarilhas a recorte, movimento que consiste \nem colocar os ferros no touro no momento em que o \ntoureiro evita a marrada. 2. Encad. Tira de papel que se \ncola na margem de um original ou prova, quando as \nemendas não cabem nas margens. \nEntrada \nBandarilha \nf. \nFarpa, enfeitada com bandeiras ou fitas, e destinada a cravar-se no cachaço dos \ntoiros, quando se correm. \n(Por bandeirilha, cast. banderilla) \nFigure 5.4: ‘bandarilha’ ‘(banderilla’) in DLPC (above) and DA (below)\ntripeiro1 [triptjru]. adj. m. ef (De tripa+ suf. -eiro). Pop. \nO m. que portuense1. \ntripeiro2 [triptjru]. s. m. ef (De tripa+ suf. -eiro). 1. Pes-\nsoa que vende tripas. 2. Pop. O m. que portuense2. \nEntrada \nTripeiro \nm. \nVendedor de tripas. \nAquele que se sustenta de tripas. \nDeprec. \nHabitante do Porto. \n(De tripa) \nFigure 5.5: ‘tripeiro’ (‘tripe seller and native of Porto’) in DLPC (above) and DA (below)\npraia [prájB]. s. f (Do lat. tardio plagia, talvez do gr. \nnÀàytoç 'oblíquo'). 1. Faixa arenosa do litoral marítimo, \nde fraca inclinação, muito utilizada por banhistas nas zo-\nnas de veraneio ou em estâncias de turismo. <<e a débil pe-\ngada que o meu obscuro pé imprimiu nas praias do Mindelo \nhá-de ficar gravada na história>> ( GARRETT, Discursos, p. \n121). casa+ de praia. colchão+ de praia. voleibol+ de \npraia. 2. Zona banhada pelo mar; zona balnear. ~ BEIRA-\n-MAR, COSTA, LITORAL. Passaram as férias na praia. \nEntrada \nPraia \nf. \nOrla de terra, geralmente coberta de areia, confinando com o mar. \nBeiramar. \nRegião, banhada pelo mar; litoral; margem. \nPI. Marn. \nDepósito geral das águas que alimentam a salina, e que também se chama loiças, (cp. \nloiça). \n(Do lat. plaga) \nFigure 5.6: ‘praia’ (‘beach’) in DLPC (above) and DA (below)\n\n5.5 evaluation\n105\n5.5\nevaluation\nNumber of senses\nFrequency\n1\n5\n10\n50\n100\n500\n1\n2\n3\n4\n5\n>5\nBasque\nBulgarian\nDanish\nDutch\nEnglish (KD)\nEnglish (NUIG)\nEstonian\nGerman\nHungarian\nIrish\nItalian\nSerbian\nSlovenian (JSI)\nSlovenian (ISJFR)\nSpanish\nPortuguese\nRussian\nFigure 5.7: Frequency of the number of senses in the datasets per language in the left resource\nNumber of senses\nFrequency\n1\n5\n10\n50\n100\n500\n1\n2\n3\n4\n5\n>5\nBasque\nBulgarian\nDanish\nDutch\nEnglish (KD)\nEnglish (NUIG)\nEstonian\nGerman\nHungarian\nIrish\nItalian\nSerbian\nSlovenian (JSI)\nSlovenian (ISJFR)\nSpanish\nPortuguese\nRussian\nFigure 5.8: Frequency of the number of senses in the datasets per language in the right re-\nsource\n\n106\na benchmark for monolingual word sense alignment\nWe performed an intrinsic evaluation on our datasets by computing a number\nof resource statistics on the senses. Table 5.7 provides resource statistics based on\npart-of-speech tags and languages. As most of the lemmas available in the resources\nbelong to open classes, namely nouns, verbs, adjectives and adverbs, we carried out\nour experiments with respect to those part-of-speech tags. Moreover, there are few\nlanguages, such as German, Italian and Serbian, for which only a certain number of\nthe part-of-speech tags are available. As a unique case, the Hungarian entries are\naligned at lemma-level without taking the POS tags into account; the POS tags are\nprovided within the senses, upon the lexicographers’ request.\nMoreover, the distribution of the frequency of the number of senses of the left\nresource (source senses) and the right resource (target senses) are respectively pre-\nsented in Figures 5.7 and 5.8, where we show for each resource how many entries\nhad 1, 2, 3, 4, 5 or more senses.\n5.5.1\nSense Granularity\nThe granularity of senses is a determining factor in applying automatic approaches\nfor semantic similarity evaluation. Sense granularity does not follow an identical\npattern across resources and languages. The type of the resource, the preference of\nthe lexicographer and the historical period of the resource edition are some of the\nfactors on how senses are shaped.\nFigure 5.9 illustrates the number of tokens in the ﬁrst and second resources of the\nlanguages provided in our datasets. The bigger the difference between the number\nof tokens, the more the difference between the deﬁnitions and length of senses. As\nan additional analysis, we divide the number of space-separated tokens in one of the\nresources by the other resource. Although most of the resources have a ratio of [1, 2]\nwhich indicates a relatively similar granularity of senses in the two resources, Danish\nand English (NUIG) represent higher ratios. In the case of Danish, a correlation score\nof 24.8 demonstrates a huge difference in how senses are expanded in the resources.\nThis can be justiﬁed by the fact that ODS as a historical resource provides many senses\nwhich are no longer used in the language. In addition, the structure of the resource\nis in a way that further details are provided at sense-level rather than separately.\n5.5.2\nSense Alignments\nOne of the main challenges in aligning senses is due to the structure of the senses. A\nresource that provides senses in a hierarchy based on main senses and their sub-\nsenses represents semantically context-dependent senses in comparison to one in\nwhich senses are semantically independent, which are stand-alone senses not inﬂuenced\nby the hierarchy. On the other hand, senses may contain descriptions beyond the def-\ninition, such as usage examples and idioms.\n\n5.5 evaluation\n107\nLanguage\nResource\nNouns\nVerbs\nAdjectives\nAdverbs\nOther\nAll\nBasque Wordnet\n929 (6836)\n0 (0)\n0 (0)\n0 (0)\n0 (0)\n929 (6836)\nBasque\nEuskal Hiztegia\n971 (7754)\n0 (0)\n0 (0)\n0 (0)\n0 (0)\n971 (7754)\nBTB-WN\n1394 (15649)\n175 (1698)\n305 (3187)\n50 (338)\n0 (0)\n1924 (20872)\nBulgarian\nBulgarian\nWik-\ntionary\n1273 (12883)\n164 (1107)\n194 (1418)\n39 (306)\n0 (0)\n1670 (15714)\nOrdbog over det\ndanske Sprog\n2176 (282040)\n983 (119163)\n436 (60599)\n0 (0)\n0 (0)\n3595 (461802)\nDanish\nDen Danske Ord-\nbog\n1036 (12326)\n383 (4045)\n248 (2228)\n0 (0)\n0 (0)\n1667 (18599)\nWoordenboek\nder\nNederlandsche\nTaal\n1459 (28979)\n405 (5185)\n527 (7878)\n106 (2662)\n0 (0)\n2497 (44704)\nDutch\nAlgemeen\nNeder-\nlands\nWoorden-\nboek\n497 (8443)\n140 (1542)\n109 (1393)\n13 (172)\n0 (0)\n759 (11550)\nGlobal\n92 (532)\n107 (617)\n80 (457)\n57 (257)\n61 (283)\n397 (2146)\nEnglish (KD)\nPassword\n66 (536)\n72 (417)\n62 (324)\n33 (177)\n46 (188)\n279 (1642)\nWebster\n1131 (11606)\n741 (4622)\n373 (2585)\n45 (269)\n0 (0)\n2290 (19082)\nEnglish (NUIG)\nPrinceton\nWord-\nNet\n730 (12166)\n496 (6980)\n249 (2892)\n24 (207)\n0 (0)\n1499 (22245)\nDictionary of Es-\ntonian (EKS)\n543 (4012)\n273 (1598)\n151 (747)\n98 (451)\n78 (370)\n1143 (7178)\nEstonian\nEstonian\nBasic\nDictionary (PSV)\n543 (4492)\n273 (1983)\n151 (1097)\n98 (596)\n79 (468)\n1144 (8636)\nGerman\nWik-\ntionary\n2026 (15160)\n0 (0)\n0 (0)\n0 (0)\n0 (0)\n2026 (15160)\nGerman\nGerman\nOmegaWiki\n1266 (14354)\n0 (0)\n0 (0)\n0 (0)\n0 (0)\n1266 (14354)\nComprehensive\n1355 (14654)\nHungarian\nExplanatory\n1038 (10934)\nAn Foclóir Beag\n891 (8053)\n11 (95)\n55 (267)\n10 (56)\n36 (171)\n1003 (8642)\nIrish\nIrish Wiktionary\n1209 (6696)\n8 (45)\n61 (181)\n10 (41)\n36 (109)\n1324 (7072)\nItalWordNet\n408 (3128)\n352 (2411)\n0 (0)\n0 (0)\n0 (0)\n760 (5539)\nItalian\nSIMPLE\n290 (1990)\n218 (1240)\n0 (0)\n0 (0)\n0 (0)\n508 (3230)\nSerbian\nWord-\nNet\n691 (5864)\n985 (6522)\n92 (713)\n0 (0)\n0 (0)\n1768 (13099)\nSerbian\nDictionary\nof\nSerbo-Croatian\nLiterary\nLan-\nguage\n289 (2360)\n281 (1527)\n29 (215)\n0 (0)\n0 (0)\n599 (4102)\nSlovene\nWord-\nNet\n409 (1106)\n303 (901)\n237 (733)\n44 (133)\n0 (0)\n993 (2873)\nSlovenian (JSI)\nSlovene\nLexical\nDatabase\n284 (2237)\n191 (1047)\n220 (1486)\n29 (102)\n0 (0)\n724 (4872)\nStandard\nSlove-\nnian\nDictionary\n(eSSKJ)\n229 (2060)\n109 (911)\n76 (620)\n0 (0)\n60 (588)\n474 (4179)\nSlovenian (ISJFR)\nKostelski slovar\n151 (1050)\n61 (308)\n45 (257)\n0 (0)\n38 (263)\n295 (1878)\nDiccionario de la\nlengua española\n617 (7986)\n225 (2426)\n305 (3269)\n26 (161)\n24 (250)\n1197 (14092)\nSpanish\nSpanish\nWik-\ntionary\n602 (6421)\n227 (2045)\n294 (2825)\n25 (129)\n22 (123)\n1170 (11543)\nDicionário da Lín-\ngua\nPortuguesa\nContemporânea\n285 (4060)\n58 (686)\n110 (1287)\n9 (143)\n1 (9)\n463 (6185)\nPortuguese\nDicionário Aberto\n199 (1521)\n53 (203)\n67 (372)\n3 (15)\n1 (5)\n323 (2116)\nOzhegov-\nShvedova\n258 (2038)\n109 (615)\n101 (533)\n15 (77)\n44 (368)\n527 (3631)\nRussian\nDictionary\nof\nthe Russian Lan-\nguage (MAS)\n310 (2811)\n173 (1338)\n190 (1219)\n20 (114)\n71 (1010)\n764 (6492)\nTable 5.7: Statistics of the datasets. This table shows the number of senses in the resources\n(the number of the words in the deﬁnitions are provided in parentheses).\n\n108\na benchmark for monolingual word sense alignment\nTo evaluate the distribution of the alignments with respect to the senses, we as-\nsume that each entry is a lexicographic network (Sina Ahmadi et al., 2018), i.e., a graph\nwhere the nodes and edges are the senses and the alignments, respectively. Given a\nset of aligned senses, we denote the number of senses in resource 1 and resource 2\nby n1 and n2, respectively. We also denote the number of alignments in each entry\nby m. Therefore, the average degree of senses in each resource is deﬁned as k1 = m\nn1\nand k2 = m\nn2 . Similarly, the average degree of the whole dataset can be calculated as\nfollows:\nk =\n2 × m\nn1 + n2\n= n1 × k1 + n2 × k2\nn1 + n2\n(5.1)\nFinally, we deﬁne the number of existing alignments divided by the number of\npossible alignments as the density δ =\nm\nn1×n2 .\n0\n10000\n20000\n30000\n40000\n50000\nBasque\nBulgarian\nDutch\nEnglish (KD)\nEnglish (NUIG)\nEstonian\nGerman\nHungarian\nIrish\nItalian\nSlovenian (JSI)\nSlovenian (ISJFR)\nSpanish\nSlovenian\nPortuguese\nRussian\nR1\nR2\nFigure 5.9: Number of tokens per dataset. R1 and R2 respectively correspond to the resources\nin Table 5.7 from up to down. Danish is removed due to its larger size.\nTable 5.8 represents the results of our evaluations on the aligned senses.\nThe\ndegree indicates the distribution of the alignments with respect to the senses. For\ninstance, a degree of 1.182 (k1) in the case of Russian shows that every sense is at\nleast aligned with another one. On the other hand, a low degree of 0.250 (k1) in the\ncase of Dutch indicates the sparsity of alignments over the senses. Moreover, density\nδ provides an insight into how alignments are distributed over the combination of\nall senses. In other words, a higher density represents a higher probability that two\nsenses are aligned in the two resources. Estonian and German resources, for example,\nhave the highest density among the resources.\n\n5.5 evaluation\n109\nLanguage\nSemantic relationship\nk1\nk2\nk\nδ × 103\nexact\nnarrower\nbroader\nrelated\nall\nBasque\n399\n138\n94\n184\n815\n0.877\n0.839\n0.858\n0.9035\nBulgarian\n958\n274\n254\n492\n1978\n1.028\n1.184\n1.101\n0.6156\nDanish\n1103\n316\n189\n36\n1644\n0.457\n0.986\n0.625\n0.0001\nDutch\n489\n30\n64\n42\n625\n0.250\n0.823\n0.384\n0.3298\nEnglish (KD)\n107\n78\n28\n88\n301\n0.758\n1.079\n0.891\n2.7175\nEnglish (NUIG)\n885\n339\n42\n67\n1333\n0.582\n0.889\n0.704\n0.3883\nEstonian\n1025\n61\n54\n4\n1144\n1.001\n1.000\n1.000\n0.8749\nGerman\n354\n311\n426\n126\n1217\n0.601\n0.961\n0.739\n0.4745\nHungarian\n465\n214\n227\n43\n949\n0.700\n0.914\n0.793\n0.6747\nIrish\n731\n45\n67\n132\n975\n0.972\n0.736\n0.838\n0.7342\nItalian\n327\n132\n44\n89\n592\n0.779\n1.165\n0.934\n1.5334\nSerbian\n325\n47\n73\n146\n591\n0.334\n0.987\n0.499\n0.5581\nSlovenian (JSI)\n306\n183\n169\n54\n712\n0.717\n0.983\n0.829\n0.9904\nSlovenian (ISJFR)\n110\n88\n10\n39\n247\n0.521\n0.837\n0.642\n1.7664\nSpanish\n867\n185\n114\n93\n1259\n1.052\n1.076\n1.064\n0.8990\nPortuguese\n207\n38\n2\n28\n275\n0.594\n0.851\n0.700\n1.8389\nRussian\n363\n15\n159\n86\n623\n1.182\n0.815\n0.965\n1.5473\nTable 5.8: A description of the semantic relationship alignments using basic graph measures\n5.5.3\nInter-annotator Agreement\nKrippendorff’s Alpha is a reliability coefﬁcient to measure the agreement of two or\nmore annotators. Reliability coefﬁcients are an important metric to determine the\ndifﬁculty of a task to be carried out by a human, and also, the agreement or potential\ndisagreement that occur between annotators. There are mainly two families of relia-\nbility coefﬁcients known as Kappa and Alpha. Different from the Kappa (κ) family of\nreliability coefﬁcients, such as Fleiss’s k, where the disagreements are treated equally\nimportant, Alpha (α) coefﬁcients are designed to incorporate a weight function that\nsets the level of disagreement based on each pair of labels. This is useful for cases\nwhere taking a decision regarding an annotation is not equally easy or difﬁcult with\nrespect to a speciﬁc class. Krippendorff’s Alpha is recommended as the standard\nreliability measure in content analysis (Hayes and Krippendorff, 2007) and has been\nwidely used in many annotation tasks in NLP (Artstein, 2017).\nWe selected Krippendorff’s Alpha as the number of the annotators for some of the\ndatasets varies between two and three, and Krippendorff’s Alpha is able to handle\nvarious numbers of annotators. Moreover, Krippendorff’s Alpha is able to calculate\nreliability at any measurement level, i.e. nominal, ordinal, interval, ratio. In addition,\nwe were initially interested to explore the agreement score based on various weight\nfunctions. This was another reason to select this measure. However, the weight func-\ntion was ﬁnally selected as the identity function where all annotations are considered\nequally signiﬁcant.\nAccording to Krippendorff (2011), α is calculated as follows:\nα = 1 −Do\nDe\n(5.2)\n\n110\na benchmark for monolingual word sense alignment\nwhere Do is the observed disagreement among values and is deﬁned as follows:\nDo = 1\nn\nX\nc∈R\nX\nk∈R\nockδ2\nck\n(5.3)\nand De is the expected disagreement which is attributable by chance:\nDe =\n1\nn(n −1)\nX\nc∈R\nX\nk∈R\nnc.nkδ2\nck\n(5.4)\nwhere δ is the metric function of difference, n is the number of annotators, n(n −\n1) is the number of pairs of annotators whose annotations are being compared, R is\nthe set of all possible annotations that an annotator can select and ﬁnally, o is the ma-\ntrix of observed coincidences containing frequencies. As our annotations are nominal,\nδ2\nck is 1 in the case of agreement and 0 otherwise. These parameters are calculated\nbased on the coincidence matrices which are created according to the annotations for\neach pair of sense deﬁnitions.\nEquation 5.2 denotes that when the agreement among annotators is the highest,\nobserved disagreement, i.e. Do = 0 and therefore, α = 1. This indicates perfect reli-\nability. On the other hand, when the annotations are carried out as if they were pro-\nduced by chance, observed disagreement and the expected disagreement by chance\nare equal, i.e. Do = De, which indicates the lack of reliability. This results in α = 0\nand denotes that there is no point of agreement between the annotators. It is worth\nnoting that α varies between the range of 0 and 1, 0 ⩽α ⩽1; any score out of the\nextremes, indicates systematic disagreement and exceeds any agreement produced\nby chance, i.e. α = 0.\nWhile the linking for most of the languages was only developed by a single an-\nnotator, we collected multiple annotations for four languages which enabled us to\nevaluate the alignment agreement over the same senses. Given the conditions of our\nannotation problem, we used Krippendorff’s alpha reliability for calculating the inter-\nannotator agreement (IAA) where we considered each possible sense pair as an item\nfor the agreement. Thus, if a pair of senses was not chosen by any of the annotators,\nthey are considered to agree that the link between this is none. Table 5.9 presents\nthe IAA in a 5-class model, that is the ﬁve semantic relations namely exact, narrower,\nbroader, related and none; the latter refers to the cases where no relation is speci-\nﬁed between a pair of senses. Moreover, we provide a 2-class model where all types\nof semantic relationships, namely exact, broader, narrower and related, are merged\nand compared against none as the other class. The weight function for all classes is\nconsidered uniform. Regarding the number of senses, 561, 4979, 185 and 270 senses\nwere annotated by more than one annotator for English, German, Irish and Danish,\nrespectively, which made it possible to calculate IAA.\nRegarding the English (KD) resources, an internal evaluation of the annotated\ndata with two annotators shows an agreement for 76% of the annotators.\n\n5.5 evaluation\n111\nAgreement (5-class)\nAgreement (2-class)\nIrish (3)\n0.83\n0.99\nEnglish (NUIG) (3)\n0.43\n0.73\nDanish (2)\n0.95\n0.92\nGerman (2)\n0.71\n0.58\nTable 5.9: Inter-annotator agreement using Krippendorff’s alpha. Number of annotators pro-\nvided in parentheses.\nThe IAA results in Table 5.9 indicate that the alignment task is not equally difﬁ-\ncult for all resources and languages, even though there is a considerable agreement\nbetween annotators, generally speaking. The highest IAA score (0.99) belongs to the\n2-class problem for Irish where the possible correspondence of a sense deﬁnition pair\nis determined by the annotators, regardless of the semantic relation. On the other\nhand, the 5-class problem for the English (NUIG) data is the lowest (0.43).\nAfter a qualitative analysis of the English data, we believe that determining a se-\nmantic relation between sense deﬁnitions is subjective to the annotators’ understand-\ning of the sense. For instance, Table 5.10 provides a comparison between the anno-\ntations of sense deﬁnitions in Princeton English WordNet and Webster’s Dictionary\n1913 for the entry vulgar (adjective); Although the two annotators agree upon one\nannotation pair, they are in disagreement in three other cases. Regarding the sense of\n‘vulgar’ as ‘lacking reﬁnement’, annotator 1 seems to show more indulgence in such\na way that the overall meaning of the deﬁnition in resource 1 (R1C) is compared with\nthat of resource 2 (R2C) ignoring semantic nuances due to additional words such as\n‘low’ or ‘good taste’ in R2C. On the other hand, annotator 2 considers the additional\nmeanings, provided after a semicolon (;) in resource 2, to determine the semantic\nrelation between the two sense deﬁnitions and therefore, decided to annotate it as\nnarrower.\nThe same phenomenon can be seen in Table 5.11 for the Irish entry caora (‘sheep’,\nnoun) where, even though the two annotators have detected the correspondence of\nthe senses similarly, one selected narrower as the relation and the other one, exact.\nOne obvious reason is the differences of the deﬁnition of ‘sheep’ in the two resources:\nthe ﬁrst resource speciﬁes two meanings as ‘domestic sheep’ (Ovis aries) in sense R1A\nand ‘sheep’ (‘Ovis’) as a genus in sense R1B while the second resource only deﬁnes it\nas a genus in sense R2A. Moreover, as Table 5.9 illustrates, English glosses are more\ndescriptive being provided with synonyms or near-synonyms after semi-colons while\nthe Irish ones are more concise. This also explains how the length of glosses has been\ndisadvantageous to determine a more widely-agreed semantic relation between sense\npairs in English.\nFinally, in cases where the annotation was carried out by more than one annotator,\na third annotator analyzed the annotations and resolved cases of conﬂict to produce\na ﬁnal dataset.\n\n112\na benchmark for monolingual word sense alignment\nvulgar (adjective)\nSense deﬁnitions in resource 1, the Princeton English WordNet (R1)\nR1A\nof or associated with the great masses of people\nR1B\nbeing or characteristic of or appropriate to everyday language\nR1C\nlacking reﬁnement or cultivation or taste\nR1D\nconspicuously and tastelessly indecent\nSense deﬁnitions in resource 2, Webster’s Dictionary 1913 (R2)\nR2A\nof or pertaining to the mass, or multitude, of people; common; gen-\neral; ordinary; public; hence, in general use; vernacular.\nR2B\nbelonging or relating to the common people, as distinguished from\nthe cultivated or educated; pertaining to common life; plebeian; not\nselect or distinguished; hence, sometimes, of little or no value.\nR2C\nhence, lacking cultivation or reﬁnement; rustic; boorish; also, offen-\nsive to good taste or reﬁned feelings; low; coarse; mean; base; .\nAnnotations\nAnnotator 1\nR1A exact R2A\nR1C exact R2C\nAnnotator 2\nR1A exact R2A\nR1B narrower R2A\nR1C narrower R2C\nR1D narrower R2C\nTable 5.10: A comparison of annotations for vulgar (adjective) in English by the two anno-\ntators\ncaora (‘sheep’, noun)\nSense deﬁnitions in resource 1, the Irish Wiktionary (R1)\nR1A\nainmhí leathmhór féaránach athchogantach cuideachtúil a mbíonn adharca\nair go minic. Gné Ovis aries. Tá a lán saghas de tugtha chun tíreachais ar\nfud an domhain mar gheall ar a lomra, a mbainne agus a bhfeoil.\na semi-large, ruminant, grazing, domestic animal usually with horns.\nOf the species Ovis aries. A large number of varieties have been\ndomesticated for their ﬂeece, milk and meat around the world.\nR1B\nainmhíthe den ghéineas Ovis, agus géinis gaolta leis, a bhfuil dlúthbhaint\nacu leis na gabhair.\nanimals of the genus Ovis and related genera, which are closely\nrelated to goats.\nSense deﬁnitions in resource 2, An Foclóir Beag (R2)\nR2A\nainmhí athchogantach de chineál an ghabhair a thugann olann agus feoil\ndúinn\na ruminant animal similar to a goat that gives us wool and meat.\nAnnotations\nAnnotator 1\nR1A narrower R2A\nR1B narrower R2A\nAnnotator 2\nR1A exact R2A\nR1B exact R2A\nTable 5.11: A comparison of annotations for caora (‘sheep’, noun) in Irish by the two anno-\ntators\n\n5.6 conclusion and contributions\n113\n5.6\nconclusion and contributions\nIn this chapter, we presented a set of 17 datasets for the task of monolingual word\nsense alignment covering 15 languages. This dataset innovates on previous datasets\nby focusing on general vocabulary, which is much harder to link than the focus of\nprevious works, such as named entities. In addition to the collaboratively-curated\nresources such as Wiktionary, many expert-made resources are used in our datasets\nfor the task.\nGiven the difﬁculty of determining the overlap of sense deﬁnitions\nin various resources and languages, we created a framework where the word sense\nalignment task is carried out using 5 categories of semantic links based on SKOS\n(Miles and Bechhofer, 2009), namely exact, broader, narrower, related and not related,\ni.e.\nnone.\nGiven the signiﬁcant size of the datasets, we believe that they can be\nbeneﬁcial not only for evaluation purposes but also for training new statistical and\nneural models for various tasks such as word sense alignment, semantic relationship\ndetection, paraphrasing and semantic entailment, to mention but a few.\nVarious\nchallenges related to this task are described in a few case studies in Danish, Italian\nand Portuguese.\nThe inter-annotator agreement scores indicate that the task of word sense align-\nment is not equally challenging for all resources and all languages. For instance,\nthere is roughly 50% agreement among the annotators of the English resources. This\nreveals that determining a semantic relation is indeed a challenging task even for\nexpert lexicographers. Regardless of how the sense granularity and coverage in two\nresources are identical, the textual information provided in sense deﬁnitions creates\nfurther nuances in meaning which are not easily distinguishable. We provide a few\nexamples for ‘spring’ (noun) as a season where further speciﬁcations in a deﬁnition,\nas in ‘the season between winter and summer’, denotes a delicately different meaning\nin comparison to another deﬁnition, as in ‘the season of growth’.\nIn the following chapter, we focus on the automatic alignment of sense deﬁnitions.\nA few techniques are proposed where the textual, lexical and semantic information\nare taken into account. The performance of various methods is evaluated for the tasks\nof sense alignment and semantic relationship detection using these datasets. More-\nover, we explore language-independent techniques to facilitate monolingual lexical\ndata linking and increase the interoperability of monolingual dictionaries.\n\n\n6\nM O N O L I N G UA L W O R D S E N S E\nA L I G N M E N T\nIn the previous chapter, we discussed the manual annotation of sense deﬁnitions\nin 15 languages to create a benchmark for the evaluation of word sense alignment\n(WSA). In this chapter, we delve more into the automatic alignment of sense deﬁ-\nnitions by introducing a tool called Naisc in which a set of techniques for semantic\nsimilarity detection is implemented, ranging from string-based similarity detection to\nmore recent techniques using contextual embeddings, and semantic induction tech-\nniques. We will discuss how NLP techniques can be applied in the task of aligning\nthe senses of identical lemmas in two dictionaries, a task which otherwise would be\na time-consuming and difﬁcult challenge due to the high number of senses and the\nheterogeneity of data, in both structure and content.\n6.1\nintroduction\nSenses and deﬁnitions are important components of dictionaries where dictionary\nentries, i.e. lemmata, are described in plain language. Therefore, unlike other proper-\nties such as references, comparisons (cf.), synonyms and antonyms, sense deﬁnitions\nare unique in the sense that they are more descriptive but also highly contextualized.\nMoreover, unlike lemmata which remain identical among resources in the same lan-\nguage, except in spelling variations, senses can undergo tremendous changes based\non the choice of the editor, lexicographer and publication period, to mention but\na few factors.\nIgnoring the differences in dictionary structures and formats such\nas XML, LMF (Francopoulo et al., 2006) and Ontolex-Lemon (McCrae et al., 2017b),\nthere are different lexicographic and logical ways for describing senses in a dictionary\n(Solomonick, 1996). As an example, Table 6.1 provides the senses available for entire\n(adjective) in various lexical resources where the predominant sense of ‘whole’ or\n‘complete’ is provided in all resources. However, all resources do not equally cover\nspeciﬁc domains such as ‘botany’ and ‘mathematics’. Therefore, there are differences\nin the number of provided senses, as in Macmillan in which one sense is provided\nwhile the Oxford Dictionary provides ﬁve.\n1 https://wordnet.princeton.edu\n2 https://www.websters1913.com\n3 https://en.wiktionary.org\n115\n\n116\nmonolingual word sense alignment\nentire (adjective)\nWordNet1\n1- (of leaves or petals) having a smooth edge; not broken up into\nteeth or lobes\n2- constituting the full quantity or extent; complete\n3- constituting the undiminished entirety; lacking nothing essential\nespecially not damaged\n4- (used of domestic animals) sexually competent\nWebster2\n1- complete in all parts; undivided; undiminished; whole; full and\nperfect; not deﬁcient\n2- without mixture or alloy of anything; unqualiﬁed; morally whole;\npure; faithful\n3- not gelded; – said of a horse\n4- internal; interior.\nWiktionary3\n1- (sometimes postpositive) Whole; complete.\n2- (botany) Having a smooth margin without any indentation.\n3- (botany) Consisting of a single piece, as a corolla.\n4- (complex analysis, of a complex function) Complex-differentiable\non all of C.\n5- (of a male animal) Not gelded.\n6- morally whole; pure; sheer\nMacmillan4\n1- used for emphasizing that you mean all or every part of some-\nthing\nLongman5\n12- used when you want to emphasize that you mean all of a group,\nperiod of time, amount etc\nOxford6\n1- [attributive] with no part left out; whole.\n2- Without qualiﬁcation or reservations; absolute.\n3- Not broken, damaged, or decayed.\n4- (of a male horse) not castrated.\n5- Botany (of a leaf) without indentations or division into leaﬂets.\nCambridge7\n1- whole or complete, with nothing lacking, or continuous, without\ninterruption\nTable 6.1: Senses of entire (adjective) in various monolingual English dictionaries\nOur focus in this chapter is on the monolingual word senses alignment (MWSA)\nthat aims to ﬁnd potential links and identify the semantic relations between senses\nor sense deﬁnitions within the micro-structure of two identical lemmas belonging to\nthe same part-of-speech category. Given the setup that we described in the previous\nchapter, aligning sense deﬁnitions is meaningful when the alignment task is com-\npleted with semantic relations, such as exact, narrower, broader, related and none,\nto capture nuances in meaning. Indeed, this goes beyond the task of establishing a\nlink between sense deﬁnitions which are potentially referring to the same meanings.\nTherefore, MWSA is also the task of inferring any possible relationships between\nsenses stored in two dictionaries.\n4 https://www.macmillandictionary.com\n5 https://www.ldoceonline.com\n6 https://www.lexico.com\n7 https://dictionary.cambridge.org\n\n6.1 introduction\n117\nFrom a technical point of view, we address the MWSA task based on two sub-tasks\nas follows:\n• Semantic similarity detection: scoring in a numerical way the extent to which\ntwo senses or deﬁnitions are similar, based on their textual and non-textual\nproperties, and\n• Semantic relation induction: ﬁnding the type of semantic relations that may\nexist between the two sense deﬁnitions. This can be deﬁned formally as the\nfollowing function:\nrel = sem(p, si, sj)\n(6.1)\nwhere p is the part-of-speech of the lemma, si and sj are senses belonging to\nthe same lexemes in two monolingual resources and rel is a semantic relation,\nnamely exact, broader, narrower, related and none. Our goal is to predict a\nsemantic relation, i.e. rel, given a pair of senses.\nFurthermore, we deﬁne the MWSA task at three different levels as follows:\n• Binary classiﬁcation to predict if two senses or deﬁnitions can possibly be\naligned together. In other terms, the ‘exact’, ‘broader’, ‘narrower’ and ‘related”\nlinks are merged into a single positive class, i.e. rel ∈0, 1 in Equation 6.1. This\nis motivated by the fact that many applications do not care about the speciﬁc\ntype of link and that detecting the presence of the link is a harder task from\npredicting the type of the link.\n• SKOS classiﬁcation to predict a semantic relation among exact, broader, narrower\nand related semantic relationships.\n• SKOS+none classiﬁcation to predict a semantic relation among exact, broader,\nnarrower, related and none.\nIt is important to note that the alignment is carried out at the micro-structure level\nof each entry; this includes senses, whether deﬁned or not, and sense deﬁnitions,\ni.e. glosses. The latter may contain further information such as semantically-related\nwords which are usually speciﬁed with a semi-colon. If such information are sys-\ntematically structured differently in the micro-structure, i.e. the dictionary deﬁned a\ndifferent XML tag without grouping them with the glosses, they are not taken into\naccount in the alignment task.\nTable 6.2 provides an example of the entry ‘entire’ described in Table 6.1; this\ntable, provides the scores of various similarity measures carried out on three sense\ndeﬁnitions of ‘entire’, where Deﬁnition 1 (D1) and Deﬁnition 2 (D2) are semantically\ncloser together, both referring to the sense of ‘entire’ as being complete in parts, and\nDeﬁnition 3 (D3) denotes a slightly different function of the word used for emphasis.\nThe similarity measures are calculated per each pair of alignment, namely D1-D2,\n\n118\nmonolingual word sense alignment\nD1-D3 and D2-D3. In this example, three similarity types are provided: string-based,\nLSR-based and embeddings-based. There are two major differences between these\nmethods, among others. First, the calculated scores are not normalized and therefore,\ncannot be compared. For instance, the longest common substring method provides\nthe distance as a score while Word2vec provides a ﬂoat in the range of [0, 1]. And\nsecond, they calculate the similarity score based on various features which do not\ncapture the same information essentially, as in edit distance versus vector represen-\ntations. This leads to different scores where D1 and D2 are considered to be more\nsimilar (0.11), as in the method based on WordNet, or D1 and D3 are more similar\n(0.423) using sentence transformers.\nentire (adjective)\nSenses\nDeﬁnition 1 (D1)\nconstituting the full quantity or extent\nDeﬁnition 2 (D2)\ncomplete in all parts\nDeﬁnition 3 (D3)\nused for emphasizing that you mean\nall or every part of something\nsimilarity\nsimilarity type\nmethod\nscores\nD1 - D2\nD1 - D3\nD2 - D3\nString-based\nLongest Common Substring\n3\n6\n6\nLevenshtein\n28\n47\n49\nJaro-Winkler\n0.58\n0.592\n0.56\nLongest Common Subsequence\n37\n61\n54\nfour-gram\n0.74\n0.76\n0.81\nLSR-based\nLevenshtein + lemmas\n6\n11\n10\nWordNet\n0.11\n0\n0\n(Pawar and Mago, 2018)\nEmbeddings\nWord2vec + Cosine\n0.13\n0.11\n0.10\nSentence transformers\n0.261\n0.293\n0.423\n(Reimers and Gurevych, 2019)\nTable 6.2: A comparison of three deﬁnitions of ‘entire’ (adjective) based on various similarity\ndetection methods. Deﬁnition 1 and 2 refer to the same sense, while Deﬁnition 3\nis different.\nOf the beneﬁts of WSA, it should be noted that it will facilitate the integration\nof various resources and the creation of inter-linked language resources. Moreover,\naligning word senses across monolingual lexicographic resources increases domain\ncoverage and enables integration and incorporation of data. Considering the litera-\nture, various aspect of WSA in general, and MWSA in particular, have been matters\nof research previously. However, a few of previous papers address the alignment task\nas a speciﬁc task on its own. To remedy this and to bring various semantic similarity\nmethods together for the task of WSA, a framework called Naisc (meaning ‘links’ in\nIrish and pronounced ‘nashk’) is built. The idea of Naisc as a framework for data\nalignment was initially proposed by McCrae et al. (2017a) and McCrae and Buitelaar\n(2018) chieﬂy for ontology alignment. However, given that the tool aims to combine\nvarious semantic similarity measures at the structural and textual levels, it was fur-\nther developed in the context of the ELEXIS project and this thesis. Therefore, in\nthis chapter, the architecture of this system is also described as part of the ELEXIS in-\n\n6.2 related work\n119\nfrastructure, which covers all parts of the lexicographic process including dictionary\ndrafting. In addition, the contributions of the thesis which are also integrated into\nthe tool, are presented.\nThe rest of this chapter is organized as follows:\n• In Section 6.2, we go through the previous work in aligning word senses or\ndeﬁnitions.\n• In Section 6.3, the architecture of Naisc is described.\n• Section 6.4 describes some of the major metrics to estimate the similarity of\ntwo sense deﬁnitions, respectively based on textual and non-textual informa-\ntion extracted from them. We ﬁrst look at some basic methodologies and then\nimplement more advanced methods that use deep learning models.\n• Finally, Section 6.6 brings the described methods together by carrying out var-\nious experiments. In this experiments, a baseline system is created along with\nthree other systems based on classiﬁcation, a knowledge graph and deep learn-\ning.\nWe believe that the combination of these tools provides a highly ﬂexible imple-\nmentation that can link senses between a wide variety of input dictionaries and we\ndemonstrate how linking can be done as part of the ELEXIS toolchain. The outcomes\nof our developments are beneﬁcial to e-lexicography and the integration and main-\ntenance of lexicographical resources, opening up for new ways of presenting word\ninformation to the users of the resources.\n6.2\nrelated work\nThe alignment of lexical resources has been previously of interest both to create re-\nsources and propose alignment approaches. In this section, we only focus on WSA\ntechniques in the related literature.\nAs discussed in Chapter 2, there have been many studies where graph-based ap-\nproaches have been used for the WSA task.\nTo recap, we can mention the work\nof Matuschek and Gurevych (2013) who propose a graph-based approach, called\nDijkstra-WSA, for aligning lexical semantic resources, namely Wordnet, OmegaWiki,\nWiktionary and Wikipedia. In the same vein, in Chapter 4, the alignment task was\nmodeled as a bipartite-graph where an optimal alignment solution is selected among\nthe combination of possible sense matches in two resources. Although this algorithm\nperforms competitively with the Dijkstra-WSA technique on the same datasets, no\nviable solution is provided regarding the tuning of the matching algorithm, as dis-\ncussed in Chapter 2 in detail. Similarly, other studies such as Nancy and Véronis\n(1990); Pantel and Pennacchiotti (2008); Meyer and Gurevych (2010); Pilehvar and\nNavigli (2014) focus on linking senses without considering semantic relationships or\n\n120\nmonolingual word sense alignment\nsense deﬁnitions. Aligning resources have been also of interest to create a sense in-\nventory, as described by Pedersen et al. (2018), as a common reference for a language.\nBeyond aligning lexical resources, there has been much effort in inducing seman-\ntic relationships, particularly within more generic ﬁelds such as taxonomy extraction\n(Bordea et al., 2015), hypernym discovery (Camacho-Collados et al., 2018) and seman-\ntic textual similarity (Agirre et al., 2016b). Although in these tasks the focus is on\nthe relationship within words, there are a few works exploring how to induce seman-\ntic relationships between deﬁnitions. Heidenreich and Williams (2019) introduce an\nalgorithm using a directed acyclic graph to construct a Wordnet based on the Wik-\ntionary data and enriched with the synonym and antonym relationships. Using the\nsemantic relationship annotations provided in Wiktionary, the method induces a se-\nmantic hierarchy by identifying a subset within each sense that can relate two lemmas\ntogether. In addition to graph-based methods, there are various other closely-related\nﬁelds, such as word sense disambiguation (Maru et al., 2019) and sense embeddings\n(Iacobacci et al., 2015), which can potentially contribute to the task of WSA. However,\nwe could not ﬁnd any previous work exploring those approaches.\nOne major limitation of the previous work is with respect to the nature of the data\nused for the WSA task. Expert-made resources, such as the Oxford English Dictio-\nnary are not as widely available as collaboratively-curated ones like Wiktionary due\nto copyright restrictions. Therefore, in the previous work, experiments are carried\nout either on copyrighted material that cannot be shared or collaboratively-curated re-\nsources for speciﬁc languages with limited applicability of the proposed methods (as\nexplained in more detail in Chapter 3). As such, the creation of the benchmark, that\nwas explained in the previous chapter, containing a set of 17 datasets of monolingual\ndictionaries in 15 languages and annotated by language experts with ﬁve semantic\nrelationships according to SKOS (Miles and Bechhofer, 2009), namely, broader, nar-\nrower, related, exact and none, would provide a common ground for future endeavors\nin the ﬁeld. Further, our techniques being open-source and implemented all in one\ntool called Naisc should make it easier for user to align lexicographical data more\neasily.\nIn this context, we also organized a shared task at the GLOBALEX workshop in\n20208 where a new baseline is developed that covers 15 languages and we invited\nparticipants to address the same task (Kernerman et al., 2020a). The result of the\nparticipating systems are reported in the Section 6.7.\n6.3\nnaisc architecture\nThe Naisc architecture is depicted in Figure 6.1. The architecture of Naisc was origi-\nnally designed by McCrae and Buitelaar (2018) for linking any RDF datasets and this\n8 https://competitions.codalab.org/competitions/22163\n\n6.3 naisc architecture\n121\ncan be applied to the MWSA task by converting the dictionaries into an RDF format\nsuch as OntoLex (McCrae et al., 2017b; Cimiano et al., 2016). The process of linking\nis broken down into a number of steps that are described as follows:\n• Blocking: The blocking step ﬁnds the set of pairs that are possible candidates\nfor linking.\nFor more general linking tasks and for the multilingual linking\ntask, this may trade off some accuracy for computational efﬁciency. However,\nfor the MWSA task we only link on matching headwords so the blocking task\nhas a single implementation that simply ﬁnds matching headwords and outputs\nevery sense pair between these two entries.\nSignature: (Dataset, Dataset) ⇒(Sense, Sense)*\n• Lens: The lens examines the data around the sense pair to be linked and extracts\ntext that can be compared for similarity. Clearly, the most important lens for\nthis task extracts the senses’ deﬁnitions. However, other information such as\nexamples can also be extracted here.\nSignature: (Sense, Sense) ⇒(Text, Text)\n• Text features: The text features extract a set of similarity judgments about the\ntexts extracted with the lenses and are described in more detail in the following\nsection.\nSignature: (Text, Text) ⇒R∗\n• Graph features: Graph (or non-textual) features do not rely on the text in the\ndataset but instead look at other features. They are described in more detail\nlater in this chapter.\nSignature: (Sense, Sense) ⇒R∗\n• Scorer: From a set of features extracted either from the text or from other graph\nelements, a score must be estimated for each of the sense pairs. This can be done\nin either a supervised or unsupervised manner and we implement standard\nmethods for supervised classiﬁcation such as support vector machines (SVMs)\nand unsupervised classiﬁcation using voting.\nSignature: R∗⇒[0, 1]∗- Output corresponds to a probability distribution over the\nrelation classes\n• Matcher and Constraint: There are normally some constraints that are useful\nto enforce on the matching and these are applied by the matcher\nSignature: (Sense, Sense, [0, 1]∗)∗⇒(Sense, Sense)∗- Output is a subset of the\ninput\nNaisc is implemented in Java and is openly available at https://github.com/\ninsight-centre/naisc.\nThe conﬁguration of each run can be speciﬁed by giving a\nJSON description of the components that can be used. For example, this is a default\nconﬁguration for the MWSA task (presented using YAML syntax):\n\n122\nmonolingual word sense alignment\nRDF \nDoc 1\nRDF \nDoc 2\nBlocking\nStrategy\nLens\nText\nFeature\nScorer\nMatcher\nConstraint\nSPARQL\nGraph\nFeature\nFigure 6.1: The Architecture of the Naisc system for sense linking. Single thin arrows refer\nto the usage of SPARQL by a component.\nblocking:\nname: blocking.OntoLex\nlenses:\n- name: lens.Label\nproperty:\n- http://www.w3.org/2004/02/skos/core#definition\nid: label\ntextFeatures:\n- name: feature.BasicString\nwordWeights: models/idf\nngramWeights: models/ngidf\nlabelChar: true\n- name: feature.WordEmbeddings\nembeddingPath: models/glove.6B.100d.txt\nscorers:\n- name: scorer.LibSVM\nmodelFile: models/default.libsvm\nmatcher:\nname: matcher.BeamSearch\nconstraint:\nname: constraint.Taxonomic\ndescription: The default setting for processing two OntoLex dictionaries\nThis conﬁguration assumes that the dictionary is in the OntoLex format for block-\ning and processes it. Then, it extracts the deﬁnitions using the ‘Label’ lens and ap-\nplies various text similarity features which are described in the following sections.\nThe scores for each property type are calculated using LibSVM (Chang and Lin, 2011)\n\n6.3 naisc architecture\n123\nand ﬁnally the overall linking is calculated using the taxonomic constraints, which\nwill be deﬁned later in this chapter.\nOne of the main objectives of the development of Naisc and our techniques is the\nmultilingual aspect of the alignment problem. Even though our focus is on monolin-\ngual sense and deﬁnition alignment, it is possible to use the tool for any other lan-\nguage by implementing language-independent approaches or proper conﬁgurations\nin the tools, particularly for word embeddings and language-speciﬁc tasks such as\nremoval of stop-words or acronym ﬁnder. As an additional feature, it is also possible\nto annotate data semi-automatically and save annotations for training purposes. The\ntool is fully documented at https://uld.pages.insight-centre.org/naisc. A screenshot\nof the interface of the tool is provided in Figure 6.2.\nFigure 6.2: A screenshot of Naisc – the automated linking tool\n\n124\nmonolingual word sense alignment\n6.4\ntextual similarity methods\nIn this section, we discuss a few approaches that rely on the textual data rather\nthan the structure of the alignment problem to calculate the similarity of senses and\ndeﬁnitions. These approaches are categorized as string-based, resource-based, and\nembeddings-based. Throughout this section, we assume that A and B are the set of\nwords belonging to two senses or deﬁnitions in a dictionary, and try to deﬁne various\nsimilarity functions to estimate their similarity.\n6.4.1\nString-based Methods\nDetecting similarity between of textual data, i.e. data of string type, using string-\nbased measures are widely used not only in general usage of computer but also in\nNLP (Islam and Inkpen, 2008). Within the Naisc framework, we implement string-\nbased basic methods using frequency and surface forms of the strings to compute\nfeatures. These methods were introduced in Section 4.4.1 of Chapter 4. Most of these\nmethods can work on words or on characters.\n6.4.2\nBeyond String Similarity\nThanks to the increasing size of openly-available language resources and the wide\navailability of such resources for many languages, it is possible to incorporate lexical\nand semantic resources in the semantic similarity detection task. Such metrics are\nalso provided in Naisc as follows:\ndictionary In this method, a dictionary containing words and their synonyms is\nused to detect whether two terms are synonyms.\nwordnet WordNet has been extensively used to detect semantic similarity thanks to\nvarious relationships deﬁned in it, such as hypernymy and synonymy (Pedersen\net al., 2004; Meng et al., 2013). Figure 6.3 illustrates the synonyms deﬁned for\n‘entire’ (adjective) in the Princeton English WordNet. Based on this structure, it\nis expected to score the similarity of deﬁnitions that contain synonyms higher\nthan those not having.\nIn the same vein, WordNets are used in the target language of the user as spec-\niﬁed in the conﬁguration ﬁle to measure the relatedness of two terms in the\ndeﬁnitions. To do so, the similarity of words are calculated in Naisc based on\nthe overlap of synonymous and closely-related words according to WordNet.\nIn addition, methods based on shortest path (Lin and Sandkuhl, 2008; Wu and\nPalmer, 1994) and context (Leacock and Chodorow, 1998) are implemented.\n\n6.4 textual similarity methods\n125\nFigure 6.3: Structure of ‘entire’ (adjective) in the Princeton English WordNet. Green nodes\ndenote synonyms.\nconceptnet ConceptNet (Speer et al., 2012, 2017) is a knowledge graph that brings\nvarious lexical resources together and provides a large network of monolingual\nand multilingual data in natural language. Words in a given language are used\nas labels of the nodes of a graph among which semantic relations are extracted\nand weighted as edges. The weight is calculated according to the number of\noccurrences in the resources and can have a negative value. Figure 6.4 provides\na few monolingual relations associated to ‘entire’ (adjective) where ‘whole’ is\nconﬁdently presented as a related concept to ‘entire’ with weight value 4.2 and\n‘department’ has the lowest score of being an antonym of ‘entire’. The resource\nbased on which the relation is extracted or inferred is provided as well.\nembeddings Unlike similarity measures that rely on manually-curated lexical and\nsemantic resources such as WordNet and dictionaries, embeddings only require\nto be trained on large corpora. As embeddings are widely accessible for many\nlanguages, including low-resourced languages, it is essential to integrate mea-\nsure that rely on embeddings in Naisc. Therefore, the following approach is\nimplemented based on Global Vectors for Word Representation (GloVe) vectors\n(Pennington et al., 2014) where the word embeddings for each word is calculated\nin the two deﬁnitions and then compare pairwise the words of each deﬁnition.\nGiven VA and VB, respectively as the corresponding vector representations of\nsense deﬁnition A and sense deﬁnition B, the similarity between vectors is cal-\nculated using the cosine similarity as follows:\ncos(θ) = VA.VB\n|VA||VB|\n(6.2)\nwhere θ is the angle between two vectors projected in a multi-dimensional plane.\n\n126\nmonolingual word sense alignment\nSource word\nRelation / Weight\nTarget word\nResource\nfull (a, wn)\n― Synonym ⟶\nWeight: 2.0\nentire (a, wn)\nOpen Multilingual \nWordNet\nintact (a, wn)\n― Synonym ⟶\nWeight: 2.0\nentire (a, wn)\nOpen Multilingual \nWordNet\nentire (a, wn)\n― SimilarTo ⟶\nWeight: 2.0\nsmooth (a, botany)\nOpen Multilingual \nWordNet\nuncastrated (a, wn)\n― SimilarTo ⟶\nWeight: 2.0\nentire (a, wn)\nOpen Multilingual \nWordNet\nentire\n― RelatedTo ⟶\nWeight: 4.2\nwhole\nVerbosity players\nentire\n― RelatedTo ⟶\nWeight: 1.56\nwhole thing\nVerbosity players\nentire\n― RelatedTo ⟶\nWeight: 1.28\neverything\nVerbosity players\nentire\n― Antonym ⟶\nWeight: 0.27\nnothing\nVerbosity players\nentire\n― DistinctFrom ⟶\nWeight: 0.19\npart\nVerbosity players\ndepartment\n― Antonym ⟶\nWeight: 0.18\nentire\nVerbosity players\nentire (a)\n― HasContext ⟶\nWeight: 1.0\ncomplex analysis\nEnglish Wiktionary\nentire (a)\n― HasContext ⟶\nWeight: 1.0\nmale animal\nEnglish Wiktionary\nFigure 6.4: A few monolingual relations associated to ‘entire’ (adjective) in ConceptNet\n(https://conceptnet.io/c/en/entire). Underlined items refer to concepts.\nIn addition, the tool is extendable to various other embedding methods in the\nconﬁguration, such as Word2vec (Mikolov et al., 2013a), fastText (Grave et al.,\n2018), GloVe (Pennington et al., 2014) and BERT (Devlin et al., 2018). Given\nthe key role of the ﬁne-tuned pre-trained neural network language models in\nachieving state-of-the-art results in many NLP applications, we further expand\non it in the following.\ndeep learning : Currently, deep learning methods are widely used for word and\nsentence similarity detection. In the implementations, two methods are used\nbased on the recurrent neural network and transformers.\nRecurrent Neural Networks (RNNs): RNNs (Medsker and Jain, 2001) are a set\nof neural networks for processing sequential data and modeling long-distance\ndependencies. Given that many tasks in NLP are compatible with sequential\nmodeling of data, RNNs currently form the backbone of many tools, particu-\nlarly in machine translation and sentence embedding (Agirre et al., 2016a). The\ninitial models are further optimized, particularly using gate mechanism such a\nlong short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and the\n\n6.4 textual similarity methods\n127\nattention mechanism (Vaswani et al., 2017) to tackle vanishing gradient in long\nsequences (Ahmadi, 2018).\nTransformers: Another notable technique is based on transformers. A trans-\nformer is a type of neural network architecture that consist of self-attention\nmechanism using an encoder-decoder structure (Devlin et al., 2018).\nIn an\nencoder-decoder network, the restriction over the ﬁxed length of sentences which\nwas previously faced in neural network based methods, such as RNNs, is ad-\ndressed (Pascanu et al., 2013). As such, a variable length sequence is encoded\ninto a state with a ﬁxed shape and then mapped into a variable length sequence,\nfrom where such a network is called an encoder-decoder.\nBidirectional Encoder Representations from Transformers (BERT) (Devlin et al.,\n2018) is one of the well-known transformer-based methods that is trained on\nunlabeled data, such as Wikipedia-based corpora, using masked language mod-\neling and next sentence prediction for language modeling. By jointly condi-\ntioning on both left and right context of a given word, which is masked in the\ntraining phase, the model learns dependencies that occur at the lexical, semantic\nand syntactic levels. BERT has achieved state-of-the-art results in many tasks by\noutperforming various other models leveraging RNNs or convolutional neural\nnetworks (CNNs), both in terms of evaluation score and training time. From an\nempirical point of view, it is not fully clear yet how and on what tasks contextual\nembeddings, in general, and BERT, in particular, perform, making researchers\nwonder about bertology (Rogers et al., 2020) as a new ﬁeld of interest in NLP.\nAs the results of the systems submitted to the shared task organized for the\nsame task of alignment indicate (see Section 6.7), participants used BERT and\nRobustly optimized BERT pre-training approach (Liu et al., 2019) as well. This\nis done by using the Hugging Face transformers library which provides the API\nfor ﬁne-tuning of transformer models (Wolf et al., 2019). To do so, a deﬁnition is\nfed into the embeddings network, also referred to as transformer model, and a\n768 dimensional dense vector space is returned as the representation of the def-\ninition. Following this, the pooling operation is applied on the contextualized\nword embeddings where all contextualized word embeddings are simply aver-\naged. Finally, the similarity of two given deﬁnitions is calculated by computing\nthe cosine similarity of their vectors. More documentation regarding BERT is\navailable at https://huggingface.co/sentence-transformers.\n6.4.3\nWord Alignment\nIn addition to the string-based techniques and those based on resources and embed-\ndings, aligning two given deﬁnitions at word level can be used to estimate similarity\nas well. In this approach, similarity matrix SN×M is created based on the lengths of\n\n128\nmonolingual word sense alignment\ndeﬁnitions A and B, respectively as N and M. If two words in the two deﬁnitions are\nto be aligned, their value is set to 1, otherwise 0. This way, the value Sij in the matrix\ncorresponds to the alignment of words i in deﬁnition A and j in deﬁnition B. In order\nto extract a single similarity score based on the matrix, the following methods are\nused.\nFirstly, the precision of mapping is deﬁned according to McCrae and Buitelaar\n(2018) by calculating the number of words that are aligned with a similarity greater\nthan one half:\nf = 1\nN\n\f\f\f\f\f\n\u000e\ni | ∃j :\nsij\nP\nj′ sij′ > 0.5\n\u000f\f\f\f\f\f\nForward precision\n(6.3)\nb = 1\nM\n\f\f\f\f\n\f\nj | ∃i :\nsij\nP\ni′ si′j\n> 0.5\n\r\f\f\f\f\nBackward precision (6.4)\nThe forward and backward precision measures can be combined using a harmonic\nmean, as deﬁned by Sultan et al. (2014):\nm = 2fb\nf + b\nHarmonized Alignment Mean (6.5)\nAnother feature that can be used is the normalized and parallel column and row\nmaximums using norms (p-Norm) and parallel maxima (p-Max). p-Max takes one or\nmore vectors or matrices as f and b as arguments and returns a single vector for the\nparallel maxima of the vectors where the ﬁrst element of the result is the maximum\nof the ﬁrst elements of all the arguments, the second element of the result is the\nmaximum of the second elements of all the arguments and so on (Crawley, 2012,\np. 45). This will be larger if we tend to have one value in the similarity matrix that is\nmuch larger and, smaller if all values are approximately equal.\ncb,p = 1\nM\n\nX\nj\nmaxi\n \nsij\nP\ni′) si′j\n!p\n\n1\np\nColumn Mean p-Max\n(6.6)\ncolf,p = 1\nN\nX\ni\n\nX\nj\nsp\nij\n\n\n1\np\nColumn Mean p-Norm\n(6.7)\nTo measure the quality of an alignment and normalizing some metrics by dividing\nby matrix size to ensure uniform output, the sparsity metric introduced by Hurley\n\n6.4 textual similarity methods\n129\nand Rickard (2009) is additionally used. Following McCrae and Buitelaar (2018)’s\nﬁndings, the Gaussian Entropy Diversity is also used as the sparsity metric as follows:\nHG =\n1\nMN\nX\ni\nX\nj\n−log(s2\nij)\n(6.8)\nIt is important to note that this method can be applied to deﬁnitions of any length,\nand thus, they can produce similar scores regardless of the length of the input strings.\n6.4.4\nMonolingual Alignment\nIn addition to word alignment in the two deﬁnitions, a simpliﬁed version of the\nmonolingual alignment technique described by Sultan et al. (2014) and McCrae and\nBuitelaar (2018) is also implemented. This technique aims to discover and align se-\nmantic units in a given pair of sentences or phrases, in our case sense deﬁnitions, to\ndetect semantic similarity. To do so, ﬁrst, identical word sequences are identiﬁed and\nlinked in the two deﬁnitions. Then, named entities, such as proper names or name of\norganizations, are linked using Stanford Named Entity Recognizer (Finkel et al., 2005)\nand, content and stop words are aligned in the two deﬁnitions. Finally, the similarity\nof any pair of words in the deﬁnition pair is calculated as follows:\nsim(wi, wj) = ω × wordSim(wi, wj) + (1 −ω) × contextSim(wi, wj)\n(6.9)\nwhere\ncontextSim(wi, wj) =\n1\n|Wi||Wj|\nX\nm∈Wi\nX\nn∈Wj\nwordSim(Wi,m, Wj,n)\n(6.10)\nwhere Wi and Wj are a ﬁxed window of words respectively around wi and wj,\nwordSim is a word similarity function, similar to the previously mentioned ones in\nSection 4.4.1, returning a value in the range of [0, 1], and ω is the weight of word\nsimilarity relative to contextual similarity. It is worth mentioning that the alignment\nmeasures mentioned for the similarity task refers to the alignment of words within\nsentences, akin to alignment in machine translation (Fraser and Marcu, 2007), and is\ndifferent from our general task of alignment in dictionaries.\nOnce the various measures of these techniques, namely monolingual alignment\ndescribed here and word alignment described in Section 6.4.3, are calculated, an\nadditional step is taken to calculate a single similarity score. To do so, a range of\nmethods had been implemented in Naisc McCrae et al. (2017a) which are referred\nto as ‘Scorer’ in Figure 6.1. Throughout our experiments, LibSVM (Chang and Lin,\n\n130\nmonolingual word sense alignment\n2011) is used which trains an SVM model based on the features extracted from the\ntraining data.\n6.5\nsemantic relation induction\nAnother approach to detect the type of semantic relation that exists between a pair\nof senses is by incorporating a knowledge graph and using textual features.\nWe\ndeﬁne a few features which use the lengths of senses along with their textual and\nsemantic similarities. In addition, we incorporate word-level semantic relationships\nto determine the type of relation that two senses may possibly have. To this end, we\nuse ConceptNet (Speer et al., 2016), an openly-available and multilingual semantic\nnetwork with relational knowledge from various other resources, such as Wiktionary\nand WordNet (Miller, 1995). As a supervised method, we rely on the data instances\nextracted from the MWSA benchmark to train models. A similar approach has been\npreviously proposed for aligning bilingual with monolingual dictionaries Saurí et al.\n(2019). Our approach is illustrated in Figure 6.5 where data instances are enriched\nusing the knowledge base; the following sections describe the components of this\napproach.\nsenses1\nsenses2\nfeature extraction\nsemantic relation\nextraction\nknowledge base\nresource 1\nresource 2\nlemma (pos)\nsenses1\nsenses2\naligned senses\nFigure 6.5: Our approach where features are extracted from word senses and external seman-\ntic resources\n6.5.1\nData Extraction\nIn this step, sense instances are extracted from the MWSA datasets that were de-\nscribed in the previous chapter, as t = (p, si, sj, rij). This instance is interpreted as\nsense si has relation rij with sense sj.\nTherefore, the order of appearance is im-\nportant to correctly determine the relationship. It should also be noted that both\nsenses belong to the same lemma with the part-of-speech p. Table 6.3 provides the\nbasic statistics of the senses and their semantic relationships in various languages, ex-\ntracted for training purposes from the MWSA benchmark. “# Entries” and “# SKOS”\nrefer to the number of entries and senses with a relationship within SKOS. In addi-\n\n6.5 semantic relation induction\n131\ntion, the senses within the two resources which belong to the same lemma but are\nnot annotated with a SKOS relationship are included with a none relationship.\nGiven the class imbalance where senses with a none relationship are more fre-\nquent than the others, a data augmentation technique is carried out based on the sym-\nmetric property of the semantic relationships. By changing the order of the senses,\nalso known as relation direction, in each data instance, a new instance can be cre-\nated by semantically reversing the relationship. For instance, for the entry ‘observer’\n(noun), if the sense deﬁnition ‘an expert who observes and comments on something’\nin WordNet is annotated with a narrower relation with respect to ‘an annotator’ in\nWebster, a new instance is created where ‘an annotator’ has a broader relation in com-\nparison to ‘an expert who observes and comments on something’. In other words, for\neach t = (p, si, sj, rij) there is a t′ = (p, sj, si, r′\nij) where r′\nij is the inverse of rij. Thus,\nexact and related as symmetric properties remain the same, however, the asymmet-\nric property of the broader and narrower relationships yields narrower and broader,\nrespectively. The overall number of instances as the result of this data augmentation\nalong with SKOS and none relations is provided in the column # All in Table 6.3.\nFinally, the percentage of relations that are none is speciﬁed in the last column.\nLanguage\n# Entries\n# SKOS\n# SKOS + #none\n# All\nnone (%)\nBasque\n256\n813\n3661\n4382\n64.99%\nBulgarian\n1000\n1976\n3708\n5656\n30.62%\nDanish\n587\n1644\n16520\n18164\n81.90%\nDutch\n161\n622\n20144\n20766\n94.01%\nEnglish9\n684\n1682\n9269\n10951\n69.28%\nEstonian\n684\n1142\n2316\n3426\n34.27%\nGerman\n537\n1211\n4975\n6185\n60.86%\nHungarian\n143\n949\n15774\n16716\n88.69%\nIrish\n680\n975\n2816\n3763\n48.92%\nItalian\n207\n592\n2173\n2758\n57.32%\nSerbian\n301\n736\n5808\n6542\n77.53%\nSlovenian\n152\n244\n1100\n1343\n63.74%\nSpanish\n351\n1071\n4898\n5919\n64.66%\nPortuguese\n147\n275\n2062\n2337\n76.47%\nRussian\n213\n483\n3376\n3845\n75.24%\nTable 6.3: Number of data instances extracted from the MWSA benchmark for training pur-\nposes based on the type of semantic relation. # refers to the number.\nOnce the senses have been extracted, data instances are created using the features\nin Table 6.4. Feature 1 is a one-hot vector indicating the part-of-speech of the entry.\nFeatures 2 and 3 concern the length of senses and how they are different. Intuitively\nspeaking, this regards the wordings used to describe two concepts and their seman-\ntic relationship. In features 2 to 3, this is respectively calculated with and without\nfunction words, i.e. words with little lexical meaning. One additional step is to query\n9 English (NUIG) and English (KD) are merged as well as the Slovenian datasets.\n\n132\nmonolingual word sense alignment\nConceptNet to retrieve semantic relations between the content words in each sense\npair. For instance, the two words “gelded” and “castrated” which appear in two dif-\nferent senses of ‘entire’ in Table 6.1 are synonyms and therefore, the whole senses\ncan be possibly synonyms. In order to measure the reliability of the relationships, the\nweights of each relationship, also known as assertions, are summed up according to\nConceptNet. Features 4 to 10 correspond to the weight of various relationships based\non ConceptNet. Further, features 11 and 12 provide the semantic similarity of each\nsense pair using word embeddings, respectively with and without function words.\nFor this purpose, GloVe (Pennington et al., 2014) or fastText10 are used. Finally, fea-\ntures 13, 14 and 15 indicate the type of semantic relation based on the annotations in\nthe MWSA benchmark. These are used as the target classes for our classiﬁcation prob-\nlem. It should be mentioned that the data instances are all standardized by scaling\neach feature to the range of [0-1].\n#\nfeature\ndeﬁnition\npossible values\n1\nPOS_tag\npart of speech of the headword\na one-hot vector of {n, v, adj,\nadv, other}\n2\ns_len_no_func_1/2\nnumber of space-separated tokens\nin s1 and s2\nN\n3\ns_len_1/2\nnumber of space-separated tokens\nin s1 and s2 without function\nwords\nN\n4\nhypernymy\nhypernymy score between tokens\nsum of weights in Concept-\nNet\n5\nhyponymy\nhyponymy score between tokens\nsum of weights in Concept-\nNet\n6\nrelatedness\nrelatedness score between tokens\nsum of weights in Concept-\nNet\n7\nsynonymy\nsynonymy score between tokens\nsum of weights in Concept-\nNet\n8\nantonymy\nantonymy score between tokens\nsum of weights in Concept-\nNet\n9\nmeronymy\nmeronymy score between tokens\nsum of weights in Concept-\nNet\n10\nsimilarity\nsimilarity score between tokens\nsum of weights in Concept-\nNet\n11\nsem_sim\nsemantic similarity score between\nsenses using word embeddings\naveraging word vectors and co-\nsine similarity [0-1]\n12\nsem_sim_no_func\nsemantic similarity score between\nsenses without function words\naveraging word vectors and co-\nsine similarity excluding func-\ntion words [0-1]\n13\nsem_bin_rel\ntarget class\n1 for alignable, otherwise 0\n14\nsem_rel_with_none\ntarget class\n{exact, narrower, broader,\nrelated, none}\n15\nsem_rel\ntarget class\n{exact, narrower, broader,\nrelated}\nTable 6.4: Manually extracted features for semantic classiﬁcation of sense relationships (21\ncolumns in total)\n10 https://fasttext.cc\n\n6.5 semantic relation induction\n133\n6.5.2\nFeature Learning\nDespite the differences in measuring various similarity score metrics, there could be\na relation between some of the metrics (features) given their theoretical resemblance;\nfor instance, similarity scores obtained from ConceptNet and embeddings could cap-\nture similarity between words being semantically related, such as synonyms. In such\nscenarios where various features are brought together for a speciﬁc task with a po-\ntential relation between them, deﬁning and modeling the relationship between all the\nsimilarity measures is not feasible in a manual manner. Inferring how various simi-\nlarity measures work in relation to each other is beneﬁcial to evaluate the similarity\nbetween two deﬁnitions or senses more accurately. To this end, various representa-\ntion learning methods have been developed. Therefore, in addition to the feature\nextraction and data augmentation, we proceed with a feature learning step.\nRestricted Boltzmann machine (RBM) is a generative model representing a proba-\nbility distribution given a set of observations (Fischer and Igel, 2012). Its main applica-\ntion in feature learning and dimensionality reduction has made it a popular solution\nin various classiﬁcation and regression problems in machine learning, notably in the\nﬁelds of speech recognition (Jaitly and Hinton, 2011; Zheng et al., 2013), image pro-\ncessing (Sheri et al., 2018; Teh and Hinton, 2001) and pattern recognition (Alani, 2017).\nIt is also widely used in combination with various neural network methods such as\ndeep belief networks (Hinton, 2009). In the task of similarity detection, instead of\ntraining our models using the similarity score values, an RBM model is ﬁrst trained,\nwhich is unsupervised, and then the classiﬁers are trained using the latent features of\nthe RBM model. These new features have binary values and can be conﬁgured and\ntuned depending on the performance of the models.\nv1\nv2\nv3\n· · ·\nvn\nv ∈{0, 1}n\na1\na2\na3\nan\nh1\nh2\n· · ·\nhm\nh ∈{0, 1}m\nb1\nb2\nbm\nW ∈Rn×m\nw1,1\nwm,n\nFigure 6.6: An example of restricted Boltzmann Machine with a m latent units and n visible\nunits\nAn RBM, as illustrated in Figure 6.6, is composed of two layers: a visible one\nv where the data instances are provided, and a latent one h where a distribution is\ncreated by the model by retrieving dependencies within variables. While all the nodes\nin the visible layer are connected to the nodes in the latent layer, the nodes within the\nvisible or latent layer are not interlinked; this restriction is the main difference of an\n\n134\nmonolingual word sense alignment\nRBM with a Boltzman machine (Montúfar, 2018). Once trained, an RBM model learns\nthe underlying relation and distribution of the features in how the target classes are\npredicted. The features in the visible layer can be manually-created or based on the\noutput of another classiﬁcation problem. We follow the description of Hinton (2012)\nin implementing and using an RBM. In our case, we use similarity scores as visible\nunits as they are observed; such scores are either binary or with a value between 0\nand 1. In addition, the the values of the latent layers are binary. An RBM with such\nunits is also known as Bernoulli Restricted Boltzmann Machine.\nGiven a ﬁnite set of features in the visible layer with states vi ∈[0, 1] and bias\nvalues ai ∈R, the energy of a joint conﬁguration of the visible and latent units is\ndeﬁned as the following energy function (Hopﬁeld, 1982):\nE(v, h) = −\nX\ni∈visible\naivi −\nX\nj∈hidden\nbjhj −\nX\ni,j\nvihjwij\n(6.11)\nwhere hj is a hidden unit with state hj ∈[0, 1] and bias value bj and wij ∈R is a\nrandom variable as the weight between the visible unit vi and hj. The RBM network\nassigns a probability to every connection between a visible node and a hidden one as\nfollows:\np(v, h) = 1\nZeE(v,h)\n(6.12)\nwhere Z refers to the sum of all possible combinations of visible and hidden units:\nZ =\nX\nv,h\neE(v,h)\n(6.13)\nAnd, the probability given to a visible unit is equivalent to the sum of the values\nof all the hidden units:\np(v) =\nX\nh\np(v, h) = 1\nZ\nX\nh\ne−E(v,h)\n(6.14)\nThe objective of learning in this model is to maximize the probability that RBM\nassigns to the binary units in the training set, those being the similarity scores. There-\nfore, stochastic gradient ascent can be carried out by adjusting weights W, and biases\nsuch that the overall energy E(v, h) decreases. To calculate this, a log-likelihood ob-\njective function is used and differentiated with respect to the weight as follows:\n∂logp(v)\n∂wij\n=\n\nvihj\n\u000b\ndata −\n\nvihj\n\u000b\nmodel\n(6.15)\n\n6.6 experiments\n135\nwhere brackets refer to the expectations under the speciﬁed distributions. This\nway, the following learning rule is deﬁned which is optimized through the training\nphase:\n∆wij = η(\n\nvihj\n\u000b\ndata −\n\nvihj\n\u000b\nmodel)\n(6.16)\nwhere η refers to the learning rate. The optimization is carried out by calculating\nthe overall energy of the model for a visible vector and then, update hidden vectors\nand visible vectors, accordingly. Given a visible unit, the binary state of each hidden\nunit j is set to 1 with the following probability (without calculating the bias):\np(hj = 1|v) = σ(bj +\nX\ni\nviwij)\n(6.17)\nwhere σ is the logistic sigmoid function as non-linearity. Contrastive divergence learn-\ning (Carreira-Perpinan and Hinton, 2005) is usually used in the optimization phase\nto facilitate the convergence of the network.\n6.6\nexperiments\nIn the previous sections, various textual and non-textual similarity detection meth-\nods were introduced to estimate how similar two deﬁnitions are. In addition, a few\nlinking constraints were introduced to optimize the linking between sense pairs of\nthe same lemma belonging to the same part-of-speech tags in two different monolin-\ngual dictionaries. Using these, a few experiments are carried out to evaluate various\naspects of the alignment problem. A baseline system is ﬁrst provided as the basis to\ncreate and compare more robust approaches based on classiﬁcation, knowledge graph\nand deep learning. Given the number of datasets (17) in the evaluation benchmark,\nsome of the experiments are exclusively limited to a few of the datasets. It should\nalso be mentioned that the experiments do not include similarity scores calculated\nusing deep learning, including BERT (described in Section 6.4.2).\nMultiple metrics are used to evaluate the results of the systems. Firstly, accuracy\nmeasures the total number of links for which the correct class of relationship is pre-\ndicted, in other words, the percentage of scores for which the predicted label matches\nthe reference label. Secondly, recall, precision and F-Measure scores, deﬁned based\non Powers (2020). The systems are overall scored based on a macro-average of the\naccuracy, precision, recall and F-Measure, as deﬁned in Chapter 4.\n\n136\nmonolingual word sense alignment\n6.6.1\nBaseline System\nWe create a simple baseline system where for each sense pair, the Jaccard similarity\nof the set of words within glosses is calculated, then the Hungarian algorithm is used\nto ﬁnd the most likely unique assignment between these senses. The baseline only\npredicts the ‘exact’ and ‘none’ classes so it is expected that the results would be quite\npoor. The baseline is evaluated using accuracy, precision, recall and F-measure and\nthe results along with the statistics of the datasets are provided in Table 6.5.\nLanguage\nAccuracy\nPrecision\nRecall\nF-measure\nBasque\n0.789\n0.211\n0.050\n0.081\nBulgarian\n0.728\n0.250\n0.011\n0.020\nDanish\n0.817\n0.300\n0.023\n0.043\nDutch\n0.936\n0\n0\n0\nEnglish\n0.752\n0\n0\n0\nEstonian\n0.482\n0.545\n0.093\n0.159\nGerman\n0.7777\n0\n0\n0\nHungarian\n0.940\n0.053\n0.012\n0.020\nIrish\n0.583\n0.680\n0.185\n0.291\nItalian\n0.693\n0\n0\n0\nSerbian\n0.853\n0\n0\n0\nSlovene\n0.834\n0.100\n0.009\n0.017\nSpanish\n0.678\n0.255\n0.127\n0.170\nPortuguese\n0.921\n0.083\n0.024\n0.037\nRussian\n0.754\n0.438\n0.179\n0.255\nAverage\n0.769\n0.194\n0.048\n0.074\nTable 6.5: The baseline system using Jaccard similarity metric and Hungarian algorithm for\nalignment.\nEven though the baseline system is able to align deﬁnition pairs accurately in half\nof the cases, the fraction of relevant instances among the retrieved ones, i.e. preci-\nsion, and the fraction of relevant instances that are retrieved, i.e. recall, is quite low.\nConsequently, the F-measure is low and even zero in some of the cases. Looking\nback at Table 6.3, we notice that, except for Bulgarian, Estonian and Irish, over 50%\nof all the relations in the datasets belong to ‘none’. Therefore, there is no surprise\nthat the baseline system can achieve such an accuracy. Furthermore, the alignment of\nthe Hungarian data having the highest accuracy of 0.94 can be explained by the lack\nof distinction between part-of-speech tags in the datasets. This is an exceptional case\nas in other datasets, the alignment is carried out based on not only identical lemmas,\nbut also identical part-of-speech tags. It should also be noted that for languages for\nwhich more than one dataset exists in the benchmark, the annotations are merged\nand treated as one dataset.\nIn the intrinsic evaluation of our benchmark in the previous chapter in Section 5.5,\na few evaluations are carried out to describe the characteristics of the datasets, such\n\n6.6 experiments\n137\nas density and degree in Table 5.8, and the correlation between the number of tokens\nin the ﬁrst and second resource in Figure 5.9. In addition to the imbalance of data,\ndespite our efforts to create more data instances thanks to induction, the alignment\ntask is difﬁcult due to the difference in the granularity of senses and deﬁnitions. This\ncan be demonstrated by comparing the number of tokens in the two dictionaries per\ndataset, respectively referred to as R1 and R2 in Figure 5.9.\nIn the rest of this section, we focus on the alignment problem with binary and\nSKOS relations, but also how the length of deﬁnitions can play a role in improving\nthe results.\n6.6.2\nSystem 1: Classiﬁcation and Feature Learning\nIn this system, we train various classiﬁcation models using support vector machines\n(SVMs) based on different hyper-parameters, as implemented in Scikit-learn11 (Pe-\ndregosa et al., 2011). After a preprocessing step, where the datasets are shufﬂed, nor-\nmalized and scaled, we split them into train, test and validation sets with 80%, 10%\nand 10% proportions, respectively. The performance of the models is evaluated for all\nthe languages with and without the feature learning step. In the latter case, instead\nof training our models using the data instances described in the previous section, we\ntrain the models using the latent features of an RBM model. These new features have\nbinary values and can be conﬁgured and tuned depending on the performance of the\nmodels.\nTable 6.6 presents the best performance of the models trained for each language.\nThe experiments are carried out based on three classiﬁcation objectives: (i) a binary\nclassiﬁcation, where the model classiﬁes a pair of sense deﬁnitions to be aligned, i.e.\nthe target class is 1, or not, i.e. the target class is 0, (ii) a SKOS classiﬁcation where\none of the SKOS relations, namely exact, narrower broader and related, is determined\nby the model on those sense pairs for which a relation exists in the gold-standard\ndatasets, and ﬁnally (iii) a classiﬁcation over all the possible relations, namely SKOS\nrelations and none. The latter is referred to as All or RBM-All in the table. Our\nevaluation is carried out using the same metrics of the baseline in Table 6.5, but\nfor all classiﬁcation setups. Our optimal models that are reported in Table 6.6 were\ntrained with 50 iterations, a learning rate within [0.05-0.2], a hidden unit number of\nthe RBM model within the range of 400 and 600 and linear, radial basis and polyno-\nmial kernel functions for SVM. The tuning of the hyper-parameters was carried out\nusing the exhaustive grid search in Scikit-learn12. The highest values of F-measure\nfor each language and classiﬁcation task are indicated in different colors: cyan for\nbinary classiﬁcation, violet for SKOS classiﬁcation and green for the classiﬁcation of\nall relations.\n11 https://scikit-learn.org\n12 https://scikit-learn.org/stable/modules/grid_search.html\n\n138\nmonolingual word sense alignment\nDespite the high accuracy of the models for most languages, they do not perform\nequally efﬁciently for all languages in terms of precision and recall. Our classiﬁers\noutperform the baselines for all the relation prediction tasks in terms of accuracy and\nperform with high accuracy when trained for the binary classiﬁcation and also given\nall data instances. This is thanks to the majority of sense pairs in two dictionaries\nhaving no semantic relation, i.e. their semantic relation is ‘none’. However, there is a\nsigniﬁcant low performance when it comes to the classiﬁcation of SKOS relationships.\nIn other words, when a model is trained on the data instances that should be aligned\nas there are none with a ‘none’ relation, the F-measure is not exceeding 0.5349 (for\nPortuguese). While, the F-measure score for the binary and all classiﬁcation tasks\nrespectively reaches 0.8760 and 0.7890 (both for Dutch). It should be noted that F-\nmeasure combines both precision and recall, therefore, is a good metric to estimate\nthe effectiveness of a model.\nRegarding the performance of RBM in terms of accuracy and F-measure, we do\nnot observe an improvement in the results of all classiﬁers and see that almost half\nof the highest scores are in fact thanks to using an RBM. However, the precision\nof the models which learn features with an RBM is higher in the majority of cases.\nAs such, the initial hypothesis that using RBM would help improving the results by\nlearning latent relations between features is not unquestionably sound. It has been\ndemonstrated that models that are trained using log-likelihood objective functions,\nlike RBM, are prone to fail to assign correct probability to instances for which a lower\nnumber of data are provided in the training phase (Fisher et al., 2018). In our case,\na lower number of data instances with a SKOS relation, as Table 6.3 shows, means\nthat the trained model tends to learn assigning relations with more frequency, such\nas ‘exact’ and ‘none’ rather than the less frequent ones, as ‘broader’, ‘narrower’ and\n‘related’.\nGiven the difﬁculty of determining the type of semantic relations, the lower per-\nformance of the systems with respect to the SKOS classiﬁcation task is not surprising.\nDistinguishing certain types of relationships, such as related versus exact, is a chal-\nlenging task even for an expert annotator. This has been previously discussed by\nKoskela (2014) regarding the systematic representation of senses and broader vs. nar-\nrower distinctions in lexicography. In our case, for instance, the relationship between\ntwo senses of entire in Table 6.1, “constituting the undiminished entirety” and “com-\nplete in all parts; undivided; undiminished; whole” is annotated as ‘narrower’ and\nexact by two different annotators.\nTwo examples of the alignment of ‘tube’ (verb) and ‘glow’ (verb) are respectively\nprovided in Tables 6.7 and 6.8. In the case of ‘tube’, all systems, i.e. baseline, System\n1 and BERT (Bajcetic and Yim, 2020), detect R1A and R2A as the senses to be aligned,\nand all detect a ‘narrower’ relation between them which is not the one that the gold-\nstandard data shows (exact). On the other hand, ‘glow’ has three alignments in the\ngold-standard dataset, all with an ‘exact’ relation, while the systems, except BERT,\n\n6.6 experiments\n139\ndetect only two senses to be aligned and none of them are identical with the reference\nannotations. It should be noted that only predictions with a similarity scores of over\n0.1 are presented in the table and any predictions with a lower similarity score is\nconsidered to be ‘none’. It is worth mentioning that BERT in Tables 6.7 and 6.8 refers\nto the shared task system submitted by Bajcetic and Yim (2020) (see Section 6.7).\nRegarding the levels of difﬁculty of the semantic relations, the ‘related’ relation\nis the least-correctly predicted relation making it the most challenging one. Figure\n6.7 shows different confusion matrices with a heatmap of the binary, SKOS and\nSKOS+none (all) classiﬁcation problems. These are the results of the performance\nof the model trained on the English data and tested on a subset of the English data\nin MWSA. Therefore, there is a lower number of instances in the test sets of SKOS\nin comparison to SKOS+none and binary classiﬁcation. In the binary classiﬁcation\nin Figure 6.7a, we see that the model detects sense pairs with ‘none’ relations more\nfrequently correctly. However, in 13% of cases (358 instances), the model incorrectly\npredicts no alignment and in 4% (125 instances) of cases, the model predicts that a\nsense pair should be aligned while the true label suggests otherwise. Similarly, in\nthe SKOS relation in Figure 6.7b, the majority of the correct predictions have an ‘ex-\nact’ relation. However, the model tends to incorrectly predict other relations, namely\n‘broader’, ‘narrower’ and ‘related’, as ‘exact’ as well. The same issue is observed with\nrespect to the ‘none’ relation in the SKOS+none classiﬁcation in Figure 6.7c. More\nresults from other datasets are not provided given that it would take much more\nspace.\nOn average, the SVM method without RBM performs better in terms of F-measure\nwith 0.6845, 0.5459 and 0.3743 scores respectively for the binary, SKOS and SKOS+none\nclassiﬁcations.\n\n140\nmonolingual word sense alignment\nLanguage\nMetric\nBinary\nAll\nSKOS\nRBM-Binary\nRBM-All\nRBM-SKOS\nBasque\nAccuracy\n0.7879\n0.5847\n0.4977\n0.7037\n0.5417\n0.2885\nPrecision\n0.7140\n0.5921\n0.4365\n0.6214\n0.5908\n0.2073\nRecall\n0.7278\n0.5845\n0.4601\n0.7493\n0.5255\n0.5087\nF-measure\n0.7208\n0.5883\n0.4480\n0.6794\n0.5562\n0.2946\nBulgarian\nAccuracy\n0.7060\n0.6591\n0.3405\n0.7351\n0.6338\n0.3647\nPrecision\n0.6875\n0.6479\n0.3175\n0.7746\n0.3446\n0.3685\nRecall\n0.6932\n0.6544\n0.3183\n0.7291\n0.4987\n0.2486\nF-measure\n0.6903\n0.6511\n0.3179\n0.7511\n0.4076\n0.2969\nDanish\nAccuracy\n0.6647\n0.3482\n0.2787\n0.7385\n0.5008\n0.2967\nPrecision\n0.7454\n0.2370\n0.3649\n0.6059\n0.6096\n0.3047\nRecall\n0.7551\n0.6290\n0.2287\n0.5566\n0.6692\n0.7304\nF-measure\n0.7502\n0.3443\n0.2812\n0.5802\n0.6380\n0.4300\nDutch\nAccuracy\n0.8255\n0.5999\n0.2475\n0.8390\n0.5147\n0.3634\nPrecision\n0.8697\n0.7859\n0.3138\n0.5978\n0.7782\n0.3066\nRecall\n0.8824\n0.7922\n0.3310\n0.6733\n0.3965\n0.6603\nF-measure\n0.8760\n0.7890\n0.3222\n0.6333\n0.5254\n0.4188\nEnglish\nAccuracy\n0.8900\n0.8100\n0.4900\n0.8016\n0.6503\n0.4857\nPrecision\n0.8235\n0.7303\n0.3931\n0.6436\n0.6367\n0.5553\nRecall\n0.8287\n0.7641\n0.4663\n0.8213\n0.7935\n0.3451\nF-measure\n0.8261\n0.7468\n0.4266\n0.7217\n0.7065\n0.4257\nEstonian\nAccuracy\n0.7898\n0.5892\n0.4611\n0.7596\n0.6275\n0.4782\nPrecision\n0.7606\n0.6883\n0.4081\n0.6353\n0.6067\n0.3663\nRecall\n0.2076\n0.5782\n0.4402\n0.2818\n0.4935\n0.2244\nF-measure\n0.3262\n0.6285\n0.4235\n0.3905\n0.5443\n0.2783\nGerman\nAccuracy\n0.7314\n0.6199\n0.4958\n0.7797\n0.4323\n0.4421\nPrecision\n0.7772\n0.6474\n0.4189\n0.8044\n0.6634\n0.4099\nRecall\n0.5441\n0.5995\n0.4373\n0.2288\n0.2792\n0.4899\nF-measure\n0.6401\n0.6225\n0.4279\n0.3563\n0.3930\n0.4463\nHungarian\nAccuracy\n0.7965\n0.5840\n0.2295\n0.8146\n0.3627\n0.1520\nPrecision\n0.4996\n0.3014\n0.2341\n0.6850\n0.5980\n0.2658\nRecall\n0.5447\n0.3795\n0.6808\n0.5672\n0.7385\n0.2923\nF-measure\n0.5212\n0.3360\n0.3485\n0.6205\n0.6609\n0.2784\nIrish\nAccuracy\n0.7500\n0.5575\n0.2627\n0.7961\n0.6084\n0.2475\nPrecision\n0.8442\n0.4658\n0.3184\n0.7903\n0.4252\n0.3025\nRecall\n0.8446\n0.3985\n0.4615\n0.5247\n0.5465\n0.2540\nF-measure\n0.8444\n0.4295\n0.3768\n0.6306\n0.4783\n0.2761\nItalian\nAccuracy\n0.5908\n0.5543\n0.4448\n0.7723\n0.4626\n0.4301\nPrecision\n0.5255\n0.4298\n0.2880\n0.7569\n0.4631\n0.4056\nRecall\n0.6647\n0.5264\n0.4216\n0.4505\n0.6867\n0.3127\nF-measure\n0.5869\n0.4732\n0.3422\n0.5649\n0.5532\n0.3532\nSerbian\nAccuracy\n0.8005\n0.3253\n0.2755\n0.8235\n0.4143\n0.3296\nPrecision\n0.7678\n0.4857\n0.4306\n0.7351\n0.3770\n0.2149\nRecall\n0.6573\n0.6940\n0.2710\n0.7746\n0.4845\n0.5553\nF-measure\n0.7083\n0.5715\n0.3326\n0.7543\n0.4240\n0.3099\nSlovenian\nAccuracy\n0.8429\n0.3613\n0.2613\n0.7893\n0.3957\n0.3163\nPrecision\n0.7308\n0.2319\n0.4698\n0.7862\n0.3859\n0.2097\nRecall\n0.8322\n0.4507\n0.2861\n0.4164\n0.2809\n0.3302\nF-measure\n0.7782\n0.3062\n0.3556\n0.5445\n0.3251\n0.2565\nSpanish\nAccuracy\n0.7379\n0.5467\n0.3028\n0.8071\n0.5438\n0.5848\nPrecision\n0.7978\n0.5507\n0.3321\n0.7940\n0.4254\n0.3957\nRecall\n0.8037\n0.5315\n0.4004\n0.6018\n0.2068\n0.3859\nF-measure\n0.8007\n0.5410\n0.3631\n0.6847\n0.2783\n0.3907\nPortuguese\nAccuracy\n0.7131\n0.6662\n0.5171\n0.7314\n0.5569\n0.4287\nPrecision\n0.4929\n0.5823\n0.5352\n0.7772\n0.6941\n0.4045\nRecall\n0.3747\n0.7041\n0.5347\n0.5441\n0.2232\n0.3815\nF-measure\n0.4257\n0.6374\n0.5349\n0.6401\n0.3378\n0.3926\nRussian\nAccuracy\n0.6088\n0.5890\n0.3775\n0.7580\n0.5976\n0.3310\nPrecision\n0.7292\n0.6383\n0.2728\n0.7338\n0.7377\n0.3271\nRecall\n0.8221\n0.4443\n0.3674\n0.6823\n0.7039\n0.4775\nF-measure\n0.7729\n0.5239\n0.3131\n0.7071\n0.7204\n0.3882\nAverage\nAccuracy\n0.7491\n0.5597\n0.3655\n0.7766\n0.5229\n0.3693\nPrecision\n0.7177\n0.5343\n0.3689\n0.7161\n0.5558\n0.3363\nRecall\n0.6789\n0.5821\n0.4070\n0.5735\n0.5018\n0.4131\nF-measure\n0.6845\n0.5459\n0.3743\n0.6173\n0.5033\n0.3491\nTable 6.6: Results of the experiments on semantic induction on binary, SKOS and all relations,\nnamely exact, related, broader, narrower and none, with and without an RBM. The\nhighest F-measure scores in binary, all and SKOS classiﬁcations per language are\nrespectively indicated in cyan, green and violet. Darker shades indicate higher\nvalues.\n\n6.6 experiments\n141\n0\n1\nPredicted label\n0\n1\nTrue label\n1789\n125\n358\n437\n200\n400\n600\n800\n1000\n1200\n1400\n1600\n(a) binary classiﬁcation\nbroader\nexact\nnarrower\nrelated\nPredicted label\nbroader\nexact\nnarrower\nrelated\nTrue label\n14\n175\n7\n0\n3\n358\n5\n0\n5\n148\n9\n0\n8\n89\n11\n0\n0\n50\n100\n150\n200\n250\n300\n350\n(b) SKOS classiﬁcation\nbroader\nexact\nnarrower\nnone\nrelated\nPredicted label\nbroader\nexact\nnarrower\nnone\nrelated\nTrue label\n16\n59\n0\n125\n0\n4\n153\n0\n161\n0\n3\n34\n0\n138\n0\n1\n33\n0\n1880\n0\n5\n9\n0\n88\n0\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n(c) SKOS+none classiﬁcation\nFigure 6.7: Confusion matrices of various classiﬁcation models evaluated on the English test\nset\n\n142\nmonolingual word sense alignment\ntube (verb)\nSense deﬁnitions in resource 1, the Princeton English WordNet (R1)\nR1A\nprovide with a tube or insert a tube into\nR1B\nride or ﬂoat on an inﬂated tube\nR1C\nconvey in a tube\nR1D\nplace or enclose in a tube\nSense deﬁnitions in resource 2, Webster’s Dictionary 1913 (R2)\nR2A\nto furnish with a tube\nAlignments\nGold-standard\nR1A exact R2A\nBaseline\nR1A narrower R2A\n(similarity score: 0.2793)\nSystem 1\nR1A narrower R2A\n(similarity score: 0.8013)\nBERT\nR1A narrower R2A\n(similarity score: 0.93)\nTable 6.7: A comparison of the output of various systems for aligning sense deﬁnitions of\ntube (verb). BERT refers to the shared task system submitted by Bajcetic and Yim\n(2020).\nglow (verb)\nSense deﬁnitions in resource 1, the Princeton English WordNet (R1)\nR1A\nshine intensely, as if with heat\nR1B\nbe exuberant or high-spirited\nR1C\nexperience a feeling of well-being or happiness, as from good health\nor an intense emotion\nR1D\nhave a complexion with a strong bright color, such as red or pink\nR1E\nemit a steady even light without ﬂames\nSense deﬁnitions in resource 2, Webster’s Dictionary 1913 (R2)\nR2A\nto make hot; to ﬂush.\nR2B\nto shine with an intense or white heat; to give forth vivid light and\nheat; to be incandescent.\nR2C\nto exhibit a strong, bright color; to be brilliant, as if with heat; to be\nbright or red with heat or animation, with blushes, etc.\nR2D\nto feel hot; to have a burning sensation, as of the skin, from friction,\nexercise, etc.; to burn.\nR2E\nto feel the heat of passion; to be animated, as by intense love, zeal,\nanger, etc.\nAlignments\nGold-standard\nR1A exact R2B\nR1C exact R2D\nR1E exact R2C\nBaseline\nR1A narrower R2B\n(similarity score 0.1524)\nR1C narrower R2E\n(similarity score: 0.1836)\nSystem 1\nR1A narrower R2B\n(similarity score 0.7455)\nR1C related R2E\n(similarity score: 0.6429)\nBERT\nR1A none R2A\n(similarity score: 0.952)\nTable 6.8: A comparison of the output of various systems for aligning sense deﬁnitions of\nglow (verb). BERT refers to the shared task system submitted by Bajcetic and Yim\n(2020).\n\n6.6 experiments\n143\n6.6.3\nSystem 2: Length-limited Alignment\nIn order to evaluate the impact of length of deﬁnitions on the alignment task, an-\nother study is carried out where models are trained based on a maximum number\nof tokens per deﬁnition. To this end, we focus on the Danish dataset which has the\nhighest number of senses among all the datasets (see Table 5.8). In addition, the\nDanish dataset has a few other characteristics that makes it an interesting choice for\nexperiments: (i) it has the highest number of tokens, making deﬁnitions wordier as\nFigure 5.9 shows, (ii) it aligns a historical and modern dictionary of Danish and (iii)\nboth DDO and ODS represent senses in a hierarchy.\nIn this experiment, we particularly evaluate the performance of the following sim-\nilarity detection methods to detect whether two sense deﬁnitions should be aligned\nor not, i.e. binary classiﬁcation:\n• String metrics as introduced in Section 4.4.1, namely longest common substring,\nlength ratio, average word length ratio, Jaccard, Dice, and Containment and\nsmoothed Jaccard.\n• Similarity based on word embeddings trained on the Danish dictionaries Ordbog\nover det danske Sprog (ODS)13 (Dahlerup, 1918) and Den Danske Ordbog (DDO)\n(Farø et al., 2003) as described in Section 6.4.2. To do so, we used Sørensen and\nNimb (2018)’s word embeddings model trained using a corpus of approximately\none billion running words of modern Danish. The model is trained using the\nGloVe model (Pennington et al., 2014) with 500 features, a window size of 5 and\na minimum occurrence of 5 (any types below this threshold are discarded), and\nused the Skip-Gram version of the model.\n• Automatic feature extraction in which we automatically extract useful features\nusing the two previous methods of string similarity and word embeddings com-\nbined. Features are extracted using the training set in such a way that the per-\nformance of the extracted features is maximal among the whole combination of\nfeatures. To do so, an SVM is used with cross-validation.\nTo do so, we summarize sense deﬁnitions as the ODS sense descriptions are of-\nten very detailed and syntactically complex and the borders between deﬁnition text,\nusage examples and idioms still remain to be fully identiﬁed in the XML structure.\nFor the experiments in this section, in addition to the full original deﬁnition, we cre-\nate three other datasets in such a way that the number of space-separated tokens is\nlimited to only 15, 20 and 25 tokens.\nOnce the similarity scores are extracted based on the aforementioned methods, we\nautomatically align senses in a greedy approach where, starting with no alignment,\nthe sense pairs are ordered based on the similarity score and then aligned in such\na way that a sense is linked to only one other sense in the other resource, i.e. ODS\n13 https://ordnet.dk/ods_en\n\n144\nmonolingual word sense alignment\nand DDO. Although this bijective constraint ignores polysemous senses, it yields a\nmore diverse combination of sense matches. Table 6.9 provides the results of our\nexperiments with respect to the number of tokens in ODS.\nAlthough the precision of the models in automatically detecting the similarity of\ntwo senses varies in a close range of 50.3% (All-auto) and 66.7% (15-Word embed-\ndings), there is a more signiﬁcant difference between the recall of each dataset and so,\nin F-measure. The lowest recall appears in aligning DDO with ODS with its original\nsenses. In other words, when senses with all the composing parts, such as usage\nexamples and idioms, are aligned with DDO, all the three models can predict a link\nover 50% correctly. However, they only succeed in less than 10% of cases to retrieve\nrelevant senses. Truncating senses from 25 tokens to 15 signiﬁcantly improves both\nthe precision and recall, proving our initial observation of the noisiness of senses in\nODS. Figure 6.8 illustrates the correlation of senses sizes with F-measures in all the\nmodels.\nODS sense size\nModel\nPrecision\nRecall\nF-measure\n15\nString metrics\n0.653\n0.481\n0.554\nWord embeddings\n0.667\n0.48\n0.558\nAuto\n0.64\n0.466\n0.54\n20\nString metrics\n0.615\n0.443\n0.515\nWord embeddings\n0.647\n0.467\n0.543\nAuto\n0.633\n0.458\n0.532\n25\nString metrics\n0.575\n0.219\n0.317\nWord embeddings\n0.559\n0.212\n0.308\nAuto\n0.585\n0.222\n0.321\nAll\nString metrics\n0.547\n0.098\n0.167\nWord embeddings\n0.507\n0.097\n0.163\nAuto\n0.503\n0.094\n0.158\nTable 6.9: The performance of our similarity detection models for automatic alignment of\nDDO and ODS within a speciﬁc limit of space-separated tokens (15, 20, 25 and all\ntokens)\nThe highest F-measure of 55.8% belongs to the ODS dataset with a maximum of 15\ntokens and trained with the word embeddings model. In comparison to the baselines\npresented in Table 6.5 where an F-measure of 0.043 is reported, such an improvement\nis promising. This being said, the knowledge graph based approach described in\nthe System 1 (see Section 6.6.2) outperforms this model with an F-measure of 0.7502.\nHowever, it is important to conclude based on the current experiment that the conciser\ndeﬁnitions tend to facilitate the alignment task signiﬁcantly.\n\n6.7 elexis monolingual word sense alignment task\n145\nODS sense size\nF-measure\n0.00%\n25.00%\n50.00%\n75.00%\n100.00%\n\"15\"\n\"20\"\n\"25\"\nAll\nString metrics\nWord Embeddings\nAuto\nFigure 6.8: The correlation of sense sizes in ODS with F-measure using various methods\n6.7\nelexis monolingual word sense alignment task\nIn order to motivate other researchers to address the MWSA task, we organized a\nshared task in the 3rd GLOBALEX Workshop at LREC 202014. The task was orga-\nnized using CodaLab15 and three external teams participated, although not all teams\nparticipated for all languages.\nThe evaluation of the shared task was carried out\nas described in this chapter, using accuracy, precision, recall and F-measure. The\nperformance of the participating systems is compared with the baseline and our ex-\nperiments in System 1 described in Section 6.6.2. The following approaches were\nsuggested by the participants:\nracai (Pais et al., 2020) The RACAI system viewed this task as a case of word-sense\ndisambiguation, from this multiple features were extracted including scores\nbased on the Lesk algorithm (Lesk, 1986) as well as features from BERT (Devlin\net al., 2018) and other features, which were combined using a random forest\n(Ho, 1995).\nacdh (Bajcetic and Yim, 2020) This system deﬁnes the MWSA task as sentence pair\nclassiﬁcation task for which BERT can be ﬁne-tuned since its use of self-attention\nmechanism (Vaswani et al., 2017) to encode concatenated text pairs effectively\nincludes bidirectional cross attention between two deﬁnitions. A variety of fea-\ntures were combined in this approach including simple similarity methods such\n14 https://globalex2020.globalex.link/globalex-workshop-lrec2020-about-globalex-lrec2020/\n15 https://competitions.codalab.org/competitions/22163\n\n146\nmonolingual word sense alignment\nas used in the baseline as well as similarities coming from ELMo (Peters et al.,\n2018b) and BERT (Devlin et al., 2018). These were also combined using a super-\nvised learning framework, and different settings were used for each language.\nunior (Manna et al., 2020) This system used BERT as well as Siamese LSTMs (Mueller\nand Thyagarajan, 2016) improved with lexical semantic information related to\nthe lemma’s part-of-speech category.\nThe results of various systems along with System 1 are presented in Table 6.10\nin terms of accuracy and F-measure. Given that the participants did not report the\nperformance of their systems with respect to SKOS classiﬁcation, we only compared\nresults of the binary and SKOS+none (all) tasks.\nEven though all the evaluation\nresults were not reported for all systems and for all languages, there are promising\nimprovements in some of the systems, particularly ACDH and UNIOR in comparison\nto System 1. However, all systems can be said to have performed best on some of the\ntasks (even the baseline) and given that all systems used BERT, more research is\nneeded into the best way to ﬁne-tune BERT for this task.\nLanguage\nMetric\nBinary\nAll\nSystem 1\nRACAI\nACDH\nUNIOR\nSystem 1\nRACAI\nACDH\nUNIOR\nBasque\nAccuracy\n0.7879\n0.5847\n0.407\nF-measure\n0.7208\n0.342\n0.5883\nBulgarian\nAccuracy\n0.7351\n0.6591\n0.395\nF-measure\n0.7511\n0.475\n0.6511\nDanish\nAccuracy\n0.7385\n0.5008\n0.522\nF-measure\n0.7502\n0.379\n0.638\nDutch\nAccuracy\n0.839\n0.5999\n0.798\n0.94\n0.931\nF-measure\n0.876\n0.48\n0.35\n0.145\n0.789\nEnglish\nAccuracy\n0.89\n0.81\n0.944\n0.766\n0.759\nF-measure\n0.8261\n0.31\n0.691\n0.634\n0.7468\nEstonian\nAccuracy\n0.7898\n0.6275\n0.565\nF-measure\n0.3905\n0.754\n0.6285\nGerman\nAccuracy\n0.7797\n0.6199\n0.798\nF-measure\n0.6401\n0.667\n0.6225\nHungarian\nAccuracy\n0.8146\n0.584\nF-measure\n0.6205\n0.6609\nIrish\nAccuracy\n0.7961\n0.6084\n0.549\nF-measure\n0.8444\n0.739\n0.4783\nItalian\nAccuracy\n0.7723\n0.5543\n0.761\n0.537\n0.766\nF-measure\n0.5869\n0.463\n0.529\n0.741\n0.5532\nSerbian\nAccuracy\n0.8235\n0.4143\n0.599\nF-measure\n0.7543\n0.269\n0.5715\nSlovenian\nAccuracy\n0.8429\n0.3957\n0.442\nF-measure\n0.7782\n0.268\n0.3251\nSpanish\nAccuracy\n0.8071\n0.5467\n0.786\n0.829\nF-measure\n0.8007\n0.661\n0.81\n0.541\nPortuguese\nAccuracy\n0.7314\n0.6662\n0.87\n0.933\nF-measure\n0.6401\n0.441\n0.641\n0.6374\nRussian\nAccuracy\n0.758\n0.5976\n0.606\nF-measure\n0.7729\n0.512\n0.7204\nTable 6.10: The highest results reported by the participants of the MWSA shared task (2020)\nalong with the highest results from System 1. The highest values are indicated in\nbold.\n\n6.8 conclusion and contributions\n147\n6.8\nconclusion and contributions\nIn this chapter, the monolingual word sense alignment task is deﬁned along with a\npre-existing framework for solving this called Naisc. We looked at textual similarity\nmetrics for which there are a large number of methods that are effective for estimating\nsimilarity; however, the task of distinguishing between exactly equivalent senses with\nbroader/narrower senses is still a challenging task. We then looked at non-textual\nlinking methods methods that are effective for a few kinds of dictionary linking tasks,\nespecially with large-scale knowledge graphs such as Wikidata. Furthermore, we\nexamined the constraints that can be used to ﬁnd the best overall linking between\nsenses and showed how these can be solved. Finally, a few experiments are carried\nout using the monolingual lexicographic datasets from 15 languages described in the\nprevious chapter. We ﬁrst develop a baseline system and then, model the alignment\ntask as a classiﬁcation problem and apply a knowledge graph. These experiments aim\nat classifying sense matches across dictionaries and also, prediction of the semantic\nrelationship between two given senses, namely narrower, broader, exact and related.\nA set of the experiments are based on manually-extracted features along with\na representation learning technique, RBM, and semantic relationship detection. We\ndemonstrate that the performance of classiﬁcation methods varies based on the type\nof semantic relationships due to the nature of the task but performs better than the\nbaseline. Despite the increasing popularity of deep learning methods in providing\nstate-of-the-art results in various NLP ﬁelds, we believe that evaluating the perfor-\nmance of feature-engineered approaches is an initial and essential step to reﬂect the\ndifﬁculties of the task. In the same vein, we organized a shared task on the same task\ninviting researchers to propose new ideas and insights to improve the current align-\nment results. The results indicate a better performance of the proposed approaches\nwith respect to the baseline with differences between them, achieving strong perfor-\nmance with state-of-the-art methods such as BERT.\nAs we saw in another experiment, the length of sense deﬁnition plays an impor-\ntant role in the alignment task in such a way that conciser deﬁnitions tend to be\naligned more easily. This being said, a more complete investigation is required to\nfully understand the characteristics of concise deﬁnitions, whether related to the lin-\nguistic features or the deﬁnition paradigm, that gives automatic approaches more\neffectiveness in addressing the alignment problem. We believe that the development\nof the benchmark and providing linking techniques within Naisc facilitates not only\naligning lexicographical resources, but also makes it possible to evaluate various sys-\ntems in the future as a part of the ELEXIS dictionary infrastructure.\nOne of the limitations that should be addressed is the evaluation of the models\nfor alignment of senses based on part-of-speech tags to analyze the impact of gram-\nmatical roles on the alignment task and also, differences of deﬁnitions and senses in\nthe task of semantic relation detection.\n\n\n7\nC O N C LU S I O N S\nThis thesis sheds light on the alignment of lexical semantic resources, notably dictio-\nnaries. The task of combining dictionaries from different sources is difﬁcult, espe-\ncially for the case of mapping the senses of entries, which often differ signiﬁcantly in\ngranularity and coverage. After providing a background on the language and linguis-\ntic resources that are of importance in natural language processing, such as wordnets,\ngenerative lexicons, knowledge graphs and language models, a review of the pre-\nvious efforts in aligning language resources is presented in an essentially concise\nbut systematic manner. The signiﬁcance of the alignment task to increase the inter-\noperability of resources, reduce the heterogeneity of linguistic data and facilitate the\ntask of lexicographers and language experts for creating resources and documenting\nlanguages upholds the necessity of addressing this topic.\nIn this chapter, we provide the conclusions based on the contributions that were\nmainly presented in Chapter 4, Chapter 5 and Chapter 6. In addition to the contribu-\ntions, some of the limitations of the current work are provided along with the future\ndirections paving the way for potentially more substantial advances in this realm.\n7.1\nresearch contributions\nThe main contributions of this thesis can be summarized as follows:\n7.1.1\nBenchmarking Word Sense Alignment\nChapter 5\nOne major limitation regarding previous work was with respect to the nature of the\ndata used for the WSA task. Expert-made resources, such as the Oxford English Dic-\ntionary, require much effort to be created and therefore, are not available under an\nopen-source license as collaboratively-curated ones like Wiktionary are due to copy-\nright restrictions. On the other hand, the latter resources lack domain coverage and\ndescriptive senses. To address this, we present a set of 17 datasets containing mono-\nlingual dictionaries in 15 languages, annotated with ﬁve semantic relations according\nto SKOS (Miles and Bechhofer, 2009), namely, exact, broader, narrower, related and\nnone. The annotation was carried out by language experts and lexicographers within\nthe group of ELEXIS volunteers and partners.\n149\n\n150\nconclusions\nThe main objectives of creating a benchmark for MWSA were the following:\n(A) Collect lexicographical data from chieﬂy expert-made resources, especially dic-\ntionaries. In the collecting of the data, common practices of data management\nwere also considered, particularly by specifying various types of data by their\nidentiﬁers, making them more compatible with the semantic web standards and\nthe Ontolex-Lemon ontology.\n(B) Carry out an annotation task where the micro-structure of two entries with the\nsame part-of-speech tags are aligned at sense level. The alignment is further\ncompleted with semantic annotations denoting the type of semantic relations\nthat two senses via their deﬁnitions would have. This proved to be an effective\nway to capture information regarding sense nuances and potential biases that\nthe descriptive and explanatory paradigms of sense deﬁning would impose on\nthe alignment task. Furthermore, the sense granularity between two dictionaries\nis rarely such that we would expect one-to-one mapping between the senses of\nan entry. In this respect, we followed a simple approach such as that in SKOS\nproviding different kinds of linking predicates which is described as follows:\nexact The sense are the same, for example, the deﬁnitions are simply para-\nphrases.\nbroader The sense in the ﬁrst dictionary completely covers the meaning of the\nsense in the second dictionary and is applicable to further meanings.\nnarrower The sense in the ﬁrst dictionary is entirely covered by the sense of\nthe second dictionary, which is applicable to further meanings.\nrelated There are cases when the senses may be equal but the deﬁnitions in\nboth dictionaries differ in key aspects.\nnone There is no match for these senses.\nGiven that some of the semantic relations, such as narrower and broader, are not\nsymmetric, the order of the source and target senses is important in determining\nthe semantic relation correctly. In addition, the senses within the two resources\nwhich belong to the same lemma but are not annotated with a SKOS relation,\nare considered with a ‘none’ relation.\nThe annotation was implemented by means of dynamic spreadsheets that pro-\nvided a simple but effective manner to complete the annotation. It should be\nnoted that the senses and deﬁnitions of the headwords to be annotated were\nconditioned based on part-of-speech; this means that not only the headwords\nin two dictionaries should be identical, ignoring spelling variations that are sys-\ntematically taken care of by being uniﬁed as we saw in the case of Danish in\nSection 5.3.1, but they should also be of the same morphosyntactic category.\nFigure 7.1 shows an alignment example of the entry domestication (noun, feminine)\nin the Trésor de la Langue Française Informatisé (TLFi) and Wiktionnaire – the French\n\n7.1 research contributions\n151\nWiktionary. The two major differences between these two resources, which occur of-\ntentimes across other resources, is (i) the differences of distinction of senses and (ii)\ndissimilar and sometimes conceptually different deﬁnitions for the same senses. For\ninstance, the sense of domestication as ‘taming of animals’ is mentioned as a separate\nsense to ‘action of domesticating’ in TLFi, while Wiktionnaire is limited to only one\nsense and that corresponds only to the ‘action of domesticating’ sense. On the other\nhand, ‘subjugation, enslavement (of people, human groups, ideas).’ is referring to a\nsemantically different concept than that of ‘the act of subjecting someone to house-\nwork.’, which may be considered as having a broader or narrower relation. Therefore,\ndeﬁnitions may not essentially convey the same meanings, even though they are ap-\nproximately in the same context. This is due to many reasons, among which, editorial\npreferences, lexicographer’s style, deﬁnition paradigms, lexical semantic theories and\nsemantic shifts play an important role. Figure 7.1 also shows the alignment and an-\nnotation of semantic relations carried out by the annotators1.\nnarrower\nApprivoisement des animaux.\n[taming of animals]\nbroader\nAssujettissement, asservissement\n(de personnes, de groupes\nhumains, d'idées).\n[subjugation, enslavement (of\npeople, human groups, ideas).]\nexact\nAction de domestiquer.\n[Action of domesticating.]\n(Figuré) (Plus rare) Action de soumettre\nquelqu’un aux travaux domestiques.\n[(Figurative) (Rarer) The act of subjecting\nsomeone to housework. ]\nAction de domestiquer.\n[Action of domesticating.]\nFigure 7.1: An alignment of sense deﬁnitions of domestication (noun, feminine) in the Trésor\nde la Langue Française (to the left) and Wiktionnaire (to the right). Translations are\nprovided in brackets.\nThe inter-annotator agreement scores indicate that the task is not equally challeng-\ning for all resources and all languages. This indicates that it is certainly not easy to\ndecide which relationship is to be used among word senses and how to align them.\nRegardless of the sense granularity and coverage in two resources, the deﬁnition of\nword senses, which often follows a paradigm as discussed in Section 2.2.2, creates fur-\nther challenges and nuances in meaning that make the alignment task more difﬁcult.\nHowever, this methodology was broadly effective and can simplify the development\nof machine-learning-based classiﬁers for sense alignment prediction.\nThe datasets are available in JSON, tabular and RDF formats and external keys\nsuch as meta_ID and external_ID enable future lexicographers to integrate the an-\nnotations in external resources.\nThe benchmark can be used for training models,\n1 The French dataset was not included in the experiments as it was created at the end of my Ph.D.\n\n152\nconclusions\nﬁne-tuning existing contextual embeddings like BERT (Devlin et al., 2018) and more\nimportantly, evaluation purposes.\n7.1.2\nAlignment of dictionaries at the sense level\nChapter 4 & 6\nFollowing the curation of the benchmark, we propose solutions for the automatic\nalignment of word senses. The alignment techniques are based on a variety of meth-\nods ranging from basic string similarity features to ﬁner representations using se-\nmantic similarity. Considering the literature, various components of the WSA task\nhave been matters of research previously. However, a few of the previous papers\naddress WSA as a speciﬁc task on its own in the context of dictionaries. In the same\nvein, our focus is on providing explainable observations for the task of WSA using\nmanually-extracted features and analyzing the performance of traditional machine\nlearning algorithms for word sense alignment as a classiﬁcation problem. Despite\nthe increasing popularity of deep learning methods which provide state-of-the-art\nresults in various NLP ﬁelds, we believe that evaluating the performance of feature-\nengineered approaches is an initial and essential step to reﬂect the difﬁculties of the\ntask and also, the expectations from the future approaches.\nRegarding the WSA task, the comparison of the deﬁnitions of the lexical entries\nis the most obvious and effective method for establishing similarity between senses\nin two dictionaries and is the primary method that humans would use. As such,\nit makes sense to focus our efforts on developing an artiﬁcial intelligence approach\nfor the task of estimating the similarities of deﬁnitions, which is a kind of semantic\ntextual similarity as explored in tasks at SemEval (Agirre et al., 2016b). Moreover,\nwe move beyond similarity to also predict the taxonomic type of the relationship be-\ntween senses. Our methodology in MWSA relies on the two sub-tasks of semantic\nsimilarity detection and semantic similarity induction. To this end, three main ap-\nproaches are explored. Firstly use simple text features to provide a baseline for the\ntask. Secondly, a few classiﬁcation models are created for the alignment task by fo-\ncusing on the binary, SKOS and SKOS+none classiﬁcation tasks. We also used data\naugmentation techniques based on the properties of the semantic relations to create\nmore data instances and also, applied a representation learning technique using RBM.\nWhile the ﬁrst classiﬁcation objective only predicts whether two sense deﬁnitions can\nbe aligned or not, the two other tasks can also induce the semantic relation between\nsense deﬁnitions. And ﬁnally, deep learning methods including BERT are introduced\nand the experiment results are compared.\nAs the datasets are publicly available, we carried out a shared task on the task of\nmonolingual word sense alignment across dictionaries as part of the GLOBALEX 2020\n– Linked Lexicography workshop at the 12th Language Resources and Evaluation\nConference (LREC 2020) which took place on Tuesday, May 12 2020 in Marseille\n\n7.1 research contributions\n153\n(France). The results of this shared task are also presented and compared with the\ncontributions of the thesis.\nBased on the results of various experiments, the following ﬁndings can be enu-\nmerated:\n(A) The MWSA can be effectively addressed using methods based on classiﬁcation\nand ﬁne-tuning of embeddings and also, by incorporating knowledge graphs\nlike ConceptNet (Speer et al., 2016). Although all the proposed systems outper-\nform the baseline, the performance of the proposed techniques does not essen-\ntially follow the same pattern across datasets and languages.\n(B) The alignment of sense deﬁnitions with a narrower, broader or related is more\nchallenging than exact and none. This is mainly due to the imbalance of data\nand also, the difﬁculty of the task, even for human annotators, to determine the\ntype of semantic relation.\n(C) Among the explored methods, those based on ﬁne-tuning contextual embed-\ndings like BERT perform more efﬁciently. However, this is yet to be fully an-\nalyzed given that the experiments presented in the thesis that rely on deep\nlearning only address a few languages in the benchmark. In some other cases,\nthe classiﬁcation-based techniques perform better.\n(D) In how senses are deﬁned, structural differences and dissimilarities in the con-\ntent are the major factors that determine the level of difﬁculty of an alignment\ncase. This can, for instance, be due to the presence of a hierarchical sense orga-\nnization or additional excessive descriptions in a deﬁnition, such as synonyms\nand near-synonyms along with cross-references.\nIt is worth noting that initially, we also focused on alignment approaches based\non graph analysis. To this end, we proposed the weighted bipartite b-matching al-\ngorithm in Chapter 4 to ﬁnd the optimal combination of alignments in such a way\nthat the most similar items are linked according to a few conditions. Given that this\ncontribution was made before the creation of the benchmark, the performance of this\ntechnique is reported using another dataset limited to senses from English WordNet\nand Wiktionary.\n7.1.3\nAlignment of dictionaries at the entry level\nChapter 4\nIn addition to the alignment of dictionaries at the sense level, this thesis also partially\nfocuses on the alignment of dictionaries at the entry-level. In this task, given a set of\nbilingual dictionaries, the objective is to generate new translation pairs by inducing\namong the existing ones without using any external resources that provide a direct\ntranslation between the source and the target dictionaries. Additionally, the align-\nment task should be carried out based on the senses of each entry (see Figure 4.6\nfor an example of ‘spring’ (noun)). This task is addressed mainly using graph-based\n\n154\nconclusions\nmethods that leverage the structural information to generate new translation pairs.\nTwo techniques are proposed based on paths and cycles between source and target\nwords in two dictionaries and using other dictionaries as pivots.\nOur experiments were carried out in the context of the TIAD workshops. The\nresults indicate that structural information extracted from bilingual dictionaries are\nuseful to employ graph-based methods for the translation inference task.\nTo this\nend, cycle-based and path-based approaches are suggested. The basic idea of these\nmethods relies on the transitivity relation that leads an entry in a language to an-\nother entry in another language, as in ‘book’-‘livre’ (French), ‘livre’-‘Buch’ (German),\nthen ‘book’-‘Buch’. Although these techniques are effective, they are limited to the\ntranslation pairs provided in the dictionaries and cannot deal with missing transla-\ntions, unconnected entries and highly polysemous words. This should be addressed\nas future work by incorporating external resources.\n7.1.4\nNaisc\nSection 6.3\nFrom a practical point of view, the contributions of this thesis have been integrated\ninto an existing framework and tool for creating mappings between two dictionaries,\ncalled Naisc2. Naisc’s architecture is intended as an experimental framework into\nwhich many components can be integrated. Although many of the techniques in-\ncluded in Naisc can also be used to create multilingual linking between dictionaries\nand also linking between other kinds of datasets, our focus within this thesis is on\nonly the monolingual word sense alignment task.\n7.2\nrevisiting the research questions\nRevisiting the research questions that were introduced in Section 1.3 of Chapter 1, we\ncan provide the following responses according to the contributions of the thesis:\nRQ1. Do graph-based methods improve the performance of lexicographical alignment\nsystems?\nRQ1.1 Given the structural properties of lexicographical data, it is an effective\nway to model lexical and semantic data as graphs with nodes as lexicalized\nitems, e.g. words or senses, and edges as translations or the type of se-\nmantic relation. Graph-based methods can also be ideal to set constraints\non the alignment tasks as in bijective or taxonomic alignment proposed in\nSection 4.2.\nRQ1.2 Both path-based and cycle-based techniques in graph analysis can be effec-\ntive to generate translation pairs across bilingual dictionaries. According to\n2 https://github.com/insight-centre/naisc\n\n7.2 revisiting the research questions\n155\nthe experiments, the path-based approach performs better than the cycle-\nbased one thanks to the wider range of nodes that the ﬁrst methods visit\nto calculate a more reliable conﬁdence score for translation pairs. However,\nthe algorithmic efﬁciency of these techniques hinders their employment in\nlarge datasets as they require traversing graphs. Therefore, more optimiza-\ntions are required.\nRQ2. How can the output of a monolingual word sense alignment system be evalu-\nated in a multilingual context?\nAs described in Chapter 5, a benchmark is created that contains a set of 17\ndatasets of expert-made resources in 15 languages. Although individual datasets\nin the benchmark provide monolingual data, the benchmark can be used for\nmany languages, making it a valuable resource that ﬁlls the gap regarding\nlesser-resourced languages, like Russian and Serbian, which are included in\nthe benchmark.\nRQ2.1 In the context of historical and modern dictionaries, we study the case\nof Danish and Portuguese and show that beyond differences due to or-\nthographic reforms, semantic change and semantic shift are the most im-\nportant issues when aligning lexicographical data. Different practices in\nlexicography may also be a reason that hinders the alignment task.\nRQ2.2 These datasets focus on the alignment task and the annotation of sense\ndeﬁnitions based on various semantic relations, namely exact, narrower,\nbroader, related and none. Given that the annotations are carried out by\nlexicographers and language experts, the benchmark incorporates human\nknowledge and expertise to evaluate future efforts in this ﬁeld.\nRQ3. What features in sense deﬁnitions can be used to create techniques for word\nsense alignment?\nA few techniques are proposed in Chapter 6 for automatic alignment of mono-\nlingual word senses and deﬁnitions. One of the proposed alignment systems\nuses manually-crafted features such as length ratios, semantic similarities based\non word embeddings and knowledge graphs. These features are effective to\ncapture the semantic similarity and relation of a deﬁnition pair.\nRQ3.1 Among the proposed methods of the shared task (see Section 6.7), those\nbased on ﬁne-tuned contextual embeddings such as BERT perform bet-\nter (see Table 6.10). In addition, incorporating external resources such as\nknowledge graphs are essential to determine semantic relations between\nsenses. In addition to textual features that rely on the text of the deﬁnitions,\nstructural features can be employed for the alignment task to increase the\ncoverage of the predictions and set constraints.\n\n156\nconclusions\nRQ3.2 In addition to the differences in the structure of senses in two dictionar-\nies, the content of sense deﬁnitions affects the alignment task due to addi-\ntional information such as cross-references or citations and merging vari-\nous senses together, as in synonyms and near-synonyms. We analyze the\nimpact of deﬁnition lengths in Section 6.6.3 and observe that truncating\nsense deﬁnitions improves the estimation of similarity between a deﬁni-\ntions pair and therefore, can provide better alignments.\n7.3\nlimitations and future directions\nDespite the various methods developed within this Ph.D. project and described in\nthe thesis along with the open-source lexicographical tools, particularly Naisc, that\nare developed with the ELEXIS project, there are a few limitations that would be\ncompelling to be addressed in the future. Some of the main limitations of the current\nwork are presented as follows:\n(A) The alignment task deﬁned in this thesis is limited to the following constraints:\n(a) When aligning at the sense level, only entries with the same grammatical\ncategories are aligned. Therefore, sense deﬁnitions are not aligned per se\nregardless of the lemma that they belong to.\n(b) Due to the complexity in extracting senses, we did not take lexical combina-\ntorics, such as multiword expressions, compound forms and collocations,\ninto account in the alignment process.\n(c) The alignment task is deﬁned at the monolingual level, i.e. monolingual\ndictionaries are aligned, and not at the multilingual level, i.e. no cross-\nlingual alignment is made.\n(d) Although sense deﬁnitions are the most important components of the micro-\nstructure of an entry in a dictionary, they are not the only information pro-\nvided. Therefore, other information such as usage examples, etymologies\nand cross-references could be included in the alignment task.\n(e) The alignment task is limited to the micro-structure of dictionaries and not\nwords and their senses in context as in word sense disambiguation. The\nrelation of the latter task and WSA could be explored to achieve syner-\ngies, given that word sense disambiguation has been more widely studied\naccording to the literature.\n(B) From an experimental point of view, one major limitation of the classiﬁcation-\nbased approach (see Section 6.6.2) is the usage of crafted features. We believe\nthat as a future work further techniques can be used, particularly thanks to\nthe current advances in word representations and neural networks.\nOn the\nother hand, predicting certain semantic relations, such as related, narrower and\n\n7.3 limitations and future directions\n157\nbroader, are deemed more challenging than the other relations, namely exact\nand none. One way to address this is to merge taxonomic information as in\nknowledge graphs like Wikidata with lexicographical resources like Wiktionary.\n(C) As we initially stated, in the alignment of dictionaries where there is a hierar-\nchy of senses, also known as vertical polysemy (Koskela, 2011), all senses are\nbrought together at the same level, meaning that senses with sub-senses and\nsuper-senses are all considered as independent senses. This is a simplistic but\npragmatic solution without further analyzing the task of determining how dif-\nferent levels of senses should be merged in a signiﬁcant manner to capture the\nsense meaning completely. In order to understand the impact of this “leveling”\ntechnique, we look at the experiment results of Danish, as it is the only lan-\nguage in the MWSA benchmark whose sense information was implemented in\na hierarchy. Having said that, the sense hierarchy structure can explicitly pro-\nvide information about the semantic relationship between senses and therefore\nshould preferably be considered in later experiments with the data.\nRegarding future research directions, various ﬁelds can be explored to address the\nlimitations of the current work. A few of them are proposed as follows:\n(A) Despite the efforts to use various techniques for the alignment task, ranging\nfrom graph-based methods to those based on ﬁne-tuning contextual embedding,\nthere are various other methods that are yet to be explored.\nAmong these,\nknowledge graphs as resources and techniques based on artiﬁcial intelligence\nare eminently promising to be incorporated in the alignment task.\n(B) As thoroughly studied in this thesis, creation and maintenance of lexical seman-\ntic resources is a task that requires much time, cost and energy. Except for a\nsmall proportion of languages in the world, many languages are not privileged\nenough to ﬁnancially or intellectually invest in the creation of such resources.\nTherefore, considering other languages other than richly-resourced European\nones would be a natural step ahead to increase the usage and fair processing\nof world languages, particularly in the context of translation inference. Fur-\nthermore, this can pave the way for less Anglocentric language technology and\nbring other languages into the scene.\n(C) Adopting more semantic-aware formats should not only be of importance for\ncomputational linguists but also lexicographers and those working in digital\nhumanities. The current structure of Wiktionary, for instance, relies extensively\non content and less on the structure and structural format such as Ontolex-\nLemon (McCrae et al., 2017b). As a result, processing such a valuable open-\nsource resource is a cumbersome task, except in a few efforts such as Dbnary\n(Sérasset, 2015). To promote interoperability, it is essential to organize lexical\nand semantic data in a systematic way so that retrieving and processing them\nwill be facilitated.\n\n158\nconclusions\n(D) Converting printed historical dictionaries into structured electronic forms is an\nexpensive and burdensome task.\nAs future work, it is suggested to explore\nunsupervised methods to detect sense and deﬁnition boundaries in dictionar-\nies such as ODS (see Section 6.6.3). Moreover, further methods can be created\nto automatically detect the type of the semantic relationship that may exist be-\ntween two senses, also of non-identical lemmas, and also study to which degree\nmanual markups of the meta-information in the ODS improve the method.\n(E) Further linguistically-motivated approaches can be taken to create more robust\nalignment techniques; for instance, the syntactic analysis of a deﬁnition can be\nbeneﬁcial to detect the genus and differentia in a deﬁnition, therefore, facilitating\nthe alignment task in some cases.\n(F) Among the most promising future techniques that can be used for the alignment\ntask are zero-shot classiﬁcation (Ye and Guo, 2017), ﬁne-tuning large language\nmodels and more advanced graph-based methods, such as modiﬁed adsorption\nanalysis (Talukdar and Crammer, 2009) and graph neural networks (Wu et al.,\n2020) for translation inference. Given that current contextual embeddings have\nbeen shown to be able to distinguish word senses to some extent (see Section\n2.10), it may be interesting to use the embeddings of the lemma along with the\ndeﬁnitions as a piece of extra information for the alignment task.\n(G) The MWSA task can be considered as a paraphrasis generation task (Yang et al.,\n2019) as well and can be seen from the perspective of natural text generation\n(Koncel-Kedziorski et al., 2019) too.\n(H) Practices in lexicography should be more compatible with developments in NLP\nand language technology, particularly when it comes to publishing data using\nsemantic web technologies and linguistic linked open data.\n\n\nB I B L I O G R A P H Y\nAcademia das Ciências de Lisboa. Dicionário da Língua Portuguesa Contemporânea. João\nMalaca Casteleiro (ed.). Lisboa, 2001. Academia das Ciências de Lisboa e Editorial\nVerbo.\nEneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalová, Marius Pasca, and Aitor\nSoroa. A study on similarity and relatedness using distributional and wordnet-\nbased approaches. In Proceedings of Human Language Technologies: The 2009 Annual\nConference of the North American Chapter of the Association for Computational Linguistics,\npages 19–27, 2009.\nEneko Agirre, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, and Weiwei Guo. *\nSEM 2013 shared task: Semantic textual similarity. In Second joint conference on\nlexical and computational semantics (* SEM), volume 1: proceedings of the Main conference\nand the shared task: semantic textual similarity, pages 32–43, 2013.\nEneko Agirre, Carmen Banea, Daniel Cer, Mona Diab, Aitor Gonzalez Agirre, Rada\nMihalcea, German Rigau Claramunt, and Janyce Wiebe. Semeval-2016 task 1: Se-\nmantic textual similarity, monolingual and cross-lingual evaluation. In SemEval-\n2016. 10th International Workshop on Semantic Evaluation; 2016 Jun 16-17; San Diego,\nCA. Stroudsburg (PA): ACL; 2016. p. 497-511. ACL (Association for Computational\nLinguistics), 2016a.\nEneko Agirre, Aitor Gonzalez Agirre, Inigo Lopez-Gazpio, Montserrat Maritxalar,\nGerman Rigau Claramunt, and Larraitz Uria. SemEval-2016 task 2: Interpretable\nsemantic textual similarity.\nIn SemEval-2016 Task 2: Interpretable semantic textual\nsimilarity. SemEval-2016. 10th International Workshop on Semantic Evaluation; 2016 Jun\n16-17; San Diego, CA. Stroudsburg (PA): ACL; 2016. p. 512-24. ACL (Association for\nComputational Linguistics), 2016b.\nSina Ahmadi. Attention-based encoder-decoder networks for spelling and grammati-\ncal error correction. arXiv preprint arXiv:1810.00660, 2018.\nSina Ahmadi. Hunspell for Sorani Kurdish Spell Checking and Morphological Anal-\nysis. arXiv preprint arXiv:2109.06374, 2021.\nFaez Ahmed, John P Dickerson, and Mark Fuge.\nDiverse weighted bipartite b-\nmatching. arXiv preprint arXiv:1702.07134, 2017.\n159\n\n160\nBIBLIOGRAPHY\nLaura Aina, Kristina Gulordava, and Gemma Boleda.\nPutting Words in Context:\nLSTM Language Models and Lexical Ambiguity. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics, pages 3342–3348, 2019.\nAli A Alani.\nArabic handwritten digit recognition based on restricted Boltzmann\nmachine and convolutional neural networks. Information, 8(4):142, 2017.\nMariëtta Alberts. Lexicography versus terminography. Lexikos, 11, 2001.\nPurya Aliabadi, Mohammad Sina Ahmadi, Shahin Salavati, and Kyumars Sheykh\nEsmaili.\nTowards building Kurdnet, the Kurdish wordnet.\nIn Proceedings of the\nSeventh Global Wordnet Conference, pages 1–6, 2014.\nFelipe Almeida and Geraldo Xexéo.\nWord embeddings: A survey.\narXiv preprint\narXiv:1901.09069, 2019.\nMorris Alper.\nAuto-generating bilingual dictionaries:\nResults of the TIAD-2017\nshared task baseline algorithm. In John P. McCrae, Francis Bond, Paul Buitelaar,\nPhilipp Cimiano, Thierry Declerck, Jorge Gracia, Ilan Kernerman, Elena Montiel-\nPonsoda, Noam Ordan, and Maciej Piasecki, editors, Proceedings of the LDK 2017\nWorkshops: 1st Workshop on the OntoLex Model (OntoLex-2017), Shared Task on Trans-\nlation Inference Across Dictionaries & Challenges for Wordnets co-located with 1st Confer-\nence on Language, Data and Knowledge (LDK 2017), Galway, Ireland, June 18, 2017, vol-\nume 1899 of CEUR Workshop Proceedings, pages 85–93. CEUR-WS.org, 2017a. URL\nhttp://ceur-ws.org/Vol-1899/baseline_report.pdf.\nMorris Alper.\nAuto-generating Bilingual Dictionaries: Results of the TIAD-2017\nShared Task Baseline Algorithm. In LDK Workshops, pages 85–93, 2017b.\nAsaf Amrami and Yoav Goldberg.\nTowards better substitution-based word sense\ninduction. arXiv preprint arXiv:1905.12598, 2019.\nChristophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An\nintroduction to MCMC for machine learning. Machine learning, 50(1-2):5–43, 2003.\nGrigoris Antoniou and Frank Van Harmelen.\nWeb ontology language: OWL.\nIn\nHandbook on ontologies, pages 67–92. Springer, 2004.\nJu D Apresjan. Regular polysemy. Walter de Gruyter, Berlin/New York Berlin, New\nYork, 1974.\nMihael Arcan, Daniel Torregrosa, Sina Ahmadi, and John P McCrae. Inferring trans-\nlation candidates for multilingual dictionary generation with multi-way neural ma-\nchine translation. In Proceedings of the Translation Inference Across Dictionaries Work-\nshop (TIAD 2019), 2019a.\n\nBIBLIOGRAPHY\n161\nMihael Arcan, Daniel Torregrosa, Sina Ahmadi, and John P McCrae.\nTIAD 2019\nShared Task: Leveraging knowledge graphs with neural machine translation for\nautomatic multilingual dictionary generation. Shared Task on Translation Inference\nAcross Dictionaries, 2019b.\nSanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski. A la-\ntent variable model approach to PMI-based word embeddings. Transactions of the\nAssociation for Computational Linguistics, 4:385–399, 2016.\nSimran Arora, Avner May, Jian Zhang, and Christopher Ré. Contextual embeddings:\nWhen are they worth it? In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 2650–2663, 2020.\nRon Artstein. Inter-annotator agreement. In Handbook of linguistic annotation, pages\n297–313. Springer, 2017.\nBen Athiwaratkun, Andrew Wilson, and Animashree Anandkumar. Probabilistic Fast-\nText for Multi-Sense Word Embeddings. In Proceedings of the 56th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pages 1–11,\n2018.\nBT Sue Atkins and Michael Rundell. The Oxford guide to practical lexicography. Oxford\nUniversity Press, 2008.\nJordi Atserias, Luıs Villarejo, German Rigau, Eneko Agirre, John Carroll, Bernardo\nMagnini, and Piek Vossen. The meaning multilingual central repository. In 2nd\nInternational Global Wordnet Conference, January 20-23, 2004: proceedings, pages 23–30.\nMasaryk University, 2004.\nSophie Aubin and Thierry Hamon. Improving term extraction with terminological\nresources.\nIn International Conference on Natural Language Processing (in Finland),\npages 380–387. Springer, 2006.\nLeif Azzopardi, Mark Girolami, and Malcolm Crowe. Probabilistic hyperspace ana-\nlogue to language. In Proceedings of the 28th Annual International ACM SIGIR confer-\nence on Research and development in information retrieval, pages 575–576, 2005.\nLalit R Bahl, Peter F Brown, Peter V de Souza, and Robert L Mercer. A tree-based sta-\ntistical language model for natural language speech recognition. IEEE Transactions\non Acoustics, Speech, and Signal Processing, 37(7):1001–1008, 1989.\nLenka Bajcetic and Seung-bin Yim.\nImplementation of supervised training ap-\nproaches for monolingual word sense alignment: ACDH-CH system description\nfor the MWSA shared task at GlobaLex 2020.\nIn Proceedings of the 2020 Glob-\nalex Workshop on Linked Lexicography, pages 84–91, Marseille, France, May 2020.\nEuropean Language Resources Association. ISBN 979-10-95546-46-7. URL https:\n//aclanthology.org/2020.globalex-1.14.\n\n162\nBIBLIOGRAPHY\nCollin F Baker and Christiane Fellbaum. WordNet and FrameNet as complementary\nresources for annotation. In Proceedings of the third linguistic annotation workshop\n(LAW III), pages 125–129, 2009.\nCollin F Baker, Charles J Fillmore, and John B Lowe. The Berkeley Framenet project.\nIn Proceedings of the 17th international conference on Computational linguistics-Volume\n1, pages 86–90. Association for Computational Linguistics, 1998.\nLucie Barque and François-Régis Chaumartin. Regular polysemy in WordNet. 24(2):\n5–18, 2009.\nSiamak Barzegar, Brian Davis, Manel Zarrouk, Siegfried Handschuh, and André Fre-\nitas. SemEval-11: A multi-lingual gold-standard for semantic similarity and relat-\nedness for eleven languages. In Proceedings of the Eleventh International Conference on\nLanguage Resources and Evaluation (LREC 2018), 2018.\nChristine Basta, Marta R Costa-Jussà, and Noe Casas.\nEvaluating the underlying\ngender bias in contextualized word embeddings. arXiv preprint arXiv:1904.08783,\n2019.\nKhuyagbaatar Batsuren, Amarsanaa Ganbold, Altangerel Chagnaa, and Fausto\nGiunchiglia.\nBuilding the Mongolian Wordnet.\nIn Proceedings of the 10th global\nWordNet conference, pages 238–244, 2019.\nPetr Baudiš, Jan Pichl, Tomáš Vyskoˇcil, and Jan Šediv`y. Sentence pair scoring: To-\nwards uniﬁed framework for text comprehension. arXiv preprint arXiv:1603.06127,\n2016.\nRichard Beckwith and George A Miller. Implementing a lexical network. International\nJournal of Lexicography, 3(4):302–312, 1990.\nRobert Beekes. Etymological dictionary of Greek (2 vols.). Brill, 2009.\nHenri Béjoint.\nMonosemy and the dictionary.\nIn BudaLEX’88 Proceedings. Papers\nfrom the 3rd International EURALEX Congress, Budapest: Akadémiai Kiadó, volume 13,\npage 26, 1990.\nAndrea Bellandi. Lexo: an open-source system for managing ontolex-lemon resources.\nLanguage Resources and Evaluation, 55(4):1093–1126, 2021.\nYoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Janvin. A neural\nprobabilistic language model. The journal of machine learning research, 3:1137–1155,\n2003.\nB Bennett and C Fellbaum. Linking FrameNet to the suggested upper merged ontol-\nogy. In Formal Ontology in Information Systems: Proceedings of the Fourth International\nConference (FOIS 2006), volume 150, page 289. IOS Press, 2006.\n\nBIBLIOGRAPHY\n163\nSabine Bergler. Metonymy and metaphor: Boundary cases and the role of a generative\nlexicon. In Advances in generative lexicon theory, pages 127–145. Springer, 2013.\nTim Berners-Lee. Linked data-design issues. http://www.w3.org/DesignIssues/LinkedData.html,\n2006.\nDimitris Bertsimas, Theodore Papalexopoulos, Nikolaos Trichakis, Yuchen Wang,\nRyutaro Hirose, and Parsia A Vageﬁ.\nBalancing efﬁciency and fairness in liver\ntransplant access: tradeoff curves for the assessment of organ distribution policies.\nTransplantation, 104(5):981–987, 2020.\nMichele Bevilacqua, Marco Maru, and Roberto Navigli. Generationary or:“How we\nwent beyond word sense inventories and learned to gloss”. In Proceedings of the\n2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages\n7207–7221, 2020.\nMichele Bevilacqua, Tommaso Pasini, Alessandro Raganato, Roberto Navigli, et al.\nRecent trends in word sense disambiguation: A survey. In Proceedings of the Thirti-\neth International Joint Conference on Artiﬁcial Intelligence, IJCAI-21. International Joint\nConference on Artiﬁcial Intelligence, Inc, 2021.\nChris Biemann, Stefano Faralli, Alexander Panchenko, and Simone Paolo Ponzetto. A\nframework for enriching lexical semantic resources with distributional semantics.\nNatural Language Engineering, 24(2):265–312, 2018.\nSteven Bird, Branimir Boguraev, and Don Hindle. Computational lexical semantics. Cam-\nbridge University Press, 1995.\nChristian Bizer, Jens Lehmann, Georgi Kobilarov, Sören Auer, Christian Becker,\nRichard Cyganiak, and Sebastian Hellmann. DBpedia-a crystallization point for\nthe web of data. Journal of web semantics, 7(3):154–165, 2009.\nTerra Blevins and Luke Zettlemoyer. Moving down the long tail of word sense disam-\nbiguation with gloss-informed biencoders. arXiv preprint arXiv:2005.02590, 2020.\nPiotr Blumczy´nski. Turning the tide: A critique of natural semantic metalanguage\nfrom a translation studies perspective. Translation Studies, 6(3):261–276, 2013.\nHans C Boas. From theory to practice: Frame Semantics and the design of FrameNet. Cite-\nseer, 2005.\nOlivier Bodenreider.\nThe uniﬁed medical language system (UMLS): integrating\nbiomedical terminology. Nucleic acids research, 32(suppl_1):D267–D270, 2004.\nKrzysztof Bogacki et al. Le mot, l’entité nommée et les déﬁnitions stipulatives. Biało-\nstockie Archiwum J˛ezykowe, (15):59–77, 2015.\n\n164\nBIBLIOGRAPHY\nFrancis Bond and Ryan Foster. Linking and extending an open multilingual Word-\nNet. In Proceedings of the 51st Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 1352–1362, 2013.\nFrancis Bond and Kentaro Ogura. Combining linguistic resources to create a machine-\ntractable Japanese-Malay dictionary. Language Resources and Evaluation, 42(2):127–\n136, 2008.\nFrancis Bond and Kyonghee Paik. A survey of Wordnets and their licenses. In Pro-\nceedings of the 6th Global WordNet Conference (GWC 2012), pages 64–71, 2012.\nFrancis Bond, Piek Vossen, John Philip McCrae, and Christiane Fellbaum. CILI: the\ncollaborative interlingual index. In Proceedings of the 8th Global WordNet Conference\n(GWC), pages 50–57, 2016.\nGeorgeta Bordea, Paul Buitelaar, Stefano Faralli, and Roberto Navigli.\nSemEval-\n2015 task 17: Taxonomy extraction evaluation (TExEval).\nIn Proceedings of the\n9th International Workshop on Semantic Evaluation (SemEval 2015), pages 902–910,\nDenver, Colorado, June 2015. Association for Computational Linguistics.\ndoi:\n10.18653/v1/S15-2151. URL https://www.aclweb.org/anthology/S15-2151.\nStephen P Borgatti and Martin G Everett. Network analysis of 2-mode data. Social\nnetworks, 19(3):243–269, 1997.\nJulia Bosque-Gil, Jorge Gracia, and Elena Montiel-Ponsoda. Towards a module for\nlexicography in ontolex. In John P. McCrae, Francis Bond, Paul Buitelaar, Philipp\nCimiano, Thierry Declerck, Jorge Gracia, Ilan Kernerman, Elena Montiel-Ponsoda,\nNoam Ordan, and Maciej Piasecki, editors, Proceedings of the LDK 2017 Workshops:\n1st Workshop on the OntoLex Model (OntoLex-2017), Shared Task on Translation Inference\nAcross Dictionaries & Challenges for Wordnets co-located with 1st Conference on Language,\nData and Knowledge (LDK 2017), Galway, Ireland, June 18, 2017, volume 1899 of CEUR\nWorkshop Proceedings, pages 74–84. CEUR-WS.org, 2017. URL http://ceur-ws.org/\nVol-1899/OntoLex_2017_paper_5.pdf.\nJulia Bosque-Gil, Jorge Gracia, Elena Montiel-Ponsoda, and Asunción Gómez-Pérez.\nModels to represent linguistic linked data. Natural Language Engineering, 24(6):811–\n859, 2018.\nGerlof Bouma. Normalized (pointwise) mutual information in collocation extraction.\nProceedings of GSCL, 30:31–40, 2009.\nMyriam Bouveret and Ch Fillmore.\nMatching verbo-nominal constructions in\nFrameNet with lexical Functions in MTT. In Proceedings of the Euralex, pages 297–\n308, 2008.\nJohn Bowker. The Oxford dictionary of world religions. Oxford Univ. Press, 1997.\n\nBIBLIOGRAPHY\n165\nJordan Boyd-Graber, Christiane Fellbaum, Daniel Osherson, and Robert Schapire.\nAdding dense, weighted connections to WordNet.\nIn Proceedings of the third in-\nternational WordNet conference, pages 29–36. Citeseer, 2006.\nDan Brickley. RDF vocabulary description language 1.0: RDF schema. http://www. w3.\norg/TR/rdf-schema/, 2004.\nSusan Windisch Brown, James Pustejovsky, Annie Zaenen, and Martha Palmer. In-\ntegrating generative lexicon event structures into Verbnet.\nIn Proceedings of the\nEleventh International Conference on Language Resources and Evaluation (LREC 2018),\n2018.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Pra-\nfulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\nSandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Re-\nwon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Ben-\njamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. Language Models are Few-Shot Learners. In Hugo\nLarochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-\nTien Lin, editors, Advances in Neural Information Processing Systems 33: Annual\nConference on Neural Information Processing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/\n1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.\nPaul Buitelaar. CoreLex: An ontology of systematic polysemous classes. Proceedings\nof FOIS98, International Conference on Formal Ontology in Information Systems, 1998.\nPaul Buitelaar. Reducing lexical semantic complexity with systematic polysemous\nclasses and underspeciﬁcation. In NAACL-ANLP 2000 Workshop: Syntactic and Se-\nmantic Complexity in Natural Language Processing Systems, 2000.\nPaul Buitelaar, Thierry Declerck, Anette Frank, Stefania Racioppa, Malte Kiesel,\nMichael Sintek, Ralf Engel, Massimo Romanelli, Daniel Sonntag, Berenike Loos,\net al. LingInfo: Design and applications of a model for the integration of linguis-\ntic information in ontologies. In Proceedings of the OntoLex Workshop at Language\nResources and Evaluation LREC, 2006.\nPaul Buitelaar, Philipp Cimiano, Peter Haase, and Michael Sintek. Towards linguis-\ntically grounded ontologies. In European Semantic Web Conference, pages 111–125.\nSpringer, 2009.\nAnita Burgun and Olivier Bodenreider. Comparing terms, concepts and semantic\nclasses in WordNet and the Uniﬁed Medical Language System. In WordNet and the\nUniﬁed Medical Language System. Proc NAACL Workshop, WordNet and Other Lexical\nResources: Applications, Extensions and Customizations, pages 77–82, 2001.\n\n166\nBIBLIOGRAPHY\nLynnika Butler and Heather Van Volkinburg. Fieldworks Language Explorer (FLEx).\nTechnology Review, 1(1):1, 2007.\nYuanyuan Cai, Qingchuan Zhang, Wei Lu, and Xiaoping Che. A hybrid approach\nfor measuring semantic similarity based on IC-weighted path distance in WordNet.\nJournal of Intelligent Information Systems, 51(1):23–47, 2018.\nJose Camacho-Collados and Mohammad Taher Pilehvar. Embeddings in natural lan-\nguage processing. In Proceedings of the 28th International Conference on Computational\nLinguistics: tutorial abstracts, pages 10–15, 2020.\nJose Camacho-Collados, Claudio Delli Bovi, Luis Espinosa-Anke, Sergio Oramas,\nTommaso Pasini, Enrico Santus, Vered Shwartz, Roberto Navigli, and Horacio Sag-\ngion. SemEval-2018 task 9: Hypernym discovery. In Proceedings of the 12th Inter-\nnational Workshop on Semantic Evaluation (SemEval-2018); 2018 Jun 5-6; New Orleans,\nLA. Stroudsburg (PA): ACL; 2018. p. 712–24. ACL (Association for Computational\nLinguistics), 2018.\nCaterina Caracciolo, Armando Stellato, Sachit Rajbahndari, Ahsan Morshed, Gudrun\nJohannsen, Yves Jaques, and Johannes Keizer. Thesaurus maintenance, alignment\nand publication as linked data: the AGROVOC use case. International Journal of\nMetadata, Semantics and Ontologies, 7(1):65–75, 2012.\nMiguel A Carreira-Perpinan and Geoffrey Hinton. On contrastive divergence learning.\nIn International workshop on artiﬁcial intelligence and statistics, pages 33–40. PMLR,\n2005.\nTommaso Caselli, Carlo Strapparava, Laure Vieu, and Guido Vetere.\nAligning an\nItalian WordNet with a lexicographic dictionary: Coping with limited data.\nIn\nGlobal WordNet Conference-GWC 2014, pages pp–290, 2014.\nDaniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia.\nSemEval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual\nfocused evaluation. arXiv preprint arXiv:1708.00055, 2017.\nDhivya Chandrasekaran and Vijay Mago. Evolution of semantic similarity—a survey.\nACM Computing Surveys (CSUR), 54(2):1–37, 2021.\nChih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines.\nACM Trans. Intell. Syst. Technol., 2(3):27:1–27:27, 2011. doi: 10.1145/1961189.1961199.\nURL https://doi.org/10.1145/1961189.1961199.\nTing-Yun Chang, Yang Liu, Karthik Gopalakrishnan, Behnam Hedayatnia, Pei Zhou,\nand Dilek Hakkani-Tur.\nIncorporating commonsense knowledge graph in pre-\ntrained models for social commonsense tasks. arXiv preprint arXiv:2105.05457, 2021.\n\nBIBLIOGRAPHY\n167\nValentim Charles, Hugo Manganinhas, Antoine Isaac, Nuno Freire, and Sergiu\nGordea.\nDesigning a multilingual knowledge graph as a service for cultural\nheritage–some challenges and solutions. In International Conference on Dublin Core\nand Metadata Applications, pages 29–40, 2018.\nCheng Chen, Sean Chester, Venkatesh Srinivasan, Kui Wu, and Alex Thomo. Group-\naware weighted bipartite b-matching. In Proceedings of the 25th ACM International on\nConference on Information and Knowledge Management, pages 459–468. ACM, 2016a.\nCheng Chen, Lan Zheng, Venkatesh Srinivasan, Alex Thomo, Kui Wu, and Anthony\nSukow.\nConﬂict-aware weighted bipartite b-matching and its application to e-\ncommerce. IEEE Transactions on Knowledge and Data Engineering, 28(6):1475–1488,\n2016b.\nMuhao Chen, Yingtao Tian, Mohan Yang, and Carlo Zaniolo. Multilingual knowl-\nedge graph embeddings for cross-lingual knowledge alignment.\narXiv preprint\narXiv:1611.03954, 2016c.\nChristian Chiarcos and Maria Sukhareva. OLIA–ontologies of linguistic annotation.\nSemantic Web, 6(4):379–386, 2015.\nChristian Chiarcos, Niko Schenk, and Christian Fäth. Translation inference by con-\ncept propagation. In Proceedings of the 2020 Globalex Workshop on Linked Lexicography,\npages 98–105, Marseille, France, May 2020. European Language Resources Asso-\nciation. ISBN 979-10-95546-46-7. URL https://www.aclweb.org/anthology/2020.\nglobalex-1.16.\nTimothy Chklovski and Patrick Pantel. VerbOcean: Mining the web for ﬁne-grained\nsemantic verb relations. In Proceedings of the 2004 Conference on Empirical Methods in\nNatural Language Processing, pages 33–40, 2004.\nRudi L Cilibrasi and Paul MB Vitanyi. The Google similarity distance. IEEE Transac-\ntions on knowledge and data engineering, 19(3):370–383, 2007.\nPhilipp Cimiano, Peter Haase, Matthias Herold, Matthias Mantel, and Paul Buitelaar.\nLexOnto: A model for ontology lexicons for ontology-based NLP. In Proceedings of\nthe OntoLex07 Workshop held in conjunction with ISWC’07. Citeseer, 2007.\nPhilipp Cimiano, Paul Buitelaar, John McCrae, and Michael Sintek. Lexinfo: A declar-\native model for the lexicon-ontology interface. Web Semantics: Science, Services and\nAgents on the World Wide Web, 9(1):29–51, 2011.\nPhilipp Cimiano, John P. McCrae, and Paul Buitelaar. Lexicon Model for Ontologies:\nCommunity Report. World Wide Web Consortium, 2016.\n\n168\nBIBLIOGRAPHY\nPhilipp Cimiano, Christian Chiarcos, John P. McCrae, and Jorge Gracia. Discovery\nof Language Resources, pages 263–279.\nSpringer International Publishing, Cham,\n2020a. ISBN 978-3-030-30225-2. doi: 10.1007/978-3-030-30225-2_14. URL https:\n//doi.org/10.1007/978-3-030-30225-2_14.\nPhilipp Cimiano, Christian Chiarcos, John P McCrae, and Jorge Gracia. Linguistic\nlinked data in digital humanities. In Linguistic Linked Data, pages 229–262. Springer,\n2020b.\nPhilipp Cimiano, Christian Chiarcos, John P McCrae, and Jorge Gracia. Linguistic\nLinked Data. Springer, 2020c.\nWilliam Cohen, Pradeep Ravikumar, and Stephen Fienberg. A comparison of string\nmetrics for matching names and records. In KDD workshop on data cleaning and object\nconsolidation, volume 3, pages 73–78, 2003.\nAlexis Conneau,\nGuillaume Lample,\nMarc’Aurelio Ranzato,\nLudovic Denoyer,\nand Hervé Jégou.\nWord Translation Without Parallel Data.\narXiv preprint\narXiv:1710.04087, 2017.\nPaul Cook, Jey Han Lau, Michael Rundell, Diana McCarthy, and Timothy Baldwin.\nA lexicographic appraisal of an automatic approach for detecting new word senses.\nProceedings of eLex, pages 49–65, 2013.\nFrancesco Corcoglioniti, Marco Rospocher, Alessio Palmero Aprosio, and Sara Tonelli.\nPreMOn: a lemon extension for exposing predicate models as Linked Data. In\nProceedings of the Tenth International Conference on Language Resources and Evaluation\n(LREC’16), pages 877–884, 2016.\nRute Costa. Terminology and specialised lexicography: two complementary domains.\nLexicographica, 29(1):29–42, 2013.\nBob Coyne and Owen Rambow. Meaning-Text-Theory and Lexical Frames. In Pro-\nceedings [of the] Fourth International Conference on Meaning-Text Theory [Recurso elec-\ntrónico], pages 119–128, 2009.\nMichael J Crawley. The R book. John Wiley & Sons, 2012.\nAlan Cruse. Meaning in Language: An Introduction to Semantics and Pragmatics. Oxford\nUniversity Press UK, 2010.\nVerner Dahlerup. Ordbog over det danske sprog, volume 1. Gyldendal, 1918.\nKathleen Dahlgren.\nA linguistic ontology.\nInternational journal of human-computer\nstudies, 43(5-6):809–818, 1995.\n\nBIBLIOGRAPHY\n169\nMariana Damova, Dana Dannells, Ramona Enache, Maria Mateva, and Aarne Ranta.\nNatural language interaction with semantic web knowledge bases and lod. Towards\nthe Multilingual Semantic Web, 2013.\nBharath Dandala, Rada Mihalcea, and Razvan Bunescu. Word sense disambiguation\nusing Wikipedia. In The People’s Web Meets NLP, pages 241–262. Springer, 2013.\nThierry Declerck, Asunción Gómez-Pérez, Ovidiu Vela, Zeno Gantner, and David\nManzano-Macho. Multilingual lexical semantic resources for ontology translation.\nIn Nicoletta Calzolari, Khalid Choukri, Aldo Gangemi, Bente Maegaard, Joseph\nMariani, Jan Odijk, and Daniel Tapias, editors, Proceedings of the Fifth International\nConference on Language Resources and Evaluation, LREC 2006, Genoa, Italy, May 22-28,\n2006, pages 1492–1495. European Language Resources Association (ELRA), 2006.\nURL http://www.lrec-conf.org/proceedings/lrec2006/summaries/397.html.\nThierry Declerck, Lenka Bajˇceti´c, and Melanie Siegel. Adding pronunciation informa-\ntion to wordnets. In Proceedings of the LREC 2020 Workshop on Multimodal Wordnets\n(MMW2020), pages 39–44, 2020.\nGary S Dell, Franklin Chang, and Zenzi M Grifﬁn. Connectionist models of language\nproduction: Lexical access and grammatical encoding. Cognitive Science, 23(4):517–\n542, 1999.\nDina Demner-Fushman, Wendy W Chapman, and Clement J McDonald. What can\nnatural language processing do for clinical decision support? Journal of Biomedical\nInformatics, 42(5):760–772, 2009.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBERT: Pre-\ntraining of deep bidirectional transformers for language understanding.\narXiv\npreprint arXiv:1810.04805, 2018.\nLaura Diosan, Alexandrina Rogozan, and Jean-Pierre Pécuchet. Automatic alignment\nof medical vs. general terminologies. In ESANN, pages 487–492. Citeseer, 2008.\nJohannes Dölling. Systematic polysemy. The Wiley Blackwell companion to semantics,\npages 1–27, 2020.\nNiall Ó Dónaill and Pádraig Ua Maoileoin. An Foclóir Beag. An Gum, 1991. URL\nhttps://www.teanglann.ie/en/fb/.\nKathrin Donandt and Christian Chiarcos. Translation inference through multi-lingual\nword embedding similarity. In TIAD@ LDK, pages 42–53, 2019.\nKathrin Donandt, Christian Chiarcos, and Maxim Ionov. Using machine learning for\ntranslation inference across dictionaries. In Proceedings of the LDK 2017 Workshops:\n1st Workshop on the OntoLex Model (OntoLex-2017), Shared Task on Translation Inference\nAcross Dictionaries & Challenges for Wordnets co-located with 1st Conference on Language,\n\n170\nBIBLIOGRAPHY\nData and Knowledge (LDK 2017), Galway, Ireland, June 18, 2017., pages 103–112, 2017a.\nURL http://ceur-ws.org/Vol-1899/TIAD17_paper_2.pdf.\nKathrin Donandt, Christian Chiarcos, and Maxim Ionov. Using Machine Learning for\nTranslation Inference Across Dictionaries. In LDK Workshops, pages 103–112, 2017b.\nLacramioara Dranca. Multi-strategy system for translation inference across dictionar-\nies. In Proceedings of the 2020 Globalex Workshop on Linked Lexicography, pages 111–\n115, Marseille, France, May 2020. European Language Resources Association. ISBN\n979-10-95546-46-7. URL https://www.aclweb.org/anthology/2020.globalex-1.18.\nAgnieszka Dziob, Maciej Piasecki, Marek Maziarz, Justyna Wieczorek, and Marta\nDobrowolska-Pigon. Towards Revised System of Verb Wordnet Relations for Polish.\nIn LDK Workshops, pages 174–187, 2017.\nOfer Egozi, Shaul Markovitch, and Evgeniy Gabrilovich. Concept-based information\nretrieval using explicit semantic analysis. ACM Transactions on Information Systems\n(TOIS), 29(2):1–34, 2011.\nLisa Ehrlinger and Wolfram Wöß. Towards a deﬁnition of knowledge graphs. SE-\nMANTiCS (Posters, Demos, SuCCESS), 48(1-4):2, 2016.\nJeremy Ellman.\nEurowordnet: A multilingual database with lexical semantic net-\nworks: Edited by piek vossen. kluwer academic publishers. 1998. isbn 0792352955,£\n58/$92. 179 pages. Natural Language Engineering, 9(4):427–430, 2003.\nChristopher Engström. PageRank in evolving networks and applications of graphs in natu-\nral language processing and biology. PhD thesis, Mälardalen University, 2016.\nGökhan Ercan and Olcay Taner Yıldız. Anlamver: Semantic model evaluation dataset\nfor turkish-word similarity and relatedness. In Proceedings of the 27th International\nConference on Computational Linguistics, pages 3819–3836, 2018.\nTomaz Erjavec and Darja Fiser. Building Slovene WordNet. In Proceedings of the Fifth\nInternational Conference on Language Resources and Evaluation, pages 1678–1683, 2006.\nKawin Ethayarajh. Unsupervised random walk sentence embeddings: A strong but\nsimple baseline. In Proceedings of The Third Workshop on Representation Learning for\nNLP, pages 91–100, 2018.\nKawin Ethayarajh. How contextual are contextualized word representations? com-\nparing the geometry of BERT, ELMo, and GPT-2 embeddings.\narXiv preprint\narXiv:1909.00512, 2019.\nA. P. Evgenyeva, editor. Dictionary of the Russian Language, volume 1-4. Russkiy yazyk,\n1999. URL http://feb-web.ru/feb/mas/mas-abc/default.asp.\n\nBIBLIOGRAPHY\n171\nIngrid Lossius Falkum and Agustin Vicente. Polysemy: Current perspectives and\napproaches. Lingua, 2015.\nKen Farø, Ebba Hjorth, and Kjeld Kristensen, editors.\nDen danske ordbog, bd. 1-6,\nvolume 1-6. Gyldendal, 2003. ISBN 87-02-02401-2. https://ordnet.dk/ddo_en.\nScott Farrar and D Terence Langendoen. A linguistic ontology for the semantic web.\nGLOT international, 7(3):97–100, 2003.\nScott Farrar and D Terence Langendoen. An OWL-DL implementation of Gold. In\nLinguistic Modeling of Information and Markup Languages, pages 45–66. Springer, 2010.\nScott Farrar, William D Lewis, and D Terence Langendoen. A common ontology for\nlinguistic concepts. In Proceedings of the Knowledge Technologies Conference, pages\n10–13, 2002.\nHao Fei, Yue Zhang, Yafeng Ren, and Donghong Ji.\nA span-graph neural model\nfor overlapping entity relation extraction in biomedical texts. Bioinformatics, 37(11):\n1581–1589, 2021.\nChristiane Fellbaum. WordNet. In Theory and applications of ontology: computer applica-\ntions, pages 231–243. Springer, 2010.\nCharles J Fillmore. Frame semantics. In Cognitive linguistics: Basic readings, pages\n373–400. De Gruyter Mouton, 2008.\nCharles J Fillmore, Christopher R Johnson, and Miriam RL Petruck. Background to\nFrameNet. International journal of lexicography, 16(3):235–250, 2003.\nCharles J. Fillmore, Collin F. Baker, and Hiroaki Sato. Framenet as a \"Net\". In Proceed-\nings of the Fourth International Conference on Language Resources and Evaluation, LREC\n2004, May 26-28, 2004, Lisbon, Portugal. European Language Resources Association,\n2004. URL http://www.lrec-conf.org/proceedings/lrec2004/summaries/388.htm.\nJenny Rose Finkel, Trond Grenager, and Christopher D Manning. Incorporating non-\nlocal information into information extraction systems by gibbs sampling. In Proceed-\nings of the 43rd annual meeting of the association for computational linguistics (ACL’05),\npages 363–370, 2005.\nManuel\nFiorelli,\nArmando\nStellato,\nJohn\nP\nMcCrae,\nPhilipp\nCimiano,\nand\nMaria Teresa Pazienza. Lime: the metadata module for ontolex. In European Se-\nmantic Web Conference, pages 321–336. Springer, 2015.\nAsja Fischer and Christian Igel. An introduction to restricted Boltzmann machines.\nIn Iberoamerican congress on pattern recognition, pages 14–36. Springer, 2012.\nCharles K Fisher, Aaron M Smith, and Jonathan R Walsh. Boltzmann encoded adver-\nsarial machines. arXiv preprint arXiv:1804.08682, 2018.\n\n172\nBIBLIOGRAPHY\nJerry Fodor and Ernie Lepore. The emptiness of the Lexicon: critical reﬂections on J.\nPustejovsky’s The Generative Lexicon. Meaning and the Lexicon. New York: Crowell,\n2000.\nAlexsandro Fonseca, Fatiha Sadat, and François Lareau. Lexfom: a lexical functions\nontology model. In Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon\n(CogALex-V), pages 145–155, 2016.\nMikel L Forcada, Mireia Ginestí-Rosell, Jacob Nordfalk, Jim O’Regan, Sergio Ortiz-\nRojas, Juan Antonio Pérez-Ortiz, Felipe Sánchez-Martínez, Gema Ramírez-Sánchez,\nand Francis M Tyers. Apertium: a free/open-source platform for rule-based ma-\nchine translation. Machine translation, 25(2):127–144, 2011.\nGil Francopoulo, Monte George, Nicoletta Calzolari, Monica Monachini, Nuria Bel,\nMandy Pet, and Claudia Soria. Lexical markup framework (LMF). In Proceedings\nof the Fifth International Conference on Language Resources and Evaluation (LREC’06),\nGenoa, Italy, May 2006. European Language Resources Association (ELRA). URL\nhttp://www.lrec-conf.org/proceedings/lrec2006/pdf/577_pdf.pdf.\nGreta Franzini, Andrea Peverelli, Paolo Ruffolo, Marco Passarotti, Helena Sanna,\nEdoardo Signoroni, Viviana Ventura, and Federica Zampedri.\nNunc Est Aesti-\nmandum: Towards an Evaluation of the Latin WordNet.\nIn Raffaella Bernardi,\nRoberto Navigli, and Giovanni Semeraro, editors, Proceedings of the Sixth Italian Con-\nference on Computational Linguistics, Bari, Italy, November 13-15, 2019, volume 2481\nof CEUR Workshop Proceedings. CEUR-WS.org, 2019. URL http://ceur-ws.org/Vol-\n2481/paper33.pdf.\nAlexander Fraser and Daniel Marcu. Measuring word alignment quality for statistical\nmachine translation. Computational Linguistics, 33(3):293–303, 2007.\nBo Fu, Rob Brennan, and Declan O’sullivan.\nCross-lingual ontology mapping–an\ninvestigation of the impact of machine translation. In Asian semantic web conference,\npages 1–15. Springer, 2009.\nArtyom Gadetsky, Ilya Yakubovskiy, and Dmitry Vetrov. Conditional Generators of\nWords Deﬁnitions. In Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 2: Short Papers), pages 266–271, 2018.\nPolona Gantar and Simon Krek. Slovene lexical database. In Natural language process-\ning, multilinguality, pages 72–80, 2011.\nPolona Gantar, Lut Colman, Carla Parra Escartín, and Héctor Martínez Alonso. Mul-\ntiword expressions: between lexicography and NLP. International Journal of Lexicog-\nraphy, 32(2):138–162, 2019.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of\nsentence embeddings. arXiv preprint arXiv:2104.08821, 2021.\n\nBIBLIOGRAPHY\n173\nMarcos Garcia, Marcos García-Salido, and Miguel A Alonso. Exploring cross-lingual\nword embeddings for the inference of bilingual dictionaries. In TIAD@ LDK, pages\n32–41, 2019.\nMerrill F Garrett. Processes in language production. Linguistics: the Cambridge survey,\n3:69–96, 1989.\nDirk Geeraerts.\nVagueness’s puzzles, polysemy’s vagaries.\nWalter de Gruyter,\nBerlin/New York Berlin, New York, 1993.\nDirk Geeraerts. Theories of lexical semantics. Oxford University Press, 2010.\nR Georg, O Schonefeld, T Trippel, and A Witt. Sustainability of linguistic resources re-\nvisited. In Proceedings of the International Symposium on XML for the Long Haul: Issues\nin the Long-term Preservation of XML. Rockville, Maryland, USA: Mulberry Technologies,\nInc. (last visited October 11, 2021), 2010.\nDaniela Gerz, Ivan Vuli´c, Felix Hill, Roi Reichart, and Anna Korhonen. Simverb-3500:\nA large-scale evaluation set of verb similarity. arXiv preprint arXiv:1608.00869, 2016.\nLuke Gessler and Nathan Schneider. BERT Has Uncommon Sense: Similarity Rank-\ning for Word Sense BERTology. arXiv preprint arXiv:2109.09780, 2021.\nAbbas Ghaddar and Philippe Langlais. Transforming wikipedia into a large-scale ﬁne-\ngrained entity type corpus. In Proceedings of the Eleventh International Conference on\nLanguage Resources and Evaluation (LREC 2018), 2018.\nGaëtanelle Gilquin. Taking a new look at lexical networks. Lexis. Journal in English\nLexicology, (1), 2008.\nNataša Gliha Komac, Nataša Jakop, Janoš Ježovnik, Boris Kern, Simona Klemenˇciˇc,\nDomen Krvina, Nina Ledinek, Matej Meterc, Mija Michelizza, Matic Pavliˇc, et al.\neSSKJ: Dictionary of the Slovenian Standard Language. ZRC SAZU, 3rd edition, 2016.\nCliff Goddard. Polysemy: A problem of deﬁnition. Polysemy: Theoretical and computa-\ntional approaches, pages 129–151, 2000.\nCliff Goddard. Natural semantic metalanguage: The state of the art. Cross-linguistic\nsemantics, pages 1–34, 2008.\nCliff Goddard. Semantic molecules and semantic complexity:(with special reference\nto “environmental” molecules). Review of Cognitive Linguistics. Published under the\nauspices of the Spanish Cognitive Linguistics Association, 8(1):123–155, 2010.\nCliff Goddard and Anna Wierzbicka.\nMeaning and universal grammar: Theory and\nempirical ﬁndings, volume 1. John Benjamins Publishing, 2002.\n\n174\nBIBLIOGRAPHY\nCliff Goddard and Anna Wierzbicka.\nWords and meanings: Lexical semantics across\ndomains, languages, and cultures. OUP Oxford, 2013.\nCliff Goddard and Anna Wierzbicka. Semantic ﬁeldwork and lexical universals. Stud-\nies in Language. International Journal sponsored by the Foundation “Foundations of Lan-\nguage”, 38(1):80–127, 2014.\nShashwat Goel, Jorge Gracia, and Mikel Lorenzo Forcada. Bilingual dictionary gen-\neration and enrichment via graph exploration.\nthe Semantic Web Journal, 2021.\npreprint under review available at http://www.semantic-web-journal.net/content/\nbilingual-dictionary-generation-and-enrichment-graph-exploration.\nWael H Gomaa, Aly A Fahmy, et al. A survey of text similarity approaches. Interna-\ntional Journal of Computer Applications, 68(13):13–18, 2013.\nHugo Gonçalo Oliveira. A survey on portuguese lexical knowledge bases: Contents,\ncomparison and combination. Information, 9(2):34, 2018.\nJorge Gracia. Multilingual dictionaries and the web of data. Kernerman Dictionary\nNews, 23:1–4, 2015.\nJorge Gracia, Marta Villegas, Asuncion Gomez-Perez, and Nuria Bel. The Apertium\nbilingual dictionaries on the web of data. Semantic Web, 9(2):231–240, 2018.\nJorge Gracia, Besim Kabashi, Ilan Kernerman, Marta Lanau-Coronas, and Dorielle\nLonke. Results of the Translation Inference Across Dictionaries 2019 Shared Task.\nIn TIAD@ Language Data Knowledge conference, pages 1–12, 2019.\nEdouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, and Tomas\nMikolov. Learning word vectors for 157 languages. In Proceedings of the Interna-\ntional Conference on Language Resources and Evaluation (LREC 2018), 2018.\nJože Gregoriˇc. Kostelski slovar. Založba ZRC, 2014.\nJane Grimshaw. Argument structure. the MIT Press, 1990.\nMaurice Gross. Lexicon-grammar and the syntactic analysis of french. In International\nConference on Computational Linguistics (COLING), pages 275–282, 1984.\nNicola Guarino. Ontology and terminology: how can formal ontology help concept\nmodeling and terminology.\nIn EAFT-NordTerm Workshop on Terminology, Concept\nModeling and Ontology, 2006.\nNicola Guarino and Pierdaniele Giaretta. Ontologies and knowledge bases. Towards\nvery large knowledge bases, pages 1–2, 1995.\nValérie Guérin and Sébastien Lacrampe. Lexique pro. Technology Review, 1(2):2, 2007.\n\nBIBLIOGRAPHY\n175\nTao Gui, Yicheng Zou, Qi Zhang, Minlong Peng, Jinlan Fu, Zhongyu Wei, and Xuan-\nJing Huang. A lexicon-based graph neural network for Chinese NER. In Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\n1040–1050, 2019.\nIryna Gurevych, Judith Eckle-Kohler, Silvana Hartmann, Michael Matuschek, Chris-\ntian M Meyer, and Christian Wirth. Uby: A large-scale uniﬁed lexical-semantic\nresource based on LMF. In Proceedings of the 13th Conference of the European Chapter\nof the Association for Computational Linguistics, pages 580–590. Association for Com-\nputational Linguistics, 2012.\nIryna Gurevych, Judith Eckle-Kohler, and Michael Matuschek. Linked lexical knowl-\nedge bases: Foundations and applications. Synthesis Lectures on Human Language\nTechnologies, 9(3):1–146, 2016.\nAbdullah Hamid, Nasrullah Shiekh, Naina Said, Kashif Ahmad, Asma Gul, Laiq\nHassan, and Ala Al-Fuqaha.\nFake news detection in social media using graph\nneural networks and NLP Techniques:\nA COVID-19 use-case.\narXiv preprint\narXiv:2012.07517, 2020.\nBirgit Hamp and Helmut Feldweg. Germanet-a lexical-semantic net for German. In\nAutomatic information extraction and building of lexical semantic resources for NLP appli-\ncations, 1997.\nPatrick Hanks.\nDeﬁnition.\nIn The Oxford Handbook of Lexicography, pages 90–122.\nOxford University Press Oxford, 2016.\nValérie Hanoka and Benoît Sagot.\nWordnet creation and extension made simple:\nA multilingual lexicon-based approach using wiki resources. In LREC 2012: 8th\ninternational conference on Language Resources and Evaluation, page 6, 2012.\nSilvana Hartmann and Iryna Gurevych. FrameNet on the Way to Babel: Creating a\nBilingual FrameNet Using Wiktionary as Interlingual Connection. In Proceedings of\nthe 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, 4-9\nAugust 2013, Soﬁa, Bulgaria, Volume 1: Long Papers, pages 1363–1373. The Association\nfor Computer Linguistics, 2013. URL https://aclanthology.org/P13-1134/.\nAndrew F Hayes and Klaus Krippendorff. Answering the call for a standard reliability\nmeasure for coding data. Communication methods and measures, 1(1):77–89, 2007.\nLarry Heck and Hongzhao Huang. Deep learning of knowledge graph embeddings\nfor semantic parsing of Twitter dialogs. In 2014 IEEE Global Conference on Signal and\nInformation Processing (GlobalSIP), pages 597–601. IEEE, 2014.\n\n176\nBIBLIOGRAPHY\nHunter Heidenreich and Jake Williams. Latent semantic network induction in the\ncontext of linked example senses. In Proceedings of the 5th Workshop on Noisy User-\ngenerated Text (W-NUT 2019), pages 170–180, 2019.\nVerena Henrich, Erhard Hinrichs, and Tatiana Vodolazova.\nSemi-automatic exten-\nsion of GermaNet with sense deﬁnitions from Wiktionary. In Proceedings of the 5th\nLanguage and Technology Conference (LTC 2011), pages 126–130, 2011.\nVerena Henrich, Erhard W Hinrichs, and Klaus Suttner. Automatically linking Ger-\nmaNet to Wikipedia for harvesting corpus examples for Germanet senses. JLCL, 27\n(1):1–19, 2012.\nVerena Henrich, Erhard Hinrichs, and Reinhild Barkey.\nAligning word senses in\nGermaNet and the DWDS dictionary of the German language. In Proceedings of the\nSeventh Global Wordnet Conference, pages 63–70, 2014.\nPatrick Henry and Christian Bassac. A toolkit for a generative lexicon. arXiv preprint\narXiv:0805.2537, 2008.\nFelix Hill, Roi Reichart, and Anna Korhonen. Simlex-999: Evaluating semantic models\nwith (genuine) similarity estimation. Computational Linguistics, 41(4):665–695, 2015.\nFelix Hill, Kyunghyun Cho, Anna Korhonen, and Yoshua Bengio.\nLearning to\nunderstand phrases by embedding the dictionary.\nTransactions of the Association\nfor Computational Linguistics, 4:17–30, 2016.\ndoi:\n10.1162/tacl_a_00080.\nURL\nhttps://aclanthology.org/Q16-1002.\nGeoffrey E Hinton. Deep belief networks. Scholarpedia, 4(5):5947, 2009.\nGeoffrey E Hinton. A practical guide to training restricted Boltzmann machines. In\nNeural networks: Tricks of the trade, pages 599–619. Springer, 2012.\nGraeme Hirst. Ontology and the lexicon. In Handbook on ontologies, pages 269–292.\nSpringer, 2009.\nTin Kam Ho. Random decision forests. In Proceedings of 3rd international conference on\ndocument analysis and recognition, volume 1, pages 278–282. IEEE, 1995.\nSepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computa-\ntion, 9(8):1735–1780, 1997.\nThomas Hofmann. Probabilistic latent semantic indexing. In Proceedings of the 22nd\nannual international ACM SIGIR conference on Research and development in information\nretrieval, pages 50–57, 1999.\nAidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard de Melo,\nClaudio Gutierrez, Sabrina Kirrane, José Emilio Labra Gayo, Roberto Navigli, Se-\nbastian Neumaier, et al. Knowledge graphs. Synthesis Lectures on Data, Semantics,\nand Knowledge, 12(2):1–257, 2021.\n\nBIBLIOGRAPHY\n177\nJohn J Hopﬁeld.\nNeural networks and physical systems with emergent collective\ncomputational abilities. Proceedings of the national academy of sciences, 79(8):2554–\n2558, 1982.\nJingshan Huang, Jiangbo Dang, Michael N Huhns, and W Jim Zheng. Use artiﬁcial\nneural network to align biological ontologies. BMC genomics, 9(2):1–12, 2008.\nThad Hughes and Daniel Ramage. Lexical semantic relatedness with random graph\nwalks. In Proceedings of the 2007 joint conference on empirical methods in natural lan-\nguage processing and computational natural language learning (EMNLP-CoNLL), pages\n581–589, 2007.\nNiall Hurley and Scott Rickard. Comparing measures of sparsity. IEEE Transactions\non Information Theory, 55(10):4723–4741, 2009.\nRamon Ferrer i Cancho and Richard V Solé. The small world of human language.\nProceedings of the Royal Society of London B: Biological Sciences, 268(1482):2261–2265,\n2001.\nIgnacio Iacobacci, Mohammad Taher Pilehvar, and Roberto Navigli.\nSensembed:\nLearning sense embeddings for word and relational similarity. In Proceedings of\nthe 53rd Annual Meeting of the Association for Computational Linguistics and the 7th\nInternational Joint Conference on Natural Language Processing (Volume 1: Long Papers),\npages 95–105, 2015.\nHitoshi Isahara, Francis Bond, Kiyotaka Uchimoto, Masao Utiyama, and Kyoko Kan-\nzaki. Development of the Japanese WordNet. In Language Resources and Evaluation\nLREC, 2008.\nAminul Islam and Diana Inkpen. Second order co-occurrence PMI for determining\nthe semantic similarity of words. In Proceedings of the Fifth International Conference\non Language Resources and Evaluation (LREC’06), 2006.\nAminul Islam and Diana Inkpen. Semantic text similarity using corpus-based word\nsimilarity and string similarity. ACM Transactions on Knowledge Discovery from Data\n(TKDD), 2(2):1–25, 2008.\nMd Monjurul Islam and ASM Latiful Hoque. Automated essay scoring using general-\nized latent semantic analysis. In 2010 13th International Conference on Computer and\nInformation Technology (ICCIT), pages 358–363. IEEE, 2010.\nVarga István and Yokoyama Shoichi.\nBilingual dictionary generation for low-\nresourced language pairs. In Proceedings of the 2009 Conference on Empirical Methods\nin Natural Language Processing: Volume 2, pages 862–870. Association for Computa-\ntional Linguistics, 2009.\n\n178\nBIBLIOGRAPHY\nNavdeep Jaitly and Geoffrey Hinton.\nLearning a better representation of speech\nsoundwaves using restricted Boltzmann machines. In 2011 IEEE International Con-\nference on Acoustics, Speech and Signal Processing (ICASSP), pages 5884–5887. IEEE,\n2011.\nMatthew A Jaro. Advances in record-linkage methodology as applied to matching\nthe 1985 census of Tampa, Florida. Journal of the American Statistical Association, 84\n(406):414–420, 1989.\nMustafa Jarrar.\nThe Arabic ontology–an Arabic wordnet with ontologically clean\ncontent. Applied ontology, (Preprint):1–26, 2021.\nElisabetta Ježek. The lexicon: An introduction. Oxford University Press, 2016.\nShaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey\non knowledge graphs: Representation, acquisition, and applications. IEEE Transac-\ntions on Neural Networks and Learning Systems, 2021.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin\nBang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural lan-\nguage generation. arXiv preprint arXiv:2202.03629, 2022.\nYuncheng Jiang, Xiaopei Zhang, Yong Tang, and Ruihua Nie.\nFeature-based ap-\nproaches to semantic similarity assessment of concepts using Wikipedia. Informa-\ntion Processing & Management, 51(3):215–234, 2015.\nErnesto Jiménez-Ruiz and Bernardo Cuenca Grau. Logmap: Logic-based and scal-\nable ontology matching. In International Semantic Web Conference, pages 273–288.\nSpringer, 2011.\nHai Jin, Yi Luo, Chenjing Gao, Xunzhu Tang, and Pingpeng Yuan. ComQA: Question\nanswering over knowledge base via semantic matching. IEEE Access, 7:75235–75246,\n2019.\nDavid Jurgens, Mohammad Taher Pilehvar, and Roberto Navigli. SemEval-2014 Task\n3: Cross-Level Semantic Similarity. In SemEval@ COLING, pages 17–26, 2014.\nHiroyuki Kaji and Toshiko Aizono. Extracting word correspondences from bilingual\ncorpora based on word co-occurrences information. In Proceedings of the 16th con-\nference on Computational linguistics-Volume 1, pages 23–28. Association for Computa-\ntional Linguistics, 1996.\nHiroyuki Kaji, Shin’ichi Tamamura, and Dashtseren Erdenebat. Automatic Construc-\ntion of a Japanese-Chinese Dictionary via English. In Proceedings of the Sixth In-\nternational Conference on Language Resources and Evaluation (LREC’08), Marrakech,\nMorocco, 2008. European Language Resources Association (ELRA).\n\nBIBLIOGRAPHY\n179\nJelena Kallas, Maria Tuulik, and Margit Langemets. The basic Estonian dictionary:\nthe ﬁrst monolingual l2 learner’s dictionary of Estonian. In Proceedings of the XVI\nEuralex Congress, 2014.\nMarc Kemps-Snijders, Menzo Windhouwer, Peter Wittenburg, and Sue Ellen Wright.\nIsocat: Corralling data categories in the wild.\nIn 6th International Conference on\nLanguage Resources and Evaluation (LREC 2008), 2008.\nIlan Kernerman, Simon Krek, John P. McCrae, Jorge Gracia, Sina Ahmadi, and Besim\nKabashi, editors. Proceedings of the 2020 Globalex Workshop on Linked Lexicography,\nMarseille, France, May 2020a. European Language Resources Association. ISBN\n979-10-95546-46-7. URL https://www.aclweb.org/anthology/2020.globalex-1.0.\nIlan Kernerman, Simon Krek, John P. McCrae, Jorge Gracia, Sina Ahmadi, and Besim\nKabashi, editors. Globalex Workshop on Linked Lexicography, Language Resources and\nEvaluation LREC 2020, France, 2020b.\nFahad\nKhan,\nChristian\nChiarcos,\nThierry\nDeclerck,\nDaniela\nGifu,\nElena\nGonzález-Blanco\nGarcía,\nJorge\nGracia,\nMax\nIonov,\nPenny\nLabropoulou,\nFrancesco\nMambrini,\nJohn\nMcCrae,\nÉmilie\nPagé-Perron,\nMarco\nPassarotti,\nSalvador\nRos,\nand\nCiprian-Octavian\nTruica.\nWhen\nLinguistics\nMeets\nWeb Technologies. Recent advances in Modelling Linguistic Linked Open\nData.\nhttp://www.semantic-web-journal.net/content/when-linguistics-meets-\nweb-technologies-recent-advances-modelling-linguistic-linked-open-0, 2021.\nAc-\ncessed on 09.10.2021.\nMeriem Ali Khoudja, Messaouda Fareh, and Haﬁda Bouarfa. Ontology matching\nusing neural networks: survey and analysis.\nIn 2018 international conference on\napplied smart systems (ICASS), pages 1–6. IEEE, 2018.\nDouwe Kiela, Changhan Wang, and Kyunghyun Cho. Dynamic meta-embeddings\nfor improved sentence representations. arXiv preprint arXiv:1804.07983, 2018.\nAdam Kilgarriff. Dictionary word sense distinctions: An enquiry into their nature.\nComputers and the Humanities, 26(5/6):365–387, 1992a. ISSN 00104817. URL http:\n//www.jstor.org/stable/30204631.\nAdam Kilgarriff. Dictionary word sense distinctions: An enquiry into their nature.\nComputers and the Humanities, 26(5):365–387, 1992b.\nAdam Kilgarriff. I don’t believe in word senses. Computers and the Humanities, 31(2):\n91–113, 1997.\nPaul R. Kingsbury and Martha Palmer.\nFrom TreeBank to PropBank.\nIn Proceed-\nings of the Third International Conference on Language Resources and Evaluation, LREC\n\n180\nBIBLIOGRAPHY\n2002, May 29-31, 2002, Las Palmas, Canary Islands, Spain. European Language Re-\nsources Association, 2002. URL http://www.lrec-conf.org/proceedings/lrec2002/\nsumarios/283.htm.\nKarin Kipper, Anna Korhonen, Neville Ryant, and Martha Palmer. Extending VerbNet\nwith Novel Verb Classes. In Nicoletta Calzolari, Khalid Choukri, Aldo Gangemi,\nBente Maegaard, Joseph Mariani, Jan Odijk, and Daniel Tapias, editors, Proceed-\nings of the Fifth International Conference on Language Resources and Evaluation, LREC\n2006, Genoa, Italy, May 22-28, 2006, pages 1027–1032. European Language Resources\nAssociation (ELRA), 2006. URL http://www.lrec-conf.org/proceedings/lrec2006/\nsummaries/468.html.\nWolfgang Klein and Alexander Geyken.\nDas digitale Wörterbuch der deutschen\nSprache (DWDS). In Lexicographica: International annual for lexicography, pages 79–96.\nDe Gruyter, 2010.\nEkaterini Klepousniotou and Shari R Baum. Disambiguating the ambiguity advan-\ntage effect in word recognition: An advantage for polysemous but not homony-\nmous words. Journal of Neurolinguistics, 20(1):1–24, 2007.\nBettina Klimek and Martin Brümmer.\nEnhancing lexicography with semantic lan-\nguage databases. Kernerman Dictionary News, 23:5–10, 2015.\nBettina Klimek, John P McCrae, Julia Bosque-Gil, Maxim Ionov, James K Tauber, and\nChristian Chiarcos. Challenges for the representation of morphology in ontology\nlexicons. Proceedings of eLex, pages 570–591, 2019.\nKevin Knight and Steve K. Luk. Building a large-scale knowledge base for machine\ntranslation. In Barbara Hayes-Roth and Richard E. Korf, editors, Proceedings of the\n12th National Conference on Artiﬁcial Intelligence, Seattle, WA, USA, July 31 - August\n4, 1994, Volume 1, pages 773–778. AAAI Press / The MIT Press, 1994. URL http:\n//www.aaai.org/Library/AAAI/1994/aaai94-118.php.\nPeter Kolb. Disco: A multilingual database of distributionally similar words. Proceed-\nings of KONVENS-2008, Berlin, 156, 2008.\nOlga Kolesnikova. Automatic detection of lexical functions in context. Computación y\nsistemas, 24(3), 2020.\nRik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, and Hannaneh Ha-\njishirzi. Text generation from knowledge graphs with graph transformers. arXiv\npreprint arXiv:1904.02342, 2019.\nAnu Koskela. Metonymy, category broadening and narrowing, and vertical polysemy.\nDeﬁning Metonymy in Cognitive Linguistics: Towards a Consensus View. Amsterdam:\nJohn Benjamins, pages 125–146, 2011.\n\nBIBLIOGRAPHY\n181\nAnu Koskela.\nInclusion, contrast and polysemy in dictionaries: The relationship\nbetween theory, language use and lexicographic practice. Research in Language, 12\n(4):319–340, 2014.\nJanina Kotarbinska. On ostensive deﬁnitions. Philosophy of Science, 27(1):1–22, 1960.\nISSN 00318248, 1539767X. URL http://www.jstor.org/stable/185302.\nGang Kou and Yi Peng. An application of latent semantic analysis for text catego-\nrization. International Journal of Computers Communications & Control, 10(3):357–369,\n2015.\nKlaus Krippendorff. Computing Krippendorff’s alpha-reliability. Annenberg School\nfor Communication Departmental Papers. Philadelphia, 2011. URL http://repository.\nupenn.edu/cgi/viewcontent.cgi?article=1043&context=asc_papers.\nRobert Krovetz and W Bruce Croft.\nWord sense disambiguation using machine-\nreadable dictionaries.\nIn Proceedings of the 12th annual international ACM SIGIR\nconference on Research and development in information retrieval, pages 127–136, 1989.\nCvetana Krstev, Gordana Palovi´c-Lažeti´c, Duško Vitas, and Ivan Obradovi´c. Using\ntextual and lexical resources in developing Serbian Wordnet. SCIENCE AND TECH-\nNOLOGY, 7(1-2):147–161, 2004.\nMarek Kubis. A semantic similarity measurement tool for wordnet-like databases. In\nLanguage and Technology Conference, pages 155–168. Springer, 2015.\nHarold W Kuhn. The Hungarian method for the assignment problem. Naval research\nlogistics quarterly, 2(1-2):83–97, 1955.\nMalhar Kulkarni, Chaitali Dangarikar, Irawati Kulkarni, Abhishek Nanda, and Push-\npak Bhattacharyya. Introducing Sanskrit Wordnet. In Proceedings on the 5th global\nwordnet conference (GWC 2010), Narosa, Mumbai, pages 287–294, 2010.\nOi Yee Kwong. Aligning WordNet with additional lexical resources. Usage of WordNet\nin Natural Language Processing Systems, 1998.\nMathieu Lafourcade. Making people play for Lexical Acquisition with the JeuxDe-\nMots prototype. In SNLP’07: 7th international symposium on natural language process-\ning, page 7, 2007.\nPatrick Lambrix and He Tan. Sambo—a system for aligning and merging biomedical\nontologies. Journal of Web Semantics, 4(3):196–206, 2006.\nMarion Lamé, Perrine Pittet, Federico Ponchio, Béatrice Markhoff, and Emilio San-\nﬁlippo. Heterotoki: non-structured and heterogeneous terminology alignment for\nDigital Humanities data producers. In Open Data and Ontologies for Cultural Heritage,\n2019.\n\n182\nBIBLIOGRAPHY\nWuwei Lan and Wei Xu. Neural network models for paraphrase identiﬁcation, se-\nmantic textual similarity, natural language inference, and question answering. In\nProceedings of the 27th International Conference on Computational Linguistics, pages\n3890–3902, 2018.\nMarta Lanau-Coronas and Jorge Gracia. Graph exploration and cross-lingual word\nembeddings for translation inference across dictionaries. In Proceedings of the 2020\nGlobalex Workshop on Linked Lexicography, pages 106–110, Marseille, France, May\n2020. European Language Resources Association. ISBN 979-10-95546-46-7. URL\nhttps://www.aclweb.org/anthology/2020.globalex-1.17.\nEric Laporte. Dictionaries for language processing. readability and organization of\ninformation. PPGEL/UFES, 2013.\nFrançois Lareau, Mark Dras, Benjamin Börschinger, Myfany Turpin, Miriam Butt, and\nTracy Holloway King. Implementing lexical functions in XLE. Proceedings of LFG12,\npages 362–382, 2012.\nMatthieu Latapy, Clémence Magnien, and Nathalie Del Vecchio. Basic notions for the\nanalysis of large two-mode networks. Social networks, 30(1):31–48, 2008.\nJey Han Lau, Paul Cook, Diana McCarthy, Spandana Gella, and Timothy Baldwin.\nLearning word sense distributions, detecting unattested senses and identifying\nnovel senses using topic models. In Proceedings of the 52nd Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers), pages 259–270, 2014.\nGregory F Lawler and Vlada Limic. Random walk: a modern introduction, volume 123.\nCambridge University Press, 2010.\nFabrice Le Fessant, Sidath Handurukande, A-M Kermarrec, and Laurent Massoulié.\nClustering in peer-to-peer ﬁle sharing workloads. In International Workshop on Peer-\nto-Peer Systems, pages 217–226. Springer, 2004.\nClaudia Leacock and Martin Chodorow. Combining local context and WordNet sim-\nilarity for word sense identiﬁcation. WordNet: An electronic lexical database, 49(2):\n265–283, 1998.\nChristian Lehmann.\nLexicography.\nhttps://www.christianlehmann.eu/ling/ling_\nmeth/ling_description/lexicography/index.html, 2020. Accessed on 09.10.2021.\nAlessandro Lenci, Nuria Bel, Federica Busa, Nicoletta Calzolari, Elisabetta Gola, Mon-\nica Monachini, Antoine Ogonowski, Ivonne Peters, Wim Peters, Nilda Ruimy, et al.\nSIMPLE: A general framework for the development of multilingual lexicons. Inter-\nnational Journal of Lexicography, 13(4):249–263, 2000.\n\nBIBLIOGRAPHY\n183\nMichael Lesk. Automatic sense disambiguation using machine readable dictionaries:\nhow to tell a pine cone from an ice cream cone. In Proceedings of the 5th annual\ninternational conference on Systems documentation, pages 24–26, 1986.\nTatiana Lesnikova. NLP for interlinking multilingual LOD. In Proc. ISWC Doctoral\nconsortium, pages 32–39. No commercial editor., 2013.\nTatiana Lesnikova, Jérôme David, and Jérôme Euzenat.\nCross-lingual RDF the-\nsauri interlinking. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Sara\nGoggi, Marko Grobelnik, Bente Maegaard, Joseph Mariani, Hélène Mazo, Asunción\nMoreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Tenth Interna-\ntional Conference on Language Resources and Evaluation LREC 2016, Portorož, Slovenia,\nMay 23-28, 2016. European Language Resources Association (ELRA), 2016. URL\nhttp://www.lrec-conf.org/proceedings/lrec2016/summaries/1220.html.\nVladimir I Levenshtein et al. Binary codes capable of correcting deletions, insertions,\nand reversals. In Soviet physics doklady, volume 10, pages 707–710. Soviet Union,\n1966.\nYoav Levine, Barak Lenz, Or Dagan, Ori Ram, Dan Padnos, Or Sharir, Shai Shalev-\nShwartz, Amnon Shashua, and Yoav Shoham. SenseBERT: Driving Some Sense into\nBERT. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, pages 4656–4667, 2020.\nRobert Lew. How can we make electronic dictionaries more effective? Oxford Uni-\nversity Press, 2012.\nRobert Lew. Identifying, ordering and deﬁning senses. pages 284–302, 2013.\nM.C. L’Homme. Lexical Semantics for Terminology: An introduction. Terminology and\nLexicography Research and Practice. John Benjamins Publishing Company, 2020.\nISBN 9789027261786. URL https://books.google.ie/books?id=jdbHDwAAQBAJ.\nYuhua Li, Zuhair A Bandar, and David McLean. An approach for measuring semantic\nsimilarity between words using multiple information sources. IEEE Transactions on\nknowledge and data engineering, 15(4):871–882, 2003.\nYuhua Li, David McLean, Zuhair A Bandar, James D O’Shea, and Keeley Crockett.\nSentence similarity based on semantic nets and corpus statistics. IEEE transactions\non knowledge and data engineering, 18(8):1138–1150, 2006.\nFeiyu Lin and Kurt Sandkuhl. A survey of exploiting wordnet in ontology matching.\nIn IFIP International Conference on Artiﬁcial Intelligence in Theory and Practice, pages\n341–350. Springer, 2008.\n\n184\nBIBLIOGRAPHY\nZheng Lin, Songbo Tan, Yue Liu, Xueqi Cheng, and Xueke Xu. Cross-language opin-\nion lexicon extraction using mutual-reinforcement label propagation. PloS one, 8\n(11):e79294, 2013.\nXiang Ling, Lingfei Wu, Chunming Wu, and Shouling Ji. Graph neural networks:\nGraph matching. In Graph Neural Networks: Foundations, Frontiers, and Applications,\npages 277–295. Springer, 2022.\nXiang Liu, Torsten Suel, and Nasir Memon.\nA robust model for paper reviewer\nassignment. In Proceedings of the 8th ACM Conference on Recommender systems, pages\n25–32, 2014.\nYang Liu, Zhiyuan Liu, Tat-Seng Chua, and Maosong Sun. Topical word embeddings.\nIn Twenty-ninth AAAI conference on artiﬁcial intelligence, 2015.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer\nLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly\noptimized BERT pretraining approach.\nCoRR, abs/1907.11692, 2019.\nURL http:\n//arxiv.org/abs/1907.11692.\nPeter Lofgren, Siddhartha Banerjee, Ashish Goel, and Seshadhri Comandur. FAST-\nPPR: scaling personalized pagerank estimation for large graphs. In Sofus A. Mac-\nskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and Rayid Ghani, editors, The\n20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\nKDD ’14, New York, NY, USA - August 24 - 27, 2014, pages 1436–1445. ACM, 2014.\nRobert L Logan IV, Nelson F Liu, Matthew E Peters, Matt Gardner, and Sameer Singh.\nBarack’s wife Hillary: Using knowledge-graphs for fact-aware language modeling.\narXiv preprint arXiv:1906.07241, 2019.\nDaniel Loureiro, Kiamehr Rezaee, Mohammad Taher Pilehvar, and Jose Camacho-\nCollados. Language models and word sense disambiguation: An overview and\nanalysis. arXiv preprint arXiv:2008.11608, 2020.\nYu Lu, Jiajun Zhang, and Chengqing Zong. Exploiting knowledge graph in neural ma-\nchine translation. In China Workshop on Machine Translation, pages 27–38. Springer,\n2018.\nVeronika Lux-Pogodalla and Alain Polguère. Construction of a French lexical net-\nwork: Methodological issues. In First International Workshop on Lexical Resources,\nWoLeR 2011, pages 54–61, 2011.\nThomas Ly, Carol A. Pamer, Oanh Dang, Sonja Brajovic, Shahrukh Haider, Taxiarchis\nBotsis, David Milward, Andrew Winter, Susan Lu, and Robert Ball. Evaluation of\nnatural language processing (NLP) systems to annotate drug product labeling with\nmeddra terminology. J. Biomed. Informatics, 83:73–86, 2018. doi: 10.1016/j.jbi.2018.\n05.019. URL https://doi.org/10.1016/j.jbi.2018.05.019.\n\nBIBLIOGRAPHY\n185\nJ. Lyons.\nSemantics:\nVolume 2.\nACLS Humanities E-Book. Cambridge Univer-\nsity Press, 1977.\nISBN 9780521291866.\nURL https://books.google.ie/books?id=\nidKaEUGPTLkC.\nJ. Lyons and L. John. Linguistic Semantics: An Introduction. Cambridge Approaches\nto Linguistics. Cambridge University Press, 1995. ISBN 9780521438773. URL https:\n//books.google.ie/books?id=Na2g1ltaKuAC.\nMarie-Claude L’Homme. Using explanatory and combinatorial lexicology to describe\nterms. Selected Lexical and Grammatical Topics in the Meaning-Text Theory. In Honour\nof Igor Mel’ˇcuk, pages 167–202, 2007.\nFadi Maali, John Erickson, and Phil Archer. Data catalog vocabulary (DCAT). W3C\nrecommendation. The World Wide Web Consortium, 2014.\nBernardo Magnini and Gabriela Cavaglia. Integrating subject ﬁeld codes into wordnet.\nIn Language Resources and Evaluation LREC, pages 1413–1418, 2000.\nBrigid Maher. Natural semantic metalanguage theory and some Italian speech act\nverbs. Studies in Pragmatics, 4:33–48, 2002.\nRila Mandala, Takenobu Tokunaga, and Hozumi Tanaka. The use of WordNet in\ninformation retrieval. In Usage of WordNet in Natural Language Processing Systems,\n1998.\nGideon S Mann and David Yarowsky. Multipath translation lexicon induction via\nbridge languages. In Proceedings of the Second Meeting of the North American Chapter\nof the Association for Computational Linguistics on Language Technologies, pages 1–8.\nAssociation for Computational Linguistics, 2001.\nRaffaele Manna, Giulia Speranza, Maria Pia di Buono, and Johanna Monti. UNIOR\nNLP at MWSA task - GlobaLex 2020: Siamese LSTM with attention for word sense\nalignment. In Proceedings of the 2020 Globalex Workshop on Linked Lexicography, pages\n76–83, Marseille, France, May 2020. European Language Resources Association.\nISBN 979-10-95546-46-7.\nMitch Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. Building a Large\nAnnotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2):\n313–330, 1993.\nMarco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi,\nand Roberto Zamparelli. A sick cure for the evaluation of compositional distri-\nbutional semantic models.\nIn Proceedings of the Ninth International Conference on\nLanguage Resources and Evaluation (LREC’14), pages 216–223, 2014.\n\n186\nBIBLIOGRAPHY\nLluís Màrquez, Xavier Carreras, Kenneth C. Litkowski, and Suzanne Stevenson. Se-\nmantic role labeling: An introduction to the special issue. Comput. Linguistics, 34(2):\n145–159, 2008. doi: 10.1162/coli.2008.34.2.145. URL https://doi.org/10.1162/coli.\n2008.34.2.145.\nPatricia Martín-Chozas, Sina Ahmadi, and Elena Montiel-Ponsoda. Defying Wiki-\ndata: validation of terminological relations in the web of data. In Proceedings of the\n12th Language Resources and Evaluation Conference, pages 5654–5659, 2020.\nMarco Maru, Federico Scozzafava, Federico Martelli, and Roberto Navigli. SyntagNet:\nchallenging supervised word sense disambiguation with lexical-semantic combina-\ntions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 3525–3531, 2019.\nEleanor Mattern. 5 the linguistic data life cycle, sustainability of data, and principles.\nThe Open Handbook of Linguistic Data Management, page 61, 2022.\nMichael Matuschek. Word sense alignment of lexical resources. Technische Univer-\nsität, 2015.\nMichael Matuschek and Iryna Gurevych. Dijkstra-WSA: A graph-based approach to\nword sense alignment. Transactions of the Association for Computational Linguistics, 1:\n151–164, 2013.\nMichael Matuschek and Iryna Gurevych. High performance word sense alignment\nby joint modeling of sense distance and gloss similarity. In Proceedings of COLING\n2014, the 25th International Conference on Computational Linguistics: Technical Papers,\npages 245–256, 2014.\nMausam, Stephen Soderland, Oren Etzioni, Daniel S. Weld, Michael Skinner, and Jeff\nBilmes. Compiling a massive, multilingual dictionary via probabilistic inference.\nIn Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the\n4th International Joint Conference on Natural Language Processing of the AFNLP: Volume\n1 - Volume 1, ACL ’09, pages 262–270, Stroudsburg, PA, USA, 2009. Association\nfor Computational Linguistics. ISBN 978-1-932432-45-9. URL http://dl.acm.org/\ncitation.cfm?id=1687878.1687917.\nMichael Mayor. Longman dictionary of contemporary English. Pearson Education India,\n2009.\nDiana McCarthy, Rob Koeling, Julie Weeds, and John A Carroll. Automatic identiﬁca-\ntion of infrequent word senses. In COLING 2004: Proceedings of the 20th International\nConference on Computational Linguistics, pages 1220–1226, 2004.\n\nBIBLIOGRAPHY\n187\nJohn McCrae, Dennis Spohr, and Philipp Cimiano.\nLinking lexical resources and\nontologies on the semantic web with lemon. In Extended Semantic Web Conference,\npages 245–259. Springer, 2011.\nJohn P McCrae. Yuzu: Publishing any data as linked data. In International Semantic\nWeb Conference (Posters & Demos), 2016.\nJohn P McCrae. Mapping wordnet instances to Wikipedia. In Proceedings of the 9th\nGlobal WordNet Conference (GWC 2018), pages 62–69, 2018.\nJohn P McCrae.\nTIAD Shared Task 2019: orthonormal explicit topic analysis for\ntranslation inference across dictionaries. In TIAD@ LDK, pages 54–60, 2019.\nJohn P McCrae and Paul Buitelaar. Linking datasets using semantic textual similarity.\nCybernetics and Information Technologies, 18(1):109–123, 2018.\nJohn P. McCrae and David Cillessen. Towards a linking between WordNet and Wiki-\ndata. In Proceedings of the 11th Global Wordnet Conference, pages 252–257, Univer-\nsity of South Africa (UNISA), January 2021. Global Wordnet Association.\nURL\nhttps://www.aclweb.org/anthology/2021.gwc-1.29.\nJohn P McCrae and Philipp Cimiano. Linghub: a linked data based portal supporting\nthe discovery of language resources. SEMANTiCS (Posters & Demos), 1481:88–91,\n2015.\nJohn P McCrae, Penny Labropoulou, Jorge Gracia, Marta Villegas, Victor Rodriguez-\nDoncel, and Philipp Cimiano. One ontology to bind them all: The META-SHARE\nOWL ontology for the interoperability of linguistic datasets on the Web. In European\nSemantic Web Conference, pages 271–282. Springer, 2015.\nJohn P McCrae, Mihael Arcan, and Paul Buitelaar. Linking knowledge graphs across\nlanguages with semantic similarity and machine translation. The First Workshop on\nMulti-Language Processing in a Globalising World (MLP 2017), 1:31, 2017a.\nJohn P McCrae, Julia Bosque-Gil, Jorge Gracia, Paul Buitelaar, and Philipp Cimiano.\nThe Ontolex-Lemon model: development and applications. In Proceedings of eLex\n2017 conference, pages 19–21, 2017b.\nJohn P. McCrae, Alexandre Rademaker, Francis Bond, Ewa Rudnicka, and Christiane\nFellbaum. English WordNet 2019 – an open-source WordNet for English. In Pro-\nceedings of the 10th Global Wordnet Conference, pages 245–252, Wroclaw, Poland, July\n2019a. Global Wordnet Association.\nURL https://www.aclweb.org/anthology/\n2019.gwc-1.31.\nJohn P. McCrae, Carole Tiberius, Anas Fahad Khan, Ilan Kernerman, Thierry De-\nclerck, Simon Krek, Monica Monachini, and Sina Ahmadi. The ELEXIS interface\nfor interoperable lexical resources.\nIn Proceedings of the sixth biennial conference\n\n188\nBIBLIOGRAPHY\non electronic lexicography (eLex), pages 642–659, Sintra, Portugal, 10 2019b.\nURL\nhttps://elex.link/elex2019/wp-content/uploads/2019/09/eLex_2019_37.pdf.\nJohn P. McCrae, Sina Ahmadi, Seung-bin Yim, and Lenka Bajˇceti´c.\nThe ELEXIS\nsystem for monolingual sense linking in dictionaries. Proceedings of Seventh Biennial\nConference on Electronic Lexicography (eLex 2021), 2021.\nJohn P. McCrae, Theodorus Fransen, Sina Ahmadi, Paul Buitelaar, and Koustava\nGoswami. Toward an integrative approach for making sense distinctions. Frontiers\nin Artiﬁcial Intelligence, 5, 2022. ISSN 2624-8212. doi: 10.3389/frai.2022.745626. URL\nhttps://www.frontiersin.org/article/10.3389/frai.2022.745626.\nJohn Philip McCrae and Mihael Arcan. NUIG at TIAD: Combining unsupervised\nNLP and graph metrics for translation inference. In Proceedings of the 2020 Glob-\nalex Workshop on Linked Lexicography, pages 92–97, Marseille, France, May 2020.\nEuropean Language Resources Association. ISBN 979-10-95546-46-7. URL https:\n//www.aclweb.org/anthology/2020.globalex-1.15.\nJohn Philip McCrae, Alexandre Rademaker, Ewa Rudnicka, and Francis Bond. En-\nglish WordNet 2020: Improving and extending a WordNet for English using an\nopen-source methodology. In Proceedings of the LREC 2020 workshop on Multimodal\nWordNets (MMW2020), pages 14–19, 2020.\nMichal Boleslav Mˇechura. Léacslann: a platform for building dictionary writing sys-\ntems. In Proceedings of the 15th Euralex International Congress, pages 855–861, 2012.\nLarry R Medsker and LC Jain. Recurrent neural networks. Design and Applications, 5:\n64–67, 2001.\nOren Melamud, Jacob Goldberger, and Ido Dagan. context2vec: Learning generic con-\ntext embedding with bidirectional lstm. In Proceedings of the 20th SIGNLL conference\non computational natural language learning, pages 51–61, 2016.\nIgor Mel’ˇcuk. Lexical functions: a tool for the description of lexical relations in a\nlexicon. Lexical functions in lexicography and natural language processing, 31:37–102,\n1996.\nIgor Mel’ˇcuk. Explanatory combinatorial dictionary. Open problems in linguistics and\nlexicography, pages 225–355, 2006.\nIgor A Mel’ˇcuk. Towards a linguistic ‘meaning-text’ model. Trends in Soviet theoretical\nlinguistics, pages 33–57, 1973.\nIgor A Mel’ˇcuk. Meaning-Text Models: A recent trend in Soviet linguistics. Annual\nreview of Anthropology, 10(1):27–62, 1981.\n\nBIBLIOGRAPHY\n189\nIgor Aleksandroviˇc Mel’ˇcuk and Nadia Arbatchewsky-Jumarie. Dictionnaire explicatif\net combinatoire du français contemporain: recherches lexico-sémantiques, volume 4. PUM,\n1999.\nLingling Meng, Runqing Huang, and Junzhong Gu. A review of semantic similarity\nmeasures in Wordnet.\nInternational Journal of Hybrid Information Technology, 6(1):\n1–12, 2013.\nAmil Merchant, Elahe Rahimtoroghi, Ellie Pavlick, and Ian Tenney. What happens to\nBERT embeddings during ﬁne-tuning? arXiv preprint arXiv:2004.14448, 2020.\nChristian M. Meyer. How web communities analyze human language: Word senses\nin Wiktionary. In In Second Web Science Conference, 2010.\nChristian M Meyer and Iryna Gurevych. Worth its weight in gold or yet another\nresource—a comparative study of Wiktionary, OpenThesaurus and GermaNet. In\nInternational Conference on Intelligent Text Processing and Computational Linguistics,\npages 38–49. Springer, 2010.\nChristian M Meyer and Iryna Gurevych. What psycholinguists know about chemistry:\nAligning Wiktionary and WordNet for increased domain coverage. In Proceedings of\n5th International Joint Conference on Natural Language Processing, pages 883–892, 2011.\nRada Mihalcea and Dan I Moldovan.\nExtended Wordnet: Progress report.\nIn in\nProceedings of NAACL Workshop on WordNet and Other Lexical Resources. Citeseer,\n2001.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of\nword representations in vector space. arXiv preprint arXiv:1301.3781, 2013a.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed\nrepresentations of words and phrases and their compositionality. In Advances in\nneural information processing systems, pages 3111–3119, 2013b.\nAlistair Miles and Sean Bechhofer.\nSKOS simple knowledge organization system\nreference. W3C recommendation https://www.w3.org/TR/skos-reference/, 18:W3C, 2009.\nSimon Mille, Leo Wanner, and Alicia Burga. Treebank annotation in the light of the\nMeaning-Text Theory. Linguistic Issues in Language Technology, 7, 2012.\nGeorge Miller, Christiane Fellbaum, Judy Kegl, and Katherine Miller. Wordnet: An\nelectronic lexical reference system based on theories of lexical memory. Revue que-\nbecoise de linguistique, 17(2):181–212, 1988.\nGeorge A Miller. Wordnet: a lexical database for english. Communications of the ACM,\n38(11):39–41, 1995.\nGeorge A Miller. WordNet: An electronic lexical database. MIT press, 1998.\n\n190\nBIBLIOGRAPHY\nGeorge A Miller and Christiane Fellbaum. WordNet then and now. Language Resources\nand Evaluation, 41(2):209–214, 2007.\nTristan Miller. Adjusting Sense Representations for Word Sense Disambiguation and Auto-\nmatic Pun Interpretation. PhD thesis, Technische Universität Darmstadt, Darmstadt,\nJanuary 2016. URL http://tuprints.ulb.tu-darmstadt.de/5400/.\nTristan Miller and Iryna Gurevych. WordNet—Wikipedia—Wiktionary: Construction\nof a three-way alignment.\nIn Proceedings of the Ninth International Conference on\nLanguage Resources and Evaluation, pages 2094–2100, 2014.\nDavid Milne. Computing semantic relatedness using Wikipedia link structure. In\nProceedings of the New Zealand Computer Science Research Student Conference. Citeseer,\n2007.\nShachar Mirkin, Ido Dagan, and Eyal Shnarch. Evaluating the inferential utility of\nlexical-semantic resources. In Proceedings of the 12th Conference of the European Chap-\nter of the ACL (EACL 2009), pages 558–566, 2009.\nMuhidin Mohamed and Mourad Oussalah. A hybrid approach for paraphrase iden-\ntiﬁcation based on knowledge-enriched semantic heuristics. Language Resources and\nEvaluation, 54(2):457–485, 2020.\nSalman Mohammed, Peng Shi, and Jimmy Lin. Strong baselines for simple question\nanswering over knowledge graphs with and without neural networks. In Proceed-\nings of the 2018 Conference of the North American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages\n291–296, 2018.\nDan Moldovan and Vasile Rus. Logic form transformation of wordnet and its ap-\nplicability to question answering. In Proceedings of the 39th Annual Meeting of the\nAssociation for Computational Linguistics, pages 402–409, 2001.\nElena Montiel-Ponsoda, Guadalupe Aguado De Cea, Asunción Gómez-Pérez, and\nWim Peters. Modelling multilinguality in ontologies. COLING 2008: Companion\nvolume: Posters, pages 67–70, 2008.\nGuido Montúfar. Restricted Boltzmann Machines: Introduction and Review. CoRR,\nabs/1806.07066, 2018. URL http://arxiv.org/abs/1806.07066.\nSteven Moran and Daniel McCloy, editors. PHOIBLE 2.0. Max Planck Institute for the\nScience of Human History, Jena, 2019. URL https://phoible.org/.\nJorge Morato, Miguel Angel Marzal, Juan Lloréns, and José Moreiro. Wordnet appli-\ncations. In Proceedings of GWC, pages 20–23, 2004.\n\nBIBLIOGRAPHY\n191\nAndrea Moro, Hong Li, Sebastian Krause, Feiyu Xu, Roberto Navigli, and Hans\nUszkoreit. Semantic rule ﬁltering for web-scale relation extraction. In International\nSemantic Web Conference, pages 347–362. Springer, 2013.\nDiego Moussallem, Mohamed Ahmed Sherif, Diego Esteves, Marcos Zampieri, and\nAxel-Cyrille Ngonga Ngomo.\nLIDIOMS: A multilingual linked idioms data set.\nCoRR, abs/1802.08148, 2018. URL http://arxiv.org/abs/1802.08148.\nJonas Mueller and Aditya Thyagarajan. Siamese recurrent architectures for learning\nsentence similarity. In Thirtieth AAAI Conference on Artiﬁcial Intelligence, 2016.\nI Nancy and Jean Véronis. Mapping dictionaries: A spreading activation approach.\nIn 6th Annual Conference of the Centre for the New Oxford English Dictionary, pages\n52–64. Citeseer, 1990.\nUsman Naseem, Imran Razzak, Shah Khalid Khan, and Mukesh Prasad. A compre-\nhensive survey on word representation models: From classical to state-of-the-art\nword representation language models. Transactions on Asian and Low-Resource Lan-\nguage Information Processing, 20(5):1–35, 2021.\nVivi Nastase, Rada Mihalcea, and Dragomir R Radev. A survey of graphs in natural\nlanguage processing. Natural Language Engineering, 21(5):665–698, 2015.\nRoberto Navigli. Meaningful clustering of senses helps boost word sense disambigua-\ntion performance. In Proceedings of the 21st International Conference on Computational\nLinguistics and the 44th annual meeting of the Association for Computational Linguistics,\npages 105–112. Association for Computational Linguistics, 2006.\nRoberto Navigli and Mirella Lapata. An experimental study of graph connectivity for\nunsupervised word sense disambiguation. IEEE transactions on pattern analysis and\nmachine intelligence, 32(4):678–692, 2009.\nRoberto Navigli and Simone Paolo Ponzetto. BabelNet: The automatic construction,\nevaluation and application of a wide-coverage multilingual semantic network. Ar-\ntiﬁcial Intelligence, 193:217–250, 2012a.\nRoberto Navigli and Simone Paolo Ponzetto. Joining forces pays off: Multilingual\njoint word sense disambiguation. In Proceedings of the 2012 Joint Conference on Em-\npirical Methods in Natural Language Processing and Computational Natural Language\nLearning, pages 1399–1410. Association for Computational Linguistics, 2012b.\nNeha Nayak, Gabor Angeli, and Christopher D Manning. Evaluating word embed-\ndings using a representative suite of practical tasks. In Proceedings of the 1st Work-\nshop on Evaluating Vector-Space Representations for NLP, pages 19–23, 2016.\nMark EJ Newman. The structure of scientiﬁc collaboration networks. Proceedings of\nthe National Academy of Sciences, 98(2):404–409, 2001.\n\n192\nBIBLIOGRAPHY\nMark EJ Newman, Steven H Strogatz, and Duncan J Watts. Random graphs with\narbitrary degree distributions and their applications. Physical review E, 64(2):026118,\n2001.\nDavid N Nicholson and Casey S Greene. Constructing knowledge graphs and their\nbiomedical applications. Computational and Structural Biotechnology Journal, 18:1414–\n1428, 2020.\nElisabeth Niemann and Iryna Gurevych. The people’s web meets linguistic knowl-\nedge: Automatic sense alignment of Wikipedia and WordNet. In Proceedings of the\nNinth International Conference on Computational Semantics (IWCS 2011), 2011. URL\nhttps://www.aclweb.org/anthology/W11-0122.\nIan Niles and Adam Pease. Towards a standard upper ontology. In Proceedings of the\ninternational conference on Formal Ontology in Information Systems-Volume 2001, pages\n2–9, 2001.\nIan Niles and Adam Pease. Linking lexicons and ontologies: Mapping wordnet to\nthe suggested upper merged ontology. In Hamid R. Arabnia, editor, Proceedings of\nthe International Conference on Information and Knowledge Engineering. IKE’03, June 23\n- 26, 2003, Las Vegas, Nevada, USA, Volume 2, pages 412–416. CSREA Press, 2003.\nSanni Nimb. The Danish FrameNet lexicon: method and lexical coverage. In Proceed-\nings of the International FrameNet Workshop at LREC 2018: Multilingual FrameNets and\nConstructions, pages 51–55, 2018.\nSanni Nimb, Lars Trap-Jensen, and Henrik Lorentzen. The Danish thesaurus: Prob-\nlems and perspectives. In Proceedings of the XVI EURALEX International Congress:\nThe User in Focus, pages 15–19, 2014.\nSanni Nimb, Nicolai H. Sørensen, and Thomas Troelsgård.\nFrom standalone the-\nsaurus to integrated related words in the Danish dictionary. In Proceedings of the\nXVIII EURALEX International Congress: Lexicography in Global Contexts, pages 915–\n923, 2018.\nThanapon Noraset, Chen Liang, Larry Birnbaum, and Doug Downey.\nDeﬁnition\nmodeling: Learning to deﬁne word embeddings in natural language. In Thirty-\nFirst AAAI Conference on Artiﬁcial Intelligence, 2017.\nPeter Norvig. Building a large lexicon with lexical network theory. In the Proceedings\nof the IJCAI Workshop on Lexical Acquisition, 1989.\nPeter Ochieng and Swaib Kyanda. Large-scale ontology matching: State-of-the-art\nanalysis. ACM Computing Surveys (CSUR), 51(4):1–35, 2018.\n\nBIBLIOGRAPHY\n193\nHugo Gonçalo Oliveira and Paulo Gomes. ECO and onto.pt: a ﬂexible approach for\ncreating a portuguese wordnet automatically. Lang. Resour. Evaluation, 48(2):373–\n393, 2014. doi: 10.1007/s10579-013-9249-9. URL https://doi.org/10.1007/s10579-\n013-9249-9.\nPetya Osenova and Kiril Simov. Challenges Behind the Data-driven Bulgarian Word-\nNet (BulTreeBank Bulgarian Wordnet).\nIn John P. McCrae, Francis Bond, Paul\nBuitelaar, Philipp Cimiano, Thierry Declerck, Jorge Gracia, Ilan Kernerman, Elena\nMontiel-Ponsoda, Noam Ordan, and Maciej Piasecki, editors, Proceedings of the LDK\n2017 Workshops: 1st Workshop on the OntoLex Model (OntoLex-2017), Shared Task on\nTranslation Inference Across Dictionaries & Challenges for Wordnets co-located with 1st\nConference on Language, Data and Knowledge (LDK 2017), Galway, Ireland, June 18,\n2017, volume 1899 of CEUR Workshop Proceedings, pages 152–163. CEUR-WS.org,\n2017. URL http://ceur-ws.org/Vol-1899/CfWNs_2017_proc4-paper_3.pdf.\nSergey I Ozhegov and N. Y. Shvedova. Explanatory Dictionary of the Russian Language.\nAz, Moscow, 1992.\nKyonghee Paik, Francis Bond, and Satoshi Shirai.\nUsing multiple pivots to align\nKorean and Japanese lexical resources.\nIn Proc. of the NLPRS-2001 Workshop on\nLanguage Resources in Asia, pages 63–70, 2001.\nKyonghee Paik, Satoshi Shirai, and Hiromi Nakaiwa. Automatic construction of a\ntransfer dictionary considering directionality. In Proceedings of the Workshop on Mul-\ntilingual Linguistic Ressources, pages 31–38. Association for Computational Linguis-\ntics, 2004.\nVasile Pais, Dan Tuﬁs,, and Radu Ion. MWSA task at GlobaLex 2020: RACAI’s word\nsense alignment system using a similarity measurement of dictionary deﬁnitions.\nIn Proceedings of the 2020 Globalex Workshop on Linked Lexicography, pages 69–75,\nMarseille, France, May 2020. European Language Resources Association. ISBN 979-\n10-95546-46-7. URL https://aclanthology.org/2020.globalex-1.12.\nAlok Ranjan Pal and Diganta Saha. Word sense disambiguation: A survey. arXiv\npreprint arXiv:1508.01346, 2015.\nMartha Palmer. SemLink: Linking PropBank, VerbNet and FrameNet. In Proceedings\nof the generative lexicon conference, pages 9–15. GenLex-09, Pisa, Italy, 2009.\nAlexander Panchenko, Natalia Loukachevitch, Dmitry Ustalov, Denis Paperno, Chris-\ntian Meyer, and Natalia Konstantinova.\nRusse: The ﬁrst workshop on Russian\nsemantic similarity. arXiv preprint arXiv:1803.05820, 2018.\nPatrick Pantel and Marco Pennacchiotti. Automatically Harvesting and Ontologizing\nSemantic Relations. In Proceedings of the 2008 Conference on Ontology Learning and\n\n194\nBIBLIOGRAPHY\nPopulation: Bridging the Gap between Text and Knowledge, page 171–195, NLD, 2008.\nIOS Press. ISBN 9781586038182.\nMarius Pasca and Sanda M Harabagiu. The informative role of WordNet in open-\ndomain question answering. In Proceedings of NAACL-2001 Workshop on WordNet\nand Other Lexical Resources, pages 138–143, 2001.\nRazvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difﬁculty of training\nrecurrent neural networks.\nIn International conference on machine learning, pages\n1310–1318. PMLR, 2013.\nAtish Pawar and Vijay Mago. Calculating the similarity between words and sentences\nusing a lexical database and corpus statistics. arXiv preprint arXiv:1802.05667, 2018.\nBolette Sandford Pedersen, Sanni Nimb, Jørg Asmussen, Nicolai Hartvig Sørensen,\nLars Trap-Jensen, and Henrik Lorentzen. DanNet: the challenge of compiling a\nwordnet for Danish by reusing a monolingual dictionary. Language resources and\nevaluation, 43(3):269–299, 2009.\nBolette Sandford Pedersen, Sanni Nimb, Sussi Olsen, and Nocolai H. Sørensen. Com-\nbining dictionaries, wordnets and other lexical resources-advantages and chal-\nlenges. In Globalex Proceedings 2018, Miyasaki, Japan, 2018.\nBolette Sandford Pedersen, Sanni Nimb, Ida Rørmann Olsen, , and Sussi Olsen. Link-\ning DanNet with Princeton WordNet. In Global WordNet 2019 Proceedings, 2019.\nTed Pedersen, Siddharth Patwardhan, Jason Michelizzi, et al. WordNet: Similarity-\nMeasuring the Relatedness of Concepts. In Proceedings of the Nineteenth National\nConference on Artiﬁcial Intelligence, Sixteenth Conference on Innovative Applications of\nArtiﬁcial Intelligence, volume 4, pages 25–29, 2004.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,\nP. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau,\nM. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine Learning in Python.\nJournal of Machine Learning Research, 12:2825–2830, 2011.\nJeffrey Pennington, Richard Socher, and Christopher D. Manning.\nGlove: Global\nvectors for word representation.\nIn Alessandro Moschitti, Bo Pang, and Walter\nDaelemans, editors, Proceedings of the 2014 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of\nSIGDAT, a Special Interest Group of the ACL, pages 1532–1543. ACL, 2014. doi: 10.\n3115/v1/d14-1162. URL https://doi.org/10.3115/v1/d14-1162.\nMaria Pershina, Yifan He, and Ralph Grishman. Personalized page rank for named\nentity disambiguation. In Proceedings of the 2015 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies,\npages 238–243, 2015.\n\nBIBLIOGRAPHY\n195\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,\nKenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In\nProceedings of the 2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, NAACL-HLT, 2018a.\nMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,\nKenton Lee, and Luke Zettlemoyer.\nDeep contextualized word representations.\narXiv preprint arXiv:1802.05365, 2018b.\nWim Peters and Ivonne Peters.\nLexicalised Systematic Polysemy in WordNet.\nIn\nProceedings of the Second International Conference on Language Resources and Evalua-\ntion, LREC 2000, 31 May - June 2, 2000, Athens, Greece. European Language Re-\nsources Association, 2000. URL http://www.lrec-conf.org/proceedings/lrec2000/\nhtml/summary/148.htm.\nWim Peters, Ivonne Peters, and Piek Vossen. Automatic sense clustering in EuroWord-\nNet. In Proceedings of ﬁrst international conference on language resource and evaluation:\nGranada, Spain, 28-30 May, 1998, pages 409–416. ELRA, 1998.\nTommaso Petrolito and Francis Bond. A survey of wordnet annotated corpora. In\nProceedings of the Seventh Global WordNet Conference, pages 236–245, 2014.\nAnders Pettersson. The Idea of a Text and the Nature of Textual Meaning. John Benjamins,\n2017.\nMohammad Taher Pilehvar and Roberto Navigli. A robust approach to aligning het-\nerogeneous lexical resources. In Proceedings of the 52nd Annual Meeting of the Associ-\nation for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 468–478,\n2014.\nStelios Piperidis.\nThe META-SHARE Language Resources Sharing Infrastructure:\nPrinciples, Challenges, Solutions. In Language Resources and Evaluation LREC, pages\n36–42, 2012.\nJulien Plu, Kévin Cousot, Mathieu Lafourcade, Raphaël Troncy, and Giuseppe Rizzo.\nJeuxDeLiens: Word Embeddings and Path-Based Similarity for Entity Linking us-\ning the French JeuxDeMots Lexical Semantic Network. In Actes de la Conférence\nTALN. Volume 1-Articles longs, articles courts de TALN, pages 529–538, 2018.\nAlain Polguere. Une base de données lexicales du français et ses applications pos-\nsibles en didactique. Revue de Linguistique et de Didactique des Langues, 21:75–97,\n2000.\nAlain Polguere. Lexical systems: graph models of natural language lexicons. Language\nresources and evaluation, 43(1):41–55, 2009.\n\n196\nBIBLIOGRAPHY\nAlain Polguère. Lexicographie des dictionnaires virtuels. Apresjan, Y., Boguslavsky, I.,\nL’Homme, M.-C., Iomdin, L., Milicevic, J., Polguère, A., and Wanner, L., editors, Meanings,\nTexts, and Other Exciting Things. A Festschrift to Commemorate the 80th Anniversary of\nProfessor Igor Alexandrovic Mel’cuk, Studia Philologica, pages 509–523, 2012.\nAlain Polguère. From writing dictionaries to weaving lexical networks. International\nJournal of Lexicography, 27(4):396–418, 2014.\nAlain Polguère. A lexicographic approach to the study of copolysemy relations. Rus-\nsian Journal of Linguistics, 22(4):788–820, 2018.\nAlain Polguère. From Writing Dictionaries to Weaving Lexical Networks. International\nJournal of Lexicography, 27(4):396–418, 09 2014. ISSN 0950-3846. doi: 10.1093/ijl/\necu017. URL https://doi.org/10.1093/ijl/ecu017.\nSimone Paolo Ponzetto and Roberto Navigli. Large-scale taxonomy mapping for re-\nstructuring and integrating Wikipedia. In Twenty-First International Joint Conference\non Artiﬁcial Intelligence, 2009.\nSimone Paolo Ponzetto and Roberto Navigli.\nKnowledge-rich word sense disam-\nbiguation rivaling supervised systems. In Proceedings of the 48th annual meeting of\nthe association for computational linguistics, pages 1522–1531. Association for Compu-\ntational Linguistics, 2010.\nDavid M. W. Powers.\nEvaluation: from precision, recall and F-measure to ROC,\ninformedness, markedness and correlation.\nCoRR, abs/2010.16061, 2020.\nURL\nhttps://arxiv.org/abs/2010.16061.\nAnat Prior and Ma’ayan Geffet. Word association strength, mutual information and\nsemantic similarity. EuroCogSci 2003, 2003.\nThomas Proisl, Philipp Heinrich, Stefan Evert, and Besim Kabashi. Translation in-\nference across dictionaries via a combination of graph-based methods and co-\noccurrence statistics.\nIn Proceedings of the LDK 2017 Workshops: 1st Workshop on\nthe OntoLex Model (OntoLex-2017), Shared Task on Translation Inference Across Dictio-\nnaries & Challenges for Wordnets co-located with 1st Conference on Language, Data and\nKnowledge (LDK 2017), Galway, Ireland, June 18, 2017., 2017a.\nThomas Proisl, Philipp Heinrich, Stefan Evert, and Besim Kabashi. Translation In-\nference across Dictionaries via a Combination of Graph-based Methods and Co-\noccurrence Statistics. In LDK Workshops, pages 94–82, 2017b.\nJames Pustejovsky. The Generative Lexicon. MIT Press, Cambridge, MA, 1995.\nJames Pustejovsky. Introduction to generative lexicon. Unpublished manuscript. Mi-\ncrosoft Word ﬁle, 2006.\n\nBIBLIOGRAPHY\n197\nJames Pustejovsky. The semantics of lexical underspeciﬁcation. Folia linguistica, 51\n(s1000):1–25, 2017.\nJames Pustejovsky, Catherine Havasi, Jessica Littman, Anna Rumshisky, and Marc\nVerhagen. Towards a Generative Lexical Resource: The Brandeis Semantic Ontol-\nogy. In Language Resources and Evaluation LREC, pages 1702–1705, 2006.\nZhe Quan, Zhi-Jie Wang, Yuquan Le, Bin Yao, Kenli Li, and Jian Yin. An efﬁcient\nframework for sentence similarity modeling.\nIEEE/ACM Transactions on Audio,\nSpeech, and Language Processing, 27(4):853–865, 2019.\nReal Academia Española RAE. Diccionario de la Lengua Espanola RAE. Diccionario\nde la lengua española. Planeta Publishing Corporation, 2001. ISBN 9786070723513.\nURL https://books.google.ie/books?id=naqwoQEACAAJ.\nAlessandro Raganato, Jose Camacho-Collados, and Roberto Navigli. Word sense dis-\nambiguation: A uniﬁed evaluation framework and empirical comparison. In Pro-\nceedings of the 15th Conference of the European Chapter of the Association for Computa-\ntional Linguistics: Volume 1, Long Papers, pages 99–110, 2017.\nGeorg Rehm. The language resource life cycle: towards a generic model for creating,\nmaintaining, using and distributing language resources. In Proceedings of the Tenth\nInternational Conference on Language Resources and Evaluation (LREC’16), pages 2450–\n2454, 2016.\nGeorg Rehm, Oliver Schonefeld, Andreas Witt, C. Chiarcos, and Timm Lehmberg.\nSPLICR: A Sustainability Platform for Linguistic Corpora and Resources. Proceed-\nings of KONVENS 2008., 2008.\nNils Reimers and Iryna Gurevych.\nSentence-BERT: Sentence embeddings using\nSiamese BERT-networks. arXiv preprint arXiv:1908.10084, 2019.\nRidho Reinanda, Edgar Meij, Maarten de Rijke, et al. Knowledge graphs: An information\nretrieval perspective. Now Publishers, 2020.\nVeit Reuer. Language resources for a network-based dictionary. In Proceedings of the\nWorkshop on Enhancing and Using Electronic Dictionaries, pages 81–84, 2004.\nJ. Rey-Debove. Étude linguistique et sémiotique des dictionnaires français contemporains.\nApproaches to Semiotics [AS]. De Gruyter, 2012. ISBN 9783111323459. URL https:\n//books.google.ie/books?id=o89aimry0ToC.\nPetar Ristoski, Anna Lisa Gentile, Alfredo Alba, Daniel Gruhl, and Steven Welch.\nLarge-scale relation extraction from web documents and knowledge graphs with\nhuman-in-the-loop. Journal of Web Semantics, 60:100546, 2020.\n\n198\nBIBLIOGRAPHY\nRichard Robinson. Deﬁnition. Oxford: Oxford University Press., 1 edition, 2003. ISBN\n9780198241607.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky. A primer in Bertology: What\nwe know about how BERT works. Transactions of the Association for Computational\nLinguistics, 8:842–866, 2020.\nPeter Mark Roget. Thesaurus of English Words and Phrases: Classiﬁed and Arranged so\nas to Facilitate the Expression of Ideas and Assist in Literary Composition. Cambridge\nLibrary Collection - Linguistics. Cambridge University Press, 2014. doi: 10.1017/\nCBO9781107448735.\nLaurent Romary and Toma Tasovac.\nTEI Lex-0: A target format for TEI-encoded\ndictionaries and lexical resources. In TEI Conference and Members’ Meeting, 2018.\nAdriana Roventini and Nilda Ruimy.\nMapping events and abstract entities from\nPAROLE-SIMPLE-CLIPS to ItalWordNet. In Proceedings of the Sixth International Con-\nference on Language Resources and Evaluation (LREC’08), Marrakech, Morocco, May\n2008. European Language Resources Association (ELRA). URL http://www.lrec-\nconf.org/proceedings/lrec2008/pdf/471_paper.pdf.\nAdriana Roventini, Antonietta Alonge, Nicoletta Calzolari, Bernardo Magnini, and\nFrancesca Bertagna. ItalWordNet: a Large Semantic Database for Italian. In Pro-\nceedings of the Second International Conference on Language Resources and Evaluation,\n2000.\nAdriana Roventini, Marisa Ulivieri, and Nicoletta Calzolari. Integrating two seman-\ntic lexicons, SIMPLE and ItalWordNet: What can we gain?\nIn Proceedings of the\nThird International Conference on Language Resources and Evaluation (LREC’02), Las\nPalmas, Canary Islands - Spain, May 2002. European Language Resources Associa-\ntion (ELRA). URL http://www.lrec-conf.org/proceedings/lrec2002/pdf/229.pdf.\nAdriana Roventini, Nilda Ruimy, Rita Marinelli, Marisa Ulivieri, and Michele Mam-\nmini.\nMapping concrete entities from PAROLE-SIMPLE-CLIPS to ItalWordNet:\nMethodology and results.\nIn Proceedings of the 45th Annual Meeting of the Asso-\nciation for Computational Linguistics Companion Volume Proceedings of the Demo and\nPoster Sessions, pages 161–164, Prague, Czech Republic, June 2007. Association for\nComputational Linguistics. URL https://www.aclweb.org/anthology/P07-2041.\nEmilio Rubiera, Luis Polo, Diego Berrueta, and Adil El Ghali. TELIX: An RDF-based\nmodel for linguistic annotation. In Extended Semantic Web Conference, pages 195–209.\nSpringer, 2012.\nSebastian Ruder, Ivan Vuli´c, and Anders Søgaard. A survey of cross-lingual word\nembedding models. Journal of Artiﬁcial Intelligence Research, 65:569–631, 2019.\n\nBIBLIOGRAPHY\n199\nEwa Katarzyna Rudnicka, Wojciech Witkowski, and Michał Kali´nski. Towards the\nmethodology for extending princeton wordnet. Cognitive Studies| Études cognitives,\n(15):335–351, 2015.\nMaria Ruiz-Casado, Enrique Alfonseca, and Pablo Castells. Automatic assignment\nof Wikipedia encyclopedic entries to wordnet synsets. In International Atlantic Web\nIntelligence Conference, pages 380–386. Springer, 2005.\nBenoît Sagot and Darja Fišer. Automatic extension of WOLF. In GWC2012-6th Inter-\nnational Global Wordnet Conference, 2012.\nAna Salgado, Sina Ahmadi, Alberto Simões, John P. McCrae, and Rute Costa. Chal-\nlenges of word sense alignment: Portuguese language resources. In the 7th Workshop\non Linked Data in Linguistics: Building tools and infrastructure at the 12th International\nConference on Language Resources and Evaluation (LREC), Marseille, France, 2020.\nJ Fernando Sánchez-Rada and Carlos A Iglesias. Onyx: A linked data approach to\nemotion representation. Information Processing & Management, 52(1):99–114, 2016.\nXabier Saralegi, Iker Manterola, and Inaki San Vicente. Analyzing methods for im-\nproving precision of pivot based bilingual dictionaries. In Proceedings of the Confer-\nence on Empirical Methods in Natural Language Processing, pages 846–856. Association\nfor Computational Linguistics, 2011.\nSerhad Sarica, Jianxi Luo, and Kristin L Wood. Technet: Technology semantic network\nbased on patent data. Expert Systems with Applications, 142:112995, 2020.\nAndreyeva Sasha. Lexical-Functional Correspondences and Their Use in the System\nof Machine Translation ETAP-3. In Coling 2008: Proceedings of the Workshop on Cog-\nnitive Aspects of the Lexicon (COGALEX 2008), pages 64–72, 2008.\nRoser Saurí, Louis Mahon, Irene Russo, and Mironas Bitinis. Cross-Dictionary Link-\ning at Sense Level with a Double-Layer Classiﬁer. In 2nd Conference on Language,\nData and Knowledge (LDK 2019). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik,\n2019.\nCharles Schafer and David Yarowsky. Inducing translation lexicons via diverse simi-\nlarity measures and bridge languages. In Proceedings of the 6th Conference on Natural\nlanguage learning-Volume 20, pages 1–7. Association for Computational Linguistics,\n2002.\nMichael Sejr Schlichtkrull, Nicola De Cao, and Ivan Titov. Interpreting graph neural\nnetworks for nlp with differentiable edge masking. arXiv preprint arXiv:2010.00577,\n2020.\nKarin Kipper Schuler. VerbNet: A broad-coverage, comprehensive verb lexicon. University\nof Pennsylvania, 2005.\n\n200\nBIBLIOGRAPHY\nTal Schuster, Ori Ram, Regina Barzilay, and Amir Globerson. Cross-lingual align-\nment of contextual word embeddings, with applications to zero-shot dependency\nparsing. arXiv preprint arXiv:1902.09492, 2019.\nFederico Scozzafava, Marco Maru, Fabrizio Brignone, Giovanni Torrisi, and Roberto\nNavigli.\nPersonalized pagerank with syntagmatic information for multilingual\nword sense disambiguation. In Proceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics: System Demonstrations, pages 37–46, 2020.\nThierry Selva, Serge Verlinde, and Jean Binon.\nVers une deuxième génération de\ndictionnaires électroniques. Traitement automatique des langues (TAL), 44(2):177–197,\n2003.\nGilles Sérasset. DBnary: Wiktionary as a Lemon-based multilingual lexical resource\nin RDF. Semantic Web, 6(4):355–361, 2015.\nChirag Shah and W Bruce Croft. Evaluating high accuracy retrieval techniques. In\nProceedings of the 27th annual international ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval, pages 2–9, 2004.\nAhmad Muqeem Sheri, Muhammad Aasim Raﬁque, Moongu Jeon, and Witold\nPedrycz. Background subtraction using Gaussian–Bernoulli restricted Boltzmann\nmachine. IET Image Processing, 12(9):1646–1654, 2018.\nDaphna Shezaf and Ari Rappoport. Bilingual lexicon generation using non-aligned\nsignatures. In Proceedings of the 48th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 98–107. Association for Computational Linguistics, 2010.\nPavel Shvaiko and Jérôme Euzenat. Ontology matching: state of the art and future\nchallenges. IEEE Transactions on knowledge and data engineering, 25(1):158–176, 2011.\nVivian Silva, Siegfried Handschuh, and André Freitas. Categorization of semantic\nroles for dictionary deﬁnitions. In Proceedings of the 5th Workshop on Cognitive Aspects\nof the Lexicon (CogALex-V), pages 176–184, 2016.\nAlberto Simões, José João Almeida, and Ana Salgado.\nBuilding a Dictionary Us-\ning XML Technology. In 5th Symposium on Languages, Applications and Technologies\n(SLATE’16). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2016.\nKiril Simov, Petya Osenova, Laska Laskova, Ivajlo Radev, and Zara Kancheva. Align-\ning the Bulgarian BTB WordNet with the Bulgarian Wikipedia. In Christiane Fell-\nbaum, Piek Vossen, Ewa Rudnicka, Marek Maziarz, and Maciej Piasecki, editors,\nProceedings of the Tenth Global Wordnet Conference, pages 290–297, 2019.\nAlberto Simões and Rita Farinha. Dicionário aberto: um recurso para processamento\nde linguagem natural. Viceversa: revista galega de traducción, 16:159–171, 2010.\n\nBIBLIOGRAPHY\n201\nJonas Sjöbergh. Creating a free digital Japanese-Swedish lexicon. In Proceedings of\nPACLING, pages 296–300. Citeseer, 2005.\nJennifer Sleeman and Tim Finin. Type prediction for efﬁcient coreference resolution\nin heterogeneous semantic graphs. In 2013 IEEE Seventh International Conference on\nSemantic Computing, pages 78–85. IEEE, 2013.\nStephen Soderland, Oren Etzioni, Daniel S Weld, Michael Skinner, Jeff Bilmes, et al.\nCompiling a massive, multilingual dictionary via probabilistic inference. In Proceed-\nings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th Interna-\ntional Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume\n1, pages 262–270. Association for Computational Linguistics, 2009.\nAnders Søgaard, Sebastian Ruder, and Ivan Vuli´c. On the limitations of unsupervised\nbilingual dictionary induction. arXiv preprint arXiv:1805.03620, 2018.\nAbraham Solomonick. Towards a comprehensive theory of lexicographic deﬁnitions.\nIn Euralex 1996 Conference Proceedings, pages 1–8, 1996.\nNicolai Hartvig Sørensen and Sanni Nimb. Word2Dict-Lemma Selection and Dictio-\nnary Editing Assisted by Word Embeddings. In Proceedings of the 18th EURALEX\nInternational Congres: Lexocography in Global Contexts, pages 819–827, 2018.\nSasha Spala, Nicholas A Miller, Yiming Yang, Franck Dernoncourt, and Carl Dock-\nhorn. DEFT: A corpus for deﬁnition extraction in free-and semi-structured text. In\nProceedings of the 13th Linguistic Annotation Workshop, pages 124–131, 2019.\nRobyn Speer, Catherine Havasi, et al.\nRepresenting general relational knowledge\nin ConceptNet 5. In Language Resources and Evaluation LREC, volume 2012, pages\n3679–86, 2012.\nRobyn Speer, Joshua Chin, and Catherine Havasi. ConceptNet 5.5: An open multilin-\ngual graph of general knowledge. arXiv preprint arXiv:1612.03975, 2016.\nRobyn Speer, Joshua Chin, and Catherine Havasi. ConceptNet 5.5: An Open Multi-\nlingual Graph of General Knowledge. pages 4444–4451, 2017. http://aaai.org/ocs/\nindex.php/AAAI/AAAI17/paper/view/14972.\nGiulia Speranza, Carola Carlino, and Sina Ahmadi. Creating a multilingual termino-\nlogical resource using linked data: the case of archaeological domain in the Italian\nlanguage. In Proceedings of the Sixth Italian Conference on Computational Linguistics\n(CLiC-it), Bari, Italy, 11 2019.\nGiulia Speranza, Maria Pia di Buono, Johanna Monti, and Federico Sangati. From\nlinguistic resources to ontology-aware terminologies: Minding the representation\ngap. In Proceedings of the 12th Language Resources and Evaluation Conference, pages\n\n202\nBIBLIOGRAPHY\n2503–2510, Marseille, France, May 2020. European Language Resources Association.\nISBN 979-10-95546-34-4. URL https://aclanthology.org/2020.lrec-1.305.\nMichael Speriosu, Nikita Sudan, Sid Upadhyay, and Jason Baldridge. Twitter polarity\nclassiﬁcation with label propagation over lexical links and the follower graph. In\nProceedings of the First workshop on Unsupervised Learning in NLP, pages 53–63, 2011.\nDennis Spohr. Towards a multifunctional lexical resource. de Gruyter, 2012.\nDennis Spohr, Laura Hollink, and Philipp Cimiano. A machine learning approach\nto multilingual and cross-lingual ontology matching. In International Semantic Web\nConference, pages 665–680. Springer, 2011.\nRanka Stankovi´c, Miljana Mladenovi´c, Ivan Obradovi´c, Marko Vitas, and Cvetana\nKrstev. Resource-based WordNet augmentation and enrichment. In Svetla Koeva,\neditor, Proceedings of the Third International Conference Computational Linguistics in\nBulgaria (CLIB 2018), pages 104–114, Soﬁa, Bulgaria, May 2018. Institute for Bulgar-\nian Language “Prof. Lyubomir Andreychin”, Bulgarian Academy of Sciences. ISBN\n2367-5675 (on-line).\nRalf Steinberger, Andreas Eisele, Szymon Klocek, Spyridon Pilos, and Patrick Schlüter.\nDGT-TM: A freely available translation memory in 22 languages. arXiv preprint\narXiv:1309.5226, 2013.\nMark Stevenson and Yorick Wilks. Word sense disambiguation. The Oxford handbook\nof computational linguistics, pages 249–265, 2003.\nKristin Stock. Determining semantic similarity of behaviour using natural semantic\nmetalanguage to match user objectives to available web services. Transactions in\nGIS, 12(6):733–755, 2008.\nCarlo Strapparava, Alessandro Valitutti, et al. Wordnet Affect: an affective extension\nof Wordnet. In Language Resources and Evaluation LREC, volume 4, page 40. Lisbon,\n2004.\nCarlos Subirats and Hiroaki Sato. Spanish FrameNet and FrameSQL. In 4th Interna-\ntional Conference on Language Resources and Evaluation. Workshop on Building Lexical\nResources from Semantically Annotated Corpora. Lisbon (Portugal). Citeseer, 2004.\nFabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic\nknowledge.\nIn Proceedings of the 16th international conference on World Wide Web,\npages 697–706. ACM, 2007.\nMd Arafat Sultan, Steven Bethard, and Tamara Sumner. Back to basics for monolin-\ngual alignment: Exploiting word similarity and contextual evidence. Transactions of\nthe Association for Computational Linguistics, 2:219–230, 2014.\n\nBIBLIOGRAPHY\n203\nP Sunilkumar and Athira P Shaji. A survey on semantic similarity. In 2019 Inter-\nnational Conference on Advances in Computing, Communication and Control (ICAC3),\npages 1–8. IEEE, 2019.\nRobert S Swier and Suzanne Stevenson. Exploiting a verb lexicon in automatic se-\nmantic role labelling. In Proceedings of the conference on Human Language Technology\nand Empirical Methods in Natural Language Processing, pages 883–890. Association for\nComputational Linguistics, 2005.\nOscar Täckström, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre.\nToken and type constraints for cross-lingual part-of-speech tagging. Transactions of\nthe Association for Computational Linguistics, 1:1–12, 2013.\nPartha Pratim Talukdar and Koby Crammer. New regularized algorithms for trans-\nductive learning. In Joint European Conference on Machine Learning and Knowledge\nDiscovery in Databases, pages 442–457. Springer, 2009.\nKumiko Tanaka and Kyoji Umemura. Construction of a bilingual dictionary inter-\nmediated by a third language.\nIn Proceedings of the 15th Conference on Computa-\ntional Linguistics - Volume 1, COLING ’94, pages 297–303, Stroudsburg, PA, USA,\n1994a. Association for Computational Linguistics. doi: 10.3115/991886.991937. URL\nhttps://doi.org/10.3115/991886.991937.\nKumiko Tanaka and Kyoji Umemura. Construction of a bilingual dictionary inter-\nmediated by a third language.\nIn Proceedings of the 15th conference on Computa-\ntional linguistics-Volume 1, pages 297–303. Association for Computational Linguis-\ntics, 1994b.\nAndon Tchechmedjiev. Interopérabilité sémantique multilingue des ressources lexicales en\ndonnées lexicales liées ouvertes. PhD thesis, Université Grenoble Alpes, 2016.\nAndon Tchechmedjiev, Théophile Mandon, Mathieu Lafourcade, Anne Laurent, and\nKonstantin Todorov.\nOntolex JeuxDeMots and Its Alignment to the Linguistic\nLinked Open Data Cloud. In International Semantic Web Conference, pages 678–693.\nSpringer, 2017.\nYee Whye Teh and Geoffrey E Hinton. Rate-coded restricted Boltzmann machines for\nface recognition. Advances in neural information processing systems, pages 908–914,\n2001.\nConsortium TEI. TEI P5: Guidelines for Electronic Text Encoding and Interchange,\nAugust 2020. URL https://doi.org/10.5281/zenodo.3992514.\nSina Ahmadi and John P. McCrae. Monolingual word sense alignment as a classiﬁca-\ntion problem. In Proceedings of the 11th Global Wordnet Conference, GWC 2021, Univer-\nsity of South Africa (UNISA), Potchefstroom, South Africa, January 18-21, 2021, pages\n\n204\nBIBLIOGRAPHY\n73–80. Global Wordnet Association, 2021. URL https://aclanthology.org/2021.gwc-\n1.9/.\nSina Ahmadi, Mihael Arcan, and John McCrae. On lexicographical networks. In\nWorkshop on eLexicography: Between Digital Humanities and Artiﬁcial Intelligence, 2018.\nSina Ahmadi, Mihael Arcan, and John McCrae.\nLexical sense alignment using\nweighted bipartite b-matching. In Proceedings of the LDK 2019 Workshops. 2nd Con-\nference on Language, Data and Knowledge (LDK 2019), 2019a.\nSina Ahmadi, Hossein Hassani, and John P. McCrae. Towards electronic lexicography\nfor the Kurdish language. In Proceedings of the sixth biennial conference on electronic\nlexicography (eLex), pages 881–906, Sintra, Portugal, 10 2019b.\nSina Ahmadi, John P. McCrae, Sanni Nimb, Fahad Khan, Monica Monachini, Bo-\nlette S. Pedersen, Thierry Declerck, Tanja Wissik, Andrea Bellandi, Irene Pisani,\nThomas Troelsgård, Sussi Olsen, Simon Krek, Veronika Lipp, Tamás Váradi,\nLászló Simon, András Gy˝orffy, Carole Tiberius, Tanneke Schoonheim, Yifat\nBen Moshe, Maya Rudich, Raya Abu Ahmad, Dorielle Lonke, Kira Kovalenko, Mar-\ngit Langemets, Jelena Kallas, Oksana Dereza, Theodorus Fransen, David Cillessen,\nDavid Lindemann, Mikel Alonso, Ana Salgado, José Luis Sancho, Rafael-J. Ureña-\nRuiz, Kiril Simov, Petya Osenova, Zara Kancheva, Ivaylo Radev, Ranka Stankovi´c,\nAndrej Perdih, and Dejan Gabrovšek. A Multilingual Evaluation Dataset for Mono-\nlingual Word Sense Alignment.\nIn Proceedings of the 12th Language Resource and\nEvaluation Conference (LREC 2020), Marseille, France, 2020a.\nSina Ahmadi, Sanni Nimb, John P. McCrae, and Nicolai H. Sørensen. Towards Auto-\nmatic Linking of Lexicographic Data: the case of a historical and a modern Danish\ndictionary. In The XIX EURALEX International Congress of the European Association\nfor Lexicography, Alexandroupolis, Greece, 2020b.\nSina Ahmadi, Mathieu Constant, Karën Fort, Bruno Guillaume, and John P. McCrae.\nConvertir le Trésor de la Langue Française en Ontolex-Lemon : un zeste de données liées.\nLIFT 2021 : Journées scientiﬁques de linguistique informatique, formelle & de terrain,\nDecember 2021a.\nSina Ahmadi, Atul Kr. Ojha, Shubhanker Banerjee, and John P. McCrae. NUIG at\nTIAD 2021: Cross-lingual Word Embeddings for Translation Inference. Shared Task\non Translation Inference Across Dictionaries, 2021b.\nCarole Tiberius, Simon Krek, Katrien Depuydt, Polona Gantar, Jelena Kallas, Iztok\nKosem, and Michael Rundell. Towards the ELEXIS data model: deﬁning a common\nvocabulary for lexicographic resources. Electronic lexicography in the 21st century\n(eLex 2021) Post-editing lexicography, page 91.\n\nBIBLIOGRAPHY\n205\nJulien Tissier, Christophe Gravier, and Amaury Habrard. Dict2vec: Learning word\nembeddings using lexical dictionaries. In Proceedings of the 2017 Conference on Em-\npirical Methods in Natural Language Processing, pages 254–263, 2017.\nAntonio Toral and Monica Monachini. Named entity Wordnet. In Proceedings of the\n6th International Conference on Language Resources and Evaluation. Citeseer, 2008.\nAntonio Toral, Monica Monachini, et al. SIMPLE-OWL: a generative lexicon ontology\nfor NLP and the semantic web. In Workshop on Cooperative Construction of Linguistic\nKnowledge Bases (AIIA 2007). Citeseer, 2007.\nDaniel Torregrosa, Mihael Arcan, Sina Ahmadi, and John P McCrae.\nTIAD 2019\nshared task: Leveraging knowledge graphs with neural machine translation for au-\ntomatic multilingual dictionary generation. Translation Inference Across Dictionaries,\n2019.\nTakashi Tsunakawa, Naoaki Okazaki, Xiao Liu, and Jun’ichi Tsujii.\nA Chinese-\nJapanese lexical machine translation through a pivot language. ACM Transactions\non Asian Language Information Processing (TALIP), 8(2):9, 2009.\nAlberto Ueda, Rodrygo LT Santos, Craig Macdonald, and Iadh Ounis. Structured\nﬁne-tuning of contextual embeddings for effective biomedical retrieval. In Proceed-\nings of the 44th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval, pages 2031–2035, 2021.\nDmitry Ustalov, Denis Teslenko, Alexander Panchenko, Mikhail Chernoskutov, Chris\nBiemann, and Simone Paolo Ponzetto. An unsupervised word sense disambigua-\ntion system for under-resourced languages. arXiv preprint arXiv:1804.10686, 2018.\nLaurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal\nof machine learning research, 9(11), 2008.\nGiannis Varelas, Epimenidis Voutsakis, Paraskevi Raftopoulou, Euripides GM Pe-\ntrakis, and Evangelos E Milios. Semantic similarity methods in WordNet and their\napplication to information retrieval on the web. In Proceedings of the 7th annual ACM\nInternational Workshop on Web Information and Data Management, pages 10–16, 2005.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in\nNeural Information Processing Systems, 30, 2017.\nViljami Venekoski and Jouko Vankka.\nFinnish resources for evaluating language\nmodel semantics. In Proceedings of the 21st Nordic Conference on Computational Lin-\nguistics, pages 231–236, 2017.\n\n206\nBIBLIOGRAPHY\nLeón Enrique Verdín-Armenta and Miriam Díaz-Rodríguez.\nTraductor de español a\nmetalenguaje semantico natural (translator from spanish to natural semantic metalan-\nguage). volume 13, pages 123–132. Universidad Autónoma Indígena de México,\n2017.\nAgustín\nVicente\nand\nIngrid\nL.\nFalkum.\nPolysemy.\nOxford\nUniversity\nPress,\n07\n2017.\ndoi:\n10.1093/acrefore/9780199384655.013.325.\nURL\nhttps://oxfordre.com/linguistics/view/10.1093/acrefore/9780199384655.001.\n0001/acrefore-9780199384655-e-325.\nMK Vijaymeena and K Kavitha.\nA survey on similarity measures in text mining.\nMachine Learning and Applications: An International Journal, 3(2):19–28, 2016.\nCarl Vikner and Per Anker Jensen. A semantic analysis of the english genitive. inter-\naction of lexical and formal semantics. Studia linguistica, 56(2):191–226, 2002.\nMarta Villegas, Maite Melero, Núria Bel, and Jorge Gracia. Leveraging RDF Graphs\nfor Crossing Multiple Bilingual Dictionaries.\nIn Nicoletta Calzolari (Conference\nChair), Khalid Choukri, Thierry Declerck, Marko Grobelnik, Bente Maegaard,\nJoseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceed-\nings of the Tenth International Conference on Language Resources and Evaluation (LREC\n2016), Paris, France, 2016. European Language Resources Association (ELRA). ISBN\n978-2-9517408-9-1.\nSoroush Vosoughi, Prashanth Vijayaraghavan, and Deb Roy. Tweet2vec: Learning\ntweet embeddings using character-level CNN-LSTM encoder-decoder. In Proceed-\nings of the 39th International ACM SIGIR conference on Research and Development in\nInformation Retrieval, pages 1041–1044, 2016.\nPJTM Vossen. EuroWordNet: general document. https://research.vu.nl/ws/ﬁles/\n77020259/EWNGeneral, 2002. Accessed: 2021-07-30.\nIvan Vuli´c, Simon Baker, Edoardo Maria Ponti, Ulla Petti, Ira Leviant, Kelly Wing,\nOlga Majewska, Eden Bar, Matt Malone, Thierry Poibeau, et al. Multi-SimLex: A\nlarge-scale evaluation of multilingual and crosslingual lexical semantic similarity.\nComputational Linguistics, 46(4):847–897, 2020a.\nIvan Vuli´c, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, and Anna Korhonen.\nProbing pretrained language models for lexical semantics. In Proceedings of the 2020\nConference on Empirical Methods in Natural Language Processing (EMNLP), pages 7222–\n7240, 2020b.\nDanqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu, and Xuan-Jing Huang. Het-\nerogeneous graph neural networks for extractive document summarization. In Pro-\nceedings of the 58th Annual Meeting of the Association for Computational Linguistics,\npages 6209–6219, 2020.\n\nBIBLIOGRAPHY\n207\nQuan Wang, Zhendong Mao, Bin Wang, and Li Guo. Knowledge graph embedding:\nA survey of approaches and applications. IEEE Transactions on Knowledge and Data\nEngineering, 29(12):2724–2743, 2017.\nNoah Webster and Rosalie J Slater. Noah Webster’s ﬁrst edition of an American dictionary\nof the English language. Foundation for American Christian Education San Francisco,\n1828.\nEline Westerhout. Deﬁnition extraction for glossary creation: a study on extracting deﬁni-\ntions for semi-automatic glossary creation in Dutch. Netherlands Graduate School of\nLinguistics, 2010.\nAnna Wierzbicka. Deﬁning emotion concepts. Cognitive science, 16(4):539–581, 1992.\nAnna Wierzbicka.\nSemantics: Primes and universals: Primes and universals.\nOxford\nUniversity Press, UK, 1996.\nMark D Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Apple-\nton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino\nda Silva Santos, Philip E Bourne, et al. The FAIR Guiding Principles for scientiﬁc\ndata management and stewardship. Scientiﬁc data, 3(1):1–9, 2016.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,\nAnthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Hug-\ngingface’s transformers: State-of-the-art natural language processing. arXiv preprint\narXiv:1910.03771, 2019.\nLingfei Wu, Yu Chen, Kai Shen, Xiaojie Guo, Hanning Gao, Shucheng Li, Jian Pei,\nand Bo Long. Graph neural networks for natural language processing: A survey.\narXiv preprint arXiv:2106.06090, 2021.\nZhibiao Wu and Martha Palmer. Verb semantics and lexical selection. arXiv preprint\ncmp-lg/9406033, 1994.\nZonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu\nPhilip. A comprehensive survey on graph neural networks. IEEE transactions on\nneural networks and learning systems, 32(1):4–24, 2020.\nYikun Xian, Zuohui Fu, Shan Muthukrishnan, Gerard De Melo, and Yongfeng Zhang.\nReinforcement knowledge graph reasoning for explainable recommendation. In\nProceedings of the 42nd international ACM SIGIR conference on research and development\nin information retrieval, pages 285–294, 2019.\nWenpu Xing and Ali Ghorbani. Weighted pagerank algorithm. In Proceedings. Second\nAnnual Conference on Communication Networks and Services Research, 2004., pages 305–\n314. IEEE, 2004.\n\n208\nBIBLIOGRAPHY\nNianwen Xue and Martha Palmer. Calibrating features for semantic role labeling. In\nProceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,\n2004.\nQian Yang, Zhouyuan Huo, Dinghan Shen, Yong Cheng, Wenlin Wang, Guoyin Wang,\nand Lawrence Carin. An end-to-end generative architecture for paraphrase gener-\nation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 3132–3142, 2019.\nHaipeng Yao, Huiwen Liu, and Peiying Zhang. A novel sentence similarity model\nwith word embedding based on convolutional neural network. Concurrency and\nComputation: Practice and Experience, 30(23):e4415, 2018.\nWenlin Yao, Xiaoman Pan, Lifeng Jin, Jianshu Chen, Dian Yu, and Dong Yu. Connect-\nthe-Dots: Bridging Semantics between Words and Deﬁnitions via Aligning Word\nSense Inventories. arXiv preprint arXiv:2110.14091, 2021.\nMeng Ye and Yuhong Guo.\nZero-shot classiﬁcation with discriminative semantic\nrepresentation learning. In Proceedings of the IEEE conference on computer vision and\npattern recognition, pages 7140–7148, 2017.\nEric Yeh, Daniel Ramage, Christopher D Manning, Eneko Agirre, and Aitor Soroa.\nWikiWalk: random walks on Wikipedia for semantic relatedness. In Proceedings of\nthe 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-\n4), pages 41–49, 2009.\nSoYeop Yoo and OkRan Jeong.\nAn intelligent chatbot utilizing BERT model and\nknowledge graph. Journal of Society for e-Business Studies, 24(3), 2020.\nMinghe Yu, Guoliang Li, Dong Deng, and Jianhua Feng. String similarity search and\njoin: a survey. Frontiers of Computer Science, 10(3):399–417, 2016.\nAyesha Zafar. Developing Urdu Wordnet using the merge approach. Society for Natu-\nral Language Processing, Pakistan (SNLP), 2012.\nFrancesco Zamblera. Computational NSM: a PROLOG-based notation. Online]. SÍN-\nTESIS CURRICULAR, 2010.\nTorsten Zesch, Iryna Gurevych, and Max Mühlhäuser.\nAnalyzing and accessing\nWikipedia as a lexical semantic resource. Data Structures for Linguistic Resources\nand Applications, 197205, 2007.\nYang Zhao, Lu Xiang, Junnan Zhu, Jiajun Zhang, Yu Zhou, and Chengqing Zong.\nKnowledge graph enhanced neural machine translation via multi-task learning on\nsub-entity granularity. In Proceedings of the 28th International Conference on Computa-\ntional Linguistics, pages 4495–4505, 2020.\n\nBIBLIOGRAPHY\n209\nXin Zheng, Zhiyong Wu, Helen Meng, Weifeng Li, and Lianhong Cai. Feature learn-\ning with Gaussian restricted Boltzmann machine for robust speech recognition.\narXiv preprint arXiv:1309.6176, 2013.\nJie Zhou and Wei Xu. End-to-end learning of semantic role labeling using recurrent\nneural networks.\nIn Proceedings of the 53rd Annual Meeting of the Association for\nComputational Linguistics and the 7th International Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 1127–1137, 2015.\nYi Zhou and Danushka Bollegala. Learning sense-speciﬁc static embeddings using\ncontextualised word embeddings as a proxy. arXiv preprint arXiv:2110.02204, 2021.\nChenguang Zhu, William Hinthorn, Ruochen Xu, Qingkai Zeng, Michael Zeng, Xue-\ndong Huang, and Meng Jiang. Boosting factual correctness of abstractive summa-\nrization with knowledge graph. arXiv e-prints, pages arXiv–2003, 2020.\nGanggao Zhu and Carlos A Iglesias. Computing semantic similarity of concepts in\nknowledge graphs. IEEE Transactions on Knowledge and Data Engineering, 29(1):72–\n85, 2016.\nMichael Zock and Chris Biemann. Comparison of Different Lexical Resources With\nRespect to the Tip-of-the-Tongue Problem. Journal of Cognitive Science, 21(2):193–252,\n2020.\nMichael Zock and Slaven Bilac. Word lookup on the basis of associations: from an\nidea to a roadmap. In Proceedings of the Workshop on Enhancing and Using Electronic\nDictionaries, pages 29–35, 2004.",
    "pdf_filename": "Monolingual alignment of word senses and definitions in lexicographical resources.pdf"
}