{
    "title": "Sufficient Invariant Learning for Distribution Shift",
    "abstract": "Learning robust models under distribution shifts between training and test datasets is a fundamental challenge in machine learning. While learning invariant features across environments is a popular approach, it often assumes that these features are fully observed in both training and test sets—a condition frequently violated in practice. When models rely on invariant features absent in the test set, their robustness in new environments can deteriorate. To tackle this problem, we in- troduce a novel learning principle called the Sufficient Invariant Learning (SIL) framework, which focuses on learning a sufficient subset of invariant features rather than relying on a single feature. After demonstrating the limitation of existing in- variant learning methods, we propose a new algorithm, Adaptive Sharpness-aware Group Distributionally Robust Optimization (ASGDRO), to learn diverse invariant features by seeking common flat minima across the environments. We theoretically demonstrate that finding a common flat minima enables robust predictions based on diverse invariant features. Empirical evaluations on multiple datasets, including our new benchmark, confirm ASGDRO’s robustness against distribution shifts, highlighting the limitations of existing methods. 1 Introduction Figure 1: Left visualizes the images that contain a spurious feature, ZNI, and multiple invariant fea- tures, ZTail, ZBeak, and ZFeet in training environment Etr. If the model focuses on the ZNI (green back- ground), then it fails to predict correctly in the test environment E\\Etr (Right). Even if the model cap- tures the invariant features in Etr, e.g., ZFeet, it still fails to predict correctly when the invariant features are not present (Gray). However, it is possible to predict correctly if we learn diverse invariant fea- tures sufficiently, ZFeet, ZTail, and ZBeak. With SIL (Red), the model predicts the label using remaining invariant features, ZTail and ZBeak even though ZFeet is not present in the test environment E\\Etr. Machine learning models typically assume that train- ing and test data are drawn from the same distribu- tion. However, in real-world scenarios, this assump- tion is often violated whenever the training and test distribution differ, known as distribution shifts. In these cases, model performance tends to degrade, highlighting the need to develop models that are robust to distribution shifts for reliable outcomes. To train models robust to distribution shift, invari- ant learning focuses on identifying latent features that remain constant across environments, referred to as invariant features. These features enable con- sistent predictions across environments by discour- aging models from relying on spurious features (Ar- jovsky et al., 2019) – features that are not preserved across changes in environments or groups1. For ex- ample, in domain generalization tasks (Koh et al., 2021; Gulrajani and Lopez-Paz, 2020), the goal is to learn invariant features that consistently predict 1In this paper, the terms environment and domain are used interchangeably. A group refers to a subpopulation corresponding to a particular label within a specific environment. arXiv:2210.13533v3  [cs.LG]  19 Nov 2024",
    "body": "Sufficient Invariant Learning for Distribution Shift\nTaero Kim1\nSubeen Park1\nSungjun Lim1\nYonghan Jung2\nKrikamol Muandet3\nKyungwoo Song1\n1Yonsei University\n2Purdue University\n3CISPA Helmholtz Center for Information Security\nAbstract\nLearning robust models under distribution shifts between training and test datasets\nis a fundamental challenge in machine learning. While learning invariant features\nacross environments is a popular approach, it often assumes that these features\nare fully observed in both training and test sets—a condition frequently violated\nin practice. When models rely on invariant features absent in the test set, their\nrobustness in new environments can deteriorate. To tackle this problem, we in-\ntroduce a novel learning principle called the Sufficient Invariant Learning (SIL)\nframework, which focuses on learning a sufficient subset of invariant features rather\nthan relying on a single feature. After demonstrating the limitation of existing in-\nvariant learning methods, we propose a new algorithm, Adaptive Sharpness-aware\nGroup Distributionally Robust Optimization (ASGDRO), to learn diverse invariant\nfeatures by seeking common flat minima across the environments. We theoretically\ndemonstrate that finding a common flat minima enables robust predictions based\non diverse invariant features. Empirical evaluations on multiple datasets, including\nour new benchmark, confirm ASGDRO’s robustness against distribution shifts,\nhighlighting the limitations of existing methods.\n1\nIntroduction\nFigure 1: Left visualizes the images that contain\na spurious feature, ZNI, and multiple invariant fea-\ntures, ZTail, ZBeak, and ZFeet in training environment\nEtr. If the model focuses on the ZNI (green back-\nground), then it fails to predict correctly in the test\nenvironment E\\Etr (Right). Even if the model cap-\ntures the invariant features in Etr, e.g., ZFeet, it still\nfails to predict correctly when the invariant features\nare not present (Gray). However, it is possible to\npredict correctly if we learn diverse invariant fea-\ntures sufficiently, ZFeet, ZTail, and ZBeak. With SIL\n(Red), the model predicts the label using remaining\ninvariant features, ZTail and ZBeak even though ZFeet\nis not present in the test environment E\\Etr.\nMachine learning models typically assume that train-\ning and test data are drawn from the same distribu-\ntion. However, in real-world scenarios, this assump-\ntion is often violated whenever the training and test\ndistribution differ, known as distribution shifts. In\nthese cases, model performance tends to degrade,\nhighlighting the need to develop models that are\nrobust to distribution shifts for reliable outcomes.\nTo train models robust to distribution shift, invari-\nant learning focuses on identifying latent features\nthat remain constant across environments, referred\nto as invariant features. These features enable con-\nsistent predictions across environments by discour-\naging models from relying on spurious features (Ar-\njovsky et al., 2019) – features that are not preserved\nacross changes in environments or groups1. For ex-\nample, in domain generalization tasks (Koh et al.,\n2021; Gulrajani and Lopez-Paz, 2020), the goal is\nto learn invariant features that consistently predict\n1In this paper, the terms environment and domain are used interchangeably. A group refers to a subpopulation\ncorresponding to a particular label within a specific environment.\narXiv:2210.13533v3  [cs.LG]  19 Nov 2024\n\nlabels across multiple environments. Assuming that the learned invariant features persist in all unseen\nenvironments, they guarantee the model’s generalization performance on new environments (Muandet\net al., 2013; Li et al., 2018). Similarly, learning models robust to subpopulation shifts is essential in\ncases of severe imbalances between groups. In this scenario, invariant features play a crucial role in\naddressing the challenges faced by underrepresented groups, which are disproportionately impacted\nby strong spurious correlations (Sagawa et al., 2019; Yao et al., 2022; Izmailov et al., 2018).\nHowever, learning all possible invariant features is challenging in practice because most existing\ninvariant learning approaches focus on eliminating spurious correlations, which can be achieved by\nleveraging only a subset of the invariant features present in the training environments. Moreover,\ninvariant features identified by the model may not be observable in unseen environments (Guo et al.,\n2024; Tsymbal, 2004). This underscores the importance of learning a sufficient number of invariant\nfeatures, rather than relying on a single invariant feature. To address this, we introduce a novel\napproach called Sufficient Invariant Learning (SIL), which focuses on learning a sufficient set of\ninvariant features for improved generalization. For example, consider the scenario depicted in Figure\n1. Training environments for an image of a bird may include multiple invariant features, such as\nZTail, ZBeak and ZFeet. If a model relies on a single invariant feature, say ZFeet, it may fail to classify\nan image of the bird if the feature is unobservable (e.g., the bird’s feet are hidden underwater). In\ncontrast, if the model uses a sufficiently diverse set of invariant features (e.g., all of ZTail, ZBeak and\nZFeet), it can still classify the image correctly as long as one or more of the other invariant features\nare present. This highlights the robustness and generalization benefits of learning a sufficient number\nof invariant features.\nIn this study, we develop the SIL framework and demonstrate that leveraging sufficiently diverse\ninvariant features through SIL enhances model robustness. As a method for SIL, we propose Adaptive\nSharpness-aware Group Distributionally Robust Optimization (ASGDRO). We show that ASGDRO\nattains SIL by effectively learning diverse invariant features while successfully eliminating spurious\ncorrelations. Furthermore, we show that the ability of ASGDRO to perform SIL is due to its\nconvergence to a common flat minima (Foret et al., 2020) across diverse environments. Through\nempirical evaluations on a toy example and our newly introduced SIL Benchmark dataset, we show\nthat existing invariant learning algorithms fall short in capturing diverse invariant features, whereas\nASGDRO successfully achieves SIL. By learning a wide range of invariant features sufficiently,\nASGDRO exhibits robust generalization performance under various distribution shift scenarios, as\nevidenced by extensive experiments involving subpopulation and domain shifts.\n2\nRelated Works\n2.1\nInvariant Learning for Distribution Shift\nThe standard approach to modern deep learning is Empirical Risk Minimization (ERM) (Vapnik,\n1999), which minimizes the average training loss. However, ERM may not guarantee robustness in\ndistribution shifts. To improve the generalization performance in distribution shift, Group Distribu-\ntionally Robust Optimization (GDRO) minimizes the worst group loss for each iteration to alleviate\nspurious correlations (Sagawa et al., 2019). Meanwhile, various studies utilize loss gradient for\ninvariant learning. For example, Arjovsky et al. (2019) minimizes the gradient norm of the fixed\nclassifier across environments. Other research matches the loss gradient for each environment to find\ninvariant features (Shi et al., 2021; Rame et al., 2022a). Furthermore, balancing the representation\nusing selective sampling with mix-up samples (Yao et al., 2022) or re-training the classifier on a\nsmall balanced set (Kirichenko et al., 2022) show the effectiveness of learning a robust model. Some\nstudies enhance generalization by combining invariant learning algorithms with feature extractors\nwith rich representations (Zhang et al., 2022; Chen et al., 2024a; Zhang and Bottou, 2023).\nUnder the assumption that invariant features in the training environment also exist in the test en-\nvironment, invariant learning theoretically guarantees an optimal predictor (Rojas-Carulla et al.,\n2018). However, we argue that existing invariant learning algorithms do not learn sufficiently diverse\ninvariant features, and they still suffer from significant performance drops in test environments where\nsome invariant features are unobserved (Guo et al., 2024; Tsymbal, 2004). To remedy this problem,\nwe introduce the novel framework, SIL, and guarantee the generalization ability for diverse invariant\nfeatures. Through experiments on the newly proposed benchmark in this paper, as well as on existing\nbenchmarks for evaluating model robustness to distribution shifts (Gulrajani and Lopez-Paz, 2020;\n2\n\nKoh et al., 2021), we demonstrate that our novel algorithm designed for SIL leads to more robust\npredictions.\n2.2\nFlatness and Generalization\nVarious studies argue that finding flat minima improves generalization performance (Keskar et al.,\n2016; Neyshabur et al., 2017). As a result, many algorithms emerge to find flat minima. Sharpness-\naware Minimization (SAM) (Foret et al., 2020) finds flat minima by minimizing the maximum\ntraining loss of neighborhoods for the current parameter within ρ radius ball on the parameter space.\nMoreover, Adaptive SAM (ASAM) introduces the normalization operator to get a better correlation\nbetween flatness and the model’s generalization ability by avoiding the scale symmetries between\nthe layers (Kwon et al., 2021). Stochastic Weight Averaging (SWA) also reaches the flat minima by\naveraging the weight (Izmailov et al., 2018). Under the IID setting, these approaches (Foret et al.,\n2020; Kwon et al., 2021; Izmailov et al., 2018) successfully decrease the generalization gap.\nCha et al. (2021) shows that optimizing the model towards flatter minima through weight averaging\nimproves domain generalization performance. However, it is still necessary to verify whether models\noperate robustly through weight averaging when strong spurious correlations exist. Indeed, some\nstudies demonstrate that weight averaging methods may still not be robust in certain subpopulation\nshift tasks (Rame et al., 2022b). Zhang et al. (2023) also shows that flat minima make models more\nrobust to noise present in instances. However, our study aims to show the effectiveness of flatness\nin more extreme distribution shift settings, such as subpopulation shift and domain generalization.\nSpringer et al. (2024) presents that when easy-to-learn and hard-to-learn features coexist, models\ntrained by SAM learn more balanced representations. This aligns with our observations, and we\naim to achieve SIL by successfully removing spurious correlations and learning sufficiently diverse\ninvariant features by introducing the constraints related to flatness for the robust model in various\ndistribution shift settings.\n3\nMethodology\n3.1\nProblem Setting\nLet X denote the input space, Y the label space, Z the feature space, and Θ the parameter space.\nConsider a set of environments E, where, for each environment e ∈E, there exists a dataset\nDe = {(Xe, Y e)}ne with the input data Xe ∈X, corresponding labels Y e ∈Y, and ne as the\nnumber of data points in environment e. We assume a set of features Z = (ZI, ZNI) ⊂Z, where ZI\nis a set of invariant features satisfying the following invariance condition and ZNI represents a set of\nspurious features whose correlation with Y e varies depending on the environment e (Arjovsky et al.,\n2019; Creager et al., 2021; Krueger et al., 2021):\nDefinition 1 (Invariance Condition). ZI is a set of invariant features satisfying\nE[Y e|ZI] = E[Y e′|ZI]\nfor all e, e′ ∈Etr,\n(1)\nEtr ⊂E denotes the set of environments in training dataset.\nIn fact, for training environments Etr, the invariance condition holds for any subset ˆZI ⊆ZI. In\nparticular, we denote ZI\ni as a singleton set with i–th element of ZI, where i ∈{1, . . . , p} and p denotes\nthe number of invariant features. For example, in Figure 1, consider a task to classify the images of\nbirds into water birds or land birds, ZI = {ZBeak, ZTail, ZFeet} with p = 3, ZNI = {ZBackground} and\nZI\n1 = {ZBeak}.\nSuppose a model f = h ◦g parametrized by θ = (θg, θh) ∈Θ, where g : X →Z is an encoder with\nparameters θg and h : Z →Y is a classifier with parameters θh. Let Re(θ) = E[ℓ(f(Xe; θ), Y e)]\ndenote the risk of a model f in environment e, where ℓdenotes a loss function. Invariant learning\nseeks to minimize the maximum risk across environments,\nmin\nθ\nmax\ne∈E Re(θ),\nand to train models that have robust performance and generalization ability for unseen environments\nby learning invariant feature ZI (Arjovsky et al., 2019; Sagawa et al., 2019; Creager et al., 2021;\n3\n\nKrueger et al., 2021). In particular, given ZI, Rojas-Carulla et al. (2018) demonstrate that learning\noptimal classifier θ∗\nh, which is based on all invariant features in ZI, leads to robust model predictions,\nθ∗\nh ∈min\nθh max\ne∈E Re(θh),\n(2)\nwhere Re(θh) = [ℓ(h(ZI; θh), Y e)], assuming that the invariance condition holds for all e ∈E. In\nthis work, however, we focus on situations where the optimal classifier for Equation 2 is not unique,\nfor instance, when any classifier that depends on a subset of ˆZI remains optimal. To address the\nchallenges in such scenarios, we propose a framework called Sufficient Invariant Learning (SIL).\n3.2\nSufficient Invariant Learning\nIn the classification task, we concentrate on the fact that any subset of ZI allows a model to minimize\nthe maximum risk across environments e ∈Etr. In the previous example of Figure 1, the model’s\nclassifier may utilize only ZFeet to distinguish between water birds and land birds, or it may employ\nall ZI\ni simultaneously in Etr. Consequently, a classifier that satisfies Equation 2 is not unique, and\nsince the optimal encoder is also not unique when derived from the optimal classifier (Arjovsky et al.,\n2019), Equation 2 is similarly not unique. To differentiate among various prediction mechanisms that\nleverage invariant features in ZI, we define the invariant mechanism as follows:\nDefinition 2 (Invariant Mechanism). For an encoder gθIg parameterized by θI\ng and a classifier hθI\nh\nparameterized by θI\nh, the invariant mechanism θI = (θI\ng, θI\nh) ∈Θ is a tuple for a subset ˆZI ⊆ZI\nsatisfying the followings:\n• Condition 1:\nhθI\nh : ˆZI 7→Y e,\n∀e ∈Etr.\n• Condition 2:\nθI ∈argminθ maxe∈Etr Re(θ).\nΘI ⊂Θ denotes a collection of all invariant mechanisms.\nSpecifically, we denote the invariant mechanism that utilizes only ZI\ni as θI\ni, for i = {1, . . . p}.\nAs a result, invariant mechanisms that focus solely on a specific invariant feature θI\ni may encounter\nchallenges in producing robust predictions when the part of the input corresponding to that feature\nis distorted by noise, absent due to cropping, or occluded by environmental factors. Accordingly,\nthe non-uniqueness of the invariant mechanism suggests that training the encoder based on classifier\ninvariance (Arjovsky et al., 2019; Ahuja et al., 2021) or refining it to capture richer information\n(Zhang et al., 2022; Chen et al., 2024a) can benefit from additional regularization on the invariant\nmechanism. This observation also implies that robust optimization methods designed to satisfy\nEquation 2 over Etr (Duchi et al., 2016; Oren et al., 2019; Sagawa et al., 2019) have an avenue for\nachieving enhanced generalization performance.\nWe argue that training more robust models requires ensuring generalization performance across a\nsufficiently diverse set of invariant features. To achieve this, we introduce a novel invariant learning\nframework, termed Sufficient Invariant Learning (SIL):\nDefinition 3 (Sufficient Invariant Learning). Sufficient Invariant Learning refers to identify θSI such\nthat\nθSI ∈argmin\nθ\nmax\ne∈E Re(θ),\ns.t.\nθSI\nh ∈argmin\nθh\nmax\ne∈E max\nˆ\nZI⊆ZI E[ℓ(hθh( ˆZI), Y e)].\nSIL aims to train a classifier that operates robustly not only across all environments but also when it\nis provided with only a subset ˆZI. SIL ensures that the model leverages sufficiently diverse invariant\nfeatures consistently in making predictions, assuming that a model trained on the target task has\nalready learned sufficient representations of the invariant features (Kirichenko et al., 2022). The\nmost challenging aspect of achieving SIL is that providing individually intervened data on each ˆZI to\nperform SIL is costly, and situations where defining ˆZI individually is ambiguous are common. To\naddress this, we propose ASGDRO, a novel method motivated by the perspective of the loss surface\nand demonstrates the effectiveness of finding common flat minima for SIL.\n4\n\nAlgorithm 1 Adaptive Sharpness-aware Group Distributionally Robust Optimization (ASGDRO)\nInput: Training dataset De\ntr = {(Xe, Y e)} for e ∈Etr, Radius ρ > 0, Learning rate η > 0, Robust step size\nγ > 0, The number of environments |Etr|\n1: Initialization: θ0; λ(0)\ne\n= 1/|Etr|, e = 1, . . . , |Etr|;\n2: for t = 1, 2, 3, . . . do\n3:\nCompute training loss Re(θt);\n4:\nCompute ϵ∗\ne = ρ\nT 2\nθ ∇Re(θt)\n∥Tθ∇Re(θt)∥;\n5:\nGradient ascent: θ∗\nt = θt + ϵ∗\ne;\n6:\nFind loss for each environment Re(θ∗\nt );\n7:\nCompute ˜λ(t)\ne\n= λ(t−1)\ne\nexp(γRe(θ∗\nt )) respectively;\n8:\nUpdate λ(t)\ne\n= ˜λ(t)\ne /P\ne ˜λ(t)\ne ;\n9:\nCompute RASGDRO(θt) = P\ne λ(t)\ne Re(θ∗\nt );\n10:\nCompute ∇RASGDRO(θt) = P\ne λ(t)\ne ∇Re(θ∗\nt );\n11:\nReturn to θt;\n12:\nUpdate the parameters: θt+1 = θt −η∇RASGDRO(θt);\n13: end for\n3.3\nASGDRO: Adaptive Sharpness-aware Group Distributionally Robust Optimization\nIn the literature on model merging and multi-task learning (Ilharco et al., 2022; Wortsman et al.,\n2022; Ainsworth et al.; Ramé et al., 2023), it is often assumed that a robust model across all tasks lies\nwithin the linear interpolation of models that perform well on each individual task. Inspired by this\nobservation, we consider θI\ni as a model that performs well on a single task, and we hypothesize that\nθSI exists within the linear interpolation of these mechanisms. Without loss of generality, subsets that\nare not singletons can be equivalently represented as an interpolation of singleton invariant features\nZI\ni. Hence, for the remainder of this work, we restrict our consideration to ZI\ni and ZI (Appendix A.2).\nThe key difference from previous studies is that we evaluate each task solely on the same dataset.\nTherefore, as discussed in Section 3.2, different invariant mechanisms are expected to have similar\nrisks,\nRe(θSI) −Re(θI\ni) ≈0\nfor all e ∈Etr.\n(3)\nA challenge for SIL is that we do not have access to information about θI\ni. However, based on the\nobservation in Neyshabur et al. (2020) that different models trained from the same pre-trained model\nlie in the same loss basin, we assume that models located on the linear path between θSI and θI\ni\nalso exhibit similar risk. Therefore, θSI should guarantee low risks within a ball of radius at least\nmaxi ||θI\ni −θSI||, denoted as ρ, in Euclidean space. Introducing a perturbation ϵe := θI\ni −θSI, we\nobtain the following condition for the risk of θI\ni:\nmax\ni∈{1,...,p} Re(θI\ni) = max\n||ϵe||≤ρ Re(θSI + ϵe).\n(4)\nFrom our motivation, ρ is a hyper-parameter adjusting the model class of θI\ni deviated from θSI.\nMoreover, according to Definition 1, all θI\ni should exhibit robust performance across environments\ne ∈Etr. Finally, we propose a novel objective function named Adaptive Sharpness-aware Group\nDistributionally Robust Optimization (ASGDRO), which is formulated as follows:\nmax\ne∈Etr max\n||ϵe||≤ρ Re(θ + ϵe).\n(5)\nIn the following sections, we theoretically show that ASGDRO not only learns invariant features but\nalso balances the learning of invariant mechanisms, thereby achieving SIL. Also, we demonstrate that\nASGDRO finds the common flat minima across environments, leading to SIL.\n3.4\nSIL and Common Flat Minima\nWe demonstrate that ASGDRO trains the model to achieve SIL by showing that ASGDRO balances\nthe use of invariant mechanisms.\nTheorem 1 (Sufficient Invariant Mechanism). Let θI\nλ be a convex combination of θI\ni, where λ is a\np-dimensional vector. Consider mean-squared error as the loss function. Then, given ZI = (1, . . . , 1)\n5\n\nwith |Z| = p,\nλ∗= argmin\nλ\nmax\ne∈Etr max\n||ϵ||≤ρ Re(θI\nλ + ϵ)\n= argmin\nλ\nmax\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ||λ|| · ||∇Re(θI\nλ)||\n\u0003\n(6)\n= argmin\nλ\n||λ|| = (1\np, . . . , 1\np)\nwhere || · || denotes L2 norm.\nRefer to Appendix A.4 for the proof. Theorem 1 states that ASGDRO ensures that even when\ninvariant features contribute equally to the output, the model does not favor a simple solution focusing\non a single invariant feature. Instead, it learns a diverse range of invariant mechanisms. As shown in\nEquation 6, this regularization effect arises through the gradient norm ||∇Re(θ)||.\nProposition 1 (Common Flat Minima). By the Taylor expansion,\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe) ≈max\ne∈E [Re(θ) + ρ||∇Re(θ)||].\n(7)\nASGDRO leads to a regularization of the gradient norm, Re, ||∇Re(θ)||, across environments, which\ndrives the model to converge to common flat minima.\nRefer to Appendix A.5 for proof. As demonstrated in (Zhao et al., 2022), small ||∇Re(θ)|| indicates\nflat minima. We also demonstrate this property empirically in Figure 5 and Appendix A.11 Finally,\nwe argue that finding common flat minima encourages the model to learn sufficiently diverse invariant\nmechanisms. Moreover, this aligns with existing studies in IID settings, which suggest that flatter\nminima improve the generalization performance of models (Foret et al., 2020; Kwon et al., 2021;\nKeskar et al., 2016). Additionally, we demonstrate in Appendix A.5 that ASGDRO successfully\neliminates the spurious feature Ze while effectively learning the invariant feature.\n3.5\nImplementation of ASGDRO\nFrom Foret et al. (2020), maximum value of inner term in Equation 5 is approximated when ϵe =\nρ ∇Re(θ)\n∥∇Re(θ)∥. However, Kwon et al. (2021) demonstrate that by introducing the normalization matrix\nTθ, which removes the scale symmetry present on the loss surface, the correlation between flatness\nand generalization performance is strengthened. ASGDRO also adopts the same Tθ, and modified\nobjective function is as follows:\nRASGDRO(θ) = max\ne∈Etr Re(θ + ϵ∗\ne),\n(8)\nwhere ϵ∗\ne = ρ T 2\nθ ∇Re(θ)\n∥Tθ∇Re(θ)∥is adversarial perturbation for each environment e.\nTo address the instability in training that arises from the optimization approach of selecting only\nthe worst environment at each step, we adopt an alternative gradient-based optimization algorithm\ninspired by GDRO (Sagawa et al., 2019). We modify the objective function of ASGDRO into the\nform of linear interpolation across environments and also update their coefficients:\nmax\ne∈Etr Re(θ + ϵ∗\ne) =\nmax\nP\ne λe=1,λe≥0\nX\ne∈Etr\nλeRe(θ + ϵ∗\ne),\n(9)\nwhere λe is the weight imposed on adversarial perturbed loss for each environment. Finally, we\nupdate our model parameter from the current parameter θt as follows:\nθt −η∇RASGDRO(θ) = θt −η\nX\ne∈Etr\nλ(t)\ne ∇Re(θt + ϵ∗\ne),\n(10)\nwhere η denote the learning rate and λ(t)\ne\ndenote the weight imposed on each environment loss at\ntime step t. Refer to Algorithm 1 for the details.\n6\n\nFigure 2: Sufficient Invariant Learning and Common Flat Minima In (a-1) and (a-2), two axes, θI\n1 and θI\n2,\nrepresent the invariant directions of parameters corresponding to each invariant mechanism respectively. The red\ncircle indicates the area bound by ρ for measuring flatness in ASGDRO. (b-1) and (b-2) show that when Env 2\nhas sharp minima in the direction of θI\n1, GDRO still converges, but ASGDRO does not have any optimal point\ndue to the sharpness of θI\n1. However, in (c-1) and (c-2) when both invariant directions of Env 2 as well as Env\n1 are flat, ASGDRO has an optimal point and prefers to converge. That is, ASGDRO learns diverse invariant\nfeatures sufficiently.\n4\nExperiments\n4.1\nToy Exmaple\nWe demonstrate through a toy example that the representative invariant learning algorithm GDRO\nSagawa et al. (2019) fails to learn diverse invariant mechanisms, whereas ASGDRO successfully\nachieves SIL by encouraging the model to converge to the common flat minima (Figure 2). First, we\nassume that we know two different directions corresponding to the different invariant mechanism θI\n1\nand θI\n2, which learns different invariant features, ZI\n1 and ZI\n2, respectively. We define the loss surface\nof each environment e following a Gaussian function with respect to θI\n1 and θI\n2:\nG(θ) =\n1\n2π\np\n|Σ|\nexp\n\u0012\n−1\n2(θ −µ)T Σ−1(θ −µ)\n\u0013\n,\n(11)\nwhere\nθ =\n\u0014\nθI\n1\nθI\n2\n\u0015\n, µ(e) =\n\u0014\nµ1\nµ2\n\u0015\n, Σ(e) =\n\u0014\nσ11σ12\nσ21σ22\n\u0015\n.\nTo make losses greater than 0, we subtracted G(θ) from its maximum value. As a result, we define\nthe loss surface corresponding to the two environments, each with a minimum value of 0, as follows:\nRe=1(θ) = max\nθ\nG(θ; µ(1), Σ(1)) −G(θ; µ(1), Σ(1))\n(12)\nRe=2(θ) = max\nθ\nG(θ; µ(2), Σ(2)) −G(θ; µ(2), Σ(2))\n(13)\nNow, we create sharp or flat minima in a specific direction by adjusting the covariance matrix Σ(e).\nIn this example, we consider a fixed situation where both e = 1 and e = 2 have flat minima with\nrespect to θI\n2. When Re=1(θ) always has flat minima in the direction of θI\n1, we aim to observe how\nthe loss Robj corresponding to each objective function changes depending on whether θI\n2 has sharp\nor flat minima (a-1 and a-2 in Figure 2). The parameters that we use to generate the toy examples are\nas follows:\nEnv 1 (e = 1) : µ =\n\u0014\n−2.0\n0.0\n\u0015\n, Flat Σ =\n\u0014\n1.5\n0.0\n0.0\n2.0\n\u0015\n(14)\nEnv 2 (e = 2) : µ =\n\u0014\n2.0\n0.0\n\u0015\n,\nSharp Σ =\n\u0014\n1.5\n0.0\n0.0\n0.05\n\u0015\n(15)\nWe evaluate each algorithm through the loss surface in each direction (second and third columns of\nFigure 2). When Env 2 exhibits sharpness for θI\n1 (first row of Figure 2), it indicates that learning the\ninvariant feature corresponding to θI\n1 may result in a large generalization gap (Keskar et al., 2016).\nHowever, GDRO does not incorporate regularization on flatness and only considers the loss at the\ncurrent parameter, allowing convergence to a sharp solution. From Theorem 1, it implies the large\ngradient norm, and this situation does not constitute successful SIL. In contrast, ASGDRO, which\ntakes into account the loss in neighboring parameters, avoids sharp regions for θI\n1 (b-1 and c-1 in\nFigure 2).\n7\n\nFigure 3: Overview of H-CMNIST. There are three features, color and shape (invariant features, ZI =\n{ZColor, ZShape}) and box position (spurious feature, ZNI = {ZBP}). The ratio of ZBP is flipped between the train\nand test set. The test set consists of two testbeds, one for evaluating whether learning invariant features and the\nother for evaluating whether learning sufficiently diverse invariant features.\nWhen Env 2 is flat for θI\n1 (second row in Figure 2), we say that the model performs SIL if it converges\ninto the common flat minima between Env 1 and Env 2. However, GDRO has the same loss at the\noptimal point in this situation as in the previous case, indicating that GDRO does not specifically\nregularize the model to perform SIL. On the other hand, ASGDRO, by accounting for common flat\nminima, identifies an optimal parameter that promotes learning of diverse invariant mechanisms (b-2\nand c-2 in Figure 2). As a result, by considering flatness, the model performs SIL and is expected to\nmake robust predictions in unseen environments by leveraging multiple invariant features.\n4.2\nHeterogenous ColoredMNIST\nTestBed 1\nTestBed 2\nSpu & Inv\nInv\nSpu & Shape\nShape\nERM\n97.11 ± 3.44\n98.75 ± 1.19\n34.64 ± 9.90\n57.41 ± 2.58\nASAM\n98.57 ± 1.21\n98.12 ± 1.74\n34.78 ± 8.41\n57.07 ± 1.91\nGDRO\n99.95 ± 0.07\n99.92 ± 0.08\n57.53 ± 2.11\n61.44 ± 1.03\nASGDRO\n99.88 ± 0.11\n99.83 ± 0.12\n66.62 ± 5.61\n69.17 ± 6.19\nTable 1: H-CMNIST Results. TestBed1 evaluates\nwhether the model learns easy invariant feature ZColor,\nand TestBed2 evaluates the ability to learn additional\ninvariant feature ZShape.\nBy finding the common flat minima, ASGDRO\nlearns diverse invariant features. To demonstrate\nthis, we propose Heterogeneous ColoredMNIST\n(H-CMNIST), a new dataset designed to evalu-\nate whether the model learns diverse invariant\nmechanisms sufficiently (Figure 3). H-CMNIST\nevaluate whether the remaining invariant fea-\nture is additionally learned by the algorithm,\nassuming that the model has already learned one\ninvariant feature.\nH-CMNIST includes two invariant features, the color ZI\n1 = {Zcolor} and shape of digits ZI\n2 =\n{Zshape}, and one spurious feature, the position of the box (BP) ZNI = {ZBP}. That is, each class has\nits own color and shape. Using BP, we construct two environments, Top Left (Env 0) and Bottom\nRight (Env 1). It simplifies the situations where spurious correlations occur (Sagawa et al., 2019;\nDeGrave et al., 2021). Specifically, in the training set, 95% of Left Top BP belongs to class 0, and\nonly 5% belongs to class 1. In contrast, we collect 95% of Right Bottom BP in class 1, and assigned\nonly 5% to class 0. In test environments, the composition of BP is flipped. For experimental details,\nrefer to Appendix A.6\nTable 1 shows the results of H-CMNIST. H-CMNIST assumes an easily learnable invariant feature\nZcolor to evaluate whether the model, having already learned one invariant feature, can learn additional\ninvariant features Zshape. Concretely, TestBed1 serves as a preliminary step to verify that an easily\nlearnable invariant feature is indeed present. In TestBed1, the performance of all algorithms is similar\nregardless of the presence of the spurious feature ZBP, indicating that all have learned at least one\ninvariant feature.\nHowever, in Testbed 2, without Zcolor, both ERM and ASAM show significant performance discrep-\nancies depending on the presence of spurious feature ZBP. Compared with the results of TestBed 1,\nERM and ASAM only learn Zcolor successfully, but they fail to capture the additional invariant feature,\nZshape. It indicates that even when a relatively easier invariant feature exists, the spurious feature\ninfluences the relatively more challenging invariant feature. Although GDRO exhibits robustness to\nspurious correlations compared to ERM and ASAM, it still fails to learn one of the invariant features,\nZshape. However, ASGDRO makes robust predictions against spurious features and more successful\nlearning of shape features in TestBed2, compared to other baselines. It implies that SIL is necessary\nfor the robust model and ASGDRO optimizes the model to learn sufficiently diverse invariant features\nZI = {Zshape, Zshape} considering the common flat minima across environments.\n8\n\nCMNIST\nWaterbirds\nCelebA\nCivilComments\nAvg.\nWorst\nAvg.\nWorst\nAvg.\nWorst\nAvg.\nWorst\nERM‡\n27.8% 0.0%\n97.0% 63.7%\n94.9% 47.8%\n92.2% 56.0%\nASAM\n40.5% 34.1%\n97.4% 72.4%\n93.7% 46.5%\n92.3% 58.9%\nIRM‡\n72.1% 70.3%\n87.5% 75.6%\n94.0% 77.8%\n88.8% 66.3%\nIB-IRM‡\n72.2% 70.7%\n88.5% 76.5%\n93.6% 85.0%\n89.1% 65.3%\nV-REx‡\n71.7% 70.2%\n88.0% 73.6%\n92.2% 86.7%\n90.2% 64.9%\nCORAL‡\n71.8% 69.5%\n90.3% 79.8%\n93.8% 76.9%\n88.7% 65.6%\nGDRO‡\n72.3% 68.6%\n91.8% 90.6%\n92.1% 87.2%\n89.9% 70.0%\nDomainMix‡\n51.4% 48.0%\n76.4% 53.0%\n93.4% 65.6%\n90.9% 63.6%\nFish‡\n46.9% 35.6%\n85.6% 64.0%\n93.1% 61.2%\n89.8% 71.1%\nLISA‡\n74.0% 73.3%\n91.8% 89.2%\n92.4% 89.3%\n89.2% 72.6%\nPDE‡‡\n–%\n–%\n92.4% 90.3%\n92.0% 91.0%\n86.3% 71.5%\nASGDRO\n74.8% 74.2%\n92.3% 91.4%\n92.1% 91.0%\n90.2% 71.8%\nTable 2: Subpopulation Shift. ‡ denotes the perfor-\nmance reported from (Yao et al., 2022), and ‡‡ denotes\nthe performance reported from (Deng et al., 2024). Avg.\ndenotes average accuracy, and Worst denotes worst\ngroup accuracy. Refer to Appendix A.7 for error bars\nand experimental details.\nPT–FT\nCamelyon17\nCivilComments\nFMoW\nAmazon\nRxRx1\nAvg. (%)\nWorst (%)\nWorst (%)\n10th per. (%)\nAvg. (%)\n×–ERM\n70.3 ±6.4\n56.0 ±3.6\n32.3 ±1.3\n53.8 ±0.8\n29.9 ±0.4\n×–GDRO\n68.4 ±7.3\n70.0 ±2.0\n30.8 ±0.8\n53.3 ±0.0\n23.0 ±0.3\n×–IRM\n64.2 ±8.1\n66.3 ±2.1\n30.0 ±1.4\n52.4 ±0.8\n8.2 ±1.1\nERM–ERM\n74.3 ±6.0\n55.5 ±1.8\n33.6 ±1.0\n51.1 ±0.6\n30.2 ±0.1\nERM–GDRO\n76.1 ±6.5\n69.5 ±0.2\n33.0 ±0.5\n52.0 ±0.0\n30.0 ±0.1\nERM–IRM\n75.7 ±7.4\n68.8 ±1.0\n33.5 ±1.1\n52.0 ±0.0\n30.1 ±0.1\nBonsai–ERM\n74.0 ±5.3\n63.3 ±3.5\n31.9 ±0.5\n48.6 ±0.6\n24.2 ±0.4\nBonsai–GDRO\n72.8 ±5.4\n70.2 ±1.3\n33.1 ±1.2\n42.7 ±1.1\n23.0 ±0.5\nBonsai–IRM\n73.6 ±6.2\n68.4 ±2.0\n32.5 ±1.2\n47.1 ±0.6\n23.4 ±0.4\nFeAT–ERM\n77.8 ±2.5\n68.1 ±2.3\n33.1 ±0.8\n52.9 ±0.6\n30.7 ±0.4\nFeAT–GDRO\n80.4 ±3.3\n71.3 ±0.5\n33.6 ±1.7\n52.6 ±0.6\n30.0 ±0.1\nFeAT–IRM\n78.0 ±3.1\n70.3 ±1.1\n34.0 ±0.7\n52.9 ±0.6\n30.0 ±0.2\n×–ASGDRO\n81.0 ±3.8\n71.8 ±0.4\n35.0 ±0.3\n54.5 ±0.5\n30.5 ±0.1\nTable 3: Wilds Benchmark. Out-of-distribution\ngeneralization performances on wilds benchmark\nwith rich representation. The performances of the\nbaseline models are the reported results from Koh\net al. (2021) and Chen et al. (2024a). Refer to\nAppendix A.8 for error bars.\n4.3\nExperimental Results\nMethod\nPACS\nVLCS\nOH\nTI\nDN\nAvg\nERM†\n85.5\n77.5\n66.5\n46.1\n40.9\n63.3\nIRM†\n83.5\n78.6\n64.3\n47.6\n33.9\n61.6\nGDRO†\n84.4\n76.7\n66.0\n43.2\n33.3\n60.7\nI-Mixup†\n84.6\n77.4\n68.1\n47.9\n39.2\n63.4\nMMD†\n84.7\n77.5\n66.4\n42.2\n23.4\n58.8\nSagNet†\n86.3\n77.8\n68.1\n48.6\n40.3\n64.2\nARM†\n85.1\n77.6\n64.8\n45.5\n35.5\n61.7\nVREx†\n84.9\n78.3\n66.4\n46.4\n33.6\n61.9\nRSC†\n85.2\n77.1\n65.5\n46.6\n38.9\n62.7\nGSAM (Zhuang et al., 2021)\n85.9\n79.1\n69.3\n47.0\n44.6\n65.1\nRDM (Nguyen et al., 2024)\n87.2\n78.4\n67.3\n47.5\n43.4\n64.8\nRS-SCM (Chen et al., 2024b)\n85.8\n77.6\n68.8\n47.6\n42.5\n64.4\nLFME (Chen et al., 2024c)\n85.0\n78.4\n69.1\n48.3\n42.1\n64.6\nDPLCLIP\n96.6\n79.0\n82.7\n45.4\n59.1\n72.6\nDPLCLIP+GDRO\n95.9\n79.7\n83.6\n46.0\n59.1\n72.9\nDPLCLIP+ASGDRO\n96.8\n80.7\n83.7\n48.9\n59.8\n74.0\nTable 4: DomainBed. The symbol † indicates reported per-\nformance in Gulrajani and Lopez-Paz (2020). Refer to Ap-\npendix A.9 for error bars and experimental details.\nIn all experiments except for the toy\nexample, instead of calculating ϵ∗\ne\n=\nρ T 2\nθ ∇Re(θ)\n|Tθ∇Re(θ)| for each environment, we\nuse a common adversarial perturbation\nby utilizing the empirical risk RS(θ) =\n1\n|De||Etr|\nP\ne∈Etr\nP\nne ℓ(f(Xe; θ), Y e), i.e.,\nϵ∗= ρ T 2\nθ ∇RS(θ)\n|Tθ∇RS(θ)|. In each performance ta-\nble, boldface and underlined text represent\nthe highest and second-highest accuracy\nfor each dataset, respectively.\nWe conduct experiments for subpopulation\nshift, CMNIST (Arjovsky et al., 2019), Wa-\nterbirds (Sagawa et al., 2019), CelebA (Liu\net al., 2015), and CivilComments (Borkan\net al., 2019). The goal of the subpopulation\nshift task is to obtain the better worst group performance by learning invariant features. Different\nfrom H-CMNIST, the spurious correlation acts as a stronger shortcut. As a result, the models cannot\nlearn any invariant feature easily. Table 2 shows the results of subpopulation shift experiments.\nASAM, which considers flatness, fails to eliminate spurious correlations and shows limited predic-\ntive accuracy on the worst group. On the other hand, ASGDRO shows the best and worst group\nperformance for all data except CivilComments. For CivilComments data, ASGDRO also shows\ncomparable performance with the best algorithms among the baselines. Compared to GDRO, the\nprimary distinction of ASGDRO is its ability to find a common flat minima, which not only enhances\nrobustness for the worst group but also reduces the gap between average accuracy and worst group\naccuracy. Therefore, Table 2 provides support for our claim that sufficiently learning diverse invariant\nmechanisms leads to robust generalization performance.\nOne approach to training a robust model is to enrich the representation learning of invariant features\nZhang et al. (2022); Chen et al. (2024a) rather than training by ERM. This process consists of a\npre-training (PT) stage dedicated to representation learning, followed by a fine-tuning (FT) stage\nutilizing existing invariant learning algorithms. In Table 3, we compare these algorithms with\nASGDRO, evaluated on the Wilds benchmark dataset, which includes various types of distribution\nshifts collected from real-world scenarios. Notably, the superior performance of ASGDRO, even\ncompared to invariant learning algorithms trained with rich representations during the FT stage,\nsuggests that it is important not only to learn rich representations of invariant features but also to\nensure that predictions are composed using diverse invariant features by learning sufficiently diverse\ninvariant mechanisms.\n9\n\nFigure 4: Grad-CAM ASGDRO learns diverse\ninvariant features.\nFigure 5: Hessian Analysis on CelebA. ASGDRO finds\nthe common flat minima for all groups.\nASGDRO is a model-agnostic method and is easily applied to various algorithms. We apply ASGDRO\nwith DPLCLIP (Zhang et al., 2021), which performs the prompt learning for domain generalization.\nWe conduct DomainBed benchmark (Gulrajani and Lopez-Paz, 2020), which is the most commonly\nused for evaluating domain generalization performance under a fair setting. Table 4 presents that\nASGDRO shows better performance in all datasets compared to DPLCLIP. ASGDRO also achieves\nbetter domain generalization performance than the algorithm that combined DPLCLIP and GDRO.\n4.4\nVisual Interpretation by Grad-CAM\nWe conduct Grad-CAM analysis to verify whether the effect of learning SIL is being properly applied\non the ground-truth label (Figure 4). The minority group, land birds on a water background, is\nunderrepresented by the spurious correlation as it has only a few samples. ERM and ASAM use\nseveral features to predict the majority group, land birds on a land background, but fail to remove\nspurious correlation. As a result, they also use the background feature. For the minority groups,\nhowever, only a small part of the invariant features is observed to be used for prediction. GDRO\nsuccessfully removes spurious correlation regardless of the group but still uses only the part of\ninvariant features for prediction. On the other hand, ASGDRO focuses on various invariant features\nfor prediction regardless of the group; that is, it sufficiently uses diverse invariant features of land\nbirds. Additionally, ASGDRO successfully excludes spurious features in their prediction. Appendix\nA.10 provides additional results on Grad-CAM.\n4.5\nHessian Analysis\nIn Figure 5, we report the eigenvalues of the Hessian matrix to measure and compare the flatness\nof the model Yao et al. (2020). A lower eigenvalue indicates a flatter minima. Compared to GDRO,\nASGDRO exhibits lower eigenvalues across all groups. Furthermore, GDRO shows particularly\nsharper minima in Group 2 and 3, which include minority groups. In contrast, ASGDRO maintains\nrelatively uniform eigenvalues regardless of the group. This suggests that ASGDRO indeed finds a\ncommon flat minima, with the regularization for such minima enabling the model to make robust\npredictions by leveraging diverse invariant mechanisms. Refer to Appendix A.11 for additional\nexperimental analysis.\n5\nConclusion\nThis study highlights the significance of SIL, which promotes the learning of diverse invariant\nfeatures. Unlike traditional invariant learning, SIL enables models to leverage these diverse invariant\nmechanisms for prediction, ensuring robustness even in environments where some invariant features\nare unobserved. We also introduce ASGDRO, the first SIL algorithm specifically designed to identify\ncommon flat minima across environments. Through both theoretical analysis and experimental\nvalidation, we demonstrate that ASGDRO effectively learns a diverse invariant mechanism sufficiently\nand finds a common flat minima, which in turn facilitates SIL. We further validate the effectiveness of\nSIL by demonstrating the generalization capabilities of ASGDRO on our newly developed synthetic\nSIL dataset, H-CMNIST, as well as on various types of distribution shift benchmark datasets.\n10\n\nReferences\nMartin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv\npreprint arXiv:1907.02893, 2019.\nPang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani,\nWeihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild\ndistribution shifts. In International Conference on Machine Learning, pages 5637–5664. PMLR, 2021.\nIshaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434,\n2020.\nKrikamol Muandet, David Balduzzi, and Bernhard Schölkopf. Domain generalization via invariant feature\nrepresentation. In International conference on machine learning, pages 10–18. PMLR, 2013.\nYa Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep domain\ngeneralization via conditional invariant adversarial networks. In Proceedings of the European conference on\ncomputer vision (ECCV), pages 624–639, 2018.\nShiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks.\nIn International Conference on Learning Representations, 2019.\nHuaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and Chelsea Finn. Improving out-of-\ndistribution robustness via selective augmentation. In International Conference on Machine Learning, pages\n25407–25437. PMLR, 2022.\nP Izmailov, AG Wilson, D Podoprikhin, D Vetrov, and T Garipov. Averaging weights leads to wider optima and\nbetter generalization. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages\n876–885, 2018.\nSiyuan Guo, Jonas Bernhard Wildberger, and Bernhard Schölkopf. Out-of-variable generalisation for dis-\ncriminative models. In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=zwMfg9PfPs.\nAlexey Tsymbal. The problem of concept drift: definitions and related work. Computer Science Department,\nTrinity College Dublin, 106(2):58, 2004.\nPierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for\nefficiently improving generalization. In International Conference on Learning Representations, 2020.\nVladimir Vapnik. The nature of statistical learning theory. Springer science & business media, 1999.\nYuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve.\nGradient matching for domain generalization. arXiv preprint arXiv:2104.09937, 2021.\nAlexandre Rame, Corentin Dancette, and Matthieu Cord.\nFishr: Invariant gradient variances for out-of-\ndistribution generalization. In International Conference on Machine Learning, pages 18347–18377. PMLR,\n2022a.\nPolina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is sufficient for robustness\nto spurious correlations. arXiv preprint arXiv:2204.02937, 2022.\nJianyu Zhang, David Lopez-Paz, and Léon Bottou. Rich feature construction for the optimization-generalization\ndilemma. In International Conference on Machine Learning, pages 26397–26411. PMLR, 2022.\nYongqiang Chen, Wei Huang, Kaiwen Zhou, Yatao Bian, Bo Han, and James Cheng. Understanding and\nimproving feature learning for out-of-distribution generalization. Advances in Neural Information Processing\nSystems, 36, 2024a.\nJianyu Zhang and Léon Bottou.\nLearning useful representations for shifting tasks and distributions.\nIn\nInternational Conference on Machine Learning, pages 40830–40850. PMLR, 2023.\nMateo Rojas-Carulla, Bernhard Schölkopf, Richard Turner, and Jonas Peters. Invariant models for causal transfer\nlearning. Journal of Machine Learning Research, 19(36):1–34, 2018.\nNitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On\nlarge-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836,\n2016.\n11\n\nBehnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro. Exploring generalization in deep\nlearning. Advances in neural information processing systems, 30, 2017.\nJungmin Kwon, Jeongseop Kim, Hyunseo Park, and In Kwon Choi. Asam: Adaptive sharpness-aware minimiza-\ntion for scale-invariant learning of deep neural networks. In International Conference on Machine Learning,\npages 5905–5914. PMLR, 2021.\nJunbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and Sungrae\nPark. Swad: Domain generalization by seeking flat minima. Advances in Neural Information Processing\nSystems, 34:22405–22418, 2021.\nAlexandre Rame, Matthieu Kirchmeyer, Thibaud Rahier, Alain Rakotomamonjy, Patrick Gallinari, and Matthieu\nCord. Diverse weight averaging for out-of-distribution generalization. Advances in Neural Information\nProcessing Systems, 35:10821–10836, 2022b.\nXingxuan Zhang, Renzhe Xu, Han Yu, Yancheng Dong, Pengfei Tian, and Peng Cu. Flatness-aware minimization\nfor domain generalization. arXiv preprint arXiv:2307.11108, 2023.\nJacob Mitchell Springer, Vaishnavh Nagarajan, and Aditi Raghunathan. Sharpness-aware minimization enhances\nfeature quality via balanced learning. In The Twelfth International Conference on Learning Representations,\n2024. URL https://openreview.net/forum?id=3xDaj4pRna.\nElliot Creager, Jörn-Henrik Jacobsen, and Richard Zemel. Environment inference for invariant learning. In\nInternational Conference on Machine Learning, pages 2189–2200. PMLR, 2021.\nDavid Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi\nLe Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International\nConference on Machine Learning, pages 5815–5826. PMLR, 2021.\nKartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis\nMitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution general-\nization. Advances in Neural Information Processing Systems, 34:3438–3450, 2021.\nJohn Duchi, Peter Glynn, and Hongseok Namkoong. Statistics of robust optimization: A generalized empirical\nlikelihood approach. arXiv preprint arXiv:1610.03425, 2016.\nYonatan Oren, Shiori Sagawa, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust language\nmodeling. arXiv preprint arXiv:1909.02060, 2019.\nGabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh\nHajishirzi, and Ali Farhadi. Editing models with task arithmetic. arXiv preprint arXiv:2212.04089, 2022.\nMitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gon-\ntijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot\nmodels. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages\n7959–7971, 2022.\nSamuel K Ainsworth, Jonathan Hayase, and Siddhartha Srinivasa. Git re-basin: Merging models modulo\npermutation symmetries, 2022. URL https://arxiv. org/abs/2209.04836.\nAlexandre Ramé, Kartik Ahuja, Jianyu Zhang, Matthieu Cord, Léon Bottou, and David Lopez-Paz. Model\nratatouille: Recycling diverse models for out-of-distribution generalization. In International Conference on\nMachine Learning, pages 28656–28679. PMLR, 2023.\nBehnam Neyshabur, Hanie Sedghi, and Chiyuan Zhang. What is being transferred in transfer learning? Advances\nin neural information processing systems, 33:512–523, 2020.\nYang Zhao, Hao Zhang, and Xiuyuan Hu. Penalizing gradient norm for efficiently improving generalization in\ndeep learning. arXiv preprint arXiv:2202.03599, 2022.\nAlex J DeGrave, Joseph D Janizek, and Su-In Lee. Ai for radiographic covid-19 detection selects shortcuts over\nsignal. Nature Machine Intelligence, 3(7):610–619, 2021.\nYihe Deng, Yu Yang, Baharan Mirzasoleiman, and Quanquan Gu. Robust learning with progressive data\nexpansion against spurious correlation. Advances in neural information processing systems, 36, 2024.\nJuntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha C Dvornek, James s Duncan,\nTing Liu, et al. Surrogate gap minimization improves sharpness-aware training. In International Conference\non Learning Representations, 2021.\n12\n\nToan Nguyen, Kien Do, Bao Duong, and Thin Nguyen. Domain generalisation via risk distribution matching. In\nProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2790–2799,\n2024.\nZiliang Chen, Yongsen Zheng, Zhao-Rong Lai, Quanlong Guan, and Liang Lin. Diagnosing and rectifying\nfake ood invariance: A restructured causal approach. In Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 38, pages 11471–11479, 2024b.\nLiang Chen, Yong Zhang, Yibing Song, Zhiqiang Shen, and Lingqiao Liu. Lfme: A simple framework for\nlearning from multiple experts in domain generalization. arXiv preprint arXiv:2410.17020, 2024c.\nZiwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings\nof the IEEE international conference on computer vision, pages 3730–3738, 2015.\nDaniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced metrics for\nmeasuring unintended bias with real data for text classification. In Companion proceedings of the 2019 world\nwide web conference, pages 491–500, 2019.\nXin Zhang, Yusuke Iwasawa, Yutaka Matsuo, and Shixiang Shane Gu. Amortized prompt: Lightweight\nfine-tuning for clip in domain generalization. arXiv preprint arXiv:2111.12853, 2021.\nZhewei Yao, Amir Gholami, Kurt Keutzer, and Michael W Mahoney. Pyhessian: Neural networks through the\nlens of the hessian. In 2020 IEEE international conference on big data (Big data), pages 581–590. IEEE,\n2020.\nJiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, and Vincent YF\nTan. Efficient sharpness-aware minimization for improved training of neural networks. arXiv preprint\narXiv:2110.03141, 2021.\nJiawei Du, Daquan Zhou, Jiashi Feng, Vincent YF Tan, and Joey Tianyi Zhou. Sharpness-aware training for free.\narXiv preprint arXiv:2205.14083, 2022.\nMaksym Andriushchenko, Dara Bahri, Hossein Mobahi, and Nicolas Flammarion. Sharpness-aware mini-\nmization leads to low-rank features. Advances in Neural Information Processing Systems, 36:47032–47051,\n2023.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In\nProceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.\nYann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document\nrecognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\nCatherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-\n2011 dataset. 2011.\nBolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image\ndatabase for scene recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):\n1452–1464, 2017.\nEvan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang,\nand Chelsea Finn. Just train twice: Improving group robustness without training group information. In\nInternational Conference on Machine Learning, pages 6781–6792. PMLR, 2021.\nZongbo Han, Zhipeng Liang, Fan Yang, Liu Liu, Lanqing Li, Yatao Bian, Peilin Zhao, Bingzhe Wu, Changqing\nZhang, and Jianhua Yao. Umix: Improving importance weighting for subpopulation shift via uncertainty-\naware mixup. arXiv preprint arXiv:2209.08928, 2022.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert: smaller,\nfaster, cheaper and lighter. arXiv preprint arXiv:1910.01108, 2019.\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101,\n2017.\nAdina Williams, Nikita Nangia, and Samuel R Bowman. A broad-coverage challenge corpus for sentence\nunderstanding through inference. arXiv preprint arXiv:1704.05426, 2017.\nChen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple datasets\nand web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision,\npages 1657–1664, 2013.\n13\n\nDa Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain gen-\neralization. In Proceedings of the IEEE international conference on computer vision, pages 5542–5550,\n2017.\nHemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing\nnetwork for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and\npattern recognition, pages 5018–5027, 2017.\nSara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings of the European\nconference on computer vision (ECCV), pages 456–473, 2018.\nXingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for\nmulti-source domain adaptation. In Proceedings of the IEEE/CVF international conference on computer\nvision, pages 1406–1415, 2019.\nRamprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv\nBatra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In 2017 IEEE\nInternational Conference on Computer Vision (ICCV), pages 618–626, 2017. doi: 10.1109/ICCV.2017.74.\n14\n\nA\nAppendix: Sufficient Invariant Learning for Distribution Shift\nA.1\nLimitations and Future Works\nASGDRO utilizes adversarial perturbations to find flat minima, similar to SAM. It requires two\nforward and backward passes in a single training iteration, which is one of the persistent issues\nwith SAM-based algorithms. However, recent research has been actively focusing on improving the\ncomputational cost of SAM (Du et al., 2021, 2022). The computational cost of ASGDRO can also be\nimproved in a similar context, and we consider this to be a future work.\nTo evaluate whether the algorithm effectively learns diverse invariant mechanisms sufficiently and\nperforms robust predictions, a new benchmark dataset is necessary. Unlike existing invariant learning\nbenchmarks that only require a small number of attributes, constructing an SIL benchmark demands\nrich attribute annotations to form multiple invariant features. In this paper, we attempt to validate\nSIL using H-CMNIST, but it is a synthetic dataset based on MNIST. This implies the need for a new\nbenchmark to validate SIL on real-world data, which we leave it as a future work.\nA.2\nThe subset relationship of invariant features\nIn Definition 3, hθg( ˆZI) refers to a classifier that relies solely on ˆZI ⊆ZI. Given a single sample, if\nany invariant feature within ˆZI is observed, we expect the loss evaluated by the classifier to be very\nsmall. For two different subset ˆZI\na, ˆZI\nb ⊆ˆZI that satisfy ˆZI\nb ⊆ˆZI\na, the following inequality holds:\nP( ˆZI\ni ⊆ˆZI\nb is observed in e ∈E) ≤P( ˆZI\ni ⊆ˆZI\na is observed in e ∈E).\nwhere P denotes the probability. Note that ZI also can be partitioned as follows:\nZI =\np[\ni=1\n{ ˆZI | | ˆZI| = i},\nwhere |·| denotes the cardinality of a set and p the number of invariant features. It follows that\nmax\nˆ\nZI⊆ZI E[ℓ(hθh( ˆZI), Y e)] = max\nh\nE[ℓ(hθh(ZI), Y e)],\nmax\nˆ\nZI⊆ZI\ns.t.| ˆ\nZI|=p−1\nE[ℓ(hθh( ˆZI), Y e)],\n. . . ,\nmax\nˆ\nZI⊆ZI\ns.t.| ˆ\nZI|=1\nE[ℓ(hθh( ˆZI), Y e)]\ni\n=\nmax\nˆ\nZI⊆ZI\ns.t.| ˆ\nZI|=1\nE[ℓ(hθh( ˆZI), Y e)]\n= max\nZI\ni⊂ZI E[ℓ(hθh(ZI\ni), Y e)],\nassuming that observing additional invariant features do not adversely affect the performance of the\ncurrent model.\nA.3\nProof of Proposition 1\nProposition 1 (Common Flat Minima). By the Taylor expansion,\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe) ≈max\ne∈E [Re(θ) + ρ||∇Re(θ)||].\n(7)\nASGDRO leads to a regularization of the gradient norm, Re, ||∇Re(θ)||, across environments, which\ndrives the model to converge to common flat minima.\n15\n\nProof. Recall that objective function of ASGDRO (Equation 5) is as follows:\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe).\nWe use E instead of Etr, since this property of ASGDRO holds in any set of environments. As Re(θ)\nis independent of ϵe, it can be factored out of the maximization term over ϵe as follows:\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe) = max\ne∈E [Re(θ) + max\n||ϵe||≤ρ[Re(θ + ϵe) −Re(θ)]]\nNote that we intentionally add and subtract Re to reformulate the expression, enabling the separation\nof terms for clearer analysis. Using the Taylor approximation expanded up to the first-order term, we\nhave:\nmax\ne∈E [Re(θ) + max\n||ϵe||≤ρ[Re(θ + ϵe) −Re(θ)]] ≈max\ne∈E [Re(θ) + max\n||ϵe||≤ρ[ϵe · ∇Re(θ)]]\n= max\ne∈E [Re(θ) + ϵ∗\ne · ∇Re(θ)],\n(16)\nwhere ϵ∗\ne = ρ\n∇Re(θ)\n||∇Re(θ)||. Note that Equation 16 holds because the maximum value over ||ϵe|| ≤ρ is\nachieved when ϵe and ∇Re(θ) are aligned in the same direction (Foret et al., 2020). By substituting\nϵ∗\ne, we obtain the following equation:\nmax\ne∈E [Re(θ) + ϵ∗\ne · ∇Re(θ)] = max\ne∈E [Re(θ) + ρ||∇Re(θ)||].\nZhao et al. (2022) demonstrate that minimizing the gradient norm of the risk leads to finding flat\nminima. Equation 17 minimizes both risk and the gradient norm of risk for each environment.\nConsequently, ASGDRO constrains the training process to find a common flat minimum across\nenvironments.\nA.4\nProof of Theorem 1\nTheorem 1 (Sufficient Invariant Mechanism). Let θI\nλ be a convex combination of θI\ni, where λ is a\np-dimensional vector. Consider mean-squared error as the loss function. Then, given ZI = (1, . . . , 1)\nwith |Z| = p,\nλ∗= argmin\nλ\nmax\ne∈Etr max\n||ϵ||≤ρ Re(θI\nλ + ϵ)\n= argmin\nλ\nmax\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ||λ|| · ||∇Re(θI\nλ)||\n\u0003\n(6)\n= argmin\nλ\n||λ|| = (1\np, . . . , 1\np)\nwhere || · || denotes L2 norm.\nProof. In this setting, we consider a single input for each environment e. Suppose there are p invariant\nfeatures, and every invariant feature has the same activation:\nZI = (1, . . . , 1),\nwhere |ZI| = p. We assume that all spurious features are completely removed. Thus, Z =\n(ZI, ZNI) = ZI, where |Z| = p. Consequently, the risk for Z is identical across all environments e:\nRe(θ) = Re′(θ) = c\nfor any e, e′ ∈Etr,\n(17)\nwhere c is a constant. Given ZI, we focus only on the parameters of the classifier, denoted by θI.\nRecall that the classifier satisfying Equation 2, and Equation 17, is not unique. Define θI\ni as the\nclassifier that utilizes only the i-th element of ZI.\nFor simplicity, let θI\ni be a column vector where only the i–th element is one, and all other elements\nare zero:\nZIθI\ni = ZI\ni = 1.\n16\n\nFurthermore, the convex combination of θI\ni also yields an equivalent output:\nZI\np\nX\ni=1\nλiθI\ni = 1,\nwhere Pp\ni=1 λi = 1 and 0 ≤λi ≤1 for all i ∈{1, . . . , p}. We denote the current classifier as\nθI\nλ := Pp\ni=1 λiθI\ni, where λ = (λ1, . . . , λp). From Proposition 1, we know:\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe) = max\ne∈Etr [Re(θ) + ρ||∇θRe(θ)||] .\n(18)\nFor the mean-squared error loss function Re(θ) = 1\n2∥Y e −Pp\ni=1 θi∥2, the gradient is given by\n∇Re(θ) = −(Y e −Pp\ni=1 θi) · 1, where 1 is a p-dimensional vector whose elements are all equal to\n1. Substituting θI\nλ into Equation 18, we get:\nmax\ne∈E\nmax\n∥ϵe∥≤ρ Re(θI\nλ + ϵe) = max\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ∥∇θRe(θI\nλ)∥\n\u0003\n.\nThis simplifies to:\nmax\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ∥−λ ⊙∇Re(θI\nλ)∥\n\u0003\n= max\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ∥λ∥· ∥∇Re(θI\nλ)∥\n\u0003\n,\nwhere Re(θI\nλ) = c for any λ. Since the classifier uses only invariant features, minimizing the\nadversarial term reduces to:\nargmin\nλ\nmax\ne∈Etr max\n||ϵ||≤ρ Re(θI\nλ + ϵ) = argmin\nλ\nmax\ne∈Etr\n\u0002\nRe(θI\nλ) + ρ||λ|| · ||∇Re(θI\nλ)||\n\u0003\n= argmin\nλ\n||λ||.\nBy the Cauchy-Schwarz inequality:\n p\nX\ni=1\nλi\n!2\n≤p ·\np\nX\ni=1\nλ2\ni = p · ||λ||2.\nUnder the condition Pp\ni=1 λi = 1, equality holds when λi = 1\np for all i, yielding:\nargmin\nλ\n||λ|| = (1\np, . . . , 1\np)\nA.5\nMechanism of ASGDRO for Removing Spurious Features\nASGDRO successfully removes spurious features. Inspired by Andriushchenko et al. (2023) we\nreformulate the two-layer ReLU case presented in that paper to demonstrate this. Consider a two–layer\nReLU network\nf(θ) = ⟨θh, σ(θgx)⟩,\n(19)\nwhere θ = (θg, θh), θg ∈Rk×m and θh ∈Rk. Recall that ASGDRO minimizes the maximum\nsharpness across environments:\nmax\ne∈E\nmax\n||ϵe||≤ρ Re(θ + ϵe).\nLet et denote the environment that attains the maximum risk at the current step t. Then, the adversarial\nperturbation is ϵ∗\net = ρ ∇Ret(θ)\n∥∇Ret(θ)∥(Foret et al., 2020) and the risk is\nmax\n||ϵet||≤ρ Ret(θ + ϵet) = Ret(θ + ρ ∇Ret(θ)\n∥∇Ret(θ)∥)\nUnder the first–order Taylor approximation,\n∇Ret\n\u0012\nθ + ρ ∇Ret(θ)\n∥∇Ret(θ)∥\n\u0013\n≈∇[Ret(θ) + ρ∥∇Ret(θ)∥]\n(20)\n17\n\nAndriushchenko et al. (2023) shows that under two–layer ReLU network, the update rule for pre-\nactivation of k–th neuron is as follows:\n⟨θ(k)\ng , x⟩(t+1) ≈⟨θ(k)\ng , x⟩(t) −ηγ\n \n1 + ρ ∥∇f(θ)∥\np\nRet(θ)\n!\nakσ′(⟨θ(k)\ng , x⟩)∥x∥2\n|\n{z\n}\n(a)\n−ηρ\np\nRet(θ)\n∥∇f(θ)∥σ(⟨θ(k)\ng , x⟩)∥x∥2\n|\n{z\n}\n(b)\n,\nwhere η denotes the learning rate, γ = f(θ) −y, i.e. the residual.\nIn ASGDRO, regularization on the gradient norm has two key effects. First, as seen in term (a),\nthe gradient update direction remains the same, but the model is updated with a larger learning rate.\nSecond, in term (b), when Ret(θ) is large enough, the pre-activation of the k-th neuron, ⟨θ(k)\ng , x⟩,\nturns negative. Note that a large Ret implies that highly activated neurons at this point tend to\nencode significant information from spurious features. When Ret(θ) causes the pre-activation of a\nneuron to become negative, the nature of the ReLU activation function ensures that the output of that\nneuron becomes zero. This indicates that, under distribution shifts, regularization via the common\nflat minima in ASGDRO effectively removes spurious features.\nA.6\nHeterogeneous-CMNIST (H-CMNIST): Experimental Details\nIn H-CMNIST experiments, we use ResNet18 (He et al., 2016) with SGD. We also conduct reweighted\nsampling when the algorithm setting can use the environment information, i.e., GDRO (Sagawa et al.,\n2019) and ASGDRO. In the H-CMNIST experiment, we set the loss of GDRO and ASGDRO by the\ngroup, not the domain. That is, there is four groups; (Class=0,BP=Top Left), (Class=0,BP=Bottom\nRight), (Class=1,BP=Top Left), (Class=1,BP=Bottom Right). For hyperparameter tuning, we perform\ngrid search over learning rate, {10−3, 10−4}, and L2–regularization, {1, 10−1, 10−3, 10−4}. We\nfix the batch size, 128, and train the model up to 20 epochs. For ASAM (Kwon et al., 2021) and\nASGDRO, we search the hyperparameter ρ among {0.05, 0.2, 0.5, 0.8}. We fix the robust step size,\nγ, as 0.01 for GDRO and ASGDRO. We evaluate the models with three random seeds.\nA.7\nSubpopulation Shifts: Datasets and Experimental Details\nDataset Details\nIn Table 2 in the main paper, we conduct our experiment for subpopulation shifts with five datasets:\nCMNIST (Arjovsky et al., 2019), Waterbirds (Sagawa et al., 2019), CelebA (Liu et al., 2015),\nCivilComments (Borkan et al., 2019). CMNIST, Waterbirds, and CelebA datasets correspond to\ncomputer vision tasks (Figure 6), while CivilComments pertain to natural language processing tasks.\nIn this section, we will describe each dataset and provide experimental details. To implement this, we\nutilized the codes provided by (Yao et al., 2022)2.\nColored MNIST (CMNIST)\nIn the CMNIST dataset provided by (Arjovsky et al., 2019), we perform binary classification to\npredict which number corresponds to the shape of a given digit. Specifically, when the shape of the\ndigit corresponds to a logit between 0 and 4, the class is assigned as 0, and when it falls between 5\nand 9, the class is assigned as 1. However, unlike the original MNIST dataset (LeCun et al., 1998),\nCMNIST introduces color as a spurious feature in the training set. When this spurious correlation\nbecomes stronger than the invariant relationship between the class and the shape of the digit, a model\ntrained without any regularization may be prone to relying on the spurious feature for predictions.\nWhile Arjovsky et al. (2019) constructs two environments with different ratios of spurious features\nin the training set, Yao et al. (2022) uses a single environment to compose the training set. Our\nCMNIST dataset experiment follows the same setting as (Yao et al., 2022), where the dataset consists\n2https://github.com/huaxiuyao/LISA\n18\n\nFigure 6: CMNIST, Waterbirds, CelebA. In each dataset, each row represents the class and each\ncolumn represents the spurious feature. The numbers written below the images represent the ratio or\ncount of data belonging to each group in the training dataset, where each group consists of (Class,\nSpurious Feature) pairs.\nof four groups when considering combinations of “Shape of Logit” and “Color” as a single group.\nConcretely, Class 0 and Class 1 have similar numbers of data points, but the distribution of spurious\nfeatures differs between the two classes. Class 0 consists of 80% red logits and 20% green logits,\nwhile Class 1 has 80% green logits and 20% red logits. Furthermore, within each class, 25% of the\ndata acts as label noise, having a logit shape that does not correspond to its class. Therefore, the\nspurious feature, color, forms a stronger correlation between classes compared to that of the invariant\nfeature, the shape of logits.\nThe validation set is constructed with an equal number of instances per group. The worst-group\naccuracy, defined as the lowest accuracy among all the groups, is utilized to select the best model.\nFor the test set, we assume a distribution of the spurious feature that is opposite to the training set.\nSpecifically, for Class 0, 90% of the data has a red color, and 10% has a green color, while for Class 1,\nit is the opposite. It is done to assess whether the model relies on the spurious feature for predictions.\nWaterbirds\nWaterbirds dataset, constructed by (Sagawa et al., 2019), is designed for the task of determining\nwhether a bird belongs to the Landbird or Waterbird class. It consists of images of birds, from\n(Wah et al., 2011), as the invariant feature, while the spurious feature is the background, from (Zhou\net al., 2017), which can either be Water or Land background. Indeed, in the Waterbirds dataset, the\ngroups are formed by the combination of “Bird” and “Background”. Specifically, the bird images\ncorresponding to each class consist of more than 10 different species of birds. On the other hand,\neach background is composed of two categories obtained from (Zhou et al., 2017). As can be seen in\nFigure 6, the Landbird class predominantly has images with Land background, while the majority of\nimages in the Waterbird class have Water background. Therefore, the spurious feature, background,\nmay indeed form a strong spurious correlation with each class.\nWe follow the setting of previous research, (Sagawa et al., 2019; Yao et al., 2022), for the validation\nand test processes as well. The best model is selected based on the highest worst-group accuracy on\nthe validation set. Unlike the training set, the validation and test sets are designed to have an equal\nnumber of images for each group within each class. When reporting the average accuracy on the\ntest dataset using the best model, we first compute the group accuracy for each group in the test set.\nThen, we calculate the weighted average of these accuracies using the group distribution from the\ntraining set. This approach is adopted to mitigate the uncertainty in estimating group accuracies,\nas the number of images belonging to the minority group in the Waterbird dataset is significantly\nsmaller compared to other datasets (Sagawa et al., 2019).\nCelebA\nCelebA dataset by (Liu et al., 2015) is a collection of facial images of celebrities from around the\nworld. It includes attribute values associated with each individual, such as hair color and gender. In\norder to evaluate the effects of subpopulation shifts, Sagawa et al. (2019) reformulated the CelebA\n19\n\nCMNIST\nWaterbirds\nCelebA\nCivilComments\nAvg\nWorst\nAvg\nWorst\nAvg\nWorst\nAvg\nWorst\nERM‡\n27.8± 1.9%\n0.0± 0.0%\n97.0± 0.2%\n63.7± 1.9%\n94.9± 0.2%\n47.8± 3.7%\n92.2± 0.1%\n56.0± 3.6%\nASAM\n40.5± 0.8%\n34.1± 1.2%\n97.4± 0.0%\n72.4± 0.4%\n93.7± 0.8%\n46.5± 10.3%\n92.3± 0.1%\n58.9± 1.7%\nIRM‡\n72.1± 1.2%\n70.3± 0.8%\n87.5± 0.7%\n75.6± 3.1%\n94.0± 0.4%\n77.8± 3.9%\n88.8± 0.7%\n66.3± 2.1%\nIB-IRM‡\n72.2± 1.3%\n70.7± 1.2%\n88.5± 0.6%\n76.5± 1.2%\n93.6± 0.3%\n85.0± 1.8%\n89.1± 0.3%\n65.3± 1.5%\nV-REx‡\n71.7± 1.2%\n70.2± 0.9%\n88.0± 1.0%\n73.6± 0.2%\n92.2± 0.1%\n86.7± 1.0%\n90.2± 0.3%\n64.9± 1.2%\nCORAL‡\n71.8± 1.7%\n69.5± 0.9%\n90.3± 1.1%\n79.8± 1.8%\n93.8± 0.3%\n76.9± 3.6%\n88.7± 0.5%\n65.6± 1.3%\nGDRO‡\n72.3± 1.2%\n68.6± 0.8%\n91.8± 0.3%\n90.6± 1.1%\n92.1± 0.4%\n87.2± 1.6%\n89.9± 0.5%\n70.0± 2.0%\nDomainMix‡\n51.4± 1.3%\n48.0± 1.3%\n76.4± 0.3%\n53.0± 1.3%\n93.4± 0.1%\n65.6± 1.7%\n90.9 ± 0.4%\n63.6± 2.5%\nFish‡\n46.9± 1.4%\n35.6± 1.7%\n85.6± 0.4%\n64.0± 0.3%\n93.1± 0.3%\n61.2± 2.5%\n89.8± 0.4%\n71.1± 0.4%\nLISA‡\n74.0± 0.1%\n73.3± 0.2%\n91.8± 0.3%\n89.2± 0.6%\n92.4± 0.4%\n89.3± 1.1%\n89.2± 0.9%\n72.6± 0.1%\nPDE‡‡\n–%\n–%\n92.4± 0.8%\n90.3± 0.3%\n92.0± 0.6%\n91.0± 0.4%\n86.3± 1.7%\n71.5± 0.5%\nASGDRO\n74.8± 0.1%\n74.2± 0.0%\n92.3± 0.1%\n91.4± 0.1%\n92.1± 0.4%\n91.0± 0.5%\n90.2± 0.2%\n71.8± 0.4%\nTable 5: Subpopulation Shift. ‡ denotes the performance reported from (Yao et al., 2022), and ‡‡ denotes the\nperformance reported from (Deng et al., 2024). Avg. denotes average accuracy, and Worst denotes worst group\naccuracy\ndataset to align with the task of predicting whether the hair color is blond or not. In this case, the\nspurious feature is gender, and thus, the dataset is composed of four groups based on the combinations\nof hair color and gender. It can be observed from Figure 6 that images belonging to Class 0,\ncorresponding to dark hair rather, are plentiful regardless of gender. However, for images in Class\n1, which represent blond hair, the majority of them are distributed in the Female group. Therefore,\ngender can act as a spurious feature, and the goal of this task is to obtain a model that focuses solely\non the invariant feature, hair color, rather than the face which may capture the characteristics of\ngender-related features.\nThe best model is selected based on the best worst-group accuracy on the validation set. In this\ncase, the validation set and test set have the same distribution of images per group as the training set.\nTherefore, the average test accuracy reflects this distribution accordingly.\nCivilComments\nThe CivilComments dataset, (Borkan et al., 2019), is a dataset that gathers comments from online\nplatforms and is used for the task of classifying whether a given comment is toxic or not. We\nconduct the experiment on the CivilComments dataset, which has been reformulated by (Koh et al.,\n2021). Each comment is labeled to indicate whether it mentions the presence of any word of\nthe 8 demographic identities; Black, White, Christian, Muslim, other religions, Male and Female.\nTherefore, the CivilComments dataset consists of 16 groups, formed by the combination of toxic labels\nand the presence or absence of the 8 demographic identities in each comment. Each demographic\nidentity can potentially act as a spurious feature. To prevent this, the goal of the task is to train the\nmodel to focus solely on the invariant feature of toxic labels and not rely on demographic identities\nas predictive factors.\nHowever, in reality, unlike other datasets, each comment in the CivilComments dataset can mention\nmore than one demographic identity. Considering all possible combinations of demographic identities\nfor each comment and training the model on all these combinations would be inefficient. Therefore,\nwe follow the learning approach proposed by (Koh et al., 2021). Concretely, we only consider four\ngroups based on whether the comment mentions toxicity and whether it mentions the demographic\nidentity of being “Black”, without considering other demographic identities. We train the model using\nthese four groups. However, during the validation and test, we evaluate the model’s performance\nindividually for all 16 groups and record the lowest accuracy among the group accuracies as the\nworst-group accuracy. The Best model is selected based on this worst-group accuracy.\nExperimental Details\nThe search range of the hyperparameter ρ, which determines the range for exploring the flat region, is\nfixed to {0.05, 0.2, 0.5, 0.8, 1.0, 1.2, 1.5} for all datasets. We evaluate the model across three random\nseeds and report the average performance. We set robust step size γ, in Algorithm 1 of the main paper,\n{0.1, 0.01}. In addition, we use the same range for adjusted-group coefficient C, {0, 1, 2, 3, 4, 5}\n(Section 3.3 in (Sagawa et al., 2019) for details). In CMNIST, Waterbirds, and CelebA datasets, we\n20\n\nutilize ResNet50 (He et al., 2016) models. The same hyperparameter ranges are applied to ASAM\nand ASGDRO, and the other performances for other baselines are reported performances from (Liu\net al., 2021; Yao et al., 2022; Han et al., 2022). All experiments in this paper were conducted using\nNVIDIA RTX A6000 with 49140 MiB of GPU memory and GeForce RTX 3090 with 24.00 GiB of\nGPU memory.\nIn CMNIST, we have the same hyperparameter search range as (Yao et al., 2022) by default: batch\nsize 16, learning rate 10−3, L2–regularization 10−4 with SGD over 300 epochs. For Waterbirds, we\nperform the grid search over the batch size, {16, 64}, the learning rate, {10−3, 10−4, 10−5}, and\nL2–regularization, {10−4, 10−1, 1}. We train our model with SGD over 300 epochs. We also conduct\ngrid search over the batch size, {16, 128}, the learning rate, {10−4, 10−5}, and L2–regularization,\n{10−4, 10−2, 1} for CelebA, training with SGD over 50 epochs. We referenced (Yao et al., 2022;\nLiu et al., 2021) for this range of hyperparameter search. For CivilComments, we use DistilBERT\n(Sanh et al., 2019) model. We follow the hyperparameter search range provided in (Koh et al., 2021).\nFor optimizer, we use AdamW (Loshchilov and Hutter, 2017) with 10−2 for L2–regularization. We\nfind the optimal learning rate among {10−6, 2 × 10−6, 10−5, 2 × 10−5}. We train up to 5 epochs\nwith batch size 16. The gradient clipping is applied only during the second step, which is the actual\nupdate step, in the SAM-based algorithm (Foret et al., 2020).\nA.8\nError bars for Wilds Benchmark\nFigure 7: Standard Deviations for Wilds Benchmark Datasets.\nWe demonstrate the differences between GDRO and ASGDRO in various distribution shift scenarios\nthat could occur in the real world. Wilds benchmark Koh et al. (2021) consists of datasets collected\nfrom the real world. Camelyon17 and RxRx1 are datasets where domain shift is predominant.\nAmazon and FMoW are datasets where both subpopulation shift and domain shift are simultaneously\npredominant. Figure 7 shows the results of ASGDRO and GDRO on Wilds Benchmark, MetaShift\ndataset, and Multi-NLI (Williams et al., 2017). ASGDRO shows superior performances consistently\ncompared with GDRO. It implies that identifying common flat minima across environments enhances\nthe robustness of models.\n21\n\nA.9\nExperimental Details and Error bars for Domainbed with DPLCLIP\nExperimental Details for DomainBed Experiment\nUsing DomainBed framework (Gulrajani and Lopez-Paz, 2020), we evaluate domain generalization\nalgorithms by randomly sampling hyperparameter combinations within predefined hyperparameter\nsearch ranges for each algorithm. The goal of domain generalization is to train models that perform\nrobustly on unseen domains. Consequently, the choice of the best model is heavily influenced by\nwhether the validation set used for model selection is sampled from the test domain or the train\ndomains. To account for this, we provide results for both the training-domain validation set, which\ndoes not utilize information from the test domain, and the test-domain validation set, where model\nselection is performed using information from the test domain. The following subsections present the\nresults for each dataset, considering both model selection methods.\nBy combining ASGDRO with the existing successful domain generalization approach, DPLCLIP\n(Zhang et al., 2021)3, we demonstrate the versatility of ASGDRO, as it can easily be integrated\nwith other algorithms.\nMoreover, our results show that ASGDRO not only improves perfor-\nmance in the context of subpopulation shift but also achieves performance gains in the pres-\nence of domain shift. For experimental details, we set the range of the robust step size γ as\nlambda r: 10**r.uniform(-4, -2) with γ = 0.001 by default and the neighborhood size ρ as\nlambda r: r.choice([0.05, 0.5, 1.0, 5.0]). The other settings are the same as DPLCLIP\n(Zhang et al., 2021). Following common convention, we conducted 20 hyperparameter searches\nand reported the averages for three random seeds. We evaluated our model on the four datasets as\nin the original DPLCLIP paper: VLCS (Fang et al., 2013), PACS (Li et al., 2017), OfficeHome\n(Venkateswara et al., 2017), and TerraIncognita (Beery et al., 2018) and DomainNet (Peng et al.,\n2019).\nModel selection: training-domain validation set\nVLCS\nAlgorithm\nC\nL\nS\nV\nAvg\nDPLCLIP\n99.1 ± 0.5\n61.1 ± 1.5\n72.6 ± 2.6\n83.1 ± 2.5\n79.0\nDPLCLIP GDRO\n99.9 ± 0.0\n61.3 ± 2.5\n74.4 ± 1.1\n83.4 ± 2.6\n79.7\nDPLCLIP ASGDRO\n100.0 ± 0.0\n62.7 ± 0.4\n74.5 ± 1.4\n85.7 ± 0.8\n80.7\nPACS\nAlgorithm\nA\nC\nP\nS\nAvg\nDPLCLIP\n97.6 ± 0.2\n98.3 ± 0.3\n99.9 ± 0.0\n90.5 ± 0.5\n96.6\nDPLCLIP GDRO\n97.0 ± 0.7\n98.2 ± 0.1\n99.8 ± 0.1\n88.6 ± 1.4\n95.9\nDPLCLIP ASGDRO\n97.7 ± 0.1\n98.7 ± 0.1\n99.8 ± 0.0\n91.0 ± 0.5\n96.8\nOfficeHome\nAlgorithm\nA\nC\nP\nR\nAvg\nDPLCLIP\n80.6 ± 0.8\n69.2 ± 0.2\n90.1 ± 0.2\n91.1 ± 0.0\n82.7\nDPLCLIP GDRO\n82.3 ± 0.2\n70.9 ± 0.1\n90.0 ± 0.4\n91.1 ± 0.1\n83.6\nDPLCLIP ASGDRO\n82.1 ± 0.4\n71.3 ± 0.8\n90.3 ± 0.6\n91.2 ± 0.3\n83.7\nTerraIncognita\nAlgorithm\nL100\nL38\nL43\nL46\nAvg\nDPLCLIP\n47.1 ± 1.4\n50.1 ± 1.2\n41.6 ± 1.9\n42.7 ± 0.7\n45.4\nDPLCLIP GDRO\n49.1 ± 0.9\n48.7 ± 2.6\n46.3 ± 2.6\n39.8 ± 1.4\n46.0\nDPLCLIP ASGDRO\n52.8 ± 0.9\n51.5 ± 2.1\n49.2 ± 1.2\n42.1 ± 0.9\n48.9\n3https://github.com/shogi880/DPLCLIP\n22\n\nDomainNet\nAlgorithm\nclip\ninfo\npaint\nquick\nreal\nsketch\nAvg\nDPLCLIP\n70.9 ± 0.3\n51.9 ± 0.3\n66.6 ± 0.3\n14.6 ± 0.5\n84.3 ± 0.2\n66.6 ± 0.1\n59.1\nDPLCLIP GDRO\n71.8 ± 0.4\n51.3 ± 0.4\n67.0 ± 0.3\n15.3 ± 0.2\n84.4 ± 0.1\n65.0 ± 0.9\n59.1\nDPLCLIP ASGDRO\n71.5 ± 0.5\n52.2 ± 0.4\n67.5 ± 0.6\n16.4 ± 0.2\n84.7 ± 0.1\n66.5 ± 0.2\n59.8\nAverages\nAlgorithm\nVLCS\nPACS\nOfficeHome\nTerraIncognita\nDomainNet\nAvg\nDPLCLIP\n79.0 ± 0.7\n96.6 ± 0.1\n82.7 ± 0.2\n45.4 ± 1.0\n59.1 ± 0.1\n72.6\nDPLCLIP GDRO\n79.7 ± 1.3\n95.9 ± 0.4\n83.6 ± 0.1\n46.0 ± 1.0\n59.1 ± 0.2\n72.9\nDPLCLIP ASGDRO\n80.7 ± 0.3\n96.8 ± 0.2\n83.7 ± 0.5\n48.9 ± 0.3\n59.8 ± 0.2\n74.0\nModel selection: test-domain validation set (Oracle)\nVLCS\nAlgorithm\nC\nL\nS\nV\nAvg\nDPLCLIP\n99.8 ± 0.1\n69.7 ± 0.6\n72.4 ± 1.0\n86.2 ± 0.5\n82.0\nDPLCLIP GDRO\n99.9 ± 0.0\n64.9 ± 1.1\n79.1 ± 0.5\n86.5 ± 0.2\n82.6\nDPLCLIP ASGDRO\n99.8 ± 0.1\n67.4 ± 0.9\n78.1 ± 0.5\n86.9 ± 0.1\n83.1\nPACS\nAlgorithm\nA\nC\nP\nS\nAvg\nDPLCLIP\n97.6 ± 0.1\n98.7 ± 0.3\n99.8 ± 0.1\n91.2 ± 0.3\n96.8\nDPLCLIP GDRO\n97.4 ± 0.3\n98.9 ± 0.2\n99.8 ± 0.1\n91.9 ± 0.3\n97.0\nDPLCLIP ASGDRO\n97.7 ± 0.2\n99.1 ± 0.0\n99.9 ± 0.0\n91.7 ± 0.3\n97.1\nOfficeHome\nAlgorithm\nA\nC\nP\nR\nAvg\nDPLCLIP\n81.7 ± 0.2\n70.9 ± 0.1\n90.3 ± 0.3\n90.7 ± 0.0\n83.4\nDPLCLIP GDRO\n81.3 ± 0.8\n70.6 ± 0.3\n90.5 ± 0.1\n90.9 ± 0.3\n83.3\nDPLCLIP ASGDRO\n83.2 ± 0.4\n71.7 ± 0.2\n91.9 ± 0.1\n91.3 ± 0.1\n84.5\nTerraIncognita\nAlgorithm\nL100\nL38\nL43\nL46\nAvg\nDPLCLIP\n55.9 ± 2.3\n58.5 ± 0.3\n48.2 ± 0.5\n40.9 ± 3.0\n50.9\nDPLCLIP GDRO\n57.9 ± 1.0\n55.3 ± 1.5\n49.6 ± 2.0\n41.8 ± 1.4\n51.2\nDPLCLIP ASGDRO\n56.2 ± 0.8\n54.1 ± 0.3\n50.7 ± 0.7\n42.1 ± 0.5\n50.8\nDomainNet\nAlgorithm\nclip\ninfo\npaint\nquick\nreal\nsketch\nAvg\nDPLCLIP\n72.0 ± 0.5\n52.1 ± 0.3\n67.3 ± 0.2\n16.6 ± 0.2\n84.4 ± 0.2\n66.8 ± 0.1\n59.9\nDPLCLIP GDRO\n72.0 ± 0.2\n51.7 ± 0.1\n67.2 ± 0.4\n16.7 ± 0.2\n84.5 ± 0.0\n66.3 ± 0.1\n59.7\nDPLCLIP ASGDRO\n71.5 ± 0.5\n52.8 ± 0.3\n68.1 ± 0.3\n16.5 ± 0.2\n84.9 ± 0.0\n67.0 ± 0.1\n60.2\n23\n\nAverages\nAlgorithm\nVLCS\nPACS\nOfficeHome\nTerraIncognita\nDomainNet\nAvg\nDPLCLIP\n82.0 ± 0.3\n96.8 ± 0.1\n83.4 ± 0.1\n50.9 ± 0.6\n59.9 ± 0.2\n74.6\nDPLCLIP GDRO\n82.6 ± 0.2\n97.0 ± 0.2\n83.3 ± 0.2\n51.2 ± 1.0\n59.7 ± 0.0\n74.8\nDPLCLIP ASGDRO\n83.1 ± 0.2\n97.1 ± 0.1\n84.5 ± 0.1\n50.8 ± 0.3\n60.2 ± 0.1\n75.1\nA.10\nGrad-CAM Analysis\nIn this section, we present additional Grad-CAM (Selvaraju et al., 2017) results on the Waterbirds and\nCelebA datasets. In Figure 8 and 9, the red-colored-name features represent invariant features in the\nrespective task, while the green-colored-name features represent spurious features. In the Grad-CAM\nimages, the pixels that each model focuses on to predict the ground-truth label are highlighted closer\nto the red color in the image.\nERM (Vapnik, 1999) and ASAM (Kwon et al., 2021) are regularization-free algorithms that do not\nspecifically encourage models to focus on invariant features, and this is reflected in the Grad-CAM\nresults. Specifically, when observing Group 0 and Group 3 of Waterbirds, which can strongly\nform the correlation between class and spurious, as well as Group 0, 1, and 2 of CelebA, in most\ncases, the results show a strong focus on both spurious and invariant features simultaneously or\nsolely on spurious features. For some images, particularly between CelebA dataset’s Group 0 and\n1 where there are no minority groups within a class, there is some degree of focus on invariant\nfeatures. However, these images still contain a significant amount of unnecessary pixels such as the\nbackground. Conversely, in minority groups such as Group 1 and 2 in Waterbirds or Group 3 in\nCelebA, there is a predominant focus on invariant features to predict the ground-truth label. However,\nthis focus is limited to only a subset of the overall invariant features and still include some spurious\nfeatures.\nIn algorithms specifically designed to learn invariant features like GDRO (Sagawa et al., 2019), LISA\n(Yao et al., 2022), and ASGDRO (Ours), the Grad-CAM results exhibit different patterns compared to\nERM and ASAM. In the most of results for the three algorithms, the models demonstrate a reasonable\nfocus on invariant features. Compared with ERM and ASAM, there are significant reductions in\nthe extent to which they focus on spurious features. However, GDRO and LISA still concentrate\nonly on a part of invariant features. Additionally, in some cases, they may exhibit a greater focus on\nspurious features than on the subset of invariant features. It is also frequently observed that they still\nheavily include spurious features or solely focus on spurious features when dealing with majority\ngroups such as Group 1 and 3 in Waterbirds or Group 0, 1, and 2 in CelebA. As in the results of\nGroup 1, and 2 in Waterbirds or Group 3 in CelebA, we observe that the models’ low ability to fully\nconcentrate on invariant features is affected by the performance of models that still exhibit a focus on\nspurious features. This observation highlights the impact of the models’ performance on their ability\nto completely focus on invariant features.\nIn contrast to other baselines, ASGDRO demonstrates a stronger focus on invariant features. As a\nresult, Grad-CAM analysis shows that ASGDRO has relatively larger regions of focus on invariant\nfeatures compared to other baselines. Simultaneously, it successfully eliminates spurious features\nwhile accurately predicting the ground-truth label. Therefore, these results demonstrate that ASGDRO\nhas a higher capacity for capturing sufficiently diverse invariant features, and this characteristic is\nreflected in its performance. That is, ASGDRO promotes that the model performs SIL.\n24\n\nFigure 8: Grad-CAM results on the Waterbirds Dataset. The words highlighted in red represent\ninvariant features: Landbird and Waterbird. On the contrary, the words highlighted in green represent\nspurious features: Land and Water background. In the Training Set, Group 1 and Group 2 are minority\ngroups with significantly fewer data samples compared to other groups.\n25\n\nFigure 9: Grad-CAM results on the CelebA Dataset. The features highlighted in red represent\ninvariant words: Dark Hair and Blond Hair. On the contrary, the words highlighted in green represent\nspurious features: Female and Male. In the Training Set, Group 3 is a minority group with significantly\nfewer data samples compared to other groups.\n26\n\nA.11\nHessian Analysis for Waterbirds Dataset\nThe Largest Eigenvalue\nThe Second Largest Eigenvalue\nMethod\nMajority\nMinority\nTotal\nMajority\nMinority\nTotal\nERM\n990\n4894\n2265\n166\n511\n709\nASAM\n972\n5475\n2624\n178\n524\n647\nGDRO\n131\n447\n353\n118\n346\n129\nASGDRO\n107\n342\n279\n98\n274\n105\nTable 6: Hessian Analysis on Waterbirds. ASGDRO finds the common flat minima for both majority and\nminority groups.\nERM and ASAM have significantly sharper minima for the minority group compared to GDRO and\nASGDRO due to the spurious correlation, although ASAM is designed to find flat minima. Compared\nto GDRO and other baselines, ASGDRO achieves the lowest eigenvalue in the first and second\nmaximum eigenvalues for every group.\n27",
    "pdf_filename": "Sufficient_Invariant_Learning_for_Distribution_Shift.pdf"
}