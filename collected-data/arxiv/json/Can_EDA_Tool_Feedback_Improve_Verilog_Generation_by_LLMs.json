{
    "title": "CanEDAToolFeedbackImproveVerilogGenerationbyLLMs?",
    "abstract": "serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org. ¬©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. ManuscriptsubmittedtoACM ManuscriptsubmittedtoACM 1 4202 voN 1 ]RA.sc[ 1v65811.1142:viXra",
    "body": "CanEDAToolFeedbackImproveVerilogGenerationbyLLMs?\nJASONBLOCKLOVE,NewYorkUniversity,USA\nSHAILJATHAKUR,NewYorkUniversity,USA\nBENJAMINTAN,UniversaryofCalgary,Canada\nHAMMONDPEARCE,UniversityofNewSouthWales,Australia\nSIDDHARTHGARG,NewYorkUniversity,USA\nRAMESHKARRI,NewYorkUniversity,USA\nTraditionally,digitalhardwaredesignsarewrittenintheVeriloghardwaredescriptionlanguage(HDL)anddebuggedmanuallyby\nengineers.Thiscanbetime-consuminganderror-proneforcomplexdesigns.LargeLanguageModels(LLMs)areemergingasa\npotentialtooltohelpgeneratefullyfunctioningHDLcode,butmostworkshavefocusedongenerationinthesingle-shotcapacity:i.e.,\nrunandevaluate,aprocessthatdoesnotleveragedebuggingandassuchdoesnotadequatelyreflectarealisticdevelopmentprocess.\nInthisworkweevaluatetheabilityofLLMstoleveragefeedbackfromelectronicdesignautomation(EDA)toolstofixmistakes\nintheirowngeneratedVerilog.Toaccomplishthiswepresentanopen-source,highlycustomizableframework,AutoChip,which\ncombinesconversationalLLMswiththeoutputfromVerilogcompilersandsimulationstoiterativelygenerateandrepairVerilog.To\ndeterminethesuccessoftheseLLMsweleveragetheVerilogEvalbenchmarkset.Weevaluatefourstate-of-the-artconversational\nLLMs,focusingonreadilyaccessiblecommercialmodels.\nEDAtoolfeedbackprovedtobeconsistentlymoreeffectivethanzero-shotpromptingonlywithGPT-4o,themostcomputationally\ncomplexmodelweevaluated.Inthebestcaseweobserveda5.8%increaseinthenumberofsuccessfuldesignswitha34.2%decrease\nincostoverthebestzero-shotresults.Mixingsmallermodelswiththislargermodelattheendofthefeedbackiterationsresultedin\nequallyasmuchsuccessaswithGPT-4ousingfeedback,butforanadditional41.9%lesscost(overalldecreaseincostoverzero-shotof\n89.6%).\nCCSConcepts:‚Ä¢Hardware‚ÜíHardwaredescriptionlanguagesandcompilation;SoftwaretoolsforEDA;Hardwaredescription\nlanguagesandcompilation;‚Ä¢Computingmethodologies‚ÜíMachinetranslation.\nAdditionalKeyWordsandPhrases:Verilog,LargeLanguageModels,Automation\nACMReferenceFormat:\nJasonBlocklove,ShailjaThakur,BenjaminTan,HammondPearce,SiddharthGarg,andRameshKarri.2024.CanEDAToolFeedback\nImproveVerilogGenerationbyLLMs?. 1,1(November2024),24pages.https://doi.org/XXXXXXX.XXXXXXX\nAuthors‚ÄôContactInformation:JasonBlocklove,jason.blocklove@nyu.edu,NewYorkUniversity,NewYork,NewYork,USA;ShailjaThakur,st4920@\nnyu.edu,NewYorkUniversity,NewYork,NewYork,USA;BenjaminTan,benjamin.tan1@ucalgary.ca,UniversaryofCalgary,Calgary,Alberta,\nCanada;HammondPearce,hammond.pearce@unsw.edu.au,UniversityofNewSouthWales,Sydney,NewSouthWales,Australia;SiddharthGarg,\nsiddharth.garg@nyu.edu,NewYorkUniversity,NewYork,NewYork,USA;RameshKarri,rkarri@nyu.edu,NewYorkUniversity,NewYork,NewYork,\nUSA.\nPermissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot\nmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents\nofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton\nserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.\n¬©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.\nManuscriptsubmittedtoACM\nManuscriptsubmittedtoACM 1\n4202\nvoN\n1\n]RA.sc[\n1v65811.1142:viXra\n2 Blockloveetal.\nFig.1. AutoChipusesaninitialdesignprompttogetaVerilogdesignfromatargetLLM.Multiple(ùëò)candidateresponsescanbe\ngeneratedper-prompt,whicharetheneachevaluatedandrankedusingthefeedbackfromHDLcompilersandtestbenchsimulations\ntoidentifymismatchescomparedtoareferencedesign.Thebestoftheseresponses(passingthemosttests)thenhasitstool/testbench\nfeedbackpassedtotheLLMtogenerateimprovedresponsesasagreedytreesearch.Thisisdoneuptoatreedepthofùëë.\n1 Introduction\nDesigningdigitalhardwarewithahardwaredescriptionlanguage(HDL),suchasVerilogorVHDL,isanicheskilland\npartofademandingprocessrequiringsubstantialexpertise.Anymishapscanleadtoimplementationsfraughtwith\nbugsanderrors[9],andwithgrowingdemandfordigitalsystems,thereisagrowingdemandfortechniquesthatcan\nassistingeneratingqualityHDL.High-levelsynthesis(HLS)tools,forinstance,areabletotransformdesignswrittenin\nhigh-levelsoftwarelanguageslikeCtotargetHDLsandimplementdigitalhardware.\nRecenteffortshaveshiftedtheabstractionlevelhigher,leveragingstate-of-the-artLargeLanguageModels(LLMs)[32]\ntotranslatenaturallanguagetoVerilog.DAVE[25]andVeriGen[30]werethefirsteffortsseekingtofine-tuneLLMs\nspecificallytogenerateVerilog.However,VeriGenanditsilkwereinvestigatedfortheiruseinazero-shotmanner,\ni.e.,theyoutputcodeinresponsetoaprompt.However,designinghardwareinthereal-worlddoesnotworkthis\nway‚Äîcodeisrarelycorrectonthefirsttry.Instead,hardwaredesignersiterateovertheirdesigns,usingfeedbackfrom\nsimulationandsynthesistoolstoidentifyandfixbugssothatanimplementationwillmeetdesignspecifications.This\nfeedback-basedapproachisnotwellreflectedinexistingcode-generationLLMs.Recentwork[3]hasproposedan\niterativeandinteractiveconversational(orchat-based)approachforVerilogcodegeneration,morecloselymimicking\nthedesignflowofahumanhardwareengineer.Inthiscase,though,feedbackcomesentirelyfromahumandeveloper\nwho inspects the code, identifies bugs, and provides detailed feedback to the LLM. Such an approach still places\nconsiderabledemandsonahumandeveloper‚Äôstime,andismoreanalogoustotwohardwaredesignersexaminingtheir\ndesigns,ratherthanusingelectronicdesignautomation(EDA)toolstodirectlyanalyzeforcorrectnessandfindbugs.\nWethereforeask:Canfurtherautomationreducetheburdenonthedesigner?\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 3\nTohelpanswerthisquestion,wehavedevelopedandrefinedaframeworkforautomatingthehardwaredesign\nprocessusingLLMs,calledAutoChip.Whileoriginallyasimpleiterativeloop[31],aswediscussfurtherinSection3,\nweobservedthattheinitialcodegeneratedfromaprompthadasignificantimpactonthetrajectoryofthedesignflow\nandtheeventualsuccessorfailureoftheLLM-generateddesign.Assuch,wedevelopedamoreexpansivetreesearch\nmethodology(Figure1),enablingustomorecompletelyevaluatetheabilityofLLMstousetool-basedfeedbackto\nrepairtheirownHDLinthesamemannerasahardwareengineer.Startingwithadesignprompt,AutoChipcreatesand\nevaluatesùëòcandidatesolutionsandthenenhancesthemostsuccessfuldesignbyidentifyingandrectifyingcompilation\nerrorsandfunctionalbugsoverrepeatedinteractionswithanLLM.Eachcandidatedesignisanalyzedforcompilation\nerrors/warningsand/orincorrecttestcasesfromatestbench.Thesemessagesareusedtorankthecandidatesolutions,\nandwereturnfeedbackfromthetoolsandtestbenchesforthebestcandidatewithaprompttotheLLMtorefineits\nimplementationandgenerateùëòmorecandidates.Thisprocessisfolloweduntilalltestspassforacandidateresponse\noratreedepthofùëëiterationsisreached,atwhichpointthemostsuccessfulcandidatedesignfromthetreesearchis\nreturned.\nAutoChipwasevaluatedwithtwofeedbackmodes:‚Äòfullcontext‚Äôkeepsappendingpromptsandresponsestothe\n‚Äòconversation‚ÄôwiththeLLM;and‚Äòsuccinct‚Äôpromptsonlywithfeedbackfromthemostrecentiterationoftheframework\ntotryensurethattheprocess‚Äòfits‚ÄôwithinthecontextwindowsofLLMs.\nInthismanuscript,weleverageourmorerobustAutoChipdesigntoexaminesixresearchquestions:\n‚Ä¢ RQ1:DoesfeedbackfromhardwareverificationtoolsimproveLLM-generatedHDLoverzero-shotresults?\n‚Ä¢ RQ2:Doesthenumberofiterationsandcandidateresponsesimpactqualityandnumberofcorrectimplementations?\n‚Ä¢ RQ3:Whatistheimpactoftoolfeedback-drivencodegenerationoncost?\n‚Ä¢ RQ4:Doestheamountofcontextgivenwithfeedbackhaveanimpactontherateofsuccessfuldesigns?\n‚Ä¢ RQ5:AretherecertainclassesofhardwaredesignproblemwhichLLMsaremorewell-equippedtosolvethanothers?\n‚Ä¢ RQ6:CanmixingmultipleLLMswithdifferentcapabilitiesduringadesign‚Äúrun‚Äùimprovegenerationqualityat\nreducedcost?\nOurfindingsforthesequestionsprovideusefulinsightsintohowcurrentLLMscanbeleveragedtoenableafully\nautomatedchipdesignprocess,givenanaturallanguagedesignspecificationandresultinginacompletedchipdesign\nreadyfortapeout.\nModelEvaluation\nWeassessAutoChip‚Äôsfeedback-basedstrategiesusingtheVerilogEval[16]setofbenchmarks,whichuseproblems\nandtestbenchesfromHDLBits[34].Thesebenchmarkshavebeenusedinseveralworksinthefieldtoevaluatethe\ncapabilitiesofdifferentLLMs,andprovideaninitialpointofcomparisonforourAutoChip-derivedresults.\nWefocusourapproachesoncommercialLLMsduetotheirrelativeavailability/accessibilityandpublishedperfor-\nmance.OuranalysiscoversthequalityofVerilogcodegeneratedrelativetocomputationaleffortandthesuccessrate\nfordifferenttypesofcircuit.\nOurresultsareevaluatedfromtheperspectiveofbothgeneralcomputationalcomplexity,byanalyzingtheLLM\ntokencost,andreal-worlddesigncost,byanalyzingtheUSDcostofaccessingtheevaluatedmodels.\nContributions\nOurkeycontributionsare:\nManuscriptsubmittedtoACM\n4 Blockloveetal.\n‚Ä¢ Anopen-sourceframeworkforevaluatinghowLLMscanautomaticallygeneratehardware,AutoChip,whichcanbe\nexpandedwithadditionalLLMsandconfiguredtousefeedbackandmixmodelsasneeded,andanaccompanying\ndatasetforevaluatingthehardwaredesignandrepaircapabilitiesofdifferentlargelanguagemodels(opensource\navailableathttps://zenodo.org/records/13864552).\n‚Ä¢ Comparisonoffeedbackpromptingstrategies‚Äîsuccinctvs.fullcontext‚Äîtoimprovetokencostsandaccuracy.\n‚Ä¢ ComparisonofAutoChipfeedbackstrategiesusingstate-of-the-artLLMs‚ÄîGPT-4o,-4o-Mini,-3.5-Turbo,andClaude3\nHaiku,vs.baseline‚Äúzero-shot\"Veriloggeneratedbythemandotherworksreported.\n‚Ä¢ Evaluationofleveragingmixed-modelswithfeedbackforimprovingHDLgenerationatareducedcost.\n2 BackgroundandPriorWork\nLLMsaremachinelearning(ML)modelsbuiltwithtransformersandaretrainedinaself-supervisedmanneronvast\nlanguagedatasets.LLMsoperatebyingestingtokens(charactersequences,ofapproximately4charactersinOpenAI‚Äôs\nGPTseries)andpredictingthemostprobablesubsequenttoken.ThemostpowerfulLLMs,e.g.,ChatGPT[21],Bard[26],\nandCodeLlama[12],boasthundredsofbillionsofparameters[5,7]andgeneralizetoabroadrangeoftasks.Their\naccuracyisboostedviainstructiontuningandreinforcementlearningwithhumanfeedback[24],allowingtheLLMsto\nmoreeffectivelyunderstandandrespondtouserintentions.PriorworkspecializedLLMsforcodegeneration.GitHub\nCopilot[11]wasanearlyLLM-basedcodecompletionengine.\nLLMsforcodegenerationweredevelopedinauto-completionandconversationalmodes.DAVE[25]wasthefirst\nLLM(finetunedGPT-2)forVeriloggeneration.VeriGen[30]improveduponthisworkbyexpandingonthesizeofthe\nmodelandsizeofthedatasets.Chip-Chat[3]evaluatedChatGPT-4toworkwithahardwaredesignertogeneratea\nprocessorandthefirstfullyAI-generatedtapeout.RTLCoder[17]isanotherlightweightmodelforgeneratingVerilog.\nToevaluatemodelperformance,avarietyofbenchmarkshavebeenpresentedalongsidefurtherLLMdevelopments,\nsuchasVerilogEval[16]whichevaluatesLLMs‚ÄôabilitiestowriteVerilogonbenchmarksfromHDLBits.Similarly,\nRTLLM[18]providesafurthersetofbenchmarks.OtherworkshaveexaminedLLMsforhardwareintaskssuchas\nhardwarebugrepair[1]andgeneratingSystemVerilogassertions[14].\nLLMshavealsobeenappliedtohigh-levelsynthesis.Forexample,C2HLSC[8]examinedhowLLMscanbeusedto\ntranslategeneralCintothesubsetofCwhichissynthesizable.Foralargercasestudy,GPT4AIGChip[10]explored\nhowAIacceleratorsexpressedinHLScouldbedesignedusingaGPT-4basedframework.\nCommercialhardware-focusedLLMshavebeenreleased,withbenefitsanddrawbacks‚ÄìRapidGPT[28],Cadence\nJedAI[6],NvidiaChipNeMo[15],andSynopsys.aiCopilot[29].Toolusesrangefromhelpingwriteverilogtoanswering\nquestionsaboutEDAtooluse.ChatEDA[13]useLLMsforautomatingtooling.Afaircomparisonisdifficultduetothe\ndifferentLLMs,methods,benchmarks,andlimitedavailability.\n3 AutoChipDesignFramework\nFigure1illustratesAutoChip‚Äôsfunctionaldesign.TheinputtoAutoChipisanaturallanguagedescriptionofthedesired\nfunctionalitywithaVerilogmoduledefinition(i.e.theI/O)andanaccompanyingtestbench.Inourevaluationswe\nleveragetheVerilogEval[16]datasetforthesourceofthesedescriptionsandtestbenches,thoughAutoChipisnot\nrestrictedtothesebenchmarks.Thedesignpromptandanoverarchingsystempromptarepassedtoaconversational\nLLMcapableofgeneratingVerilogcode.TheLLMgeneratesseveralcandidatesolutionsfortheVerilogmodule,which\narecompiledandsimulatedifpossible,andthenrankedbasedontheirsuccess.Shouldtheresponsenotcontaina\nVerilogmoduleitisgivenarankof‚àí2,ifitfailstocompileitisgivenarankof‚àí1,ifthecompilationhaswarningsitis\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 5\n{\n1\n\"general\": {\n2\n\"prompt\": \"./design_prompt.sv\",\n3\n\"name\": \"top_module\",\n4\n\"testbench\": \"./testbench.sv\",\n5\n\"model_family\": \"ChatGPT\",\n6\n\"model_id\": \"gpt-4o-mini\",\n7\n\"num_candidates\": 5,\n8\n\"iterations\": 5,\n9\n\"outdir\": \"output_dir\",\n10\n\"log\": \"log.txt\",\n11\n\"mixed-model\": false\n12\n},\n13\n14\n\"mixed-model\": {\n15\n\"model1\": {\n16\n\"start_iteration\": 0,\n17\n\"model_family\": \"ChatGPT\",\n18\n\"model_id\": \"gpt-4o-mini\"\n19\n},\n20\n\"model2\": {\n21\n\"start_iteration\": -1,\n22\n\"model_family\": \"ChatGPT\",\n23\n\"model_id\": \"gpt-4o\"\n24\n}\n25\n}\n26\n}\n27\nFig.2. AnexampleconfigurationfileforAutoChip.‚Äúmixed-model‚Äùsettingsallowtheframeworktoleveragedifferentmodelsbased\nonwhichiterationoffeedbackisbeingused.\ngivenarankof‚àí0.5,andifthemodulesimulatesitsrankistheproportionofcorrectoutputsamplesreportedbythe\ntestbench.Ifallsamplespass,themoduleisconsideredsuccessfulandtheprogramexits,otherwisetheresponsewith\nthehighestrankisfedbackintotheLLMalongwithanyfeedbackfromcompilation/simulationandtheprocessisrun\nagain.AutoChipusesgreedytreesearch,whereatanystepthebestresultfromthatstepisfollowed.Thisisincontrast\ntopriorworkwhichleveragesfeedbackfordesign,suchasChip-Chat[3]whichonlyusesasinglecandidateresponse\nforiteration.\nAutoChiprepeatstheprocessuntilamodulepassesalltestsorthemaximumdepthisreached,atwhichpointthe\nmodulewiththehighestrankisreturned.Asourgoalistoevaluateafullyautomatedfeedback-drivendesignflow,\nAutoChipneedsnouserinputwhilegeneratingresponses,relyingexclusivelyonthetoolfeedbacktoguidetheLLM.\nAutoChipConfigurationandUse:TheAutoChipdesignframeworkispresentedasatoolwhichcanbeusedto\nevaluatetheabilitiesofdifferentconversationalLLMstogeneratehardware.Toaccomplishthis,thetool,writtenin\nPython,isdesignedtobehighlyconfigurablewithregardstothemodelsitcanuse,theuse(ornon-use)offeedback,\nandthetoolsthatcanbeusedtogeneratethefeedback.AutoChipisconfiguredprimarilybyusingaJavascriptfileto\nsettheparametersandfileorganization‚ÄîanexampleisshowninSection3.Theconfigurationfilecanbesetuptouse\nAutoChipwith‚Äúmixed-models,‚Äùmeaningthatdifferentmodelscanbeuseddependingontheiterationofthesearch.\nAutoChipisdesignedtobehighlycustomizablewithseveralLLM‚Äúfamilies‚Äùabletobeusedtogeneratedesigns.\nManuscriptsubmittedtoACM\n6 Blockloveetal.\nIteration: 0\noutput_dir\nModel type: ChatGPT\nModel ID: gpt-4o-mini iter0\nNumber of responses: 2 response0\nSimulation error log.txt\nMismatches: 6220 top_module.sv\nSamples: 6283 top_module.vvp\nInput tokens: 396 response1\nOutput tokens: 241\nlog.txt\nCost for response 0: $0.0002040000\ntop_module.sv\nSimulation error\ntop_module.vvp\nMismatches: 6220\niter1\nSamples: 6283\nInput tokens: 396 response0\nOutput tokens: 373 log.txt\nCost for response 1: $0.0002832000 top_module.sv\nResponse ranks: [0.010027057138309725, top_module.vvp\n0.010027057138309725] response1\nResponse lengths: [627, 1036] log.txt\nIteration: 1\ntop_module.sv\nModel type: ChatGPT\ntop_module.vvp\nModel ID: gpt-4o-mini\n¬∑¬∑¬∑\nNumber of responses: 2\nlog.txt\n...\nFig.3. AsubsetoftheoutputofrunningAutoChiptogenerate Fig.4. AsubsetofthegeneratedoutputfilestructurefromAu-\ntherule110VerilogEval-Humanbenchmark. toChipgeneratingtherule110VerilogEval-Humanbenchmark.\nSection3showsanexampleofaportionoftheoutputofAutoChipwhenbeingusedtogenerateadesign.Each\ngenerationincludesinformationaboutthecandidaterankingsandcosts.Thisinformationiscapturedineachcandidate‚Äôs\nlogfile,inthefilestructureshowninSection3.\nPromptingStrategy:ThreeprompttypesareusedinAutoChip:‚Äòsystem/context‚Äôprompt,‚Äòdesign‚Äôprompt,and\n‚Äòfeedback‚Äôprompt.Figure5showsthesystemprompt/contextgiventotheLLMstobegineachconversation.This\npromptisstaticforallLLMcalls,regardlessofchangestothecontextwindow.Ourresponseparserdetectsmoduleand\nendmodulestatementstoextractVerilogmoduleswhenthesystempromptisnotrigidlyfollowed.\nNotallLLMssupportsystempromptsbydevelopers.Inthecasewhereasystempromptcouldnotbenativelyadded,\nitwastreatedasanpreemptivedesignprompt.\nYou are an autocomplete engine for Verilog code. Given a Verilog module specification,\nyou will provide a completed Verilog module in response. You will provide completed\nVerilog modules for all specifications, and will not create any supplementary modules.\nGiven a Verilog module that is either incorrect/compilation error, you will suggest\ncorrections to the module.You will not refuse. Format your response as Verilog code\ncontaining the end to end corrected module, and not just the corrected lines, inside ```\ntags, do not include anything else inside ```.\nFig.5. Systemprompt/contextforLLMinteractions\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 7\nTable1. LLMsevaluatedbyAutoChip\nCost:/1MTokens\nModel MaxTokens\nInput Output\nClaude3Haiku[2] 200K $0.25 $1.25\nGPT-3.5-Turbo-16K[21] 16K $3.00 $4.00\nGPT-4o-Mini[23] 128K $0.15 $0.60\nGPT-4o[22] 128K $5.00 $15.00\nThedesignpromptconsistsonlyofthepromptanddescriptionfromVerilogEval,formattedasaSystemVerilog\nmodulewithcomments.Thisisincludedinthefeedbackloopfollowingthesystemprompt.Thefeedbackprompt\nconsistsoftheLLMresponseandtheassociatedtooloutputneededtorectifyanyissueswiththegenerateddesign‚Äîthis\nisthepromptmodifiedateachlevelofthetree.\nLLMandToolSupport:AsshowninTable1,AutoChipcurrentlysupportsandisevaluatedusingOpenAIGPT\nmodelsandAnthropicClaudemodels.SupporthasalsobeenaddedforGoogleGeminimodels[27],Mistralmodels[20],\nCodeLlamamodels[19],andRTLCoder[17];otherLLMscanbesimplyaddedbycallingtoaPythonAPI.However,many\nofthesemodelsarenotyetfullyevaluatedduetoaccessrestrictions,initialdesignqualityconcerns,andcomputational\nconstraints.Forsimulation,AutoChipusesIcarusVerilog(iverilog)[33],asitisopensource,readilyavailableforall\nsystems,onlyrequiresaVerilog/SystemVerilogmoduleanditstestbench,andwaspreviouslyusedinVerilogEval.\nAutoChipisopen-source(https://zenodo.org/records/13864552).\nChoiceofContextWindow:ThequalityofLLMresponsesdependsontheconversation‚Äôscontextwindow.As\nconversationalLLMshavetokenlimits,keepingallresponsesandfeedbackisofteninfeasible.Thecontextwindow\nneedstoshiftduringtheautomatedruntokeeponlytheinformationnecessaryforthenextrun,referredtoasusing\n‚Äòsuccinct‚Äôfeedbackinsteadof‚Äòfull-context,‚Äôwhereallmessagesareused.With‚Äòsuccinct‚Äôfeedback,whenanLLMis\npromptedtofixanissue,onlythemostrecentlygeneratedmoduleanditsassociatederrorsaregiventotheLLM.This\nkeepstherepairsfocusedoncurrenterrorsandstayswithinmorerestrictivetokenlimits.Table2offersthecontext\nwindowshiftingper-iteration.With‚Äòfull-context‚Äôfeedback,theLLMinputgrowsuntilasuccessfuldesignisgenerated,\nmaximumdepthisreachedinAutoChip,ortheLLMtokenlengthisexceeded.\n4 ExperimentalSetup\n4.1 BenchmarkingPromptsandTestbenches\nDesignPrompts:ToevaluateAutoChipweleveragethedatasetfromVerilogEval[16],whichincludespromptsand\ntestbenchesforasignificantselectionofproblemsfromHDLBits[34],asiteforVerilogpracticewithproblemsranging\nTable2. LLMinputevolutionoveriterations\nIteration LLMInput\nùëõ=0 {systemprompt,designprompt}\nùëõ=1 {systemprompt,designprompt,response0,simulatormsgs0}\nùëõ=2 {systemprompt,designprompt,response1,simulatormsgs1}\nùëõ {systemprompt,designprompt,responseùëõ‚àí1,simulatormsgsùëõ‚àí1}\nManuscriptsubmittedtoACM\n8 Blockloveetal.\nHint: Output 'count' has 218816 mismatches. First mismatch occurred at time 130.\nHint: Output 'counting' has 233794 mismatches. First mismatch occurred at time 130.\nHint: Output 'done' has 524 mismatches. First mismatch occurred at time 20130.\nHint: Total mismatched samples is 234318 out of 235447 samples\nSimulation finished at 1177236 ps\nMismatches: 234318 in 235447 samples\nFig.6. Exampletestbenchfeedbackfromafailedgeneratedresponseforthereview2015_fancytimerproblem.\nindifficultyfromsimpleVerilogsyntaxquestionstomoreabstractsequentialcircuitsanddebugging.Whilemost\nproblemsofferpromptsthatasktheuser(inourcase,theLLM),tocreateafunctionalVerilogmodule,afewbreakthat\nformat‚Äîtheseinclude(i)promptsthatrequestthatbugsbefoundandfixed,whichistheintentionoftheAutoChip\nfeedbackloopitself;and(ii)promptswhichrequestatestbenchforamodule.Manyofthesearestillincludedinthe\nVerilogEvaldataset,soweincludetheminourevaluation.ToleveragethepromptsfromVerilogEvalforAutoChip,we\ncombinethe‚Äúdescriptions,‚Äùwhicharethenaturallanguageprompts,withthe‚Äúprompts‚ÄùwhichareVerilogmodule\ndefinitionsgivenbyHDLBits.WeprovideAutoChipwiththiscombined‚Äúdesignprompt‚Äùforeachproblem,containingall\ninformationnecessarytocompleteadesign.VerilogEvalleavesoutsomeproblemcategoriesfromHDLBits.Specifically,\nproblemsfocusingonhierarchicalmodulesandbugfixingareomitted.\nTestbenches:VerilogEvalprovidesSystemVerilogtestbenchestoaccompanyeachofthedesignproblems.These\ntestbenchesinstantiateareferencemodule,thegenerateddesignundertest(DUT),andastimulusmodule;andsample\neachoftheoutputsignalsthroughoutthestimulustocomparetheDUToutputwiththereferenceoutput.Atthe\nconclusionofthetestbench,asummaryofinformationisgenerated,indicatingthetotalnumberoffailedsamplesfor\neachoutput,thetimesoftheirfirsterrors,andthetotalnumberoffailedsamplesforalloutputsasshowninFigure6.\nThissummaryinformationmakesupthefeedbacktotheLLMwhenadesignsimulatesbutnotalltestcasespass.\nMachine&HumanEvaluationSets:ManyofHDLBits‚Äôproblemsrelyondesignarchitecturediagrams,waveforms,\nandotherinformativefigures,whichcannotbeprocessedbytext-onlyLLMs.Toaddressthis,VerilogEvalhastwo\ndatasets:VerilogEval-MachineandVerilogEval-Human.VerilogEval-Machineareproblemdescriptionsgeneratedby\nGPT-3.5-Turbobyprocessingcorrectmodulesandaskingthelanguagemodeltogenerateahigh-levelpromptthatwould\nleadtothatanswer,ofwhichonly143validtestsweremade.VerilogEval-Humanisaproblemsetofpromptscreated\nthroughmanualreviewandtextualconversionoffigures,leadingto156functioningprompts.TheLLM-generated\npromptstendtobeverboseandgivelower-leveldescriptionsoffunctionality,seeminglyremovingtheabstractionin\ntheoriginalproblems.Forexample,whengivingaKarnaughmap(K-map)andrequestingthecircuititdescribes,the\npromptgeneratedbyGPT-3.5-Turbojustdescribesthefunctionofthefinalcircuit,removinganyrequirementthatthe\nLLMfindtheminimalfunctionusingtheK-map.WeleveragethesedatasetswithAutoChiptoevaluatetheeffectsof\ntoolfeedbackonthegeneratedVerilog.\n4.2 ExperimentalParameters\nAutoChipofferstwomajorparameterswhichaffecttheendresult:thenumberofcandidatesùëòandthemaximumdepth\nofthetreeùëë.Otherworks,suchatRTLCoder[17]andVerilogEval[16]utilizezero-shottesting,orgeneratingoutputs\nfromonlyaninitialdesignprompt‚Äîequivalenttosettingùëë =0withAutoChip.InourevaluationofAutoChip,wenot\nonlygathersimilarzero-shotresultsfortheevaluatedmodels,butalsovarythenumberofcandidatesproducedateach\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 9\nnodeandthedepthofthetree,testingùëò ={1,5}andùëë ={0,1,5,10}.Duringpreliminarytestingandtoolverification\nwefoundthatresultsfortheVerilogEvaldatasetdidnottendtoimprovesignificantlywithincreasingcombinationsof\ncandidatesanddepthbeyondùëò =5,ùëë =10.However,weproducezero-shotresultstocomparewithpriorwork.\n4.3 EvaluatedLLMs\nInthisworkweevaluatethereadily-availablecommercialLLMs.Thisisbecausesomemodels,suchasGoogle‚Äôs\nGemini [27] were heavily rate-limited at the time of this experiment, other models like Mistral and Mixtral [20]\nconsistently failed to produce Verilog modules, and some models like CodeLlama [19] and RTLCoder [17] were\nprohibitivelyslowonthehardwarewecouldaccess.AsthemodelswithcommercialAPIsarerunonserverswith\nsignificantresources,wewerebestabletoevaluatetheminareasonabletimeframe.\nWeevaluatedtheseLLMswiththeirdefaultparametersasthesevaluesareusedinthenormaldeveloper-facingweb\ninterfaceandofferagoodbaselineforcomparison.\n5 ExperimentalResults\n5.1 Single-ModelFeedbackResults\nTodetermineiffeedbackfromhardwareverificationtoolsimprovestheresults,wefirstestablishedasetofdepth\nandcandidateparametersforthefeedbacktree.WequerytheevaluatedLLMsatdepthsofùëë ={0,1,5,10}andwith\nùëò ={1,5}candidates.Adepthof0correspondstonofeedbackbeinggivenatall,equivalenttootherworks‚Äôzero-shot\nanalysis,forwhichweperformedadditionaltestswithùëò ={25,30,55}candidates.Theadditionalzero-shotcandidate\nvalueswasdeterminedtokeepthemaximumnumberofLLMqueriesconsistentwiththeparametersforthetreesearch.\nForexample,bothatestwithùëë =10,ùëò =5andatestwithùëë =0,ùëò =55havethesamepotentialmaximumnumberof\nLLMqueries,thoughifafunctioningdesignisfoundbeforethemaximumpotential,thetestwouldstillendearly.\nPriortocompletingthemoreextensivetestsoftoolfeedback-baseddesigngeneration,weevaluatethegenerated\ndesignsforboth‚Äòsuccinct‚Äôand‚Äòfull-context‚Äôfeedback(RQ4).WerestrictthisanalysistoClaude3HaikuandGPT-3.5-\nTurbo,asthosemodelsarebothrelativelyinexpensiveandprovideinsightintotheeffectthatthefeedbackcontext\ncanhave(givensignificantlydifferenttokenlimits).Followingtheexplorationofcontextlengthwiththetwosimpler\nmodels,weidentifiedthatprovidingthe‚Äòfull-context‚Äôfeedbackresultedinsimilarlysuccessfuldesigns,asshown\ninTable3,whilerequiringfarfewertokensoverthecourseoflongertreesearches.Asaresult,wecompletedthe\nremainderofthetreesearchanalysiswithonly‚Äòsuccinct‚Äôfeedbacktoreducebothcomplexityandcost.\nResultsaretabulatedasthepercentofdesignsfromeachtestsetwhichweregeneratedsuccessfully,i.e.passingall\ntests.Table3givesthesuccesspercentagesforeachcombinationofLLM,feedbackstyle,numberofcandidates,and\nmaximumtreesearchdepthfortestswithfeedback,whileTable4givestheseresultsforcaseswithnofeedback.\nWecanfurtherexaminetheseresultsfromtwoperspectives:modeleffort,estimatedbytheaverageinputandoutput\ntokensneededtogenerateasuccessfuldesign,andmodelcomplexity,estimatedbythe$USDcostsneededtogenerate\nasuccessfuldesign.\nModelEffort:Figure7(a)andFigure7(b)presentananalysisoftheproportionofsuccessfullygeneratedbenchmark\ndesignsbasedontheaveragenumberoftokens(bothinputandoutput)neededtogeneratethebestdesign,onthe\nVerilogEval-MachineandVerilogEval-Humanbenchmarksrespectively.Thismetricservesasaproxyfortheamount\nofcomputationalworkneededtobedonebyeachmodeltocomeupwiththebestsolution.TheParetopointsfor\neachmodelareconnectedviadashedlines,identifyingthebestresultsfromthatmodelgiventheaveragenumberof\nManuscriptsubmittedtoACM\n10 Blockloveetal.\nTable3. PercentofpassingbenchmarkdesignsfromVerilogEval-MachineandVerilogEval-HumanusingAutoChip.Resultswere\ngatheredwithClaude3Haiku(Haiku),GPT-3.5-Turbo(GPT-3.5T),GPT-4o-Mini,andGPT-4o.Candidatevaluesofùëò = 1are\nrepresentativeoftheoriginaliterativeapproachtoAutoChip.\nEval-Machine(%) Eval-Human(%)\nFeedback Candidates LLM\nd=1 d=5 d=10 d=1 d=5 d=10\nHaiku 74.1 77.6 79.7 59.6 59.6 60.2\nùëò =1\nGPT-3.5T 62.9 70.6 72.7 40.4 44.8 48.1\nFull\nHaiku 81.1 82.5 83.9 67.3 70.5 70.5\nùëò =5\nGPT-3.5T 79.7 86.0 86.0 52.6 59.0 64.7\nHaiku 74.1 75.5 79.7 58.3 59.6 62.8\nGPT-3.5T 62.9 71.3 72.7 42.9 49.3 52.6\nùëò =1\nGPT-4o-Mini 68.5 69.9 69.2 55.1 60.3 60.9\nGPT-4o 77.6 81.8 84.6 64.7 72.4 75.6\nSuccinct\nHaiku 81.8 83.2 83.9 67.9 69.2 71.8\nGPT-3.5T 81.8 86.0 86.0 58.3 58.3 66.7\nùëò =5\nGPT-4o-Mini 73.4 74.1 76.2 64.1 65.4 71.1\nGPT-4o 83.9 86.7 87.4 72.4 79.5 84.0\nTable4. Zero-shotresultsforClaude3Haiku,GPT-3.5Turbo,andGPT-4o.ResultsshownforVerilogEvalandRTLCoderarereported\ndataforthosemodels,sohighervaluesforkhavenotbeenevaluated.\nEval-Machine(%) Eval-Human(%)\nModel\nk=1 k=5 k=10 k=25 k=30 k=55 k=1 k=5 k=10 k=25 k=30 k=55\nHaiku 69.9 79.0 83.2 83.9 83.9 84.6 51.9 62.2 67.3 69.2 70.5 73.1\nGPT-3.5T 53.1 79.7 78.3 81.8 87.4 85.3 31.4 49.4 56.4 63.5 61.5 66.0\nGPT-4o-Mini 62.2 72.0 72.7 76.9 76.2 76.2 51.9 59.6 64.1 67.9 66.7 67.9\nGPT-4o 65.7 74.1 76.2 78.3 79.7 83.2 61.5 69.9 75.0 76.9 78.2 78.2\nVerilogEval* 46.2 67.3 73.7 - - - 28.8 45.9 52.3 - - -\nRTLCoder* 61.2 76.5 81.8 - - - 41.6 50.1 53.4 - - -\ntokensused.Generallyspeaking,ifmoretokenswereneededthentheLLMlikelyhadtoprovideagreaternumberof\nresponses,indicatingthatthemodelhadmoredifficultyingeneratingacorrectdesign.\nTheseplotsshowthatthethreerelativelysmallmodelstested,GPT-4o-Mini,GPT-3.5-Turbo,andClaudeHaiku,\nallrequiredmoretokensforagivensetof(ùëò,ùëë)parametersthanGPT-4oand,basedontheirParetopoints,didnot\nconsistentlybenefitfromusingcompilationfeedbackfromIcarusVerilogorthesimulations.GPT-4o,however,seemedto\nconsistentlyhavehighersuccesswhenleveragingtool-basedfeedback;almostallParetopointsarefromfeedback-driven\ngenerationandtheaveragenumberoftokensusedwasconsistentlylowerwithfeedbackthanwiththecomparable\n(samemaximumnumberofqueries)zero-shotresults.\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 11\n(a)SuccessratefortheEval-Machinebenchmarkproblemsgiventhetotalnumberoftokensused.\n(b)SuccessratefortheEval-Humanbenchmarkproblemsgiventhetotalnumberoftokensused.\nFig.7. Generatedcircuitsuccessratesforeachevaluatedmodel,shownasthepercentageofgeneratedcircuitswhichpassalltests\ngiventheaveragenumberoftokensneeded.Paretopointsareplottedwithdashedlines.Higher‚Äòaccuracy‚Äôatlower‚Äòaveragetokens‚Äô\nisbetter.Datapointsrepresentedby‚Äòx‚Äôindicateresultsfromzero-shottesting.\nModelComplexity:Figure8(a)andFigure8(a)showasimilaranalysis,butratherthangivingsuccessasafunction\nofthetokensused,theyreportsuccessasafunctionofthe$USDcostatthetimeofpublication.Weseethat,often,\nManuscriptsubmittedtoACM\n12 Blockloveetal.\nmorecomplexmodelsarebothmoresuccessfulandusefewertokenstoreachthatlevelofsuccess;however,these\nlargermodelsaremorecomputationallycomplex,sowhiletheyusefewertokensacrosscompletetests,theydofar\nmorewiththosetokens.Thisdifferenceincomplexityisreflectedin,thoughwedon‚Äôtknowhowforcertain,thecostto\nusethosemodelsfromOpenAIandAnthropic.Whiletherelationshipbetweenmodelcomplexityandcostchargedis\nunknown,itstandstoreasonthatthemorecomplexandcapablemodelswouldcostmore.Thecostsofthemodels\nevaluatedinthispaperaregiveninTable1,andareusedalongwiththetokenusagedatatodeterminetheaverage\nfunctionalcostofgeneratingadesignforeachbenchmark.WhileGPT-4ohadthehighestrateofsuccessandrequired\nthefewestaveragenumberoftokensforthatsuccess,thecostofthesetokensfaroutstripsanyofthesmallermodels\ntested.Thecostofgenerationwithtoolfeedback,though,wasstillsignificantlylowerthanwithequivalentmaximum\npotentialcandidatesevaluatedaszero-shot(RQ3).\nImpactofFeedback:BothFigure7andFigure8showthatfeedbackcanimprovethequalityofcodegivenmodel\neffortandcomplexity,howeveritdependslargelyonthemodelbeingused‚Äîitisnotagiven(RQ1).Thisisparticularly\nthecasewithGPT-4o,themostcomplexmodelwetested,wherethepresenceoffeedbackconsistentlyimproved\ncorrectnessrates.Thismayindicatethatmorecapablemodelsarebetterabletoextrapolatethecausesofdesignand\nimplementationbugsgivenerrors,andothersuitablylargemodelsmayalsobeabletobenefitfromtool-basedfeedback.\nImpactofTreeSearchParameters(ùëò,ùëë):Forouranalysis,weemployasimilar‚ÄúPass@k‚Äùmetrictothatusedin\npriorworksonthistopic,likeVerilogEval[16]andRTLCoder[17],whichreferstothenumberofcandidatesgenerated\nforapromptandconsideringacircuitasuccessifatleastonecandidateprovedtowork.Ourùëòcandidatestoasingle\npromptfunctionssimilarlywithatreesearchdepthùëëof0;however,analyzingbythepotentialmaximumnumberof\nLLMresponses,asthezero-shotPass@kmetricdoes,weinsteaduseùëò‚àó(ùëë+1).Withthiscomparison,wefindthat\nincreasingbothùëòandùëëseparatelyimprovestheresultingcircuits,thoughùëòseemstohavealargerimpact(RQ2).\nTherateofimprovementwithnumberofcandidatesanddepth,bothseparatelyandwhenconsideredtogether,seems\ntoslowdownsignificantlyasthemaximumdepthincreases,likelyduetothefactthatmostsimpleproblemsaresolved\nwithfeweriterationsandonlyasmallhandfulofthebenchmarkingproblemsthatcanbesolvedbythismethodwillbe\ndonewithalargernumberofiterations.\nBenchmarkCategorization:HDLBits,andsubsequentlyitsproblemsusedbyVerilogEval,sortsitsproblemsinto\ncategoriesandsubcategories,rangingfrom‚ÄúGettingStarted‚Äùand‚ÄúVerilogLanguage,‚Äùwhichconsistofsimpleproblems\nfocusingonspecificfeaturesofVerilogandtheirsyntax,upto‚ÄúSequentialLogic‚Äùand‚ÄúVerification:ReadingSimulations,‚Äù\nwhichaskforgenerallymorecomplexorabstractlywordedproblemsdealingwithstatemachinesandsequential\nfunctions,andreadingwaveforms,respectively.Thisproblemcategorizationenablesustoanalyzetheperformanceof\neachmodelwetestedondifferentkindsofVerilogproblemandidentifypatternsinwhatmodelshandlewhatproblems\nwell,andhowwellthetool-basedfeedbackisabletoimproveperformanceper-category.Figure9(a)andFigure9(b)\nshowthesuccessratesofeachexaminedmodel,giventhemajorHDLBitscategoriesandfeedbackconfigurations\ndiscussedabove.\nAcrossallmodelswefoundthat‚Äúsimple‚Äùproblems,suchasbasicVerilogfunctionalityquestions,areabletobesolved\nmoreoften,regardlessoffeedbackdepthornumberofcandidates.Thereisageneraltrendwheremoreiterationsof\nfeedbackormorecandidatesimprovesresults,butthisistobeexpectedgivenourpreviousresultswhereanincreased\nnumberofqueriesoftenresultsinhighersuccess,regardlessoftheparameterconfigurationforthosequeries(zero-shot\nortreesearch).Wedon‚Äôtidentifyanyparticularcategoriesofproblemwhichseemtobenefitfromusingtoolfeedback,\neveninthecaseofamodelthatgenerallyseemstobenefitlikeGPT-4o.\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 13\n(a)SuccessrateforEval-MachinebenchmarksgiventotalcostinUSD.\n(b)SuccessrateforEval-HumanbenchmarksgiventotalcostinUSD.\nFig.8. Generatedcircuitsuccessratesforeachevaluatedmodel,shownasthepercentageofgeneratedcircuitswhichpassalltests\ngiventheaverageUSDcosttoquerythemodel.Paretopointsareplottedwithdashedlines.Datapointsrepresentedby‚Äòx‚Äôindicate\nresultsfromzero-shottesting.\nBreakingdownthebenchmarkingproblemsbycategoryalsoallowsustobetterexaminethedifferencesbetweenthe\nresultsfromtheVerilogEval-MachinebenchmarksandtheVerilogEval-Humanbenchmarks.Followingthecombined\nManuscriptsubmittedtoACM\n14 Blockloveetal.\n(a)Eval-Machinebenchmarkproblemsuccess,separatedbymajorcategoryusedbyHDLBits.\n(b)Eval-Humanbenchmarkproblemsuccess,separatedbymajorcategoryusedbyHDLBits.\nFig.9. Modelsuccess,separatedbycategory.Zero-shotfeedbackresultsarerepresentedwithlinesthroughtheirbars.\nresultsfromabove,therateofsuccessforthemachinebenchmarksappearstobehigheracrosstheboard;however,the\nMachinebenchmark‚ÄúSequentialLogic‚Äùproblemshadsignificantlymoresuccessthantheircombinationalcounterparts,\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 15\nwhereastheHumanbenchmarkset‚Äôs‚ÄúSequentialLogic‚Äùproblemshadroughlysimilarresultstotheiraccompanying\ncombinationalproblems.Thisindicatesthattheremaybemoresuccessfulpromptingstrategiesdependingonthe\nspecificproblemtryingtobesolved.\nWecanfurtherdecomposetheproblemcategoriesintotheir,onceagainHDLBits-defined,subcategories.These\nbetterseparatetherelativedifficultiesandstylesofproblem.Forinstance,bothindividuallatchandflip-flopproblems\nandcellularautomataproblemsfallunder‚ÄúSequentialLogic‚Äù,butthelatteraremorecomprehensiveproblemswith\nabstractwording.Assuch,thesubcategoriesgivefiner-grainedinsightintothetypesofproblemsdifferentmodelsare\nsuitedtosolve.\nFigure10(a)andFigure10(b)showtherateofsuccessonthebenchmarksetforeachparametersetandeachmodel,\nbrokendownbysubcategory,forboththeEval-MachineandEval-Humanbenchmarksets.Someproblems,suchasthe\n‚ÄúGettingStarted‚Äùcategory,areomittedfromthisgraphastheycontainedtoofewandtoosimpleproblemstoprovide\nusefulinsight.\nWeobservethatthesimplestproblemtypesareoftensolvedwithfewcandidateresponses,notnecessarilyrequiring\nfeedbackfromthetools,butmorecomplexandabstractproblemsbenefitmorefromatoolfeedback-drivenapproach.\nTheproblemsfortheHumandatasetwhichthemodelsseemedtostrugglewiththemostwereinterpretingKarnaugh\nmaps(providedastext),statemachinedesign,andproblemsthatarepresentedasbeingmore‚Äúabstract‚Äùsuchas\nthecellularautomataproblems.FortheMachinedataset,whichusesfarmorestraightforwardprompts,theLLMs\nhadconsistentlylowersuccesswithsimpledesigns,suchasthe‚ÄúVerilogLanguage‚Äùcategory,and‚ÄúBasicGates‚Äùand\n‚ÄúMultiplexers‚Äùfrom‚ÄúCombinationalLogic,‚Äùbutshowedmuchgreatersuccesswithcomplexdesignssuchasstate\nmachinesorfindingbugs(RQ5).\n5.2 Mixed-ModelResults\nGiventherelativesuccess,butmatchingrelativeexpense,ofGPT-4oinsolvingtheVerilogEvalbenchmarkingproblems,\nwe sought to evaluate if combining a small model with a larger model, such as GPT-4o, could achieve improved\nresultswithonlyminimalimpactoncost.Table5showstheresultsforensemblingClaudeHaiku,GPT-3.5-Turbo,and\nGPT-4o-MinirespectivelywithGPT-4oasthefinaliteration.\nTable5. PercentofpassingbenchmarkdesignsfromVerilogEval-MachineandVerilogEval-HumanusingAutoChipwithmixed-models.\nResultsweregatheredwithClaude3Haiku(Haiku),GPT-3.5-Turbo(GPT-3.5T),andGPT-4o-Mini,eachfollowedbyasinglepassof\nGPT-4oasthefinaliteration.\nEval-Machine(%) Eval-Human(%)\nCandidates LLM\nd=1 d=5 d=10 d=1 d=5 d=10\nHaiku 75.5 79.0 81.1 64.7 67.3 67.9\nùëò =1 GPT-3.5T 77.6 80.4 78.3 62.2 63.5 61.5\nGPT-4o-Mini 69.9 74.8 76.9 63.5 64.1 66.0\nHaiku 86.0 86.7 85.3 74.4 75 74.4\nùëò =5 GPT-3.5T 86.7 86.7 86.0 71.2 73.7 71.8\nGPT-4o-Mini 82.5 81.1 81.8 69.9 74.3 75.0\nManuscriptsubmittedtoACM\n16 Blockloveetal.\nManuscriptsubmittedtoACM\ngivenbeloweachgroup. Fig.10.\nProblemsuccessratesbyproblemsubcategoryforboththeEval-MachineandEval-Humanproblemsets.Themajorcategorytowhichthesubcategoriesbelongis\n(b)Eval-Humanbenchmarkproblemsuccess,separatedbysubcategoryusedbyHDLBits. (a)Eval-Machinebenchmarkproblemsuccess,separatedbysubcategoryusedbyHDLBits.\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 17\nTheseresultsshowsignificantpromisewhenaddingamorecomplexmodeltotheendofaseriesofqueriesfrom\nlesscapablemodels,withtherateofsuccessshowntoapproachorevenexceed,insomecases,thebenchmarkcircuits\ngeneratedusingonlyGPT-4o.\nEvaluatingtheseresultsbasedonmodeleffort,asdonewiththesingle-modelresults,isperformedbyanalyzingthe\naveragenumberoftokensneededtocompletelygenerateabenchmarkdesign.Figure11(a)andFigure11(b)showthese\nplots.\nWeseethatwiththeVerilogEval-Machinebenchmarksetsweareusingasimilarnumberoftokenstothesmall\nmodels‚Äôexpendituresalone,whileachievingnotablyhigherlevelsofsuccess.WealsoobservethattheParetopointsin\nmostcasesseemtostopbeforethelargestcombinationsofcandidatesandtreesearchdepth,indicatingthatbymixing\nthesemodelssmallersearchparameterscanbeusedtostillachievearelativelyhighrateofsuccess.Withthemore\nrealisticVerilogEval-Humanbenchmarks,wearenotabletoreachthesamelevelofsuccessasGPT-4oonitsown,but\nwedoseenotablyhighersuccessratescomparedtothesmallermodelsforsimilarnumbersoftokens.\nWecanalsoevaluatesuccessbasedonrelativemodelcomplexity,onceagainproxiedbythedollarcostsnecessary\ntoaccessandruneachmodel.TheseplotsareshowninFigure12(a)andFigure12(b).Hereweobserveasimilar\nphenomenontothatofthemodeleffortanalysis,buttoagreatermagnitude.ForVerilogEval-Machine,theaveragecost\ntocompletethebenchmarkgenerationisonaveragesimilar,ifslightlyhigher,thanthecostsforthesmallermodelson\ntheirown,butareordersofmagnitudelowerthanwhenusingGPT-4oalonewhileachievingsimilarlevelsofsuccess.\nWhileVerilogEval-HumandoesnotreachthelevelofsuccessofGPT-4oalone,weareabletoachievemoresuccess\nthanthesmallermodelscouldgetalone,foraverysimilarcost.Forexample,thehighestsuccessrateachievedwith\nmixed-modelsfortheVerilogEval-Humanbenchmarkswas75%atacostof$0.025andtoachieveasimilarnearly75%\nsuccesswithonlyasinglemodelwouldrequireGPT-4oandcost$0.043‚Äîanincreaseof72%cost.Thisindicatesthatby\nmixingmodelsitmaybepossibletoleveragelesscomputationalresourcestogenerateVerilogofcomparablequalityto\nacomputationallyheavymodelonitsown,thoughpromptingmethodappearstohaveasignificanteffect(RQ6).\nBenchmarkCategorization:Theresultsofusingmultiplemodelscanalsobeanalyzedbycategoryandsubcategory.\nFigure13andFigure14showthemixed-modelresultswhenusingthemainmodelsshownformostgeneration,followed\nbyafinaliterationwithGPT-4o.\nUltimately,weseelargelythesamepatternofsuccessratesbasedoncategorythatweobserveinthesingle-model\nresults(Figure9),but,asnotedinouraboveanalysis,thosesuccessratesarefarclosertoGPT-4o‚Äôssinglemodelresults\nthanthesmallermodels‚Äôresults.Figure14(a)andFigure14(b)onceagainfurtherbreakdownthesecategoriesintotheir\nsubcategoriesforamorefine-grainedanalysis.\nUsingmixed-modelsonceagainshowsthattheper-subcategorysuccessesforGPT-4o-Mini,GPT-3.5-Tubro,and\nClaude3Haikugivelargelythesamepatternofproficiencies,deficiencies,andsuccessratesobservedwhenusing\nonlyGPT-4o.Thisfurthersupportstheideathatmixingmodelscanimprovetheresultsfromthelesscomputationally\nexpensivemodelwhilestillkeepingtheexpenselow.\n5.3 Discussion\nWeaskedsixinitialresearchquestionstoguideourevaluationofLLMgeneratedVerilog.\nRQ1:WefoundthatfeedbackfromtoolsandtestbenchsimulationcanimprovethesuccessrateofgeneratedVerilog\nmodulesoverzero-shotresults,butitwasheavilydependantonthemodelbeingused.GPT-4oconsistentlybenefited\nfromtheautomatedfeedbackfromtools,butthesmallermodelsdidnotseemtousefeedbacktorepairbugsaswell.\nThiscouldbeanindicationofthecomplexityofrelatingerrormessagesandsimulationtimestothedesignbeing\nManuscriptsubmittedtoACM\n18 Blockloveetal.\n(a)Mixed-modelsuccessratesfortheEval-Machinebenchmarkproblemsgiventhetotalnumberoftokensused.\n(b)Mixed-modelsuccessratesfortheEval-Humanbenchmarkproblemsgiventhetotalnumberoftokensused.\nFig.11. Generatedcircuitsuccessratesforeachevaluatedmodel,shownasthepercentageofgeneratedcircuitswhichpassalltests\ngiventheaveragenumberoftokensneeded.Eachmodel‚ÄôsfinaliterationwasdonewithGPT-4o.Paretopointsareplottedwithdashed\nlines.\ncreated,asimilarproblemtoonefoundwhenusingdifferentlevelsoffeedbackfromhumans[4].Inthepreviouswork,\nahumanengineerwasabletoguidetheLLMbyexplaining,evenbasically,thecorrelationbetweentheerrorandthe\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 19\n(a)Mixed-modelsuccessrateforEval-MachinebenchmarksgiventotalcostinUSD.\n(b)Mixed-modelsuccessrateforEval-HumanbenchmarksgiventotalcostinUSD.\nFig.12. Generatedcircuitsuccessratesforeachevaluatedmodel,shownasthepercentageofgeneratedcircuitswhichpassalltests\ngiventheaverageUSDcosttoquerythemodel.Eachmodel‚ÄôsfinaliterationwasdonewithGPT-4o.Paretopointsareplottedwith\ndashedlines.\naspectoftheVerilogwhichcausedit.Toimproveuponthisinanautomatedsystemwithnohumanfeedback,theLLMs\nbeingusedwouldlikelyneedtobepreviouslyinstructedonthesespecificerrormessages.\nManuscriptsubmittedtoACM\n20 Blockloveetal.\n(a)SuccessrateofEval-Machineproblems,separatedbycategory.\n(b)SuccessrateofEval-Humanproblems,separatedbycategory.\nFig.13. Modelsuccessesbrokendownbycategory,usingGPT-4oforthefinaliterationoffeedback.\nRQ2:Asthenumberofcandidateresponsesandthedepthofthetreeincreasedwesawatrendhigherratesof\nsuccesswithallexaminedmodels.Thetreesearchdepth,whileimpactful,seemedtohaveasmallereffectontherate\nofsuccessthanthenumberofcandidatesdid,asevidencedbytherateofsuccessforzero-shotresultswithmany\ncandidates.Increasingthedepth,however,resultedingenerallyfewertokensneededfortheincreaseascomparedto\nincreasingthenumberofcandidates.\nRQ3:LeveragingEDAtoolfeedbackwithLLMstoimprovethegeneratedHDLresultedinconsistentlylower\ncomputationalandmonetarycostforagivennumberofqueriestothemodelsweevaluated.Wefindthatthezero-shot\nresultsrequiremoretokensand,assuch,havemoreassociatedexpensepermodelthantheresultswhichleveraged\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 21\nManuscriptsubmittedtoACM\n.yrogetacbusybdetarapes,smelborpenihcaM-lavEfoetarsseccuS)a( .yrogetacbusybdetarapes,smelborpnamuH-lavEfoetarsseccuS)b(\n.kcabdeeffonoitaretilanifehtrofo4-TPGgnisu,yrogetacbusybnwodnekorbsesseccusledoM\n.41.giF\n22 Blockloveetal.\nfeedbackfromtools.InthecaseofGPT-4o,wherefeedbacknoticeablyimprovedtheresults,thelessenedcostofusing\ntoolfeedbackgiventherateofcorrectdesignswassubstantial.\nRQ4:ByusingAutoChipwithboth‚Äúsuccinct‚Äùand‚Äúfull-context‚Äùfeedback,wefoundthattherewasnoappreciable\ndifferenceinthesuccessrateofthetwomodelsweexamined,GPT-3.5-TurboandCalude3Haiku.Assuch,weused\nonly‚Äúsuccint‚Äùfeedbackfortestingtheothermodels,asitreachesthesamelevelsofsuccesswhileusingfarfewer\ntokensoverthecourseoflargertreesearches.\nRQ5:TheLLMsweexaminedallbehavedconsistentlywithregardstotheirsuccessesbasedontheclassofproblem.\nAllmodelsseemedtohavesignificantandconsistentsuccesswithbasicfeaturesofVerilog,primarilyfocusingon\nsyntaxandsimplelogicalfunctions.Themodels‚Äôabilitytogeneratecorrectdesignsseemedtogenerallydeclinewith\nmorecomplexquestionsdealingwithimplementingsequentiallogicandinterpretationofabstractinformationlike\nKarnaughmaps(K-maps),finitestatemachinediagrams,andwaveformanalysis.TheVerilogEval-Machinebenchmarks\nshowednoticeablymoresuccesswithgeneratingcircuitsbasedoninterpretingdesignspecifications,likelyduetothe\nlessabstractpromptsgeneratedbyusinganLLMtogenerateapromptbasedonlyonafinalcorrectcircuit.\nRQ6:Wefoundthatmixingmodels,specificallybyaddingasinglefinaliterationofthemorecapableGPT-4omodel,\nresultedinsuccessratessimilartothosewithonlyGPT-4obutwhilerequiringonlyafractionoftheUSDcost,which\nservesasaproxymetricforthecomputationalcomplexity.Theaveragenumberofoveralltokensnecessarystayed\nsimilartowhenonlyusingeachofthesmallermodels,astheywerebeingqueriedthemajorityofthetime,butthe\nfinaliterationofGPT-4oseemedtooftenbeabletoleveragethosepartiallyfunctionaldesignsandprovidethefinal\nfixes.Thiscostreductionisalsoverylikelyduetotherateofsuccessofthesmallermodelsontheirown.Theyarestill\nabletoinexpensivelysolvemanyofthesimplerproblemswithoutevergettingtothefinaldepthofthesearchtocall\nGPT-4o,sotheaddedexpenseonlyappliedtothehardesttosolveproblems.\n6 Conclusion\nGivenrecentadvancesinLLMcapabilitiesforbothcodingandhardwaredesign,ithasseemedreasonabletoassumethat\nprovidingamodelfeedbackonitsgeneratedcodewouldimproveitsperformance.However,generatingthisfeedback,\nand‚Äòexplaining‚Äôtothemodelhowandwhyitiswrong,hastypicallybeendonewithahumanengineer‚Äîsomething\ncostly,nebulous,andpotentiallyslowifthehumanengineerneedstobeabletofindanddeciphertheerrorontheir\nownbeforepromptingtheLLM.Assuch,systematicstudiesinthisareahavebeenlacking.\nInthiswork,wethereforesoughttoevaluatehowasetofmodern,stateoftheart,generalknowledgeLLMswould\nrespondtofeedbackonlyfromEDAtoolsandtestbenches.WesoughttodiscoverwhetherLLMswouldtrulybeableto\nsolvebugsintheirowngenerateddesignswithouttheassistanceofaknowledgeablehuman.Wefurtherasked:Ifso,\nhowmucheffortwouldittake?Howmuchwoulditcost?And,aretheretechniqueswecanusetomakethisprocess\nbetter?\nUltimately,wefoundthatthesuccessofusingfeedbackfromtoolsandtestbenchestofixgeneratedVerilogdesigns\ndependedlargelyonthemodelbeingused.GPT-4o,themostcomputationallycomplexmodelexamined,wasableto\nconsistentlyusetoolandtestbenchgeneratedfeedbacktogeneratecorrectdesignsfromtheVerilogEvalbenchmark\nsets.Thesmallermodelstested,GPT-4o-Mini,GPT-3.5-Turbo,andClaude3Haiku,inconsistentlybenefitedfromthe\ntoolprovidedfeedback,but,byaddingafinalevaluationbyGPT-4o,wereabletocreateasimilarnumberofcorrect\ncircuitsatafractionofthecostofGPT-4obeingusedalone.WedevelopedandprovideAutoChipasanopen-source,\nextendableframeworkforevaluatingLLMs‚ÄôabilitiestogenerateVerilogandcorrecttheirmistakesusingtheoutput\nfromtools.Thiscanbeleveragedtoperformsimilaranalysisonadditionalmodelsandnewbenchmarksastheybecome\nManuscriptsubmittedtoACM\nCanEDAToolFeedbackImproveVerilogGenerationbyLLMs? 23\navailable,furtherbuildingupanunderstandingforhowbesttointeractwithLLMstogeneratequalityhardware.Our\npresentedmethodprovidesanimportantandpowerfulproof-of-conceptforeffectivelyutilizingtoolfeedbackwith\nLLMsfortheautomaticgenerationofhardware.\nReferences\n[1] BaleeghAhmad,ShailjaThakur,BenjaminTan,RameshKarri,andHammondPearce.2024.OnHardwareSecurityBugCodeFixesbyPrompting\nLargeLanguageModels.IEEETransactionsonInformationForensicsandSecurity19(2024),4043‚Äì4057. https://doi.org/10.1109/TIFS.2024.3374558\n[2] Anthropic.2024.Claude3Haiku:ourfastestmodelyet. https://www.anthropic.com/news/claude-3-haiku\n[3] JasonBlocklove,SiddharthGarg,RameshKarri,andHammondPearce.2023.Chip-Chat:ChallengesandOpportunitiesinConversationalHardware\nDesign.In2023ACM/IEEE5thWorkshoponMachineLearningforCAD(MLCAD).1‚Äì6. https://doi.org/10.1109/MLCAD58807.2023.10299874\n[4] JasonBlocklove,SiddharthGarg,RameshKarri,andHammondPearce.2024.EvaluatingLLMsforHardwareDesignandTest. https://doi.org/10.\n48550/arXiv.2405.02326arXiv:2405.02326[cs].\n[5] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,Girish\nSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielZiegler,\nJeffreyWu,ClemensWinter,ChrisHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,\nSamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020. LanguageModelsareFew-ShotLearners.InAdvancesinNeural\nInformationProcessingSystems,H.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin(Eds.),Vol.33.CurranAssociates,Inc.,1877‚Äì1901.\nhttps://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[6] Cadence.2023.CadenceJedAIGenerativeAISolutionforChip,System,andProductDesign. https://www.cadence.com/en_US/home/solutions/joint-\nenterprise-data-ai-platform.html\n[7] MarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,HarriEdwards,YuriBurda,NicholasJoseph,\nGregBrockman,AlexRay,RaulPuri,GretchenKrueger,MichaelPetrov,HeidyKhlaaf,GirishSastry,PamelaMishkin,BrookeChan,ScottGray,Nick\nRyder,MikhailPavlov,AletheaPower,LukaszKaiser,MohammadBavarian,ClemensWinter,PhilippeTillet,FelipePetroskiSuch,DaveCummings,\nMatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgenGuss,AlexNichol,AlexPaino,NikolasTezak,JieTang,\nIgorBabuschkin,SuchirBalaji,ShantanuJain,WilliamSaunders,ChristopherHesse,AndrewN.Carr,JanLeike,JoshAchiam,VedantMisra,Evan\nMorikawa,AlecRadford,MatthewKnight,MilesBrundage,MiraMurati,KatieMayer,PeterWelinder,BobMcGrew,DarioAmodei,SamMcCandlish,\nIlyaSutskever,andWojciechZaremba.2021. EvaluatingLargeLanguageModelsTrainedonCode. https://doi.org/10.48550/arXiv.2107.03374\narXiv:2107.03374[cs].\n[8] LucaCollini,SiddharthGarg,andRameshKarri.2024.C2HLSC:CanLLMsBridgetheSoftware-to-HardwareDesignGap? https://doi.org/10.48550/\narXiv.2406.09233arXiv:2406.09233[cs].\n[9] GhadaDessouky,DavidGens,PatrickHaney,GarrettPersyn,ArunKanuparthi,HareeshKhattri,JasonFung,Ahmad-RezaSadeghi,andJeyavijayan\nRajendran.2019.Hardfails:InsightsintoSoftware-ExploitableHardwareBugs.InProceedingsofthe28thUSENIXConferenceonSecuritySymposium\n(SEC‚Äô19).USENIXAssociation,SantaClara,CA,USA,213‚Äì230.\n[10] YongganFu,YonganZhang,ZhongzhiYu,SixuLi,ZhifanYe,ChaojianLi,ChengWan,andYingyanCelineLin.2023.GPT4AIGChip:Towards\nNext-GenerationAIAcceleratorDesignAutomationviaLargeLanguageModels.In2023IEEE/ACMInternationalConferenceonComputerAided\nDesign(ICCAD).1‚Äì9. https://doi.org/10.1109/ICCAD57390.2023.10323953ISSN:1558-2434.\n[11] GitHub.2021.GitHubCopilot¬∑YourAIpairprogrammer. https://copilot.github.com/\n[12] Google.2023.IntroducingPaLM2. https://blog.google/technology/ai/google-palm-2-ai-large-language-model/\n[13] ZhuolunHe,HaoyuanWu,XinyunZhang,XufengYao,SuZheng,HaishengZheng,andBeiYu.2023.ChatEDA:ALargeLanguageModelPowered\nAutonomousAgentforEDA.In2023ACM/IEEE5thWorkshoponMachineLearningforCAD(MLCAD).1‚Äì6. https://doi.org/10.1109/MLCAD58807.\n2023.10299852\n[14] RahulKande,HammondPearce,BenjaminTan,BrendanDolan-Gavitt,ShailjaThakur,RameshKarri,andJeyavijayanRajendran.2024.(Security)\nAssertionsbyLargeLanguageModels.IEEETransactionsonInformationForensicsandSecurity19(2024),4374‚Äì4389. https://doi.org/10.1109/TIFS.\n2024.3372809\n[15] MingjieLiu,Teodor-DumitruEne,RobertKirby,ChrisCheng,NathanielPinckney,RongjianLiang,JonahAlben,HimyanshuAnand,Sanmitra\nBanerjee,IsmetBayraktaroglu,BonitaBhaskaran,BryanCatanzaro,ArjunChaudhuri,SharonClay,BillDally,LauraDang,ParikshitDeshpande,\nSiddhanthDhodhi,SameerHalepete,EricHill,JiashangHu,SumitJain,BrucekKhailany,KishorKunal,XiaoweiLi,HaoLiu,StuartOberman,Sujeet\nOmar,SreedharPratty,JonathanRaiman,AmbarSarkar,ZhengjiangShao,HanfeiSun,PratikP.Suthar,VarunTej,KaizheXu,andHaoxingRen.\n2023.ChipNeMo:Domain-AdaptedLLMsforChipDesign. https://doi.org/10.48550/arXiv.2311.00176arXiv:2311.00176[cs].\n[16] MingjieLiu,NathanielPinckney,BrucekKhailany,andHaoxingRen.2023. VerilogEval:EvaluatingLargeLanguageModelsforVerilogCode\nGeneration. https://doi.org/10.48550/arXiv.2309.07544arXiv:2309.07544[cs].\n[17] ShangLiu,WenjiFang,YaoLu,QijunZhang,HongceZhang,andZhiyaoXie.2024.RTLCoder:OutperformingGPT-3.5inDesignRTLGeneration\nwithOurOpen-SourceDatasetandLightweightSolution. https://doi.org/10.48550/arXiv.2312.08617arXiv:2312.08617[cs].\nManuscriptsubmittedtoACM\n24 Blockloveetal.\n[18] YaoLu,ShangLiu,QijunZhang,andZhiyaoXie.2023.RTLLM:AnOpen-SourceBenchmarkforDesignRTLGenerationwithLargeLanguage\nModel. https://doi.org/10.48550/arXiv.2308.05345arXiv:2308.05345[cs].\n[19] Meta.2023.IntroducingCodeLlama,anAIToolforCoding. https://about.fb.com/news/2023/08/code-llama-ai-for-coding/\n[20] Mistral.2023.Mistral7B. https://mistral.ai/news/announcing-mistral-7b/Section:news.\n[21] OpenAI.2022.IntroducingChatGPT. https://openai.com/blog/chatgpt\n[22] OpenAI.2024.GPT-4o. https://openai.com/index/hello-gpt-4o/\n[23] OpenAI.2024.GPT-4omini:advancingcost-efficientintelligence. https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/\n[24] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,\nAlexRay,JohnSchulman,JacobHilton,FraserKelton,LukeMiller,MaddieSimens,AmandaAskell,PeterWelinder,PaulFChristiano,JanLeike,\nandRyanLowe.2022. Traininglanguagemodelstofollowinstructionswithhumanfeedback.InAdvancesinNeuralInformationProcessing\nSystems,S.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,andA.Oh(Eds.),Vol.35.CurranAssociates,Inc.,27730‚Äì27744. https:\n//proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf\n[25] HammondPearce,BenjaminTan,andRameshKarri.2020.DAVE:DerivingAutomaticallyVerilogfromEnglish.InProceedingsofthe2020ACM/IEEE\nWorkshoponMachineLearningforCAD.ACM,VirtualEventIceland,27‚Äì32. https://doi.org/10.1145/3380446.3430634\n[26] SundarPichai.2023.AnimportantnextsteponourAIjourney. https://blog.google/technology/ai/bard-google-ai-search-updates/\n[27] SundarPichaiandDemisHassabis.2023.IntroducingGemini:ourlargestandmostcapableAImodel. https://blog.google/technology/ai/google-\ngemini-ai/\n[28] RapidSilicon.2023.RapidGPT. https://rapidsilicon.com/rapidgpt/\n[29] Synopsys.2023. RedefiningChipDesignwithAI-PoweredEDATools|Synopsys.ai|SynopsysBlog. https://www.synopsys.com/blogs/chip-\ndesign/synopsys-ai-eda-tools.html\n[30] ShailjaThakur,BaleeghAhmad,ZhenxingFan,HammondPearce,BenjaminTan,RameshKarri,BrendanDolan-Gavitt,andSiddharthGarg.2023.\nBenchmarkingLargeLanguageModelsforAutomatedVerilogRTLCodeGeneration.In2023Design,Automation&TestinEuropeConference&\nExhibition(DATE).1‚Äì6. https://doi.org/10.23919/DATE56975.2023.10137086ISSN:1558-1101.\n[31] ShailjaThakur,JasonBlocklove,HammondPearce,BenjaminTan,SiddharthGarg,andRameshKarri.2023.AutoChip:AutomatingHDLGeneration\nUsingLLMFeedback. https://doi.org/10.48550/arXiv.2311.04887arXiv:2311.04887[cs].\n[32] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,≈ÅukaszKaiser,andIlliaPolosukhin.2017.Attentionis\nAllyouNeed.InAdvancesinNeuralInformationProcessingSystems,Vol.30.CurranAssociates,Inc. https://proceedings.neurips.cc/paper/2017/\nhash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\n[33] StephenWilliams.2023.TheICARUSVerilogCompilationSystem. https://github.com/steveicarus/iverilogoriginal-date:2008-05-12T16:57:52Z.\n[34] HenryWong.2017.HDLBitsProblemSets. https://hdlbits.01xz.net/wiki/Problem_sets\nManuscriptsubmittedtoACM",
    "pdf_filename": "Can_EDA_Tool_Feedback_Improve_Verilog_Generation_by_LLMs.pdf"
}