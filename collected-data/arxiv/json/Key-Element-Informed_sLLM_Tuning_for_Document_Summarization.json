{
    "title": "Key-Element-Informed sLLM Tuning for Document Summarization",
    "context": "Remarkable advances in large language models (LLMs) have enabled high-quality text summarization. However, this capa- bility is currently accessible only through LLMs of substantial size or proprietary LLMs with usage fees. In response, smaller- scale LLMs (sLLMs) of easy accessibility and low costs have been extensively studied, yet they often suffer from missing key information and entities, i.e., low relevance, in particular, when input documents are long. We hence propose a key-element- informed instruction tuning for summarization, so-called KEIT- Sum, which identifies key elements in documents and instructs sLLM to generate summaries capturing these key elements. Ex- perimental results on dialogue and news datasets demonstrate that sLLM with KEITSum indeed provides high-quality sum- marization with higher relevance and less hallucinations, com- petitive to proprietary LLM. document summarization, named entity recognition With the advent of Large Language Models (LLMs), recent studies have utilized LLMs across a broad spectrum of ap- plications. Consequently, for summarization tasks, there is a paradigm shift from traditional encoder-decoder-based models [1, 2, 3, 4, 5] to LLMs. It has been revealed that LLMs pro- duce more contextual and natural summaries than the encoder- decoder models [6, 7, 8] where LLMs do not merely put words from the document; instead, they substitute appropriate syn- onyms for a summary, resulting in more natural expressions and flows [6]. Noticeably, LLMs often generate even better sum- maries than human-written references [7, 8]. However, such a high-quality summarization has been only accessible by proprietary LLMs with usage fees or LLMs of large sizes. To improve accessibility, publicly available smaller- scale LLMs (sLLMs) can be considered. Noting that sLLMs can generate more fluent sentences than traditional encoder- decoder models, using sLLMs for summarization is a promising approach. However, according to our evaluation (Figure 2), they still suffer from the problem of omitting key entities or informa- tion but including superfluous sentences in summaries, i.e., low relevance. Hence, we aim to unleash the summarization capabilities of sLLMs by addressing the problem of low relevance. To this end, we propose key-element-informed sLLM tuning for docu- ment summarization (KEITSum), of which an overview is illus- trated in Figure 1. Given an input document, KEITSum identi- *equal contribution †correspondence to: jungseul@postech.ac.kr fies key elements consisting of the named entities and conclu- sion sentence and then instructs a fine-tuned sLLM to include the key elements when generating a summary, where the fine- tuning is conducted to optimize the sLLM for the key-element- informed summarization. We evaluate KEITSum on a dialogue summarization dataset, DialogSum [9], and a news summariza- tion dataset, CNN/DM [10], using a multi-dimensional metric to assess summarization quality, UniEval [11]. It is demon- strated that KEITSum improves the summary quality compared to the baseline LLaMA2-7B, particularly in terms of relevance and when summarizing long dialogs or documents. In addition, we also observed that KEITSum is effective in reducing hallu- cinations.",
    "body": "Key-Element-Informed sLLM Tuning for Document Summarization\nSangwon Ryu∗1, Heejin Do∗1, Yunsu Kim3, Gary Geunbae Lee1,2, Jungseul Ok†1,2\n1Graduate School of Artificial Intelligence, POSTECH, South Korea\n2Department of Computer Science and Engineering, POSTECH, South Korea\n3aiXplain Inc., Los Gatos, CA, USA\n{ryusangwon, heejindo, gblee, jungseul}@postech.ac.kr, yunsu.kim@aixplain.com\nAbstract\nRemarkable advances in large language models (LLMs) have\nenabled high-quality text summarization. However, this capa-\nbility is currently accessible only through LLMs of substantial\nsize or proprietary LLMs with usage fees. In response, smaller-\nscale LLMs (sLLMs) of easy accessibility and low costs have\nbeen extensively studied, yet they often suffer from missing key\ninformation and entities, i.e., low relevance, in particular, when\ninput documents are long. We hence propose a key-element-\ninformed instruction tuning for summarization, so-called KEIT-\nSum, which identifies key elements in documents and instructs\nsLLM to generate summaries capturing these key elements. Ex-\nperimental results on dialogue and news datasets demonstrate\nthat sLLM with KEITSum indeed provides high-quality sum-\nmarization with higher relevance and less hallucinations, com-\npetitive to proprietary LLM.\nIndex Terms: natural language generation, abstractive spoken\ndocument summarization, named entity recognition\n1. Introduction\nWith the advent of Large Language Models (LLMs), recent\nstudies have utilized LLMs across a broad spectrum of ap-\nplications. Consequently, for summarization tasks, there is a\nparadigm shift from traditional encoder-decoder-based models\n[1, 2, 3, 4, 5] to LLMs. It has been revealed that LLMs pro-\nduce more contextual and natural summaries than the encoder-\ndecoder models [6, 7, 8] where LLMs do not merely put words\nfrom the document; instead, they substitute appropriate syn-\nonyms for a summary, resulting in more natural expressions and\nflows [6]. Noticeably, LLMs often generate even better sum-\nmaries than human-written references [7, 8].\nHowever, such a high-quality summarization has been only\naccessible by proprietary LLMs with usage fees or LLMs of\nlarge sizes. To improve accessibility, publicly available smaller-\nscale LLMs (sLLMs) can be considered. Noting that sLLMs\ncan generate more fluent sentences than traditional encoder-\ndecoder models, using sLLMs for summarization is a promising\napproach. However, according to our evaluation (Figure 2), they\nstill suffer from the problem of omitting key entities or informa-\ntion but including superfluous sentences in summaries, i.e., low\nrelevance.\nHence, we aim to unleash the summarization capabilities\nof sLLMs by addressing the problem of low relevance. To this\nend, we propose key-element-informed sLLM tuning for docu-\nment summarization (KEITSum), of which an overview is illus-\ntrated in Figure 1. Given an input document, KEITSum identi-\n*equal contribution\n†correspondence to: jungseul@postech.ac.kr\nfies key elements consisting of the named entities and conclu-\nsion sentence and then instructs a fine-tuned sLLM to include\nthe key elements when generating a summary, where the fine-\ntuning is conducted to optimize the sLLM for the key-element-\ninformed summarization. We evaluate KEITSum on a dialogue\nsummarization dataset, DialogSum [9], and a news summariza-\ntion dataset, CNN/DM [10], using a multi-dimensional metric\nto assess summarization quality, UniEval [11]. It is demon-\nstrated that KEITSum improves the summary quality compared\nto the baseline LLaMA2-7B, particularly in terms of relevance\nand when summarizing long dialogs or documents. In addition,\nwe also observed that KEITSum is effective in reducing hallu-\ncinations.\n2. Related work\nInformation omission in dialogue summarization. Informa-\ntion or entity omission remains a persistent challenge in dia-\nlogue summarization. Traditional encoder-decoder models have\ntried to overcome this problem using various methods: [12]\nintroduces a method to detect information missing in conver-\nsations. [13] introduces contrastive and self-supervised losses\nto address entity omission and other inconsistency problems.\n[14] guided the inclusion of important spans identified through\nQuestion-Answering (QA) signals into the summaries. How-\never, research on addressing missing information in dialogue\ndatasets via sLLMs has not yet been extensively explored.\nEntity extraction for summarization. Methods for extract-\ning entities from the document to ensure their inclusion in the\nsummaries have been introduced to mitigate entity omission\nin other summarization domains. [15] used the named entity\nrecognition (NER) by masking extracted entities instead of ran-\ndom tokens when pre-training BART. However, it still has fun-\ndamental limitations inherent to encoder-decoder models. [16]\nemployed a two-stage CoT method, where elements were ex-\ntracted via GPT-3 [17] in the initial stage, and then GPT-3 was\nutilized again to integrate those extracted elements to generate\na summary. However, it could achieve element extraction only\nwith models exceeding 175B parameters, requiring tremendous\ncosts. Distinguished from their works, we aim to leverage the\npreviously unexplored sLLM, LLaMA2-7B, to take advantage\nof its comprehending abilities while alleviating the cost burden.\nUnlike the API-relied entity extraction of [16], our simple use\nof NER further diminishes the burden.\nEvaluation metrics.\nRecently, critical limitations of the\nROUGE score have been pointed out [16, 18, 19, 7]: it highly\nrelies on the number of overlapping words and, thus, deval-\nues appropriate synonyms generated in LLM. Furthermore,\nROUGE is unable to evaluate entity omission or hallucination\n[20, 21, 22, 23, 11, 24, 25, 26].\nTherefore, various multi-\narXiv:2406.04625v3  [cs.CL]  19 Nov 2024\n\nSource Article\nNER\nExtraction\nConclusion \nExtraction\n+\nKey-element-informed\nInstruction\nLLaMA2-7B\nSummary\nFine-tune\nArticle\nInstruction\ninstruction:\nSummarize the following text concisely while ensuring the accuracy of important content. Specifically emphasize and accurately represent entities enclosed \nbetween '<' and '>'. Additionally, conclude the summary with a '<conclusion>' and '<\\conclusion>' tag to encapsulate the main takeaway or conclusion of the \nnews article. Provide a comprehensive yet brief overview:\nDialogue\nBy . Anthony Bond . PUBLISHED: . 07:03 EST, 2 March 2013 . | . UPDATED: . \n08:07 EST, 2 March 2013 . Three members of the same family who died in a \nstatic caravan from carbon monoxide poisoning would have been \nunconscious 'within minutes', investigators said today. The bodies of married \ncouple John and Audrey Cook were discovered alongside their daughter, \nMaureen, at the mobile home they shared on Tremarle Home Park in \nCamborne, west Cornwall. The inquests have now opened into the deaths \nlast Saturday, with investigators ...\n#Person1#: Hello, can I help you?\n#Person2#: I'd like to rent a Toyota Carola.\n#Person1#: Alright. How long will you need it?\n#Person2#: For 3 days.\n#Person1#: Have you ever rented a car before?\n#Person2#: No, I haven't. Can I choose the color of the car?\n#Person1#: Sure, we have Toyota Carola's in black, red and silver ...\ndialogue:\n#Person1#: Hello, can I help you?\n<conclusion>#Person2#: I'd like to rent a <Toyota> Carola.<\\conclusion>\n#Person1#: Alright. How long will you need it?\n#Person2#: For <3 days>.\n#Person1#: Have you ever rented a car before?\n#Person2#: No, I haven't. Can I choose the color of the car?\n#Person1#: Sure, we have <Toyota> Carola's in black, red and silver ...\nsummary:\n#Person2#'d like to rent a silver Toyota Carola and #Person1# helps \n#Person2# go through procedures.\narticle:\nBy . Anthony Bond . PUBLISHED: . 07:03 EST, 2 March 2013 . | . UPDATED: . \n08:07 EST, 2 March 2013 . <conclusion>Three members of the same family \nwho died in a static caravan from carbon monoxide poisoning would have \nbeen unconscious 'within minutes', investigators said <today>.<\\conclusion>\nThe bodies of married couple <John> and <Audrey <Cook>> were discovered \nalongside their daughter, <Maureen>, at the mobile home they shared on \nTremarle Home Park in Camborne, west Cornwall. The inquests have now \nopened into the deaths <last Saturday>, with investigators ...\nsummary:\nJohn and .Audrey Cook were discovered alongside their daughter, \nMaureen .They were found at Tremarle Home Park in Cornwall .Investigators \nsay the three died of carbon monoxide .poisoning .\nFigure 1: Description of KEITSum Framework. We extract named entities and conclusion sentence from the source document and insert\nemphasis tokens. Following this, we create a full description by adding detailed instructions.\ndimensional evaluation metrics have emerged [18, 19, 11, 24,\n25], among which UniEval is known to have the highest cor-\nrelation with human evaluation currently. UniEval assesses\nscores for coherence, consistency, fluency, and relevance. We\nmainly aim to improve relevance, which evaluates whether only\nthe key information from the document has been included in the\nsummary.\n3. Key-element-informed tuning\nTo efficiently capture the critical elements for the dialogue doc-\nument, we propose a key-element-informed tuning for sLLMs.\nSpecifically, we first extract two distinct key elements, identi-\nfied as named entities and the conclusion sentence, using sepa-\nrate models. Then, we perform instruction tuning on the sLLM\nto guide the model in focusing on those extracted elements\nwhile generating the summary.\n3.1. Key-element extraction\nEntity extraction. We use the NER mechanism for entity ex-\ntraction. To select the named entities for extraction, we calcu-\nlate the ratio of entities appearing in both the dialogues and the\nsummaries. Table 1 presents the proportion of named entities\nappearing in the dialogue that also appear in the reference sum-\nmary. If a named entity appears in the reference summary with a\nhigh frequency, it indicates that such named entity should be in-\ncluded in the summary; therefore, we select named entities that\nappeared in more than 30% of the summaries. Additionally, we\nconduct experiments with a news dataset and, following [16],\nwe use entities suitable for the news domain, such as person,\ndate, organization, and event.\nAfter extracting the entities suitable for each domain, we\nemphasize each entity in the document by surrounding them\nwith the emphasis tokens, < and >. Unlike a prior work [16],\nour approach solely emphasizes the entities with tokens without\nexplicitly listing their meaning.\nConclusion extraction. Furthermore, to extract the key sen-\ntence from the document, we employ a pre-trained BERT-based\nextractive summarizer [27] and select the top-1 sentence. This\nis motivated by combining extractive summarization with ab-\nTable 1: The numbers in Dialogue and Summary represent the\ncount of samples containing each entity out of 500 in the valida-\ntion set. The ratio is the number in the Summary divided by that\nin the Dialogue. Blue background highlights selected entities.\nNamed Entity\nRatio\nDialogue\nSummary\nPERSON\n0.839\n186\n156\nGPE\n0.481\n81\n39\nLANGUAGE\n0.474\n19\n9\nORG\n0.411\n56\n23\nFAC\n0.350\n20\n7\nNORP\n0.333\n42\n14\nDATE\n0.311\n183\n57\nMONEY\n0.182\n55\n10\nORDINAL\n0.180\n50\n9\nCARDINAL\n0.172\n145\n25\nTIME\n0.143\n112\n16\nLOC\n0.071\n14\n1\nstractive methods to improve summary quality [28, 29]. Instead\nof explicitly passing the selected sentence, we merely mark\nthe sentence in the document when designing the instruction.\nSpecifically, we highlight the key sentence by adding a dis-\ntinct token by encapsulating it between <conclusion> and\n</conclusion> tokens. A more concentrated summary can\nbe generated by implicitly guiding the model to conclude the\nsummary using the marked main points. Figure 1 illustrates the\noverall structure.\n3.2. Instruction tuning\nAs a prompt for fine-tuning the sLLM, we provide the instruc-\ntion with a key-element-informed document and a reference\nsummary (Figure 1). For the instruction, we describe a task\ndefinition and explain how the key elements are emphasized in\nthe following source document. Addressing missing informa-\ntion or entities can potentially lead to hallucinations [12]; thus,\nwe sought to mitigate this trade-off by explicitly demanding ac-\ncurate generation in detailed instructions. In particular, we con-\ncatenate the instruction (i), converted document (d′), and ref-\nerence summary (s) to construct the prompt ([i; d′; s]). Then,\nwe fine-tune the sLLM using the designed prompt. This key-\nelement-informed tuning enables the model to focus more on\nimportant points within the document in the generation process.\n\nTable 2: Comparison between encoder-decoder-based models, LLaMA-2-7B, and GPT-3 in DialogSum and CNN/DM dataset.\nKEITSumall refers to the results when all entities are extracted, while KEITSumtop−1 indicates the results when only the entity with the\nhighest proportion is extracted. Finally, KEITSum represents the outcomes when entities with a ratio of over 30% are extracted.\nDataset\nModel\nUniEval\nROUGE-1\nCoherence\nConsistency\nFluency\nRelevance\nOverall\nDialogSum\nBART [2]\n0.928\n0.914\n0.913\n0.846\n0.900\n0.418\nT-5 [4]\n0.948\n0.939\n0.920\n0.870\n0.919\n0.414\nLLaMA2-7B (Fine-tuned)\n0.959\n0.939\n0.935\n0.912\n0.936\n0.440\nKEITSumall (ours)\n0.963\n0.942\n0.939\n0.914\n0.939\n0.429\nKEITSumtop−1 (ours)\n0.962\n0.941\n0.941\n0.915\n0.940\n0.429\nKEITSum (ours)\n0.965\n0.942\n0.942\n0.918\n0.942\n0.430\nGPT-3 [17]\n0.969\n0.907\n0.944\n0.932\n0.938\n0.270\nCNN/DM\nPEGASUS [3]\n0.944\n0.935\n0.829\n0.697\n0.851\n0.412\nBART [2]\n0.956\n0.943\n0.837\n0.684\n0.855\n0.415\nT5 [4]\n0.968\n0.959\n0.838\n0.767\n0.883\n0.426\nBRIO [5]\n0.947\n0.927\n0.833\n0.790\n0.874\n0.455\nLLaMA2-7B (Fine-tuned)\n0.943\n0.933\n0.870\n0.770\n0.879\n0.364\nKEITSum (ours)\n0.954\n0.923\n0.930\n0.805\n0.903\n0.343\nGPT-3 [17]\n0.964\n0.909\n0.949\n0.905\n0.932\n0.399\nGPT-3 + CoT [16]\n0.948\n0.870\n0.948\n0.910\n0.919\n0.464\nTable 3: The performance variation of KEITSum on the DialogSum according to dialogue length. The test set was divided based on the\naverage length of dialogues.\nModel\n# of Dialogues\nSummary Length\nUniEval\nDocument\nSummary\nCoherence\nConsistency\nFluency\nRelevance\nOverall\nLLaMA2-7Bshort\n882\n87.6\n17.2\n0.961\n0.948\n0.933\n0.914\n0.939\nKEITSumshort\n20.0\n0.964\n0.948\n0.939\n0.916\n0.942\nLLaMA2-7Blong\n618\n201.3\n32.5\n0.955\n0.927\n0.938\n0.909\n0.932\nKEITSumlong\n35.6\n0.965\n0.934\n0.945\n0.920\n0.941\n4. Experimental setup\nDatasets. We use the DialogSum dataset [9], a large-scale di-\nalogue summarization dataset. It comprises a 12.5K training\nset and a 1.5K test set, each accompanied by a human-written\nsummary that captures the most salient information and entities.\nIt encompasses a broad spectrum of daily-life topics through\nface-to-face spoken dialogues with a diverse distribution of\nlengths. To demonstrate domain extensibility, we employ the\nCNN/Daily Mail (CNN/DM) dataset [10], a news article col-\nlection paired with multi-sentence human-written summaries.\nIn contrast to the encoder-decoder model trained on the full\ndataset, the sLLMs were trained on only 10,000 subsets for effi-\nciency in both datasets. Following previous research that high-\nlights the poor quality of reference summaries in the CNN/DM\n[7], we use the recently released element-aware test set [16] de-\nsigned to address the deficiencies of the original dataset.\nModels.\nTo extract entity, we use the Flair1 [30], a well-\ndesigned NER framework. It was specifically pre-trained on\nthe OntoNote5 [31] for NER tasks in various domains, such\nas conversational speech and broadcast. For key sentence ex-\ntraction, we use the BERT summarizer2 [27]. For the sLLM,\nwe fine-tune the smallest LLaMA2 [32] of 7 billion parame-\nters, one of the famous open-source sLLMs. We fine-tune both\nLLaMA2 and KEITSum via LoRA [33], which facilitates ef-\nficient training by modifying a limited parameter subset while\noriginal ones are frozen; thus, it eliminates the need for full-\nmodel retraining. We fine-tune LLaMA2 using a basic prompt\nformat commonly used for summarization tasks. We set rank\nr=8, dropout=0.05, alpha=32, and epoch=3 as LoRA hyper-\nparameter. As our comparative models, we use robust encoder-\ndecoder models, such as BART [2], T5 [4], PEGASUS [3] and\nBRIO [5]. They were fine-tuned on the entire training set. For\n1https://github.com/flairNLP/flair\n2https://pypi.org/project/bert-extractive-summarizer/\nGPT-3 [17], we generated summaries using GPT-3.5-turbo\nfor DialogSum, while we used summaries created by [16] using\nthe text-davinci-002 for CNN/DM.\nEvaluation metrics. ROUGE scores, which fail to evaluate\nsummaries properly [20, 21, 22, 23, 11, 24, 25], suffer from\nanother significant drawback: heavy reliance on reference sum-\nmaries. Recent research highlighted that the quality of reference\nsummaries in abstractive summarization is often subpar [7, 34].\nThus, to measure the omission and hallucination of the\nsummaries precisely, we employ UniEval [11] and hu-\nman evaluation for multi-dimensional evaluation, and Chat-\nGPT evaluation [35] to examine the presence of inconsisten-\ncies in the summaries. UniEval is a recently proposed multi-\ndimensional evaluation tool for natural language generation\n(NLG) tasks, which demonstrates the highest correlation with\nhuman evaluation among open-source multi-dimensional evalu-\nation metrics. While not overly relying on reference summaries,\nit provides four explainable evaluation dimensions: coherence,\nconsistency, fluency, and relevance. To gauge the extent of hal-\nlucinations in model-generated summaries, we use the recently\nintroduced ChatGPT Evaluation [35, 36]. Finally, we conduct\nthe human evaluation.\n5. Results and discussions\n5.1. Main results\nMulti-dimensional evaluation. As shown in Table 2, our ap-\nproach demonstrated improvements across all UniEval di-\nmensions in the DialogSum.\nEmphasizing only the high-\nrelevance named entities, rather than highlighting all named en-\ntities as done in KEITSumall or the most frequent named en-\ntity as done in KEITSumtop−1, slightly benefited performance\nenhancement. Notably, by ensuring the inclusion of essential\nelements in the summaries, KEITSum boosted relevance score\nin both the DialogSum and CNN/DM. As a result, our model\n\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nKEITSum\nLLaMA2-7B\nBRIO\nGPT-3\nGPT-3+CoT\nPERSON\nDATE\nEVENT\nORG\nFigure 2: The proportion of entities included in the element-\naware dataset that are also included in the summaries gener-\nated by each model.\nTable 4: Human evaluation in DialogSum.\nModel\nComprehension\nFaithfulness\nRelevance\nFluency\nOverall\nBART\n4.192\n3.440\n3.652\n4.368\n3.910\nT5\n4.130\n3.322\n3.527\n4.288\n3.838\nReference\n4.363\n3.812\n3.950\n4.460\n4.137\nLLaMA2-7B\n4.413\n3.927\n4.040\n4.458\n4.183\nKEITSum\n4.527\n4.115\n4.145\n4.562\n4.347\nGPT-3\n4.880\n4.740\n4.772\n4.876\n4.802\nachieved higher overall scores not only compared to existing\nencoder-decoder-based summarization models but also compa-\nrable to the much larger model, GPT-3.\nCompared to the encoder-decoder models fine-tuned with\nthe full dataset in the CNN/DM dataset, our model performs\nbetter in most dimensions despite using only 3.6% of the train\nset.\nIn detail, it shows lower and consistency scores while\nexhibiting markedly higher fluency scores. This could be at-\ntributed to the difference in the generation procedure, i.e.,\nencoder-decoder models often generate content directly from\nthe source text, resulting in high consistency, whereas our\ndecoder-only approach leads to diverse yet more appropriate\nsynonyms in the summaries.\nEven GPT-3 and GPT-3+CoT\nshow comparable or lower scores on these aspects than T5,\nthereby supporting our assumption.\nAdditionally, we measured the ROUGE-1 scores for each\nmodel. Table 2 showed that the ROUGE-1 score of KEITSum\nslightly decreased compared to the LLaMA2-7B model on Di-\nalogSum. Moreover, the GPT-3 model, known for generating\nthe highest quality summaries, showed lower ROUGE-1 scores\nthan other summarization models. This underscores once again\nthat ROUGE scores are insufficient to measure the quality of\nsummaries generated by LLMs and fail to capture dimensions\nsuch as relevance.\nEntity ratio. To verify the actual inclusion of the emphasized\nentities in the generated summaries, we investigate the entity\nratio using the CNN/DM element-aware test set [16]. We ex-\ntracted the entities in the reference summaries and then calcu-\nlated the ratio of these entities present in the summaries pro-\nduced by each model. Figure 2 shows that KEITSum measured\nsimilarly to the tendencies of GPT-3 or GPT-3+CoT, exhibit-\ning a notable improvement over LLaMA2-7B across all entities.\nRemarkably, the ratio of EVENT entities shows a considerable\nincrease, where the LLaMA2-7B notably failed to capture well.\n5.2. Length dependency\nWhen the document is longer, more frequent missing informa-\ntion issues occur. Therefore, our method, emphasizing enti-\nties and key sentences to ensure accurate entities are included\nin the summary, is more effective in longer text. Indeed, as\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nBART\nT5\nLLaMA-7B\nReference\nKEITSum\nFigure 3: Hallucination ratio per dialog in DialogSum.\nseen in Tables 2, there is a greater performance improvement in\nthe CNN/DM, which has a longer average text length than Di-\nalogSum. For a more detailed analysis, we divide the Dialog-\nSum dataset into long and short categories based on the average\nlength of the text. As shown in Table 3, while there was a slight\nperformance improvement when the summary length was short,\nour model showed notable performance improvement when the\nsummary length was long.\n5.3. Human evaluation\nWe conducted a human evaluation to ascertain the performance\nimprovement of our model compared to other summarization\nmodels (Table 4). We hired three English teachers to assess 20\ndialogues via Upwork3. The evaluation criteria encompass com-\nprehension, faithfulness, relevance, fluency, and overall score\nbased on individual preference, rated on a scale of 0 to 5 (high-\nest). KEITSum surpassed LLaMA2-7B in faithfulness and rel-\nevance, reflecting better alignment with the original document\nand inclusion of only crucial information. This improvement\nstems from our focus on key entities and sentences, ensuring no\nimportant details are missed in the summaries.\n5.4. Measuring hallucinations\nAs Incorporating missing entities can potentially lead to hallu-\ncinations [12], we quantified how inconsistent information was\npresent in the generated summaries. Inspired by the following\nresearch findings that ChatGPT can evaluate in a manner simi-\nlar to humans [37, 35, 38], we employed ChatGPT to gauge the\nextent of hallucination in model-generated summaries of 20 di-\nalogue samples; here, hallucination refers to any incorrect con-\ntent, including misattribution, misinterpretation, and redundant\ncontent. Figure 3 illustrates that our model produces summaries\nwith an average of 60% fewer hallucinations per dialogue than\nthose generated by LLaMA2-7B, even surpassing the reference\nsummaries in hallucination reduction.\n6. Conclusion\nWith the advent of GPT-3, LLM-utilized summarization has\nachieved superior performance. However, large-scale propri-\netary LLMs are only accessible via APIs and are expensive,\nwhile the smaller public model, sLLMs, still struggles with\nentity omission in summarization and delivers inferior perfor-\nmance. We propose a key-element-informed instruction tuning\nmethod to overcome this issue in sLLMs. By adding emphasis\ntokens to essential elements and detailed instruction for sum-\nmarization, UniEval scores noticeably improved in relevance,\nexhibiting a comparable overall score of GPT-3. Furthermore,\nboth 60% reduced hallucinations on ChatGPT evaluation and\n4.8% improved faithfulness in human evaluation, proving the\nefficacy of our method.\n3https://www.upwork.com/\n\n7. Acknowledgements\nThis work was supported by the National Research Founda-\ntion of Korea (NRF) grant funded by the Korea government\n(MSIT) (No.\nRS-2023-00217286) and Institute of Informa-\ntion & communications Technology Planning & Evaluation\n(IITP) grant funded by the Korea government (MSIT) (No.RS-\n2019-II191906, Artificial Intelligence Graduate School Pro-\ngram (POSTECH)).\n8. References\n[1] Vaswani et al., “Attention is all you need,” Advances in neural\ninformation processing systems, 2017.\n[2] M. Lewis et al., “BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation, and compre-\nhension,” in Proceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, 2020.\n[3] Zhang et al., “Pegasus: pre-training with extracted gap-sentences\nfor abstractive summarization,” in Proceedings of the 37th Inter-\nnational Conference on Machine Learning, 2020.\n[4] C. Raffel et al., “Exploring the limits of transfer learning with\na unified text-to-text transformer,” Journal of Machine Learning\nResearch, 2020.\n[5] Y. Liu et al., “BRIO: Bringing order to abstractive summariza-\ntion,” in Proceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics, 2022.\n[6] T. Goyal et al., “News summarization and evaluation in the era of\ngpt-3,” 2023.\n[7] T. Zhang et al., “Benchmarking large language models for news\nsummarization,” 2023.\n[8] X. Pu, M. Gao, and X. Wan, “Summarization is (almost) dead,”\narXiv preprint arXiv:2309.09558, 2023.\n[9] Y. Chen et al., “DialogSum: A real-life scenario dialogue summa-\nrization dataset,” in Findings of the Association for Computational\nLinguistics: ACL-IJCNLP 2021, 2021.\n[10] R. Nallapati et al.,\n“Abstractive text summarization using\nsequence-to-sequence RNNs and beyond,” in Proceedings of the\n20th SIGNLL Conference on Computational Natural Language\nLearning, 2016.\n[11] M. Zhong et al., “Towards a unified multi-dimensional evaluator\nfor text generation,” in Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing, 2022.\n[12] Y. Zou et al., “Towards understanding omission in dialogue sum-\nmarization,” in Proceedings of the 61st Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1: Long Papers),\n2023.\n[13] X. Tang et al., “CONFIT: Toward faithful dialogue summarization\nwith linguistically-informed contrastive fine-tuning,” in Proceed-\nings of the 2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language\nTechnologies, Seattle, United States, 2022.\n[14] D. Deutsch and D. Roth, “Incorporating question answering-\nbased signals into abstractive summarization via salient span se-\nlection,” in Proceedings of the 17th Conference of the European\nChapter of the Association for Computational Linguistics, 2023.\n[15] S. Berezin et al., “Named entity inclusion in abstractive text sum-\nmarization,” in Proceedings of the Third Workshop on Scholarly\nDocument Processing, 2022.\n[16] Y. Wang et al., “Element-aware summarization with large lan-\nguage models: Expert-aligned evaluation and chain-of-thought\nmethod,” in Proceedings of the 61st Annual Meeting of the As-\nsociation for Computational Linguistics, 2023.\n[17] T. Brown et al., “Language models are few-shot learners,” in Ad-\nvances in Neural Information Processing Systems.\nCurran Asso-\nciates, Inc., 2020.\n[18] T. Scialom et al., “QuestEval: Summarization asks for fact-based\nevaluation,” in Proceedings of the 2021 Conference on Empirical\nMethods in Natural Language Processing, 2021.\n[19] O. Honovich et al., “q2:\nEvaluating factual consistency in\nknowledge-grounded dialogues via question generation and ques-\ntion answering,” in Proceedings of the 2021 Conference on Em-\npirical Methods in Natural Language Processing, 2021.\n[20] D. Wan et al., “Faithfulness-aware decoding strategies for abstrac-\ntive summarization,” in Proceedings of the 17th Conference of the\nEuropean Chapter of the Association for Computational Linguis-\ntics, May 2023.\n[21] P. Roit et al., “Factually consistent summarization via reinforce-\nment learning with textual entailment feedback,” in Proceedings\nof the 61st Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), 2023.\n[22] T. Goyal et al.,\n“Evaluating factuality in generation with\ndependency-level entailment,” in Findings of the Association for\nComputational Linguistics: EMNLP 2020. Association for Com-\nputational Linguistics, 2020.\n[23] W. Kryscinski et al., “Evaluating the factual consistency of ab-\nstractive text summarization,” in Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language Processing\n(EMNLP), 2020.\n[24] T. Zhang* et al., “Bertscore: Evaluating text generation with\nbert,” in International Conference on Learning Representations,\n2020.\n[25] Y. Liu et al., “G-eval: NLG evaluation using gpt-4 with better hu-\nman alignment,” in Proceedings of the 2023 Conference on Em-\npirical Methods in Natural Language Processing, 2023.\n[26] S. Ryu et al., “Multi-dimensional optimization for text summa-\nrization via reinforcement learning,” in Proceedings of the 62nd\nAnnual Meeting of the Association for Computational Linguistics,\n2024.\n[27] D. Miller, “Leveraging bert for extractive text summarization on\nlectures,” 2019.\n[28] Y. Mao et al., “Constrained abstractive summarization: Preserv-\ning factual consistency with constrained generation,” 2021.\n[29] Y. Liu et al., “Text summarization with pretrained encoders,”\nin Proceedings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th International Joint\nConference on Natural Language Processing, 2019.\n[30] A. Akbik, Bergmann et al., “FLAIR: An easy-to-use framework\nfor state-of-the-art NLP,” in Annual Conference of the North\nAmerican Chapter of the Association for Computational Linguis-\ntics (Demonstrations), 2019.\n[31] S. Pradhan et al., “Towards robust linguistic analysis using\nontonotes,” in Proceedings of the Seventeenth Conference on\nComputational Natural Language Learning, 2013.\n[32] Touvron et al., “Llama 2: Open foundation and fine-tuned chat\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\n[33] E. Hu et al., “Lora: Low-rank adaptation of large language mod-\nels,” arXiv preprint arXiv:2106.09685, 2021.\n[34] G. Adams et al., “Learning to revise references for faithful\nsummarization,” in Findings of the Association for Computational\nLinguistics:\nEMNLP 2022, 2022. [Online]. Available:\nhttps:\n//aclanthology.org/2022.findings-emnlp.296\n[35] C.-H. Chiang and oth, “Can large language models be an alter-\nnative to human evaluations?” in Proceedings of the 61st Annual\nMeeting of the Association for Computational Linguistics (Volume\n1: Long Papers), 2023.\n[36] C. Shen et al., “Are large language models good evaluators for\nabstractive summarization?” arXiv preprint arXiv:2305.13091,\n2023.\n[37] M. Gao, J. Ruan, R. Sun, X. Yin, S. Yang, and X. Wan, “Human-\nlike summarization evaluation with chatgpt,” arXiv preprint\narXiv:2304.02554, 2023.\n[38] L. Du et al., “Quantifying and attributing the hallucination of large\nlanguage models via association analysis,” 2023.",
    "pdf_filename": "Key-Element-Informed_sLLM_Tuning_for_Document_Summarization.pdf"
}