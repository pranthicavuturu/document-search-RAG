{
    "title": "Testability of Instrumental Variables in Additive Nonlinear, Non-Constant Effects Models",
    "context": "We address the issue of the testability of instrumental variables derived from observational data. Most existing testable implications are centered on scenarios where the treatment is a discrete variable, e.g., instrumental inequality (Pearl, 1995), or where the eﬀect is assumed to be constant, e.g., instrumental variables condition based on the principle of independent mechanisms (Burauel, 2023). However, treatments can often be continuous variables, such as drug dosages or nutritional content levels, and non-constant eﬀects may occur in many real-world scenarios. In this paper, we consider an additive nonlinear, non- constant eﬀects model with unmeasured confounders, in which treatments can be either discrete or continuous, and propose an Auxiliary-based Independence Test (AIT) condition to test whether a variable is a valid instrument. We ﬁrst show that if the candidate instrument is valid, then the AIT condition holds. Moreover, we illustrate the implications of the AIT condition and demonstrate that, in certain conditions, AIT conditions are necessary and suﬃcient to detect all invalid IVs. We also extend the AIT condition to include covariates and introduce a practical testing algorithm. Experimental results on both synthetic and three diﬀerent real-world datasets show the eﬀectiveness of our proposed condition. ∗. Equal contribution †. Corresponding author ©2022 Author One and Author Two. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/.",
    "body": "arXiv:2411.12184v1  [stat.ME]  19 Nov 2024\nTestability of Instrumental Variables in Additive Nonlinear,\nNon-Constant Eﬀects Models\nXichen Guo∗\nguoxichen0@gmail.com\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nZheng Li∗\nzhengli0060@gmail.com\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nBiwei Huang\nbih007@ucsd.edu\nHalicioglu Data Science Institute (HDSI), University of California San Diego\nLa Jolla, San Diego, California, 92093, USA\nYan Zeng\nyanazeng013@btbu.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nZhi Geng\nzhigeng@pku.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nSchool of Mathematical Sciences, Peking University\nBeijing, 100871, China\nFeng Xie †\nfengxie@btbu.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nAbstract\nWe address the issue of the testability of instrumental variables derived from observational\ndata. Most existing testable implications are centered on scenarios where the treatment\nis a discrete variable, e.g., instrumental inequality (Pearl, 1995), or where the eﬀect is\nassumed to be constant, e.g., instrumental variables condition based on the principle of\nindependent mechanisms (Burauel, 2023). However, treatments can often be continuous\nvariables, such as drug dosages or nutritional content levels, and non-constant eﬀects may\noccur in many real-world scenarios. In this paper, we consider an additive nonlinear, non-\nconstant eﬀects model with unmeasured confounders, in which treatments can be either\ndiscrete or continuous, and propose an Auxiliary-based Independence Test (AIT) condition\nto test whether a variable is a valid instrument.\nWe ﬁrst show that if the candidate\ninstrument is valid, then the AIT condition holds. Moreover, we illustrate the implications\nof the AIT condition and demonstrate that, in certain conditions, AIT conditions are\nnecessary and suﬃcient to detect all invalid IVs. We also extend the AIT condition to\ninclude covariates and introduce a practical testing algorithm. Experimental results on\nboth synthetic and three diﬀerent real-world datasets show the eﬀectiveness of our proposed\ncondition.\n∗. Equal contribution\n†. Corresponding author\n©2022 Author One and Author Two.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/.\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nKeywords:\ninstrumental variable; testability; unmeasured confounders; non-constant\neﬀects; causal graphical models\n1 Introduction\nEstimating causal eﬀects from observational data is a fundamental task in understanding\nthe underlying relationships between variables. The instrumental variables (IV) model is\na well-established method for estimating the causal eﬀect of a treatment (exposure) X\non an outcome Y in the presence of latent confounding and has been used in a range of\nﬁelds, such as economics (Imbens, 2014; Imbens and Rubin, 2015), sociology (Pearl, 2009;\nSpirtes et al., 2000), epidemiology (Hern´an and Robins, 2006; Baiocchi et al., 2014), and\nartiﬁcial intelligence (Chen et al., 2022; Wu et al., 2022). Generally speaking, given a causal\nrelationship X →Y , the valid IV Z is required to satisfy the following three conditions:\nC1. Z is related to the treatment (relevance), C2. Z is independent of the unmeasured\nconfounders that aﬀect the treatment and outcome (exogeneity), and C3. Z has no direct\npath to the outcome (exclusion restriction). Figure 1 illustrates the graphical criteria of\nthe IV model, where Z is a valid IV relative to X →Y in the subgraph (a).\nU\nZ\nX\nY\n(a) Valid IV model\nU\nZ\nX\nY\n(b) IV model that violates C2\nU\nZ\nX\nY\n(c) IV model that violates C3\nFigure 1: Graphical illustration of IV models, where U is the set of unmeasured confounders.\n(a) Z is a valid IV. (b) Z is an invalid IV due to the edge U →Z (Violate C2).\n(c) Z is an invalid IV due to the edge Z →Y (Violate C3).\nDue to the presence of unmeasured confounders U, determining which variable serve\nas a valid IV is not always straightforward based solely on observational data, and often\nrequires domain knowledge. A classic test for IV model is the Durbin-Wu-Hausman test\n(Nakamura and Nakamura, 1981). Given a subset of valid IVs, it can identify whether other\npotential candidates are also valid IVs. However, it does not guide how to ﬁnd the initial\nset of valid IVs. Meanwhile, given an invalid IV, it may not consistently identify the correct\ncausal eﬀect (Bound et al., 1995; Chu et al., 2001). Thus, it is vital to develop statistical\nmethods for selecting IVs solely from observational data.\nIt is not feasible to ascertain the validity of IVs solely based on the joint distribution\nof observed variables, without incorporating additional assumptions (Pearl, 2009). Pearl\n(1995) introduced a seminal necessary criterion known as the instrumental inequality, which\nacts as a critical test for identifying potential IVs in models featuring discrete variables.\nBuilding on this groundwork, subsequent research by Manski (2003); Palmer et al. (2011);\nKitagawa (2015); Wang et al. (2017) broadened the scope, exploring the applicability and\nlimitations of IV validity tests across diverse scenarios. A notable advancement was made\nby K´edagni and Mouriﬁ´e (2020), who formulated a more encompassing set of criteria, the\ngeneralized instrumental inequalities. These criteria cater to scenarios with discrete treat-\n2\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nment variables, removing constraints of the type of data on the IV and outcome variables\nand oﬀering a robust framework to challenge the exogeneity condition. The above methods\nuse the idea that if the IV is independent of the confounders and exclusion restriction (C3)\nholds, then changes in the IV should not have a signiﬁcant impact on the outcome vari-\nable without altering the treatment variable, because the treatment variable mediates the\ninﬂuence of the instrumental variable on the outcome variable. However, these methods fail\nto work when treatment is a continuous variable. In reality, one may often be concerned\nabout the causal eﬀect of the continuous treatment on the outcome; see Skaaby et al. (2013);\nMartinussen et al. (2019).\nSeveral contributions have been made to address continuous treatment settings under\ncertain assumptions. In an additive linear, constant eﬀects (ALICE) model, Kang et al.\n(2016); Bowden et al. (2016), and Windmeijer et al. (2019) have shown that if we assume\nmore than half of the variables are valid IVs in the potential IVs (known as the majority\nrule), we may identify the valid IVs solely from observed data. Later, Hartwig et al. (2017);\nGuo et al. (2018); Windmeijer et al. (2021) relaxed the majority rule and assumed that the\nnumber of valid IVs is larger than any number of invalid IVs with the same ratio estimator\nlimit (known as the plurality rule). They demonstrated that it is still possible to identify\nvalid IVs under the plurality rule. Another interesting work by Silva and Shimizu (2017) pro-\nposed the IV-TETRAD algorithm, which uses the so-called Trek conditions (Sullivant et al.,\n2010; Spirtes, 2013) for selecting a valid IV set. This method requires at least two or more\nvalid IVs in the system. However, although these methods have been used in a range of\nﬁelds, they may fail to test whether a single IV is valid.\nRecently, Xie et al. (2022) have demonstrated that a single IV imposes speciﬁc con-\nstraints within the linear non-Gaussian acyclic causal model. However, their method as-\nsumes that all noise terms are non-Gaussian and that the eﬀects remain constant. More\nrecently, Burauel (2023) have introduced a novel validity condition for Instrumental Vari-\nables based on the Principle of Independent Mechanisms, termed IV-PIM, within the linear\nIV framework. This condition is particularly notable as it applies to both continuous and\ndiscrete treatment variables. Nevertheless, its applicability is constrained by the presence\nof covariates, making it unsuitable when no covariates are available.\nAdditionally, the\ncondition is limited to scenarios with constant treatment eﬀects.\nPearl (1995) conjectured that the validity of an instrument cannot be tested when deal-\ning with continuous treatment variables without additional assumptions, a theory recently\nconﬁrmed by Gunsilius (2021). Unlike the existing work that focuses on the parametric\nlinear constant eﬀects model, we consider IV validity in a more challenging additive non-\nparametric model, the Additive NonlInear, Non-Constant Eﬀects (ANINCE) Model. Rather\nsurprisingly, although a single IV is in general not fully testable within the ANINCE model,\nwe will show that a single variable Z, being a valid IV relative to X →Y , imposes speciﬁc\nconstraints in the ANINCE model. Speciﬁcally, we make the following contributions:\n1. We introduce a necessary condition, termed the Auxiliary-based Independence Test\n(AIT) condition, for detecting a single variable that cannot serve as an IV within\nthe ANINCE model. This condition is applicable to scenarios involving non-constant\ncausal eﬀects and both discrete and continuous treatment.\n3\n\nGuo, Li, Huang, Zeng, Geng, and Xie\n2. We further provide the necessary and suﬃcient conditions for detecting all invalid IVs\nusing the AIT condition under the ANINCE model. Speciﬁcally, we show that, under\nthe partial non-Gaussianity assumption (Assumption 1), all observable violations of\nthe IV exogeneity condition can be identiﬁed in the linear, constant eﬀects model.\nAdditionally, under the algebraic equation condition assumption (Assumption 2), we\ncan detect invalid IVs resulting from violations of either exogeneity or the exclusion re-\nstriction in the ANINCE model. We also present two notable types of non-identiﬁable\ninvalid IVs (See Corollaries 1 ∼3), along with intuitive explanations for each.\n3. We present a practical implementation of the AIT condition test that accounts for the\npresence of covariates with ﬁnite data. We demonstrate the eﬃcacy and applicability\nof the proposed approach on both synthetic and three real-world datasets with diﬀerent\nscenarios.\nThe rest of this paper is organized as follows. In Section 2, we introduce notations, the\nadditive non-parametric IV model, and the ANINCE model. In Section 3, we formulate\nthe AIT condition for the single IV. We show the AIT condition is a necessary condition\nfor IV validity in the ANINCE model. We discuss the implications of AIT condition in the\nlinear, constant eﬀects model and the nonlinear, non-constant eﬀects model, respectively.\nWe show that, under additional assumptions, the AIT condition is a necessary and suﬃcient\ncondition for IV validity. In Section 4, we address the practical scenario with covariates and\nprovide the AIT Condition algorithm to test the validity of IV. We present the eﬃcacy and\napplicability of our method on both synthetic and three real-world datasets which contain\ncontinuous and discrete data in Section 5. Conclusions are given in Section 6.\n2 Preliminaries\n2.1 Notations\nOur research is conducted within the framework of causal graphical models as elaborated\nby Pearl (2009) and Spirtes et al. (2000).\nSpeciﬁcally, we represent causal relationships\nusing the directed acyclic graph (DAG), denoted as G, where nodes represent variables and\ndirected edges (arrows) indicate causal links between those variables. Sets of variables are\nrepresented in bold, and individual variables and symbols for graphs are in italics. We use\n“instrumental variable (IV)” and “instrument” interchangeably. The main symbols used in\nthis paper are summarized in Table 1.\n2.2 Additive Non-Parametric Instrumental Variable Model\nThe instrumental variable approach oﬀers a strategy for inferring the causal eﬀect of interest\nin the presence of unmeasured confounders (Bowden and Turkington, 1990; Angrist et al.,\n1996; Pearl, 2009; Imbens and Rubin, 2015). Given a causal relationship X →Y , a valid\nIV Z is required to satisfy the following three conditions:\nC1. (Relevance). Z has directly aﬀect the treatment X;\nC2. (Exogeneity or Randomness). Z is independent of the unmeasured confounders U;\nC3. (Exclusion Restriction). Z does not directly aﬀect the outcome Y .\n4\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nSymbol\nDescription\nG\nA directed acyclic graph\nX\nTreatment (exposure)\nY\nOutcome\nZ\nA candidate (potential) instrument\nU\nThe latent (unmeasured) confounders\nW\nCovariates\nZ\nThe residual of Z after regressing on covariates W\nIV\nInstrumental Variable\nA ⊥⊥B|C\nA is statistically independent of B given C\nA ̸⊥⊥B|C\nA is statistically dependent on B given C\n|W|\nThe number of variables in set W\nf(X, Z)\nThe causal eﬀect of X and Z on Y\nefbias(X, Z)\nThe bias between estimate causal eﬀect of X on Y and ground-truth causal\neﬀect of (X, Z) on Y\nε∗\nThe noise term of a variable\nϕ∗(U)\nThe eﬀect of the latent variables U on the observed variables\ng∗(Z)\nThe eﬀect of the instrument variable Z on the other observed variables\nR\nThe ﬁeld of real numbers\nR →R\nA mapping from the real numbers to the real numbers\nI(∗)\nThe indicator function\nE(X)\nThe expected value of random variable X\n∂2Y\n∂X∂Z\nThe second-order partial derivative of Y with respect to X and Z\nAX→Y ||Z (A)\nThe auxiliary variable of causal relationship X →Y relative to Z. We often\ndrop the subscript X →Y ||Z when there is no ambiguity in this paper\nK-test method\nThe Kitagawa’s method from Kitagawa (2015)\nIV-PIM\nmethod\nThe Burauel’s method from Burauel (2023)\nTable 1: The list of main symbols used in this paper\nDeﬁnition 1 A random variable Z is a valid IV for causal relationship X →Y if the above\nthree conditions C1 ∼C3 are satisﬁed.\nWe here consider the additive non-parametric IV model presented in Newey and Powell\n(2003), which, for a valid IV Z, it can be expressed as follows 1:\nX = g(Z) + ϕX(U) + εX\n|\n{z\n}\nδ\n,\nY = f(X) + ϕY (U) + εY\n|\n{z\n}\nǫ\n,\n(1)\nwhere E[ϕY (U) + εY |Z] = 0, and the noise terms εX and εY are statistically independent.\nRemark 1 Newey and Powell (2003) have shown that, given a valid IV Z, the causal eﬀect\nf(·) of interest in the above model in Equation (1) can be consistently estimated if the\n1. We here slightly modiﬁed the model from Newey and Powell (2003) to explicitly represent the unmea-\nsured confounders for subsequent analysis.\n5\n\nGuo, Li, Huang, Zeng, Geng, and Xie\ncompleteness of the conditional expectation of functions of X conditional Z is satisﬁed.\nNote that the completeness is generic, in the sense that it holds for “most ” s(X|Z), if it\nholds for one (Andrews, 2017; Newey, 2013). Hence, in the remainder of the paper, we will\nassume completeness holds when using the additive non-parametric IV model for estimation,\nwithout explicitly stating it each time.\n2.3 Additive Nonlinear, Non-Constant Eﬀects Model\nWithout loss of generality, we assume that all variables have a zero mean (otherwise can\nbe centered) and that no covariates are present for simplicity. In Section 4, we address the\npractical scenario where covariates are included. In this paper, we focus our attention on the\nAdditive NonlInear, Non-Constant Eﬀects (ANINCE) Model. Speciﬁcally, the generation\nprocess satisﬁes the following structural causal model:\nX = g(Z) + ϕX(U) + εX,\nY = f(X, Z) + ϕY (U) + εY ,\n(2)\nwhere f(·) denotes the true, unknown causal eﬀect of interest, and g(·), f(·) and ϕ∗(·) are\nsmooth/deterministic functions from R →R. The noise terms εX and εY are statistically\nindependent. Note that Z and U may be dependent, which indicates that the exogeneity\ncondition (C2) is violated, and the non-zero f(·, Z) function indicates that Z directly aﬀects\nthe outcome Y , implies that the exclusion restriction condition (C3) is violated.\nA special case of the ANINCE model is the additive linear, constant eﬀects model (AL-\nICE), where functions g(·), f(·), and ϕ∗(·) are linear functions, which have been extensively\nstudied in works such as those by Bowden et al. (2015); Kang et al. (2016); Silva and Shimizu\n(2017); Windmeijer et al. (2021). Compared to these works, we investigate the testability\nof IV in a more challenging scenario, where g(·), f(·), and ϕ∗(·) may be non-linear functions.\nAdditionally, we focus on the testability of a single valid IV, whereas previous works have\nfocused on the testability of a set of IVs (including at least two or more valid IVs among\nthe candidate variables).\nOur Goal. The goal of this paper is to determine, from the observed dataset {X, Y, Z}\nsatisfying an ANINCE model, whether Z is related to X (i.e., relevance condition), Z\nis exogenous relative to (X, Y ) (i.e., exogeneity condition) and Z does not directly aﬀect\noutcome Y (i.e., exclusion restriction condition). Note that the ﬁrst condition relevance,\ncan be easily checked by the independent test because Z and X are observed variables.\nTherefore, we focus on the last two conditions of IV Z. In summary, we aim to provide\na new necessary condition to detect whether a variable is a valid IV and investigate the\nnecessary and suﬃcient conditions under which all invalid IVs can be detected.\nRemark 2 Existing approaches have attempted to detect the violations of exogeneity of\na single IV within the discrete variable setting. Representative methods along this line in-\nclude instrumental inequality (Pearl, 1995), and its extensions (Manski, 2003; Palmer et al.,\n2011; Kitagawa, 2015; Wang et al., 2017; K´edagni and Mouriﬁ´e, 2020). Unlike existing\nwork, we focus on settings with continuous variables. Pearl (1995) already conjectured that\ninstrument validity is not testable in a continuous variable setting without additional as-\nsumptions, a theory recently conﬁrmed by Gunsilius (2021). The key diﬀerence to existing\n6\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nresearch considering instrumental variable models is that we introduce the additive function\nconstraints, allowing us to detect the invalid IVs when the treatment variable is continuous.\nMore recently, Burauel (2023) have proposed a testable IV condition for the continuous treat-\nment setting, based on the Principle of Independent Mechanisms (Janzing and Sch¨olkopf,\n2018). However, this condition is restricted to linear models and heavily depends on the\ndimensionality of the covariates.\n3 AIT Condition and Its Implications in ANINCE Models\nIn this section, we ﬁrst formulate the Auxiliary-based Independence Test Condition (AIT\nCondition) and show that it is a necessary condition for evaluating IV validity. We further\npresent theoretical results regarding the implications of the AIT condition in the linear,\nconstant eﬀects model and nonlinear, non-constant eﬀects model.\n3.1 AIT Condition\nBelow, we give the AIT Condition, which deﬁnes the independent relationship between\nthe “Auxiliary variable” and candidate IV. Note that concepts to “auxiliary variable” have\nbeen developed to address diﬀerent tasks (Drton and Richardson, 2004; Chen et al., 2017;\nCai et al., 2019), but our formalization is diﬀerent from theirs (See Equation (3)). To the\nbest of our knowledge, it has not been realized that the independence property involving\nsuch an auxiliary variable reﬂects the validity of the IV in the ANINCE model.\nDeﬁnition 2 (AIT Condition) Suppose treatment X, outcome Y , and candidate IV Z\nare nodes in a causal graph G. Deﬁne the auxiliary variable of the causal relationship X →Y\nrelative to Z, as\nAX→Y ||Z := Y −h(X),\n(3)\nwhere h(·) satisﬁes E[AX→Y ||Z|Z] = 0 and h(·) ̸= 0. We say that {X, Y ||Z} follows the\nAIT condition if and only if AX→Y ||Z is independent from Z.\nFor the sake of conciseness, we often drop the subscript X →Y ||Z from AX→Y ||Z when\nthere is no ambiguity. The following theorem shows the testability of an IV in light of the\nAIT condition in an ANINCE model.\nTheorem 1 (Necessary Condition for IV) Let X, Y , and Z be the treatment, outcome,\nand candidate IV in an ANINCE model, respectively. Suppose that X, Y , and Z are corre-\nlated and that the sample size n →∞holds. Further, suppose that the probability densities\np(εU) and p(εZ) are twice diﬀerentiable, and positive on (−∞, ∞).\nIf Z is a valid IV\nrelative to X →Y , then {X, Y ||Z} always satisﬁes the AIT condition.\nProof If Z is a valid IV relative to X →Y , then the ANINCE model can be rephrased as\nadditive non-parametric IV models (Equation (1)). Following the consistent IV estimation\nmethod via the conditional mean model (e.g., Newey and Powell (2003); Singh et al. (2019);\nBennett et al. (2019)), h(·) can represent the unbiased causal eﬀect f(·) of X on Y as the\nsample size n →∞, implying that h(·) = f(·). Thus, we have auxiliary variable\nAX→Y ||Z = Y −h(X) = Y −f(X) = ǫ = ϕY (U) + εY .\n(4)\n7\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nBelow, we prove this theorem using the linear separability of the logarithm of the joint\ndensity of independent variables, which states the fact that for a set of independent random\nvariables whose joint density is twice diﬀerentiable, the Hessian of the logarithm of their\ndensity is diagonal everywhere from Lin (1997) (See Theorem 5 in Appendix A for further\ndetails).\nCombining Z = εZ with Equation (4), we observe that the transformation from (AX→Y ||Z, Z)\nto (εU, εZ) is:\nεU = ϕY −1(AX→Y ||Z −εY ),\nεZ = Z.\n(5)\nLet |J| denote the Jacobian matrix of this transformation, giving by |J| = ∂εU\n∂A ·∂εZ\n∂Z −∂εU\n∂Z ·∂εZ\n∂A .\nDeﬁne p(AX→Y ||Z, Z) as the joint density of (AX→Y ||Z, Z). Then, we have p(AX→Y ||Z, Z) =\np(εU, εZ)|J| = p(εU) · p(εZ) · |J|. Let K1 ≜log p(εU), K2 ≜log p(εZ), and K3 ≜log(|J|).\nSince the densities p(εU) and p(εZ) are twice diﬀerentiable and positive on (−∞, ∞), we\nhave\nlog p(AX→Y ||Z, Z) = log(p(εU) · p(εZ) · |J|),\n= log p(εU) + log p(εZ) + log(|J|) = K1 + K2 + K3.\n(6)\nOne can ﬁnd the (1, 2)-th entry of the Hessian matrix of log p(AX→Y ||Z, Z):\n∂2 log p(AX→Y ||Z, Z)\n∂AX→Y ||Z∂Z\n= ∂2(K1 + K2 + K3)\n∂AX→Y ||Z∂Z\n= ∂(K′\n1\n∂εU\n∂Z + K′\n2\n∂εZ\n∂Z + K′\n3\n∂|J|\n∂Z )\n∂A\n= K′′\n1\n∂εU\n∂A · ∂εU\n∂Z + K′\n1\n∂2εU\n∂A∂Z + K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z\n+ K′\n2\n∂2εZ\n∂A∂Z + K′′\n3\n∂|J|\n∂A · ∂|J|\n∂Z + K′\n3\n∂2|J|\n∂A∂Z .\n(7)\nFor a valid IV Z, the following conditions hold: ∂εU\n∂Z = 0, ∂εZ\n∂A = 0, ∂|J|\n∂Z = 0, and\n∂2|J|\n∂A∂Z = 0.\nConsequently, the second-order partial derivative\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\n= 0, which implies that\nAX→Y ||Z and Z are statistically independent. In other words, {X, Y ||Z} satisﬁes the AIT\ncondition.\nTheorem 1 means that if {X, Y ||Z} violates the AIT condition, then Z is an invalid IV\nrelative to X →Y . Otherwise, Z may or may not be valid.\n3.2 Implications of AIT Condition in Additive Linear, Constant Eﬀects\nModels\nIn this section, we focus our attention on a special type of ANINCE model, the linear, con-\nstant eﬀects model, which has been widely studied (Bowden et al., 2015; Kang et al., 2016;\nSilva and Shimizu, 2017; Windmeijer et al., 2021). Specially, we assume that each node in\nthe graph G represents a linear structural equation model, i.e., Vi = ΣVj∈pa(Vi)αijVj + εVi, i =\n1, 2, ..., n, where the noise terms εV1, ..., εVn are independent of each other, and αij is the\ndirect eﬀect of Vj →Vi. Hence, the ANINCE model in Equation (2) can be expressed as\nfollows:\nX = τZ + ρU + εX,\nY = βX + νZ + κU + εY ,\n(8)\n8\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nwhere Z = γU +εZ. When γ = 0 (satisfying the exogeneity condition) and ν = 0 (satisfying\nthe exclusion restriction condition), Z qualiﬁes as a valid IV relative to X →Y . Below, we\nshow the implications of the AIT condition in this model.\nMotivating Examples: Firstly, we illustrate with two simple examples that while a\nvalid IV does not impose any restrictions on the joint marginal distribution of the observed\nvariables within the linear Gaussian model, it does impose certain constraints in the linear\npartial non-Gaussian model, which can be identiﬁed using AIT condition. Consider the\ncausal graph in Figure 1(b), where Z is an invalid IV for X →Y , as it violates the\nexogeneity condition. Let N(0, 1) denote the standard normal distribution, and Exp(0.5)\ndenote the exponential distribution with a rate parameter of 0.5. Suppose the generating\nmechanisms of these models are as follows:\n• Linear Gaussian model.\nU = εU, Z = 2U + εZ, X = 1.5Z + 0.8U + εX, Y =\nX + 3.5U + εY , and εU, εZ, εX, εY ∼N(0, 1).\n• Linear partial non-Gaussian model. U = εU, Z = 2U + εZ, X = 1.5Z + 0.8U + εX,\nY = X + 3.5U + εY , εU ∼Exp(0.5), and εZ, εX, εY ∼N(0, 1).\n−8\n−4\n0\n4\n8\n−4\n0\n4\nAuxiliary−variable A\nCandidate IV Z\n(a) Linear Gaussian Model\n0\n10\n20\n30\n−4\n0\n4\nAuxiliary−variable A\nCandidate IV Z\n(b) Linear Partial Non-Gaussian Model\nFigure 2: Scatter plots of Candidate IV Z and Auxiliary-variable A under the linear models.\n(a) All noise terms follow Gaussian distributions. (b) Some noise terms follow non-\nGaussian distributions.\nThe diﬀerence between the above two models lies in the noise term εU; the ﬁrst follows a\nGaussian distribution, while the second follows an exponential distribution (non-Gaussian\ndistribution).\nFigure 2 shows the scatter plots of AX→Y ||Z versus the invalid IV Z for\ntwo models. Interestingly, we ﬁnd that, in the linear Gaussian model, AX→Y ||Z and Z are\nstatistically independent (satisfying AIT condition), while in the linear partial non-Gaussian\nmodel, AX→Y ||Z and Z are statistically dependent (violating AIT condition). These results\nsuggest that non-Gaussianity is beneﬁcial for identifying the invalid IV.\nThe following Propositions 1 and 2 formalize the phenomena discussed above.\nProposition 1 (Non-testability in Linear Gaussian Models) Let X, Y , and Z be\nthe treatment, outcome, and candidate IV in a linear model (Equation (8)), respectively.\nSuppose that X, Y , and Z are correlated and that the sample size n →∞holds. If all noise\nterms of variables follow Gaussian distributions, then regardless of whether Z is a valid IV\nrelative to X →Y or not, {X, Y ||Z} always satisﬁes the AIT condition.\n9\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nProof The proof of Proposition 1 is straightforward.\nLet Z represents any candidate\nIV, which may or may not be valid.\nBy the deﬁnition of the AIT condition, we have\nE[AX→Y ||Z|Z] ≡0, regardless of the choice of h(·). This directly implies that the correla-\ntion between AX→Y ||Z and Z is zero. In the linear Gaussian model, zero correlation implies\nindependence (Bain and Engelhardt, 1992). Therefore, the condition E[AX→Y ||Z|Z] ≡0\nimplies that AX→Y ||Z is independent of the candidate IV Z in the linear Gaussian model.\nIn other words, {X, Y ||Z} always satisﬁes the AIT condition.\nProposition 1 states that checking the AIT condition in a linear Gaussian causal model\n(second-order statistics) does not provide any useful information for identifying invalid IVs.\nBelow, we show that higher-order statistics 2 of noise terms enable us to identify certain\ntypes of invalid IVs that violate the exogeneity condition. Before presenting the result, we\ngive the key assumption.\nAssumption 1 (Partial Non-Gaussianity) At least one of the following conditions holds:\n(i) there exists at least one variable Uk ∈U whose noise term follows a non-Gaussian dis-\ntribution and cause Z; (ii) the noise term of Z follows a non-Gaussian distribution.\nAssumption 1 states the non-Gaussianity of data, which is expected to be widespread,\nas suggested by Cram´er Decomposition Theorem (Cram´er, 1962). Considerable works have\nalready been built on this assumption (Shimizu et al., 2006; Salehkaleybar et al., 2020). For\nadditional references, see Spirtes and Zhang (2016); Shimizu (2022).\nWe now show that the AIT condition can access the validity of exogeneity condition in\nlinear models under Assumption 1.\nProposition 2 (Testability of Exogeneity in Linear Models) Let X, Y , and Z be\nthe treatment, outcome, and candidate IV in a linear model (Equation (8)), respectively.\nSuppose that X, Y , and Z are correlated and that the sample size n →∞holds. Further-\nmore, suppose that Assumption 1 holds. If Z violates the exogeneity condition, i.e., at least\none variable Uk ∈U causes Z, then {X, Y ||Z} violates the AIT condition.\nProof Roughly speaking, if AX→Y ||Z shares common non-Gaussian noise terms with Z, by\nthe Darmois–Skitovich theorem (Darmois, 1953; Skitovitch, 1953), AX→Y ||Z is statistically\ndependent from Z. This implies that {X, Y ||Z} violates the AIT condition. See Appendix\nA.1 for its complete proof.\nRemark 3 When all noise terms follow the non-Gaussian distributions, the linear partial\nnon-Gaussian model becomes the well-known Linear Non-Gaussian Acyclic Model (LiNGAM),\nwhich has been extensively studied (Shimizu et al., 2006; Salehkaleybar et al., 2020). Con-\nsequently, according to Proposition 2, an invalid IV that violates the exogeneity condition\nin LiNGAM can be detected in light of the AIT condition.\n2. Higher-order statistics mean beyond the second-order moments in statistics, e.g., skewness, kurtosis, etc.,\nof the data.\n10\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nProposition 2 states that we can detect an invalid IV that violates exogeneity condi-\ntion using the AIT condition based on the observational data in the linear model under\nAssumption 1. A natural question that arises is whether we can detect IVs that violate the\nexclusion restriction condition within the same framework. Unfortunately, in practice, we\ncannot detect an invalid IV that solely violates the exclusion restriction condition in the\nlinear model, as shown in the following example.\nExample 1 Let’s consider the causal structure illustrated in Figure 1 (a), where Z is a valid\nIV. We assume the following relationship: Z = εZ, X = τZ +ρU +εX, Y = βX +κU +εY .\nNext, we demonstrate how to construct another causal structure as shown in Figure 1 (c),\nwhere Z becomes an invalid IV (violating solely exlcusion restriction condition). Speciﬁcally,\nlet β′ = β −ν\nτ , Z′ = Z, X′ = X, and Y ′ = β′X′ + νZ′ + κU + εY + ν\nτ (ρU + εX) = Y .\nThus, (X, Y, Z) has the same distribution as (X′, Y ′, Z′). This implies that a variable being\nan instrument imposes no constraints on the joint marginal distribution of the observed\nvariables. The same result is also discussed in Section 3 of Chu et al. (2001).\nThe following proposition states the above phenomenon in the linear model.\nProposition 3 (Non-testability of Exclusion Restriction in Linear Models) Let X,\nY , and Z be the treatment, outcome, and candidate IV in a linear model (Equation (8)),\nrespectively. Suppose that X, Y , and Z are correlated and that the sample size n →∞\nholds. If Z satisﬁes the exogeneity condition, regardless of whether Z violates the exclusion\nrestriction condition or not, then {X, Y ||Z} always satisﬁes the AIT condition.\nProof This proof is straightforward. The auxiliary variable AX→Y ||Z shares no common\nnoise terms with candidate IV Z, whether the noise terms are Gaussian or non-Gaussian.\nBy the Darmois-Skitovich theorem (Darmois, 1953; Skitovitch, 1953), AX→Y ||Z is statisti-\ncally independent from Z. This implies that {X, Y ||Z} always satisﬁes the AIT condition.\nSee Appendix A.2 for its complete proof.\nBased on Theorem 1 and Propositions 1 ∼3, we derive the following theorem, which\nprovides a necessary and suﬃcient condition for detecting all invalid IVs within a linear\ncausal model.\nTheorem 2 (Necessary and Suﬃcient Conditions in Linear Models) Let X, Y , and\nZ be the treatment, outcome, and candidate IV in a linear model (Equation (8)), respec-\ntively. Suppose that X, Y , and Z are correlated and that the sample size n →∞holds.\nFurthermore, suppose that Assumption 1 holds. {X, Y ||Z} violates the AIT condition if\nand only if the candidate IV Z is invalid due to a violation of the exogeneity condition.\nProof See Appendix A.3 for its proof.\nThis theorem states that the AIT condition is necessary and suﬃcient to detect the\nvariable violations of the exogeneity condition when Assumption 1 holds.\n11\n\nGuo, Li, Huang, Zeng, Geng, and Xie\n3.3 Implications of AIT Condition in Additive Nonlinear, Non-Constant\nEﬀects Models\nIn this section, we investigate the implications of the AIT condition on the ANINCE model.\nBefore giving our main results, we ﬁrst show a simple example to show that nonlinearity is\nbeneﬁcial in identifying the invalid IV.\nA Motivating Example: Continue to consider the causal graph in Figure 1 (b),\nwhere Z serves as an invalid IV for the causal relationship X →Y , violating the exogeneity\ncondition.\nHere, we modify the generation mechanism of the linear Gaussian model by\nintroducing a nonlinear function between U and Z, speciﬁcally as follows:\n• Partial Non-linear Gaussian model. U = εU, Z = eU + εZ, X = 1.5Z + 0.8U + εX,\nY = X + 3.5U + εY , and εU, εZ, εX, εY ∼N(0, 1).\n0\n10\n20\n30\n−15\n−10\n−5\n0\n5\nAuxiliary−variable A\nCandidate IV Z\nFigure 3: Scatter plot of Candidate IV Z and Auxiliary-variable A when all noise terms\nfollow Gaussian distribution in the partially non-linear invalid IV model.\nFigure 3 presents the scatter plots of AX→Y ||Z versus the candidate IV Z in the partial\nnon-linear Gaussian model. Compared to the linear Gaussian model, we transformed the\nfunctional relationship between U and Z from a linear function (2U) to an exponential\nfunction (eU). Interestingly, in the partial non-linear Gaussian model, AX→Y ||Z and Z are\nstatistically dependent (violating AIT condition). Note that Proposition 1 shows that the\nAIT condition is always satisﬁed in the linear Gaussian model. These ﬁndings suggest that\nnonlinearity is beneﬁcial in accessing the validity of exogeneity condition.\nWe now investigate the conditions under which the invalid IV can be detected in terms\nof AIT condition.\nIt is noteworthy that the ANINCE model (Equation (2)) is ﬂexible\nas functions g, f, ϕX, and ϕY might be any unknown functions. Consequently, without\nimposing further parametric assumptions, it is impossible to determine the explicit forms\nof the estimated f and AX→Y ||Z. Hence, let h(·) be the estimated function, where h(·)\nsatisﬁes E[Y −h(X)|Z] = 0 and h(·) ̸= 0. According to the deﬁnition of the AIT condition,\nThe auxiliary variable AX→Y ||Z is given by:\nAX→Y ||Z = Y −h(X) = f(X, Z) −h(X)\n|\n{z\n}\nefbias(X,Z)\n+ϕY (U) + εY ,\n(9)\n12\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nwhere efbias(X, Z) = f(X, Z) −h(X). It is important to note that for a valid instrumental\nvariable Z, efbias(X, Z) = 0. For the sake of convenience, we often use efbias(X, Z) throughout\nthis paper.\nBelow, we give the key assumption regarding the second-order partial derivative in the\nnonlinear model.\nAssumption 2 (Algebraic Equation Condition) Deﬁne the algebraic equation condi-\ntion characterizing the second-order partial derivative below:\n∂2 log p(AX→Y ||Z, Z)\n∂AX→Y ||Z∂Z\n= ∂2(K1 + K2 + K3)\n∂AX→Y ||Z∂Z\n̸= 0,\n(10)\ni.e.,\nK′′\n1\n∂εU\n∂A · ∂εU\n∂Z + K′\n1\n∂2εU\n∂A∂Z + K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z + K′\n2\n∂2εZ\n∂A∂Z + K′′\n3\n∂|J|\n∂A · ∂|J|\n∂Z\n+K′\n3\n∂2|J|\n∂A∂Z ̸= 0,\n(11)\nwhere AX→Y ||Z = efbias(X, Z) + ϕY (U) + εY , K1 = log p(εU), K2 = log p(εZ), and K3 =\nlog |J|. Here, |J| represents the Jacobian matrix of the transformation from (AX→Y ||Z, Z)\nto (εU, εZ).\nRemark 4 Speciﬁcally, giving that the second and higher-order derivatives in the linear\nmodel are zero, the following holds:\n∂2εU\n∂A∂Z = 0,\n∂2εZ\n∂A∂Z = 0, ∂|J|\n∂A · ∂|J|\n∂Z = 0, and\n∂2|J|\n∂A∂Z = 0.\nTherefore, the algebraic equation condition can be expressed as\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\n= K′′\n1\n∂εU\n∂A ·\n∂εU\n∂Z + K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z ̸= 0.\nAssumption 2 is a very natural condition that one expects to hold for detecting all invalid\nIVs in the ANINCE model. Assumption 2 says that the second-order partial derivative\nis non-zero. By leveraging the linear separability of the logarithm of the joint density of\nindependent variables (Lin, 1997), we obtain the auxiliary variable AX→Y ||Z is dependent\non Z.\nProposition 4 (Testability of IV in ANINCE Models) Let X, Y , and Z be the treat-\nment, outcome, and candidate IV in an ANINCE model, respectively. Suppose that X, Y ,\nand Z are correlated and that the sample size n →∞holds. Furthermore, suppose that\nthe probability densities p(εU) and p(εZ) are twice diﬀerentiable, and positive on (−∞, ∞),\nand Assumption 2 holds. If the candidate IV Z is invalid, then {X, Y ||Z} violates the AIT\ncondition.\nProof See Appendix A.4 for its proof.\nThe proposition above shows that, under Assumption 2, the AIT condition can be used to\ndetect invalid IVs. Although it is not obvious whether Assumption 2 (the algebraic equation\ncondition) holds in general, some solutions under which the Assumption 2 is not hold are\nworth reporting here.\n13\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nCorollary 1 If all noise terms follow the Gaussian distributions within the linear causal\nmodel, then Assumption 2 does not hold.\nProof See Appendix A.5 for its proof.\nCorollary 1 implies that the AIT condition is always satisﬁed in the linear Gaussian model,\nconsistent with the result of Proposition 1.\nCorollary 2 If the candidate IV Z solely violates the exclusion restriction condition within\nthe linear causal model, then Assumption 2 does not hold.\nProof See Appendix A.6 for its proof.\nCorollary 2 implies that the AIT condition is always satisﬁed in the linear model when\ncandidate IV Z satisﬁes the exogeneity condition, consistent with the result of Proposition\n3.\nCorollary 3 If the candidate IV Z solely violates the exclusion restriction condition and\nthe direct causal eﬀect of Z →Y is a linear function of the direct causal eﬀect of Z →X,\ni.e., gY (Z) = a · gX(Z) + b, where a and b are non-zero constants, then Assumption 2 does\nnot hold.\nProof See Appendix A.7 for its proof.\nCorollary 3 implies that the AIT condition is always satisﬁed when the candidate IV Z\nsatisﬁes exogeneity condition and the relationship of eﬀect gY (Z) = a · gX(Z) + b holds\nin the ANINCE model.\nIn the special case with the linear model, the above corollary\nbecomes Corollary 2. Intuitively speaking, the distribution of the invalid IV model, where\ncandidate IV Z solely violates the exclusion restriction condition, can be transformed into\nthe distribution of the valid IV model, as illustrated in Example 2.\nExample 2 Continue to consider the causal graph in Figure 1 (c), where Z is an invalid\nIV relative to X →Y . The generating mechanism is as follows:\nZ = εZ,\nX = gX(Z) + ϕX(U) + εX,\nY = f(X) + gY (Z) + ϕY (U) + εY ,\n(12)\nwhere gY (Z) = a · gX(Z) + b. We now construct another model based on the causal graph\nshown in Figure 1 (a), where Z is a valid IV relative to X →Y . Let Z′ = Z, X′ = X, and\nf ′(X′) = f(X′)+a·gX(Z′)+b. Furthermore, Y ′ is expressed as Y ′ = f ′(X′)+ϕY (U)+εY =\nf(X) + gY (Z) + ϕY (U) + εY = Y . Hence, we conclude that the distribution of (Z, X, Y )\nand (Z′, X′, Y ′) are identical.\nBecause we can solely observe the variables (Z, X, Y ), it\nis impossible to determine from the distribution of (Z, X, Y ) whether the data come from\nFigure 1 (a) or Figure 1 (c). In other words, we cannot ascertain whether Z is a valid IV\nor not.\nThe above example shows that if the direct causal eﬀect of Z →Y is not a linear function\nof the direct causal eﬀect of Z →X, we can identify invalid IVs that solely violate the\nexclusion restriction condition using the AIT condition. According to the above corollaries,\nnot all invalid IVs can be identiﬁed solely from the joint distribution of observational data.\nBelow, based on Theorem 1 and Proposition 4, we introduce the necessary and suﬃcient\nconditions for invalid IV in the additive nonlinear, non-constant eﬀects model.\n14\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nTheorem 3 (Necessary and Suﬃcient Conditions for IV in ANINCE Models) Let\nX, Y , and Z be the treatment, outcome, and candidate IV in an ANINCE model (Equation\n(2)), respectively. Suppose that X, Y , and Z are correlated, and that the sample size n →∞\nholds. Furthermore, suppose that the probability densities p(εU) and p(εZ) are twice diﬀer-\nentiable, and positive on (−∞, ∞), and Assumption 2 holds. {X, Y ||Z} violates the AIT\ncondition if and only if the candidate IV Z is invalid due to the violation of at least one IV\nconditions.\nProof See Appendix A.8 for its proof.\nTheorem 3 outlines two scenarios where a candidate IV would be considered invalid: either\nthe IV doesn’t meet the exogeneity condition or it violates the exclusion restriction condition\nwithin a nonlinear model.\n4 Practical Implementation of AIT Condition\nIn this section, we discuss the practical implementation of the AIT condition. In Section\n4.1, we ﬁrst address how to conduct the AIT condition when covariates are present. We\nthen present a method for applying the AIT condition to data with a limited sample size\nin Section 4.2.\n4.1 AIT Condition with Covariates\nIn practice, there are scenarios where covariates W are present. For instance, age may\ninﬂuence how the treatment method aﬀects patient recovery speed.\nTherefore, we ﬁrst\nextend the AIT condition from Deﬁnition 2 to account for the presence of covariates, as\nstated in the following deﬁnition.\nDeﬁnition 3 (AIT Condition with Covariates) Suppose treatment X, outcome Y , co-\nvariates W, and candidate IV Z are nodes in a causal graph G. Deﬁne the auxiliary variable\nof the causal relationship X →Y relative to (Z, W), as\nAX→Y ||(Z,W) := Y −h(X, W),\n(13)\nwhere h(·) satisﬁes E[AX→Y ||(Z,W)|Z, W] = 0 and h(·) ̸= 0. Deﬁne the residual of Z after\nregressing on W as:\nZ := Z −E[Z|W].\n(14)\nWe say that {X, Y ||(Z, W)} follows the AIT condition if and only if AX→Y ||(Z,W) is inde-\npendent from Z.\nBased on Deﬁnition 3 and Theorem 1, we obtain the necessary condition for IV in the\npresence of covariates W, as described in the following corollary.\nCorollary 4 (Necessary Condition for IV with Covariates) Let X, Y , W, and Z\nbe the treatment, outcome, covariates, and candidate IV in an ANINCE model, respectively.\nSuppose that X, Y , W, and Z are correlated and that the sample size n →∞holds. Fur-\nthermore, suppose that the probability densities p(εU) and p(εZ) are twice diﬀerentiable, and\n15\n\nGuo, Li, Huang, Zeng, Geng, and Xie\npositive on (−∞, ∞). If Z is a valid IV relative to X →Y given W, then {X, Y ||(Z, W)}\nalways satisﬁes the AIT condition.\nProof See Appendix A.9 for its proof.\nCorollary 4 means that if {X, Y ||(Z, W)} violates the AIT condition, then Z is an invalid\nIV relative to X →Y given W. Otherwise, Z may or may not be valid.\n4.2 AIT Condition with Finite Data\nBelow, we provide the practical implementation of AIT condition with ﬁnite data. For a\ncandidate IV Z, under the ANINCE model, we need to test the following hypothesis:\nH0 : Z is a valid IV,\nH1 : Z is an invalid IV.\n(15)\nTo achieve this goal, we need to address the following two issues:\n• how can we compute the auxiliary variable AX→Y ||(Z,W) using {X, Y, W, Z}?\n• how to test whether AX→Y ||(Z,W) is statistical independence of Z?\nNext, we address the ﬁrst issue. The intuitive idea is that we ﬁrst use a standard IV\nestimator to estimate h(X, W), and then compute AX→Y ||(Z,W) = Y −h(X, W). Note that\ngiven a valid IV, the estimated h(X, W) is exactly f(X, W) (Newey and Powell, 2003).\nOtherwise, given an invalid IV, the estimated h(X, W) is biased relative to the true model.\nThere are now many IV estimators for Additive Non-Parametric IV Models (Guo and Small,\n2016; Singh et al., 2019; Bennett et al., 2019). Here, we adopt the control function IV esti-\nmator proposed by Guo and Small (2016), which is a two-stage approach. In the ﬁrst stage,\nit regresses the treatment variable X on covariates W and instruments (Z, h2(Z), . . . , hk(Z))\n(a known vector of linearly independent functions of Z), obtaining the predicted value ˆX\nand the residual e1 = X −ˆX. In the second stage, the outcome Y is regressed on the\ntreatment X, covariates W, and the residual e1 from the ﬁrst stage regression. The coeﬃ-\ncients of the second stage regression are taken as the control function estimates. Note that\nnonlinear functions can be estimated using basis functions. In our experiments, we apply\npolynomial basis functions as a predeﬁned set of linearly independent functions, leveraging\nthis control function method.\nWe now tackle the second issue. To check the statistical independence of AX→Y ||(Z,W)\nand Z, we employ the Large-Scale HSIC Test, a Hilbert-Schmidt Independence Criterion\n(HSIC)-based test proposed by Zhang et al. (2018), which utilizes large-scale kernel approx-\nimations for independence testing. If the output pvalue is less than the preset signiﬁcance\nlevel α, we reject the null hypothesis H0, indicating that the candidate IV Z is invalid.\nConversely, if we fail to reject the null hypothesis, it suggests that Z is a valid IV.\nBased on the above discussions, the complete AIT Condition test procedure is given\nin Algorithm 1. To allow for greater ﬂexibility in the algorithm and considering that prior\nknowledge, such as a constant causal eﬀect, may sometimes be available, we include a two-\nstage least squares estimator suitable for linear eﬀects (Basmann, 1957; Henckel et al., 2024)\nto estimate the causal eﬀect (See Lines 2 ∼3). Note that if the covariates W have a causal\neﬀect on IV Z, we will use the random forest method to obtain the residual Z of IV Z (See\nLine 8).\n16\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nAlgorithm 1 AIT Condition\nInput: Observed dataset D = {X, Y, W, Z}, containing: treatment X, outcome Y , covari-\nates W, and candidate IV Z, and signiﬁcance level α.\n1: Initialize: Result ←Do not reject H0\n/* Step one: Estimate AX→Y ||(Z,W) */\n2: if there is a constant eﬀect between X and Y then\n3:\nh(X, W) ←Two-Stage Least Squares Estimator (X, Y, W, Z)\n4: else\n5:\nh(X, W) ←Control Function IV Estimator (X, Y, W, Z)\n6: end if\n7: AX→Y ||(Z,W) ←Y −h(X, W)\n/* Step two: Test the AIT condition */\n8: Residual Z ←Random Forset Method (Z, W); set Z = Z if W = ∅\n9: pvalue ←Large-Scale HSIC Test(AX→Y ||(Z,W), Z)\n10: if pvalue < α then\n11:\nResult ←Reject H0\n12:\nreturn Result\n13: else\n14:\nreturn Result\n15: end if\nOutput: Result\n5 Experiments\nIn this section, we evaluated the performance of the proposed instrument validity AIT\ncondition using both synthetic data and three real-world datasets. All experiments were\nperformed with Intel 2.90 GHz and 2.89 GHz CPUs and 128 GB of memory. Our source\ncode is available from https://github.com/zhengli0060/AIT_Condition.\n5.1 Synthetic Data\nWe conducted simulation experiments from three perspectives. First, in Section 5.1.1, we\nveriﬁed the correctness of our theoretical results. Then, in Section 5.1.2, we compared the IV-\nPIM method proposed by Burauel (2023), which is designed for continuous treatments with\ncovariates. Finally, in Section 5.1.3, we compared the proposed method with Kitagawa’s\nmethod, abbreviated as the K-test method (Kitagawa, 2015), which is designed for discrete\ntreatments.\nIn all experiments, we evaluated the performance of our method using the\nfollowing metrics:\n•\nValid IVs Misidentiﬁcation Ratio (Valid MR): the ratio of the number of valid\nIVs incorrectly identiﬁed in the output.\n•\nInvalid IVs Misidentiﬁcation Ratio (Invalid MR): the ratio of the number of\ninvalid IVs incorrectly identiﬁed.\n17\n\nGuo, Li, Huang, Zeng, Geng, and Xie\n5.1.1 Theoretical Validation of Proposed Method\nIn this section, we conducted simulations to verify our theoretical results for both the linear\nmodel and the ANINCE model.\nSpeciﬁcally, we tested our method’s ability to identify\ninvalid IVs that violate the exogeneity condition under three scenarios: linear constant con-\nditions with varied distributions, partially nonlinear constant conditions (with Gaussian\nnoise terms), and partially nonlinear non-constant conditions with varied functional forms\nbut a consistent Uniform distribution. The performance results are presented in Table 2, Ta-\nble 3, and Table 4, respectively. Further, we examined the proposed method’s eﬀectiveness\nin identifying invalid IVs that violate the exclusion restriction condition under nonlinear\nconstant and nonlinear non-constant conditions with diﬀerent functional forms but the same\nBeta distribution. Results for these tests are shown in Table 5 and Table 6.\nExperimental Design: We generated data according to the model in Equation (2),\nwhere each candidate IV set contains both a valid IV and an invalid IV. For the nonlin-\near non-constant eﬀects model, we applied ﬁve functions-logarithmic, quadratic polynomial,\ncubic polynomial, logarithmic quadratic polynomial, exponent quadratic polynomial-for g(·),\nf(·) and ϕ∗(·). In contrast, these functions were linear under linear, constant settings. For\nthe error term ε∗, we selected six distributions3: Gaussian, Uniform, T, Beta, Gamma, Log-\nnormal. In all experiments, the signiﬁcance level was adjusted to 10 divided by the sample\nsize. Each experiment was repeated 100 times with randomly generated data, and the re-\nported results were averaged. Additional experimental details can be found in Appendix\nB.\nTable 2: Performance in Testing Violations of Exogeneity within Linear Models.\nSize=3K\nSize=5K\nSize=7K\nDistribution\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nUniform\n0.00\n0.06\n0.00\n0.01\n0.00\n0.01\nBeta\n0.00\n0.09\n0.00\n0.08\n0.00\n0.05\nT-distribution\n0.00\n0.03\n0.00\n0.02\n0.00\n0.00\nGamma\n0.00\n0.08\n0.00\n0.03\n0.00\n0.02\nLog-normal\n0.00\n0.13\n0.00\n0.08\n0.00\n0.03\nGaussian\n0.00\n1.00\n0.00\n1.00\n0.00\n1.00\nMixed\n0.01\n0.20\n0.00\n0.15\n0.00\n0.13\nNote: ↓means a lower value is better, and vice versa.\nTable 3: Performance in Testing Violations of Exogeneity within Partial Non-Linear Con-\nstant Eﬀect Models.\nSize=3K\nSize=5K\nSize=7K\nFunction\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nLog\n0.02\n0.00\n0.02\n0.00\n0.02\n0.00\nQuadratic polynomial\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nCubic polynomial\n0.00\n0.05\n0.00\n0.00\n0.00\n0.00\nLog(quadratic)\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nExp(quadratic)\n0.01\n0.16\n0.01\n0.02\n0.01\n0.02\nNote: ↓means a lower value is better, and vice versa.\n3. The “Mixed distribution” refers to that obtained by randomly selecting from the mentioned distributions.\n18\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nTable 4: Performance in Testing Violations of Exogeneity within Partial Non-Linear Non-\nConstant Models.\nSize=3K\nSize=5K\nSize=7K\nFunction\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nLog\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nQuadratic polynomial\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nCubic polynomial\n0.01\n0.00\n0.00\n0.00\n0.00\n0.00\nLog(quadratic)\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nExp(quadratic)\n0.01\n0.00\n0.00\n0.00\n0.00\n0.00\nNote: ↓means a lower value is better, and vice versa.\nTable 5: Performance in Testing Violations of Exclusion Restriction within Partial Non-\nLinear Constant Models.\nSize=3K\nSize=5K\nSize=7K\nFunction\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nLog\n0.14\n0.03\n0.09\n0.00\n0.07\n0.00\nQuadratic polynomial\n0.00\n0.03\n0.00\n0.01\n0.00\n0.00\nCubic polynomial\n0.00\n0.25\n0.00\n0.16\n0.00\n0.13\nLog(quadratic)\n0.03\n0.00\n0.01\n0.00\n0.00\n0.00\nExp(quadratic)\n0.00\n0.12\n0.00\n0.06\n0.00\n0.03\nNote: ↓means a lower value is better, and vice versa.\nTable 6: Performance in Testing Violations of Exclusion Restriction within Non-Linear Non-\nConstant Models.\nSize=3K\nSize=5K\nSize=7K\nFunction\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nLog\n0.20\n0.00\n0.18\n0.00\n0.12\n0.00\nQuadratic polynomial\n0.00\n0.04\n0.00\n0.03\n0.00\n0.02\nCubic polynomial\n0.00\n0.19\n0.00\n0.11\n0.00\n0.08\nLog(quadratic)\n0.09\n0.02\n0.06\n0.02\n0.03\n0.00\nExp(quadratic)\n0.02\n0.09\n0.00\n0.03\n0.00\n0.01\nNote: ↓means a lower value is better, and vice versa.\n19\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nResults: As shown in Tables 2 ∼6, both metrics generally improve signiﬁcantly with\nincreasing sample sizes across various distributions and functions.\nThose facts suggest\nthat our method can correctly identify invalid IVs that violate the exogeneity condition or\nviolate the exclusion restriction condition. More speciﬁcally, Table 2 highlights that non-\nGaussianity is beneﬁcial for identifying IV in linear models, as demonstrated in Figure 2\nand supported by Proposition 2. Notably, the Invalid MR value in the Gaussian distribution\nof the linear model in Table 2 is 1, indicating that our method cannot detect invalid IVs\nin a linear Gaussian model. This ﬁnding is consistent with the conclusions presented in\nProposition 1. Tables 3 ∼4 further show that even a slight degree of nonlinearity facilitates\nthe assessment of IV validity under the exogeneity condition in both nonlinear constant and\nnon-constant eﬀect models, as illustrated in Figure 3 and stated in Proposition 4. Lastly,\nTables 5 ∼6 reveal that in nonlinear models, when the direct causal eﬀect of Z →Y does\nnot follow a linear function of the eﬀect of Z →X, it becomes possible to assess the validity\nof IVs solely concerning the exclusion restriction condition, as highlighted in the negative\nof Corollary 3 and elaborated in Proposition 4.\n5.1.2 Comparison with IV-PIM in Continuous Treatment Setting\nIn this section, we compared the proposed AIT Condition with IV-PIM, as proposed by\nBurauel (2023), in continuous treatment settings. Note that since IV-PIM requires covari-\nates, we introduce covariates here for a fair comparison.\nExperimental Design: The speciﬁc generation mechanism with covariates W in the\nlinear mdoel is deﬁned as follows: U = εU, W = εW , Z1 = I(U + W + εZ1), Z2 =\nI(W + εZ2), X = 0.5Z1 + 0.5Z2 + λW + δ, and Y = X + W + ǫ, where εU ∼T(5), εZ1 ∼\nBeta(0.5, 0.1), εZ2 ∼N(0, 1), and δ, ǫ ∼T(5). Here, I(∗) is the indicator function such\nthat I(∗) > mean(∗) equals 1; otherwise, it is 0. The coeﬃcient λ is randomly drawn from\na normalized standard normal distribution. The noise terms εW follow a multidimensional\nnormal distribution and are consistent with IV-PIM, with the dimensionality of covariates\nW varying across |W| = {2, 3, 5}. The remaining settings are the same as in Section 5.1.1.\nResults: As shown in Table 7, our method outperforms experimental results of IV-PIM\nwith covariates under both Valid MR and Invalid MR. Interestingly, IV-PIM’s performance\nimproves as the dimensionality of covariates increases, consistent with ﬁndings in Burauel\n(2023). Additionally, Table 7 highlights the practicality of the AIT condition with covariates,\nas presented in Corollary 4.\nTable 7: Performance in Testing Instrumental Variables with Covariates.\nSize=3K\nSize=5K\nSize=7K\n|W|\nCondition\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\n2\nIV-PIM method (Burauel, 2023)\n0.23\n0.28\n0.23\n0.21\n0.33\n0.17\nAIT condition\n0.00\n0.28\n0.00\n0.06\n0.00\n0.02\n3\nIV-PIM method (Burauel, 2023)\n0.14\n0.26\n0.21\n0.22\n0.17\n0.19\nAIT condition\n0.00\n0.19\n0.00\n0.01\n0.00\n0.01\n5\nIV-PIM method (Burauel, 2023)\n0.12\n0.19\n0.05\n0.28\n0.08\n0.24\nAIT condition\n0.00\n0.06\n0.00\n0.00\n0.00\n0.00\nNote: ↓means a lower value is better, and vice versa.\n20\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\n5.1.3 Comparison with K-test in Discrete Treatment Setting\nIn\nthis\nsection,\nwe\ncompared\nthe\nproposed\ninstrument\nvalidity\ntest\nwith\nthe\nK-test,\nwhich\nwas\nproposed\nby\nKitagawa\n(2015)\nfor\ndiscrete\ntreatment\nset-\ntings\nwithout\ncovariates.\nThe\nsource\ncode\nfor\nthe\nK-test\nis\navailable\nat\nhttps://rdrr.io/github/CarrThomas/TestforInstrumentValidity/.\nExperimental Design: The discrete treatment data that simulates violations of the\nexogeneity and exclusion restriction conditions as follows: U = εU, Z = I(ϕZ(U) + εZ),\nX = I(gX(Z)+ϕX(U)+εX), Y = βX +gY (Z)+ϕY (U)+εY , and ε∗∼N(0, 1), where the\ncausal eﬀect β = 1, and I(∗) is the indicator function such that I(∗) > mean(∗) equals 1;\notherwise, it is 0. The functions ϕ∗(U) and g∗(Z) are nonlinear and randomly selected from\nthe following: cos, sin, square, cubic(third-degree polynomials), logarithmic, exponential\nfunction. The remaining settings are the same as in Section 5.1.1.\nResults: As shown in Table 8, our method outperforms the K-test method in terms of\nInvalid MR across all sample sizes. The Invalid MR for the K-test method is slightly higher,\nparticularly with smaller sample sizes, though it decreases as the sample size increases. For\nthe Valid MR metric, both methods achieve a value of 0, indicating that neither method\nmistakenly identiﬁes valid IVs as invalid.\nTable 8: Performance in Testing Instrumental Variables with Discrete Treatment.\nSize=3K\nSize=5K\nSize=7K\nCondition\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nValid MR↓\nInvalid MR↓\nK-test method (Kitagawa, 2015)\n0.00\n0.20\n0.00\n0.15\n0.00\n0.10\nAIT condition\n0.00\n0.09\n0.00\n0.07\n0.00\n0.01\nNote: ↓means a lower value is better, and vice versa.\n5.2 Real-World Datasets\nIn this section, we evaluated the eﬀectiveness of the proposed method by applying it to\nthree real-world datasets from diﬀerent domains.\n5.2.1 Schooling-Returns Data\nWe consider the application of our method to the study by Card (1993). This study inves-\ntigates the impact of education levels on earnings using data from the Young Men Cohort\nof the National Longitudinal Survey.\nData Description: The dataset is a sample of 3010 men taken from the US National\nLongitudinal Survey of Young Men (NLSY). It includes variables such as Lived near the col-\nlege (Lnc), Schooling (Sch), Returns (Re), and a set of covariates including {Experience, Ex-\nperience square, Black, Smsa, Smsa66, South, Region information (reg662-reg669)} (ER),\namong others.\nThe hypothesized model of Card (1993) is presented in Figure 4.\nThe\nhypothesized data generation mechanism is described as follows:\nSch = α0 + α1Lnc + α⊤ER + δ,\nRe = β0 + β1Sch + β⊤ER + ǫ,\n(16)\nwhere δ and ǫ are dependent.\n21\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nER\nLnc\nSch\nRe\nIndividual\nAbility\nFigure 4: Graphical illustration of an IV model for estimating the causal eﬀect of schooling\n(Sch) on returns of education (Re) (Card, 1993).\nResults: Card (1993) demonstrated that Lnc can serve as a valid IV for the causal\nrelationship Sch →Re, while controlling for the covariates ER. For consistency, we adopt\nthe causal eﬀect of Sch on Re, i.e., β1 = 0.1315, as well as the coeﬃcients β of the covariates\nfrom Card (1993), as the estimated parameter ˆβ under the AIT condition. We then obtain\nthe residual g\nLnc by regressing Lnc on the covariates ER. The P-value of the independence\ntest between the auxiliary variable and the residual g\nLnc is 0.732, indicating that we cannot\nreject Lnc as a valid IV. This result further supports the validity of using Lnc as an IV,\nconsistent with the ﬁndings in Card (1993).\n5.2.2 Colonial Origins data\nWe apply our method to the study by Acemoglu et al. (2001), which estimates the impact of\ncolonial history on the economic development of diﬀerent regions using the Colonial Origins\nof Comparative Development dataset.\nData Description: The dataset includes ﬁve key variables across 64 countries, after ex-\ncluding samples with missing data. These variables are: Mortality (Mor), Euro1990 (Euro),\nLatitude (Lat), Institutions (Ins), and Economic Development (Ed).\nThe hypothesized\nmodel proposed by Acemoglu et al. (2001) is illustrated in Figure 5, and the hypothesized\ndata generation mechanism is described as follows:\nIns = γ + γ1Mor + γ2Lat + γ3Euro + δ,\nEd = β + β1Ins + β2Lat + ǫ,\n(17)\nwhere δ and ǫ are dependent.\nResults: Acemoglu et al. (2001) demonstrated that both Mor and Euor can serve as\nvalid IVs, conditional on Lat, with respect to Ins and Ed. To verify this, we test their\nvalidity using the AIT condition. For consistency, we adopt the causal eﬀects of Ins on Ed\nas reported by Acemoglu et al. (2001), speciﬁcally β1 = 0.9458 and β2 = −0.5971, as the\nestimated parameters ˆβi(i = 1, 2) in the AIT condition. We next obtain the residuals g\nMor\nand g\nEuro by regressing Mor and Euro on covariate Lat, respectively. The validity test for\nMor yields a P-value of 0.608, whereas the test for Euro yields a P-value of 0.248. These\nresults indicate that Euro is more likely to be an invalid IV compared to Mor, suggesting\nthat the exogeneity of Euro is weaker than that of Mor. These ﬁndings are consistent with\nthose of Acemoglu et al. (2001), and we cannot reject the validity of Mor and Euro as IVs,\naligning with their conclusions.\n22\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nEuro\nIns\nEd\nCultural\ndifference\nLat\nMor\nFigure 5: Graphical illustration of an IV model for estimating the causal eﬀect of institu-\ntions (Ins) on economic development (Ed) (Acemoglu et al., 2001).\n5.2.3 Conflict and Time Preference Data\nWe consider the application of our method to the study by Voors et al. (2012). This study\nuses the Conﬂict and Time Preference Data to investigate the impact of violence on a\nperson’s patience.\nData Description: The dataset consists of 302 observations and ﬁfteen variables, as\ndescribed in Voors et al. (2012). Treatment violence is measured by the percentage dead\nin attacks in the area the person lived (Dper), while the person’s patience (outcome) is\nassessed by a person’s discount rate for willingness to receive larger amounts of money\nin the future compared to smaller amounts of money now (Disc). Other variables include\ndistance to Bujumbura (dist), altitude (alti), and covariates such as {whether the respondent\nis literate, the respondent’s age, the respondent’s sex, the total land holding per capita, land\nGini coeﬃcient, distance to market, conﬂict over land, ethnic homogeneity, socioeconomic\nhomogeneity, population density, per capita total expenditure}(PG). The covariates used\nin the study represent exogenous personal and geographical information variables (PG). As\ndiscussed in Voors et al. (2012), violence may be targeted in a non-random way, potentially\nrelated to community patience, which makes violence (Dper) endogenous. The hypothesized\nmodel from Guo and Small (2016) is illustrated in Figure 6, and the hypothesized generation\nmechanism is as follows:\nDper = α0 + α1dist + α2alti + α3d2\nist + α4a2\nlti + α5dist ∗alti + α⊤\n6 P G + δ,\nDisc = β0 + β⊤\n1 P G + β2Dper + β3D2\nper + ǫ,\n(18)\nwhere δ and ǫ are dependent.\nResults: Voors et al. (2012) showed that both dist and alti can serve as valid IVs,\nconditional on PG, with respect to Dper on Disc. To verify this, we test their validity\nusing the AIT condition. For consistency, we adopt the causal eﬀects of Dper on Disc as\nreported by Guo and Small (2016), speciﬁcally β2 = 2.054 and β3 = 0.049, as the estimated\nparameters ˆβi(i = 2, 3) in the AIT condition.\nWe obtain the residual g\ndist and f\nalti by\nregressing dist and alti on covariates PG, respectively. We ﬁrst test the validity of dist, which\nyields a P-value of 0.326, suggesting that dist cannot be rejected as a valid instrumental\n23\n\nGuo, Li, Huang, Zeng, Geng, and Xie\ndist\nalti\nDper\nDisc\nPG\nSocial and\nPolitical\nconfounder\nFigure 6: Graphical illustration of an IV model for estimating the causal eﬀect of violence\n(Dper) on a person’s patience (Disc)(Voors et al., 2012).\nvariable. This is consistent with the ﬁndings of Voors et al. (2012). Similarly, testing alti\nas a potential IV results in a P-value of 0.758, indicating that alti also cannot be rejected\nas a valid IV. These results align with the conclusions of Voors et al. (2012).\n6 Conclusions\nIn this paper, we explored the testability of single IVs in the additive nonlinear, non-constant\neﬀects (ANINCE) model, where the treatment variable can be either discrete or continuous.\nTo this end, we introduced a necessary condition, termed the AIT Condition, to detect\nwhether a variable is a valid IV without knowing whether some other variable is an instru-\nment. Furthermore, we provided the precision conditions for identifying all invalid IVs in\nlinear and ANINCE models. We then proposed the practical AIT condition test algorithm\nwith covariates and ﬁnite data. Experimental results using both simulation data and three\nreal datasets have further validated the usefulness of our algorithm. In the future, we plan\nto investigate whether the AIT condition could facilitate the testability implication of an\ninvalid IV set.\nAcknowledgements\nThe authors would like to thank Kun Zhang for his helpful comments and suggestions. The\nauthors also would like to thank Patrick Burauel, who kindly provided us with his R imple-\nmentation of the IV-PIM. FX would like to acknowledge the support by the Natural Science\nFoundation of China (62306019). XCG acknowledges the support of the Graduate Research\nAbility Enhancement Program Project Funding at Beijing Technology and Business Uni-\nversity.\nYZ would like to acknowledge the support of the Beijing Municipal Education\nCommission Science and Technology Program General Project (KM202410011016).\n24\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nAppendix A. Proofs\nBefore presenting the proofs, we introduce two important theorems since these are used to\nprove our results.\nWe ﬁrst quote the Darmois–Skitovitch theorem that characterizes the independence of\ntwo linear statistics (Darmois, 1953; Skitovitch, 1953). This theorem provides the founda-\ntion for proving Propositions 2 ∼3 and Theorem 2.\nTheorem 4 (Darmois–Skitovitch Theorem) Deﬁne two random variables V1 and V2\nas linear combinations of independent random variables ε1, ..., εp:\nV1 =\np\nX\ni=1\nαiεi,\nV2 =\np\nX\ni=1\nβiεi,\n(19)\nwhere the αi, βi are constant coeﬃcients. If V1 and V2 are independent, then the random\nvariables εj for which αjβj ̸= 0 are Gaussian.\nThe above theorem states that if there exists a non-Gaussian εj for which αjβj ̸= 0, V1 and\nV2 are dependent.\nNext, we introduce a local geometric information theorem that characterizes the inde-\npendence of two nonlinear statistics (Lin, 1997). This result provides the foundation for\nproving Proposition 4, Theorems 1, 3 and Corollarys 1 ∼4.\nTheorem 5 The Hessian Hf of function f is block diagonal everywhere, ∂i∂jf\n\f\f\n⃗s0 = 0 for\nall points ⃗s0 and all i ≤k, j > k, if and only if f is separable into a sum f(s1, ..., sn) =\ng(s1, ..., sk) + h(sk+1, ..., sn) for some functions g and h.\nThe above proposition states that function f is separable if and only if its mixed second-\norder partial derivative is zero.\nA.1 Proof of Proposition 2: Testability of Exogeneity in Linear Models\nProof Under the assumption of a linear model, Equation (2) can be expressed as follows:\nU = εU,\nZ = γU + εZ,\nX = τZ + ρU + εX,\nY = βX + νZ + κU + εY .\n(20)\nIf candidate IV Z violates the exogeneity condition, the causal eﬀect estimated via the IV\nestimator-speciﬁcally, the Two Stages Least Square method (Bowden and Turkington, 1990;\nPearl, 2009))-will be biased:\nˆβ = β + γ(νγ + κ)Var(U) + ν Var(εZ)\nγ(τγ + ρ)Var(U) + τ Var(εZ)\n|\n{z\n}\nβbias\n.\n(21)\nBased on the deﬁnition of the AIT condition, we have\nAX→Y ||Z = Y −ˆβX\n= νZ + κU + εY −βbiasX\n= [νγ + κ −(ντ + ρ) βbias] εU + (ν −τβbias) εZ −βbiasεX + εY .\n(22)\n25\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nBecause Z is an invalid IV that violates the exogeneity condition, without loss of generation,\nwe assume that Uk causes the candidate IV Z, i.e., γk ̸= 0, then βbias ̸= 0. This will imply\nthat [νγk + κk −(ντ + ρk) βbias] ̸= 0 for εUk, and (ν −τβbias) ̸= 0 for εZ. Furthermore,\nbecause of Assumption 1, i.e., (i) there exists at least one variable Uk ∈U whose noise\nterm follows a non-Gaussian distribution and cause Z or, (ii) the noise term of Z follows\na non-Gaussian distribution, then at least one of the non-Gaussian noise terms εUk\nor εZ, is common between AX→Y ||Z and Z.\nDue to the Darmois–Skitovitch Theorem,\nwe have AX→Y ||Z is dependent on Z. That is to say, {X, Y ||Z} violates the AIT condition.\nA.2 Proof of Proposition 3: Non-testability of Exclusion Restriction in Linear\nModels\nProof Because candidate IV Z satisﬁes exogeneity condition, the model of Equation (2)\ncan be written as:\nU = εU,\nZ = εZ,\nX = τZ + ρU + εX,\nY = βX + νZ + κU + εY .\n(23)\nThe estimated causal eﬀect is given by ˆβ = β + βbias = β + ν\nτ , where βbias ̸= 0. According\nto the AIT condition, we obtain\nAX→Y ||Z = Y −ˆβX\n= νZ + κU + εY −βbiasX\n=\n\u0010\nκ −ρν\nτ\n\u0011\nεU −ν\nτ εX + εY .\n(24)\nWhen ν = 0, implying that Z is a valid IV, we have AX→Y ||Z = κεU + εY .\nIn both\ncases—whether Z is an invalid IV that violates solely the exclusion restriction condition\nor a valid IV—there are no shared noise terms between AX→Y ||Z and Z.\nBy the Dar-\nmois–Skitovitch Theorem (Theorem 4), we have AX→Y ||Z is independent of Z.\nThus,\n{X, Y ||Z} always satisﬁes the AIT condition.\nA.3 Proof of Theorem 2: Necessary and Suﬃcient Conditions in Linear\nModels\nProof Below, we prove the necessary and suﬃcient condition for identifying invalid IV in\nthe linear model.\n(⇒): According to Theorem 1, we know that if Z is a valid IV relative to X →Y , then\n{X, Y ||Z} always satisﬁes the AIT condition. This indicates that if {X, Y ||Z} violates the\nAIT condition, then Z is an invalid IV. Below, we processed with a proof by contradiction\nto prove that candidate IV Z violates the exogeneity condition. If Z solely violates the\nexclusion restriction condition, then by Proposition 3, {X, Y ||Z} always satisﬁes the AIT\ncondition. This contradicts the assumption that {X, Y ||Z} violates the AIT condition. As\na result, candidate IV Z violates the exogeneity condition.\n26\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\n(⇐): To establish that Assumption 1 holds and that the candidate IV Z is invalid due\nto a violation of the exogeneity condition, we need to show that {X, Y ||Z} consequently\nviolates the AIT condition. This conclusion is equivalent to Proposition 2, thereby proving\nthe theorem.\nA.4 Proof of Proposition 4: Testability of IV in ANINCE Models\nProof If Z violates the IV conditions, the generating mechanism can be described as follows:\nU = εU,\nZ = ϕZ(U) + εZ,\nX = g(Z) + ϕX(U) + εX,\nY = f(X, Z) + ϕY (U) + εY ,\n(25)\nwhere function g(·), f(·), and ϕ∗(·) are twice diﬀerentiable. Hence, let h(·) be the estimated\nfunction, where h(·) satisﬁes E[Y −h(X)|Z] = 0 and h(·) ̸= 0. According to the deﬁnition\nof the AIT condition, we have\nAX→Y ||Z = Y −h(X)\n= f(X, Z) −h(X)\n|\n{z\n}\nefbias(X,Z)\n+ϕY (U) + εY ,\n(26)\nwhere efbias(X, Z) = f(X, Z) −h(X). Combining the Equations (25) and (26), we have\nAX→Y ||Z = efbias(X, Z) + ϕY (U) + εY ,\nZ = ϕZ(U) + εZ.\n(27)\nAccording to the above Equation (27), one can see that the transformation from\n(AX→Y ||Z, Z) to (εU, εZ) is:\nεU = ϕ−1\nY (AX→Y ||Z −efbias(X, Z) −εY ),\nεZ = Z −ϕZ(εU).\n(28)\nDenote by |J| the Jacobian matrix of this transformation. One can see that |J| = ∂εU\n∂A ·\n∂εZ\n∂Z −∂εU\n∂Z · ∂εZ\n∂A . Denote by p(AX→Y ||Z, Z) the joint density of (AX→Y ||Z, Z). Then, we have\np(AX→Y ||Z, Z) = p(εU, εZ)|J| = p(εU) · p(εZ) · |J|. Let K1 ≜log p(εU), K2 ≜log p(εZ),\nand K3 ≜log |J|. Since the densities p(εU) and p(εZ) are twice diﬀerentiable and positive\non (−∞, ∞), we have\nlog p(AX→Y ||Z, Z) = log(p(εU) · p(εZ) · |J|),\n= log p(εU) + log p(εZ) + log(|J|) = K1 + K2 + K3.\n(29)\n27\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nOne can ﬁnd the (1, 2)-th entry of the Hessian matrix of log p(AX→Y ||Z, Z):\n∂2 log p(AX→Y ||Z, Z)\n∂AX→Y ||Z∂Z\n= ∂2(K1 + K2 + K3)\n∂AX→Y ||Z∂Z\n= ∂(K′\n1\n∂εU\n∂Z + K′\n2\n∂εZ\n∂Z + K′\n3\n∂|J|\n∂Z )\n∂A\n= K′′\n1\n∂εU\n∂A · ∂εU\n∂Z + K′\n1\n∂2εU\n∂A∂Z + K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z\n+ K′\n2\n∂2εZ\n∂A∂Z + K′′\n3\n∂|J|\n∂A · ∂|J|\n∂Z + K′\n3\n∂2|J|\n∂A∂Z .\n(30)\nFor an invalid IV Z that violates the IV conditions, there are two scenarios:\n• Violation the exogeneity condition:\n∂εU\n∂Z ̸= 0, ∂εZ\n∂A ̸= 0, ∂εU\n∂A ̸= 0, ∂|J|\n∂A ̸= 0, ∂|J|\n∂Z ̸= 0,\nand\n∂2|J|\n∂A∂Z ̸= 0;\n• Violation the exclusion restriction condition while satisfying the exogeneity condition:\n∂εU\n∂Z = 0, ∂εZ\n∂A ̸= 0,\n∂εZ\n∂A∂Z = 0, ∂|J|\n∂Z = 0, and\n∂2|J|\n∂A∂Z = 0.\nAccording to Assumption 2, speciﬁcally the condition that the second-order partial deriva-\ntive\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\n̸= 0, it follows that AX→Y ||Z ̸⊥⊥Z. This implies that {X, Y ||Z}\nviolates the AIT condition.\nA.5 Proof of Corollary 1\nProof Due to the assumption of linearity in the model, the model in Equation (2) can be\nwritten as:\nU = εU,\nZ = γU + εZ,\nX = τZ + ρU + εX,\nY = βX + νZ + κU + εY .\n(31)\nIf candidate IV Z violates the IV conditions, the estimated causal eﬀect using the IV\nestimator (i.e., Two Stages Least Square (Bowden and Turkington, 1990; Pearl, 2009)) will\nbe biased:\nˆβ = β + γ(νγ + κ)Var(U) + ν Var(εZ)\nγ(τγ + ρ)Var(U) + τ Var(εZ)\n|\n{z\n}\nβbias\n(32)\nAccording to the deﬁnition of AIT condition, we have\nAX→Y ||Z = Y −ˆβX\n= νZ + κU + εY −βbiasX\n= [νγ + κ −(ντ + ρ) βbias] εU + (ν −τβbias) εZ −βbiasεX + εY .\n(33)\nAccordingly, using Equation (31), the transformation from (AX→Y ||Z, Z) to (εU, εZ) be-\ncomes:\nεU = A −(ν −τβbias)εZ + βbiasεX −εY\nνγ + κ −(ντ + ρ)βbias\n,\nεZ = Z −γεU.\n(34)\n28\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nGiving that the second and higher-order derivatives in the linear model are zero, the\nfollowing holds:\n∂2εU\n∂A∂Z = 0, ∂2εZ\n∂A∂Z = 0, ∂|J|\n∂A · ∂|J|\n∂Z = 0, and ∂2|J|\n∂A∂Z = 0. Therefore, the algebraic\nequation condition can be expressed as follows:\n∂2 log p(AX→Y ||Z, Z)\n∂AX→Y ||Z∂Z\n= K′′\n1\n1\nγ2(ν −βbiasτ) + γ(κ −βbiasρ) + K′′\n2\n1\nν −βbiasτ .\n(35)\nBecause all noise terms follow Gaussian distribution, we have K′′\n1 = log p(εU)′′ = −\n1\nV ar(εU )\nand K′′\n2 = log p(εZ)′′ = −\n1\nV ar(εZ).\nFurther combined with Equation (35), we obtain\nK′′\n1\n1\nγ2(ν−βbiasτ)+γ(κ−βbiasρ) + K′′\n2\n1\nν−βbiasτ = 0, which imply that the second-order partial\nderivative\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\nis zero.\nThis result indicates that, under the linear model,\nGaussian noise terms yield a scenario where Assumption 2 does not hold.\nA.6 Proof of Corollary 2\nProof Due to the assumption of linearity in the model and given that the candidate IV Z\nsatisﬁes the exogeneity condition, the model of Equation (2) can be expressed as follows:\nU = εU,\nZ = εZ,\nX = τZ + ρU + εX,\nY = βX + νZ + κU + εY .\n(36)\nSince the second and higher-order derivatives in the linear model are zero, it follows that\n∂2εU\n∂A∂Z = 0,\n∂2εZ\n∂A∂Z = 0, ∂|J|\n∂A · ∂|J|\n∂Z = 0, and\n∂2|J|\n∂A∂Z = 0. Further, since Z = εZ, we also have\n∂εU\n∂Z\n= 0.\nAccordingly, the second-order partial derivative of the logarithm of the joint\nprobability density can be written as\n∂2 log p(AX→Y ||Z, Z)\n∂AX→Y ||Z∂Z\n= K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z .\n(37)\nIf IV Z solely violates the exclusion restriction condition, the estimated causal eﬀect using\nthe two-stage least square method (2SLS) is given by\nˆβ = β + βbias = β + ν\nτ ,\n(38)\nwhere βbias = ν\nτ .\nAccording to the deﬁnition of AIT condition, we obtain\nAX→Y ||Z = Y −ˆβX =\n\u0010\nκ −ρν\nτ\n\u0011\nεU −ν\nτ εX + εY .\n(39)\nThus, we obtain\n∂εZ\n∂A = 0.\nCombined with Equation (37), this yields the second-order\npartial derivative\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\n= 0. This result indicates that Assumption 2 does not\nhold.\n29\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nA.7 Proof of Corollary 3\nProof\nBecause candidate IV Z satisﬁes exogeneity condition, the model of Equation (2)\ncan be written as:\nU = εU,\nZ = εZ,\nX = gX(Z) + ϕX(U) + εX,\nY = f(X) + gY (Z) + ϕY (U) + εY .\n(40)\nIf the direct causal eﬀect of Z →Y is a linear function of the direct causal eﬀect of Z →X,\ni.e., gY (Z) = a · gX(Z) + b, then it is possible to construct a valid IV model that shares the\nsame distribution as the above invalid IV model (40). The model for this valid IV, which\nhas an identical distribution, is as follows:\nU′ = U,\nZ′ = Z,\nX′ = X,\nY ′ = f ′(X′) + ϕY (U) + εY = Y,\n(41)\nwhere f ′(X′) = f(X) + gY (Z).\nAccording to Equation (41), we know that Z′ is a valid IV relative to X′ →Y ′. Based\non the Theorem 1, the second-order partial derivative\n∂2 log p(AX→Y ||Z,Z)\n∂AX→Y ||Z∂Z\n= 0, indicating\nthat Assumption 2 does not hold.\nA.8 Proof of Theorem 3: Necessary and Suﬃcient Conditions for IV in\nANINCE Models\nProof Below, we prove the necessary and suﬃcient conditions for identifying invalid IV in\nthe ANINCE model.\n(⇒): According to Theorem 1, we know that if Z is a valid IV relative to X →Y , then\n{X, Y ||Z} always satisﬁes the AIT condition. This indicates that if {X, Y ||Z} violates the\nAIT condition, then Z is an invalid IV.\n(⇐): To establish that Assumption 2 holds and that the candidate IV Z is invalid, we\nneed to show that {X, Y ||Z} consequently violates the AIT condition. This conclusion is\nequivalent to Proposition 4, thereby proving the theorem.\nA.9 Proof of Corollary 4: Necessary Condition for IV with Covariates\nProof\nBelow, we apply the same proof technique used in Theorem 1 to demonstrate\nCorollary 4. Suppose Z is a valid IV relative to X →Y given W, the generating mechanism\ncan be expressed as follows:\nU = εU,\nW = ϕW (U) + εW ,\nZ = tZ(W) + εZ,\nX = g(W, Z) + ϕX(U) + εX,\nY = f(X, W) + ϕY (U) + εY ,\n(42)\nwhere functions g(·), f(·), t∗(·), and ϕ∗(·) are smooth functions.\nFollowing the consis-\ntent IV estimation method via the conditional mean model (e.g., Newey and Powell (2003);\n30\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nSingh et al. (2019); Bennett et al. (2019)), h(·) can represent the unbiased causal eﬀect f(·)\nof X on Y as the sample size n →∞, implying that h(·) = f(·). Thus, we have\nAX→Y ||(Z,W) = Y −h(X, W) = Y −f(X, W) = ǫ = ϕY (U) + εY .\n(43)\nLet Z denote the residual from the regression Z on W. Thus, Z = εZ.\nBelow, by combining Equations (43) and Z = εZ, we observe that the transformation\nfrom (AX→Y ||(Z,W), Z) to (εU, εZ) is:\nεU = ϕY −1(AX→Y ||(Z,W) −εY ),\nεZ = Z.\n(44)\nLet |J|A,Z denote the Jacobian matrix of this transformation, giving by |J|A,Z = ∂εU\n∂A · ∂εZ\n∂Z −\n∂εU\n∂Z · ∂εZ\n∂A . Denote by p(AX→Y ||(Z,W), Z) the joint density of (AX→Y ||(Z,W), Z). Then, we\nhave p(AX→Y ||(Z,W), Z) = p(εU, εZ)|J|A,Z = p(εU) · p(εZ) · |J|A,Z. Let K1 ≜log p(εU),\nK2 ≜log p(εZ), and K3 ≜log(|J|A,Z). The involved densities p(εU) and p(εZ) are twice\ndiﬀerentiable, and positive on (−∞, ∞), we have\nlog p(AX→Y ||(Z,W), Z) = log(p(εU) · p(εZ) · |J|A,Z),\n= log p(εU) + log p(εZ) + log(|J|A,Z) = K1 + K2 + K3.\n(45)\nOne can ﬁnd the (1, 2)-th entry of the Hessian matrix of log p(AX→Y ||(Z,W), Z):\n∂2 log p(AX→Y ||(Z,W), Z)\n∂AX→Y ||(Z,W)∂Z\n= ∂(K′\n1\n∂εU\n∂Z + K′\n2\n∂εZ\n∂Z + K′\n3\n∂|J|A,Z\n∂Z\n)\n∂A\n= K′′\n1\n∂εU\n∂A · ∂εU\n∂Z + K′\n1\n∂2εU\n∂A∂Z + K′′\n2\n∂εZ\n∂A · ∂εZ\n∂Z\n+ K′\n2\n∂2εZ\n∂A∂Z + K′′\n3\n∂|J|A,Z\n∂A\n· ∂|J|A,Z\n∂Z\n+ K′\n3\n∂2|J|A,Z\n∂A∂Z .\n(46)\nFor a valid IV Z, we know that ∂εU\n∂Z = ∂εZ\n∂A = 0 and ∂|J|A,Z\n∂Z\n= ∂2|J|A,Z\n∂A∂Z\n= 0. Hence, the\nsecond-order derivative\n∂2 log p(AX→Y ||(Z,W),Z)\n∂AX→Y ||(Z,W)∂Z\n= 0, i.e., AX→Y ||(Z,W) and Z are statistically\nindependent. Consequently, {X, Y ||(Z, W)} satisﬁes the AIT condition.\nAppendix B. More Details on Simulation Experiments in Section 5\nIn this section, we provide details of the simulation experiments corresponding to Tables 2\n∼8. Speciﬁcally, the generation mechanism for each table is as follows:\n• Table 2: The model setup is as follows: U = εU, Z1 = γU + εZ1, Z2 = εZ2, X =\nτ1Z1 +τ2Z2 +ρU +εX, Y = X +κU +εY , where all constant coeﬃcients are randomly\nselected from a uniform distribution with parameters min = 0.5 and max = 1.5. The\nnoise terms εU, εZ1, εZ2, εX, and εY follow the speciﬁc distributions listedin each row.\nThe ﬁnal row indicates that all noise terms are randomly drawn from one of six\ndistributions 4.\n4. These six distributions include Unifrom, Beta, T, Gamma, Lognormal, and Gaussian.\n31\n\nGuo, Li, Huang, Zeng, Geng, and Xie\n• Table 3: The model setup is as follows: U = εU, Z1 = ϕZ1(U) + εZ1, Z2 = εZ2,\nX = τ1Z1 + τ2Z2 + ρU + εX, Y = βX + κU + εY , where all constant coeﬃcients\nare set to 1, and all noise terms follow the Gaussian distribution with mean 0 and\nstandard deviation 1.\nThe nonlinear function ϕZ1(U) matches the corresponding\nfunction provided in each row. The details of the nonlinear function are as follows:\nLog:\nY = loge(0.2|X| −1);\nQuadratic polynomial:\nY = X2 −2 · X + 1;\nCubic polynomial:\nY = X3 −0.5 · X2 + 0.2 · X;\nLog (quadratic):\nY = loge(|0.5 · X2 + X|);\nExp (quadratic):\nY = e0.3·X2+X;\n(47)\n• Table 4: The model setup is as follows: U = εU, Z1 = γU + εZ1, Z2 = εZ2, X =\nτ1Z1 +τ2Z2 +ρU +εX, Y = f(X)+κU +εY , where all constant coeﬃcients are set to\n1, and all noise terms follow the Uniform distribution with parametric min = -2 and\nmax = 2. The nonlinear function f(X) corresponds to the speciﬁc function listed in\neach row. The details of the nonlinear function are as follows:\nLog:\nY = loge(0.5|X|);\nQuadratic polynomial:\nY = X2 −2 · X + 1;\nCubic polynomial:\nY = 0.01 · X3 −0.5 · X2 + 0.2 · X;\nLog (quadratic):\nY = 0.1 · loge(|0.5 · X2 −1|) −2;\nExp (quadratic):\nY = e0.3·X2+X;\n(48)\n• Table 5: The model setup is as follows: U = εU, Z1 = εZ1, Z2 = εZ2, X = sign(Z1) +\ngX(Z2) + ρU + εX, Y = X + gY (Z1) + κU + εY , where all constant coeﬃcients are\nrandomly selected from a uniform distribution with parameters min = 0.5 and max\n= 1.5. The sign(∗) denotes sign function, where ∗> 0 equals 1, ∗= 0 equals 0, and\notherwise, it equals -1; all noise terms follow a Beta distribution with parameters\nalpha = 0.5 and beta = 0.1. The nonlinear functions gX(Z2), gY (Z1) are deﬁned by\nthe speciﬁc functions provided in each row. The speciﬁc nonlinear functions are as\nfollows:\nLog:\nY = loge(0.2|X|) −2;\nQuadratic polynomial:\nY = 0.2 · X2 + 2 · X −2;\nCubic polynomial:\nY = 0.01 · X3 −X −6;\nLog (quadratic):\nY = loge(|0.5 · X2 + X −0.1|);\nExp (quadratic):\nY = e0.3·X2+X −0.1;\n(49)\n• Table 6: The model setup is as follows: U = εU, Z1 = εZ1, Z2 = εZ2, X = sign(Z1) +\ngX(Z2) + ϕX(U) + εX, Y = f(X) + gY (Z1) + ϕY (U) + εY , where sign(∗) denotes sign\nfunction. All noise terms follow the Beta distribution with parameters alpha = 0.5\n32\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nand beta = 0.1. The nonlinear functions correspond to the speciﬁc functions provided\nin each row. The detailed forms of these nonlinear functions are as follows:\nLog:\nY = loge(0.2|X| −2) −1;\nQuadratic polynomial:\nY = 0.2 · X2 + 2 · X −2;\nCubic polynomial:\nY = 0.01 · X3 −X −6;\nLog (quadratic):\nY = loge(|0.5 · X2 + X −1|);\nExp (quadratic):\nY = e0.2·X2 −3;\n(50)\n• Table 7: The speciﬁc generation mechanism for the linear model with covariates W\nis deﬁned as follows: U = εU, W = εW , Z1 = I(U + W + εZ1), Z2 = I(W + εZ2),\nX = 0.5Z1 + 0.5Z2 + λW + δ, and Y = X + W + ǫ, where εU ∼T(5), εZ1 ∼\nBeta(0.5, 0.1), εZ2 ∼N(0, 1), and δ, ǫ ∼T(5). Here, I(∗) is the indicator function\nsuch that I(∗) > mean(∗) equals 1; otherwise, it is 0. The coeﬃcient λ is randomly\ndrawn from a normalized standard normal distribution. The noise terms εW follow a\nmultidimensional normal distribution, consistent with IV-PIM, with the dimensional-\nity of covariates W varying across |W| = {2, 3, 5}.\nIn the IV-PIM method, the parameters are set as follows: the number of bootstrap\nsamples B=5, the kappa method is speciﬁed as spectral, and the synthetic treatment\nvariable method is set to knockoﬀ.\n• Table 8: The discrete treatment data that simulates violations of the exogeneity\nand exclusion restriction conditions as follows:\nU = εU, Z = I(ϕZ(U) + εZ),\nX = I(gX(Z)+ϕX(U)+εX), Y = βX +gY (Z)+ϕY (U)+εY , and ε∗∼N(0, 1), where\nβ = 1, and I(∗) is the indicator function such that I(∗) > mean(∗) equals 1; otherwise,\nit is 0. The functions ϕ∗(U) and g∗(Z) are nonlinear and randomly selected from the\nfollowing: cos, sin, square, cubic(third-degree polynomials), logarithmic, exponential\nfunction.\nReferences\nDaron Acemoglu, Simon Johnson, and James A Robinson. The colonial origins of com-\nparative development: An empirical investigation.\nAmerican economic review, 91(5):\n1369–1401, 2001.\nDonald WK Andrews. Examples of l2-complete and boundedly-complete distributions. Jour-\nnal of econometrics, 199(2):213–220, 2017.\nJoshua D Angrist, Guido W Imbens, and Donald B Rubin. Identiﬁcation of causal eﬀects\nusing instrumental variables. Journal of the American statistical Association, 91(434):\n444–455, 1996.\nLee J Bain and Max Engelhardt. Introduction to probability and mathematical statistics,\nvolume 4. Duxbury Press Belmont, CA, 1992.\nMichael Baiocchi, Jing Cheng, and Dylan S Small. Instrumental variable methods for causal\ninference. Statistics in medicine, 33(13):2297–2340, 2014.\n33\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nRobert L Basmann. A generalized classical method of linear estimation of coeﬃcients in\na structural equation. Econometrica: Journal of the Econometric Society, pages 77–83,\n1957.\nAndrew Bennett, Nathan Kallus, and Tobias Schnabel. Deep generalized method of mo-\nments for instrumental variable analysis. Advances in neural information processing sys-\ntems, 32, 2019.\nJohn Bound, David A Jaeger, and Regina M Baker. Problems with instrumental variables\nestimation when the correlation between the instruments and the endogenous explanatory\nvariable is weak. Journal of the American statistical association, 90(430):443–450, 1995.\nJack Bowden, George Davey Smith, and Stephen Burgess. Mendelian randomization with\ninvalid instruments: eﬀect estimation and bias detection through egger regression. Inter-\nnational journal of epidemiology, 44(2):512–525, 2015.\nJack Bowden, George Davey Smith, Philip C Haycock, and Stephen Burgess. Consistent\nestimation in mendelian randomization with some invalid instruments using a weighted\nmedian estimator. Genetic epidemiology, 40(4):304–314, 2016.\nRoger J Bowden and Darrell A Turkington. Instrumental variables. Number 8. Cambridge\nuniversity press, 1990.\nPatrick F Burauel. Evaluating instrument validity using the principle of independent mech-\nanisms. Journal of Machine Learning Research, 24(176):1–56, 2023.\nRuichu Cai, Feng Xie, Clark Glymour, Zhifeng Hao, and Kun Zhang. Triad constraints for\nlearning causal structure of latent variables. Advances in neural information processing\nsystems, 32, 2019.\nDavid Card.\nUsing geographic variation in college proximity to estimate the return to\nschooling, 1993.\nBryant Chen, Daniel Kumor, and Elias Bareinboim. Identiﬁcation and model testing in\nlinear structural equation models using auxiliary variables. In International Conference\non Machine Learning, pages 757–766. PMLR, 2017.\nYutian Chen, Liyuan Xu, Caglar Gulcehre, Tom Le Paine, Arthur Gretton, Nando De Fre-\nitas, and Arnaud Doucet.\nOn instrumental variable regression for deep oﬄine policy\nevaluation. The Journal of Machine Learning Research, 23(1):13635–13674, 2022.\nTianjiao Chu, Richard Scheines, and Peter Spirtes. Semi-instrumental variables: a test for\ninstrument admissibility. In Proceedings of the Seventeenth conference on Uncertainty in\nartiﬁcial intelligence, pages 83–90, 2001.\nH. Cram´er. Random variables and probability distributions. Cambridge University Press,\nCambridge, 2nd edition, 1962.\nGeorge Darmois. Analyse g´en´erale des liaisons stochastiques: etude particuli`ere de l’analyse\nfactorielle lin´eaire. Revue de l’Institut international de statistique, pages 2–8, 1953.\n34\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nMathias Drton and Thomas S Richardson.\nIterative conditional ﬁtting for gaussian an-\ncestral graph models. In Proceedings of the 20th conference on Uncertainty in artiﬁcial\nintelligence, pages 130–137, 2004.\nFlorian F Gunsilius.\nNontestability of instrument validity under continuous treatments.\nBiometrika, 108(4):989–995, 2021.\nZijian Guo and Dylan S Small. Control function instrumental variable estimation of non-\nlinear causal eﬀect models. Journal of Machine Learning Research, 17(100):1–35, 2016.\nZijian Guo, Hyunseung Kang, T Tony Cai, and Dylan S Small. Conﬁdence intervals for\ncausal eﬀects with invalid instruments by using two-stage hard thresholding with voting.\nJournal of the Royal Statistical Society: Series B (Statistical Methodology), 80(4):793–815,\n2018.\nFernando Pires Hartwig, George Davey Smith, and Jack Bowden.\nRobust inference in\nsummary data mendelian randomization via the zero modal pleiotropy assumption. In-\nternational journal of epidemiology, 46(6):1985–1998, 2017.\nLeonard Henckel, Martin Buttenschoen, and Marloes H Maathuis.\nGraphical tools for\nselecting conditional instrumental sets. Biometrika, 111(3):771–788, 2024.\nMiguel A Hern´an and James M Robins. Instruments for causal inference: an epidemiologist’s\ndream? Epidemiology, pages 360–372, 2006.\nGuido W. Imbens. Instrumental variables: An econometrician’s perspective. Statistical\nScience, 29(3):323–358, 2014.\nGuido W Imbens and Donald B Rubin. Causal inference for statistics, social, and biomedical\nsciences: An introduction. Cambridge University Press, 2015.\nDominik Janzing and Bernhard Sch¨olkopf. Detecting confounding in multivariate linear\nmodels via spectral analysis. Journal of Causal Inference, 6(1):20170013, 2018.\nHyunseung Kang, Anru Zhang, T Tony Cai, and Dylan S Small. Instrumental variables\nestimation with some invalid instruments and its application to mendelian randomization.\nJournal of the American statistical Association, 111(513):132–144, 2016.\nD´esir´e K´edagni and Ismael Mouriﬁ´e.\nGeneralized instrumental inequalities: testing the\ninstrumental variable independence assumption. Biometrika, 107(3):661–675, 2020.\nToru Kitagawa. A test for instrument validity. Econometrica, 83(5):2043–2063, 2015.\nJuan Lin. Factorizing multivariate function classes. Advances in neural information pro-\ncessing systems, 10, 1997.\nCharles F Manski. Partial identiﬁcation of probability distributions. Springer Science &\nBusiness Media, 2003.\nTorben Martinussen, Ditte Nørbo Sørensen, and Stijn Vansteelandt. Instrumental variables\nestimation under a structural cox model. Biostatistics, 20(1):65–79, 2019.\n35\n\nGuo, Li, Huang, Zeng, Geng, and Xie\nAlice Nakamura and Masao Nakamura. On the relationships among several speciﬁcation\nerror tests presented by durbin, wu, and hausman. Econometrica: journal of the Econo-\nmetric Society, pages 1583–1588, 1981.\nWhitney K Newey. Nonparametric instrumental variables estimation. American Economic\nReview, 103(3):550–556, 2013.\nWhitney K Newey and James L Powell. Instrumental variable estimation of nonparametric\nmodels. Econometrica, 71(5):1565–1578, 2003.\nTom M Palmer, Roland R Ramsahai, Vanessa Didelez, and Nuala A Sheehan. Nonpara-\nmetric bounds for the causal eﬀect in a binary instrumental-variable model. The Stata\nJournal, 11(3):345–367, 2011.\nJudea Pearl. On the testability of causal models with latent and instrumental variables.\nIn Proceedings of the Eleventh conference on Uncertainty in artiﬁcial intelligence, pages\n435–443, 1995.\nJudea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press,\nNew York, 2nd edition, 2009.\nSaber Salehkaleybar, AmirEmad Ghassami, Negar Kiyavash, and Kun Zhang. Learning\nlinear non-gaussian causal models in the presence of latent variables. Journal of Machine\nLearning Research, 21(39):1–24, 2020.\nShohei Shimizu. Statistical Causal Discovery: LiNGAM Approach. Springer, 2022.\nShohei Shimizu, Patrik O Hoyer, Aapo Hyv¨arinen, and Antti Kerminen.\nA linear non-\nGaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7\n(Oct):2003–2030, 2006.\nRicardo Silva and Shohei Shimizu. Learning instrumental variables with structural and non-\ngaussianity assumptions. Journal of Machine Learning Research, 18(120):1–49, 2017.\nRahul Singh, Maneesh Sahani, and Arthur Gretton. Kernel instrumental variable regression.\nAdvances in Neural Information Processing Systems, 32, 2019.\nTea Skaaby, Lise Lotte Nystrup Husemoen, Torben Martinussen, Jacob P Thyssen, Michael\nMelgaard, Betina Heinsbæk Thuesen, Charlotta Pisinger, Torben Jørgensen, Jeanne D\nJohansen, Torkil Menn´e, et al. Vitamin d status, ﬁlaggrin genotype, and cardiovascular\nrisk factors: a mendelian randomization approach. PloS one, 8(2):e57647, 2013.\nVP Skitovitch. On a property of the normal distribution. DAN SSSR, 89:217–219, 1953.\nPeter Spirtes. Calculation of entailed rank constraints in partially non-linear and cyclic\nmodels.\nIn Proceedings of the Twenty-Ninth Conference on Uncertainty in Artiﬁcial\nIntelligence, pages 606–615. AUAI Press, 2013.\nPeter Spirtes and Kun Zhang. Causal discovery and inference: concepts and recent method-\nological advances. In Applied informatics, volume 3, pages 1–28. SpringerOpen, 2016.\n36\n\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nPeter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search.\nMIT press, 2000.\nSeth Sullivant, Kelli Talaska, Jan Draisma, et al. Trek separation for gaussian graphical\nmodels. The Annals of Statistics, 38(3):1665–1685, 2010.\nMaarten J Voors, Eleonora E M Nillesen, Philip Verwimp, Erwin H Bulte, Robert Lensink,\nand Daan P Van Soest. Violent conﬂict and behavior: a ﬁeld experiment in burundi.\nAmerican Economic Review, 102(2):941–964, 2012.\nLinbo Wang, James M Robins, and Thomas S Richardson. On falsiﬁcation of the binary\ninstrumental variable model. Biometrika, 104(1):229–236, 2017.\nFrank Windmeijer, Helmut Farbmacher, Neil Davies, and George Davey Smith. On the use\nof the lasso for instrumental variables estimation with some invalid instruments. Journal\nof the American Statistical Association, 114(527):1339–1350, 2019.\nFrank Windmeijer, Xiaoran Liang, Fernando P Hartwig, and Jack Bowden. The conﬁdence\ninterval method for selecting valid instrumental variables. Journal of the Royal Statistical\nSociety: Series B (Statistical Methodology), 83(4):752–776, 2021.\nAnpeng Wu, Kun Kuang, Bo Li, and Fei Wu. Instrumental variable regression with con-\nfounder balancing. In International Conference on Machine Learning, pages 24056–24075.\nPMLR, 2022.\nFeng Xie, Yangbo He, Zhi Geng, Zhengming Chen, Ru Hou, and Kun Zhang. Testability of\ninstrumental variables in linear non-gaussian acyclic causal models. Entropy, 24(4):512,\n2022.\nQinyi Zhang, Sarah Filippi, Arthur Gretton, and Dino Sejdinovic. Large-scale kernel meth-\nods for independence testing. Statistics and Computing, 28(1):113–130, 2018.\n37",
    "pdf_filename": "Testability_of_Instrumental_Variables_in_Additive_Nonlinear,_Non-Constant_Effects_Models.pdf"
}