{
    "title": "Testability of Instrumental Variables in Additive Nonlinear,",
    "abstract": "We addressthe issue ofthe testabilityofinstrumentalvariablesderivedfromobservational data. Most existing testable implications are centered on scenarios where the treatment is a discrete variable, e.g., instrumental inequality (Pearl, 1995), or where the effect is assumed to be constant, e.g., instrumental variables condition based on the principle of independent mechanisms (Burauel, 2023). However, treatments can often be continuous variables, such as drug dosages or nutritional content levels, and non-constant effects may occur in many real-world scenarios. In this paper, we consider an additive nonlinear, non- constant effects model with unmeasured confounders, in which treatments can be either discreteorcontinuous,andproposeanAuxiliary-basedIndependenceTest(AIT)condition to test whether a variable is a valid instrument. We first show that if the candidate instrumentis valid,thenthe AIT conditionholds. Moreover,we illustratethe implications of the AIT condition and demonstrate that, in certain conditions, AIT conditions are necessary and sufficient to detect all invalid IVs. We also extend the AIT condition to include covariates and introduce a practical testing algorithm. Experimental results on bothsyntheticandthreedifferentreal-worlddatasetsshowtheeffectivenessofourproposed condition. ∗. Equalcontribution †. Corresponding author ©2022AuthorOneandAuthorTwo. License: CC-BY4.0,seehttps://creativecommons.org/licenses/by/4.0/. 4202 voN 91 ]EM.tats[ 1v48121.1142:viXra",
    "body": "Testability of Instrumental Variables in Additive Nonlinear,\nNon-Constant Effects Models\nXichen Guo∗ guoxichen0@gmail.com\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nZheng Li∗ zhengli0060@gmail.com\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nBiwei Huang bih007@ucsd.edu\nHalicioglu Data Science Institute (HDSI), University of California San Diego\nLa Jolla, San Diego, California, 92093, USA\nYan Zeng yanazeng013@btbu.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nZhi Geng zhigeng@pku.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nSchool of Mathematical Sciences, Peking University\nBeijing, 100871, China\nFeng Xie † fengxie@btbu.edu.cn\nDepartment of Applied Statistics, Beijing Technology and Business University\nBeijing, 102488, China\nAbstract\nWe addressthe issue ofthe testabilityofinstrumentalvariablesderivedfromobservational\ndata. Most existing testable implications are centered on scenarios where the treatment\nis a discrete variable, e.g., instrumental inequality (Pearl, 1995), or where the effect is\nassumed to be constant, e.g., instrumental variables condition based on the principle of\nindependent mechanisms (Burauel, 2023). However, treatments can often be continuous\nvariables, such as drug dosages or nutritional content levels, and non-constant effects may\noccur in many real-world scenarios. In this paper, we consider an additive nonlinear, non-\nconstant effects model with unmeasured confounders, in which treatments can be either\ndiscreteorcontinuous,andproposeanAuxiliary-basedIndependenceTest(AIT)condition\nto test whether a variable is a valid instrument. We first show that if the candidate\ninstrumentis valid,thenthe AIT conditionholds. Moreover,we illustratethe implications\nof the AIT condition and demonstrate that, in certain conditions, AIT conditions are\nnecessary and sufficient to detect all invalid IVs. We also extend the AIT condition to\ninclude covariates and introduce a practical testing algorithm. Experimental results on\nbothsyntheticandthreedifferentreal-worlddatasetsshowtheeffectivenessofourproposed\ncondition.\n∗. Equalcontribution\n†. Corresponding author\n©2022AuthorOneandAuthorTwo.\nLicense: CC-BY4.0,seehttps://creativecommons.org/licenses/by/4.0/.\n4202\nvoN\n91\n]EM.tats[\n1v48121.1142:viXra\nGuo, Li, Huang, Zeng, Geng, and Xie\nKeywords: instrumental variable; testability; unmeasured confounders; non-constant\neffects; causal graphical models\n1 Introduction\nEstimating causal effects from observational data is a fundamental task in understanding\nthe underlying relationships between variables. The instrumental variables (IV) model is\na well-established method for estimating the causal effect of a treatment (exposure) X\non an outcome Y in the presence of latent confounding and has been used in a range of\nfields, such as economics (Imbens, 2014; Imbens and Rubin, 2015), sociology (Pearl, 2009;\nSpirtes et al., 2000), epidemiology (Hern´an and Robins, 2006; Baiocchi et al., 2014), and\nartificialintelligence(Chen et al.,2022;Wu et al.,2022). Generallyspeaking,givenacausal\nrelationship X → Y, the valid IV Z is required to satisfy the following three conditions:\nC1. Z is related to the treatment (relevance), C2. Z is independent of the unmeasured\nconfounders that affect the treatment and outcome (exogeneity), and C3. Z has no direct\npath to the outcome (exclusion restriction). Figure 1 illustrates the graphical criteria of\nthe IV model, where Z is a valid IV relative to X → Y in the subgraph (a).\nU U U\nZ X Y Z X Y Z X Y\n(a) Valid IV model (b) IV model that violates C2 (c) IV model that violates C3\nFigure 1: GraphicalillustrationofIVmodels,whereUisthesetofunmeasuredconfounders.\n(a) Z is a valid IV. (b) Z is an invalid IV due to the edge U → Z (Violate C2).\n(c) Z is an invalid IV due to the edge Z → Y (Violate C3).\nDue to the presence of unmeasured confounders U, determining which variable serve\nas a valid IV is not always straightforward based solely on observational data, and often\nrequires domain knowledge. A classic test for IV model is the Durbin-Wu-Hausman test\n(Nakamura and Nakamura, 1981). Given asubsetof valid IVs, itcan identify whetherother\npotential candidates are also valid IVs. However, it does not guide how to find the initial\nset of valid IVs. Meanwhile, given an invalid IV, it may not consistently identify the correct\ncausal effect (Bound et al., 1995; Chu et al., 2001). Thus, it is vital to develop statistical\nmethods for selecting IVs solely from observational data.\nIt is not feasible to ascertain the validity of IVs solely based on the joint distribution\nof observed variables, without incorporating additional assumptions (Pearl, 2009). Pearl\n(1995)introduced a seminal necessary criterion known as the instrumental inequality, which\nacts as a critical test for identifying potential IVs in models featuring discrete variables.\nBuilding on this groundwork, subsequent research by Manski (2003); Palmer et al. (2011);\nKitagawa (2015); Wang et al. (2017) broadened the scope, exploring the applicability and\nlimitations of IV validity tests across diverse scenarios. A notable advancement was made\nby K´edagni and Mourifi´e (2020), who formulated a more encompassing set of criteria, the\ngeneralized instrumental inequalities. These criteria cater to scenarios with discrete treat-\n2\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nment variables, removing constraints of the type of data on the IV and outcome variables\nand offering a robust framework to challenge the exogeneity condition. The above methods\nuse the idea that if the IV is independent of the confounders and exclusion restriction (C3)\nholds, then changes in the IV should not have a significant impact on the outcome vari-\nable without altering the treatment variable, because the treatment variable mediates the\ninfluenceof the instrumental variable on the outcome variable. However, these methods fail\nto work when treatment is a continuous variable. In reality, one may often be concerned\naboutthecausaleffectofthecontinuoustreatmentontheoutcome; seeSkaaby et al.(2013);\nMartinussen et al. (2019).\nSeveral contributions have been made to address continuous treatment settings under\ncertain assumptions. In an additive linear, constant effects (ALICE) model, Kang et al.\n(2016); Bowden et al. (2016), and Windmeijer et al. (2019) have shown that if we assume\nmore than half of the variables are valid IVs in the potential IVs (known as the majority\nrule), we may identify the valid IVs solely from observed data. Later, Hartwig et al. (2017);\nGuo et al. (2018); Windmeijer et al. (2021) relaxed the majority rule and assumed that the\nnumber of valid IVs is larger than any number of invalid IVs with the same ratio estimator\nlimit (known as the plurality rule). They demonstrated that it is still possible to identify\nvalidIVsunderthepluralityrule. AnotherinterestingworkbySilva and Shimizu(2017)pro-\nposedtheIV-TETRADalgorithm, whichusestheso-called Trekconditions(Sullivant et al.,\n2010; Spirtes, 2013) for selecting a valid IV set. This method requires at least two or more\nvalid IVs in the system. However, although these methods have been used in a range of\nfields, they may fail to test whether a single IV is valid.\nRecently, Xie et al. (2022) have demonstrated that a single IV imposes specific con-\nstraints within the linear non-Gaussian acyclic causal model. However, their method as-\nsumes that all noise terms are non-Gaussian and that the effects remain constant. More\nrecently, Burauel (2023) have introduced a novel validity condition for Instrumental Vari-\nables based on the Principle of IndependentMechanisms, termed IV-PIM, within the linear\nIV framework. This condition is particularly notable as it applies to both continuous and\ndiscrete treatment variables. Nevertheless, its applicability is constrained by the presence\nof covariates, making it unsuitable when no covariates are available. Additionally, the\ncondition is limited to scenarios with constant treatment effects.\nPearl (1995) conjectured that the validity of an instrument cannot be tested when deal-\ning with continuous treatment variables without additional assumptions, a theory recently\nconfirmed by Gunsilius (2021). Unlike the existing work that focuses on the parametric\nlinear constant effects model, we consider IV validity in a more challenging additive non-\nparametricmodel,theAdditiveNonlInear,Non-ConstantEffects(ANINCE)Model. Rather\nsurprisingly, although a single IV is in general not fully testable within the ANINCE model,\nwe will show that a single variable Z, being a valid IV relative to X → Y, imposes specific\nconstraints in the ANINCE model. Specifically, we make the following contributions:\n1. We introduce a necessary condition, termed the Auxiliary-based Independence Test\n(AIT) condition, for detecting a single variable that cannot serve as an IV within\nthe ANINCE model. This condition is applicable to scenarios involving non-constant\ncausal effects and both discrete and continuous treatment.\n3\nGuo, Li, Huang, Zeng, Geng, and Xie\n2. We further provide the necessary and sufficient conditions for detecting all invalid IVs\nusing the AIT condition under the ANINCE model. Specifically, we show that, under\nthe partial non-Gaussianity assumption (Assumption 1), all observable violations of\nthe IV exogeneity condition can be identified in the linear, constant effects model.\nAdditionally, under the algebraic equation condition assumption (Assumption 2), we\ncandetectinvalidIVsresultingfromviolations ofeitherexogeneity ortheexclusionre-\nstriction inthe ANINCE model. We also presenttwo notable types of non-identifiable\ninvalid IVs (See Corollaries 1 ∼ 3), along with intuitive explanations for each.\n3. We present a practical implementation of the AIT condition test that accounts for the\npresence of covariates with finite data. We demonstrate the efficacy and applicability\noftheproposedapproachonbothsyntheticandthreereal-worlddatasetswithdifferent\nscenarios.\nThe rest of this paper is organized as follows. In Section 2, we introduce notations, the\nadditive non-parametric IV model, and the ANINCE model. In Section 3, we formulate\nthe AIT condition for the single IV. We show the AIT condition is a necessary condition\nfor IV validity in the ANINCE model. We discuss the implications of AIT condition in the\nlinear, constant effects model and the nonlinear, non-constant effects model, respectively.\nWe showthat, underadditionalassumptions,theAITcondition isanecessaryandsufficient\ncondition for IVvalidity. InSection 4, we addressthe practical scenario with covariates and\nprovide the AIT Condition algorithm to test the validity of IV. We present the efficacy and\napplicability of our method on both synthetic and three real-world datasets which contain\ncontinuous and discrete data in Section 5. Conclusions are given in Section 6.\n2 Preliminaries\n2.1 Notations\nOur research is conducted within the framework of causal graphical models as elaborated\nby Pearl (2009) and Spirtes et al. (2000). Specifically, we represent causal relationships\nusing the directed acyclic graph (DAG), denoted as G, where nodes represent variables and\ndirected edges (arrows) indicate causal links between those variables. Sets of variables are\nrepresented in bold, and individual variables and symbols for graphs are in italics. We use\n“instrumental variable (IV)” and “instrument” interchangeably. The main symbols used in\nthis paper are summarized in Table 1.\n2.2 Additive Non-Parametric Instrumental Variable Model\nTheinstrumentalvariableapproachoffersastrategy forinferringthecausaleffectofinterest\nin the presence of unmeasured confounders (Bowden and Turkington, 1990; Angrist et al.,\n1996; Pearl, 2009; Imbens and Rubin, 2015). Given a causal relationship X → Y, a valid\nIV Z is required to satisfy the following three conditions:\nC1. (Relevance). Z has directly affect the treatment X;\nC2. (Exogeneity or Randomness). Z isindependentof theunmeasuredconfoundersU;\nC3. (Exclusion Restriction). Z does not directly affect the outcome Y.\n4\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nSymbol Description\nG A directed acyclic graph\nX Treatment (exposure)\nY Outcome\nZ A candidate (potential) instrument\nU The latent (unmeasured) confounders\nW Covariates\nZ The residual of Z after regressing on covariates W\nIV Instrumental Variable\nA⊥⊥B|C A is statistically independent of B given C\nA⊥6⊥B|C A is statistically dependent on B given C\n|W| The number of variables in set W\nf(X,Z) The causal effect of X and Z on Y\nfbias(X,Z) The bias between estimate causaleffect of X on Y and ground-truth causal\ne effect of (X,Z) on Y\nε The noise term of a variable\n∗\nϕ (U) The effect of the latent variables U on the observed variables\n∗\ng (Z) The effect of the instrument variable Z on the other observed variables\n∗\nR The field of real numbers\nR→R A mapping from the real numbers to the real numbers\nI(∗) The indicator function\nE(X) The expected value of random variable X\n∂2Y\nThe second-order partial derivative of Y with respect to X and Z\n∂X∂Z\nAX→Y||Z (A) The auxiliaryvariableofcausalrelationshipX →Y relativetoZ. We often\ndrop the subscript X →Y||Z when there is no ambiguity in this paper\nK-test method The Kitagawa’s method from Kitagawa (2015)\nIV-PIM The Burauel’s method from Burauel (2023)\nmethod\nTable 1: The list of main symbols used in this paper\nDefinition 1 A random variable Z is a valid IV for causal relationship X → Y if the above\nthree conditions C1 ∼ C3 are satisfied.\nWe here consider the additive non-parametric IV model presented in Newey and Powell\n(2003), which, for a valid IV Z, it can be expressed as follows 1:\nX = g(Z)+ϕ (U)+ε ,\nX X\nδ\n| {z } (1)\nY = f(X)+ϕ (U)+ε ,\nY Y\nǫ\n| {z }\nwhere E[ϕ (U)+ε |Z]= 0, and the noise terms ε and ε are statistically independent.\nY Y X Y\nRemark 1 Newey and Powell (2003) have shown that, given a valid IV Z, the causal effect\nf(·) of interest in the above model in Equation (1) can be consistently estimated if the\n1. We here slightly modified the model from Newey and Powell (2003) to explicitly represent the unmea-\nsured confounders for subsequentanalysis.\n5\nGuo, Li, Huang, Zeng, Geng, and Xie\ncompleteness of the conditional expectation of functions of X conditional Z is satisfied.\nNote that the completeness is generic, in the sense that it holds for “most ” s(X|Z), if it\nholds for one (Andrews, 2017; Newey, 2013). Hence, in the remainder of the paper, we will\nassume completeness holds when using the additive non-parametric IV model for estimation,\nwithout explicitly stating it each time.\n2.3 Additive Nonlinear, Non-Constant Effects Model\nWithout loss of generality, we assume that all variables have a zero mean (otherwise can\nbe centered) and that no covariates are present for simplicity. In Section 4, we address the\npracticalscenariowherecovariates areincluded. Inthispaper,wefocusourattention onthe\nAdditive NonlInear, Non-Constant Effects (ANINCE) Model. Specifically, the generation\nprocess satisfies the following structural causal model:\nX = g(Z)+ϕ (U)+ε ,\nX X\n(2)\nY = f(X,Z)+ϕ (U)+ε ,\nY Y\nwhere f(·) denotes the true, unknown causal effect of interest, and g(·), f(·) and ϕ (·) are\n∗\nsmooth/deterministic functions from R → R. The noise terms ε and ε are statistically\nX Y\nindependent. Note that Z and U may be dependent, which indicates that the exogeneity\ncondition (C2) is violated, andthe non-zero f(·,Z)function indicates that Z directly affects\nthe outcome Y, implies that the exclusion restriction condition (C3) is violated.\nA special case of the ANINCE model is the additive linear, constant effects model (AL-\nICE), where functions g(·), f(·), and ϕ (·) are linear functions, which have been extensively\n∗\nstudiedinworkssuchasthosebyBowden et al.(2015);Kang et al.(2016);Silva and Shimizu\n(2017); Windmeijer et al. (2021). Compared to these works, we investigate the testability\nof IVina morechallenging scenario, whereg(·), f(·), andϕ (·) may benon-linear functions.\n∗\nAdditionally, we focus on the testability of a single valid IV, whereas previous works have\nfocused on the testability of a set of IVs (including at least two or more valid IVs among\nthe candidate variables).\nOur Goal. The goal of this paper is to determine, from the observed dataset {X,Y,Z}\nsatisfying an ANINCE model, whether Z is related to X (i.e., relevance condition), Z\nis exogenous relative to (X,Y) (i.e., exogeneity condition) and Z does not directly affect\noutcome Y (i.e., exclusion restriction condition). Note that the first condition relevance,\ncan be easily checked by the independent test because Z and X are observed variables.\nTherefore, we focus on the last two conditions of IV Z. In summary, we aim to provide\na new necessary condition to detect whether a variable is a valid IV and investigate the\nnecessary and sufficient conditions under which all invalid IVs can be detected.\nRemark 2 Existing approaches have attempted to detect the violations of exogeneity of\na single IV within the discrete variable setting. Representative methods along this line in-\nclude instrumentalinequality (Pearl,1995), anditsextensions(Manski,2003;Palmer et al.,\n2011; Kitagawa, 2015; Wang et al., 2017; K´edagni and Mourifi´e, 2020). Unlike existing\nwork, we focus on settings with continuous variables. Pearl (1995) already conjectured that\ninstrument validity is not testable in a continuous variable setting without additional as-\nsumptions, a theory recently confirmed by Gunsilius (2021). The key difference to existing\n6\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nresearch considering instrumental variable models is that we introduce the additive function\nconstraints, allowing us to detect the invalid IVs when the treatment variable is continuous.\nMore recently, Burauel (2023) have proposed a testable IV condition for the continuous treat-\nment setting, based on the Principle of Independent Mechanisms (Janzing and Sch¨olkopf,\n2018). However, this condition is restricted to linear models and heavily depends on the\ndimensionality of the covariates.\n3 AIT Condition and Its Implications in ANINCE Models\nIn this section, we first formulate the Auxiliary-based Independence Test Condition (AIT\nCondition) and show that it is a necessary condition for evaluating IV validity. We further\npresent theoretical results regarding the implications of the AIT condition in the linear,\nconstant effects model and nonlinear, non-constant effects model.\n3.1 AIT Condition\nBelow, we give the AIT Condition, which defines the independent relationship between\nthe “Auxiliary variable” and candidate IV. Note that concepts to “auxiliary variable” have\nbeen developed to address different tasks (Drton and Richardson, 2004; Chen et al., 2017;\nCai et al., 2019), but our formalization is different from theirs (See Equation (3)). To the\nbest of our knowledge, it has not been realized that the independence property involving\nsuch an auxiliary variable reflects the validity of the IV in the ANINCE model.\nDefinition 2 (AIT Condition) Suppose treatment X, outcome Y, and candidate IV Z\nare nodes inacausal graph G. Definethe auxiliary variable of the causal relationship X → Y\nrelative to Z, as\nA := Y −h(X), (3)\nX→Y||Z\nwhere h(·) satisfies E[A |Z] = 0 and h(·) 6= 0. We say that {X,Y||Z} follows the\nX→Y||Z\nAIT condition if and only if A is independent from Z.\nX→Y||Z\nFor the sake of conciseness, we often drop the subscript X → Y||Z from A when\nX→Y||Z\nthere is no ambiguity. The following theorem shows the testability of an IV in light of the\nAIT condition in an ANINCE model.\nTheorem 1 (Necessary Condition for IV) LetX, Y, andZ bethetreatment, outcome,\nand candidate IV in an ANINCE model, respectively. Suppose that X, Y, and Z are corre-\nlated and that the sample size n → ∞ holds. Further, suppose that the probability densities\np(ε ) and p(ε ) are twice differentiable, and positive on (−∞,∞). If Z is a valid IV\nU Z\nrelative to X → Y, then {X,Y||Z} always satisfies the AIT condition.\nProof If Z is a valid IV relative to X → Y, then the ANINCE model can be rephrased as\nadditive non-parametric IV models (Equation (1)). Following the consistent IV estimation\nmethodviatheconditionalmean model(e.g., Newey and Powell (2003);Singh et al. (2019);\nBennett et al. (2019)), h(·) can represent the unbiased causal effect f(·) of X on Y as the\nsample size n → ∞, implying that h(·) = f(·). Thus, we have auxiliary variable\nA = Y −h(X) = Y −f(X)= ǫ = ϕ (U)+ε . (4)\nX→Y||Z Y Y\n7\nGuo, Li, Huang, Zeng, Geng, and Xie\nBelow, we prove this theorem using the linear separability of the logarithm of the joint\ndensity of independentvariables, which states the fact that for a set of independentrandom\nvariables whose joint density is twice differentiable, the Hessian of the logarithm of their\ndensity is diagonal everywhere from Lin (1997) (See Theorem 5 in Appendix A for further\ndetails).\nCombiningZ = ε withEquation(4),weobservethatthetransformationfrom(A ,Z)\nZ X→Y||Z\nto (ε ,ε ) is:\nU Z\nε = ϕ −1(A −ε ),\nU Y X→Y||Z Y\n(5)\nε = Z.\nZ\nLet|J|denotetheJacobianmatrixofthistransformation,givingby|J| = ∂εU·∂εZ−∂εU·∂εZ.\n∂A ∂Z ∂Z ∂A\nDefinep(A ,Z)asthejointdensityof(A ,Z). Then,wehavep(A ,Z)=\nX→Y||Z X→Y||Z X→Y||Z\np(ε ,ε )|J| = p(ε )·p(ε )·|J|. Let K , logp(ε ), K , logp(ε ), and K , log(|J|).\nU Z U Z 1 U 2 Z 3\nSince the densities p(ε ) and p(ε ) are twice differentiable and positive on (−∞,∞), we\nU Z\nhave\nlogp(A ,Z)= log(p(ε )·p(ε )·|J|),\nX→Y||Z U Z\n(6)\n= logp(ε )+logp(ε )+log(|J|) = K +K +K .\nU Z 1 2 3\nOne can find the (1, 2)-th entry of the Hessian matrix of logp(A ,Z):\nX→Y||Z\n∂2logp(A ,Z) ∂2(K +K +K ) ∂(K′∂εU +K′∂εZ +K′∂|J| )\nX→Y||Z = 1 2 3 = 1 ∂Z 2 ∂Z 3 ∂Z\n∂A ∂Z ∂A ∂Z ∂A\nX→Y||Z X→Y||Z\n= K′′∂ε U · ∂ε U +K′ ∂2ε U +K′′∂ε Z · ∂ε Z (7)\n1 ∂A ∂Z 1∂A∂Z 2 ∂A ∂Z\n∂2ε ∂|J| ∂|J| ∂2|J|\n+K′ Z +K′′ · +K′ .\n2∂A∂Z 3 ∂A ∂Z 3∂A∂Z\nFor a valid IV Z, the following conditions hold: ∂εU = 0, ∂εZ = 0, ∂|J| = 0, and ∂2|J| = 0.\n∂Z ∂A ∂Z ∂A∂Z\nConsequently, the second-order partial derivative\n∂2logp(AX→Y||Z,Z)\n= 0, which implies that\n∂AX→Y||Z∂Z\nA and Z are statistically independent. In other words, {X,Y||Z} satisfies the AIT\nX→Y||Z\ncondition.\nTheorem 1 means that if {X,Y||Z} violates the AIT condition, then Z is an invalid IV\nrelative to X → Y. Otherwise, Z may or may not be valid.\n3.2 Implications of AIT Condition in Additive Linear, Constant Effects\nModels\nIn this section, we focus our attention on a special type of ANINCE model, the linear, con-\nstant effects model, which has been widely studied (Bowden et al., 2015; Kang et al., 2016;\nSilva and Shimizu, 2017; Windmeijer et al., 2021). Specially, we assume that each node in\nthegraphG representsalinearstructuralequationmodel,i.e.,V = Σ α V +ε ,i =\ni Vj∈pa(Vi) ij j Vi\n1,2,...,n, where the noise terms ε ,...,ε are independent of each other, and α is the\nV1 Vn ij\ndirect effect of V → V . Hence, the ANINCE model in Equation (2) can be expressed as\nj i\nfollows:\nX = τZ +ρU +ε , Y = βX +νZ +κU +ε , (8)\nX Y\n8\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nwhereZ = γU+ε . Whenγ = 0(satisfyingtheexogeneity condition)andν = 0(satisfying\nZ\nthe exclusion restriction condition), Z qualifies as a valid IV relative to X → Y. Below, we\nshow the implications of the AIT condition in this model.\nMotivating Examples: Firstly, we illustrate with two simple examples that while a\nvalid IV does not impose any restrictions on the joint marginal distribution of the observed\nvariables within the linear Gaussian model, it does impose certain constraints in the linear\npartial non-Gaussian model, which can be identified using AIT condition. Consider the\ncausal graph in Figure 1(b), where Z is an invalid IV for X → Y, as it violates the\nexogeneity condition. Let N(0,1) denote the standard normal distribution, and Exp(0.5)\ndenote the exponential distribution with a rate parameter of 0.5. Suppose the generating\nmechanisms of these models are as follows:\n• Linear Gaussian model. U = ε , Z = 2U + ε , X = 1.5Z + 0.8U + ε , Y =\nU Z X\nX +3.5U +ε , and ε ,ε ,ε ,ε ∼ N(0,1).\nY U Z X Y\n• Linear partial non-Gaussian model. U = ε , Z = 2U +ε , X = 1.5Z +0.8U +ε ,\nU Z X\nY =X +3.5U +ε , ε ∼ Exp(0.5), and ε ,ε ,ε ∼ N(0,1).\nY U Z X Y\n8\n30\n4\n20\n0\n10\n−4\n0\n−8\n−4 0 4 −4 0 4\nAuxiliary−variable A Auxiliary−variable A\n(a) Linear Gaussian Model (b) Linear Partial Non-Gaussian Model\nFigure 2: ScatterplotsofCandidateIVZ andAuxiliary-variableAunderthelinearmodels.\n(a)AllnoisetermsfollowGaussiandistributions. (b)Somenoisetermsfollownon-\nGaussian distributions.\nThedifference between theabove two models lies in thenoise termε ; thefirstfollows a\nU\nGaussian distribution, while the second follows an exponential distribution (non-Gaussian\ndistribution). Figure 2 shows the scatter plots of A versus the invalid IV Z for\nX→Y||Z\ntwo models. Interestingly, we find that, in the linear Gaussian model, A and Z are\nX→Y||Z\nstatistically independent(satisfyingAITcondition),whileinthelinearpartialnon-Gaussian\nmodel, A and Z are statistically dependent (violating AIT condition). These results\nX→Y||Z\nsuggest that non-Gaussianity is beneficial for identifying the invalid IV.\nThe following Propositions 1 and 2 formalize the phenomena discussed above.\nProposition 1 (Non-testability in Linear Gaussian Models) Let X, Y, and Z be\nthe treatment, outcome, and candidate IV in a linear model (Equation (8)), respectively.\nSuppose that X, Y, and Z are correlated and that the sample size n → ∞ holds. If all noise\nterms of variables follow Gaussian distributions, then regardless of whether Z is a valid IV\nrelative to X → Y or not, {X,Y||Z} always satisfies the AIT condition.\n9\nZ VI\netadidnaC\nZ\nVI\netadidnaC\nGuo, Li, Huang, Zeng, Geng, and Xie\nProof The proof of Proposition 1 is straightforward. Let Z represents any candidate\nIV, which may or may not be valid. By the definition of the AIT condition, we have\nE[A |Z] ≡ 0, regardless of the choice of h(·). This directly implies that the correla-\nX→Y||Z\ntion between A and Z is zero. In the linear Gaussian model, zero correlation implies\nX→Y||Z\nindependence (Bain and Engelhardt, 1992). Therefore, the condition E[A |Z] ≡ 0\nX→Y||Z\nimplies that A is independent of the candidate IV Z in the linear Gaussian model.\nX→Y||Z\nIn other words, {X,Y||Z} always satisfies the AIT condition.\nProposition 1 states that checking the AIT condition in a linear Gaussian causal model\n(second-order statistics) does not provide any useful information for identifying invalid IVs.\nBelow, we show that higher-order statistics 2 of noise terms enable us to identify certain\ntypes of invalid IVs that violate the exogeneity condition. Before presenting the result, we\ngive the key assumption.\nAssumption 1 (Partial Non-Gaussianity) Atleastoneofthefollowingconditions holds:\n(i) there exists at least one variable U ∈ U whose noise term follows a non-Gaussian dis-\nk\ntribution and cause Z; (ii) the noise term of Z follows a non-Gaussian distribution.\nAssumption 1 states the non-Gaussianity of data, which is expected to be widespread,\nas suggested by Cram´er Decomposition Theorem (Cram´er, 1962). Considerable works have\nalreadybeenbuiltonthisassumption(Shimizu et al.,2006;Salehkaleybar et al.,2020). For\nadditional references, see Spirtes and Zhang (2016); Shimizu (2022).\nWe now show that the AIT condition can access the validity of exogeneity condition in\nlinear models under Assumption 1.\nProposition 2 (Testability of Exogeneity in Linear Models) Let X, Y, and Z be\nthe treatment, outcome, and candidate IV in a linear model (Equation (8)), respectively.\nSuppose that X, Y, and Z are correlated and that the sample size n → ∞ holds. Further-\nmore, suppose that Assumption 1 holds. If Z violates the exogeneity condition, i.e., at least\none variable U ∈ U causes Z, then {X,Y||Z} violates the AIT condition.\nk\nProof Roughly speaking, if A shares common non-Gaussian noise terms with Z, by\nX→Y||Z\nthe Darmois–Skitovich theorem (Darmois, 1953; Skitovitch, 1953), A is statistically\nX→Y||Z\ndependent from Z. This implies that {X,Y||Z} violates the AIT condition. See Appendix\nA.1 for its complete proof.\nRemark 3 When all noise terms follow the non-Gaussian distributions, the linear partial\nnon-Gaussianmodelbecomesthewell-knownLinearNon-GaussianAcyclicModel(LiNGAM),\nwhich has been extensively studied (Shimizu et al., 2006; Salehkaleybar et al., 2020). Con-\nsequently, according to Proposition 2, an invalid IV that violates the exogeneity condition\nin LiNGAM can be detected in light of the AIT condition.\n2. Higher-orderstatisticsmeanbeyondthesecond-ordermomentsinstatistics,e.g.,skewness,kurtosis,etc.,\nof thedata.\n10\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nProposition 2 states that we can detect an invalid IV that violates exogeneity condi-\ntion using the AIT condition based on the observational data in the linear model under\nAssumption 1. A natural question that arises is whether we can detect IVs that violate the\nexclusion restriction condition within the same framework. Unfortunately, in practice, we\ncannot detect an invalid IV that solely violates the exclusion restriction condition in the\nlinear model, as shown in the following example.\nExample 1 Let’sconsider the causalstructure illustrated inFigure 1(a), where Z isavalid\nIV. We assume the following relationship: Z = ε , X = τZ+ρU+ε , Y = βX+κU+ε .\nZ X Y\nNext, we demonstrate how to construct another causal structure as shown in Figure 1 (c),\nwhere Z becomes an invalid IV (violating solely exlcusion restriction condition). Specifically,\nlet β′ = β − ν, Z′ = Z, X′ = X, and Y′ = β′X′ +νZ′ +κU +ε + ν(ρU +ε ) = Y.\nτ Y τ X\nThus, (X,Y,Z) has the same distribution as (X′,Y′,Z′). This implies that a variable being\nan instrument imposes no constraints on the joint marginal distribution of the observed\nvariables. The same result is also discussed in Section 3 of Chu et al. (2001).\nThe following proposition states the above phenomenon in the linear model.\nProposition 3 (Non-testability of Exclusion Restriction in Linear Models) LetX,\nY, and Z be the treatment, outcome, and candidate IV in a linear model (Equation (8)),\nrespectively. Suppose that X, Y, and Z are correlated and that the sample size n → ∞\nholds. If Z satisfies the exogeneity condition, regardless of whether Z violates the exclusion\nrestriction condition or not, then {X,Y||Z} always satisfies the AIT condition.\nProof This proof is straightforward. The auxiliary variable A shares no common\nX→Y||Z\nnoise terms with candidate IV Z, whether the noise terms are Gaussian or non-Gaussian.\nBy the Darmois-Skitovich theorem (Darmois, 1953; Skitovitch, 1953), A is statisti-\nX→Y||Z\ncally independent from Z. This implies that {X,Y||Z} always satisfies the AIT condition.\nSee Appendix A.2 for its complete proof.\nBased on Theorem 1 and Propositions 1 ∼ 3, we derive the following theorem, which\nprovides a necessary and sufficient condition for detecting all invalid IVs within a linear\ncausal model.\nTheorem 2 (Necessary and Sufficient Conditions in Linear Models) LetX, Y, and\nZ be the treatment, outcome, and candidate IV in a linear model (Equation (8)), respec-\ntively. Suppose that X, Y, and Z are correlated and that the sample size n → ∞ holds.\nFurthermore, suppose that Assumption 1 holds. {X,Y||Z} violates the AIT condition if\nand only if the candidate IV Z is invalid due to a violation of the exogeneity condition.\nProof See Appendix A.3 for its proof.\nThis theorem states that the AIT condition is necessary and sufficient to detect the\nvariable violations of the exogeneity condition when Assumption 1 holds.\n11\nGuo, Li, Huang, Zeng, Geng, and Xie\n3.3 Implications of AIT Condition in Additive Nonlinear, Non-Constant\nEffects Models\nIn this section, we investigate the implications of the AIT condition on the ANINCE model.\nBefore giving our main results, we first show a simple example to show that nonlinearity is\nbeneficial in identifying the invalid IV.\nA Motivating Example: Continue to consider the causal graph in Figure 1 (b),\nwhere Z serves as an invalid IV for the causal relationship X → Y, violating the exogeneity\ncondition. Here, we modify the generation mechanism of the linear Gaussian model by\nintroducing a nonlinear function between U and Z, specifically as follows:\n• Partial Non-linear Gaussian model. U = ε , Z = eU +ε , X = 1.5Z +0.8U +ε ,\nU Z X\nY =X +3.5U +ε , and ε ,ε ,ε ,ε ∼N(0,1).\nY U Z X Y\n30\n20\n10\n0\n−15 −10 −5 0 5\nAuxiliary−variable A\nFigure 3: Scatter plot of Candidate IV Z and Auxiliary-variable A when all noise terms\nfollow Gaussian distribution in the partially non-linear invalid IV model.\nFigure 3 presents the scatter plots of A versus the candidate IV Z in the partial\nX→Y||Z\nnon-linear Gaussian model. Compared to the linear Gaussian model, we transformed the\nfunctional relationship between U and Z from a linear function (2U) to an exponential\nfunction (eU). Interestingly, in the partial non-linear Gaussian model, A and Z are\nX→Y||Z\nstatistically dependent (violating AIT condition). Note that Proposition 1 shows that the\nAIT condition is always satisfied in the linear Gaussian model. These findings suggest that\nnonlinearity is beneficial in accessing the validity of exogeneity condition.\nWe now investigate the conditions under which the invalid IV can be detected in terms\nof AIT condition. It is noteworthy that the ANINCE model (Equation (2)) is flexible\nas functions g, f, ϕ , and ϕ might be any unknown functions. Consequently, without\nX Y\nimposing further parametric assumptions, it is impossible to determine the explicit forms\nof the estimated f and A . Hence, let h(·) be the estimated function, where h(·)\nX→Y||Z\nsatisfies E[Y −h(X)|Z] = 0 and h(·) 6= 0. According to the definition of the AIT condition,\nThe auxiliary variable A is given by:\nX→Y||Z\nA = Y −h(X) = f(X,Z)−h(X)+ϕ (U)+ε ,\nX→Y||Z Y Y\n(9)\ne\n| f bias{(zX,Z) }\n12\nZ\nVI\netadidnaC\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nwhere f (X,Z) = f(X,Z)−h(X). It is important to note that for a valid instrumental\nbias\nvariableeZ,f (X,Z) = 0. Forthesakeofconvenience, weoftenusef (X,Z)throughout\nbias bias\nthis paper. e e\nBelow, we give the key assumption regarding the second-order partial derivative in the\nnonlinear model.\nAssumption 2 (Algebraic Equation Condition) Define the algebraic equation condi-\ntion characterizing the second-order partial derivative below:\n∂2logp(A X→Y||Z,Z) ∂2(K 1+K 2+K 3)\n= 6= 0, (10)\n∂A ∂Z ∂A ∂Z\nX→Y||Z X→Y||Z\ni.e.,\n∂ε ∂ε ∂2ε ∂ε ∂ε ∂2ε ∂|J| ∂|J|\nK′′ U · U +K′ U +K′′ Z · Z +K′ Z +K′′ ·\n1 ∂A ∂Z 1∂A∂Z 2 ∂A ∂Z 2∂A∂Z 3 ∂A ∂Z\n(11)\n∂2|J|\n+K′ 6= 0,\n3∂A∂Z\nwhere A = f (X,Z)+ϕ (U)+ε , K = logp(ε ), K = logp(ε ), and K =\nX→Y||Z bias Y Y 1 U 2 Z 3\nlog|J|. Here, |J| reperesents the Jacobian matrix of the transformation from (A ,Z)\nX→Y||Z\nto (ε ,ε ).\nU Z\nRemark 4 Specifically, giving that the second and higher-order derivatives in the linear\nmodel are zero, the following holds:\n∂2εU\n= 0,\n∂2εZ\n= 0,\n∂|J|\n·\n∂|J|\n= 0, and\n∂2|J|\n= 0.\n∂A∂Z ∂A∂Z ∂A ∂Z ∂A∂Z\nTherefore, the algebraic equation condition can be expressed as ∂2logp(AX→Y||Z,Z) = K′′∂εU ·\n∂AX→Y||Z∂Z 1 ∂A\n∂εU +K′′∂εZ · ∂εZ 6= 0.\n∂Z 2 ∂A ∂Z\nAssumption 2 is a very natural condition that one expects to hold for detecting all invalid\nIVs in the ANINCE model. Assumption 2 says that the second-order partial derivative\nis non-zero. By leveraging the linear separability of the logarithm of the joint density of\nindependent variables (Lin, 1997), we obtain the auxiliary variable A is dependent\nX→Y||Z\non Z.\nProposition 4 (Testability of IV in ANINCE Models) LetX, Y, andZ bethe treat-\nment, outcome, and candidate IV in an ANINCE model, respectively. Suppose that X, Y,\nand Z are correlated and that the sample size n → ∞ holds. Furthermore, suppose that\nthe probability densities p(ε ) and p(ε ) are twice differentiable, and positive on (−∞,∞),\nU Z\nand Assumption 2 holds. If the candidate IV Z is invalid, then {X,Y||Z} violates the AIT\ncondition.\nProof See Appendix A.4 for its proof.\nThe proposition above shows that, under Assumption 2, the AIT condition can be used to\ndetectinvalidIVs. AlthoughitisnotobviouswhetherAssumption2(thealgebraicequation\ncondition) holds in general, some solutions under which the Assumption 2 is not hold are\nworth reporting here.\n13\nGuo, Li, Huang, Zeng, Geng, and Xie\nCorollary 1 If all noise terms follow the Gaussian distributions within the linear causal\nmodel, then Assumption 2 does not hold.\nProof See Appendix A.5 for its proof.\nCorollary 1 implies that the AIT condition is always satisfied in the linear Gaussian model,\nconsistent with the result of Proposition 1.\nCorollary 2 If the candidate IV Z solely violates the exclusion restriction condition within\nthe linear causal model, then Assumption 2 does not hold.\nProof See Appendix A.6 for its proof.\nCorollary 2 implies that the AIT condition is always satisfied in the linear model when\ncandidate IV Z satisfies the exogeneity condition, consistent with the result of Proposition\n3.\nCorollary 3 If the candidate IV Z solely violates the exclusion restriction condition and\nthe direct causal effect of Z → Y is a linear function of the direct causal effect of Z → X,\ni.e., g (Z)= a·g (Z)+b, where a and b are non-zero constants, then Assumption 2 does\nY X\nnot hold.\nProof See Appendix A.7 for its proof.\nCorollary 3 implies that the AIT condition is always satisfied when the candidate IV Z\nsatisfies exogeneity condition and the relationship of effect g (Z) = a · g (Z) + b holds\nY X\nin the ANINCE model. In the special case with the linear model, the above corollary\nbecomes Corollary 2. Intuitively speaking, the distribution of the invalid IV model, where\ncandidate IV Z solely violates the exclusion restriction condition, can be transformed into\nthe distribution of the valid IV model, as illustrated in Example 2.\nExample 2 Continue to consider the causal graph in Figure 1 (c), where Z is an invalid\nIV relative to X → Y. The generating mechanism is as follows:\nZ = ε , X = g (Z)+ϕ (U)+ε , Y = f(X)+g (Z)+ϕ (U)+ε , (12)\nZ X X X Y Y Y\nwhere g (Z) = a·g (Z)+b. We now construct another model based on the causal graph\nY X\nshown in Figure 1 (a), where Z is a valid IV relative to X → Y. Let Z′ = Z, X′ = X, and\nf′(X′)= f(X′)+a·g (Z′)+b. Furthermore, Y′ is expressed as Y′ = f′(X′)+ϕ (U)+ε =\nX Y Y\nf(X)+g (Z)+ϕ (U)+ε = Y. Hence, we conclude that the distribution of (Z,X,Y)\nY Y Y\nand (Z′,X′,Y′) are identical. Because we can solely observe the variables (Z,X,Y), it\nis impossible to determine from the distribution of (Z,X,Y) whether the data come from\nFigure 1 (a) or Figure 1 (c). In other words, we cannot ascertain whether Z is a valid IV\nor not.\nThe above example shows that if the direct causal effect of Z → Y is not a linear function\nof the direct causal effect of Z → X, we can identify invalid IVs that solely violate the\nexclusion restriction condition using the AIT condition. According to the above corollaries,\nnot all invalid IVs can be identified solely from the joint distribution of observational data.\nBelow, based on Theorem 1 and Proposition 4, we introduce the necessary and sufficient\nconditions for invalid IV in the additive nonlinear, non-constant effects model.\n14\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nTheorem 3 (Necessary and Sufficient Conditions for IV in ANINCE Models) Let\nX, Y, and Z be the treatment, outcome, and candidate IV in an ANINCE model (Equation\n(2)), respectively. Suppose that X, Y, and Z are correlated, and that the sample size n → ∞\nholds. Furthermore, suppose that the probability densities p(ε ) and p(ε ) are twice differ-\nU Z\nentiable, and positive on (−∞,∞), and Assumption 2 holds. {X,Y||Z} violates the AIT\ncondition if and only if the candidate IV Z is invalid due to the violation of at least one IV\nconditions.\nProof See Appendix A.8 for its proof.\nTheorem 3 outlines two scenarios where a candidate IV would be considered invalid: either\ntheIVdoesn’tmeettheexogeneity conditionoritviolatestheexclusionrestriction condition\nwithin a nonlinear model.\n4 Practical Implementation of AIT Condition\nIn this section, we discuss the practical implementation of the AIT condition. In Section\n4.1, we first address how to conduct the AIT condition when covariates are present. We\nthen present a method for applying the AIT condition to data with a limited sample size\nin Section 4.2.\n4.1 AIT Condition with Covariates\nIn practice, there are scenarios where covariates W are present. For instance, age may\ninfluence how the treatment method affects patient recovery speed. Therefore, we first\nextend the AIT condition from Definition 2 to account for the presence of covariates, as\nstated in the following definition.\nDefinition 3 (AIT Condition with Covariates) Suppose treatment X, outcome Y, co-\nvariates W, and candidate IV Z are nodes in a causal graph G. Define the auxiliary variable\nof the causal relationship X → Y relative to (Z,W), as\nA X→Y||(Z,W) := Y −h(X,W), (13)\nwhere h(·) satisfies E[A X→Y||(Z,W)|Z,W] = 0 and h(·) 6= 0. Define the residual of Z after\nregressing on W as:\nZ := Z −E[Z|W]. (14)\nWe say that {X,Y||(Z,W)} follows the AIT condition if and only if A X→Y||(Z,W) is inde-\npendent from Z.\nBased on Definition 3 and Theorem 1, we obtain the necessary condition for IV in the\npresence of covariates W, as described in the following corollary.\nCorollary 4 (Necessary Condition for IV with Covariates) Let X, Y, W, and Z\nbe the treatment, outcome, covariates, and candidate IV in an ANINCE model, respectively.\nSuppose that X, Y, W, and Z are correlated and that the sample size n → ∞ holds. Fur-\nthermore, suppose that the probability densities p(ε ) and p(ε ) are twice differentiable, and\nU Z\n15\nGuo, Li, Huang, Zeng, Geng, and Xie\npositive on (−∞,∞). If Z is a valid IV relative to X → Y given W, then {X,Y||(Z,W)}\nalways satisfies the AIT condition.\nProof See Appendix A.9 for its proof.\nCorollary 4 means that if {X,Y||(Z,W)} violates the AIT condition, then Z is an invalid\nIV relative to X → Y given W. Otherwise, Z may or may not be valid.\n4.2 AIT Condition with Finite Data\nBelow, we provide the practical implementation of AIT condition with finite data. For a\ncandidate IV Z, under the ANINCE model, we need to test the following hypothesis:\nH : Z is a valid IV, H :Z is an invalid IV. (15)\n0 1\nTo achieve this goal, we need to address the following two issues:\n• how can we compute the auxiliary variable A X→Y||(Z,W) using {X,Y,W,Z}?\n• how to test whether A X→Y||(Z,W) is statistical independence of Z?\nNext, we address the first issue. The intuitive idea is that we first use a standard IV\nestimator to estimate h(X,W), and then compute A X→Y||(Z,W) = Y −h(X,W). Note that\ngiven a valid IV, the estimated h(X,W) is exactly f(X,W) (Newey and Powell, 2003).\nOtherwise, given an invalid IV, the estimated h(X,W) is biased relative to the true model.\nTherearenowmanyIVestimatorsforAdditiveNon-ParametricIVModels(Guo and Small,\n2016; Singh et al., 2019; Bennett et al., 2019). Here, we adopt the control function IV esti-\nmator proposed by Guo and Small (2016), which is a two-stage approach. In the first stage,\nitregressesthetreatmentvariableX oncovariatesWandinstruments(Z,h (Z),...,h (Z))\n2 k\n(a known vector of linearly independent functions of Z), obtaining the predicted value Xˆ\nand the residual e = X − Xˆ. In the second stage, the outcome Y is regressed on the\n1\ntreatment X, covariates W, and the residual e from the first stage regression. The coeffi-\n1\ncients of the second stage regression are taken as the control function estimates. Note that\nnonlinear functions can be estimated using basis functions. In our experiments, we apply\npolynomial basis functions as a predefined set of linearly independent functions, leveraging\nthis control function method.\nWe now tackle the second issue. To check the statistical independence of A X→Y||(Z,W)\nand Z, we employ the Large-Scale HSIC Test, a Hilbert-Schmidt Independence Criterion\n(HSIC)-based test proposed by Zhang et al. (2018), which utilizes large-scale kernel approx-\nimations for independence testing. If the output p is less than the preset significance\nvalue\nlevel α, we reject the null hypothesis H , indicating that the candidate IV Z is invalid.\n0\nConversely, if we fail to reject the null hypothesis, it suggests that Z is a valid IV.\nBased on the above discussions, the complete AIT Condition test procedure is given\nin Algorithm 1. To allow for greater flexibility in the algorithm and considering that prior\nknowledge, such as a constant causal effect, may sometimes be available, we include a two-\nstageleastsquaresestimator suitableforlineareffects(Basmann,1957;Henckel et al.,2024)\nto estimate the causal effect (See Lines 2 ∼ 3). Note that if the covariates W have a causal\neffect on IV Z, we will use the random forest method to obtain the residual Z of IV Z (See\nLine 8).\n16\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nAlgorithm 1 AIT Condition\nInput: Observed dataset D = {X,Y,W,Z}, containing: treatment X, outcome Y, covari-\nates W, and candidate IV Z, and significance level α.\n1: Initialize: Result ← Do not reject H 0\n/* Step one: Estimate A X→Y||(Z,W) */\n2: if there is a constant effect between X and Y then\n3: h(X,W) ← Two-Stage Least Squares Estimator (X,Y,W,Z)\n4: else\n5: h(X,W) ← Control Function IV Estimator (X,Y,W,Z)\n6: end if\n7: A X→Y||(Z,W) ← Y −h(X,W)\n/* Step two: Test the AIT condition */\n8: Residual Z ← Random Forset Method (Z,W); set Z = Z if W = ∅\n9: p value ← Large-Scale HSIC Test(A X→Y||(Z,W),Z)\n10: if p value < α then\n11: Result ← Reject H 0\n12: return Result\n13: else\n14: return Result\n15: end if\nOutput: Result\n5 Experiments\nIn this section, we evaluated the performance of the proposed instrument validity AIT\ncondition using both synthetic data and three real-world datasets. All experiments were\nperformed with Intel 2.90 GHz and 2.89 GHz CPUs and 128 GB of memory. Our source\ncode is available from https://github.com/zhengli0060/AIT_Condition.\n5.1 Synthetic Data\nWe conducted simulation experiments from three perspectives. First, in Section 5.1.1, we\nverifiedthecorrectnessofourtheoreticalresults. Then,inSection5.1.2,wecomparedtheIV-\nPIM method proposed by Burauel (2023), which is designed for continuous treatments with\ncovariates. Finally, in Section 5.1.3, we compared the proposed method with Kitagawa’s\nmethod, abbreviated as the K-test method (Kitagawa, 2015), which is designed for discrete\ntreatments. In all experiments, we evaluated the performance of our method using the\nfollowing metrics:\n• Valid IVs Misidentification Ratio (Valid MR): the ratio of the number of valid\nIVs incorrectly identified in the output.\n• Invalid IVs Misidentification Ratio (Invalid MR): the ratio of the number of\ninvalid IVs incorrectly identified.\n17\nGuo, Li, Huang, Zeng, Geng, and Xie\n5.1.1 Theoretical Validation of Proposed Method\nIn this section, we conducted simulations to verify our theoretical results for both the linear\nmodel and the ANINCE model. Specifically, we tested our method’s ability to identify\ninvalid IVs that violate the exogeneity condition under three scenarios: linear constant con-\nditions with varied distributions, partially nonlinear constant conditions (with Gaussian\nnoise terms), and partially nonlinear non-constant conditions with varied functional forms\nbutaconsistentUniformdistribution. TheperformanceresultsarepresentedinTable2,Ta-\nble 3, and Table 4, respectively. Further, we examined the proposed method’s effectiveness\nin identifying invalid IVs that violate the exclusion restriction condition under nonlinear\nconstantandnonlinearnon-constantconditionswithdifferentfunctionalformsbutthesame\nBeta distribution. Results for these tests are shown in Table 5 and Table 6.\nExperimental Design: We generated data according to the model in Equation (2),\nwhere each candidate IV set contains both a valid IV and an invalid IV. For the nonlin-\near non-constant effects model, we applied five functions-logarithmic, quadratic polynomial,\ncubic polynomial, logarithmic quadratic polynomial, exponent quadratic polynomial-for g(·),\nf(·) and ϕ (·). In contrast, these functions were linear under linear, constant settings. For\n∗\ntheerrortermε , weselected sixdistributions3: Gaussian, Uniform, T, Beta, Gamma, Log-\n∗\nnormal. In all experiments, the significance level was adjusted to 10 divided by the sample\nsize. Each experiment was repeated 100 times with randomly generated data, and the re-\nported results were averaged. Additional experimental details can be found in Appendix\nB.\nTable 2: Performance in Testing Violations of Exogeneity within Linear Models.\nSize=3K Size=5K Size=7K\nDistribution Valid MR↓ Invalid MR↓ Valid MR↓ Invalid MR↓ Valid MR↓ Invalid MR↓\nUniform 0.00 0.06 0.00 0.01 0.00 0.01\nBeta 0.00 0.09 0.00 0.08 0.00 0.05\nT-distribution 0.00 0.03 0.00 0.02 0.00 0.00\nGamma 0.00 0.08 0.00 0.03 0.00 0.02\nLog-normal 0.00 0.13 0.00 0.08 0.00 0.03\nGaussian 0.00 1.00 0.00 1.00 0.00 1.00\nMixed 0.01 0.20 0.00 0.15 0.00 0.13\nNote: ↓ means a lower value is better, and vice versa.\nTable 3: Performance in Testing Violations of Exogeneity within Partial Non-Linear Con-\nstant Effect Models.\nSize=3K Size=5K Size=7K\nFunction Valid MR↓ Invalid MR↓ ValidMR↓ Invalid MR↓ Valid MR↓ Invalid MR↓\nLog 0.02 0.00 0.02 0.00 0.02 0.00\nQuadraticpolynomial 0.00 0.00 0.00 0.00 0.00 0.00\nCubicpolynomial 0.00 0.05 0.00 0.00 0.00 0.00\nLog(quadratic) 0.00 0.00 0.00 0.00 0.00 0.00\nExp(quadratic) 0.01 0.16 0.01 0.02 0.01 0.02\nNote: ↓ means a lower value is better, and vice versa.\n3. The“Mixeddistribution”referstothatobtainedbyrandomlyselectingfromthementioneddistributions.\n18\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nTable 4: Performance in Testing Violations of Exogeneity within Partial Non-Linear Non-\nConstant Models.\nSize=3K Size=5K Size=7K\nFunction Valid MR↓ Invalid MR↓ ValidMR↓ Invalid MR↓ Valid MR↓ Invalid MR↓\nLog 0.00 0.00 0.00 0.00 0.00 0.00\nQuadraticpolynomial 0.00 0.00 0.00 0.00 0.00 0.00\nCubicpolynomial 0.01 0.00 0.00 0.00 0.00 0.00\nLog(quadratic) 0.00 0.00 0.00 0.00 0.00 0.00\nExp(quadratic) 0.01 0.00 0.00 0.00 0.00 0.00\nNote: ↓ means a lower value is better, and vice versa.\nTable 5: Performance in Testing Violations of Exclusion Restriction within Partial Non-\nLinear Constant Models.\nSize=3K Size=5K Size=7K\nFunction Valid MR↓ Invalid MR↓ ValidMR↓ Invalid MR↓ Valid MR↓ Invalid MR↓\nLog 0.14 0.03 0.09 0.00 0.07 0.00\nQuadraticpolynomial 0.00 0.03 0.00 0.01 0.00 0.00\nCubicpolynomial 0.00 0.25 0.00 0.16 0.00 0.13\nLog(quadratic) 0.03 0.00 0.01 0.00 0.00 0.00\nExp(quadratic) 0.00 0.12 0.00 0.06 0.00 0.03\nNote: ↓ means a lower value is better, and vice versa.\nTable 6: PerformanceinTestingViolationsofExclusionRestrictionwithinNon-LinearNon-\nConstant Models.\nSize=3K Size=5K Size=7K\nFunction Valid MR↓ Invalid MR↓ ValidMR↓ Invalid MR↓ Valid MR↓ Invalid MR↓\nLog 0.20 0.00 0.18 0.00 0.12 0.00\nQuadraticpolynomial 0.00 0.04 0.00 0.03 0.00 0.02\nCubicpolynomial 0.00 0.19 0.00 0.11 0.00 0.08\nLog(quadratic) 0.09 0.02 0.06 0.02 0.03 0.00\nExp(quadratic) 0.02 0.09 0.00 0.03 0.00 0.01\nNote: ↓ means a lower value is better, and vice versa.\n19\nGuo, Li, Huang, Zeng, Geng, and Xie\nResults: As shown in Tables 2 ∼ 6, both metrics generally improve significantly with\nincreasing sample sizes across various distributions and functions. Those facts suggest\nthat our method can correctly identify invalid IVs that violate the exogeneity condition or\nviolate the exclusion restriction condition. More specifically, Table 2 highlights that non-\nGaussianity is beneficial for identifying IV in linear models, as demonstrated in Figure 2\nandsupportedbyProposition2. Notably, theInvalidMRvalueintheGaussiandistribution\nof the linear model in Table 2 is 1, indicating that our method cannot detect invalid IVs\nin a linear Gaussian model. This finding is consistent with the conclusions presented in\nProposition 1. Tables 3 ∼ 4 furthershow that even a slight degree of nonlinearity facilitates\ntheassessment of IVvalidity undertheexogeneity condition in bothnonlinear constant and\nnon-constant effect models, as illustrated in Figure 3 and stated in Proposition 4. Lastly,\nTables 5 ∼ 6 reveal that in nonlinear models, when the direct causal effect of Z → Y does\nnot follow a linear function of the effect of Z → X, it becomes possible to assess the validity\nof IVs solely concerning the exclusion restriction condition, as highlighted in the negative\nof Corollary 3 and elaborated in Proposition 4.\n5.1.2 Comparison with IV-PIM in Continuous Treatment Setting\nIn this section, we compared the proposed AIT Condition with IV-PIM, as proposed by\nBurauel (2023), in continuous treatment settings. Note that since IV-PIM requires covari-\nates, we introduce covariates here for a fair comparison.\nExperimental Design: The specific generation mechanism with covariates W in the\nlinear mdoel is defined as follows: U = ε , W = ε , Z = I(U + W + ε ), Z =\nU W 1 Z1 2\nI(W+ε ), X = 0.5Z +0.5Z +λW +δ, and Y = X +W+ǫ, where ε ∼ T(5), ε ∼\nZ2 1 2 U Z1\nBeta(0.5,0.1), ε ∼ N(0,1), and δ,ǫ ∼ T(5). Here, I(∗) is the indicator function such\nZ2\nthat I(∗) > mean(∗) equals 1; otherwise, it is 0. The coefficient λ is randomly drawn from\na normalized standard normal distribution. The noise terms ε follow a multidimensional\nW\nnormal distribution and are consistent with IV-PIM, with the dimensionality of covariates\nW varying across |W| = {2,3,5}. The remaining settings are the same as in Section 5.1.1.\nResults: As shownin Table7, ourmethodoutperformsexperimentalresults of IV-PIM\nwith covariates under both Valid MR and Invalid MR. Interestingly, IV-PIM’s performance\nimproves as the dimensionality of covariates increases, consistent with findings in Burauel\n(2023). Additionally,Table7highlightsthepracticalityoftheAITconditionwithcovariates,\nas presented in Corollary 4.\nTable 7: Performance in Testing Instrumental Variables with Covariates.\nSize=3K Size=5K Size=7K\n|W| Condition ValidMR↓ InvalidMR↓ ValidMR↓ InvalidMR↓ ValidMR↓ InvalidMR↓\n2 IV-PIMmethod(Burauel,2023) 0.23 0.28 0.23 0.21 0.33 0.17\nAITcondition 0.00 0.28 0.00 0.06 0.00 0.02\n3 IV-PIMmethod(Burauel,2023) 0.14 0.26 0.21 0.22 0.17 0.19\nAITcondition 0.00 0.19 0.00 0.01 0.00 0.01\n5 IV-PIMmethod(Burauel,2023) 0.12 0.19 0.05 0.28 0.08 0.24\nAITcondition 0.00 0.06 0.00 0.00 0.00 0.00\nNote: ↓ means a lower value is better, and vice versa.\n20\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\n5.1.3 Comparison with K-test in Discrete Treatment Setting\nIn this section, we compared the proposed instrument validity test with the\nK-test, which was proposed by Kitagawa (2015) for discrete treatment set-\ntings without covariates. The source code for the K-test is available at\nhttps://rdrr.io/github/CarrThomas/TestforInstrumentValidity/.\nExperimental Design: The discrete treatment data that simulates violations of the\nexogeneity and exclusion restriction conditions as follows: U = ε , Z = I(ϕ (U)+ ε ),\nU Z Z\nX = I(g (Z)+ϕ (U)+ε ), Y = βX+g (Z)+ϕ (U)+ε , and ε ∼ N(0,1), where the\nX X X Y Y Y ∗\ncausal effect β = 1, and I(∗) is the indicator function such that I(∗) > mean(∗) equals 1;\notherwise, it is 0. Thefunctions ϕ (U) and g (Z) are nonlinear and randomly selected from\n∗ ∗\nthe following: cos, sin, square, cubic(third-degree polynomials), logarithmic, exponential\nfunction. The remaining settings are the same as in Section 5.1.1.\nResults: As shown in Table 8, our method outperforms the K-test method in terms of\nInvalid MR across all samplesizes. TheInvalid MR for the K-test method is slightly higher,\nparticularly with smaller sample sizes, though it decreases as the sample size increases. For\nthe Valid MR metric, both methods achieve a value of 0, indicating that neither method\nmistakenly identifies valid IVs as invalid.\nTable 8: Performance in Testing Instrumental Variables with Discrete Treatment.\nSize=3K Size=5K Size=7K\nCondition ValidMR↓ InvalidMR↓ ValidMR↓ InvalidMR↓ ValidMR↓ InvalidMR↓\nK-testmethod(Kitagawa,2015) 0.00 0.20 0.00 0.15 0.00 0.10\nAITcondition 0.00 0.09 0.00 0.07 0.00 0.01\nNote: ↓ means a lower value is better, and vice versa.\n5.2 Real-World Datasets\nIn this section, we evaluated the effectiveness of the proposed method by applying it to\nthree real-world datasets from different domains.\n5.2.1 Schooling-Returns Data\nWe consider the application of our method to the study by Card (1993). This study inves-\ntigates the impact of education levels on earnings using data from the Young Men Cohort\nof the National Longitudinal Survey.\nData Description: The dataset is a sample of 3010 men taken from the US National\nLongitudinal Surveyof Young Men (NLSY). It includes variables such as Lived near the col-\nlege (L ), Schooling (S ), Returns (R ), anda setof covariates including{Experience, Ex-\nnc ch e\nperience square, Black, Smsa, Smsa66, South, Region information (reg662-reg669)} (ER),\namong others. The hypothesized model of Card (1993) is presented in Figure 4. The\nhypothesized data generation mechanism is described as follows:\n⊤\nS =α +α L +α ER+δ,\nch 0 1 nc\n(16)\n⊤\nR =β +β S +β ER+ǫ,\ne 0 1 ch\nwhere δ and ǫ are dependent.\n21\nGuo, Li, Huang, Zeng, Geng, and Xie\nIndividual\nER\nAbility\nL S R\nnc ch e\nFigure 4: Graphical illustration of an IV model for estimating the causal effect of schooling\n(S ) on returns of education (R ) (Card, 1993).\nch e\nResults: Card (1993) demonstrated that L can serve as a valid IV for the causal\nnc\nrelationship S → R , while controlling for the covariates ER. For consistency, we adopt\nch e\nthe causal effect of S on R , i.e., β = 0.1315, as well as the coefficients β of thecovariates\nch e 1\nfrom Card (1993), as the estimated parameter βˆ under the AIT condition. We then obtain\nthe residual L by regressing L on the covariates ER. The P-value of the independence\nnc nc\ntest betweengthe auxiliary variable and the residual L is 0.732, indicating that we cannot\nnc\nreject L as a valid IV. This result further supporgts the validity of using L as an IV,\nnc nc\nconsistent with the findings in Card (1993).\n5.2.2 Colonial Origins data\nWeapplyourmethodtothestudybyAcemoglu et al.(2001),whichestimates theimpactof\ncolonial history on theeconomic development of different regions usingthe Colonial Origins\nof Comparative Development dataset.\nData Description: Thedatasetincludesfivekeyvariables across64countries, afterex-\ncluding samples with missing data. These variables are: Mortality (M ), Euro1990 (E ),\nor uro\nLatitude (L ), Institutions (I ), and Economic Development (E ). The hypothesized\nat ns d\nmodel proposed by Acemoglu et al. (2001) is illustrated in Figure 5, and the hypothesized\ndata generation mechanism is described as follows:\nI = γ+γ M +γ L +γ E +δ,\nns 1 or 2 at 3 uro\n(17)\nE = β+β I +β L +ǫ,\nd 1 ns 2 at\nwhere δ and ǫ are dependent.\nResults: Acemoglu et al. (2001) demonstrated that both M and E can serve as\nor uor\nvalid IVs, conditional on L , with respect to I and E . To verify this, we test their\nat ns d\nvalidity using the AIT condition. For consistency, we adopt the causal effects of I on E\nns d\nas reported by Acemoglu et al. (2001), specifically β = 0.9458 and β = −0.5971, as the\n1 2\nestimated parameters βˆ(i = 1,2) in the AIT condition. We next obtain the residuals M\ni or\nand E by regressing M and E on covariate L , respectively. The validity testgfor\nuro or uro at\nM ygields a P-value of 0.608, whereas the test for E yields a P-value of 0.248. These\nor uro\nresults indicate that E is more likely to be an invalid IV compared to M , suggesting\nuro or\nthat the exogeneity of E is weaker than that of M . These findings are consistent with\nuro or\nthose of Acemoglu et al. (2001), and we cannot reject the validity of M and E as IVs,\nor uro\naligning with their conclusions.\n22\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nCultural\ndifference\nE\nuro\nI E\nns d\nM\nor\nL\nat\nFigure 5: Graphical illustration of an IV model for estimating the causal effect of institu-\ntions (I ) on economic development (E ) (Acemoglu et al., 2001).\nns d\n5.2.3 Conflict and Time Preference Data\nWe consider the application of our method to the study by Voors et al. (2012). This study\nuses the Conflict and Time Preference Data to investigate the impact of violence on a\nperson’s patience.\nData Description: The dataset consists of 302 observations and fifteen variables, as\ndescribed in Voors et al. (2012). Treatment violence is measured by the percentage dead\nin attacks in the area the person lived (D ), while the person’s patience (outcome) is\nper\nassessed by a person’s discount rate for willingness to receive larger amounts of money\nin the future compared to smaller amounts of money now (D ). Other variables include\nisc\ndistancetoBujumbura(d ),altitude(a ),andcovariates suchas{whethertherespondent\nist lti\nisliterate, therespondent’sage, therespondent’ssex,thetotallandholdingpercapita, land\nGini coefficient, distance to market, conflict over land, ethnic homogeneity, socioeconomic\nhomogeneity, population density, per capita total expenditure}(PG). The covariates used\ninthestudyrepresentexogenouspersonalandgeographicalinformationvariables(PG). As\ndiscussed in Voors et al. (2012), violence may be targeted in a non-random way, potentially\nrelated to community patience, which makes violence (D )endogenous. Thehypothesized\nper\nmodelfromGuo and Small(2016)isillustratedinFigure6,andthehypothesizedgeneration\nmechanism is as follows:\nD = α +α d +α a +α d2 +α a2 +α d ∗a +α⊤ PG+δ,\nper 0 1 ist 2 lti 3 ist 4 lti 5 ist lti 6\n(18)\nD = β +β⊤ PG+β D +β D2 +ǫ,\nisc 0 1 2 per 3 per\nwhere δ and ǫ are dependent.\nResults: Voors et al. (2012) showed that both d and a can serve as valid IVs,\nist lti\nconditional on PG, with respect to D on D . To verify this, we test their validity\nper isc\nusing the AIT condition. For consistency, we adopt the causal effects of D on D as\nper isc\nreported by Guo and Small (2016), specifically β = 2.054 and β = 0.049, as the estimated\n2 3\nparameters βˆ(i = 2,3) in the AIT condition. We obtain the residual d and a by\ni ist lti\nregressingd\nist\nanda\nlti\noncovariates PG,respectively. Wefirsttestthevalidigtyofd ist,fwhich\nyields a P-value of 0.326, suggesting that d cannot be rejected as a valid instrumental\nist\n23\nGuo, Li, Huang, Zeng, Geng, and Xie\nSocialand\nPolitical\nconfounder\nd\nist\nD D\nper isc\na\nlti\nPG\nFigure 6: Graphical illustration of an IV model for estimating the causal effect of violence\n(D ) on a person’s patience (D )(Voors et al., 2012).\nper isc\nvariable. This is consistent with the findings of Voors et al. (2012). Similarly, testing a\nlti\nas a potential IV results in a P-value of 0.758, indicating that a also cannot be rejected\nlti\nas a valid IV. These results align with the conclusions of Voors et al. (2012).\n6 Conclusions\nInthispaper,weexploredthetestabilityofsingleIVsintheadditivenonlinear,non-constant\neffects (ANINCE) model, where the treatment variable can be either discrete or continuous.\nTo this end, we introduced a necessary condition, termed the AIT Condition, to detect\nwhether a variable is a valid IV without knowing whether some other variable is an instru-\nment. Furthermore, we provided the precision conditions for identifying all invalid IVs in\nlinear and ANINCE models. We then proposed the practical AIT condition test algorithm\nwith covariates and finite data. Experimental results using both simulation data and three\nreal datasets have further validated the usefulness of our algorithm. In the future, we plan\nto investigate whether the AIT condition could facilitate the testability implication of an\ninvalid IV set.\nAcknowledgements\nThe authors would like to thank Kun Zhang for his helpfulcomments and suggestions. The\nauthors also would like to thank Patrick Burauel, who kindly provided us with his R imple-\nmentation of theIV-PIM.FXwouldlike to acknowledge thesupportby theNaturalScience\nFoundation of China(62306019). XCGacknowledges the supportof theGraduate Research\nAbility Enhancement Program Project Funding at Beijing Technology and Business Uni-\nversity. YZ would like to acknowledge the support of the Beijing Municipal Education\nCommission Science and Technology Program General Project (KM202410011016).\n24\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nAppendix A. Proofs\nBefore presenting the proofs, we introduce two important theorems since these are used to\nprove our results.\nWe first quote the Darmois–Skitovitch theorem that characterizes the independence of\ntwo linear statistics (Darmois, 1953; Skitovitch, 1953). This theorem provides the founda-\ntion for proving Propositions 2 ∼ 3 and Theorem 2.\nTheorem 4 (Darmois–Skitovitch Theorem) Define two random variables V and V\n1 2\nas linear combinations of independent random variables ε ,...,ε :\n1 p\np p\nV = α ε , V = β ε , (19)\n1 X i i 2 X i i\ni=1 i=1\nwhere the α ,β are constant coefficients. If V and V are independent, then the random\ni i 1 2\nvariables ε for which α β 6= 0 are Gaussian.\nj j j\nThe above theorem states that if there exists a non-Gaussian ε for which α β 6= 0, V and\nj j j 1\nV are dependent.\n2\nNext, we introduce a local geometric information theorem that characterizes the inde-\npendence of two nonlinear statistics (Lin, 1997). This result provides the foundation for\nproving Proposition 4, Theorems 1, 3 and Corollarys 1 ∼ 4.\nTheorem 5 The Hessian H of function f is block diagonal everywhere, ∂ ∂ f = 0 for\nf i j (cid:12)s~0\nall points s~ and all i ≤ k, j > k, if and only if f is separable into a sum f(s(cid:12),...,s ) =\n0 1 n\ng(s ,...,s )+h(s ,...,s ) for some functions g and h.\n1 k k+1 n\nTheabove proposition states that function f is separable if and only if its mixed second-\norder partial derivative is zero.\nA.1 Proof of Proposition 2: Testability of Exogeneity in Linear Models\nProof Under the assumption of a linear model, Equation (2) can be expressed as follows:\nU = ε , Z = γU +ε ,\nU Z\n(20)\nX = τZ +ρU +ε , Y = βX +νZ +κU +ε .\nX Y\nIf candidate IV Z violates the exogeneity condition, the causal effect estimated via the IV\nestimator-specifically, theTwoStages LeastSquaremethod(Bowden and Turkington,1990;\nPearl, 2009))-will be biased:\nγ(νγ +κ)Var(U)+νVar(ε )\nβˆ= β + Z . (21)\nγ(τγ +ρ)Var(U)+τ Var(ε )\nZ\nβ\n| {bizas }\nBased on the definition of the AIT condition, we have\nA = Y −βˆX\nX→Y||Z\n= νZ +κU+ε −β X (22)\nY bias\n= [νγ +κ−(ντ +ρ)β ]ε +(ν −τβ )ε −β ε +ε .\nbias U bias Z bias X Y\n25\nGuo, Li, Huang, Zeng, Geng, and Xie\nBecauseZ isaninvalid IVthatviolates theexogeneity condition, withoutloss ofgeneration,\nwe assume that U causes the candidate IV Z, i.e., γ 6= 0, then β 6= 0. This will imply\nk k bias\nthat [νγ +κ −(ντ +ρ )β ] 6= 0 for ε , and (ν −τβ ) 6= 0 for ε . Furthermore,\nk k k bias U k bias Z\nbecause of Assumption 1, i.e., (i) there exists at least one variable U ∈ U whose noise\nk\nterm follows a non-Gaussian distribution and cause Z or, (ii) the noise term of Z follows\na non-Gaussian distribution, then at least one of the non-Gaussian noise terms ε\nU\nk\nor ε , is common between A and Z. Due to the Darmois–Skitovitch Theorem,\nZ X→Y||Z\nwehaveA isdependentonZ. Thatistosay,{X,Y||Z}violates theAITcondition.\nX→Y||Z\nA.2 Proof of Proposition 3: Non-testability of Exclusion Restriction in Linear\nModels\nProof Because candidate IV Z satisfies exogeneity condition, the model of Equation (2)\ncan be written as:\nU = ε , Z = ε ,\nU Z\n(23)\nX = τZ +ρU +ε , Y = βX +νZ +κU +ε .\nX Y\nThe estimated causal effect is given by βˆ= β +β = β+ ν , where β 6= 0. According\nbias τ bias\nto the AIT condition, we obtain\nA = Y −βˆX\nX→Y||Z\n= νZ +κU +ε Y −β biasX (24)\nρν ν\n= κ− ε − ε +ε .\n(cid:16) τ (cid:17) U τ X Y\nWhen ν = 0, implying that Z is a valid IV, we have A = κε + ε . In both\nX→Y||Z U Y\ncases—whether Z is an invalid IV that violates solely the exclusion restriction condition\nor a valid IV—there are no shared noise terms between A and Z. By the Dar-\nX→Y||Z\nmois–Skitovitch Theorem (Theorem 4), we have A is independent of Z. Thus,\nX→Y||Z\n{X,Y||Z} always satisfies the AIT condition.\nA.3 Proof of Theorem 2: Necessary and Sufficient Conditions in Linear\nModels\nProof Below, we prove the necessary and sufficient condition for identifying invalid IV in\nthe linear model.\n(⇒): According to Theorem 1, we know that if Z is a valid IV relative to X → Y, then\n{X,Y||Z} always satisfies the AIT condition. This indicates that if {X,Y||Z} violates the\nAIT condition, then Z is an invalid IV. Below, we processed with a proof by contradiction\nto prove that candidate IV Z violates the exogeneity condition. If Z solely violates the\nexclusion restriction condition, then by Proposition 3, {X,Y||Z} always satisfies the AIT\ncondition. This contradicts the assumption that {X,Y||Z} violates the AIT condition. As\na result, candidate IV Z violates the exogeneity condition.\n26\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\n(⇐): To establish that Assumption 1 holds and that the candidate IV Z is invalid due\nto a violation of the exogeneity condition, we need to show that {X,Y||Z} consequently\nviolates the AIT condition. This conclusion is equivalent to Proposition 2, thereby proving\nthe theorem.\nA.4 Proof of Proposition 4: Testability of IV in ANINCE Models\nProof IfZ violates theIVconditions,thegeneratingmechanismcanbedescribedasfollows:\nU = ε , Z = ϕ (U)+ε ,\nU Z Z\n(25)\nX = g(Z)+ϕ (U)+ε , Y = f(X,Z)+ϕ (U)+ε ,\nX X Y Y\nwherefunction g(·), f(·), and ϕ (·) are twice differentiable. Hence, let h(·) bethe estimated\n∗\nfunction, where h(·) satisfies E[Y −h(X)|Z] = 0 and h(·) 6= 0. According to the definition\nof the AIT condition, we have\nA = Y −h(X)\nX→Y||Z\n= f(X,Z)−h(X)+ϕ (U)+ε , (26)\nY Y\ne\n| f bias{(zX,Z) }\nwhere f (X,Z) = f(X,Z)−h(X). Combining the Equations (25) and (26), we have\nbias\ne\nA = f (X,Z)+ϕ (U)+ε ,\nX→Y||Z bias Y Y\n(27)\ne\nZ = ϕ (U)+ε .\nZ Z\nAccording to the above Equation (27), one can see that the transformation from\n(A ,Z) to (ε ,ε ) is:\nX→Y||Z U Z\nε = ϕ−1(A −f (X,Z)−ε ),\nU Y X→Y||Z bias Y (28)\ne\nε = Z −ϕ (ε ).\nZ Z U\nDenote by |J| the Jacobian matrix of this transformation. One can see that |J| = ∂εU ·\n∂A\n∂εZ −∂εU ·∂εZ. Denote by p(A ,Z)thejointdensity of (A ,Z). Then,wehave\n∂Z ∂Z ∂A X→Y||Z X→Y||Z\np(A ,Z) = p(ε ,ε )|J| = p(ε )·p(ε )·|J|. Let K , logp(ε ), K , logp(ε ),\nX→Y||Z U Z U Z 1 U 2 Z\nand K , log|J|. Since the densities p(ε ) and p(ε ) are twice differentiable and positive\n3 U Z\non (−∞,∞), we have\nlogp(A ,Z)= log(p(ε )·p(ε )·|J|),\nX→Y||Z U Z\n(29)\n= logp(ε )+logp(ε )+log(|J|) = K +K +K .\nU Z 1 2 3\n27\nGuo, Li, Huang, Zeng, Geng, and Xie\nOne can find the (1, 2)-th entry of the Hessian matrix of logp(A ,Z):\nX→Y||Z\n∂2logp(A X→Y||Z,Z) ∂2(K\n1\n+K 2+K 3)\n=\n∂A ∂Z ∂A ∂Z\nX→Y||Z X→Y||Z\n∂(K′∂εU +K′∂εZ +K′∂|J| )\n= 1 ∂Z 2 ∂Z 3 ∂Z\n∂A (30)\n∂ε ∂ε ∂2ε ∂ε ∂ε\n= K′′ U · U +K′ U +K′′ Z · Z\n1 ∂A ∂Z 1∂A∂Z 2 ∂A ∂Z\n∂2ε ∂|J| ∂|J| ∂2|J|\n+K′ Z +K′′ · +K′ .\n2∂A∂Z 3 ∂A ∂Z 3∂A∂Z\nFor an invalid IV Z that violates the IV conditions, there are two scenarios:\n• Violation the exogeneity condition: ∂εU 6= 0, ∂εZ 6= 0, ∂εU 6= 0, ∂|J| 6= 0, ∂|J| 6= 0,\n∂Z ∂A ∂A ∂A ∂Z\n∂2|J|\nand 6= 0;\n∂A∂Z\n• Violation the exclusion restriction condition while satisfying the exogeneity condition:\n∂εU = 0, ∂εZ 6= 0, ∂εZ = 0, ∂|J| = 0, and ∂2|J| = 0.\n∂Z ∂A ∂A∂Z ∂Z ∂A∂Z\nAccording to Assumption 2, specifically the condition that the second-order partial deriva-\ntive\n∂2logp(AX→Y||Z,Z)\n6= 0, it follows that A ⊥6⊥ Z. This implies that {X,Y||Z}\n∂AX→Y||Z∂Z X→Y||Z\nviolates the AIT condition.\nA.5 Proof of Corollary 1\nProof Due to the assumption of linearity in the model, the model in Equation (2) can be\nwritten as:\nU = ε , Z = γU +ε ,\nU Z\n(31)\nX = τZ +ρU +ε , Y = βX +νZ +κU +ε .\nX Y\nIf candidate IV Z violates the IV conditions, the estimated causal effect using the IV\nestimator (i.e., Two Stages Least Square (Bowden and Turkington, 1990; Pearl, 2009)) will\nbe biased:\nγ(νγ +κ)Var(U)+νVar(ε )\nβˆ= β + Z (32)\nγ(τγ +ρ)Var(U)+τ Var(ε )\nZ\nβ\n| {bizas }\nAccording to the definition of AIT condition, we have\nA = Y −βˆX\nX→Y||Z\n= νZ +κU+ε −β X (33)\nY bias\n= [νγ +κ−(ντ +ρ)β ]ε +(ν −τβ )ε −β ε +ε .\nbias U bias Z bias X Y\nAccordingly, using Equation (31), the transformation from (A ,Z) to (ε ,ε ) be-\nX→Y||Z U Z\ncomes:\nA−(ν −τβ )ε +β ε −ε\nbias Z bias X Y\nε = ,\nU\nνγ +κ−(ντ +ρ)β bias (34)\nε = Z −γε .\nZ U\n28\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nGiving that the second and higher-order derivatives in the linear model are zero, the\nfollowing holds:\n∂2εU\n= 0,\n∂2εZ\n= 0,\n∂|J| ·∂|J|\n= 0, and\n∂2|J|\n= 0. Therefore,thealgebraic\n∂A∂Z ∂A∂Z ∂A ∂Z ∂A∂Z\nequation condition can be expressed as follows:\n∂2logp(A ,Z) 1 1\nX→Y||Z = K′′ +K′′ . (35)\n∂A ∂Z 1γ2(ν −β τ)+γ(κ−β ρ) 2ν −β τ\nX→Y||Z bias bias bias\nBecause all noise terms follow Gaussian distribution, we have K′′ = logp(ε )′′ = − 1\n1 U Var(εU)\nand K′′ = logp(ε )′′ = − 1 . Further combined with Equation (35), we obtain\n2 Z Var(εZ)\nK′′ 1 + K′′ 1 = 0, which imply that the second-order partial\n1γ2(ν−β biasτ)+γ(κ−β biasρ) 2ν−β biasτ\nderivative\n∂2logp(AX→Y||Z,Z)\nis zero. This result indicates that, under the linear model,\n∂AX→Y||Z∂Z\nGaussian noise terms yield a scenario where Assumption 2 does not hold.\nA.6 Proof of Corollary 2\nProof Due to the assumption of linearity in the model and given that the candidate IV Z\nsatisfies the exogeneity condition, the model of Equation (2) can be expressed as follows:\nU= ε , Z = ε ,\nU Z\n(36)\nX = τZ +ρU +ε , Y = βX +νZ +κU +ε .\nX Y\nSince the second and higher-order derivatives in the linear model are zero, it follows that\n∂2εU\n= 0,\n∂2εZ\n= 0,\n∂|J|\n·\n∂|J|\n= 0, and\n∂2|J|\n= 0. Further, since Z = ε , we also have\n∂A∂Z ∂A∂Z ∂A ∂Z ∂A∂Z Z\n∂εU = 0. Accordingly, the second-order partial derivative of the logarithm of the joint\n∂Z\nprobability density can be written as\n∂2logp(A ,Z) ∂ε ∂ε\nX→Y||Z = K′′ Z · Z . (37)\n∂A ∂Z 2 ∂A ∂Z\nX→Y||Z\nIf IV Z solely violates the exclusion restriction condition, the estimated causal effect using\nthe two-stage least square method (2SLS) is given by\nν\nβˆ= β+β = β + , (38)\nbias\nτ\nwhere β = ν.\nbias τ\nAccording to the definition of AIT condition, we obtain\nρν ν\nA = Y −βˆX = κ− ε − ε +ε . (39)\nX→Y||Z (cid:16) τ (cid:17) U τ X Y\nThus, we obtain ∂εZ = 0. Combined with Equation (37), this yields the second-order\n∂A\npartial derivative\n∂2logp(AX→Y||Z,Z)\n= 0. This result indicates that Assumption 2 does not\n∂AX→Y||Z∂Z\nhold.\n29\nGuo, Li, Huang, Zeng, Geng, and Xie\nA.7 Proof of Corollary 3\nProof Because candidate IV Z satisfies exogeneity condition, the model of Equation (2)\ncan be written as:\nU = εU, Z = ε Z,\n(40)\nX = g (Z)+ϕ (U)+ε , Y = f(X)+g (Z)+ϕ (U)+ε .\nX X X Y Y Y\nIf the direct causal effect of Z → Y is a linear function of the direct causal effect of Z → X,\ni.e., g (Z) = a·g (Z)+b, then it is possible to construct a valid IV model that shares the\nY X\nsame distribution as the above invalid IV model (40). The model for this valid IV, which\nhas an identical distribution, is as follows:\nU′ = U, Z′ = Z,\n(41)\nX′ = X, Y′ = f′(X′)+ϕ (U)+ε = Y,\nY Y\nwhere f′(X′) = f(X)+g (Z).\nY\nAccording to Equation (41), we know that Z′ is a valid IV relative to X′ → Y′. Based\non the Theorem 1, the second-order partial derivative\n∂2logp(AX→Y||Z,Z)\n= 0, indicating\n∂AX→Y||Z∂Z\nthat Assumption 2 does not hold.\nA.8 Proof of Theorem 3: Necessary and Sufficient Conditions for IV in\nANINCE Models\nProof Below, we prove the necessary and sufficient conditions for identifying invalid IV in\nthe ANINCE model.\n(⇒): According to Theorem 1, we know that if Z is a valid IV relative to X → Y, then\n{X,Y||Z} always satisfies the AIT condition. This indicates that if {X,Y||Z} violates the\nAIT condition, then Z is an invalid IV.\n(⇐): To establish that Assumption 2 holds and that the candidate IV Z is invalid, we\nneed to show that {X,Y||Z} consequently violates the AIT condition. This conclusion is\nequivalent to Proposition 4, thereby proving the theorem.\nA.9 Proof of Corollary 4: Necessary Condition for IV with Covariates\nProof Below, we apply the same proof technique used in Theorem 1 to demonstrate\nCorollary 4. SupposeZ is avalidIVrelative toX → Y given W, thegenerating mechanism\ncan be expressed as follows:\nU = ε , W = ϕ (U)+ε , Z = t (W)+ε ,\nU W W Z Z\n(42)\nX = g(W,Z)+ϕ (U)+ε , Y = f(X,W)+ϕ (U)+ε ,\nX X Y Y\nwhere functions g(·), f(·), t (·), and ϕ (·) are smooth functions. Following the consis-\n∗ ∗\ntent IV estimation method via the conditional mean model (e.g., Newey and Powell (2003);\n30\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nSingh et al. (2019); Bennett et al. (2019)), h(·) can represent the unbiased causal effect f(·)\nof X on Y as the sample size n → ∞, implying that h(·) = f(·). Thus, we have\nA X→Y||(Z,W) = Y −h(X,W) = Y −f(X,W) = ǫ = ϕ Y(U)+ε Y. (43)\nLet Z denote the residual from the regression Z on W. Thus, Z = ε .\nZ\nBelow, by combining Equations (43) and Z = ε , we observe that the transformation\nZ\nfrom (A X→Y||(Z,W),Z) to (ε U,ε Z) is:\nε\nU\n= ϕ Y−1(A X→Y||(Z,W)−ε Y),\n(44)\nε = Z.\nZ\nLet|J| denotetheJacobian matrixof thistransformation, givingby |J| = ∂εU ·∂εZ −\nA,Z A,Z ∂A ∂Z\n∂ ∂ε ZU · ∂ ∂ε AZ. Denote by p(A X→Y||(Z,W),Z) the joint density of (A X→Y||(Z,W),Z). Then, we\nhave p(A X→Y||(Z,W),Z) = p(ε U,ε Z)|J|\nA,Z\n= p(ε U)· p(ε Z)·|J| A,Z. Let K\n1\n, logp(ε U),\nK , logp(ε ), and K , log(|J| ). The involved densities p(ε ) and p(ε ) are twice\n2 Z 3 A,Z U Z\ndifferentiable, and positive on (−∞,∞), we have\nlogp(A X→Y||(Z,W),Z) = log(p(ε U)·p(ε Z)·|J| A,Z),\n(45)\n= logp(ε )+logp(ε )+log(|J| ) = K +K +K .\nU Z A,Z 1 2 3\nOne can find the (1, 2)-th entry of the Hessian matrix of logp(A X→Y||(Z,W),Z):\n∂2logp(A X→Y||(Z,W),Z)\n=\n∂(K 1′∂ ∂ε ZU +K 2′∂ ∂ε ZZ +K 3′∂|J ∂| ZA,Z)\n∂A X→Y||(Z,W)∂Z ∂A\n= K′′∂ε U · ∂ε U +K′ ∂2ε U +K′′∂ε Z · ∂ε Z (46)\n1 ∂A ∂Z 1∂A∂Z 2 ∂A ∂Z\n∂2ε ∂|J| ∂|J| ∂2|J|\n+K′ Z +K′′ A,Z · A,Z +K′ A,Z .\n2∂A∂Z 3 ∂A ∂Z 3 ∂A∂Z\nFor a valid IV Z, we know that ∂εU = ∂εZ = 0 and ∂|J|A,Z = ∂2|J|A,Z = 0. Hence, the\n∂Z ∂A ∂Z ∂A∂Z\nsecond-order derivative ∂2lo ∂g Ap X(A →X Y→ ||(Y Z| ,| W(Z ), ∂W Z),Z) = 0, i.e., A X→Y||(Z,W) and Z are statistically\nindependent. Consequently, {X,Y||(Z,W)} satisfies the AIT condition.\nAppendix B. More Details on Simulation Experiments in Section 5\nIn this section, we provide details of the simulation experiments corresponding to Tables 2\n∼ 8. Specifically, the generation mechanism for each table is as follows:\n• Table 2: The model setup is as follows: U = ε , Z = γU + ε , Z = ε , X =\nU 1 Z1 2 Z2\nτ Z +τ Z +ρU+ε , Y = X+κU+ε , whereall constant coefficients are randomly\n1 1 2 2 X Y\nselected from a uniform distribution with parameters min = 0.5 and max = 1.5. The\nnoise terms ε ,ε ,ε ,ε , and ε follow the specific distributions listedin each row.\nU Z1 Z2 X Y\nThe final row indicates that all noise terms are randomly drawn from one of six\ndistributions 4.\n4. These six distributions includeUnifrom, Beta, T, Gamma, Lognormal, and Gaussian.\n31\nGuo, Li, Huang, Zeng, Geng, and Xie\n• Table 3: The model setup is as follows: U = ε , Z = ϕ (U) + ε , Z = ε ,\nU 1 Z1 Z1 2 Z2\nX = τ Z + τ Z + ρU + ε , Y = βX + κU + ε , where all constant coefficients\n1 1 2 2 X Y\nare set to 1, and all noise terms follow the Gaussian distribution with mean 0 and\nstandard deviation 1. The nonlinear function ϕ (U) matches the corresponding\nZ1\nfunction provided in each row. The details of the nonlinear function are as follows:\nLog: Y = log (0.2|X|−1);\ne\nQuadratic polynomial: Y = X2−2·X +1;\nCubic polynomial: Y = X3−0.5·X2 +0.2·X; (47)\nLog (quadratic): Y = log (|0.5·X2+X|);\ne\nExp (quadratic): Y =\ne0.3·X2+X;\n• Table 4: The model setup is as follows: U = ε , Z = γU + ε , Z = ε , X =\nU 1 Z1 2 Z2\nτ Z +τ Z +ρU+ε , Y = f(X)+κU+ε , where all constant coefficients are set to\n1 1 2 2 X Y\n1, and all noise terms follow the Uniform distribution with parametric min = -2 and\nmax = 2. The nonlinear function f(X) corresponds to the specific function listed in\neach row. The details of the nonlinear function are as follows:\nLog: Y = log (0.5|X|);\ne\nQuadratic polynomial: Y = X2−2·X +1;\nCubic polynomial: Y = 0.01·X3−0.5·X2+0.2·X; (48)\nLog (quadratic): Y = 0.1·log (|0.5·X2−1|)−2;\ne\nExp (quadratic): Y =\ne0.3·X2+X;\n• Table 5: The model setup is as follows: U = ε , Z = ε , Z = ε , X = sign(Z )+\nU 1 Z1 2 Z2 1\ng (Z )+ρU +ε , Y = X +g (Z )+κU +ε , where all constant coefficients are\nX 2 X Y 1 Y\nrandomly selected from a uniform distribution with parameters min = 0.5 and max\n= 1.5. The sign(∗) denotes sign function, where ∗ > 0 equals 1, ∗ = 0 equals 0, and\notherwise, it equals -1; all noise terms follow a Beta distribution with parameters\nalpha = 0.5 and beta = 0.1. The nonlinear functions g (Z ),g (Z ) are defined by\nX 2 Y 1\nthe specific functions provided in each row. The specific nonlinear functions are as\nfollows:\nLog: Y = log (0.2|X|)−2;\ne\nQuadratic polynomial: Y = 0.2·X2 +2·X −2;\nCubic polynomial: Y = 0.01·X3−X −6; (49)\nLog (quadratic): Y = log (|0.5·X2+X −0.1|);\ne\nExp (quadratic): Y =\ne0.3·X2+X\n−0.1;\n• Table 6: The model setup is as follows: U = ε , Z = ε , Z = ε , X = sign(Z )+\nU 1 Z1 2 Z2 1\ng (Z )+ϕ (U)+ε , Y = f(X)+g (Z )+ϕ (U)+ε , where sign(∗) denotes sign\nX 2 X X Y 1 Y Y\nfunction. All noise terms follow the Beta distribution with parameters alpha = 0.5\n32\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nand beta = 0.1. Thenonlinear functions correspond to the specific functions provided\nin each row. The detailed forms of these nonlinear functions are as follows:\nLog: Y = log (0.2|X|−2)−1;\ne\nQuadratic polynomial: Y = 0.2·X2+2·X −2;\nCubic polynomial: Y = 0.01·X3−X −6; (50)\nLog (quadratic): Y = log (|0.5·X2+X −1|);\ne\nExp (quadratic): Y =\ne0.2·X2\n−3;\n• Table 7: The specific generation mechanism for the linear model with covariates W\nis defined as follows: U = ε , W = ε , Z = I(U +W+ε ), Z = I(W+ε ),\nU W 1 Z1 2 Z2\nX = 0.5Z + 0.5Z + λW + δ, and Y = X + W + ǫ, where ε ∼ T(5), ε ∼\n1 2 U Z1\nBeta(0.5,0.1), ε ∼ N(0,1), and δ,ǫ ∼ T(5). Here, I(∗) is the indicator function\nZ2\nsuch that I(∗) > mean(∗) equals 1; otherwise, it is 0. The coefficient λ is randomly\ndrawn from a normalized standard normal distribution. The noise terms ε follow a\nW\nmultidimensional normal distribution, consistent with IV-PIM, with the dimensional-\nity of covariates W varying across |W| = {2,3,5}.\nIn the IV-PIM method, the parameters are set as follows: the number of bootstrap\nsamples B=5, the kappa method is specified as spectral, and the synthetic treatment\nvariable method is set to knockoff.\n• Table 8: The discrete treatment data that simulates violations of the exogeneity\nand exclusion restriction conditions as follows: U = ε , Z = I(ϕ (U) + ε ),\nU Z Z\nX = I(g (Z)+ϕ (U)+ε ), Y = βX+g (Z)+ϕ (U)+ε ,andε ∼ N(0,1), where\nX X X Y Y Y ∗\nβ = 1,andI(∗)istheindicatorfunctionsuchthatI(∗) > mean(∗)equals1; otherwise,\nit is 0. The functions ϕ (U) and g (Z) are nonlinear and randomly selected from the\n∗ ∗\nfollowing: cos, sin, square, cubic(third-degree polynomials), logarithmic, exponential\nfunction.\nReferences\nDaron Acemoglu, Simon Johnson, and James A Robinson. The colonial origins of com-\nparative development: An empirical investigation. American economic review, 91(5):\n1369–1401, 2001.\nDonaldWKAndrews.Examplesofl2-completeandboundedly-completedistributions.Jour-\nnal of econometrics, 199(2):213–220, 2017.\nJoshua D Angrist, Guido W Imbens, and Donald B Rubin. Identification of causal effects\nusing instrumental variables. Journal of the American statistical Association, 91(434):\n444–455, 1996.\nLee J Bain and Max Engelhardt. Introduction to probability and mathematical statistics,\nvolume 4. Duxbury Press Belmont, CA, 1992.\nMichael Baiocchi, JingCheng,andDylanSSmall. Instrumentalvariablemethodsforcausal\ninference. Statistics in medicine, 33(13):2297–2340, 2014.\n33\nGuo, Li, Huang, Zeng, Geng, and Xie\nRobert L Basmann. A generalized classical method of linear estimation of coefficients in\na structural equation. Econometrica: Journal of the Econometric Society, pages 77–83,\n1957.\nAndrew Bennett, Nathan Kallus, and Tobias Schnabel. Deep generalized method of mo-\nments for instrumental variable analysis. Advances in neural information processing sys-\ntems, 32, 2019.\nJohn Bound, David A Jaeger, and Regina M Baker. Problems with instrumental variables\nestimationwhenthecorrelationbetweentheinstrumentsandtheendogenousexplanatory\nvariable is weak. Journal of the American statistical association, 90(430):443–450, 1995.\nJack Bowden, George Davey Smith, and Stephen Burgess. Mendelian randomization with\ninvalid instruments: effect estimation and bias detection through egger regression. Inter-\nnational journal of epidemiology, 44(2):512–525, 2015.\nJack Bowden, George Davey Smith, Philip C Haycock, and Stephen Burgess. Consistent\nestimation in mendelian randomization with some invalid instruments using a weighted\nmedian estimator. Genetic epidemiology, 40(4):304–314, 2016.\nRoger J Bowden and Darrell A Turkington. Instrumental variables. Number 8. Cambridge\nuniversity press, 1990.\nPatrick F Burauel. Evaluating instrument validity using the principle of independent mech-\nanisms. Journal of Machine Learning Research, 24(176):1–56, 2023.\nRuichu Cai, Feng Xie, Clark Glymour, Zhifeng Hao, and Kun Zhang. Triad constraints for\nlearning causal structure of latent variables. Advances in neural information processing\nsystems, 32, 2019.\nDavid Card. Using geographic variation in college proximity to estimate the return to\nschooling, 1993.\nBryant Chen, Daniel Kumor, and Elias Bareinboim. Identification and model testing in\nlinear structural equation models using auxiliary variables. In International Conference\non Machine Learning, pages 757–766. PMLR, 2017.\nYutian Chen, Liyuan Xu, Caglar Gulcehre, Tom Le Paine, Arthur Gretton, Nando De Fre-\nitas, and Arnaud Doucet. On instrumental variable regression for deep offline policy\nevaluation. The Journal of Machine Learning Research, 23(1):13635–13674, 2022.\nTianjiao Chu, Richard Scheines, and Peter Spirtes. Semi-instrumental variables: a test for\ninstrument admissibility. In Proceedings of the Seventeenth conference on Uncertainty in\nartificial intelligence, pages 83–90, 2001.\nH. Cram´er. Random variables and probability distributions. Cambridge University Press,\nCambridge, 2nd edition, 1962.\nGeorge Darmois. Analyseg´en´erale desliaisons stochastiques: etudeparticuli`ere del’analyse\nfactorielle lin´eaire. Revue de l’Institut international de statistique, pages 2–8, 1953.\n34\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nMathias Drton and Thomas S Richardson. Iterative conditional fitting for gaussian an-\ncestral graph models. In Proceedings of the 20th conference on Uncertainty in artificial\nintelligence, pages 130–137, 2004.\nFlorian F Gunsilius. Nontestability of instrument validity under continuous treatments.\nBiometrika, 108(4):989–995, 2021.\nZijian Guo and Dylan S Small. Control function instrumental variable estimation of non-\nlinear causal effect models. Journal of Machine Learning Research, 17(100):1–35, 2016.\nZijian Guo, Hyunseung Kang, T Tony Cai, and Dylan S Small. Confidence intervals for\ncausal effects with invalid instruments by using two-stage hard thresholding with voting.\nJournal of the Royal Statistical Society: Series B (Statistical Methodology), 80(4):793–815,\n2018.\nFernando Pires Hartwig, George Davey Smith, and Jack Bowden. Robust inference in\nsummary data mendelian randomization via the zero modal pleiotropy assumption. In-\nternational journal of epidemiology, 46(6):1985–1998, 2017.\nLeonard Henckel, Martin Buttenschoen, and Marloes H Maathuis. Graphical tools for\nselecting conditional instrumental sets. Biometrika, 111(3):771–788, 2024.\nMiguelAHern´anandJamesMRobins.Instrumentsforcausalinference: anepidemiologist’s\ndream? Epidemiology, pages 360–372, 2006.\nGuido W. Imbens. Instrumental variables: An econometrician’s perspective. Statistical\nScience, 29(3):323–358, 2014.\nGuidoWImbensandDonaldBRubin.Causalinferenceforstatistics, social,andbiomedical\nsciences: An introduction. Cambridge University Press, 2015.\nDominik Janzing and Bernhard Scho¨lkopf. Detecting confounding in multivariate linear\nmodels via spectral analysis. Journal of Causal Inference, 6(1):20170013, 2018.\nHyunseung Kang, Anru Zhang, T Tony Cai, and Dylan S Small. Instrumental variables\nestimation withsomeinvalid instrumentsandits application tomendelianrandomization.\nJournal of the American statistical Association, 111(513):132–144, 2016.\nD´esir´e K´edagni and Ismael Mourifi´e. Generalized instrumental inequalities: testing the\ninstrumental variable independence assumption. Biometrika, 107(3):661–675, 2020.\nToru Kitagawa. A test for instrument validity. Econometrica, 83(5):2043–2063, 2015.\nJuan Lin. Factorizing multivariate function classes. Advances in neural information pro-\ncessing systems, 10, 1997.\nCharles F Manski. Partial identification of probability distributions. Springer Science &\nBusiness Media, 2003.\nTorben Martinussen, Ditte Nørbo Sørensen, and Stijn Vansteelandt. Instrumental variables\nestimation under a structural cox model. Biostatistics, 20(1):65–79, 2019.\n35\nGuo, Li, Huang, Zeng, Geng, and Xie\nAlice Nakamura and Masao Nakamura. On the relationships among several specification\nerror tests presented by durbin, wu, and hausman. Econometrica: journal of the Econo-\nmetric Society, pages 1583–1588, 1981.\nWhitney K Newey. Nonparametric instrumental variables estimation. American Economic\nReview, 103(3):550–556, 2013.\nWhitney K Newey and James L Powell. Instrumental variable estimation of nonparametric\nmodels. Econometrica, 71(5):1565–1578, 2003.\nTom M Palmer, Roland R Ramsahai, Vanessa Didelez, and Nuala A Sheehan. Nonpara-\nmetric bounds for the causal effect in a binary instrumental-variable model. The Stata\nJournal, 11(3):345–367, 2011.\nJudea Pearl. On the testability of causal models with latent and instrumental variables.\nIn Proceedings of the Eleventh conference on Uncertainty in artificial intelligence, pages\n435–443, 1995.\nJudea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press,\nNew York, 2nd edition, 2009.\nSaber Salehkaleybar, AmirEmad Ghassami, Negar Kiyavash, and Kun Zhang. Learning\nlinear non-gaussian causal models in the presence of latent variables. Journal of Machine\nLearning Research, 21(39):1–24, 2020.\nShohei Shimizu. Statistical Causal Discovery: LiNGAM Approach. Springer, 2022.\nShohei Shimizu, Patrik O Hoyer, Aapo Hyv¨arinen, and Antti Kerminen. A linear non-\nGaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7\n(Oct):2003–2030, 2006.\nRicardoSilvaandShoheiShimizu. Learninginstrumentalvariables withstructuralandnon-\ngaussianity assumptions. Journal of Machine Learning Research, 18(120):1–49, 2017.\nRahulSingh,ManeeshSahani,andArthurGretton. Kernelinstrumentalvariableregression.\nAdvances in Neural Information Processing Systems, 32, 2019.\nTea Skaaby, Lise Lotte NystrupHusemoen, TorbenMartinussen, Jacob P Thyssen, Michael\nMelgaard, Betina Heinsbæk Thuesen, Charlotta Pisinger, Torben Jørgensen, Jeanne D\nJohansen, Torkil Menn´e, et al. Vitamin d status, filaggrin genotype, and cardiovascular\nrisk factors: a mendelian randomization approach. PloS one, 8(2):e57647, 2013.\nVP Skitovitch. On a property of the normal distribution. DAN SSSR, 89:217–219, 1953.\nPeter Spirtes. Calculation of entailed rank constraints in partially non-linear and cyclic\nmodels. In Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial\nIntelligence, pages 606–615. AUAI Press, 2013.\nPeter Spirtes and Kun Zhang. Causal discovery and inference: concepts and recent method-\nological advances. In Applied informatics, volume 3, pages 1–28. SpringerOpen, 2016.\n36\nTestability of IV in Additive Nonlinear, Non-Constant Effects Models\nPeter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search.\nMIT press, 2000.\nSeth Sullivant, Kelli Talaska, Jan Draisma, et al. Trek separation for gaussian graphical\nmodels. The Annals of Statistics, 38(3):1665–1685, 2010.\nMaarten J Voors, Eleonora E M Nillesen, Philip Verwimp, Erwin H Bulte, Robert Lensink,\nand Daan P Van Soest. Violent conflict and behavior: a field experiment in burundi.\nAmerican Economic Review, 102(2):941–964, 2012.\nLinbo Wang, James M Robins, and Thomas S Richardson. On falsification of the binary\ninstrumental variable model. Biometrika, 104(1):229–236, 2017.\nFrank Windmeijer, Helmut Farbmacher, Neil Davies, and George Davey Smith. On the use\nof the lasso for instrumental variables estimation with some invalid instruments. Journal\nof the American Statistical Association, 114(527):1339–1350, 2019.\nFrank Windmeijer, Xiaoran Liang, Fernando P Hartwig, and Jack Bowden. The confidence\ninterval methodfor selecting valid instrumentalvariables. Journal of the Royal Statistical\nSociety: Series B (Statistical Methodology), 83(4):752–776, 2021.\nAnpeng Wu, Kun Kuang, Bo Li, and Fei Wu. Instrumental variable regression with con-\nfounderbalancing. InInternational Conference on Machine Learning, pages24056–24075.\nPMLR, 2022.\nFeng Xie, Yangbo He, Zhi Geng, Zhengming Chen, Ru Hou, and Kun Zhang. Testability of\ninstrumental variables in linear non-gaussian acyclic causal models. Entropy, 24(4):512,\n2022.\nQinyi Zhang, Sarah Filippi, Arthur Gretton, and Dino Sejdinovic. Large-scale kernel meth-\nods for independence testing. Statistics and Computing, 28(1):113–130, 2018.\n37",
    "pdf_filename": "Testability_of_Instrumental_Variables_in_Additive_Nonlinear,_Non-Constant_Effects_Models.pdf"
}