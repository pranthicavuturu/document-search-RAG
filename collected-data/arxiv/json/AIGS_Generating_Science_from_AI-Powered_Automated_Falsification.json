{
    "title": "AIGS: GENERATING SCIENCE FROM AI-POWERED",
    "abstract": "Rapiddevelopmentofartificialintelligencehasdrasticallyacceleratedthedevel- opment of scientific discovery. Trained with large-scale observation data, deep neuralnetworksextractthe underlyingpatternsin anend-to-endmannerandas- sisthumanresearcherswithhighly-precisedpredictionsinunseenscenarios. The recentrise of LargeLanguageModels (LLMs) and the empoweredautonomous agentsenablescientiststogainhelpthroughinteractionindifferentstagesoftheir research, including but not limited to literature review, research ideation, idea implementation,andacademic writing. However,AI researchersinstantiatedby foundationmodelempoweredagentswithfull-processautonomyarestillintheir infancy. Inthispaper,westudyAI-GeneratedScience(AIGS),whereagentsin- dependentlyandautonomouslycompletetheentireresearchprocessanddiscover scientificlaws. By revisitingthedefinitionofscientificresearch(Popper, 1935), wearguethatfalsificationistheessenceofbothhumanresearchprocessandthe design of an AIGS system. Through the lens of falsification, prior systems at- tempting towards AI-Generated Science either lack the part in their design, or relyheavilyonexistingverificationenginesthatnarrowtheuseinspecializeddo- mains. Inthiswork,weproposeBABY-AIGS asababy-stepdemonstrationofa full-processAIGSsystem,whichisamulti-agentsystemwithagentsinrolesrep- resenting key research process. By introducing FALSIFICATIONAGENT, which identify and then verify possible scientific discoveries, we empower the system with explicit falsification. Experiments on three tasks preliminarily show that BABY-AIGS couldproducemeaningfulscientificdiscoveries,thoughnotonpar with experienced human researchers. Finally, we discuss on the limitations of currentBABY-AIGS,actionableinsights,andrelatedethicalissuesindetail.1 Hypothesis Falsification Scientific Discovery Geocentric Theory: Astronomy Observation: Final Discovery: Earth is stationary; Earth is rotating; Celestial bodies Celestial bodies revolve around revolve around the Transit of Venus the Sun; Earth; Four Largest Elliptical orbit motion. Circular motion. Satellites of Jupiter ... ... Phases of Venus Geocentric Theory Heliocentric Theory: Mathematical Reasoning: Heliocentric Theory Earth is rotating; Celestial Motion Celestial bodies Diagram: revolve around the Sun; Astronomical Kepler’s Laws Circular motion. Observation of Planetary Mathematical Proof ... Data Motion Figure1:Examplesofscientificresearchprocessesconductedbyhumanresearchers.Explicitfalsi- ficationservesasavitalstagetofalsifyorverifytheproposedhypothesesfromeitherempiricalor theoreticalexperiments,leadingtotheultimatescientificdiscovery. ∗indicatesequalcontribution. 1Official Website: https://agent-force.github.io/AIGS/. Code is released at https://github.com/AgentForceTeamOfficial/Baby-AIGS. 1 4202 voN 71 ]GL.sc[ 1v01911.1142:viXra",
    "body": "AIGS: GENERATING SCIENCE FROM AI-POWERED\nAUTOMATED FALSIFICATION\nZijunLiu1∗,KaimingLiu1∗,YiqiZhu1∗,XuanyuLei1,2∗,ZonghanYang1∗,\nZhenheZhang1,PengLi2,YangLiu1,2\n1DepartmentofComputerScience&Technology,TsinghuaUniversity\n2InstituteforAIIndustryResearch(AIR),TsinghuaUniversity\nABSTRACT\nRapiddevelopmentofartificialintelligencehasdrasticallyacceleratedthedevel-\nopment of scientific discovery. Trained with large-scale observation data, deep\nneuralnetworksextractthe underlyingpatternsin anend-to-endmannerandas-\nsisthumanresearcherswithhighly-precisedpredictionsinunseenscenarios. The\nrecentrise of LargeLanguageModels (LLMs) and the empoweredautonomous\nagentsenablescientiststogainhelpthroughinteractionindifferentstagesoftheir\nresearch, including but not limited to literature review, research ideation, idea\nimplementation,andacademic writing. However,AI researchersinstantiatedby\nfoundationmodelempoweredagentswithfull-processautonomyarestillintheir\ninfancy. Inthispaper,westudyAI-GeneratedScience(AIGS),whereagentsin-\ndependentlyandautonomouslycompletetheentireresearchprocessanddiscover\nscientificlaws. By revisitingthedefinitionofscientificresearch(Popper, 1935),\nwearguethatfalsificationistheessenceofbothhumanresearchprocessandthe\ndesign of an AIGS system. Through the lens of falsification, prior systems at-\ntempting towards AI-Generated Science either lack the part in their design, or\nrelyheavilyonexistingverificationenginesthatnarrowtheuseinspecializeddo-\nmains. Inthiswork,weproposeBABY-AIGS asababy-stepdemonstrationofa\nfull-processAIGSsystem,whichisamulti-agentsystemwithagentsinrolesrep-\nresenting key research process. By introducing FALSIFICATIONAGENT, which\nidentify and then verify possible scientific discoveries, we empower the system\nwith explicit falsification. Experiments on three tasks preliminarily show that\nBABY-AIGS couldproducemeaningfulscientificdiscoveries,thoughnotonpar\nwith experienced human researchers. Finally, we discuss on the limitations of\ncurrentBABY-AIGS,actionableinsights,andrelatedethicalissuesindetail.1\nHypothesis Falsification Scientific Discovery\nGeocentric Theory: Astronomy Observation: Final Discovery:\nEarth is stationary; Earth is rotating;\nCelestial bodies Celestial bodies revolve around\nrevolve around the Transit of Venus the Sun;\nEarth;\nFour Largest Elliptical orbit motion.\nCircular motion. Satellites of Jupiter ...\n...\nPhases of Venus Geocentric Theory\nHeliocentric Theory: Mathematical Reasoning: Heliocentric Theory\nEarth is rotating; Celestial Motion\nCelestial bodies Diagram:\nrevolve around the\nSun;\nAstronomical Kepler’s Laws\nCircular motion. Observation of Planetary Mathematical\nProof\n... Data Motion\nFigure1:Examplesofscientificresearchprocessesconductedbyhumanresearchers.Explicitfalsi-\nficationservesasavitalstagetofalsifyorverifytheproposedhypothesesfromeitherempiricalor\ntheoreticalexperiments,leadingtotheultimatescientificdiscovery.\n∗indicatesequalcontribution.\n1Official Website: https://agent-force.github.io/AIGS/. Code is released at\nhttps://github.com/AgentForceTeamOfficial/Baby-AIGS.\n1\n4202\nvoN\n71\n]GL.sc[\n1v01911.1142:viXra\nCONTENTS\n1 Introduction 3\n2 TheDevelopmentofAI-AcceleratedScientificDiscovery 4\n2.1 AIasaPerformanceOptimizer:DiscoveriesinSpecificTasks . . . . . . . . . . . 4\n2.2 AIasaResearchAssistant: Co-pilotinHuman-AICollaboration . . . . . . . . . . 5\n2.3 AIasanAutomatedScientist:TowardsEnd-to-endScientificDiscovery . . . . . . 6\n2.4 AIformsaResearchCommunity:EnableAcademicSwarmIntelligence . . . . . . 6\n3 BABY-AIGS:ABabyStepTowardsFull-ProcessAIGS 6\n3.1 DesignPrinciplesofaFull-ProcessAIGSSystem . . . . . . . . . . . . . . . . . . 6\n3.2 BABY-AIGSSystemDesign . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3 DetailedImplementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3.3.1 Domain-SpecificLanguage(DSL) . . . . . . . . . . . . . . . . . . . . . . 9\n3.3.2 PROPOSALAGENT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.3.3 REVIEWAGENT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.3.4 Multi-SamplingStrategy . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.3.5 FALSIFICATIONAGENT . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.4 AutomatedFull-ProcessResearchExperiment . . . . . . . . . . . . . . . . . . . . 15\n3.4.1 SelectedResearchTopics. . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.4.2 EvaluationSettings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.5 QuantitativeandQualitativeAnalysis . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.6 Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4 LimitationsandActionableInsights 19\n5 EthicsandImpactStatement 20\n5.1 PotentialNegativeImpactsofAIGSSystems . . . . . . . . . . . . . . . . . . . . 20\n5.2 StrategiesforResponsibleandEthicalDevelopmentofAutomatedResearchSystems 21\n6 Conclusion 22\nA ImplementationDetailsoftheBABY-AIGSsystem 29\nA.1 Research-AgnosticImplementation. . . . . . . . . . . . . . . . . . . . . . . . . . 30\nA.2 Research-SpecificImplementation . . . . . . . . . . . . . . . . . . . . . . . . . . 30\nB ExperimentDetails 31\nB.1 GuidelinesforHumanEvaluators. . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nB.2 APICostsoftheFull-ProcessResearchExperiment . . . . . . . . . . . . . . . . . 31\nB.3 DSLDemonstrationsforDifferentResearchTopics . . . . . . . . . . . . . . . . . 31\nC PromptingStructure 33\n2\n1 INTRODUCTION\nDeep learning has revolutionized scientific research (LeCunetal., 2015; Vaswanietal., 2017;\nJumperetal., 2021; Achiametal., 2023). Leveragingthe enormousamountof experimentaldata,\ndeeplearningmethodsextracttheunderlyingpatternsinanend-to-endmannerandeffectivelygen-\neralizetounobservedscenarios. Thebreakthroughsfromdeeplearninginscientificdomains,such\nasproteinstructureprediction(Jumperetal.,2021),gravitationalwavedetection(George&Huerta,\n2018), and plasma control(Degraveetal., 2022), have received award-winningrecognition. As a\nresult,AIforSciencehasemergedasahighly-regardedresearchfield(Wangetal.,2023a).\nIn the paradigm of AI for Science, AI primarily serves as a tool to assist researchers in making\ndiscoveries. Withtherapiddevelopmentoffoundationmodelsandautonomousagents(Parketal.,\n2023), AI techniques nowadays boast the capabilities of general-purposed textual understanding\nand autonomousinteraction with the externalworld. These capabilities lead to the successful ap-\nplicationsof AI-as-research-assistants, rangingfrom single-cell analysis(Hou&Ji, 2024) to drug\ndiscovery (Wangetal., 2023b). The capability of providing research assistance leads to a more\nambitiouschallenge: Canfoundationmodel-poweredagentsbeautonomousresearchers, indepen-\ndently completing the entire process of scientific discovery, thereby transforming AIforScience\nintoAI-GeneratedScience(AIGS)?\nWhen constructing an AIGS system with full-process autonomy, the desiderata of the system\ndesign should refer to the definition of the scientific research process itself. As stated by Popper\n(1935),scientificresearchfollowsasystematicprocessofproposingnovelhypotheses,conducting\nexperiments through trial and error, and falsifying these hypotheses to conclude. While it is\nwidely-believedthatcreativityisindispensableintheprocessofresearch-whichisalsoaccounted\nin previous work (Sietal., 2024) - the central component of scientific research is falsification:\ndesigning and executing experiments to validate or refute hypotheses, and falsified hypotheses\npose positive contributions to scientific progress as well2. Moreover, experienced researchers\naccumulatepracticalskillsorreusableworkflows(Giletal.,2007)fromhands-onexperimentation,\nwhicheasesthedesignandexecutionofexperimentsandhypothesisfalsification. Theabstraction\nof workflows in experiments enables effective reuse, which reflects a high level of executability\nin scientific research. To recapitulate, a creative idea is the beginning of a piece of scientific\nresearch, whichis followedby experimentsandanalysesto be conducted;executabilityformsthe\nbasis for falsification, and a sequence of logically consistent falsification processes turns a novel\nidea into scientific discoverieswith genuine creativity. As a result, falsification is the foundation\nof AI-Generated Science, pillared by experimenting scaffolds accounting for executability and\ntargetingattheultimategoalofresearchcreativity.\nSeveral preliminary works have been proposed to explore the potential of AIGS, which can be\nroughly divided into three lines. In the first line, researchers evaluate and improvethe capability\nof LLMs to generate research ideas with high creativity (Sietal., 2024; Huetal., 2024b). The\nsecond line emphasizes the executability of research experiments, e.g., benchmarks like MLA-\ngentBench (Liuetal., 2023) and MLE-Bench (Chanetal., 2024) aim to evaluate the agentic\nability of LLMs to achieve high performance on the provided benchmarks via code generation.\nThese two lines of research investigate distinct sub-stages in the research process, failing to\naddress the full-process autonomy. The third line of research attempts to construct end-to-end\nAIGS systems that cover both creativity and executability. MLR-copilot (Lietal., 2024b) takes\nexisting research papers as input, and produces execution results by both generating ideas and\nimplementing experiments. AI Scientist (Luetal., 2024) further claims to be able to organize\nthe generated ideas and experimental results into research papers as the output. This line of\nresearch arouses significant excitement in the community, but is feedbacked with controversy:\nCriticisms include the incremental nature of the generated knowledge “tweaks”, as well as the\npoorqualityofthegeneratedcodeandthepaperpresentation3. Indeed,asfurtherbenchmarkedby\nDiscoveryWorld (Jansenetal., 2024) and ScienceAgentBench (Chenetal., 2024d), an automatic\nAIGS system that produces novel research in an end-to-end manner is still in the early stages,\nwith significant gaps remains underexplored, especially in the area of autonomous falsification.\nFurthermore, while specialized systems like AlphaGeometry (Trinhetal., 2024) have achieved\nstrikingdomain-specificperformances,theyrelyheavilyontheexistingverificationengines,which\nalleviatetheneedofautonomousfalsificationbyAIitself.\n2https://ml-retrospectives.github.io/.\n3https://x.com/jimmykoppel/status/1828077203956850756.\n3\nIn this work, we initiate BABY-AIGS, our baby-stepattempt toward a full-processAIGS system.\nBABY-AIGS comprisesseveralLLM-poweredagents, including PROPOSALAGENT, EXPAGENT,\nREVIEWAGENT, FALSIFICATIONAGENT, etc., each responsible for distinct stages within the re-\nsearchworkflow,mimickingthefull-processhumanresearchthatfalsifieshypothesesbasedonem-\npiricalortheoreticalresultsforscientificdiscoveries. BABY-AIGSoperatesintwophases: thefirst\nphaseiterativelyrefinesproposedideasandmethodsthroughenrichedfeedback,incorporatingex-\nperimentaloutcomes,detailedreviews,andrelevantliterature.Thesecondphaseemphasizesexplicit\nfalsification,akeyfeatureabsentinpriorsystems(Luetal.,2024),executedbyFALSIFICATIONA-\nGENT. Basedonexperimentalresultsrelatedtotheproposedmethodology,theagentidentifiescrit-\nicalfactorslikelycontributingtonotableexperimentalphenomena,formulateshypotheses,andulti-\nmatelyproducesscientificinsightsverifiedthroughablationexperiments.Additionally,weintroduce\naDomain-SpecificLanguage(DSL)(Merniketal.,2005)forPROPOSALAGENTtoarticulateideas\nandmethodologiesinanexecutableformat,enhancingresearchexecutability—particularlyduring\nexperiments.Weobservethatmulti-samplingproposalscombinedwithre-rankingbasedonvalida-\ntionbenchmarkscanenhancethecreativityofmethodologiesdevelopedduringBABY-AIGS’sfirst\nphase.WeapplyBABY-AIGSacrossthreetasks:dataengineering,self-instructalignment,andlan-\nguagemodeling.PreliminaryexperimentalresultsindicatethatBABY-AIGScanautonomouslypro-\nducemeaningfulscientificdiscoveriesfromautomatedfalsification,supportedbyqualitativeanaly-\nsis. We alsoobserveconsistentperformanceimprovementsduringiterativerefinementofmethods\nproposed by BABY-AIGS. Nevertheless, current performanceremains below the results achieved\nbyexperiencedresearchersintopacademicvenues,suggestingavenuesforfurtherenhancement.\n2 THE DEVELOPMENT OF AI-ACCELERATED SCIENTIFIC DISCOVERY\nIn this section, we review and envision the developmentof AI-accelerated scientific discovery as\nfourparadigms(Figure2): (I) AI asa PerformanceOptimizer, where deep neuralnetworksare\ntrainedwithlarge-scaleobservationdatainaspecificscientificproblemtoextractthepatternsinan\nend-to-endmanner.Inthisparadigm,theAItechniquesareusedtooptimizethespecificprediction/\nregressionperformanceinthepre-definedscientificproblemwiththeconsiderationofout-of-domain\ngeneralization. (II) AI asa ResearchAssistant, where LLM-drivenresearchcopilotsare usedto\nassistthehumanresearchprocess.ThesynergybetweenParadigm(I)and(II)formstheAI-powered\naccelerationofscientificdiscoverynowadays. (III)AIasanAutomatedScientist. Inthisregime,\nfoundationmodelempoweredagentswithscientist-likebehaviorshouldcompletetheentireresearch\nprocess, ranging from the initial idea proposal to the ultimate delivery of the scientific findings.\n(IV)AIFormsaResearchCommunity. Upontheprosperityoffully-autonomousAIresearchers\ndepictedinthepreviousstage,weenvisionthecollaborationsamongtheagenticresearchersfoster\nanAI-formedresearchcommunity.\nHuman Literature Review\nSpecific Task Research Ideation\nPerformance\nAI Algorithm Idea Implementation\nOptimization\nPre-Defined Env Academic Writing\nAI Assistant Evaluation\nAI as a Performance Optimizer AI as a Research Assistant\nAgent Agent\nAI arXiv AI Github AI Social Media\nAgent Agent Scientific\nDiscovery AI OpenReview AI Conference ...\nAgent Agent\nAI as an Automated Scientist AI Forms a Research Community\nFigure2:OverviewofthefourparadigmsofAI-acceleratescientificdiscoverysystems.\n2.1 AI AS A PERFORMANCE OPTIMIZER: DISCOVERIES IN SPECIFIC TASKS\nWith the rise of deep learning, AI has significantly impacted scientific discoveries across vari-\nousfields, particularlyin optimizingspecific tasks by exploringwell-definedsearch spaces or ex-\ntracting patterns from piles of data. Utilizing specialized deep learning models, scientific break-\n4\nthroughs continue to emerge across diverse fields, including accurate protein structure predic-\ntion(Jumperetal.,2021;Abramsonetal.,2024),drugdiscoveryandmaterialsdesign(Gilmeretal.,\n2017; Juanetal., 2021), and the simulation of physical systems (Sanchez-Gonzalezetal., 2020).\nMoreover,a longstandingopenproblemin mathematicshasbeenresolvedthroughtraininga spe-\ncializedTransformer-basedexpert(Alfaranoetal.,2024). Itiswidelyrecognizedthatdeeplearning\nmodels are highly effective in learning representationsand patterns from data, enabling scientific\ndiscoverywhenappropriatelyguided.\nLarge Language Models (LLMs), equipped with extensive world knowledge and advanced rea-\nsoning, are emerging as increasingly creative and autonomous agents. They have demon-\nstrated remarkable proficiency in autonomously developing evolutionary strategies for instruc-\ntion datasets (Zengetal., 2024), identifying and rectifying their own weaknesses (Chengetal.,\n2024; McAleeseetal., 2024), and optimizing organizational structures for improved effi-\nciency (Zhangetal., 2024a; Huetal., 2024a), highlighting their potential for performance opti-\nmizationthroughstructuredsearch. Beyondlanguagetasks, theircreativitycontributesto impres-\nsivediscoveriesinscientificfields. Viascientificallyoriented,logicallyorganizedsearches,LLMs\ncanbeguidedtodiscovermathematicalsolutions(Romera-Paredesetal.,2024)andphysicalequa-\ntions (Maetal., 2024; Shojaeeetal., 2024). Augmented with specialized tools and verification\nengine, LLMs are capable of solving advanced geometry problems (Trinhetal., 2024), design-\ning chemical reactions (Chenetal., 2024a) and discoveringnovelmaterials (M.Branetal., 2024;\nGhafarollahi&Buehler,2024).\n2.2 AI AS A RESEARCH ASSISTANT: CO-PILOT IN HUMAN-AI COLLABORATION\nEquippedwithexpandingscientificknowledgeandgenerativecapabilities,LLMsgraduallyexhibit\ngreatpotentialtoassistresearchersatvariousstagesoftheresearchprocess.\nLiteraturereviewisafundamentalbuttediousstepforscientificresearch,highlightingtheneedfor\nautonomousagents for this task. AdvancedLLMs are employedto identify relevantliterature for\nagivenresearchtopicandgeneratestructuredsummaries(Haman&Sˇkoln´ık,2024;Huang&Tan,\n2023). For instance, Sharmaetal. (2021) introducesa retrieval-augmentedframeworkto produce\nreliablesummariesbasedonlateststudies.Furthermore,Hsuetal.(2024)utilizesLLMstoorganize\nscientificstudieswithinhierarchicalstructuresandLietal.(2024d)developsanagenticpipelinethat\nproducescomparativeliteraturesummariesguidedbyhumanworkflows. Insummary,LLM-based\nagentshavedemonstratedthecapabilitytoproducereadableanddetailedliteraturereviews.\nForresearchideation,LLMsareemployedtogeneratereasonablehypotheses(Wangetal.,2024a;\nQietal.,2023;Zhouetal.,2024)basedoninternalknowledgeandsupplementaryinputs. Tocom-\nparethequalityofLLM-generatedideaswith humanexperts,a large-scalehumanstudy(Sietal.,\n2024)findsthatLLMscangenerateresearchideasofhighernoveltybutslightlyweakerfeasibility.\nFurthermore,Kumaretal.(2024)andGirotraetal.(2023)evaluatetheideagenerationcapabilities\nofdifferentLLMsand recognizetheirpotentialto serveasthe sourcesof inspiration. To enhance\nLLM-driven ideation, Baeketal. (2024), Nigametal. (2024a) and Nigametal. (2024b) develop\nmulti-agentideationframeworksbasedonscientificliterature,generatingnovelresearchproposals\nto acceleratethelife-cycleof researchprocess. Despitethese advancements,generatingideasthat\nbalancebothnoveltyandfeasibilityremainsasignificantchallengeforLLM-basedagents(Sietal.,\n2024). Toevolveinitialproposalsintovalidatedknowledgethereforedemandssubstantialeffort.\nTheattemptsinAI-assistedideaimplementationandauto-experimentationareusuallyconducted\nas repo-levelcodingtasks, given the growingcodingcapabilities of LLMs. Focused on research-\nrelated repo-level coding, Jimenezetal. (2024), Liuetal. (2023) and Chanetal. (2024) present\nchallengingcodingbenchmarkstargetingmachinelearningandsoftwareengineeringtasks. Mean-\nwhile,Yangetal.(2024a),Wangetal.(2024b)andTaoetal.(2024)leverageagenticcollaboration\ntoautomatedcodingfromlanguageinstructions,offeringpromisingavenuestoreduceresearchers’\ncoding workloads and enhance efficiency. However, the vision for agents to autonomously im-\nplementnovelideasandconductexperimentsend-to-endimposessignificantlyhigherdemandson\ncodingagents.CurrentchallengesincludearelativelylowsuccessrateLuetal.(2024)andfrequent\nmisalignmentbetweenproposedideasandtheircodingimplementations,highlightingtheneedfor\nimprovementsinbothexecutionreliabilityandalignmentwithresearchobjectives.\nIn the realm of academic writing, LLMs can be utilized for drafting structured outlines, refin-\ning human-written texts and presenting research findings. Recent studies (Liangetal., 2024b;\nGeng&Trotta, 2024) have demonstrated a steady increase for LLM usage in scientific writing.\nThis trend presents both opportunities and challenges for academia. When properly used, LLMs\n5\ncould improve research efficiency and presentation; But when misused, risks emerge as well in\ntermsofresearchintegrity. Therefore,effectiveoversightthroughdetectionstrategies(Liangetal.,\n2024a; Yangetal., 2024b; Ghosaletal., 2023) and watermarking techniques (Kirchenbaueretal.,\n2023;Zhaoetal.,2023;Zhangetal.,2024b)isbothbeneficialandnecessary.\nAdditionally, following LLM-as-judge methods (Zhengetal., 2023), LLM-based agents are em-\nployedforcomprehensiveevaluationonresearchoutputs(Luetal.,2024;Lietal.,2024b). Com-\nparingmodel-generatedreviewswithexpertevaluations,researchershaveevaluatedthecapabilities\nof LLMs to provide insightful and high-quality reviews by constructing meticulously annotated\ndatasets(Duetal., 2024) or trainingpreferencemodels(Tyseretal., 2024). With multi-agentcol-\nlaboration to promote in-depth analysis and constructive feedback, D’Arcyetal. (2024), Jinetal.\n(2024)andYuetal.(2024)developLLM-poweredagentpipelinestoperformpaperreviews,helping\nresearchersimprovethequalityoftheirpapers. Furthermore,Sunetal.(2024)introducesareview-\ningtooldesignedtosupportreviewerswithknowledge-intensiveannotations. Inanotabledevelop-\nment,ICLRconferenceadoptrevieweragentstoprovideconstructivefeedbackonhuman-submitted\nreviews,showcasingapromisingapplicationofAI-assistedreviewing4. Recently,researchersalso\nconstructed benchmarks for AI as a research assistant at more than one stages above (Louetal.,\n2024). Overall,itispromisingforLLMstoassistresearcherswithreliableresearchfeedback.\n2.3 AI AS AN AUTOMATEDSCIENTIST: TOWARDSEND-TO-ENDSCIENTIFIC DISCOVERY\nStructuredinwell-organizedagenticpipelines,LLMsareincreasinglycapableoftacklingcomplex\ntaskscollaboratively,withend-to-endscientificresearchbeingoneofthemostambitiousandchal-\nlenging applications. For instance, Luetal. (2024) develops an iterative multi-agent framework\nthat supports the entire research process, from proposing novel ideas to presenting polished find-\nings.Similarly,Lietal.(2024b)introducesanautomatedresearchsystemformachinelearning,and\nManningetal.(2024)employsLLMstosimulatescientistsforsocialscienceresearch. Beyondre-\nsearchsystems,Jansenetal.(2024)proposesasimulationenvironmentdesignedtochallengeagents\ninautomatedscientificdiscovery.Despitetheseadvancements,currentend-to-endresearchsystems\nstill fall short of generating falsifiable scientific findings, constrained by the capabilities of both\ndesignedframeworkandfoundationmodels. Whilepreviousresearch(Luetal.,2024)hasyielded\nwell-formulatedoutcomes,thevisionofautomatedsciencediscoverystillrequiresfurtherefforts.\n2.4 AI FORMS A RESEARCH COMMUNITY: ENABLEACADEMIC SWARMINTELLIGENCE\nThroughouthumanhistory,scientificprogresshasbeengreatlydrivenbycollaboration,connection,\nanddiscussionamongscientists,highlightingthepowerofavibrantresearchcommunity. Wepro-\nposethataresearchcommunityofAIscientistscouldsignificantlyacceleratethepaceofautomated\nscientific discovery. For agenticcommunityconstruction,LLM-drivenagentscan be organizedto\ngeneratebelievable,human-likebehaviors(Parketal.,2022;Gaoetal.,2024;Parketal.,2023)and\ntoperformspecificrolesasassigned(Lietal.,2024a;Huaetal.,2023;Xuetal.,2023). Although\nagent-basedsimulationsofresearchcommunitiesareinanearlydevelopmentalstage,theyrepresent\napromisingavenueforthefutureoffullyautomated,AI-drivenresearch.\n3 BABY-AIGS: A BABY STEP TOWARDS FULL-PROCESS AIGS\nInthissection,weelaboratehowababy-stepsystemtowardsthefull-processAIGSisdesigned,in\ntermsofdesignprinciples,overallsystemdesign,anddetailedimplementations.\n3.1 DESIGN PRINCIPLES OF AFULL-PROCESS AIGSSYSTEM\nThe typical research process for human scientists (Popper, 1935) generally consists of two main\nstages: the pre-falsificationstage, whichencompassesexplorationofresearchideas, refinementof\nmethodologies, and theoretical or empirical analysis, and the falsification stage, which involves\nhypothesizingscientificlawsandvalidatingthesehypothesesbasedontheoreticalorempiricalfind-\nings. In research fields like machine learning, empirical results for falsification process, i.e. ab-\nlationstudies, are collectedafterresearchersdesignandbuilda system, and conductexperiments.\nIn contrast, other fields operate differently. For example, in physics or biology, empirical results\nare gatheredfrominstrumentsor equipmentafter the experimentaldesignand execution,while in\nmathematicsor the humanities, theoreticalinsights are often derived throughlogicalreasoning or\n4https://blog.iclr.cc/2024/10/09/iclr2025-assisting-reviewers.\n6\nHistory: FalsificationAgent\nProposalAgent ExpAgent ReviewAgent\nTurn1: S Sig cn reif eic na in nc ge\nAblationExp1\nIdea\nIdea1: Result1: Review1:\nAblationExp2\nProposal ExpResult ExpReview Result Discovery ...\nMethodology MetricValue ProposalReview Review\nCandidate1: AblationExpT\nKey Factors\nDSL ExpLogging Suggestion\n... ... ...\nTurn2 Hypothesis ExpAgent\n...\nIdea2 Result2 Review2 Turn3 DiscCandK Verification\n... ... ... ...\nIdeaN ResultN ReviewN TurnM Scientific Discovery\nOptional\nLiteratureAgent SecurityAgent EnvironmentAgent Domain-specific ExpAgent Human Interface\nModule\nFigure 3: Overview of our BABY-AIGS system design. The left part denotes Pre-Falsification\nphase,wherePROPOSALAGENTiterativelyrefinetheproposedideaandmethodologybasedonem-\npiricalandverbosefeedbackfromEXPAGENT,REVIEWAGENT,etc.Theiterativeprocesssummons\nmulti-turnlogsasthehistorycontext,basedonwhichFALSIFICATIONAGENTcouldproducescien-\ntificdiscoveryintheFalsificationphase,asshownintherightpart. Othermodulesareoptionalfor\ntheautomatedfull-processresearch.\nliteraturereviewratherthanempiricalexperimentation. Theserootfalsificationprocessesofdiffer-\nent subjects in distinct knowledgesource. In this work, we primarily focuson empirical subjects\nthatrequiresactualimplementationofthemethodologyofaresearchideatoobtainempiricalresults\nforfalsificationprocess,e.g.,machinelearning,andleaveothervenuesforfuturework.\nHumanscientificresearchworkflowabovereflectsthedesignprinciplesofafull-processAIGSsys-\ntem, which are falsification, creativity, and executability. Each of the principle could be bridged\nwith a specific stage in the researchworkflow: (1) Ablationstudiesare fundamentallyestablished\nuponfalsification,verifyinganykeyfactorsthatcontributetosignificantexperimentalresults. (2)\nToachievesmoothandconsistentexperimentation,weemphasizetheimportanceofexecutabilityof\ntheproposedmethodology,whichservesasthebasisforcollectingempiricalresultsforbothmethod\nrefinementand ablation studies. (3) Creativity of the proposedidea is the overallobjectiveof the\nresearchprocess,whichcouldbeachievedthroughidearefinementandbeidentifiedbyfalsification\nprocess. Weespeciallyarguethattheprocessoffalsificationisequally,ifnotmore,criticalin\nAI-poweredautomatedscientificdiscoverysystems,giventhathumantrustinAI-generatedfind-\ningsreliesheavilyonaconvincingfalsificationprocessthatensuresscientificrigorandtransparency.\nIn sum, falsification is the foundation of a full-process AIGS system, pillared by experimenting\nscaffoldsaccountingforexecutabilityandtargetingattheultimategoalofhighresearchcreativity.\n3.2 BABY-AIGS SYSTEMDESIGN\nHeadingtowardsafull-processsystemforautomatedscientificdiscovery,wepresentthedesignof\nBABY-AIGSsysteminthissection. Weimitatethepracticeofhumanresearchersandshapeitinto\nanLLM-poweredmulti-agentsystem. Andwealsotakeintoaccountthecapacityandbehaviorsof\ncurrentfoundationmodelstoensuretheexecutabilityinimplementation.\nThe overall input for the system would be the topic of the research field, an accessible and con-\nfigurableexperimentenvironment,andotheroptionalresourceslikealiteraturebase;andthefinal\noutcomewouldbeaverbalscientificdiscoveryandthefalsificationprocessthatsupportorfalsifyit.\nFollowingtheprinciplesinSection3.1,theBABY-AIGSsystemoperatesintwophases(Figure3):\n1. Pre-Falsification:Thisphasecontainsseveralstages,suchasideaformation,methodology\ndesign, experiment execution, result analysis, etc., and operates iteratively for M turns,\naiming to explore and refine the proposed idea and method through feedback including\nexperimentaloutcomes,reviews,etc.Specifically,theexperimentalresultsofturn0isfrom\natrivialmethodologyatthedefaultsetting,e.g.,nooperation,identicalmapping,etc. The\nmulti-turnlogofagentcommunicationsisrecordedforFalsification.Forbetterefficiency,\n7\nthisphasecouldbeconductedinparallelinN threadsbysamplingmultipletimes,andthe\nbestonesforthenextphasecouldbeidentifiedwithexperimentalresults.\n2. Falsification: This phase aims to explicitly execute falsification by automating ablation\nstudies. The agent hypothesizes on what key factors are and how they might related to\nsignificantexperimentalphenomenon,andtheonespassT designedablationexperiments\nareverifiedasfinalscientificdiscoveries.ThiscouldbealsobeK-parallel.\nInthefollowingsections, weelaborateimportantcomponentsofour BABY-AIGS system. Ahead\nofspecific modules,we introducetheDomain-SpecificLanguage(DSL) (Merniketal., 2005). In\nan BABY-AIGS system, the DSL actsacriticalroleto ensuretheautomatedpipelineiserrorless.\nSpecifically, the DSL is a human-designeddescriptivelanguagewhich can help interpretthe pro-\nposedideaandmethodologyintoexecutableexperimentalinstructionsthroughapre-definedaction\nspace. Forinstance,inadeeplearningtask,theDSLcandirectlybethecodesthatarrangetraining\nscheduleofamodel;Whileinachemistryexperiment,theDSL canbetheinterfacewithacertain\ninstrumentor material. Consequently, the DSL bridgesthe gap between formulationof proposed\nideaandexperimentation,aligningtheBABY-AIGSsystemtotheexecutabilityprinciple.\nHere,webrieflydepictthemodulesthatconstructthepipelineofBABY-AIGS:\n• PROPOSALAGENTisthemoduletoproposeideasandmethodswithinoursystem. Ittakes\nthedetaileddescriptionofthetask, therecordofpastexperiments,andthereviewgener-\nated by REVIEWAGENT as input, and outputs a proposalcontaining the idea, verbaland\nDSL-formatmethodology,andothernecessarycomponentstocarryouttheexperimentfor\nEXPAGENT.ItcoulditerativelyinteractwithEXPAGENTtorefineitsproposalinorderthat\ntheexperimentcanbesuccessfullycompletedbasedonitsproposal.\n• EXPAGENTisresponsibleforexperimentexecutionintheBABY-AIGSsystem.Itreceives\nthe proposalfrom PROPOSALAGENT and interprets DSL the componentsrelevantto the\nexperimentinto executable code. After execution, it transmits the experimentalresult as\nwellasthewholeprocessoftheexperimenttoREVIEWAGENTforreviewandanalysis.\n• REVIEWAGENT reviewsthe proposedidea andmethodbased onthe empiricalresults. It\ntakesthewholerecordofboththeexperimentsandtheproposalsasinputs,andgenerates\nthe multi-granularreview content. The review is then returnedto PROPOSALAGENT for\nthenextiterationofrefinement.Throughthisiterativeprocessbetweenagentsaboveinthe\nPre-Falsificationphase,creativityoftheproposedideaevolvesintandem.\n• FALSIFICATIONAGENTisresponsiblefordoingtheablationstudiesandderivingscientific\ndiscoveries as the final outcome. FALSIFICATIONAGENT takes the multi-turn log of all\notheragentsasinput. IthasaccesstotherecordofthewholeprocessofPre-Falsification\nphase, and hypothesize possible key factors influencing significant experimental phe-\nnomenonbased onempiricalresults. Then, itdesignsandconductsablationexperiments\nforT timestoverifythehypothesis,leadingtofinalscientificdiscoveries.\n• Other optional modules include LITERATUREAGENT, SECURITYAGENT, ENVIRON-\nMENTAGENT, DOMAIN-SPECIFIC EXPAGENT, and HUMAN INTERFACE. LITERA-\nTUREAGENT is responsible for gathering and providing relevant literature to support all\nother agents. SECURITYAGENT ensures safe experiment execution by identifying and\npreventingactions that may pose potential hazards or infringe upon intellectual property\nrights. ENVIRONMENTAGENT creates simulated environments to facilitate the testing\nand refinement of ideas, enabling more controlled and accurate scientific discoveries.\nDOMAIN-SPECIFIC EXPAGENT is a customizable agent tailored for specific fields.\nHUMAN INTERFACE allows different agents in the system to ask human researchers for\nhelpwhennecessary.\nWealsoacknowledgethattheimplementationofBABY-AIGSatthecurrentstagehasvariouslim-\nitations towards a general functionable full-process AIGS system. In Section 4, we outline these\nlimitationsanddiscussactionableinsightsforfutureimprovements.\n3.3 DETAILEDIMPLEMENTATION\nIn the following sections, we elaborate on the the detailed implementation of our AIGS system\nthroughDSL,multi-samplingstrategy,andthreemainagents:PROPOSALAGENT,REVIEWAGENT,\nandFALSIFICATIONAGENT. Therestofoptionalmoduleshavebeenomittedforthesakeofclarity.\nIn order to aid in the elaboration of the following sections, we present the research topic of data\n8\nDSL Domain Specific Natural Language\nLanguage LLM Generated\nFlexible and Language agents can gather high-quality trajectories by adjust-\nFully Executable ing actions in the original ReAct sequence and ...\nCoding Language Coding Language\nLLM Generated\nChallenging to Achieve\nCL Error-free Implementations # main.py # trajectory.py\nfrom trajectory import \\ import random\nNL random_truncate, resimulate ...\nNatural Language from llm_handler import \\ def secondary_simulation(traj):\nNon-executable call_llm return [step / (random. \\\nFormalization Degree randint(0, 5)) for step in traj]\ndef main():\nPre-Defined Domain Specific Language LLM Generated traj = random_truncate() # llm_handler.py\nFramework Settings: { resimulated_traj = \\ ...\nMethod: Bootstrap / ... “Method”: “Bootstrap”, resimulate(traj)\nBenchmark: AlfWorld / ... “Benchmark”: “AlfWorld”, ... Runtime Logging\n“Pseudocode”: “```python Traceback:\nAvailable Functions: new_traj = random_truncate() def generate_prompt(traj): ...\nrandom_truncate(param) new_traj = resimulate() ... File \"trajectory.py\", line 38 ...\nre_simulate(param) prompt = ‘’ return [step / ...\ncall_llm(param) new_traj = call_llm(prompt)```” if __name__ == \"__main__\": ZeroDivisionError:\n... } main() division by zero\nFigure 4: The relationship between formalization degree and system executability when express-\ning ideas through Natural Language (NL), Coding Language (CL), and Domain-Specific Lan-\nguage(DSL),illustratedwithexamples. NLexpressesideasinthesimplestandmostflexibleform\nbutisnon-executable;CLoffersgreaterprecisionbutischallengingtoachieveerror-freeimplemen-\ntation;DSLachievesabettertradeoffbetweenflexibilityandexecutability.\nengineering(Liuetal.,2024;Chenetal.,2024b;Lietal.,2024c;Zhaoetal.,2024),whichrequires\nBABY-AIGS to identifykeydistinguishingfeaturesofdatasets, andfilter andextracthigh-quality\ndatasubsets. ImplementationdetailsareelaboratedinAppendixAandAppendixC.\n3.3.1 DOMAIN-SPECIFIC LANGUAGE (DSL)\nA domain-specific language (Merniketal., 2005)\nPre-Defined Data Engineering\nis created specifically for a particular application Framework Settings:\ndomain,providinggreaterexpressivenessandease Paradigm: Data Sample Rating & Filtering # Score each data\npoint and filter the data based on the scores.\nof use within that domain compared to general-\npurpose languages, traditionally for programming Parameters:\nPrinciples: Prompt content of principles for scoring model;\nlanguages. However, we observed that the situa- Number: Total count of principles;\ntion is the same for agents in the AIGS systems. Threshold: The least surpassed number of principles to pass;\nRatio: The most proportion of data remained after filtering.\nWhen conducting scientific research, agents have\naccesstoawideanddiverseactionspace,making Pre-Defined Self-Instruct Alignment\nitchallengingtoperformerror-freelong-sequence Framework Settings:\nParadigm: Instruction Data Synthesis # Synthesize training\nactionsforeverystageoftheresearchprocess,par-\ndata based on the Self-Instruct framework and rewrite the seed\nticularlywhentranslatingthemethodologyintoex- data within the framework.\necutableactionsforexperimentation.Forinstance,\nParameters:\nin machine learning research, an agent may edit Prompt: The prompt used to rewrite the data;\nSeed: whether to use the seed data while training.\nmultiple code files and manipulate large amount\nof data, as part of the methodology execution. Pre-Defined Language Modeling\nHowever, limited by the currentcapacity of foun- Framework Settings:\ndation models, it remains a severe challenge for Paradigm: Generative Pre-training # Modify the pre-training\nmethod of the language model.\nagents to carry out the proposed experiment with\nboth full-process autonomy and satisfiable suc- Parameters:\nLLM_name: Base model choice;\ncess rates(Jimenezetal., 2024; Chanetal., 2024; n_layer: Number of baby GPT model;\nLuetal., 2024) without dedicated interface de- weight_sharing_layers: Config to share params across layer;\n...(other accessories)\nsign (Yangetal., 2024a; Wangetal., 2024b) or\ntooluse(Paranjapeetal.,2023;Qinetal.,2024).\nFigure5:TheDSLdesigninBABY-AIGSfor\nIn BABY-AIGS, we extendthe originaldefinition experimented research topics in Section 3.4.\nof DSL in programmingto semi-structureobjects ThefulldemonstrationisinAppendixB.\nwithpre-definedgrammars,makingitabridgethat\nfillsthegapbetweentheproposedmethodologyandexperimentation. TheDSLrestrictstheaction\nspace of the agentswhile maintainingthe freedomfor agentsto conductproposedmethodsat the\nsametime,throughdedicateddesignwithhumaneffort. ToutilizethecapabilitiesofcurrentLLMs\n9\nytilibatucexE\ninnaturallanguageandfunction-levelcoding,wedesignthesemi-structuredgrammartobeflexible\nbetween verbal instructions and structured statements. As shown in Figure 4, the DSL has both\na higher degree of formalizationand executabilitythan naturallanguage; comparedto the coding\nlanguage adopted in previous work (Luetal., 2024), though DSL has a lower degree of formal-\nization,withhumaneffort,itexhibitshigherexecutabilityandthusensuressuccessfulexecutionof\nexperiments,accordingtoempiricalanalysis(Section3.5). However,whenthegrammarispoorly\ndesigned,theDSLislikelytorestrainthecreativityofthesystem,becausesomeideasmightnotbe\nabletobeimplemented,whichisalimitationofBABY-AIGSforfuturework.\nWe present the pre-defined grammar of DSL used in a few selected research topics in Figure 5.\nUnderaspecificparadigmrelatedtotheresearchtopic,thegrammarcontainsaseriesofparameters\nin either structuredstatement, e.g., code, integers, etc., or naturallanguage, collectivelydepicting\nthe methodologyunderthe paradigm. PROPOSALAGENT would select a research paradigmwhen\ntherearemultiple,andfillouteachparameterasrequiredinthegrammar. EXPAGENT isequipped\nwitha pre-definedinterpreterto translatethe DSL intoexecutablecodelines, orinputstospecific\nLLMsorothermodels. Forinstance,oneparameteroftheDSL fordataengineeringisafewlines\nofdataratingprinciplesrepresentedinnaturallanguage,andthemodelarchitectureparametersfor\nlanguagemodelingstillremainsincodes, indicatingthe flexibilityof DSL design. Please referto\nSection3.4fordetailedformulationoftheresearchtopicsandtopic-specificDSLdesigns.\n3.3.2 PROPOSALAGENT\nAnexampleoftheproposalfromPROPOSALAGENT\nIdea&Methodology\nIdea: ...Key issues identified include overly brief or excessively lengthy answers, lack of\nuniquewords,irrelevantcontent,pooradherencetoinstructions,lackofcoherence,lowkey-\nwordoverlap,andpoorsentimentbalance...\nMethodology: Key metrics to observe include the coherence of responses, adherence to\ninstructions, relevance to the prompt, depth of information provided, clarity of instructions\nandresponses,engagementintheconversation...\nExperimentSettings\nBaseline:Iteration0(thetrivialbaseline)\nThought: ... wewillfiltertheoriginaldatasetusingtherefined DSLwithweightedcriteria.\n... andthiswillhelpinidentifyingtheinitialimpactofthenewcriteriaontherawdataand\nensurethatthedatasetisnotoverlybiasedbysimilarity...\nHypothesis&RelatedFeature\nHypothesis: Afterusingtheprocesseddata,themodel’sperformanceontheMT-benchtask\nwillimprove significantly. The model should produce longer, more detailed, and coherent\nresponses, ... The responses should be rich in unique words, and demonstrate appropriate\nsentimentbalancecomparedtothebaseline.\nRelatedFeature:...lengthofresponses,keywordoverlap,uniquewordcount,andsentiment\nbalance.\nRebuttal\nThereviewshouldprovideanoverallviewoftheexperimentresult,focusingonwhetherthe\nselectedexampleseffectivelydemonstrateimprovementsinthekeymetrics.Thereviewshould\ncomparetheperformanceofthemodelbeforeandafterthedatacurationtohighlighttheimpact\nof the methodology. Specificexamples should be used to illustrateboth improvements and\nremainingissuestoprovide...\nAs the first step towards the scientific research, idea formation and methodology design usually\nlay the foundation for valuable insights or impactful discoveries from falsification process based\non empiricalresults, i.e., creativity in the AIGSsystem. We referto the correspondingmodulein\n10\nMetric Level Description Execution\nLength Thelengthandwordcountofresponses\nPre-definedstatisticfunction\nKeywordOverlap Corpus Thekeywordoverlapbetweeninstructionsandresponses\nSentiment Thecontainedsentimentinmodel-generatedresponses NLTK(Bird&Loper,2004)\nWorstDataPoints Theworstratingsamplescomparedwithbaselines\nSample Ranking&recitingfunction\nBestDataPoints Thebestratingsamplescomparedwithbaselines\n...... Corpus/ Other useful metrics generated by REVIEWAGENT or Free-formcodesegment\nSample pre-definedbyresearchers\nTable1:Examplesofmulti-levelmetricsforREVIEWAGENTtoempiricallyreviewtheexperimental\nresultsandtheproposalfromPROPOSALAGENTinthedataengineeringresearch.\nBABY-AIGSasPROPOSALAGENT,drawinginspirationfromhumanpracticeofproposinganidea\nandformulatingthemethodologybeforestartingtheexperiments.\nPROPOSALAGENT isimportantpartofthepre-falsificationphase. Ittakesthedetaileddescription\nofresearchtopic,thehistorylog,includingrecordsofpreviousproposalsandexperiments,andthe\nreview from REVIEWAGENT as the overall input, except for the first iteration, in which only the\ndescriptionoftheresearchtopicistheinputto PROPOSALAGENT. Asshowninthecaseaboveon\nthedataengineeringresearchtopic,theoutputofPROPOSALAGENTincludes\n• the proposedidea andmethodology,thatthe formerisa high-levelthoughtand thelatter\nis a semanticallyequalbutconcisedescriptionof instructionsto becarriedoutinthe ex-\nperimentinnaturallanguageandDSL format,aimingeithertoimprovetheexperimental\nresultsortoadvancetowardsscientificdiscoveries,\n• theconfigurableexperimentsettings,suchasspecifyingwhichturn’sproposalisconsidered\nthebaselineforthecurrentiteration,alongwithotheroptionsspecifictotheresearchtopic,\n• hypothesisonhowwouldtheexperimentalresultschangecomparedtoandthemostrelated\nfeaturethatmayempiricallyreflectthehypothesis,whichcouldguideREVIEWAGENT to\nidentifyrelevantcomponentsfromallexperimentalresults,\n• andrebuttaltothereviewfrompreviousturns,exceptforthefirstiteration.\nThus,theformulationofPROPOSALAGENTcouldbeexpressedas:\nProposal(i) = Idea&Method.(i),Exp.Settings(i),Hypo.&RelatedFeat.(i),Rebuttal(i) ,\nn o\n(1)\n= PROPOSALAGENT ResearchTopic|History(i) ,1≤i≤M,\n(cid:16) (cid:17)\nwhere\n∅, ifi=1\nHistory(i) = i−1 , (2)\n Proposal(j),Exp.Res.(j),Review(j) , if1<i≤M\nn o\nj=1\n\niindicatesthenumberofiteration,N denotesthemaximumiteration,PROPOSALAGENT(·|·)indi-\ncatestheagenticworkflow,andexperimentresultandreviewarefromEXPAGENTandREVIEWA-\nGENT elaborated in Section 3.3.3. The DSL format of the proposed methodology is illustrated\ninAppendixB.Buildingupontheaforementionedcomponents,PROPOSALAGENT putsforwarda\ncomprehensiveyethighlyexecutableproposal,whichisthensubmittedtoEXPAGENTforexecution.\nUponreceivingthereviewformREVIEWAGENT,PROPOSALAGENT caninitiatethenextiteration,\neitherexploringabrandnewdirectionoroptimizingcurrentexperimentalresults.\n3.3.3 REVIEWAGENT\nDrawinginspirationfromhumanpractice,werecognizethatsignificantinsightsandbreakthroughs\noftenemergefromin-depthanalysisofexperimentsandreflectiononmethodologybasedonempir-\nicalresults. Tofacilitatethisprocess,wedesignREVIEWAGENTtoanalyzetheexperimentalresults\nandprovidefeedbacktoPROPOSALAGENT,iterativelyimprovingtheoverallproposal.\nIn order to conduct a comprehensive and constructive review, REVIEWAGENT performs analysis\natdifferentlevelsofgranularity. Forfine-grainedanalysis, REVIEWAGENT examinescomprehen-\nsiveexperimentallogs,analyzingintermediateresultsfrommulti-levelmetricswhichcouldbepre-\ndefinedbyhumanresearchers,e.g. performanceindicatorsofthe benchmark,or self-generatedin\ncode segment (examplesfor data engineeringshown in Table 1). The review of the experimental\n11\nresults identifies hidden patterns in the empirical details, resulting in fruitful low-level feedback\nmainly on experimentdesign and adjustmenton the expectationof PROPOSALAGENT for the ex-\nperimentalresults. Forcoarse-grainedanalysis,itevaluatesthegeneralvalidityandreasonableness\nof the methodologyand hypothesis, providingreview of the whole proposal. This review content\nservesashigh-leveladviceontheideaandmethodology,withtheaimofprovokingPROPOSALA-\nGENTtowardhighercreativity.Anexampleofareviewofdataengineeringresearchisasfollows:\nAnexampleofthereviewfromREVIEWAGENT\nReviewoftheExperimentalResults\nSummaryandActionableInsights: Basedonthecomprehensive analysisofvariousfeatures\ninfluencing thescoresof responses intheAlpaca-GPT4Database, here arethekey findings\nandrecommendationsforoptimizingthedataset...\nKeyInsights:\n1.LengthandWordCount:High-qualityresponsestendtobelonger,withwordcountsabove\n1000foranswersandaround15-20wordsforqueries.\n2.Conciseness: Whilelength...\nReviewoftheProposal\nEvaluationofCurrentResearchComponents:\nYourproposaleffectivelyidentifieskeyissueswithintheAlpaca-GPT4dataset,suchas...Ad-\nditionally,theneedforspecific,measurablecriteriaforevaluatingdatapointstoimprove...\nSuggestions: 1. DataDistributionAnalysis: Performaquantitativeanalysistounderstandthe\nprevalenceanddistributionoftheseissueswithinyourdataset...\nFormally,theoutcomeofREVIEWAGENTcouldbeexpressedas:\nReview(i) = ReviewoftheExp. Res.(i),ReviewoftheProposal(i) ,\nn o\n= REVIEWAGENT ResearchTopic|Proposal(i),Exp.Res.(i),History(i) ,1≤i≤M,\n(cid:16) (cid:17)\n(3)\nwhere REVIEWAGENT(· | ·,·,·) indicates the agentic workflow, and experiment result contains\nthe benchmark results and other metric values extracted from experiments. In addition, human\nscientistsderivevaluableinsightsnotonlyfromaliteraturereviewandreasoning,butalsothrough\nempiricalanalysisanddetailedinspectionoftheexperimentalphenomenon,especiallyforsubjects\nrelyinglargelyon empiricalstudies. Comparedto previouswork (Luetal., 2024; Suetal., 2024)\nthatimproveideationcreativityprimarilybasedonliterature,oursystemadvancesthisapproachby\nintroducingmulti-granularreviewofexperimentalresultsandprocesses.Wearguethegroundtruth\nofscientificlawsrootandgetreflectedinexperimentaloutcomes,whichcouldserveasprocess\nsupervision in our iterative refinement of the proposal in the pre-falsification phase, and might\ncontributetotheoverallcreativityofBABY-AIGS.PleaserefertoSection3.5forempiricalanalysis.\n3.3.4 MULTI-SAMPLINGSTRATEGY\nIn this section, we formalize the multi-sampling strategy employed in the pre-falsification phase\nof BABY-AIGS system. This strategyis designedforbetter efficiencyand qualityof iterativeex-\nplorationbyparallelexecutingPROPOSALAGENT, EXPAGENT, REVIEWAGENT,etc. formultiple\nthreads,combinedwithrerankingtoretainthemostpromisingthreadsforfurtherexploration.\nAsshowninFigure3,themulti-samplingstrategyoperatesorthogonaltotheiterativerefinementof\ntheproposal,wherethepre-falsificationprocessofeachiterationiinvolvesparallelsamplingacross\nN threads, and each sampled thread representsa full pre-falsification process, including ideation,\nexperimentation,reviewing, etc. Formally,let S(i) = {s(i),s(i),...,s(i)},i = 1,...,M represent\n1 2 N\nthesetofthreadssamplediniterationi. Eachsamples(i),j = 1,...,N undergoesexperimentsand\nj\nrerankingbasedonpre-definedcriteria, andonlya subsetwith top-rankedsamplesS(i) ⊂ S(i) of\ntop\nsizeN isretainedforthenextiteration. Theprocesscanbesummarizedasfollows:\ns\n1. Sampling Step: Ineachiterationi, the system generatesN samples{s(i),s(i),...,s(i)}\n1 2 N\nin parallel. If the former samples\nS(i−1)\nare available, i.e., it is not the first iteration,\ntop\n12\neach st+1,j = 1,...,N is generated by taking into account the historical log from the\nj\nj⌊N ⌋+1 -thsampleofthepreviousS(i−1) threads.\n(cid:16) Ns (cid:17) top\n2. Reranking: Allsamplesarererankedonthe basisofthebenchmarkingresultduringex-\nperimentation.Forsimplicity,weadopttheaverageperformancescoreofallbenchmarks.\n3. SelectionforNextIteration:Afterstep2,thesamplesarererankedandthetopN samples\ns\nareselectedtoformthesetS(i) forthenextiteration.\ntop\nWithin BABY-AIGS, the multi-sampling strategy with reranking is applied primarily in the Pre-\nFalsificationphase,facilitatinganextensiveyetefficientexplorationofideas,methods,andexperi-\nmentalconfigurations.Byiterativelynarrowingdowntothetopcandidates,thisstrategyeffectively\nfocuses resources on promising pathways. In Section 3.6, we empirically demonstrate the multi-\nsampling strategy, coupled with reranking, is essential for guiding the iterative process in BABY-\nAIGStowardsscientificallysignificantdiscoveriesinaneffectiveandpotentiallyscalablemanner.\n3.3.5 FALSIFICATIONAGENT\nIntheresearchprocess,thereisusuallyagapbetweentheexperimentalresultsindicatingimprove-\nmentinperformanceandthefinalconclusionsofthescientificfindings,andhumanresearchersusu-\nally performablationstudies to verifythe authenticityof scientific discoveries. We term progress\nlikethisfalsification,whichisacriticalsteptowardsfull-processautomatedscientificdiscoveries.\nRecognizing the importance of falsifica- Turn10\nTurn9\ntion, we introduce FALSIFICATIONAGENT,\na novel component not present in previous\nwork (Luetal., 2024; Suetal., 2024). FAL- Significant\nSIFICATIONAGENT has access to all history Turn4 S Rig en sif uic lta snt IR nce rs eu al sts\ne\nrecords, including proposals from PROPOS- Turn3 Decrease\nALAGENT, experiment results from EXPA- Turn7 Turn8\nGENT, and reviewsfrom REVIEWAGENT. We\nTurn1 Turn2\nBaseline\nhypothesizethatscientificdiscoveriesaremore Turn5\nTurn6\nlikely to emergefromsignificant experimental\nphenomena, i.e. changes in results, thus, Iteration Round\nFALSIFICATIONAGENT in BABY-AIGS first Figure6: Illustrationof“SignificanceScreening”\nperformsa“SignificanceScreening”toidentify on history records. The starting point of each\nadjacent turns of pre-falsification phase with turnrepresentsthemodificationsandexperiments\ngreatest performance discrepancies, as shown basedonproposalsfromthatround. The“Signif-\nin Figure 6. Following this, FALSIFICA- icance Screening” process identifies results with\nTIONAGENT generates scientific discovery significantperformanceincreaseordecrease.\ncandidates from these selected turns. Then\nFALSIFICATIONAGENT generates the plans and the ablated methods for ablation experiments.\nWe requirethat at most T plans are made for each discoverycandidate, indicatingthat at most T\nablation experiments will be conducted, and each ablation experimentfocuses on the verification\nofa singlefactorthatmayinfluencetheexperimentalresult. Specifically, FALSIFICATIONAGENT\nmustselectan iterationas the baselinefor theablationstudy, and FALSIFICATIONAGENT follows\nthe “Experiment Settings” of the baseline, and modify the methodology according to the ablated\nfactor.\nAttemptingtoreacharobustandreliableconclusionoftheablationstudy,bothbaselineandablation\nexperimentsare repeated multiple times. FALSIFICATIONAGENT is given the complete record of\ntheseexperimentstodecidethevalidityoftheassociatedscientificprinciple.Ifaparticulardiscovery\nwithstandsthisprocessandconsistentlyproducesresultssimilartothoseinthemainexperiment,it\nisregardedasaverifiedandvaluablescientificdiscovery.Anditisfalsifiedotherwise.\nFormally,theoutcomeofFALSIFICATIONAGENT,whichisalsotheoutputofBABY-AIGS,is:\nScientificDiscovery= FALSIFICATIONAGENT(ResearchTopic|History), (4)\nwhere\nM\nHistory= Proposal(i),Exp.Res.(i),Review(i) , (5)\nn o\ni=1\nand FALSIFICATIONAGENT(· | ·) indicatestheagenticworkflow. We also providean exampleon\nthedataengineeringresearchtobetterdescribethedifferentpartsoftheoutputofFALSIFICATION-\nAGENT in BABY-AIGS as follows, in which specific parts of the methodology are ablated and\nreasonableconclusionsaremadebasedontheresultsoftheablationexperiment:\n13\nstluseR\nkramhcneB\nAnexampleofthefalsificationprocessfromFALSIFICATIONAGENT\nDiscoveryCandidate\nKeyFactor:ImportanceofContextandSpecificity.\nAblationExperimentPlan\nConductanablationstudybysystematicallyremovingoralteringoneelementrelatedtocon-\ntextretentionorspecificityatatime.Forexample,testtheimpactofremovingspecificinstruc-\ntionsorreducingcontextretentionbylimitingthenumberofconversational turnsaccessible\nto the model. This will help identify which specific factors within context and specificity\ncontributemostsignificantlytomodelperformanceonMT-bench.\nMethodology\nMethodologyforAblationExperiments:{...“Principles”:“...7.Responsesshouldbeconcise\nandfallwithintheoptimallengthrange(800-1500characters).\\n8. Responsesshouldengage\ntheusernaturallyandbeinformative.\\n9. Weightingofeachprincipleshouldbeconsidered\nbased on itsimportance to the downstream task.\\n10. Incorporate dynamic thresholding to\nadjustbasedonthenumberofdatapointspassingtheinitialfilter.”...}\nMethodologyforBaselineExperiments:{...“Principles”:“...7.Responsesshouldbeconcise\nandfallwithintheoptimallengthrange(800-1500characters).\\n8.Responsesshoulddemon-\nstratecontextretentionandfollowmulti-turndialogueaccurately.\\n9. Responsesshoulden-\ngagetheusernaturallyandbeinformative.\\n10.Weightingofeachprincipleshouldbeconsid-\neredbasedonitsimportancetothedownstreamtask.\\n11. Incorporatedynamicthresholding\ntoadjustbasedonthenumberofdatapointspassingtheinitialfilter.\\n12. Breakdowncom-\nplexcriteriaintomorespecificsub-criteriatocapturenuances better. Forexample, ’context\nretention’canincludesub-criterialike’long-termmemory’and’contextualcontinuity.’\\n13.\nEvaluatetheimpactofeachcriterionthroughablationstudies.”...}\nExperimentResult\nAblation Baseline\nMetric\nTrial1 Trial2 Trial1 Trial2\nVicuna-Bench(Validation)↑ 7.1625 6.7500 6.475 6.5375\nMT-Bench(Test)↑ 4.10625 4.1125 4.05625 3.96875\nVerification&ScientificDiscovery\nVerification: The discovery regarding the importance of context and specificity in\nmulti-turn conversationsappears to have a negative influence on the quality of the\ndataforthisspecifictask. Theablationstudyresultssuggestthatlimitingthenum-\nber of conversational turns and focusing on fewer criteria can lead to better\nscores,whichimpliesthatthediscoverymightnotpositivelyaffectthedataqual-\nityasinitiallythought.\nScientific Discovery: The true scientific discovery here is that while maintaining\ncontextandspecificityisgenerallyimportant,overemphasizingtheseelementsmay\nnot always lead to improvedperformancein all tasks. Simplifying the criteria and\nfocusingonessentialconversationalelementswithoutexcessivecontextretentioncan\nleadtobetterqualityresultsinthecontextoftheMT-benchtask.\nToourknowledge,FALSIFICATIONAGENTisthefirstagentwithinAI-acceleratedscientificdiscov-\nerysystemscapableofautonomouslycompletingthefalsificationprocess,byindependentlypropos-\ningscientific discoverycandidates,designingandexecutingablationexperiments,andperforming\nverification.Foradetailedqualitativeanalysis,seeSection3.5.\n14\n3.4 AUTOMATEDFULL-PROCESS RESEARCH EXPERIMENT\n3.4.1 SELECTEDRESEARCH TOPICS\nWe conductexperimentson three primary research topics in machine learning to evaluate BABY-\nAIGSinautonomousfull-processresearch.Formally,letD ={(x ,y )}N denotethek-thbench-\nk i i i=1\nmarkofagivenMLproblem,wherex representsinputfeaturesandy representsthecorresponding\ni i\nlabels. Thegoalisbuildingasystemf :X →Y thatmaximizesmetricfunctionsL (f(x),y)over\nk\nallbenchmarkD . Wesplitbenchmarksintovalidationandtestones,andonlytheformerisavail-\nk\nableinthepre-falsificationphase,avoidingwrongscientificdiscoveriesfromover-fitresults.\nDataEngineering Dataengineeringisacriticalresearchtopicthatfocusesontheidentification,\nextraction,andprocessingofrelevantdatafeaturesthatsignificantlyinfluencemodelperformance.\nWe formulate the research goal as follows: Given a data set H that contains instruction-response\npairs, the goal is to identify the key distinguishing characteristics of H, which in turn enables\nthe system to filter and extract high-quality data subsets H′ ⊂ H for the developmentof LLMs.\nThis process is crucial to improving the quality and relevance of data for a wide range of areas,\nensuringdownstreamtasks, such as in-contextlearning(Brownetal., 2020) andSupervisedFine-\nTuning(SFT)forLLMalignment(Ouyangetal.,2022),aremoreeffective. Specifically,welever-\nageAlpaca-GPT4dataset(Pengetal.,2023)asthedatasetH. Wefollowpreviouswork(Liuetal.,\n2024;Chenetal.,2024b;Lietal.,2024c;Zhaoetal.,2024)inthisfieldandlettheAIGSsystems\nwriteprinciplesforLLMstoratedatasamplesandextractthetopratedonesastherefineddataset.\nThus,for BABY-AIGS, weinputthedescriptionofthetopicanddesignthemain DSL asalistof\nrequiredprinciplesfortheevaluationofthedatasampleandathresholdindicatingtheleastnumber\nofprinciplesthatadatasampleintherefineddatasethastopass.\nSelf-InstructAlignment Theself-instructalignment(Wangetal.,2023c) isa welladopteddata\nsynthesisparadigmfor LLM alignment. The objectiveof thisresearch topicis to synthesizea set\nofSFT datawithhighqualityanddiversityforLLMalignment(Ouyangetal.,2022)byrewriting\na seed set of data, thereby enhancingthe performanceof the fine-tunedmodel on this dataset. In\nthe research process, an AIGS system is required to construct an optimal set of instructions from\na seed instructiondataset, whichare used to generatean instruction-responsedataset fromLLMs.\nThis dataset is then leveraged to refine the alignment of an LLM via SFT. In the experiment, we\nrewritetheoriginalseedinstructionset,andusethesameLLMininstructionsynthesisandresponse\ngenerationforSFTdata. Specifically,forBABY-AIGS,theDSL isdesignedasanoptionwhether\ntousetheseedinstructionset,andalistofrequirementsforthegivenLLMtogenerateinstructions.\nLanguageModeling Languagemodelingisacoreresearchtopicinnaturallanguageprocessing\nthataimstoimprovetheabilityofamodeltounderstandandgeneratehumanlanguage. Currently,\nthe mainstream approach is generative pre-training (Radfordetal., 2018), and the objective is to\nmaximizetheperplexityofthenexttokenprediction,i.e. minimizethemodelperplexity.TheAIGS\nsystemseekstoexploredifferentarchitecturalandtrainingschedulemodificationstoenhancequality\noflanguagemodelpre-trainedonlargecorpora.WedesignedDSLoftheBABY-AIGSsystemasa\nsetofconstrainedconfigurationsofmodelarchitectureandtraininghyper-parameters.\nEach of these research topics requires unique methodological innovations of an AIGS system to\nfosterhighcreativity, executability,andfalsificationcapabilities. We demonstratethepre-defined\ngrammarsofBABY-AIGSinFigure5. PleaserefertoAppendixBfordetailedsettings.\n3.4.2 EVALUATIONSETTINGS\nWe evaluate BABY-AIGS based on three key principles central to AIGS systems as proposed in\nSection 3.1: falsification, creativity, and executability. We introduce the AI Scientist (Luetal.,\n2024)asthebaselineoftheautomatedresearchsystem,andalsoselectpublishedliteraturefromtop\nconferenceasthebaselineofresearchfromexperiencedhumanresearchers.\nFalsification WeassessBABY-AIGS’sabilitytoperformfalsificationthroughhumanevaluation,\nfocusingonthe falsificationprocesscarriedoutby FALSIFICATIONAGENT. Thisprocessinvolves\nhypothesizing potential influencing factors, identifying the key variables that may impact experi-\nmental results, designing and conducting ablation experiments, and ultimately validating the real\nfactorscontributingto the experimentalsignificance. The humanevaluationis carriedoutby vol-\nunteerresearcherswithexperienceinpublishingattop-tierconferences. Evaluatorsassess thefal-\n15\nMetric AVG STD P-Value MIN MAX\nImportanceScore(0∼2)\nBABY-AIGS(Ours) 1.80 0.41 0.02 0.00 2.00\nTopConference 2.00 0.00 — 2.00 2.00\nConsistencyScore(0∼2)\nBABY-AIGS(Ours) 1.00 0.86 0.00 0.00 2.00\nTopConference 2.00 0.00 — 2.00 2.00\nCorrectnessScore(0∼2)\nBABY-AIGS(Ours) 0.95 0.94 0.00 0.00 2.00\nTopConference 2.00 0.00 — 2.00 2.00\nOverallScore(0∼2)\nBABY-AIGS(Ours) 1.25 0.47 0.00 0.67 2.00\nTopConference 2.00 0.00 — 2.00 2.00\nTable 2: Statistic results of human evaluation on the falsification process in our data engineering\nresearchexperiments.\nsificationprocessbasedonthreekeydimensions,eachscoredonascalefrom0to2,withahigher\nscoreindicatingbetterperformance:\n• ImportanceScore:Thisscorereflectstheimportanceofthescientificdiscoverycandidate.\nItevaluatestheextenttowhichtheidentifiedfactorscaninfluencetheexperimentalresults,\nconsideringtheirrelevanceandpotentialimpactwiththeprimaryexperiments.\n• ConsistencyScore: Thisscoreassesseswhethertheproposedablationexperimentplanis\nalignedwiththeidentifiedscientificdiscoverycandidate. Itconsiderswhethertheexperi-\nmentsaredesignedtoablatethefactorofinterestandappropriatelytestthehypothesis.\n• Correctness Score: Thisscoreevaluatesthe accuracyofthe finalscientific discoveryde-\nrivedfromtheablationstudies. Itconsiderswhethertheconclusionsdrawnfromtheabla-\ntionexperimentsandbaselineresultsarecorrect,basedontheobservedempiricalresults.\nAdditionally,severalstudiesfromthetopconferences(Liuetal.,2024;Chenetal.,2024b;Lietal.,\n2024c;Zhaoetal.,2024)are includedin theevaluationsetto serveasa baseline. We conductthe\nevaluationonthedataengineeringresearchexperiment,withstatisticresultsshowninTable2,where\nthep-valuesobtainedfromaleft-tailedhypothesistestagainstthetopconferencebaseline.\nCreativity WemeasurethecreativityofBABY-AIGSbyevaluatingtheperformanceimprovement\nof the proposed idea and methodology against the baseline result, i.e., the result from the trivial\nmethodologyonthetestbenchmarks.Herearethebenchmarksettingsforeachresearchexperiment:\n• Data Engineering: For the refined dataset, we conduct 15-shot In-Context Learning\n(ICL) (Jiangetal., 2024) and SFT for LLM alignment to evaluate the overall quality.\nWe evaluate the ICL-aligned LLM on the Vicuna-Bench, as a efficient validation bench-\nmark, and ICL- and the SFT-aligned LLM on the MT-Bench (Zhengetal., 2023), which\nare used as test benchmarks. The baseline of turn 0 uses the original Alpaca-GPT4\ndataset(Pengetal., 2023). We replicateAI Scientistwith the same experimenttemplate.\nMoreover,wereplicateDeita(Liuetal.,2024)asthehumanresearchofthetopicfromthe\ntopconference.\n• Self-Instruct Alignment: We also assess the aligned LLM on the Vicuna-Bench, as the\nvalidationbenchmark,andtheMT-Bench,asthetestbenchmark.Thebaselineofturn0is\ntheresultoftheoriginalself-instructmethod(Wangetal.,2023c).\n• LanguageModeling: Wepre-trainamini-sizedlanguagemodelwiththemodifiedarchi-\ntecturebasedontheconfiguredtrainingschedule,onthreedifferenttrainingsets(Karpathy,\n2015;Hutter,2006;Mahoney,2011). Thevalidationandtestbenchmarksaretheperplex-\nityofLMonthesplitvalidationandtestsets. WithreferencetoLuetal.(2024),weadopt\nthedefaultsettingsofthenanoGPTproject5asthebaseline.\nResultsonalltestbenchmarksareinTable3,Table4,andTable5,foreachtopic,respectively.\n5https://github.com/karpathy/nanoGPT.\n16\nMethodologySummarization(DataEngineering)\n1. Rate the response based on its contextual coher-\nMT-Bench↑\nMethod ence,ensuringitlogicallyfollowstheconversation.\n15-shotICL SFT 2. Evaluate the relevance by checking if the answer\nstayson-topicwithminimaldigression.\nBaseline(Turn0) 4.18 4.53\n3. Checkforlogicalreasoninginexplanations,ensur-\nAIScientist 4.36 4.67\ningtheresponseisnotjustfactualbutalsothoughtful.\nBABY-AIGS(Ours) 4.51 4.77\n4. Consider if the complexity and detail match the\nTopConference 4.45 5.01 question’srequirements,avoidingoversimplification.\n5.Finally,evaluatethetoneforpoliteness,clarity,and\nnaturalconversationalflow.\nTable3: Benchmarkingresultsonthetestbenchmarksofthedataengineeringresearchexperiment\n(left)andasummarizationofthecorrespondingproposedmethodologyfromBABY-AIGS(right).\nMethodologySummarization(Self-InstructAlignment)\nMethod MT-Bench↑\nMaketheinstructiontocoverdifferentscenariosifitlacksspeci-\nBaseline(Turn0) 2.45\nficity,clearerifambiguous, alignedwithnaturalconversations,\nBABY-AIGS(Ours) 3.26\nandtocontainadiverserangeoftasktypesifitlacksvariety.\nTable4: Benchmarkingresultsonthetestbenchmarkoftheself-instructalignmentresearchexper-\niment (left) and a summarization of the correspondingproposed methodologyfrom BABY-AIGS\n(right).\nExecutability We evaluate the BABY-AIGS system’s stability to execute research ideas error-\nlesslyfromideationtoimplementation,measuredbythesuccessrateofobtainingmeaningfulexper-\nimentaloutcomesandscientificinsights,termedasExperimentSuccessRate(Exp.SR)andOverall\nSuccessRate(OverallSR),respectively.Wereporttheoverallresultsonallresearchexperimentson\nthethreetopics.AIScientistasthebaselinemethod,arealsoevaluatedexecutabilityontheselected\ntasksintheiroriginalimplementation(Luetal.,2024). ResultsareshowninTable6.\n3.5 QUANTITATIVE ANDQUALITATIVE ANALYSIS\nBABY-AIGS couldproducevalidscientificdiscoverieswithfalsificationprocess. Tovalidate\nthefalsificationprocessinBABY-AIGS,weassessitsabilitytoperformablationstudiesandidentify\ncausativefactorsforexperimentalresults. Thequalitativeanalysisin Table2 showsthat FALSIFI-\nCATIONAGENT couldproducevalidscientificdiscoveriesincurrentdesign,asthemaximumvalue\nofeachmetricistiedtothetop-conferencebaseline,contributingpositivelytotheautomationofsci-\nentificinsights.However,therearetwocriticalfindingsthatindicatefurtherimprovementisneeded.\n(1)Theaveragevalueoftheimportancescoreishigherthantheconsistencyandcorrectnessscore,\nindicatingthatFALSIFICATIONAGENT couldidentifyimportantfactorspotentiallyrelatedtoasci-\nentific discovery but failed to design a concrete experiment plan and verify the hypothesis. The\nfailure could be attribute to the capacity of foundation model or the lack of high-quality demon-\nstrationofexperimentdesigninprompts. (2)Thep-valuesindicatethatthefalsificationprocessof\nBABY-AIGSissignificantlylesssatisfactorythantheexistingliteraturefromtopconferencesfrom\nhumanperspectives,whichemphasizestheimportanceofdesigninguser-friendlyinterfacesbesides\nrefining the design of ablation experiments. Also, we acknowledge that the scale of the study is\nsmallcomparedtoSietal.(2024),whichrequiresfutureeffort.\nBABY-AIGS demonstrates creativityduring researchidea explorationand refinement. Ta-\nble3,Table4,andTable5showtheresultsofthetestbenchmarksfordataengineering,self-instruct\nalignment,andlanguagemodelingresearchexperiments,respectively,whereBABY-AIGS outper-\nforms the baseline method, demonstrating the system’s creativity in ideation and corresponding\nmethod design. For data engineering, BABY-AIGS outperforms AI Scientist with a significant\nmargin,demonstratingtheeffectivenessoftheenrichedfeedback,includingmulti-granularmetrics,\nverbosereviewonbothexperimentprocessandmethodologydesign,etc.,inexploringresearchidea.\nHowever,theresultofSFTalignmentisinferiorthanDeita(Liuetal.,2024),indicatingthatthelack\nofvalidationbenchmarkingofspecificdownstreamtasksmightresultinansuboptimaloutcome.\n17\nMethodology Summarization\n(LanguageModeling)\nPerplexity↓\nMethod\nshakespeare char enwik8 text8 Reducethedropoutratewithmoreat-\ntention heads to increase model ex-\nBaseline(Turn0) 1.473 1.003 0.974 pressiveness.Andimplementacycli-\nBABY-AIGS(Ours) 1.499 0.984 0.966 callearningrateandadjusttheweight\ndecaytoregularizethemodel.\nTable5:Benchmarkingresultsonthetestbenchmarksofthelanguagemodelingresearchexperiment\n(left)andasummarizationofthecorrespondingproposedmethodologyfromBABY-AIGS(right).\nMethod ExperimentSuccessRate(Exp.SR) OverallSuccessRate(OverallSR)\nAIScientist 44.8% 29.2%\nBaby-AIGS(Ours) Almost100% Almost100%\nTable6: SuccessratesonthreeselectedtasksofAIScientistandBaby-AIGS.Exp.SRdenotesthe\ntimesasystemsuccessfullyconductedexperimentsoutofalltrials,andOverallSRdenotesthetimes\nasystemproducesthefinalscientificdiscoveries.Highernumbersindicatebetterexecutability.\nBABY-AIGShasremarkableexecutabilityinexperimentationandfullresearchprocess. As\nshowninTable6,ourquantitativeanalysishighlightssignificantimprovementsinexecutability,with\nBABY-AIGSachievingnearly100%successratesintranslatingthegeneratedideasintoexperimen-\ntal results and the final scientific discovery. Thishigh executability,attributed to our DSL design\nfor errorless experimentation,preventsrestarting from in-process failures and enables an efficient\nautomatedresearchprocess.DetailedAPIcostsareelaboratedinAppendixB.2.\n3.6 DISCUSSIONS\nQ1:HowdocurrentLLMsperforminthefalsificationprocess? Falsification(Popper,1935)is\nessentialinAIGSsystemsasitprovidesarigorousmechanismforverificationofpotentialscientific\ndiscoveries, a core componentin the scientific method. In BABY-AIGS, FALSIFICATIONAGENT\nplays the correspondingrole. Thus, it demands related abilities in the foundationmodel, such as\nreasonable hypothesis generation, ablation experiment design, summarization and self-correction\nbased on input empirical results, etc. As shown in the case in Section 3.3.5 and Table 2, current\nLLMs are far from desired in the agentic workflow of FALSIFICATIONAGENT. Additionally, the\nconstraints may come from the ability of the LLM to understand the environment outside FAL-\nSIFICATIONAGENT. Forinstance, fromourobservation, FALSIFICATIONAGENT seldomproposes\nexperimentplansbeyondtheprovidedexperimenttemplates.Inthiscase,althoughDSLmakessure\ntheexecutabilityoftheexperimentationbyomittingextraoperations,theexperimentprocesswould\ndifferfromtheoriginalplan,thuscreatinginconsistency.\nMethod Baseline Turn1 Turn2 Turn3 Turn4 Turn5\nMulti-Sampling@1 4.18 3.68 4.01 4.05 3.88 3.90\nMulti-Sampling@32 4.18 4.02 4.05 4.50 4.51 4.42\nTable7:ResultsonMT-Bench(15-shotICL)oftheablationstudyonthemulti-samplingstrategyof\nourBABY-AIGS systeminthedataengineeringresearchexperiment. N in“Multi-Sampling@N”\nindicatesthenumberofparallelthreadsofmulti-sampling.\nQ2: Howdoesthe BABY-AIGS systemboostcreativity? BABY-AIGS enhancescreativityby\nintegrating a multi-sampling approach combined with re-ranking, allowing it to generate diverse\nresearchproposalsandrankthembasedonvalidationbenchmarks. We providedetailedresultsof\nan ablationstudyof this processin Table 7. We observedthatthe performanceonthe test bench-\nmark is steadily increasing with multi-sampling with large numbers of threads. This strategy is\nrelatedtosearch-basedinference-costscalingmethods(Snelletal.,2024;Brownetal.,2024). The\ninsightistopickrandomhigh-performingsamplesforbetteroverallperformance. However,since\nthe objectiveof AIGSis to discoverscience on a researchtopic, the rerankingmethodhere could\n18\nbe large-scale validation benchmarks indicating generalization performance, rather than reward-\nmodel-based(Stiennonetal.,2020)orself-verificationmethodsforaspecificquery.Asdepictedin\nSection3.3.3,wearguethatthegroundtruthofscientificlawsisrootedandreflectedinbenchmark-\ningresultsfromactualexperiments,whichcouldserveasprocesssupervision,whichcouldbemore\naccuratethanrewardmodels. Itexplainshowcollapsein self-refinement-stylemethods(Xuetal.,\n2024)isavoidedinthissetting,whichisalsoempiricallyvalidatedthroughtheablationresults.\nQ3: WhycouldDSL helpwithexecutability? TheuseofaDomain-SpecificLanguage(DSL)\nin BABY-AIGS facilitatesexecutabilitybyprovidingastructuredandexecutablerepresentationof\nideas and methodologies proposed by PROPOSALAGENT. DSL enhances the system’s ability to\ntranslatecomplexscientificworkflowsintoactionableexperimentplans. AsshowninTable6,DSL\nsignificantly improvedsuccess rates in generatingscientific discoveries, regardlessof correctness,\nunderscoring its role in achieving high executability. We acknowledge that the design of DSL\nrequireshumaneffortandmightnotbeabletocoverallpossiblemethodimplementations.However,\nwebelieveitisapromisinginterfacebetweenagentsandexperimentationinfull-processresearch.\n4 LIMITATIONS AND ACTIONABLE INSIGHTS\nEnvisioning the future of AI-Generated Science systems powered by foundation models in real-\nworld,inthissection,weenumerateafewlimitationsforcurrentBABY-AIGS systemandprovide\ninsightsonthenextstepsofresearchforAIGS.\nBalanceideadiversityandsystemexecutability. AsdiscussedinSection3.3.1,thedesignofthe\nDSL enhancesthesystem executabilitybutmayconstrainthe ideadiversity. Achievingabalance\nbetweenidea diversityand system executabilityrequiresfurtherempiricalanalysis. One potential\navenue is enabling agents to develop their own DSLs, which could enhance the executability of\ngeneratedideaswithoutdiminishingtheirdiversepotential.\nEstablish systematic mechanisms for evaluation and feedback. The quality of AIGS system\ndependsheavilyonrigorousevaluationofpriorproposals,methods,andresults. Currentapproaches\noften adopta peer review format, leveragingLLMs to generatefeedback on results and guide fu-\nture optimization (Luetal., 2024; Yuetal., 2024; Jinetal., 2024). However, it remains unclear\nwhetherthismethodisthemosteffectiveforlarge-scaleresearchsettings. Futureworkshouldex-\nploresystematicmechanismstoanalyzeoutcomesacrossiterations,maximizingexperiencetransfer\nandcontinuousimprovement.\nStrengthenthefalsificationprocedure. Ourresearchunderscorestheimportanceoffalsification\ntoenhancethescientific rigoroftheresearchfindings. While we haveprototypedthefalsification\nprocessinour BABY-AIGS system,moreeffortsarerequiredtostrengthenthemodulesrelatedto\nknowledge falsification, including the exploitation of the patterns and relationships derived from\nhistorical experiments for the guidance of refined research proposals. Besides, it is also vital for\nAIGSsystemstoinvestigatewhetherthedeliverednewscientificknowledgecouldgeneralizeacross\ndiverseresearchdomainsinanautonomousmanner.\nExpand channels for scientific knowledge dissemination. Facilitating the exchange of AI-\nGeneratedScienceiscritical,bothbetweenhumansandAIandamongAIsystems. WhileLuetal.\n(2024)focusondisseminatingknowledgethroughresearchpapers,alternativeformatslikeposters,\npodcasts,andvideosaregainingtractionwiththeriseofmulti-modalagents.Futureresearchshould\nalsoexploremoreefficientcommunicationchannelsbetweenAIsystems,beyondstructuredtextor\nnaturallanguage(Phametal.,2024;Chenetal.,2024c).\nExploringcommunicationdynamicsamongautonomousAIresearchers. AsdiscussedinSec-\ntion2,theadvancementofAI-acceleratedscientificdiscoveryspansfourparadigms,culminatingin\nthe emergenceof an autonomousAI research community(ParadigmIV). Within this community,\nindividualagenticresearchersengagein interactionsthat parallelcollaborativedynamicsfoundin\nhuman scientific networks. Analyzing these communication dynamics is essential to understand\nhowfully-autonomousAIagentsmighteffectivelycollaborate,exchangeknowledge,anddrivecol-\nlectiveprogress.Inparticular,adeeperexplorationoftheseinteractionsinamulti-agentsystemwill\nhelpestablishcommunicationframeworksthatsupportoptimalcollaboration,fosteringarobustand\nproductiveAI-acceleratedresearchcommunity.\n19\nPromoteinterdisciplinaryknowledgeintegrationandexperimentation. Inthiswork,wepri-\nmarilyfocusedontheapplicationofAIGSsystemswithinthedomainofmachinelearning,where\nexperimentscould be executed in computers. However, future developmentsshould extend these\nsystems to address challenges in other scientific fields, such as biology, which has been prelimi-\nnarily exploredin a concurrentwork(Swansonetal., 2024), chemistry, and physics, where cross-\ndisciplinaryknowledgeintegrationisoftencrucial. OnemajorchallengeliesinhowAIagentscan\nsynthesizeandaligndomain-specificknowledgefrommultiplefields,whichoftenhavedistinctter-\nminologies,methodologies,andepistemologicalassumptions. Anothercriticalchallengeistheex-\nperimentenvironment,whichcouldbehardlyautomatedandmightbehighlyresource-consuming.\nWe hope the integrity and developmentof optional modules like DOMAIN-SPECIFIC EXPAGENT\nand ENVIRONMENTAGENT mentioned in Section 3.2 could alleviate the challenges, and further\neffortisneededandwillbemadeinfuturework.\n5 ETHICS AND IMPACT STATEMENT\nIn our BABY-AIGS system, the agent did not perform harmful operations on computer systems\nor environment because of the design of DSL, task constraints and no access to external tools.\nHowever, while the system developedin this study is limited in scope, AIGS systems as a whole\nmayhavesignificantimpactsinthefuture,withpotentialrisksthatshouldnotbeoverlooked. This\nsection explores the potential negative impacts of such systems, drawing on prior research, and\nofferssuggestionsforpromotingtheirpositivedevelopment.\n5.1 POTENTIAL NEGATIVEIMPACTS OF AIGSSYSTEMS\nImpact on HumanResearchersand Academic Community In the absence of robustpublica-\ntionstandardsandacademicreviewprocesses,AIGSsystemscouldfloodtheacademiccommunity\nwith low-qualityliterature, which will furtherincrease researchers’workloadand disruptthe effi-\ncientdisseminationofknowledge(Luetal.,2024;Sietal.,2024;Huetal.,2024b). Andalthough\nSietal. (2024) and Kumaretal. (2024) suggest that LLMs can generate ideas more creative than\nhumans,theextentofsuchcreativityremainsuncertain. LLM-poweredAIGSsystemstendtorely\nheavily on existing data and patterns, which couldfoster path dependencyand limit opportunities\nforgroundbreakingdiscoveries. Additionally,thesesystemsmightinadvertentlyuseproprietaryor\ncopyrightedmaterial,raisingconcernsaboutintellectualpropertyinfringement(Kumaretal.,2024).\nFurthermore,AIGSsystemsalsopresentseveralunpredictablechallengesforhumanresearchers:\n• Dependence Effect andCognitive Inertia: Over-relianceon AI-generatedinsightsmay\ndiminishresearchers’independentthinking,leadingto cognitivestagnationanda decline\nincriticalthinkingskills(Sietal.,2024;Huetal.,2024b).\n• Ambiguity in Responsibility Attribution: The involvement of AI complicates the as-\nsignment of credit and responsibility, potentially disrupting existing incentive struc-\nture(Sietal.,2024;Huetal.,2024b).\n• Weakened Collaboration and Increased Isolation: As AIGS systems become capable\nofindependentlygeneratingpublishablework,researchersmayincreasinglyrelyonthese\nsystems, reducing the need for direct collaboration and communication with colleagues.\nThis shift could lead to a decline in interpersonal interaction, weakening traditional re-\nsearchnetworksbuiltonteamworkandshareddiscourse(Sietal.,2024;Huetal.,2024b).\nOver time, the diminishing frequency of collaborative exchanges may foster a sense of\nprofessionalisolationamonghumanresearchers,heighteningtheriskofloneliness,disen-\ngagement,andreducedpsychologicalwell-being.\n• ExacerbatedTechnological Barriers: Without equitable access to advancedAIGS sys-\ntems, a technologicaldividecouldemerge,disadvantagingresearchersunfamiliarwith or\nlackingaccesstothesesystems,therebyexacerbatinginequalitieswithinthecommunity.\nImpactonEnvironment AIGSsystemscanconductlarge-scaleexperimentsinparallel,buttheir\ndependenceoniterativeprocessescarriestheriskofinefficientfeedbackloops,potentiallyleading\nto issues such as infinite loops. This inefficiency, caused by limited reasoning capabilities, the\nmisuseoferroneousinformation,orambiguityintaskdefinition,coulddriveupenergyconsumption.\nMoreover,poorlyregulatedexperiments,especiallywithoutadequatesimulationenvironments,can\nlead to unintended environmental harm. For example, untested chemical processes in materials\nscience mayyieldhazardousby-products,while uncheckedexperimentsin nuclearresearchcould\nincreasetheriskofradiationleaks(Tangetal.,2024).\n20\nImpact onSocialSecurity AIGSsystems, particularlywhencompromisedbyjailbreakattacks,\ncouldgenerateresponsesthatconflictwithhumanvalues,suchasprovidinginstructionsforcreating\nexplosives.Thisraisesconcernsabouttheirmisuseforharmfulpurposes,suchasdesigningmoread-\nvancedadversarialattackstrategies(Tangetal.,2024;Sietal.,2024;Luetal.,2024;Kumaretal.,\n2024; Huetal., 2024b). Even with benign intentions, unsupervisedscientific research may intro-\nduceunforeseensocietalrisks. Forinstance,monopolizingbreakthroughsinautonomousAIcould\nleadtosevereunemployment,marketmonopolies,andsocialunrest(Tangetal.,2024).\n5.2 STRATEGIESFOR RESPONSIBLE AND ETHICALDEVELOPMENTOF AUTOMATED\nRESEARCH SYSTEMS\nStrengthening the Security of Foundation Models The most fundamental step in mitigating\nsecurityrisks associated with AIGSsystemsis enhancingthe security oftheir foundationmodels.\nIncorporatinginstructionsforhandlingunsaferesearchintothealignmenttrainingcorpus,alongside\nconductingrigoroussafety audits priorto modeldeployment, are bothcrucial strategiesto ensure\nthesystemsberobustandsecure(Tangetal.,2024).\nAligningScientificAgentswithHumanIntentions,EnvironmentandSelf-constraints Scien-\ntific agents in AIGS systems shouldalign with humanintentions, the environmentsin which they\noperate,andself-constraints(Yangetal.,2024c).\n• HumanIntentions:Agentsmustaccuratelyinterpretuserintent,goingbeyondliterallan-\nguagetocapturethedeeperpurposeofscientificinquiries.\n• Environment:Agentsneedtoadapttothespecificenvironmentsinwhichtheyfunctionby\napplyingdomain-specificknowledgeaccuratelyandutilizingspecializedtoolseffectively.\n• Self-Constraints:Agentsmustevaluatetaskfeasibility,manageresourceswisely,andmin-\nimize waste to ensure sustainable operation. This includes setting boundariesto prevent\nredundantworkorharmfulbehavior,whichisessentialformaintainingsystemefficiency.\nProvidingComprehensiveTrainingforHumanUsers Comprehensiveandrigoroustrainingis\nessential for users to fully leverage AIGS systems and prevent unintended consequences (Aidan,\n2024). Propertrainingminimizestheriskofmisusethatcouldleadtoenvironmentalharm,resource\nwaste,orunethicalresearchoutcomes. Trainingprogramsshouldfocusnotonlyontechnicalskills\nbut also on ethical considerations, ensuring users understand the limitations and responsibilities\nassociatedwiththesesystems(Tangetal.,2024).\nBuildingaCollaborativeFrameworkBetweenAutomatedResearchSystemsandHumanRe-\nsearchers TopreventAIGSsystemsfromexertingexcessiveinfluenceontheacademiccommu-\nnity,collaborationbetweenAIGSsystemsandhumanresearcherswillplayacrucialrole(Sietal.,\n2024;Huetal.,2024b). Itisessentialtoexplorethenewrolesandresponsibilitiesthathumansci-\nentists may need to assume in this evolving research landscape shaped by the presence of AIGS\nsystems. Awell-structuredpartnershipcanleveragethecomplementarystrengthsofboth,enabling\noutcomesthatneithercouldachieveindependently.Moreover,suchcollaborationfostersinteraction\namonghumanresearchers,encouragingdeepercommunicationandmitigatingthesenseofisolation\nthatmayarisefromincreasedrelianceonautomatedtools.\nEstablishing Comprehensive Legal and Accountability Frameworks A robust legal and ac-\ncountabilityframeworkiscrucialtogoverntheuseofAIGSsystems. Thisframeworkshould:\n• DefineClearScientificResearchBoundaries: Specifythepermissiblescopeandlimita-\ntionsofthesesystems,whereregulateagentswiththeDSLmightbehelpful.\n• Clarify Responsibility and Credit Allocation: Establish guidelinesfor assigning credit\nand responsibility for research outcomes generated with the assistance of AIGS sys-\ntems(Sietal.,2024;Huetal.,2024b).\n• Implement Penalties for Misuse: Outline liability measures and penalties to address\nharmfulbehaviororunethicalpracticesinvolvingthesesystems.\nUsing AIGSSystemstoAddressIts OwnChallenges AIGSsystemscan also playaproactive\nrole in addressing the challenges and even ethical issues introduced by themselves. For exam-\nple, AIGS systems could be used to monitor and evaluate outputsfrom other automated systems,\n21\nidentifyingpotentialethicalissues, biases, orenvironmentalrisks beforethey escalate. Moreover,\nAIGSsystemscanfacilitatethedevelopmentofguidelines,byautomatingtheanalysisofresearch\ntrendsand regulatoryneeds, thushelpingshape futurepoliciesforresponsibleAI use. When em-\nployed strategically, AIGS systems become not only tools for discovery but also mechanisms for\nself-regulation,creatingavirtuouscycleofinnovationandgovernance.\n6 CONCLUSION\nWe introducethe conceptofAIGSin thispaperandimplementBABY-AIGS, a baby-steptoward\nfull-processautomatedscientificdiscoverysystems,withafocusonincorporatingfalsificationinto\ntheresearchprocess. Byintegratinga FALSIFICATIONAGENT,themulti-agentsystemcanidentify\nand verify potential discoveries. Techniques as DSL and multi-sampling strategy are introduced\nfor two otherprinciplesof AIGS systems design, executability and creativity. Preliminaryexper-\nimentsshowpromise,thoughthesystem’sperformanceremainsbelowthatofexperiencedhuman\nresearchers. ThisworklaysthegroundworkforfuturedevelopmentsinAIGSsystems,withfurther\nimprovementsoverBABY-AIGSandethicalconsiderationsnecessaryforadvancingthefield.\nREFERENCES\nJosh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf\nRonneberger,LindsayWillmore, AndrewJBallard, JoshuaBambrick,et al. Accuratestructure\npredictionofbiomolecularinteractionswithAlphaFold3. Nature,pp.1–3,2024.\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-\ncia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anad-\nkat, et al. GPT-4 technical report. ArXiv preprint, abs/2303.08774, 2023. URL\nhttps://arxiv.org/abs/2303.08774.\nToner-RodgersAidan.ArtificialIntelligence,ScientificDiscovery,andProductInnovation.preprint,\n2024. URLhttps://aidantr.github.io/files/AI_innovation.pdf.\nAlberto Alfarano, Franc¸ois Charton, and Amaury Hayat. Global Lyapunov functions: a\nlong-standing open problem in mathematics, with symbolic transformers. ArXiv preprint,\nabs/2410.08304,2024. URLhttps://arxiv.org/abs/2410.08304.\nJinheonBaek,SujayKumarJauhar,SilviuCucerzan,andSungJuHwang. Researchagent:Iterative\nresearch idea generation over scientific literature with large language models. arXiv preprint\narXiv:2404.07738,2024.\nSteven Bird and EdwardLoper. NLTK: The naturallanguagetoolkit. In Proceedingsof the ACL\nInteractivePosterandDemonstrationSessions,pp.214–217,Barcelona,Spain,July2004.Asso-\nciationforComputationalLinguistics. URLhttps://aclanthology.org/P04-3031.\nBradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher Re´, and\nAzaliaMirhoseini.Largelanguagemonkeys:Scalinginferencecomputewithrepeatedsampling.\narXivpreprintarXiv:2407.21787,2024. URLhttps://arxiv.org/abs/2407.21787.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\nArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.\nZiegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,\nScott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,\nIlya Sutskever, and Dario Amodei. Language models are few-shot learners. ArXiv preprint,\nabs/2005.14165,2020. URLhttps://arxiv.org/abs/2005.14165.\nJun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio\nStarace, Kevin Liu, Leon Maksin, Tejal Patwardhan, et al. MLE-bench: Evaluating machine\nlearningagentson machinelearningengineering. ArXiv preprint, abs/2410.07095,2024. URL\nhttps://arxiv.org/abs/2410.07095.\nKexinChen,JunyouLi,KunyiWang,YuyangDu,JiahuiYu,JiaminLu,LanqingLi,JiezhongQiu,\nJianzhangPan,YiHuang,QunFang,PhengAnnHeng,andGuangyongChen. Chemist-X:Large\nlanguagemodel-empoweredagentforreactionconditionrecommendationinchemicalsynthesis,\n2024a. URLhttps://arxiv.org/abs/2311.10776.\n22\nLichangChen,ShiyangLi,JunYan,HaiWang,KalpaGunaratna,VikasYadav,ZhengTang,Vijay\nSrinivasan, Tianyi Zhou, Heng Huang, and Hongxia Jin. Alpagasus: Training a Better Alpaca\nModelwithFewerData. InTheTwelfthInternationalConferenceonLearningRepresentations,\n2024b. URLhttps://openreview.net/forum?id=FdVXgSJhvz.\nWeize Chen, Chenfei Yuan, Jiarui Yuan, Yusheng Su, Chen Qian, Cheng Yang, Ruobing Xie,\nZhiyuan Liu, and Maosong Sun. Beyond natural language: LLMs leveraging alternative for-\nmatsforenhancedreasoningandcommunication. InYaserAl-Onaizan,MohitBansal,andYun-\nNungChen(eds.),FindingsoftheAssociationforComputationalLinguistics: EMNLP2024,pp.\n10626–10641,Miami,Florida,USA,November2024c.AssociationforComputationalLinguis-\ntics. URLhttps://aclanthology.org/2024.findings-emnlp.623.\nZiruChen,ShijieChen,YutingNing,QianhengZhang,BoshiWang,BotaoYu,YifeiLi,ZeyiLiao,\nChenWei,ZitongLu,VishalDey,MingyiXue,FrazierN.Baker,BenjaminBurns,DanielAdu-\nAmpratwum, XuhuiHuang, Xia Ning, Song Gao, Yu Su, and Huan Sun. ScienceAgentBench:\nTowardrigorousassessmentoflanguageagentsfordata-drivenscientificdiscovery.arXivpreprint\narXiv:2410.05080,2024d.\nJiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang,\nand Minlie Huang. AutoDetect: Towards a unified framework for automated weakness de-\ntection in large language models. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen\n(eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 6786–\n6803,Miami, Florida, USA,November2024.AssociationforComputationalLinguistics. URL\nhttps://aclanthology.org/2024.findings-emnlp.397.\nMike D’Arcy, Tom Hope, Larry Birnbaum, and Doug Downey. MARG: Multi-Agent re-\nview generation for scientific papers. ArXiv preprint, abs/2401.04259, 2024. URL\nhttps://arxiv.org/abs/2401.04259.\nJonas Degrave, Federico Felici, Jonas Buchli, Michael Neunert, Brendan Tracey, Francesco\nCarpanese,TimoEwalds,RolandHafner,AbbasAbdolmaleki,DiegodeLasCasas,etal. Mag-\nneticcontroloftokamakplasmasthroughdeepreinforcementlearning. Nature,602(7897):414–\n419,2022.\nJiangshu Du, Yibo Wang, Wenting Zhao, Zhongfen Deng, Shuaiqi Liu, Renze Lou, Henry Zou,\nPranav Narayanan Venkit, Nan Zhang, Mukund Srinath, Haoran Zhang, Vipul Gupta, Yinghui\nLi, TaoLi,FeiWang, QinLiu, TianlinLiu,PengzhiGao,CongyingXia, ChenXing,ChengJi-\nayang,ZhaoweiWang,YingSu,RajShah,RuohaoGuo,JingGu,HaoranLi,KangdaWei,Zihao\nWang,LuCheng,SurangikaRanathunga,MengFang,JieFu,FeiLiu,RuihongHuang,Eduardo\nBlanco,YixinCao,RuiZhang,PhilipYu,andWenpengYin. LLMsassistNLPresearchers:Cri-\ntique paper (meta-)reviewing. In Yaser Al-Onaizan, MohitBansal, and Yun-NungChen (eds.),\nProceedingsofthe2024ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.\n5081–5099,Miami, Florida, USA,November2024.AssociationforComputationalLinguistics.\nURLhttps://aclanthology.org/2024.emnlp-main.292.\nChenGao,XiaochongLan,NianLi,YuanYuan,JingtaoDing,ZhilunZhou,FengliXu,andYong\nLi. Large language models empowered agent-based modeling and simulation: A survey and\nperspectives. HumanitiesandSocialSciencesCommunications,11(1):1–24,2024.\nMingmengGeng and Roberto Trotta. Is ChatGPT transformingacademics’ writing style? ArXiv\npreprint,abs/2404.08627,2024. URLhttps://arxiv.org/abs/2404.08627.\nDaniel George and EA Huerta. Deep neural networks to enable real-time multimessenger astro-\nphysics. PhysicalReviewD,97(4):044039,2018.\nAlirezaGhafarollahiandMarkusJBuehler.ProtAgents:proteindiscoveryvialargelanguagemodel\nmulti-agentcollaborationscombiningphysicsandmachinelearning. DigitalDiscovery,2024.\nSoumya Suvra Ghosal, Souradip Chakraborty, Jonas Geiping, Furong Huang, Dinesh\nManocha, and Amrit Singh Bedi. Towards possibilities & impossibilities of AI-\ngenerated text detection: A survey. ArXiv preprint, abs/2310.15264, 2023. URL\nhttps://arxiv.org/abs/2310.15264.\nYolanda Gil, Ewa Deelman, Mark Ellisman, Thomas Fahringer, Geoffrey Fox, Dennis Gannon,\nCaroleGoble,MironLivny,LucMoreau,andJimMyers. Examiningthechallengesofscientific\nworkflows. Computer,40(12):24–32,2007.\n23\nJustinGilmer,SamuelS.Schoenholz,PatrickF.Riley,OriolVinyals,andGeorgeE.Dahl. Neural\nmessagepassingforquantumchemistry. InDoinaPrecupandYeeWhyeTeh(eds.),Proceedings\nofthe34thInternationalConferenceonMachineLearning,ICML2017,Sydney,NSW,Australia,\n6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pp. 1263–1272.\nPMLR,2017. URLhttp://proceedings.mlr.press/v70/gilmer17a.html.\nKaranGirotra,LennartMeincke,ChristianTerwiesch,andKarlTUlrich. Ideasaredimesadozen:\nLargelanguagemodelsforideagenerationininnovation. AvailableatSSRN4526071,2023.\nMichaelHamanandMilanSˇkoln´ık. UsingChatGPTtoconductaliteraturereview. Accountability\ninresearch,31(8):1244–1246,2024.\nWenpin Hou and Zhicheng Ji. Assessing GPT-4 for cell type annotation in single-cell RNA-seq\nanalysis. NatureMethods,pp.1–4,2024.\nChao-ChunHsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, ChenhaoTan, David Wadden, Lucy\nWang,andAakankshaNaik.CHIME:LLM-assistedhierarchicalorganizationofscientificstudies\nforliteraturereviewsupport.InLun-WeiKu,AndreMartins,andVivekSrikumar(eds.),Findings\noftheAssociationforComputationalLinguistics: ACL2024,pp.118–132,Bangkok,Thailand,\nAugust2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/2024.findings-acl.8.\nURLhttps://aclanthology.org/2024.findings-acl.8.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean\nWang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large lan-\nguage models. In International Conference on Learning Representations, 2022. URL\nhttps://openreview.net/forum?id=nZeVKeeFYf9.\nShengran Hu, Cong Lu, and Jeff Clune. Automated design of agentic systems. ArXiv preprint,\nabs/2408.08435,2024a. URLhttps://arxiv.org/abs/2408.08435.\nXiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin,\nLili Pan, and Zhenzhong Lan. Nova: An iterative planning and search approach to enhance\nnovelty and diversity of LLM generated ideas. ArXiv preprint, abs/2410.14255, 2024b. URL\nhttps://arxiv.org/abs/2410.14255.\nWenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby\nHemphill, and Yongfeng Zhang. War and Peace (WarAgent): Large language model-\nbased multi-agent simulation of world wars. ArXiv preprint, abs/2311.17227, 2023. URL\nhttps://arxiv.org/abs/2311.17227.\nJingshan Huangand Ming Tan. The role of ChatGPT in scientific communication: writing better\nscientificreviewarticles. Americanjournalofcancerresearch,13(4):1148,2023.\nMarcusHutter. Thehutterprize,2006. URLhttp://prize.hutter1.net.\nPaul Jaccard. E´tude comparativede la distribution florale dans une portion des alpes et des jura.\nBullSocVaudoiseSciNat,37:547–579,1901.\nPeter Jansen, Marc-Alexandre Coˆte´, Tushar Khot, Erin Bransom, Bhavana Dalvi Mishra, Bod-\nhisattwa Prasad Majumder,OyvindTafjord, andPeter Clark. DISCOVERYWORLD: A virtual\nenvironmentfordevelopingandevaluatingautomatedscientificdiscoveryagents. arXivpreprint\narXiv:2406.06769,2024.\nYixing Jiang, Jeremy Andrew Irvin, Ji Hun Wang, Muhammad Ahmed Chaudhry, Jonathan H\nChen, and Andrew Y. Ng. Many-shot in-context learning in multimodal founda-\ntion models. In ICML 2024 Workshop on In-Context Learning, 2024. URL\nhttps://openreview.net/forum?id=j2rKwWXdcz.\nCarlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and\nKarthik R Narasimhan. SWE-bench: Can language models resolve real-world github is-\nsues? In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=VTF8yNQM66.\nYiqiaoJin,QinlinZhao,YiyangWang,HaoChen,KaijieZhu,YijiaXiao,andJindongWang.Agen-\ntReview: Exploring peer review dynamics with LLM agents. ArXiv preprint, abs/2406.12708,\n2024. URLhttps://arxiv.org/abs/2406.12708.\n24\nYongfeiJuan, YongbingDai, YangYang,andJiao Zhang. Acceleratingmaterialsdiscoveryusing\nmachinelearning. JournalofMaterialsScience&Technology,79:178–190,2021.\nJohnJumper,RichardEvans,AlexanderPritzel, TimGreen,MichaelFigurnov,OlafRonneberger,\nKathrynTunyasuvunakool,RussBates,AugustinZˇ´ıdek,AnnaPotapenko,etal. Highlyaccurate\nproteinstructurepredictionwithAlphaFold. Nature,596(7873):583–589,2021.\nAndrej Karpathy. The unreasonable effectiveness of recurrent neural networks, 2015. URL\nhttps://karpathy.github.io/2015/05/21/rnn-effectiveness/.\nJohn Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.\nA watermark for large language models. In Andreas Krause, Emma Brunskill, Kyunghyun\nCho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), International Confer-\nence on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume\n202 of Proceedings of Machine Learning Research, pp. 17061–17084. PMLR, 2023. URL\nhttps://proceedings.mlr.press/v202/kirchenbauer23a.html.\nSandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, and Asif Ekbal. Can large language mod-\nels unlock novel scientific research ideas? ArXiv preprint, abs/2409.06185, 2024. URL\nhttps://arxiv.org/abs/2409.06185.\nYann LeCun, Yoshua Bengio, and GeoffreyHinton. Deep learning. Nature, 521(7553):436–444,\n2015.\nJunkaiLi,SiyuWang,MengZhang,WeitaoLi,YunghweiLai,XinhuiKang,WeizhiMa,andYang\nLiu. AgentHospital: A simulacrumofhospitalwithevolvablemedicalagents. ArXivpreprint,\nabs/2405.02957,2024a. URLhttps://arxiv.org/abs/2405.02957.\nRuochen Li, Teerth Patel, Qingyun Wang, and Xinya Du. MLR-Copilot: Autonomous machine\nlearningresearchbasedonlargelanguagemodelsagent.arXivpreprintarXiv:2408.14033,2024b.\nYunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, Ling-\nHao Chen, Junhao Liu, Tongliang Liu, Fei Huang, and Yongbin Li. One-shot learning as\ninstruction data prospector for large language models. In Lun-Wei Ku, Andre Martins, and\nVivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers), pp. 4586–4601, Bangkok, Thailand, August\n2024c. Association for ComputationalLinguistics. doi: 10.18653/v1/2024.acl-long.252. URL\nhttps://aclanthology.org/2024.acl-long.252.\nYutongLi,LuChen,AiweiLiu,KaiYu,andLijieWen.ChatCite:LLMagentwithhumanworkflow\nguidance for comparative literature summary. ArXiv preprint, abs/2403.02574, 2024d. URL\nhttps://arxiv.org/abs/2403.02574.\nWeixinLiang,ZacharyIzzo,YaohuiZhang,HaleyLepp,HanchengCao,XuandongZhao,Lingjiao\nChen,HaotianYe,ShengLiu,ZhiHuang,etal. MonitoringAI-modifiedcontentatscale: Acase\nstudyontheimpactofChatGPTonAIconferencepeerreviews. ArXivpreprint,abs/2403.07183,\n2024a. URLhttps://arxiv.org/abs/2403.07183.\nWeixin Liang, Yaohui Zhang, Zhengxuan Wu, Haley Lepp, Wenlong Ji, Xuandong Zhao,\nHancheng Cao, Sheng Liu, Siyu He, Zhi Huang, et al. Mapping the increasing\nuse of LLMs in scientific papers. ArXiv preprint, abs/2404.01268, 2024b. URL\nhttps://arxiv.org/abs/2404.01268.\nWei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He. What Makes Good Data\nfor Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tun-\ning. In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=BTKAeLqLMw.\nYuliangLiu,XiangruTang,ZefanCai,JunjieLu,YichiZhang,YanjunShao,ZexuanDeng,Helan\nHu,ZengxianYang,KaikaiAn,etal. ML-Bench: Evaluatinglargelanguagemodelsandagents\nformachinelearningtasksonrepository-levelcode. ArXivpreprint,abs/2311.09835,2023. URL\nhttps://arxiv.org/abs/2311.09835.\nRenze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yux-\nuan Sun, Yusen Zhang, Jihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma,\nXi Li, Kai Zhang, Congying Xia, Lifu Huang, and Wenpeng Yin. AAAR-1.0: As-\nsessing AI’s potential to assist research. ArXiv preprint, abs/2410.22394, 2024. URL\nhttps://arxiv.org/abs/2410.22394.\n25\nChrisLu,CongLu,RobertTjarkoLange,JakobFoerster,JeffClune,andDavidHa. TheAIScien-\ntist: Towardsfullyautomatedopen-endedscientific discovery. ArXivpreprint, abs/2408.06292,\n2024. URLhttps://arxiv.org/abs/2408.06292.\nAndres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe\nSchwaller. Augmenting large language models with chemistry tools. Nature Machine Intelli-\ngence,pp.1–11,2024.\nPingchuanMa,Tsun-HsuanWang,MinghaoGuo,ZhiqingSun,JoshuaBTenenbaum,DanielaRus,\nChuangGan,andWojciechMatusik.LLMandsimulationasbileveloptimizers:Anewparadigm\nto advance physical scientific discovery. In International Conference on Machine Learning.\nPMLR,2024.\nMattMahoney.Aboutthetestdata,2011.URLhttp://mattmahoney.net/dc/textdata.html.\nBenjaminSManning,KehangZhu,andJohnJHorton.Automatedsocialscience:Languagemodels\nasscientistandsubjects. Technicalreport,NationalBureauofEconomicResearch,2024.\nNatMcAleese, Rai MichaelPokorny,Juan FelipeCeron Uribe, EvgeniaNitishinskaya, Maja Tre-\nbacz,andJanLeike. LLMcriticshelpcatchLLMbugs. ArXivpreprint,abs/2407.00215,2024.\nURLhttps://arxiv.org/abs/2407.00215.\nMarjanMernik,JanHeering,andAnthonyM.Sloane. Whenandhowtodevelopdomain-specific\nlanguages. ACMComput.Surv.,37(4):316–344,2005. ISSN0360-0300. doi: 10.1145/1118890.\n1118892. URLhttps://doi.org/10.1145/1118890.1118892.\nHarshit Nigam, Manasi Patwardhan, Lovekesh Vig, and Gautam Shroff. Acceleron: A\ntool to accelerate research ideation. ArXiv preprint, abs/2403.04382, 2024a. URL\nhttps://arxiv.org/abs/2403.04382.\nHarshit Nigam, Manasi Patwardhan, Lovekesh Vig, and Gautam Shroff. An interactive Co-\nPilot for accelerated research ideation. In Su Lin Blodgett, Amanda Cercas Curry, Sunipa\nDey, Michael Madaio, Ani Nenkova, Diyi Yang, and Ziang Xiao (eds.), Proceedings of the\nThird Workshop on Bridging Human–ComputerInteractionand Natural Language Processing,\npp. 60–73, Mexico City, Mexico, 2024b. Association for Computational Linguistics. URL\nhttps://aclanthology.org/2024.hcinlp-1.6.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-\nman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter\nWelinder, Paul F Christiano, Jan Leike, and Ryan Lowe. Training language models\nto follow instructions with human feedback. In S. Koyejo, S. Mohamed, A. Agar-\nwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural Information Pro-\ncessing Systems, volume 35, pp. 27730–27744. Curran Associates, Inc., 2022. URL\nhttps://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805\nBhargaviParanjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and\nMarcoTulioRibeiro. ART:Automaticmulti-stepreasoningandtool-useforlargelanguagemod-\nels.arXivpreprint,abs/2303.09014,2023.URLhttps://arxiv.org/abs/2303.09014.\nJoonSungPark,LindsayPopowski,CarrieCai,MeredithRingelMorris,PercyLiang,andMichaelS\nBernstein. Social simulacra: Creating populated prototypes for social computing systems. In\nProceedingsofthe35thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pp.\n1–18,2022.\nJoon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and\nMichaelSBernstein.Generativeagents:Interactivesimulacraofhumanbehavior.InProceedings\nofthe36thannualacmsymposiumonuserinterfacesoftwareandtechnology,pp.1–22,2023.\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. In-\nstruction tuning with GPT-4. ArXiv preprint, abs/2304.03277, 2023. URL\nhttps://arxiv.org/abs/2304.03277.\nChauPham,BoyiLiu,YingxiangYang,ZhengyuChen,TianyiLiu,JianboYuan,BryanA.Plum-\nmer, ZhaoranWang, and HongxiaYang. Letmodelsspeak ciphers: Multiagentdebate through\nembeddings. InInternationalConferenceonLearningRepresentations(ICLR),2024.\n26\nKarlR.Popper. TheLogicofScientificDiscovery. Routledge,London,England,1935.\nBiqingQi,KaiyanZhang,HaoxiangLi,KaiTian,SihangZeng,Zhang-RenChen,andBowenZhou.\nLargelanguagemodelsarezeroshothypothesisproposers.ArXivpreprint,abs/2311.05965,2023.\nURLhttps://arxiv.org/abs/2311.05965.\nYujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,Xiangru\nTang,BillQian,etal. ToolLLM:Facilitatinglargelanguagemodelstomaster16000+real-world\nAPIs. InInternationalConferenceonLearningRepresentations(ICLR),2024.\nAlecRadford,KarthikNarasimhan,TimSalimans,andIlyaSutskever. Improvinglanguageunder-\nstandingbygenerativepre-training. 2018.\nBernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog,\nM Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang,\nOmarFawzi,etal. Mathematicaldiscoveriesfromprogramsearchwithlargelanguagemodels.\nNature,625(7995):468–475,2024.\nAlvaroSanchez-Gonzalez,JonathanGodwin,TobiasPfaff,RexYing,JureLeskovec,andPeterW.\nBattaglia. Learningtosimulatecomplexphysicswithgraphnetworks. InProceedingsofthe37th\nInternational Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event,\nvolume119ofProceedingsofMachineLearningResearch,pp.8459–8468.PMLR,2020. URL\nhttp://proceedings.mlr.press/v119/sanchez-gonzalez20a.html.\nAbheesht Sharma, Gunjan Chhablani, Harshit Pandey, and Rajaswa Patil. DRIFT: A toolkit for\ndiachronic analysis of scientific literature. In Heike Adel and Shuming Shi (eds.), Proceed-\nings of the 2021 Conference on Empirical Methods in Natural Language Processing: System\nDemonstrations, EMNLP 2021, Online and Punta Cana, Dominican Republic, 7-11 November,\n2021, pp. 361–371.Association for ComputationalLinguistics, 2021. doi: 10.18653/V1/2021.\nEMNLP-DEMO.40. URLhttps://doi.org/10.18653/v1/2021.emnlp-demo.40.\nParshinShojaee,KazemMeidani,ShashankGupta,AmirBaratiFarimani,andChandanKReddy.\nLLM-SR: Scientific equation discovery via programming with large language models. arXiv\npreprintarXiv:2404.18400,2024.\nChengleiSi,DiyiYang,andTatsunoriHashimoto. CanLLMsgeneratenovelresearchideas? ArXiv\npreprint,abs/2409.04109,2024. URLhttps://arxiv.org/abs/2409.04109.\nCharlie Snell, Jaehoon Lee, Kelvin Xu, and AviralKumar. Scaling LLM test-time computeopti-\nmally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314,\nabs/2408.03314,2024. URLhttps://arxiv.org/abs/2408.03314.\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,\nDarioAmodei,andPaulChristiano. Learningtosummarizefromhumanfeedback. InProceed-\ningsofthe34thInternationalConferenceonNeuralInformationProcessingSystems,NIPS’20,\nRedHook,NY,USA,2020.CurranAssociatesInc. ISBN9781713829546.\nHaoyangSu,RenqiChen,ShixiangTang,XinzheZheng,JingzheLi, ZhenfeiYin, WanliOuyang,\nand Nanqing Dong. Two heads are better than one: A multi-agent system has the po-\ntential to improve scientific idea generation. ArXiv preprint, abs/2410.09403, 2024. URL\nhttps://arxiv.org/abs/2410.09403.\nLu Sun, Aaron Chan, Yun Seo Chang, and Steven P Dow. ReviewFlow: Intelligent scaffolding\nto support academic peer reviewing. In Proceedings of the 29th International Conference on\nIntelligentUserInterfaces,pp.120–137,2024.\nKyle Swanson, Wesley Wu, Nash L. Bulaong, John E. Pak, and James Zou.\nThe virtual lab: Ai agents design new sars-cov-2 nanobodies with experi-\nmental validation. bioRxiv, 2024. doi: 10.1101/2024.11.11.623004. URL\nhttps://www.biorxiv.org/content/early/2024/11/12/2024.11.11.623004.\nXiangru Tang, Qiao Jin, Kunlun Zhu, Tongxin Yuan, Yichi Zhang, Wangchunshu Zhou, Meng\nQu, Yilun Zhao, Jian Tang, Zhuosheng Zhang, et al. Prioritizing safeguarding over au-\ntonomy: Risks of LLM agents for science. ArXiv preprint, abs/2402.04247, 2024. URL\nhttps://arxiv.org/abs/2402.04247.\n27\nWei Tao, Yucheng Zhou, Wenqiang Zhang, and Yu Cheng. MAGIS: LLM-based multi-\nagent framework for GitHub issue resolution. ArXiv preprint, abs/2403.17927, 2024. URL\nhttps://arxiv.org/abs/2403.17927.\nTrieu H Trinh, Yuhuai Wu, Quoc V Le, He He, and Thang Luong. Solving olympiad geometry\nwithouthumandemonstrations. Nature,625(7995):476–482,2024.\nKeithTyser,BenSegev,GastonLonghitano,Xin-YuZhang,ZacharyMeeks,JasonLee,UdayGarg,\nNicholas Belsten, Avi Shporer, Madeleine Udell, et al. AI-driven review systems: Evaluating\nLLMsinscalableandbias-awareacademicreviews. arXivpreprintarXiv:2408.10365,2024.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\nGomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Is-\nabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus,\nS. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information\nProcessing Systems 30: Annual Conference on Neural Information Processing Sys-\ntems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5998–6008, 2017. URL\nhttps://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abst\nHanchenWang, TianfanFu,YuanqiDu,WenhaoGao,KexinHuang,ZimingLiu, PayalChandak,\nShengchaoLiu,PeterVanKatwyk,AndreeaDeac,etal.Scientificdiscoveryintheageofartificial\nintelligence. Nature,620(7972):47–60,2023a.\nRui Wang, Hongsong Feng, and Guo-Wei Wei. ChatGPT in drug discovery: A case study on\nanticocaine addiction drug development with Chatbots. Journal of chemical information and\nmodeling,63(22):7189–7209,2023b.\nRuochengWang, Eric Zelikman, GabrielPoesia, Yewen Pu, Nick Haber, andNoah D. Goodman.\nHypothesissearch:Inductivereasoningwithlanguagemodels. InTheTwelfthInternationalCon-\nference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenRe-\nview.net,2024a. URLhttps://openreview.net/forum?id=G7UtIGQmjm.\nXingyaoWang, BoxuanLi, YufanSong,FrankF. Xu, XiangruTang,MingchenZhuge,JiayiPan,\nYueqiSong,BowenLi,JaskiratSingh,HoangH.Tran,FuqiangLi,RenMa,MingzhangZheng,\nBill Qian, YanjunShao, Niklas Muennighoff,Yizhe Zhang, BinyuanHui, JunyangLin, Robert\nBrennan,HaoPeng,HengJi,andGrahamNeubig.OpenHands:AnopenplatformforAIsoftware\ndevelopersasgeneralistagents,2024b. URLhttps://arxiv.org/abs/2407.16741.\nYizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahA.Smith,DanielKhashabi,and\nHannanehHajishirzi. Self-Instruct: Aligninglanguagemodelswith self-generatedinstructions.\nInAnnaRogers,JordanBoyd-Graber,andNaoakiOkazaki(eds.),Proceedingsofthe61stAnnual\nMeetingoftheAssociationforComputationalLinguistics(Volume1: LongPapers),pp.13484–\n13508,Toronto,Canada,July2023c.AssociationforComputationalLinguistics. doi: 10.18653/\nv1/2023.acl-long.754.URLhttps://aclanthology.org/2023.acl-long.754.\nWenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, and William Wang. Pride\nandprejudice: LLMamplifiesself-biasinself-refinement. InLun-WeiKu, AndreMartins, and\nVivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Com-\nputationalLinguistics(Volume1: LongPapers), pp.15474–15492,Bangkok,Thailand,August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.826. URL\nhttps://aclanthology.org/2024.acl-long.826.\nYuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu.\nExploring large language models for communication games: An empirical study on werewolf.\narXivpreprintarXiv:2309.04658,2023. URLhttps://arxiv.org/abs/2309.04658.\nJohnYang,CarlosE.Jimenez,AlexanderWettig,KilianLieret,ShunyuYao,KarthikNarasimhan,\nandOfirPress. SWE-agent: Agent-Computerinterfacesenableautomatedsoftwareengineering,\n2024a.\nXianjun Yang, Liangming Pan, Xuandong Zhao, Haifeng Chen, Linda Petzold, William Yang\nWang, and Wei Cheng. A survey on detection of LLMs-generated content. In\nYaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Findings of the As-\nsociation for Computational Linguistics: EMNLP 2024, pp. 9786–9805, Miami,\nFlorida, USA, November 2024b. Association for Computational Linguistics. URL\nhttps://aclanthology.org/2024.findings-emnlp.572.\n28\nZonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang,\nQingyuanHu,XinruiChen,ZhenheZhang,FuwenLuo,ZhichengGuo,PengLi,andYangLiu.\nPosition: Towards unified alignment between agents, humans, and environment. In Forty-first\nInternationalConferenceonMachineLearning,ICML2024,Vienna,Austria, July21-27,2024.\nOpenReview.net,2024c. URLhttps://openreview.net/forum?id=DzLna0cFL1.\nJianxiang Yu, Zichen Ding, Jiaqi Tan, Kangyang Luo, Zhenmin Weng, Chenghua Gong,\nLong Zeng, RenJing Cui, Chengcheng Han, Qiushi Sun, Zhiyong Wu, Yunshi Lan, and\nXiang Li. Automated peer reviewing in paper SEA: Standardization, evaluation, and\nanalysis. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Findings\nof the Association for Computational Linguistics: EMNLP 2024, pp. 10164–10184, Mi-\nami, Florida, USA, November 2024. Association for Computational Linguistics. URL\nhttps://aclanthology.org/2024.findings-emnlp.595.\nWeihao Zeng, Can Xu, YingxiuZhao, Jian-GuangLou, andWeizhu Chen. Automaticinstruction\nevolving for large language models. In Yaser Al-Onaizan, Mohit Bansal, and Yun-NungChen\n(eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Pro-\ncessing,pp.6998–7018,Miami, Florida,USA, November2024.AssociationforComputational\nLinguistics. URLhttps://aclanthology.org/2024.emnlp-main.397.\nJiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen,\nMingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, et al. AFlow: Automat-\ning agentic workflow generation. ArXiv preprint, abs/2410.10762, 2024a. URL\nhttps://arxiv.org/abs/2410.10762.\nRuisiZhang,ShehzeenSamarahHussain,PaarthNeekhara,andFarinazKoushanfar. {REMARK-\nLLM}:Arobustandefficientwatermarkingframeworkforgenerativelargelanguagemodels. In\n33rdUSENIXSecuritySymposium(USENIXSecurity24),pp.1813–1830,2024b.\nHaoZhao,MaksymAndriushchenko,FrancescoCroce,andNicolasFlammarion. Longismorefor\nalignment: A simplebuttough-to-beatbaselineforinstructionfine-tuning. InRuslan Salakhut-\ndinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix\nBerkenkamp(eds.),Proceedingsofthe41stInternationalConferenceonMachineLearning,vol-\nume 235 of Proceedings of Machine Learning Research, pp. 60674–60703.PMLR, 21–27 Jul\n2024. URLhttps://proceedings.mlr.press/v235/zhao24b.html.\nXuandong Zhao, Yu-Xiang Wang, and Lei Li. Protecting language generation models via\ninvisible watermarking. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Bar-\nbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), International Conference on\nMachine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202\nof Proceedings of Machine Learning Research, pp. 42187–42199. PMLR, 2023. URL\nhttps://proceedings.mlr.press/v202/zhao23i.html.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\nZiLin,ZhuohanLi,DachengLi,EricP.Xing,HaoZhang,JosephE.Gonzalez,andIonStoica.\nJudging LLM-as-a-Judge with MT-Bench and Chatbot Arena. In Alice Oh, Tristan Naumann,\nAmir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (eds.), Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural Information Processing\nSystems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL\nhttp://papers.nips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-\nYangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, and Chenhao Tan. Hypoth-\nesis generation with large language models. ArXiv preprint, abs/2404.04326, 2024. URL\nhttps://arxiv.org/abs/2404.04326.\nA IMPLEMENTATION DETAILS OF THE BABY-AIGS SYSTEM\nInthissection,weelaboratetheimplementationdetailsoftheBABY-AIGSsystem. Allartifactsare\nusedasintendedwiththeirlicensestrictlyfollowedinourwork.\n29\nA.1 RESEARCH-AGNOSTIC IMPLEMENTATION\nSystem Pipeline We posit that all agents mentioned in Section 3.2 contribute to a full-process\nAIGS system, but based on preliminary experiments, we simplify the design of EXPAGENT and\nLITERATUREAGENTtoalargeextentinourimplementation. ForEXPAGENT,giventhedesignof\nDSL with humaneffort, proposedmethodologygeneratedby PROPOSALAGENT can be executed\nreliablyinexperiments,whichisalsoshowninSection6. Thisreducestheneedofiterativelyrefin-\ningproposalsbetweenPROPOSALAGENT and EXPAGENT. For LITERATUREAGENT,preliminary\nresultsshowliteratureintegrationdidnotsignificantlyimpacttheoutcomesinbothphasesofBABY-\nAIGS.Weconcludethereasonasthatagentsfailedtounderstandthein-depthliteratureinformation\nandtheretrievalofliteraturedidnotmatchtheneedofeachagentperfectly. Therefore,inourim-\nplementation, we minimize the design of these two agents: EXPAGENT functions through fixed\ncode,andLITERATUREAGENTwasnotputintopraticaluse. Otheroptionalagentsaredesignedto\nfunctioninbroaderresearchfields,andwechosetoomittheminexperimentsbasedontheselected\nresearchtopicsforexperiments(Section3.4).\nHyper-Parameters Experimentsin ICL (In Context Learning) of the data engineeringresearch\nandinlanguagemodelingresearchareconductedon8NVIDIAGeForceRTX309024GBGPUs.\nExperimentsinSFT(SupervisedFine-tuning)ofthedataengineeringresearchandinSelf-Instruct\nalignmentresearchareconductedon8A10080GBGPUs. Allresearchesutilizethegpt-4o-2024-\n05-13 model as the underlying model for our agents. When agents invoke GPT-4o, we use the\nopenaimodule6 witha temperaturesettingof0.7, whileallotherparametersare settingasdefault\nvalues. During the synthesis of proposals, PROPOSALAGENT generates three sets of proposals\nwithatemperatureof0.7. Aftergeneration,theJaccardsimilarity(Jaccard,1901)ofbigramsetsis\ncalculatedbetweenthemethodologyofeachproposalandthemethodologyproducedintheprevious\niteration. Theproposalwiththe lowestsimilarityinmethodologyis selectedasthefinaloutputto\nincrease its diversity. For REVIEWAGENT and FALSIFICATIONAGENT, they invoke the GPT-4o\nonlyonceeachtimewhengeneratingresponses.\nA.2 RESEARCH-SPECIFIC IMPLEMENTATION\nDataEngineering Inthisresearchexperiment,oursystemistaskedwithexploringdifferentap-\nproachestoimprovethequalityofAlpaca-GPT4dataset(Pengetal.,2023).TheDSLconfiguration\nandinstanceareshowninFigure5andFigure7. TheLlama-3-8B-Instruct7modelisemployedto\nrate all data samples with the principles in DSL. We deploy Llama-3-8B-Instruct using vLLM8,\nconfiguringthetemperatureto0.05,whilekeepingallotherparametersatthedefaultsettings. We\nuse Llama-3-8B9 for ICL- and SFT-alignment, and the model and the fine-tuned checkpoints are\ndeployed using vLLM with a maximum token limit of 1024, while other parameters follow the\ndefault configurations provided by FastChat10. In falsification process, the BABY-AIGS system\nidentifiesthefactorsthatcontributetoqualityimprovementsandconcludewhetherthereareways\ntostablyimprovethequalityoftheextracteddataset,thusdeliveringvaluablescientificdiscoveries.\nForsignificancescreeninginFALSIFICATIONAGENT,iterationsareidentifiedashavingsignificant\nimprovementsif the difference of adjacent benchmarkingresults exceeds 1.5 for the ICL-aligned\nLlama-3-8B on the Vicuna-Bench (the validation benchmark) or 0.5 on the MT-Bench (the test\nbenchmark). From these iterations, candidates for scientific discovery are extracted. For hyper-\nparameters, we set the total iteration number M = 5 and set the multi-sample threads number\nN =32.\nSelf-Instruct Alignment In this research experiment, our system is tasked with exploring dif-\nferent approaches to improve the quality of synthesized SFT data from a seed dataset in Self-\nInstruct11 (Wangetal., 2023c). We use GPT-4o to rewrite the seed data for better quality with\nthetemperatureparametersetto0.05. The DSL configurationandinstanceareshowninFigure5\nandFigure8. We usetheLlama-3-8B12 modeltogenerateinstructionsandresponses,withitalso\nservingasthebasemodelforSFTalignment.WeuseLoRA(Huetal.,2022)methodfromLLaMA-\n6https://github.com/openai/openai-python\n7https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n8https://github.com/vllm-project/vllm.\n9https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n10https://github.com/lm-sys/FastChat.\n11https://github.com/yizhongw/self-instruct.\n12https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n30\nFactory13tofine-tunethemodelwithdefaulttraininghyper-parameters14. Theotherexperimentset-\ntingisthesameasdataengineeringresearch.Forhyper-parameters,wesetthetotaliterationnumber\nM = 15andset themulti-samplethreadsnumberN = 1dueto limitedcomputingresourcesfor\nparallelmodeltraining.\nLanguage Modeling In this research, the system is tasked to pre-train a mini-sized language\nmodel on several small corpora, aiming to improve performance by minimizing loss on the se-\nlecteddatasets. TheexperimentmainlyfollowsthesamesetupasthelanguagemodelingtaskinAI\nScientist(Luetal., 2024), basedonthenanoGPTproject15. The DSL configurationandinstance\nareshowninFigure5andFigure9, whereweguidethemodelsinadjustingparametersrelatedto\nmodelarchitectureandtrainingprocess. Fortheexperiments,weusethesamplingscriptsprovided\ninthetemplatecodewithoutmodifications. Forhyper-parameters,wesetthetotaliterationnumber\nM = 10andset themulti-samplethreadsnumberN = 1dueto limitedcomputingresourcesfor\nparallelmodeltraining.\nB EXPERIMENT DETAILS\nB.1 GUIDELINES FORHUMAN EVALUATORS\nTo thoroughlyassess the qualityof ourfalsification process, we conducteda humanevaluationof\n20agent-generatedfalsificationlogs. Theguidelinesaresummarizedasfollows:\n• ImportanceScore: Assessthesignificanceoftheproposedscientificdiscoverycandidate,\nconsideringitspotentialimpactonexperimentalresultsanditsrelevanceandconsistency\nwiththemainexperiments.\n• Consistency Score: Evaluate whether the proposed ablation experiments align with the\nscientificdiscoverycandidateandwhethertheexperimentappropriatelyisolatesthefactor\ninquestion.\n• CorrectnessScore: Determinewhetherthefinalscientificdiscoverydrawnfromthefalsi-\nficationprocessiscorrectbasedontheablationandbaselineresults.\nForeachdimension,theevaluatorassignsanintegerscorerangingfrom0to2,whereahigherscore\nindicatesbetterperformance.TheoverallstatisticresultsareshowninTable2.\nB.2 API COSTS OF THEFULL-PROCESS RESEARCH EXPERIMENT\nInourexperiments,wemeasuredtheaveragetokencountsandcostsofdifferentphasesof BABY-\nAIGS (Section 3.2) for invoking the GPT-4o API and the results are presented in Table 8. Note\nthatastheexperimentalrecordsinpastiterationsareusedasinputinmostrequests,withtheriseof\niteration,thelengthofrecordwillconsequentlyincrease,leadingtotheuseofmoretokens.\nInputTokens GeneratedTokens Cost($)\nPre-Falsification(periter.) 6,616.2 761.5 0.045\nFalsification(perdisc. cand.) 43,375.5 1,120.3 0.234\nTable 8: Average token consumption and API costs for GPT-4o API in the full-process research\nexperiment. The costs at pre-falsification phase is calculated for each iteration, and the costs at\nfalsificationphaseiscalculatedforeachdiscoverycandidate.\nB.3 DSL DEMONSTRATIONS FORDIFFERENTRESEARCH TOPICS\nWe present an example of the methodology in DSL format generated during the experiment for\neachresearchtopic,asshowninFigure7,Figure8andFigure9,correspondingtodataengineering,\nself-instructalignment,andlanguagemodeling,respectively.\n13https://github.com/hiyouga/LLaMA-Factory.\n14https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/train_lora/llama3_lora_sft.yaml\n15https://github.com/karpathy/nanoGPT.\n31\nData Engineering\nLLM Generated\n{\n“Paradigm”: “Data Sample Rating & Filtering”,\n“Principles”: “Relevance: The data point should be relevant to the task of multi-turn conversation and instruction-following.\\n\nCompleteness: The conversation should be complete and coherent, without abrupt endings or missing context.\\nInstruction adherence:\nThe responses should strictly follow the given instructions and provide accurate information.\\nConversational flow: The dialogue should\nflow naturally, with each turn logically following the previous one.\\nComplexity handling: The data point should demonstrate the ability to\nhandle complex and challenging questions effectively.\\nEngagement: The conversation should be engaging and maintain the user's\ninterest throughout.\\nEach data point should involve multi-turn dialogue.\\nResponses should be contextually relevant to the preceding\nturns.\\nData points should cover a diverse range of topics to mimic common use cases.\\nResponses should be coherent and\ngrammatically correct.\\nEach response should show logical progression and consistency across turns.\\nRelevance to the prompt: The\nresponse should directly address the question or task presented in the prompt.\\nCoherence: The response should be logically structured\nand easy to follow.\\nGrammar and syntax: The response should be free of grammatical and syntactic errors.\\nCreativity and depth: The\nresponse should demonstrate creative thinking and provide in-depth information when required.\\nConsistency: The response should\nmaintain consistency in its argument or narrative throughout.\\nLength: Ensure responses are comprehensive, aiming for lengths similar\nto high-scoring entries (1000 to 3000 characters).\\nWord Count: Encourage comprehensive and thorough responses, ensuring the\ncontent is relevant and informative.\\nUnique Words: Ensure responses contain a broad range of unique words while maintaining\nrelevance and coherence.\\nStopwords Count: Ensure responses are detailed and contextually rich.\\nKeyword Overlap: Ensure\nresponses are relevant and contextually appropriate.\\nDiversity: Aim for answer diversity in the range of 0.396 to 0.690.\\nAverage Word\nLength: Encourage balanced word lengths between queries and answers.\\nSentiment: Train models to deliver engaging, relevant, and\npositive responses.\\nCoherence Score: Refine the scoring method to better capture logical progression and consistency.\\nInstruction\nAdherence: Ensure responses have high instruction adherence.\\nComplexity Score: Prioritize generating detailed and complex answers.\n\\nEngagement Score: Ensure responses are engaging and interactive.”,\n“Number”: 27,\n“Threshold”: 15,\n“Ratio”: 0.7\n}\nFigure7:TheDSLinstancefordataengineeringresearch.\nLLM-Generated Self-Instruct Alignment\n{\n“Paradigm”: “Instruction Data Synthesis”,\n“Prompt”: “1. Ensure queries are between 50-150 characters and answers are between 300-1500 characters. Aim for clear and\nconcise queries (10-26 words) and detailed yet concise answers (55-254 words).\\n2. Balance specificity to provide clear and relevant\ninformation without being overly detailed (Query specificity: 1, Answer specificity: 2-4). Ensure specific terms are contextually relevant.\\n\n3. Maintain moderate complexity in language to ensure clarity and conciseness (Query clarity score: 2-5, Answer clarity score: 3-7).\nAvoid jargon unless necessary.\\n4. Increase relevance by incorporating task-specific keywords and ensuring both queries and answers\nare contextually relevant and detailed. Ensure answers directly address the queries.\\n5. Diversify the seed data to cover a broad range\nof tasks, topics, and scenarios, including more complex instructions. Include tasks of varying complexity and from different domains\n(e.g., healthcare, finance, education).\\n6. Use an LLM to perform the initial evaluation and rewrite. Have human reviewers refine the\nrewritten instructions.\\n7. Implement a structured feedback mechanism to continuously refine the principles and methodology.\\n\n8. Analyze high-scoring tasks and responses on VicunaBench and MT-bench to tailor the principles.”,\n“Seed”: true\n}\nFigure8:TheDSLinstanceforself-instructalignmentresearch.\n32\nLanguage Modeling\nLLM Generated\n{\n“Paradigm”: “Generative Pre-training”,\n“LLM_name”: “gpt-4o”,\n“n_layer”: 6,\n“n_embd”: 384,\n“dropout”: 0.2,\n“bias”: false,\n“learning_rate”: 0.001,\n“max_iters”: 5000,\n“weight_decay”: 0.1,\n“beta1”: 0.9,\n“beta2”: 0.99,\n“grad_clip”: 1.0,\n“decay_lr”: true,\n“warmup_iters”: 100\n“lr_decay_iters”: 15,\n“min_lr”: 0.0001\n}\nFigure9: TheDSLinstanceforlanguagemodelingresearch.\nC PROMPTING STRUCTURE\nIn this section, we will briefly introduce the prompting structures of the PROPOSALAGENT, RE-\nVIEWAGENT,andFALSIFICATIONAGENTasshowninFigure10,Figure11,andFigure12,respec-\ntively.Fordetailedprompts,pleaserefertoourcoderepository16.\nProposalAgent\nSystem Prompt LLM Output Select the\ngreatest\nYou are an experienced scientist.\nsemantic\nThe task you are faced with a certain scientific research\ntask and you need to make some scientific discoveries. LLM Output difference\nfrom\nYou are provided with the task, the goal to fulfill which is related\nprevious\nto the task, and the existed experiment results and review.\n... LLM Output methodology Final\nOutput\nUser Prompt\n... ...\nYou are now an data curation scientist.\nYou are faced with a potentially large-scaled, mixed-quality data.\nYou would be ... LLM Output\nHistory\n## Turn 1 ... LLM Output\nFigure10: ThepromptingstructureforthePROPOSALAGENTincludesageneralsystemprompt,a\nresearch-topic-specificuserpromptandhistorylogs.TheLLMgeneratesmultipleoutputs,covering\nelementssuchasidea,methodology,DSL,etc. Fromtheseoutputs,theonewhosemethodologyhas\nthegreatestsemanticdifferencefromthepreviousround’smethodologyisselected astheideafor\nthecurrentround,aimingtoboostcreativityinideation.\n16https://github.com/AgentForceTeamOfficial/Baby-AIGS.\n33\nReviewAgent\n... System Prompt LLM LLM\n**query** is the query of ... System Prompt\n**answer** is the answer of ... You are an experienced\n* F* od ra eta xs ae mt* p* l eis , ta h elis mt o ef t r. i. c. can be **length** New Metrics s ac yie on ut nis gt sta cs hk oe lad r w thit rh o ug gu hid tin hg eir Eval with\n'''python research project. ... Metric1\nreturn {\"query_length\": len(query),\n\"answer_length\": len(answer)}'''... Metric Value1 Eval with ExpReview\nUser Prompt Metric Value2\n. #..\n# Data\nU onse Vr icP uro nm a-p Bt\nench\nMe .t .r .ic2\nIn this case, the proposal is ... Data: ...; Metric Value: ... Eval with Merge\nThe methodology is ... Metric Value3 ... MetricN\nThe hypothesis is ... ... ## Final Score\nThe metric is ... ...\nThe metrics and code in the last iteration... Metric ValueN LLM\nSystem Prompt\nYou are an experienced scientist tasked with guiding a young scholar through their research project.\nThroughout the process, the young scholar will present their research topic, including their proposal,\nmethodology, domain-specific language (DSL), hypothesis, metrics and some experiment results.\nHere is the breakdown of these elements: ...\nYou need to evaluate his proposal, methodology, and DSL based on his experimental results, and\nprovide insightful suggestions for the next steps in his research.\nUser Prompt Proposal\n## My Research Task Description LLM\nReview\nI want to curate the Alpaca-GPT4 Database to make it a high-quality one for the MT-bench. ...\n## Current Research ...\n## Experiment Result ...\nHistory\n## Past Research\n### Turn1\nProposal: xxx; Methodology: xxx; ...\n### Turn2 ...\nFigure11: The REVIEWAGENT willfirstgeneratenewmetricsandthenanalyzeeachmetricindi-\nviduallyusingtheLLM.Followingthis, the REVIEWAGENT willcalltheLLMtomergetheanal-\nysis resultsforeach metric, resultingin the ExpReview. Next, the REVIEWAGENT willassess the\nexperimentalresultsbyintegratinginsightsfrompreviousideasandexperiments,yieldingthePro-\nposalReview.\n34\nFalsificationAgent\nTurn1\n...\nSystem Prompt LLM\n...\nSystem Prompt\nTurn2 The student has already done a lot of experiments Now you need to carry out an ablation\n... and got some improvement against the baseline. study. You have access to all the\nTurnM However, he has no idea what lead to the experiment records, and a proposal\nimprovement of the result and what is the real DiscCand1 about what ablation study you need ...\nSignificance scientific rule behind the improvement. For First, you should select a BASELINE...\nScreening You should... DiscCand2 each\none User Prompt\nUser Prompt ...You are faced with a potentially\nTurnQ1 ...You are faced with a potentially large-scaled, DiscCand3 large-scaled, mixed-quality data. You\nTu ..r .nQ2 m deix se cd ri- pq tiu oa nl it oy\nf\nd aa dta o.\nw\nY no su\ntr\new ao mul d\nta\nb se\nk,\np ar no dv id yoe ud sla ht oe ur la\nd\n... w ofo au l dd\no\nb we\nn\np str ro ev aid me d\nta\nl sa kte\n,\nr\na\nna\nd\nd ye os ucr sip ht oio un\nld\nTurnQn curate the provided data to ... DiscCandK curate the provided data to ...\nLLM System Prompt Result1 ... System Prompt\nThe student has already done the main experiment\nUser Prompt and got the discovery from the experiment. Also,\nAblationExp1 Result2 h Ne\no\nwh ,a ys\no\nc uo n nd eu ec dt e tod dth ee\nc\nida eb la wt hio en\nth\ne ex rp te hr eim de isn ct o.\nvery is\nLLM Result3 still reasonable based on the result of the ablation Scientific\nAblationExp2 study. ... LLM\nDiscovery\nAblationExp3 DSL1 Result4 User Prompt\n...You are faced with a potentially large-scaled,\n... DSL2 ... mixed-quality data. You would be provided later a\n... description of a downstream task, and you should\nAblationExpT DSLT ResultT curate the provided data to ...\nFigure12: The FALSIFICATIONAGENT firstscreensallhistoryturnstoidentifyturnswithnotable\nchangesinresults. Itthengeneratesdiscoverycandidatesfromtheresultsobtainedthroughsignif-\nicance screening. For each discoverycandidate, it thencreates severalablationexperimentsetups\nandgeneratesthecorrespondingDSLtoobtainexperimentalresults. Oncetheexperimentalresults\nareobtained,theFALSIFICATIONAGENTcallsontheLLMtoproducethefinalscientificdiscovery.\n35",
    "pdf_filename": "AIGS_Generating_Science_from_AI-Powered_Automated_Falsification.pdf"
}