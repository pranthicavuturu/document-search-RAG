{
    "title": "Enhancing Multi-Class Disease Classification:",
    "abstract": "termsofmulti-classdiseaseclassificationviapre-trainedlanguage more attention, as it serves with a large dataset on medical records and literature [3]. One of the most important NLP calconditions.Weexcludednon-cancerconditionsandexamined areas is text classification, which helps in assigning a set of fourspecificdiseases.WeassessedfourLLMs,BioBERT,XLNet, andBERT,aswellasanovelbasemodel(Last-BERT).BioBERT, documentstothecorrectcategoriesbasedontheircontent.The which was pre-trained on medical data, demonstrated superior latest developments in the domain of NLP (Natural Language performance in medical text classification (97% accuracy). Sur- Processing) have completely changed how text categorization prisingly,XLNetfollowedclosely(96%accuracy),demonstrating isimplementedasapartofmedicalactivities.Thankstoword its generalizability across domains even though it was not pre- embeddings, transformers, and deep learning architectures trained on medical data. LastBERT, a custom model based on thelighterversionofBERT,alsoprovedcompetitivewith87.10% (i.e., the backbone of research in NLP), systems can now accuracy(justunderBERT’s89.33%).Ourfindingsconfirmthe categorize medical texts more accurately and with higher importance of specialized models such as BioBERT and also efficiency than ever before! Word embeddings like Word2Vec support impressions around more general solutions like XLNet andGloVecanelucidatemedicallexiconlearningbyrevealing andwell-tunedtransformerarchitectureswithfewerparameters semantic relations among words. More recently, transformer- (in this case, LastBERT) in medical domain tasks. Index Terms—Medical Conditions, Computational Biology, based architectures (most notably BERT = Bidirectional En- Neoplasms, Cardiovascular, Nervous System, Digestive system, coder Representations from Transformers) demonstrated an Natural Language Processing, Deep learning, Transformer mod- extraordinary ability to deal with the intricacies of natural els, BioBert, XLNet, LastBERT; language as well as capturing context [4]. These advanced naturallanguageprocessingmethodsusedtoalleviatetheissue I. INTRODUCTION of ambiguity and polysemy in medical text seem promising. The widespread of information and the internet has led to a For instance, transformer-based models do better than we are huge growth in the content volume of electronic documents at solving the select few about-counts by letting their whole posted on the internet. Such large and free-form text is decision-making process consider the surrounding context to easy to use for automatic text classification [1]. The most differentiate between noise and names of different medical common approach is called a bag of words, and binary (on problemsthatsoundexactlylikeorsimilartosymptoms.These a scale of 0 or 1) are features that can then be utilized in modelsarealsoabletofindintricatepatternsfrombigdatasets, supervised classification algorithms such as Support Vector hence the detection of new or uncommon medical conditions. Machines (SVMs), Naive Bayesian Classifiers (Turbo & Tax- Theaimoftheresearchistoseehowstate-of-the-artnatural man / NHLBI ), etc.... [2]. Given the relative sparsity and language processing systems perform in identifying diseases simplicity with which some phrases can be dismissed, as well from text data. Furthermore, we will compare multiple ad- as little training data, research has turned toward focusing on vanced NLP models and discuss which of their capabilities more complex traits. The text classification, especially the are more suitable for medical text classification. We will 4202 voN 91 ]LC.sc[ 1v21721.1142:viXra",
    "body": "Enhancing Multi-Class Disease Classification:\nNeoplasms, Cardiovascular, Nervous System, and\nDigestive Disorders Using Advanced LLMs\nAhmed Akib Jawad Karim Muhammad Zawad Mahmud\nDepartment of Computer Science and Engineering Department of Electrical and Computer Engineering\nBRAC University North South University\nDhaka, Bangladesh Dhaka-1229, Bangladesh\nakibjawaad@gmail.com zawad.mahmud1@northsouth.edu\nSamiha Islam Aznur Azam\nDepartment of Electrical and Computer Engineering Department of Computer and Science Engineering\nNorth South University Bangladesh Army University of Science and Technology\nDhaka-1229, Bangladesh Saidpur, Bangladesh\nsamiha.islam2@northsouth.edu aznurazam2@gmail.com\nAbstract—In this research, we explored the improvement in medical test classification in the field of text mining, gets\ntermsofmulti-classdiseaseclassificationviapre-trainedlanguage more attention, as it serves with a large dataset on medical\nmodelsoverMedical-Abstracts-TC-Corpusthatspansfivemedi-\nrecords and literature [3]. One of the most important NLP\ncalconditions.Weexcludednon-cancerconditionsandexamined\nareas is text classification, which helps in assigning a set of\nfourspecificdiseases.WeassessedfourLLMs,BioBERT,XLNet,\nandBERT,aswellasanovelbasemodel(Last-BERT).BioBERT, documentstothecorrectcategoriesbasedontheircontent.The\nwhich was pre-trained on medical data, demonstrated superior latest developments in the domain of NLP (Natural Language\nperformance in medical text classification (97% accuracy). Sur- Processing) have completely changed how text categorization\nprisingly,XLNetfollowedclosely(96%accuracy),demonstrating\nisimplementedasapartofmedicalactivities.Thankstoword\nits generalizability across domains even though it was not pre-\nembeddings, transformers, and deep learning architectures\ntrained on medical data. LastBERT, a custom model based on\nthelighterversionofBERT,alsoprovedcompetitivewith87.10% (i.e., the backbone of research in NLP), systems can now\naccuracy(justunderBERT’s89.33%).Ourfindingsconfirmthe categorize medical texts more accurately and with higher\nimportance of specialized models such as BioBERT and also efficiency than ever before! Word embeddings like Word2Vec\nsupport impressions around more general solutions like XLNet\nandGloVecanelucidatemedicallexiconlearningbyrevealing\nandwell-tunedtransformerarchitectureswithfewerparameters\nsemantic relations among words. More recently, transformer-\n(in this case, LastBERT) in medical domain tasks.\nIndex Terms—Medical Conditions, Computational Biology, based architectures (most notably BERT = Bidirectional En-\nNeoplasms, Cardiovascular, Nervous System, Digestive system, coder Representations from Transformers) demonstrated an\nNatural Language Processing, Deep learning, Transformer mod- extraordinary ability to deal with the intricacies of natural\nels, BioBert, XLNet, LastBERT;\nlanguage as well as capturing context [4]. These advanced\nnaturallanguageprocessingmethodsusedtoalleviatetheissue\nI. INTRODUCTION\nof ambiguity and polysemy in medical text seem promising.\nThe widespread of information and the internet has led to a For instance, transformer-based models do better than we are\nhuge growth in the content volume of electronic documents at solving the select few about-counts by letting their whole\nposted on the internet. Such large and free-form text is decision-making process consider the surrounding context to\neasy to use for automatic text classification [1]. The most differentiate between noise and names of different medical\ncommon approach is called a bag of words, and binary (on problemsthatsoundexactlylikeorsimilartosymptoms.These\na scale of 0 or 1) are features that can then be utilized in modelsarealsoabletofindintricatepatternsfrombigdatasets,\nsupervised classification algorithms such as Support Vector hence the detection of new or uncommon medical conditions.\nMachines (SVMs), Naive Bayesian Classifiers (Turbo & Tax- Theaimoftheresearchistoseehowstate-of-the-artnatural\nman / NHLBI ), etc.... [2]. Given the relative sparsity and language processing systems perform in identifying diseases\nsimplicity with which some phrases can be dismissed, as well from text data. Furthermore, we will compare multiple ad-\nas little training data, research has turned toward focusing on vanced NLP models and discuss which of their capabilities\nmore complex traits. The text classification, especially the are more suitable for medical text classification. We will\n4202\nvoN\n91\n]LC.sc[\n1v21721.1142:viXra\nalso consider the implications for public health surveillance al. [9] studied multi-label text classification of cardiovascular\nand patient care in healthcare settings. Thus, the original drug attributes based on BERT and BiGRU. The data was\ncontributions of this work are as follows: collectedfromNMPA.Afteranalysisofablationandcrossover\n• For this dataset, our model BioBERT blasted all the experiments, their proposed model achieved an accuracy of\navailable models and ended up with an accuracy rate of 83.39%. Hagan et al. [10] classified cardiovascular disease\n97%. Also, based on Table IV, this model outperformed usingMLmethods.Theyusedtwopubliclyavailabledatasets.\nexistingtextclassificationmodelsformedicalconditions. The first one is the arrhythmia dataset from the repository\n• Our novelty is annotated with the introduction of our of machine learning databases provided by the University of\ncustom language model, LastBERT which we trained California Irvine (UCI), and the second one is the Kaggle\nas a smaller version of BERT. The model achieved cardiovasculardiseasedataset.FortheUCIdataset,ExtraTrees\nan accuracy of 87.06 %, which is very comparable to outperformed all with 96% accuracy, with gradient boosting\nthe BERT performance at 89.32% but with only 29M achieving 94%. Although, for the Kaggle dataset, gradient\nparametersvsthe110MinthecaseofBERT.Thismodel boosting was able to come on top with 74% accuracy. Kanwa\nof transformers used fewer computational resources pro- etal.[11]classifiedcardiovasculardiseaseusingMLmethods.\nducing satisfactory results. TheyusedthecardiovasculardiseasedatasetfromKaggle.The\ndataset contains a total of 70,001 records. Among the ML\nII. RELATEDWORK\nmodels,theXGBOOSTandNa¨ıveBayesperformedwellwith\nIn recent years, NLP has seen impressive advances with 92.34% and 92.31% accuracy, respectively.\nthe development of powerful (pre-trained) language models\nIII. METHODOLOGY\nlike BERT and all its extensions (SciBERT, etc.), such as\nA. Dataset\nBERT. These models achieved remarkable performance in\ndifferent tasks that concerned text classification, such as The Medical-Abstracts-TC-Corpus [12] was used in this\nmedical diagnosis or disease classification. Prior studies have investigation available at GitHub. This is a text dataset on\ndemonstrated the utility of these models in automatically five various medical conditions. The five conditions are neo-\nrecognizing and categorizing diseases, suggesting that they plasms, digestive system diseases, nervous system diseases,\ncould strengthen multi-class disease classification for major cardiovascular diseases, and general pathological conditions.\ncategories (e.g., neoplasms), as well as some other types such These are labeled from 1 to 5 on the above sequence, respec-\nascardiovascular,nervoussystem,ordigestivediseases.Blom tively. There were 14,438 records, among which 3,163 were\n[5] in her MS thesis building a conversational agent with rasa neoplasms, 1,494 were digestive system diseases, 1,925 were\ntoenrichamedicalabstractsdatasetusedthesamedatasetfor nervous system diseases, 3,051 were cardiovascular diseases,\nthe text classification part. She used one ML and two LLMs and4,805weregeneralpathologicalconditions.Asthegeneral\nand got the highest accuracy from SciBERT, which is 65%. pathologicalconditionisnotinfected,wedecidetoexcludeit.\nPrabhakar and Won [6] classified medical text using hybrid The data was split into 80-20 ratios for training and testing,\ndeeplearningmodels.TheHallmarksdatasetandAIMdataset respectively. A total of 11,550 records were taken for training\nwere utilized in this study. The datasets are a collection of and 2,888 for testing. Table I represents a partial medical\nbiomedical paper abstracts with cancer hallmark annotations abstract of each medical condition of the dataset.\nand biomedical publication abstracts, which were written B. Data Prepossessing\naround 1852. This set of data includes three characteristics\nAs the database was imbalanced, we used the up-sampling\nofcancer,includinginitiatingmetastasisandinvasion,cellular\nand down-sampling techniques to balance it. Among the\nenergetics,andinflammationthatispromotedbytumors.Their\ntraining set, data was divided into 80:20 ratio again. Here,\nhybrid BiGRU performed remarkably with 95.76%. Ahmed\n80% was used for training, and 20% validation set was used\net al. [7] used deep neural networks to classify biomedical\nfor validation. The test set was used to evaluate the models\ntexts for cardiovascular diseases. They used the OHSUMED-\naftertrainingwascompleted.Finally,pandasDataFrameswere\n400 dataset, which contains abstracts of PubMed documents\nconverted into Hugging Face datasets for training, validation,\nfrom23cardiovasculardiseaseclasses.Thismodel,ultimately\nand testing.\na DNN with BLSTM, achieved 49.4% accuracy on their\ntest set of spectrograms. Chaib et al. [8] did multi-label C. Training Methodology\ntext classification of cardiovascular disease reports based on 1) BioBERT: HuggingFacemodelBioBERT(biobert-base-\nthe GL-LSTM model. For this study, they utilized a public cased-v1.1) was loaded along with the BioBERT tokenizer\ndataset called Ohsumed. The master file of the Ohsumed and model for sequence classification, as well as a function\ndatabase includes 50,216 medical summaries for patients in to tokenize medical abstracts applying padding/truncation so\nthe year 1991 and consists of nearly half a million words they all have the same size. These functions then tokenize\nfrom unstructured text. The collection is partitioned into three the datasets in a batched fashion for training or evaluation.\nsubsets–training(10percent),testing(51outofeveryhundred Trainingargumentswereepoch=10,batchsize=16,warmup\ndocuments are used), and background distribution (39/100 steps = 100, early stopping patience = 3, and weight decay of\nrecords). The model already reached 92.7% accuracy. Cui et 0.1, respectively, for training.\nTABLE I: Dataset Representation (Summary)\ntotheavailableP100GPUfortraining/inference.Thetraining\nLabel Disease MedicalAbstract(Truncated) was done with the following training arguments: number of\n1 Neoplasms Neuropeptide Y and neuron-specific enolase epochs=10,batchsize=16,warm-upsteps=100,weightdecay\nlevels in benign and malignant pheochromo-\nis decaying rate = 0.1, and early stopping patience =2 [13].\ncytomas.Neuron-specificenolase(NSE)isthe\nisoformofenolase,aglycolyticenzymefound\nD. Work Flow Diagram\nintheneuroendocrinesystem...\n2 Digestive Sexuallytransmitteddiseasesofthecolon,rec- The workflow diagram of this study is visualized in Fig. 1\nsystem tum, and anus. The challenge of the nineties.\ndiseases During the past two decades, an explosive\ngrowth in both the prevalence and types of\nsexuallytransmitteddiseases...\n3 Nervoussys- Does carotid restenosis predict an increased\ntemdiseases risk of late symptoms, stroke, or death? The\nidentificationofcarotidrestenosisasanunex-\npectedlatecomplicationofcarotidendarterec-\ntomyhaspromptedconcernsregardingitsim-\nportance as a source of new cerebral symp-\ntoms,stroke,anddeath....\n4 Cardiovascular Pharmacomechanicalthrombolysisandangio-\ndiseases plastyinthemanagementofclottedhemodial-\nysisgrafts:earlyandlateclinicalresults.The\nresults of pharmacomechanical thrombolysis\nandangioplastyof121thrombosedhemodial-\nysisgrafts...\n2) XLNet: The XLNetTokenizer and model were config-\nured for sequence classification, i.e., the ’xlnet-base-cased’\ntype. A function to tokenize medical abstracts, pad, and\ntruncate it as a maximum length of 512 tokens. The image\nprocessingfunctionisthenappliedinabatchedmannertothe\ntraining, validation, and test datasets to get them ready based\non what comes next: model training evaluation. Setting the\ntraining arguments as epoch = 10, early stopping patience =\n2, weight decay= 0.1, and batch size=16 with warm-up steps\n=100 for training of pre-train BioBERT model. Fig.1:Workflowdiagramoftheproposedstudyofmulti-class\n3) BERT: We have loaded a pre-trained BERT Tokenizer disease classification\n(for ’bert-base-cased’ model). An anonymization function is\nthen written to prepare our medical abstracts for the tokenizer IV. RESULTANALYSIS\nby trimming and padding them, readying each input length\nIn this section, model training curves, performance curves,\nof 512 tokens. This tokenization function is then applied to\nconfusion matrix, and ROC curve for the two best models\nthe train, validation, and test datasets in a batched manner\nwith the worst model’s training curves and confusion matrix\nto preprocess them for model training and evaluation. The\nare shown.\ntraining arguments are epoch = 10, batch size = 16, warmup\nsteps = 100, early stopping patience = 2, and weight decay A. BioBERT\n0.1 for training the model. Fig. 2 displays the training loss and accuracy curve for the\n4) LastBERT: BERT tokenizer was created, and the model BioBERT Model. The training and validation losses decrease\n’bert-base-uncased’wasloaded.Ithasatokenizationfunction, steadily, which is a parameter for effective learning as well as\nwhich is also specific to the task of processing medical ab- improved generalization. Meanwhile, accuracy rises to about\nstracts,paddingandtruncatingeach”abstract”–whichguaran- 1.0 and remains there confirming the performance of being\ntees that all are 512 tokens long. The CustomBERTModel able to classify those medical conditions becomes extremely\nclass is kind of a wrapper over the base BERT model (we use stable as training goes on.\nBertForSequenceClassification), and we simply add a dropout Fig.3representstheperformancecurveofBioBERTmodel.\nlayer on top of Bert’s output so as to avoid Overfitting. The The three metrics demonstrate an acceptable smooth behavior\nforward method implements both the calculation of loss and over the epochs, from around 0.89–0.90 in the first epoch\nlogits in it. This initializes the custom model as a function to roughly 0.96 by (7/12). This means that performance\ncreatecustomstudentmodel that tweaks configuration for improves, without loss in accuracy or reliability as the model\nsmaller BERT models by tuning parameters such as hidden is trained further into more epochs.\nsize, num attention heads, num of hidden layers, and interme- InFig.4,theconfusionmatrixoftheBioBERTisdisplayed.\ndiatesize.Afterthat,thiscustomizedmodelwillbetransferred The matrix is quite accurate with a large number of correct\nvarious healthcare classes in a dataset.\nFig. 2: Loss and accuracy curve of BioBERT\nFig. 5: ROC curve of BioBERT\nB. XLNet\nInFig.6,thetraininglossandaccuracygraphfortheXLNet\nmodel is shown. The training and validation losses are always\nheading down which is also a good point that the model\nlearned something new so previously made errors decreased.\nAt the same time, accuracy also continuously grows to over\nFig. 3: Performance curve of BioBERT 0.9,whichmeansbetterabilityineachepochtodetectmedical\nconditions correctly.\npredictions being along the diagonal which means that the\nmodel was able to correctly classify many samples in each\nclass.Afewcasesofneoplasmswerewronglylabeledasother\ndiseases, thus the generalization power and robustness for a\ntext classification task are excellent.\nFig. 6: Loss and accuracy curve of XLNet\nFig.7displaystheperformancemetricsgraphfortheXLNet\nmodel. The lowest score for all was 0.88-0.89 on the first\nepoch. The three metrics show a smooth improvement, with\nvaluesnearlyreaching0.96byepochsixwhilestillincreasing\ninvalue.Thismeansthemodelisgettingbetterandimproving\nfor text classification with every epoch by its ability to\npreciselycategorizeoutputclasses,whichinturnconclusively\nincreases precision-recall and overall performance as it goes\nFig. 4: Confusion matrix of BioBERT on training.\nFig. 8, the confusion matrix of the XLNet model is shown.\nThe ROC curve for the BioBERT model is visualized in Thematrixishighlyaccurate,youcanseemostofthepredic-\nFig. 5. All classes get an AUC of 1.00 because few false tionsarealongadiagonaltruepositiveandfalsenegative.Still,\npositives appear in the classification performance. The curve certain misclassifications do occur; a number of neoplasms\ndisplays the capability of that model to differentiate between were classified as other diseases, though sparsely. To sum up,\nFig. 7: Performance curve of XLNet\nthe matrix shows that the XLNet model performs well in text\nFig. 9: ROC curve of XLNet\nclassification tasks and is able to predict correctly for over\n95% of samples across all classes.\nFig. 10: Loss and accuracy curve of LastBERT\ncardiovascular heart disease are particularly diagnosed more\ncorrectly than often wrong ones. Nonetheless, some errors are\nworth noting — e.g., category confusion with nervous system\nFig. 8: Confusion matrix of XLNet diseases. The matrix shows that LastBERT works fine, but\nit could be improved especially in separating similar disease\nROC curves for the XLNet model are visualized in Fig. 9. categories.\nTheseclass-averagedprecision-recallcurvesareperfect,inthe\nsense of having AUCs equal to 1.00, which essentially means\nthat there is a full separation and hence few false negatives\nor positives at all for ideal classifiers. This graph highlights\nthat the XLNet model performs among the best in accurately\nclassifyingdifferentmedicalclassespresentwithinourdataset.\nC. LastBERT\nFig. 10 shows the loss and accuracy curve for LastBERT.\nThe loss in the training is steadily decreasing, demonstrating\nthat the model keeps learning. Although validation loss de-\ncreases at the beginning, after the third epoch it starts to rise\na little which could mean overfitting is in implementation.\nHowever, the accuracy is pretty constant and remains close\nto 0.9, so this probably means that our model performs\nclassification very well throughout all training periods.\nThe confusion matrix of the LastBERT is shown in Fig.\n11.Thereisahigherconcentrationoftruepositivepredictions\nFig. 11: Confusion matrix of LastBERT\nin the diagonal on the matrix — and neoplasms, as well as\nD. Model Performance Comparison the models, demonstrating once again how essential domain-\nspecific pre-trained model training is to medical-text classifi-\nTable II compares the performance metrics with our four\ncation tasks. An extremely strong performance of 96% fresh\nlanguage models (BioBERT, XLNet, BERT, and LastBERT)\nnormal precision, suggesting that general-purpose models still\nfocusing on both macro-average columns, then weighted av-\nmay provide decent quality in the at-spontaneous field when\nerage over precision/recall/F1 score. BioBERT and XLNet\nfinetuned (XLNet not even created for the medical domain;\nshow a good performance, which has more than 0.96 in\nyet?) Although the custom-developed LastBERT model was\nall metrics (positive means classifying). Compared to these\nsmaller and more resource-efficient, It achieved a comparable\nbaselineperformancelevels,BERTandLastBERThaveworse\nperformance against a much larger baseline BERT, which\nmetrics overall, especially the latter, which has been shown\nsuggests that even with content resources, the use of purpose-\nonly as good for lower classification accuracy numbers.\noptimized models could help. Several future works can be\nTABLE II: Performance Metrics Comparison performed to enhance the accuracy and efficiency of the\nmodel,andthefollowingpotentialoptionscouldbeconsidered\nMacroAverage WeightedAverage\nModels for experimentation. One possible first step in this direction\nPrecision Recall F1Score Precision Recall F1Score\nBioBERT 0.97 0.97 0.97 0.97 0.97 0.97 would be to experiment with including more domain-specific\nXLNet 0.96 0.96 0.96 0.96 0.96 0.96 data at training time from which models like XLNet and\nBERT 0.81 0.82 0.81 0.83 0.82 0.83\nLastBERT 0.78 0.79 0.78 0.81 0.80 0.80 LastBERT could benefit. This could potentially lead us down\nasecondpathofavant-gardealgorithms,ormaybetheanswer\nTable III shows the number of parameters of the models is to do more work on hybrid, so as you get many benefits\nin millions, accuracy, F1 score, precision, and recall of the from one methodology and others benefitting in another, then\nfour applied LLMs inthis study.Clearly, interms ofaccuracy at least have this slant going for classification can be pretty\nandf1score,BioBERToutperformedalltheothermodels.Al- solid.Anotherbenefitofthisresearchisthefactthatitreduces\nthoughXLNETwasnottrainedonbiomedicaldatasets,itstill model bloat, making them actually usable, which could come\nperformed well. Although it is the smaller model, lastBERT in handy for deploying solutions more extensively, including\nproduced respectable results with only 29M compared to all resource-limited healthcare settings.\nthe others. This means faster training in a low computational\nresource. BERT is a 110M large LLM.\nREFERENCES\nTABLE III: Model’s Results\n[1] C. Zhou, C. Sun, Z. Liu, and F. Lau, “A C-LSTM neural network for\ntextclassification,”arXivpreprintarXiv:1511.08630,2015.\nModels Parameters Accuracy(%) F1Score Precision Recall\nBioBERT 110M 97.00 0.9656 0.9662 0.9656 [2] T.Joachims,“Textcategorizationwithsupportvectormachines:Learn-\nXLNet 110M 96.00 0.9577 0.9588 0.9578 ing with many relevant features,” in European conference on machine\nBERT 110M 89.33 0.8932 0.8943 0.8933 learning. Springer,1998,pp.137–142.\nLastBERT 29M 87.10 0.8706 0.8943 0.8722 [3] A. R. Aronson, “Effective mapping of biomedical text to the UMLS\nMetathesaurus: the MetaMap program.” in Proceedings of the AMIA\nSymposium. AmericanMedicalInformaticsAssociation,2001,p.17.\nAs shown in Table IV, the models are compared to those\n[4] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova,“Bert:Pre-training\npreviously studied. It is evident from the table that the\nof deep bidirectional transformers for language understanding,” arXiv\nBioBERT model overpowers all others in the framework. preprintarXiv:1810.04805,2018.\n[5] F.A.M.Blom,“BuildingaConversationalAgentwithRasatoEnricha\nTABLE IV: Result Comparison MedicalAbstractsDataset,”Ph.D.dissertation,TilburgUniversity,2023.\n[6] S. K. Prabhakar and D.-O. Won, “Medical text classification using\nStudy Dataset Model Accuracy(%) hybrid deep learning models with multihead attention,” Computational\nThispaper Medical-Abstracts- BioBERT 97.00 intelligenceandneuroscience,vol.2021,no.1,p.9425655,2021.\nTC-Corpus [7] N.Ahmed,F.Dilmac¸,andA.Alpkocak,“ClassificationofBiomedical\nThispaper Medical-Abstracts- XLNet 96.00 Texts for Cardiovascular Diseases with Deep Neural Network Using a\nTC-Corpus WeightedFeatureRepresentationMethod,”inHealthcare,vol.8,no.4.\n[10] Arrhythmiadataset ExtraTrees 96.00 MDPI,2020,p.392.\nfromUCI [8] R.Chaib,N.Azizi,N.E.Hammami,I.Gasmi,D.Schwab,andA.Chaib,\n[6] Hallmarksdataset BiGRU 95.76 “GL-LSTMModelForMulti-labelTextClassificationOfCardiovascular\nandAIMdataset Disease Reports,” in 2022 2nd International Conference on Innovative\n[8] Ohsumed GL-LSTM 92.70 Research in Applied Science, Engineering and Technology (IRASET).\nIEEE,2022,pp.1–6.\n[11] CardiovascularDisease XGBoost 92.34\ndatasetfromKaggle [9] H. Cui, L. Zhang, X. Zhu, X. Guo, and Y. Peng, “Multi-label text\nclassification of cardiovascular drug attributes based on BERT and\nBiGRU,”JournalofIntelligent&FuzzySystems,no.Preprint,pp.1–11,\n2024.\nV. CONCLUSIONANDFUTUREWORK [10] R.Hagan,C.J.Gillan,andF.Mallett,“Comparisonofmachinelearning\nmethodsfortheclassificationofcardiovasculardisease,”Informaticsin\nAdvanced large language models are used in this study to MedicineUnlocked,vol.24,p.100606,2021.\nclassify text abstracts to determine which medical condition [11] F. Kanwal, M. K. Abid, M. S. Maqbool, N. Aslam, and M. Fuzail,\n“Optimized Classification of Cardiovascular Disease Using Machine\nthe person is in. It is not surprising that BioBERT pre-trained\nLearning Paradigms,” VFAST Transactions on Software Engineering,\nwith medical text performed best (97% accuracy) among vol.11,no.2,pp.140–148,2023.\n[12] T.Schopf,D.Braun,andF.Matthes,“Evaluatingunsupervisedtextclas-\nsification:zero-shotandsimilarity-basedapproaches,”inProceedingsof\nthe20226thInternationalConferenceonNaturalLanguageProcessing\nandInformationRetrieval,2022,pp.6–15.\n[13] A. A. J. Karim, K. H. M. Asad, and M. G. R. Alam, “Larger models\nyield better results? streamlined severity classification of adhd-related\nconcerns using bert-based knowledge distillation,” 2024. [Online].\nAvailable:https://arxiv.org/abs/2411.00052",
    "pdf_filename": "Enhancing_Multi-Class_Disease_Classification_Neoplasms,_Cardiovascular,_Nervous_System,_and_Digestiv.pdf"
}