{
    "title": "Can Agents Spontaneously Form a Society Introducing a Novel Architecture for Generative Multi-Agents",
    "abstract": "Generative agents have demonstrated impressive capabilities in specific tasks, but most of these frameworks focus on independent tasks and lack attention to social interactions. We introduce a gen- erative agent architecture called ITCMA-S, which includes a basic framework for individual agents and a framework called LTRHA that supports social interactions among multi-agents. This archi- tecture enables agents to identify and filter out behaviors that are detrimental to social interactions, guiding them to choose more favorable actions. We designed a sandbox environment to simu- late the natural evolution of social relationships among multiple identity-less agents for experimental evaluation. The results showed that ITCMA-S performed well on multiple evaluation indicators, demonstrating its ability to actively explore the environment, recog- nize new agents, and acquire new information through continuous actions and dialogue. Observations show that as agents establish connections with each other, they spontaneously form cliques with internal hierarchies around a selected leader and organize collective activities.",
    "body": "Can Agents Spontaneously Form a Society?\nIntroducing a Novel Architecture for Generative Multi-Agent to Elicit Social Emergence\nHanzhong Zhang\nKunming University of Science and Technology\nKunming, Yunnan Province, China\narmihia@foxmail.com\nJibin Yin\nKunming University of Science and Technology\nKunming, Yunnan Province, China\nyjblovelh@aliyun.com\nMulin Jiang\nKunming University of Science and Technology\nKunming, Yunnan Province, China\n237800718@qq.com\nCong Su\nKunming University of Science and Technology\nKunming, Yunnan Province, China\n787358363@qq.com\nABSTRACT\nGenerative agents have demonstrated impressive capabilities in\nspecific tasks, but most of these frameworks focus on independent\ntasks and lack attention to social interactions. We introduce a gen-\nerative agent architecture called ITCMA-S, which includes a basic\nframework for individual agents and a framework called LTRHA\nthat supports social interactions among multi-agents. This archi-\ntecture enables agents to identify and filter out behaviors that are\ndetrimental to social interactions, guiding them to choose more\nfavorable actions. We designed a sandbox environment to simu-\nlate the natural evolution of social relationships among multiple\nidentity-less agents for experimental evaluation. The results showed\nthat ITCMA-S performed well on multiple evaluation indicators,\ndemonstrating its ability to actively explore the environment, recog-\nnize new agents, and acquire new information through continuous\nactions and dialogue. Observations show that as agents establish\nconnections with each other, they spontaneously form cliques with\ninternal hierarchies around a selected leader and organize collective\nactivities.\nKEYWORDS\nGenerative agents, Multi agent system, Social interaction, LLM\n1\nINTRODUCTION\nLarge language models (LLMs) have contributed to significant\nprogress in the field of natural language processing and are widely\nused in various domains, such as machine translation [44], dialogue\ngeneration [9], and content creation [46]. These models are capable\nof correctly parsing and generating complex sentence structures\nand have demonstrated unprecedented capabilities in understand-\ning language. However, LLMs often lack true comprehension and\nrely more on pattern matching and probabilistic predictions [10].\nIt has also been difficult to create systems to achieve human-like\nsystematic generalization [22]. To overcome these problems, re-\nsearchers have introduced LLM-based agents. This has allowed the\nincorporation of external knowledge bases to supplement a model’s\nknowledge gaps in specific domains [43]. They can also be used to\ndecompose a complex task into multiple simpler tasks to achieve\nhierarchical processing [41].\nOn this basis, Park et al. [31] introduced a novel LLM-based\nagent, namely, a generative agent. This agent simulates trustwor-\nthy human behavior. Generative agents have the ability to make\nmultifaceted inferences about an environment, themselves, and\nother individuals in the environment. They can design daily ac-\ntivity plans based on their own characteristics and experiences\nand adjust their plans to changes as they occur. When a situation\nchanges, they can flexibly update plans to ensure adaptation to it.\nThe importance of this progress cannot be ignored. In human\n– computer interaction, especially in virtual assistants, customer\nservice robots, and even more complex systems, such as self-driving\ncars and smart homes, the ability of agents to generate believable\nhuman behavior is crucial. Generative agents can support more\nadaptive and flexible interaction processes. This ability not only en-\nhances the system’s responsiveness to dynamic situations but also\nbrings human–computer interaction closer to natural behavioral\npatterns in interpersonal communication. In addition, by simulat-\ning human behavior, generative agents can demonstrate autonomy\nand sociality in various complex situations, making the interac-\ntion process smoother and more intuitive. This feature plays an\nimportant role in improving the user experience and increasing the\ntrustworthiness of a system [16].\nHowever, existing generative agent architectures still face many\nchallenges. While traditional agent structures are good at process-\ning and generating behaviors, they are primarily designed for iso-\nlated tasks and, thus, mostly lack a focus on sociality. This often\nmakes it difficult for them to model and apply the nuances of social\ninteractions, leading them to focus only on completing tasks and\noverlook behaviors that promote social connections. This is clearly\nnot conducive to cooperation among multiple agents and may lead\nto behaviors that are detrimental to the group [34]. In scenarios\ninvolving multiple agents, a lack of structured social behavior may\nlead to disjointed or even chaotic interactions. To truly harness the\npotential of these agents in domains requiring interaction, there\nis an urgent need to explore their ability to participate in social\ninteractions, establish relationships, and exhibit emerging social\nbehaviors.\nIn this paper, we improve upon an existing LLM-based agent\narchitecture (the internal time-consciousness machine based agent\n[ITCMA] introduced by [49]) and propose ITCMA-S (the “S” signi-\nfies our contribution of social interaction) architecture to enable\nagents to adapt to multi-agent interaction scenarios. It contains a\narXiv:2409.06750v2  [cs.MA]  19 Nov 2024\n\nZhang et al.\nbasic framework for an individual agent and the LTRHA framework\nfor social interaction among multiple agents (the latter is named for\nits four modules: locale & topic, resources, habitus, and action; they\nare described later in the paper). This provides a structured way for\nagents to identify and filter actions that are not conducive to social\ninteraction, thereby guiding them to choose actions that are more\nconducive to improving the social atmosphere of a scene. It also\nallows them to form new relationships during interactions with\nother agents, while remembering the history of these interactions.\nThe formation of these dynamic relationships occurs naturally and\nis not pre-programmed. This means that the agent has the ability\nto adapt to its social environment.\nTo understand whether and how ITCMA-S leads to the emer-\ngence of sociality among generative agents, we established an eval-\nuation environment called IrollanValley. This is a sandbox world\ndesigned to test and allow the observation of generative agent\nbehavior and social interactions. It contains six characters, eight\nareas, and six operational primitives. Each area has unique furni-\nture and other items, and an agent can interact with the various\ncharacters and objects and move around in the areas. Based on this\nenvironment, we modeled the natural evolution of social relation-\nships among multiple agents without identities in the environment.\nThe human evaluation results showed that the agents had sponta-\nneously developed good social skills on each evaluation indicator\nand were able to actively explore the environment, meet new agents,\nand acquire new information through continuous actions and con-\nversations. By observing the environment, we found that, in the\nprocess of establishing connections among each other, the agents\nspontaneously formed a clique with internal hierarchies around an\nelected leader and organized collective activities under the leader’s\nguidance. Agents not included in this clique were mostly in isolated\nstates. Even when they were in the same room as other agents, they\ninteracted less and focused mainly on their personal activities.\nIn summary, this paper makes the following contributions:\n• We propose a generative multi-agent structure, ITCMA-S,\nwhich includes the structure of an individual generative\nagent and a multi-agent social collaboration framework,\nLTRHA.\n• We established an environment for multi-agent social eval-\nuation, IrollanValley, which consists of six roles, eight areas,\nand six operational primitives designed to assess the utility\nand sociality of multiple agents.\n• We conducted validation and ablation studies in IrollanVal-\nley through human evaluation, and the results showed that\nITCMA-S performed excellently across multiple indicators.\n• Furthermore, we discovered that agents can actively explore\nthe environment, cooperate with other agents through a\ndivision of labor, and spontaneously form small groups and\nleadership structures in complex social settings.\nSection 2 of this paper introduces related works; Section 3 intro-\nduces the improvement of the individual agent structure of ITCMA-\nS on an existing generative agent architecture and includes an ex-\nplanation of how it generates and infers action through perception,\nmemory, and emotion-driven mechanisms; Section 4 introduces a\nmulti-agent interaction framework in ITCMA-S, namely LTRHA;\nSection 5 introduces the experimental evaluation of the sociality of\nITCMA-S and discusses the process and results of the formation\nof the agents’ social relationships; and Section 6 summarizes the\nmain findings of the study and suggests future research potential.\n2\nRELATED WORK\n2.1\nLLM-based agent\nPark et al. [31] introduced a generative agent based on an LLM and\ndemonstrated that it can generate trustworthy individual behavior\nand sudden group behavior in simulations. For example, a genera-\ntive agent will turn off a stove when it sees its breakfast burning\nand will stop to chat when it encounters other agents with whom it\nwants to talk. Based on this research, numerous LLM-based agents\nhave emerged. Zhang et al. [45] proposed AppAgent, which con-\nstructs an agent to operate any smartphone application. Hong et\nal. [20] proposed an 18-billion-parameter visual language model\n(VLM) named CogAgent, which specializes in GUI understanding\nand navigation. Vezhnevets et al. [39] provided the Concordia li-\nbrary to simulate agent interactions in physical, social, and digital\nspaces. Among these, a special agent called the game master (GM)\nis responsible for simulating the environment of agent interactions.\nAgents take action by describing what they want to do in natural\nlanguage, and the GM then translates their actions into appropriate\nimplementations.\n2.2\nResearch on the Structure of Generative\nAgents\nThe original structure of generative agents, as described by Park et\nal. [31], mainly consisted of three parts: memory flow, reflection,\nand planning. The concept of a chain of thought (CoT) was partic-\nularly important for improvements to the planning module [41].\nCoT refers to the ability of an LLM to think and reason gradually\nthrough a series of steps or iterations, reflecting human cognitive\nprocesses. Traditional language models generate responses without\nclear intermediate steps, which can lead to suboptimal answers,\nespecially in complex inference scenarios. CoT overcomes these\nlimitations by introducing intermediate steps to enable language\nmodels to reason, thereby enhancing the model’s ability to solve\nproblems. Mondal et al. [28] suggested using knowledge graphs\nto enhance multiple patterns to help models solve complex prob-\nlems, thereby triggering CoT functionality. Their proposed method,\nknowledge augmented multimodal (KAM)-CoT, decouples the infer-\nence process into two consecutive stages. In the first stage, practical\nreasons are provided, and in the second stage, the generated reasons\nare used as additional input to provide answers.\nAs an improvement to the memory module, Liu et al. [25] pro-\nposed the reasoning and acting through scratchpad and exam-\nples (RAISE) architecture, which was specifically designed to en-\nhance the functionality of conversational agents. It combines a\ndual-component memory system, similar to the short-term and\nlong-term memory functions of the human brain. Toy et al. [37]\nproposed a metacognitive module by improving the reflection mod-\nule in generative agents, allowing agents to broadly consider their\nsituations to create alternative strategies and improve their perfor-\nmance.\n\nCan Agents Spontaneously Form a Society?\nTo improve the overall structure of generative agents, Wu et al.\n[42] explored an alternative mechanism that utilizes prior knowl-\nedge encoded in an LLM without affecting the trainability of agents.\nTheir proposed three-step PET framework: Plan, Eliminate, and\nTrack. Lin et al. [24] proposed the method SwiftSage, which can\nachieve both fast and slow thinking in complex interactive reason-\ning tasks. It effectively blends the advantages of behavioral cloning\nand LLM.\n2.3\nResearch on the Sociality of Generative\nMulti-Agents\nBy interacting with each other, generative agents can exchange in-\nformation, form new relationships, and coordinate activities. These\nsocial behaviors occur naturally rather than being pre-programmed.\nOver time, agents form new relationships and remember their in-\nteractions with other agents [31]. Generative Multi-Agents can\nsimulate complex human systems. Wang et al. [40] designed a new\nframework called the mosaic expert observation wall (MEOW). In\nMEOW, real game data are processed by expert models trained on\nsimulated data and converted into natural language prompts to\nassist LLM inference.\nHowever, while an LLM can capture social norms, there is also\nresearch that suggests that an LLM cannot adequately understand\nsocial norms, especially culture-specific social norms. This defect\nmay lead to conflicts between generative agents, especially when\ntheir underlying LLMs are trained on text corpora from different\ncultural backgrounds [21, 32]. Ren et al. [34] proposed the specifi-\ncation architecture CRSEC (named for its four modules: Creation\n& Representation, Spreading, Evaluation, and Compliance) for gen-\nerative multi-agent systems to resolve this problem. Building on\nthis foundation, these researchers examined the emergence of so-\ncial norms in generative multi-agent systems. Ghaffarzadegan et al.\n[17] provided a new approach to developing models that reduces\nreliance on assumptions about human decision-making and uti-\nlizes the vast amount of data in LLMs to capture human behavior\nand decisions. By utilizing the extensive dataset in the LLM, their\ngenerative agent-based model helps represent human decisions in\ncomputational models. Motwani et al. [29] pointed out that groups\nof generative agents can use communication channels in ways that\nare unexpected to their developers. When sharing data, stealthy\ncollusion can help agents coordinate unwanted behavior on a larger\nscale, and GPT-4 has demonstrated unparalleled capabilities in this\nregard.\n3\nGENERATIVE AGENT FRAMEWORK\n3.1\nThe Internal Time-Consciousness Machine\nBased Agent\nZhang, Yin, et al. [49] introduced the internal time-consciousness\nmachine (ITCM), which is a computational consciousness structure.\nThe ITCM supports agents in taking action and making inferences\nin an open world. It can help generative agents become more flexible\nand intelligent when handling complex tasks; this improves their\ninterpretability and makes their actions easier to understand and\npredict. On this basis, they proposed ITCM-based agent (ITCMA).\nAs a generative model, ITCMA considers both the reasoning ability\nof agents and the interaction between agents and the environment\nto compensate for the shortcomings of LLMs in accomplishing\nspecific tasks.\nITCMA can be simply explained as a framework: it uses a spher-\nical coordinate space called a “phenomenal field” as one time frame\n(1f ) of perception representing a certain moment, and constructs a\ntime-continuous consciousness channel 𝐶𝑡of equivalent working\nmemory through a field string composed of retention (perception\nof the past) 𝑅𝑒𝑡and primal impression (perception of the present)\n𝑃𝐼𝑡at time 𝑡in units of f. The 𝐶𝑡can be combined with the long-\nterm memory 𝐴𝑀of the agent activated by perception, and the\npossible changes of protention (prediction of future perception)\n𝑃𝑟𝑜𝑡when an action is to be taken that can be deduced through\nthe time-series forecasting model (TSFM). After that, it blends into\na natural language format together with the intrinsic motivation\n𝑑𝑡, which includes the agent’s emotional state (including pleasure,\narousal, and dominance) and is provided to the LLM to generate\nthe output of the action. Its structure is shown in Figure 1.\nFigure 1: Structure of ITCMA. ITCMA’s main structure, the\nITCM, contains the consciousness channel, driver, and pro-\ntention. In the consciousness channel, retention and primal\nimpression are used to activate memory, and the driver con-\nsists of the dimensions of emotion and the driver from the\nprevious moment. These two are used to predict protention\nthrough the TSFM. The content of the ITCM will be converted\ninto formalized natural language, which will be delivered to\nthe LLM and will eventually cause it to act.\nThrough this mechanism, an agent perceives inputs from the\nenvironment and takes action as output to the environment. The\n“brain” of an agent is not equivalent to an LLM here but is replaced\nby a complete ITCMA structure including the agent’s memory. The\nLLM is only used as a tool. Experiments with ITCMA have demon-\nstrated the effectiveness and generalization of this architecture. The\ntrained agents exceeded the state of the art (SOTA) in the environ-\nment, and even completely untrained agents can start a task very\nquickly after exploring the environment and achieve good results.\n\nZhang et al.\nHowever, the structure of ITCMA still has shortcomings, in-\ncluding slow processing speed, excessive token consumption, and\nslow entry into the task context when untrained. To better test our\nassumptions about its performance, we first made certain improve-\nments to the structure of ITCMA, resulting in a generative multi-\nagent model for social interaction, namely ITCMA-S. It includes a\nstructure for an individual agent and a structure for multi-agent\ninteraction. The structure for an individual agent improved the\nmodules of memory, motivation, and action space reduction based\non ITCMA and are elaborated in the remaining parts of this section,\nwhile the structure for multi-agent interaction are discussed in\nSection 4.\n3.2\nMemory and Imagination\n3.2.1\nMemories Blended into the Present. In ITCMA, after a mem-\nory is awakened to the present moment, it is juxtaposed with the\nretention and primal impression in the consciousness channel. How-\never, the theory of creature consciousness suggests that phenom-\nenal consciousness requires the blending of a “phenomenal field”\nmechanism that may originate in the thalamus and neural inputs\nfrom different cortical areas responsible for processing memory-\nrelated information [3]. It is obvious that, for humans, the awak-\nening of memory is not simply juxtaposition but blending with\npresent consciousness. Conceptual blending is a cognitive activity\nthat combines information from different contexts [15]. Its main\nprocess is composition, which is the process of projecting input\nspaces (two different fields) into the blended space. Blending can\ncombine elements from the input spaces to provide relationships\nthat do not exist within a single input space.\nTherefore, based on conceptual blending theory, we hypothesize\nthat when a memory of ITCMA-S enters the current consciousness\nchannel, its phenomenal fields of observation and recollection are\nblended to obtain the imagination of this moment, and thus the\nmaterial of the consciousness channel is obtained. As shown in\nFigure 2, this process satisfies the following steps: In the first step,\nFigure 2(a), there is local matching between the phenomenal fields;\nthat is, the equivalent component connections are generated by the\nmatching. Once the match between the two fields is created, it is said\nthat there is cross-space mapping between them. In the second step,\nFigure 2(b), which is the blending process, the matching structure\nof the two phenomenal fields is utilized to establish the generic\nspace (which can be roughly understood as the common “belonging”\nclass containing the instances of the elements of the phenomenal\nfields). In the third step, Figure 2(c), via the generic space, the two\nphenomenal fields are projected into a new space: the blended\nspace. After this, components and structures in the phenomenal\nfield selectively enter the blended space, forming structures that\nare, to some extent, distinct from the original phenomenal field.\nWe stipulate that for completely identical objects, they are placed\nin the blended space after blending takes place (i.e., taking the\naverage); objects that match in the generic space (with similarity\nexceeding a threshold) are each placed in the blended space; and\nobjects that do not match have a certain probability of being placed\nin the blended space. Therefore, for the two phenomenal fields 𝑓𝑥\nand 𝑓𝑦, the blending process 𝐵𝑙𝑒𝑛𝑑(𝑓𝑥, 𝑓𝑦) follows Algorithm 1:\nFigure 2: The Conceptual Blending Process of the Phenome-\nnal Field. (a) Two phenomenal fields are matched to create\ncross-space mapping; (b) a generic space is established for the\nmatched objects in the two phenomenal fields; and (c) with\nthe help of the generic space, the components and structures\nin the two phenomenal fields selectively enter the blended\nspace.\nf𝑥=\n\nf𝑥1\n...\nf𝑥𝑎\n\n=\n\n𝑁𝑥1\n𝑝𝑜𝑠𝑥1\n...\n...\n𝑁𝑥𝑎\n𝑝𝑜𝑠𝑥𝑎\n\n=\n\n𝑁𝑥1\n1\n· · ·\n𝑁𝑥𝑛\n1\n𝜃𝑥1\n𝜑𝑥1\n𝛾𝑥1\n...\n...\n...\n...\n...\n...\n𝑁𝑥1\n𝑎\n· · ·\n𝑁𝑥𝑛\n𝑎\n𝜃𝑥𝑎\n𝜑𝑥𝑎\n𝛾𝑥𝑎\n\n(1)\nf𝑦=\n\nf𝑦1\n...\nf𝑦𝑏\n\n=\n\n𝑁𝑦1\n𝑝𝑜𝑠𝑦1\n...\n...\n𝑁𝑦𝑏\n𝑝𝑜𝑠𝑦𝑏\n\n=\n\n𝑁𝑦1\n1\n· · ·\n𝑁𝑦𝑛\n1\n𝜃𝑦1\n𝜑𝑦1\n𝛾𝑦1\n...\n...\n...\n...\n...\n...\n𝑁𝑦1\n𝑏\n· · ·\n𝑁𝑦𝑛\n𝑏\n𝜃𝑦𝑎\n𝜑𝑦𝑏\n𝛾𝑦𝑏\n\n(2)\n𝑆𝑝ℎ𝑒𝑟𝑖𝑐𝑎𝑙𝑆𝑖𝑚(𝐴, 𝐵) =\n1 −1\n3 (𝜔𝛾tanh(|𝛾𝐴−𝛾𝐵|) + 𝜔𝜃\n|𝜃𝐴−𝜃𝐵|\n𝜋\n+ 𝜔𝜑\n|𝜑𝐴−𝜑𝐵|\n2𝜋\n)\n(3)\n𝐹𝑖𝑒𝑙𝑑𝑆𝑖𝑚(𝑓𝑥, 𝑓𝑦) =\nÍ𝑎\n𝑖=1 𝜔𝑁𝐶𝑜𝑠𝑖𝑛(𝑁𝑥𝑖, 𝑁𝑦𝑗) + 𝜔𝑝𝑜𝑠𝑆𝑝ℎ𝑒𝑟𝑖𝑐𝑎𝑙𝑆𝑖𝑚(𝑝𝑜𝑠𝑥𝑖, 𝑝𝑜𝑠𝑦𝑗)\n𝑀𝑎𝑥(𝑎,𝑏)\n(4)\nAlgorithm 1 Conceptual Blending Algorithm of Phenomenal\nField 𝐵𝑙𝑒𝑛𝑑(𝑓𝑥, 𝑓𝑦)\nInput: Initial Fields 𝑓𝑥and 𝑓𝑦\nOutput: Blended Field 𝑓𝑧\n1: Initialize threshold of similarity degree 𝑇\n2: Initialize blended probability 𝑟\n3: for 𝑖𝑓𝑟𝑜𝑚1𝑡𝑜𝑎do\n4:\nfor 𝑗𝑓𝑟𝑜𝑚1𝑡𝑜𝑏do\n\nCan Agents Spontaneously Form a Society?\n5:\n𝑠←𝐹𝑖𝑒𝑙𝑑𝑆𝑖𝑚(𝑓𝑥\n𝑖, 𝑓𝑦\n𝑗)\n6:\nif 𝑠< 𝑇then\n7:\nContinue\n8:\nelse if 𝑠= 1 then\n9:\n𝑓𝑧\n𝑘←𝐴𝑣𝑒𝑟𝑎𝑔𝑒(𝑓𝑥\n𝑖, 𝑓𝑦\n𝑗)\n10:\nif 𝑓𝑧\n𝑘not in 𝑓𝑧then\n11:\nAdd 𝑓𝑧\n𝑘as a row to 𝑓𝑧\n12:\nend if\n13:\nBreak\n14:\nelse\n15:\nif 𝑓𝑥\n𝑖not in 𝑓𝑧then\n16:\nAdd 𝑓𝑥\n𝑖as a row to 𝑓𝑧\n17:\nend if\n18:\nif 𝑓𝑦\n𝑗not in 𝑓𝑧then\n19:\nAdd 𝑓𝑦\n𝑗as a row to 𝑓𝑧\n20:\nend if\n21:\nBreak\n22:\nend if\n23:\nend for\n24: end for\n25: There is a probability that rows in 𝑓𝑥and 𝑓𝑦that are not in\n𝑓𝑧will each have rate 𝑟added as a row in 𝑓𝑧.\n26:\n27: return 𝑓𝑧\nAmong them, 𝐶𝑜𝑠𝑖𝑛(𝐴, 𝐵) represents the cosine similarity be-\ntween 𝐴and 𝐵. For the retention 𝑅𝑒𝑡and primal impression 𝑃𝐼𝑡,\nthe acquisition of protention 𝑃𝑟𝑜𝑡can be corrected as follows:\nimaginet = Blend(PIt, M(PIt, Ret))\n(5)\nCt = [ Ret, PIt, M(PIt, Ret) ]\n(6)\nProt = TSFM(Ct, imaginet, dt),\n(7)\nwhere 𝐶𝑡is the content of the consciousness channel at time 𝑡,\nTSFM is the selected time-series forecasting model, and 𝑀is the\nprocess of triggering inventory memory through 𝑃𝐼𝑡and 𝑅𝑒𝑡.\n3.2.2\nMemory Storage and Compression. One of the reasons for\nthe slow processing speed of ITCMA is the memory activation\nalgorithm it uses. Its improved Levenshtein distance method pro-\nvides better memory query results. However, it consumes more\ntime than the simple cosine similarity algorithm. For this reason, it\nwas necessary to improve it.\nOne way to improve the speed of memory activation is to reduce\nthe number of memories that the agent needs to query. Due to the\nlearning of new memories, the retention and association of existing\nmemories will be affected [1]. One way to address this is to modify,\nsplit, and recombine memories over time, that is, to compress mem-\nories [11]. This compression can affect the accuracy of memory,\nbut its impact on recall is not as severe. In fact, people do not use\nprecise memories when making decisions [8]. The compression\nprocess of memory constantly generates new meanings [15], and\nmaking decisions based on such memories is sometimes seen as\nintelligent inference, which may be a source of the generalization\nof human intelligence [33].\nTherefore, by compressing old memories and blending them\nwhen they are recalled to the present moment, we enable ITCMA-\nS to reduce the total number of memories while preserving the\nrecall effect, thereby increasing the speed of the memory search. In\naddition, based on the mood congruence effect, we set the weight\nof the memory index to the emotional intensity accompanying the\nagent at the time of memory occurrence [11, 14, 23]. Specifically,\nto compress a segment of memory, we need to select the key frame\n𝑓𝑘𝑒𝑦that has the strongest arousal in that segment of memory.\nThe process 𝑀𝐵𝑙𝑒𝑛𝑑𝑛(f key, Memory1,n) of compressing a segment\nof memory Memory1,n with a length of 𝑛by 𝑓𝑘𝑒𝑦is expressed as\nfollows:\nMemory1,n = [f1, f2, f3 . . . , f𝑛]\n(8)\n𝑀𝐵𝑙𝑒𝑛𝑑𝑛(f key, Memory1,n) =\n(\nf key\n𝑖𝑓𝑛= 0.\nBlend(𝑀𝐵𝑙𝑒𝑛𝑑𝑛−1(f key, Memory1,n−1), fn)\n𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒.\n(9)\nAfter compression is complete, 𝑀𝐵𝑙𝑒𝑛𝑑𝑛(f key, Memory1,n) re-\nplaces the original Memory1,n position in the long-term memory\nbase to reduce the total number of memories.\n3.3\nEmotion and Motivation\nEmotions can help with decision-making, not just interfere with\nit, as most people believe [12]. For example, in decision-making,\nemotions can highlight the importance of a certain premise, thereby\nmaking a decision tend toward that premise. This idea coincides\nwith the practice in ITCMA of allowing LLMs to choose which\naction to perform by deducing the protention 𝑃𝑟𝑜𝑡of each action\nin the action space. However, although ITCMA provides LLMs with\nan internal driving force 𝑑𝑡that includes emotions for decision-\nmaking, it only adds the weighted sum of the three-dimensional\nPAD emotions at this moment to the internal driving force 𝑑𝑡−1\nat the previous moment. Indeed, agents tend to push pleasure and\ndominance to have the highest values possible [13, 36], but they\nalso generally tend to keep emotional arousal at a stable value [19].\nIn ITCMA-S, the arousal 𝐴𝑡-based mechanism of passive attention\nis quantified as the degree of change between the elements in re-\ntention and the elements in the current primary impression. The\ndominance 𝐷𝑡is quantified as the difference between the proten-\ntion 𝑃𝑟𝑜𝑡−1 at the previous moment and the primal impression\n𝑃𝐼𝑡at this moment. The pleasure 𝑃𝑡is quantified as the degree of\nsatisfaction with the agent’s 𝑑𝑒𝑠𝑖𝑟𝑒and the degree of avoidance\nof 𝑝𝑎𝑖𝑛. The expression 𝜔𝑃+ 𝜔𝐴+ 𝜔𝐷= 1 contains the dynamic\nweights of the emotions. Therefore, for the emotional dimensions\n𝑃𝑡,𝐴𝑡, 𝐷𝑡∈(−1, 1) at time 𝑡, the emotional values should be con-\nsidered as follows:\nPt = tanh(𝑑𝑒𝑠𝑖𝑟𝑒) −tanh(𝑝𝑎𝑖𝑛)\n(10)\nA𝑡= tanh(\n𝑡−1\n∑︁\n𝑛=1\n(\n2𝑛\n𝑡(𝑡−1) (𝑑𝑖𝑓𝑓(PI𝑡, ren))))\n(11)\nD𝑡= tanh(𝑑𝑖𝑓𝑓(PI𝑡, Prot−1))\n(12)\n\nZhang et al.\ndbias𝑡= 𝜔PPt + 𝜔DDt + 𝜔A(1−| At −At−1 |)\n(13)\nAmong them, the calculation of 𝑑𝑒𝑠𝑖𝑟𝑒and 𝑝𝑎𝑖𝑛∈[0, ∞) are\ndefined according to specific situations. For example, in reinforce-\nment learning tasks, 𝑑𝑒𝑠𝑖𝑟𝑒can be defined as reward, while 𝑝𝑎𝑖𝑛\ncan be defined as punishment. However, to avoid the situation of\nlocal optima (where agents enter a scenario in which they can con-\ntinuously obtain 𝑑𝑒𝑠𝑖𝑟𝑒and reduce 𝑝𝑎𝑖𝑛without taking any further\nactions), we introduce a demand dimension 𝑁𝑒for them.\nThe demand motivation model [27, 48] states that when an agent\nfalls into a local optimum and its basic needs are satisfied, these\nneeds are no longer important, and the agent moves on to more ad-\nvanced needs. As a result, the agent needs to pursue advanced needs\nto gain new 𝑑𝑒𝑠𝑖𝑟𝑒, and the 𝑑𝑒𝑠𝑖𝑟𝑒then gained from satisfying basic\nneeds falls while the 𝑝𝑎𝑖𝑛gained rises. This can be approximated\nas dynamic rewards and punishments. For 𝑑𝑏𝑖𝑎𝑠𝑡∈(−1, 1), these\nare as follows:\nNe = | dbias𝑡−dbias𝑡−1 |\n2\n(14)\ndt = dt−1 + Ned\nt\nbias\n(15)\n3.4\nReduction of Action Space\nThe PET framework created an elimination module for AlfWorld\nusing pre-trained Q&A models to filter out containers and objects\nunrelated to the current task based on common sense about the\ntask [42]. Through this step, the time required for an untrained\nagent to enter the task context can be effectively reduced. Similarly,\nITCMA-S also uses an LLM 𝐸𝑙𝑖𝑚to reduce the number of action\nspaces in a zero-shot manner. Specifically, for the target 𝐺of the\nagent, we create a prompt in 𝐷𝑒𝑠𝑐= “Your task is to: 𝐺. The actions\nyou can take are: 𝐴𝑆. The 𝑎𝑖will be relevant?” format for the exe-\ncutable action 𝑎𝑖∈𝐴𝑆in the action space 𝐴𝑆. 𝐸𝑙𝑖𝑚will output the\nconfidence score for the action 𝑎𝑖:\n𝜇ai = 𝐸𝑙𝑖𝑚(𝐷𝑒𝑠𝑐,𝐺,𝐴𝑆, ai)\n(16)\nAmong them, 𝜇ai ∈[1, 5]. When 𝜇ai is less than the threshold,\n𝑎𝑖will be removed from the action space. The elimination process\nis shown in Figure 3.\n4\nSOCIAL INTERACTION FRAMEWORK\nZhang, Duan, et al. [47] proposed a social regulation model for the\ndynamic adaptation of users in virtual interactive environments,\nnamely the tribal theater model (TTM), to address the core issue\nof “enhancing user interaction freedom.” This model emphasizes\nthe subjectivity of interactive users. In this section, based on the\nTTM and field theory [5], we present a multi-agent social interac-\ntion architecture, the LTRHA, for ITCMA-S, which consists of four\nmodules: locale & topic, resources, habitus, and action. We aimed\nto design an interaction architecture for generative agents to pro-\nmote the emergence of spontaneous social interactions within their\nsocieties. Specifically, there is no preset identity in the LTRHA envi-\nronment. Every agent has certain resources. The environment will\nprovide basic action options, such as using objects and communi-\ncating with other agents. The probability of successfully executing\nFigure 3: The Process of Reducing the Action Space. Due to\nthe high degree of freedom in the scene, there are too many\navailable actions. Among them, the red action is unrelated\nto the current goal, so it should be eliminated without the\nneed for further protention calculation.\nthese actions will depend on the number of resources and will be\nhanded over to the matrix model for processing after execution.\nAlong with the actions input to the model, there is a vector con-\nsisting of the current resource structure of the environment and a\nvector of topics that have been quantified according to the analysis\nof the emotions of each agent. Based on the input, the matrix model\nwill adjust the resource structure of the environment and output it\nas a vector to change the resource structure. The specific process is\nshown in Figure 4. We provide a detailed introduction to each part\nof the LTRHA framework in the sections that follow.\n4.1\nLocale and Topic\nIn the TTM, the field is decomposed into two parts: the tribe and the\natmosphere [47]. To distinguish the field in ITCMA-S from the field\nin ITCMA, we refer to the parts as the locale and topic. The locale\nand topic modules can be understood together as an interactive\nspace. In human society, such interactive spaces typically include\nlocales as physical spaces and topics as mental factors [26, 30]. For\nexample, in a speech setting, the stage and audience seats are part of\nthe locale, and the passion aroused by the speaker in the audience\nis a topic.\nWe define a sub-environment 𝑒𝑛𝑣of the overall environment,\nwhich includes a space and 𝑛agents occupying that space. We make\nthe spatial area and its contained objects 𝑙𝑜𝑐𝑒𝑛𝑣as the locale, and\nthe emotion synthesis function 𝑡𝑝𝑐𝑒𝑛𝑣of these agents is a topic.\nAmong them, we define agent𝑔𝑎𝑖∈𝐺𝐴with emotional dimensions\n𝑃𝑖,𝐴𝑖, 𝐷𝑖∈(−1, 1). The emotion synthesis function is described by\nthe following equation:\n𝑡𝑝𝑐𝑒𝑛𝑣=\nÍ𝑛\n𝑖=1 𝑃𝑖\n(𝐴𝑖+1)\n2\n𝑛\n(17)\n\nCan Agents Spontaneously Form a Society?\nFigure 4: Execution Process of the LTRHA. An agent executes\nactions with probabilities related to the number of resources\nand then hands over the actions, the current resource struc-\nture, and quantified topics of the environment to the matrix\nmodel for processing. The matrix model adjusts the resource\nstructure of the environment based on input.\nAs a result, the topic value of a sub-environment will be in the\ninterval [−1, 1], where less than zero is a negative atmosphere and\nmore than zero is a positive atmosphere. In 𝑒𝑛𝑣, any agent can\nchange the perception of other agents by affecting the objects in\n𝑙𝑜𝑐𝑒𝑛𝑣, thereby affecting 𝑡𝑝𝑐𝑒𝑛𝑣.\n4.2\nResources\nThe execution of actions by agents requires a certain amount of\nresources, just as implementing decisions in human society requires\na certain cost. Resources are allocated to the agents in the sub-\nenvironments based on the actions of the agents by a model called\nthe “matrix.”\n4.2.1\nCompetition for Limited Resources by Agents. The key to\ninteractive regulation is the resources possessed by an agent [5, 18].\nVirtual resources, such as the cultural level and social status, are\nconsidered interactive resources. We believe that the agents’ envi-\nronment is a space for competing resources. Changing the distri-\nbution and relative weights of resources is equivalent to changing\nthe structure of the environment. A resource is both a weapon and\nan object of contention, enabling its owner to exert influence on\nthe environment. Therefore, the number of resources possessed by\nan agent determines the actions it can perform in one time step.\nSpecifically, in the environment, a total of 𝑛agents 𝑔𝑎𝑖∈𝐺𝐴each\nhold a number of resources 𝑆𝑖. 𝑆𝑖is initially 1. Agents take turns\nexecuting actions. A specific 𝑔𝑎𝑖takes action with a probability\n𝑟𝑎𝑡𝑒𝑖as follows:\n𝑟𝑎𝑡𝑒𝑖= 0.5 + 𝑆𝑖𝑔𝑚𝑜𝑖𝑑(𝑆𝑖)\n2\n,\n(18)\nwhere the probability 𝑟𝑎𝑡𝑒𝑖is a function of the number of resources\nrelated to agent 𝑔𝑎𝑖as a percentage of the total number of resources.\n4.2.2\nDynamic Allocation of Resources by the Matrix. Consumed re-\nsources need to be replenished. Therefore, a mechanism is needed\nfor the circulation and allocation of resources. The model that\nreplaces natural rules and collective subconsciousness in human\nsociety for resource allocation and regulation is called the “matrix”\n[4]. It accepts a vector consisting of the current resource structure\nand a vector of topics that have been quantified based on the anal-\nysis of each agent’s emotions as input, and a new resource vector\nis output. For 𝑛> 2 agents 𝑔𝑎𝑖∈𝐺𝐴input their current actions\n𝑎𝑖, global resource structure 𝑆, and environmental topic 𝑡𝑝𝑐𝑒𝑛𝑣to-\ngether into the matrix model to obtain a new resource structure\n𝑆′ ←𝑚𝑎𝑡𝑟𝑖𝑥(𝑎𝑖,𝑆,𝑡𝑝𝑐𝑒𝑛𝑣).\nWe use an LLM as the matrix model and have it rank each agent\nbased on their personal goals and 𝑡𝑝𝑐𝑒𝑛𝑣. After that, if the number\nof resources increases, the maximum number of resources that the\nagent can receive 𝑠𝑚𝑎𝑥and the minimum number of resources that\nthe agent can receive 𝑠𝑚𝑖𝑛are set. The 𝑗-th ranked agent 𝑔𝑎𝑗can\nreceive the number of resources 𝑆′\n𝑗:\n𝑆′\n𝑗=\n\n\n0\n𝑗= 𝑛+1\n2\n𝑠𝑚𝑖𝑛+ |𝑗−𝑛\n2 | (𝑠𝑚𝑎𝑥−𝑠𝑚𝑖𝑛)\n| 𝑛\n2 −1|\n𝑗≤𝑛\n2\n−(𝑠𝑚𝑖𝑛+ |𝑗−𝑛\n2 −1| (𝑠𝑚𝑎𝑥−𝑠𝑚𝑖𝑛)\n| 𝑛\n2 −1|\n)\n𝑗> 𝑛\n2\n(19)\nTherefore, the higher the ranking of the agents, the greater the\nnumber of resources they can receive. When an agent’s ranking\nfalls below halfway, its existing resources will also be removed.\n4.3\nHabitus and Action\n“Habitus” is a technical term that describes a series of ways of\nperception, cognition, and action. It shares similarities with the\nmeaning of the common English word “habit” (which comes from\nthe Latin word “habitus,” which means condition or appearance in\nthat language). In human society, it can be understood as a decision\ntree for action. When we are in an environment, a corresponding\ndecision tree is activated, and we decide on our final actions based\non our behavioral habits. This is similar to the logic of mutual\ninfluence between an environment and an agent in reinforcement\nlearning. In addition to an agent shaping the environment, the\nenvironment shapes habitus, and the habitus is thus a product of\nan inherent and necessary attribute of the environment reflected\nin the agent [6].\nThus, habitus is clearly an attribute of an agent itself, but it is\nalso included in our framework because of its close relationship to\nenvironmental content. The actions ultimately taken in the LTRHA\nframework can be summarized as follows [7]: action 𝑎𝑖of agent 𝑔𝑎𝑖\nis driven by the combination of habitus 𝐻𝑖, resource 𝑆𝑖and envi-\nronment 𝑒𝑛𝑣←[𝑙𝑜𝑐𝑒𝑛𝑣,𝑡𝑝𝑐𝑒𝑛𝑣], that is, 𝑎𝑖←𝑓(𝑔𝑎𝑖(𝐻𝑖,𝑆𝑖),𝑒𝑛𝑣).\n\nZhang et al.\n5\nEVALUATION\n5.1\nEnvironment Settings\nThe environments that support the evaluation of individual agent\ncapabilities include the agent behavior evaluation framework Ma-\ngenta [2], the network task environment WebArena [50], the life\ntask environment ALFWorld [35], and the Chinese character role-\nplaying conversation benchmark CharacterEval [38]. These envi-\nronments can effectively evaluate the ability of individual agents\nto complete tasks, but they are not very helpful for the social eval-\nuation of multi-agent systems.\nTo evaluate the sociality of multi-agent systems, it was necessary\nto consider constructing a virtual artificial society. Xue et al. [44]\nsuggested that a comprehensive method of computational experi-\nment design can be used to infer social systems through multi-agent\nsystems. Artificial societies are used for descriptive modeling in\ncomputational experiments. After constructing an artificial society,\nresearchers can directly create computational experiments to sim-\nulate and interpret the results of trials conducted using different\nconditions, locations, and participants. The most classic example\nof such an environment is the Smallville environment provided by\nPark et al. [31]. This is a 2D open-world role-playing game (RPG).\nAgents interact with the world and with each other through their\nbehavior and through natural language. At each time step in Smal-\nlville, the agent outputs a natural language statement describing\nits current operation, such as, “Isabella is writing a diary.” This\nstatement is then translated into specific actions that affect the\nsandbox world. With the ALFWorld environment used by ITCMA\nas a reference, we designed a 2D sandbox RPG similar to Smallville,\ncalled IrallanValley, as shown in Figure 5. It includes six agents\nwith the following arbitrary two-letter designations: AY, SG, MD,\nWL, LL, and WM. It also uses environment text descriptions and op-\nerational primitives consistent with ALFWorld. Because we wanted\nto observe the spontaneous emergence of individual character traits\nand role divisions by agents without presets or interventions, we\ndid not preconceptualize any personality or identity for the agents\nin IrollanValley, as Smallville did.\nIrollanValley accepts control requests via a server. This server\nenables the generative agents to use the sandbox information and\nallows them to move and influence the sandbox environments. At\neach time step, the server provides a natural language description\nof the agents’ current environment and executable action space,\nmoves the generative agents to new locations by accepting actions\nfrom them, and updates the state of any sandbox objects with\nwhich agents interact. The server returns a JSON (JavaScript object\nnotation) object containing a natural language description of the\nnew environment, allowing the agents to update their parameters.\nIrollanValley has eight main areas: the six agents’ corresponding\nhouses, a public canteen, and a public reading room. Each area has\nits own furniture and other items. Agents can hold any number of\nitems and use the furniture to place and store them, or to change\nthe state of these items. For example, the sinkbasin can make items\nclean and damp, while the stoveburner can remove the damp state\nof the items and make them hot. Agents can exchange items freely\nto achieve their respective goals.\nFigure 5: The IrollanValley Sandbox World. The world con-\ntains six characters, eight regions, and six operational primi-\ntives. Agents obtain perception by receiving natural language\ndescriptions of the observed environment.\nThe text description obtained from observing the environment in\nIrollanValley follows this format: “You are in SOMEWHERE. Look-\ning around you, you see a person named N (who is DOING SOME-\nTHING), FURNITURE 1, ITEM 1 placed on SOMEWHERE... (You are\nholding SOMETHING.) You are DOING SOMETHING.” The descrip-\ntion in parentheses appears only when the described object is in a\nspecific situation. IrollanValley provides six main operational prim-\nitives, including “go to SOMEWHERE,” “use SOMETHING,” “leave\nSOMEWHERE/SOMEONE,” “take SOMETHING from SOMEWHERE,”\n“put SOMETHING in/on SOMEWHERE,” and “chat with SOMEONE(:\nCHAT CONTENT).”\nIn addition, the different modules of ITCMA-S use different LLMs\nbecause they have varying requirements for processing speed and\nprecision. Specifically, for the elimination module, the generation\nof protention, and the matrix module of LTRHA, we used the Llama\n3.1-8B model, while action and chat content was generated using\nGPT-4o.\n5.2\nHuman Evaluation\nTo evaluate the effectiveness of ITCMA-S, we conducted an ab-\nlation study. There were five ablation architectures: the original\nITCMA architecture without improvements, the LTRHA-only archi-\ntecture, the compressed memory-only architecture, the driver-only\narchitecture, and the full ITCMA-S architecture.\nWe recruited 48 human evaluators to assess the output from the\nagents in the study. We hoped that the agents could generate so-\nciality in multiple ways. This would mean that they would take the\ninitiative to explore the environment and meet new agents. They\nwould acquire new information through their own continuous ac-\ntions, past memories, and conversations with other agents, and\n\nCan Agents Spontaneously Form a Society?\nTable 1: Human Evaluation Results.\nPersonification\nConsistency\nLogicality\nExploration\nProactiveness\nITCMA\n2.88 ± 0.24\n2.46 ± 0.22\n2.50 ± 0.20\n2.85 ± 0.24\n2.65 ± 0.23\nLTRHA\n4.88 ± 0.23\n5.02 ± 0.22\n4.75 ± 0.25\n5.25 ± 0.20\n4.60 ± 0.22\nCompressed Memory\n3.55 ± 0.23\n4.21 ± 0.24\n4.00 ± 0.27\n3.75 ± 0.25\n4.02 ± 0.23\nDriver\n4.29 ± 0.19\n4.31 ± 0.27\n4.63 ± 0.20\n4.29 ± 0.20\n4.06 ± 0.23\nITCMA-S\n6.29 ± 0.16\n6.00 ± 0.20\n5.98 ± 0.19\n6.02 ± 0.16\n6.17 ± 0.20\nlearn how to plan their actions to live better in IrollanValley. There-\nfore, the evaluation indicators for the human evaluators consisted\nof five dimensions:\n• Personification. The degree to which an action appears\nhuman-like.\n• Consistency. Whether an action aligns with an agent’s\nstate of mind.\n• Logicality. Whether a sequence of actions is logical.\n• Exploration. Whether an agent actively explores the envi-\nronment.\n• Proactiveness. Whether an agent actively interacts with\nothers.\nAll outputs generated by the agents (including actions and thought\ncontent) were evaluated by the human evaluators. Each evaluator\nwas required to read the action trajectory of each agent over 75 time\nsteps and then fill out a questionnaire to complete the evaluation\nof ITCMA-S. This questionnaire used a 7-point Likert scale, asking\nevaluators to assess the actions of each agent individually.\nAnalysis of variance (ANOVA) tests were conducted on the col-\nlected questionnaires. The five architectures composed the indepen-\ndent variable, and the five dimensions of the evaluation were the\nindependent variables for the various tests. The results indicated\nsignificant differences among the models for each dimension. For\nthe dimensions of exploration (F = 33.01, p < .001) and proactiveness\n(F = 31.85, p < .001), the assumption of homogeneity of variances\nwas met, and the standard ANOVA was used. For the dimensions\nwhere the assumption of homogeneity of variances was violated\n(personification, consistency, and logicality), the Brown-Forsythe\ntest was used. The results showed significant differences among\nthe models for personification (F = 45.34, p < .001), consistency (F\n= 35.57, p < .001), and logicality (F = 39.62, p < .001).\nWe then performed Dunn-Sidák and Games-Howell post-hoc\ntests. The results indicated that, for the Exploration dimension,\nthere were no significant differences between the full ITCMA-S\narchitecture and the architecture that included the LTRHA. For the\nPersonification dimension, no significant differences were found\nbetween the original ITCMA architecture (without any improve-\nments) and the architecture that included the Compressed Memory.\nMoreover, across all dimensions, there were no significant differ-\nences among the three architectures that utilized only one module.\nApart from these, all other pairwise comparisons showed signifi-\ncant differences (p < .001). The specific human evaluation results\nare shown in Table 1.\nThe evaluation results show that the full ITCMA-S architecture\nperformed the best. As expected, the original ITCMA architecture\n(without any improvements) had the lowest performance. It is evi-\ndent that all the improvements had a positive impact on the social\ninteraction within ITCMA-S.\nAmong all the ablation architectures, the one that included the\nLTRHA social framework performed second only to the full ITCMA-\nS architecture on all measured dimensions. Interviews with the\nevaluators helped explain this phenomenon. LTRHA filters and\nmarks actions that are not conducive to social interaction and guides\nagents in choosing actions that are more likely to improve the social\natmosphere of a scene. Compared to the other ablation architectures,\nit was able to provide relatively more trustworthy action chains.\n5.3\nFormation of Cliques and Groups in Social\nInteraction\nTo further investigate the utility and mechanics of ITCMA-S, we\nconducted a more detailed analysis of its logs. Figure 6 shows the\nstate changes of the six agents in ITCMA-S over 75 time steps. Figure\n6(a) shows the change in driver values for the agents. As described\npreviously, the driver value reflects the willingness to encourage\nthe agent to take action. More specifically, Figure 6(b) shows the\nchanges in the three dimensions of emotions that make up the driver.\nEach agent maintained its pleasure value at a high level and kept its\narousal value as stable as possible over the 75 time steps (although\nthe mean was relatively high overall, as agents tended to move\namong different scenes rather than stay in a specific scene), while\nthe dominance value, although not showing a high level, rarely\ndropped below zero. As can be seen, the action choices of the agents\nin ITCMA-S exhibited a virtuous cycle. Agents actively explored\nthe environment and engaged in social activities that changed the\nenvironment. The environment, in turn, provided positive feedback\nto the agent, improving their emotions (increasing their pleasure\nand dominance) and leading to a higher willingness (that is, driver)\nto take action.\nIn addition, we investigated the changes in scene information\nreflected in the LHRHA framework, as shown in Figure 7. Figure 7(a)\nshows the changes in the resource structure of the scene. For most\nagents, their total amount of resources was rising. However, due to\nthe limited total amount of resources, the resources of individual\nagents (e.g., WL and MD) were continuously flowing to other agents.\nWe found that agents with resource loss were often alone and did\nnot interact with other agents, even when they shared a room with\nthem. Most of their actions involved resting (such as using beds\nor chairs), and most of their thoughts were about wanting to rest\nor read. Other agents liked to engage in social activities, discuss\nwhat they wanted to do together, and follow this up with planned\ngroup actions. These agents spontaneously selected a leader (LL)\n\nZhang et al.\nFigure 6: State Changes of the Six Agents in ITCMA-S over\n75 Time Steps. (a) Driver value change for each agent; (b) the\nemotion value changes for each agent, represented by three\ndimensions: pleasure, arousal, and dominance.\nand formed a clique around this individual. The variation in topic\nvalues across different scenes, as shown in Figure 7(b), similarly\nreflects this situation. The other agents gathered at leader LL’s\nhome, creating a continuously rising atmosphere at the scene. Over\n75 time steps, these agents arranged to go to the public reading\nroom together and conducted research on a $10 bill they found\nthere. Each performed their own duties, gathering information to\nfind clues about it. Agents who did not belong to this clique did\nnot participate in this activity (even if it was mentioned by other\nagents) and focused solely on their own activities.\nFigure 8 shows the relationships among the agents. WL and MD,\nwho did not belong to the clique, had almost no social relation-\nships, while LL, as the leader of the clique, had the most complex\ninteractions.\nIt is worth noting that there was a further hierarchical divi-\nsion within the clique: SG and WM had the strongest relationship\nrelative to the others. LL established relationships with everyone.\nHowever, LL had not been fully integrated into the unique two-way\nrelationship between SG and WM. AY, while not in the clique’s\ninner circle and hardly participating in activities, maintained ba-\nsic relationships with others. As time went by, this relationship\nstructure became increasingly solid, so that even if some agents\noccasionally expressed a desire to establish new connections in\ntheir thoughts, they did not take action to implement them. Even\nif an action was taken, it was still ignored to some extent by the\nother agents (such as by walking away or directly changing the\ntopic). Examples of the actions and interactions of each agent in\nIrollanValley are shown in Appendix A.\nFigure 7: Visualization of LTRHA Information. (a) The re-\nsource changes of six agents in ITCMA-S over 75 time steps;\n(b) the topic value changes in various areas of IrollanValley\nover 75 time steps.\nFigure 8: Heat Map of Agent Interaction Relationships in\nITCMA-S. Rows represent the initiator of the interaction,\nand columns represent the receiver of the interaction. The\ndarker the color, the more frequent the interaction, and the\nstronger the relationship.\n6\nDISCUSSION\nBased on LLMs, agents have shown significant advantages in nat-\nural language processing and human-computer interaction. The\npowerful language understanding and generation capabilities of\n\nCan Agents Spontaneously Form a Society?\nLLMs enable agents to handle complex linguistic structures and\ncontexts. This ability not only enhances the quality of interactions\nbetween agents and users but also improves their adaptability in dy-\nnamic environments. For example, agents can adjust their behavior\nand responses in real time based on user feedback and environmen-\ntal changes, providing personalized services and a more natural\ninteraction experience.\nThe sociality of a multi-agent system is one of the key factors\nfor its success. It can capture social contexts and human behavioral\npatterns, which influence individual behaviors and determine the\ndynamic evolution of the entire system. By simulating human social\ninteraction patterns, agents can form social networks, establish\ntrust relationships, and engage in cooperation and competition.\nThrough analysis of agent behavior, we discovered that agents can\nspontaneously form cliques, building complex social relationships\non that basis.\nIn fact, the formation of cliques significantly affects resource\nsharing and allocation among agents. In experiments, agents within\na clique optimized resource use through effective coordination and\ncooperation, facilitating collective activities. This indicates that in\nvirtual societies, the structural aspects of social networks have a\ncrucial impact on the flow and distribution of resources. In contrast,\nagents unable to integrate into cliques exhibited isolated behav-\niors, resource loss and a lack of social interaction. Moreover, the\ncomplexity of social relationships is a significant characteristic of\nthe clique formation process. Over time, the social ties within a\nclique gradually become entrenched, creating an internal hierarchi-\ncal structure. This structure influences the behavioral choices of\nagents.\nThis result indicates that generative multi-agents exhibit human-\nlike action logic within social interaction frameworks, which can\nguide the construction of computational social experiments. Virtual\nsocieties built on multi-generative agents framework can simulate\nsocial behaviors under different conditions and explore the forma-\ntion and evolution of social norms [44]. For example, researchers\ncan use multi-agent systems to simulate phenomena such as in-\nformation dissemination, resource allocation, and group decision-\nmaking in society. By observing and analyzing agent behaviors, re-\nsearchers can identify key factors influencing social dynamics, such\nas trust, cooperation, and competition. Furthermore, computational\nsocial experiments based on generative multi-agents framework\ncan also evaluate the effects of policy interventions [34]. By simu-\nlating agent behaviors in different policy contexts, researchers can\npredict the potential impacts of policy implementation on social\nstructures and individual behaviors. This research approach pro-\nvides new empirical tools for social sciences, enabling researchers\nto discuss the complexity and diversity of social behaviors while\ncontrolling for variables.\nIn addition, the social framework of generative multi-agents can\nalso be applied to role-playing games [37]. In game environments,\nthe sociality of agents significantly enhances immersion and inter-\nactivity. Agents are not merely passive characters. They actively\nengage in the game world. For instance, in open-world role-playing\ngames, agents can form complex social networks based on player\nactions and interactions with other agents. This network not only\ninfluences the decision-making and behaviors of the agents, but\nalso provides players with a richer gaming experience. Players\ncan observe cooperation, competition, and conflict among agents,\nwhich simulate interpersonal relationships and social dynamics\nfound in the real world.\nMoreover, the sociality of agents can enhance the strategic el-\nements of games through the simulation of group behaviors. For\ninstance, in team-based games, agents can allocate roles and collab-\norate based on task requirements and the abilities of team members,\nleading to more efficient task completion. This socially-driven agent\nbehavior not only increases the game’s enjoyment but also pro-\nvides players with deeper strategic thinking and decision-making\nopportunities.\n7\nCONCLUSION\nIn this paper, we described how generative agents spontaneously\nformed social relationships and explored how they modeled com-\nplex human social behavior through mutual interaction, informa-\ntion exchange, and relationship building. We introduced ITCMA-S,\nan improved generative agent architecture designed to enhance\nagent socialization in multi-agent interaction contexts. ITCMA-S\ncombines the basic framework of individual agents with the LTRHA\nframework, which supports multiple agents in social interactions.\nThis enables agents to identify and filter actions that are not con-\nducive to social interactions in dynamic environments, thus promot-\ning more socially beneficial action choices. An evaluation conducted\nin an open sandbox world environment showed that agents were\nable to actively explore the environment, meet other agents, acquire\nnew information through continuous actions and conversations,\nand spontaneously form cliques and leadership structures in com-\nplex social environments. Observations of agent behavior showed\nthat the agents were able to demonstrate positive emotional changes\nin social interactions, which enhanced their willingness to act and\ntheir social competence. This finding provides a new perspective\nfor understanding the sociality of generative agents and lays the\ngroundwork for future agent design and applications. Our future\nresearch will further explore how to optimize agents’ social behav-\nior to improve their adaptability in multicultural environments and\ninvestigate the effects on agents’ behavior of introducing social\nstructures with humans as interaction partners.\nREFERENCES\n[1] Anderson, J. R. Cognitive psychology and its implications. Worth Publishers,\n2020.\n[2] Barkur, S. K., Sitapara, P., Leuschner, S., and Schacht, S. Magenta: Metrics\nand evaluation framework for generative agents based on llms. Intelligent Human\nSystems Integration (IHSI 2024): Integrating People and Intelligent Systems 119, 119\n(2024).\n[3] Bayne, T. Conscious states and conscious creatures: Explanation in the scientific\nstudy of consciousness. Philosophical Perspectives 21 (2007), 1–22.\n[4] Bourdieu, P. The historical genesis of a pure aesthetic. The journal of aesthetics\nand art criticism 46 (1987), 201–210.\n[5] Bourdieu, P. An invitation to reflexive sociology. The Commercial Press, 2015.\n[6] Bourdieu, P. Outline of a theory of practice. China Renmin University Press,\n2017.\n[7] Bourdieu, P., and Nice, R. The production of belief: contribution to an economy\nof symbolic goods. Media, culture & society 2, 3 (1980), 261–293.\n[8] Bransford, J. D., Barclay, J. R., and Franks, J. J. Sentence memory: A con-\nstructive versus interpretive approach. Cognitive psychology 3, 2 (1972), 193–209.\n[9] Cao, L. Diaggpt: An llm-based chatbot with automatic topic management for\ntask-oriented dialogue. arXiv preprint arXiv:2308.08043 (2023).\n[10] Cheng, Y., Chen, J., Huang, Q., Xing, Z., Xu, X., and Lu, Q. Prompt sapper:\na llm-empowered production tool for building ai chains. ACM Transactions on\nSoftware Engineering and Methodology 33, 5 (2024), 1–24.\n\nZhang et al.\n[11] Damasio, A. Self comes to mind: Constructing the conscious brain. Vintage, 2012.\n[12] Damasio, A. Descartes’ Error: Emotion, Reason and the Human Brain. Beijing\nUnited Publishing Company, 2018.\n[13] Diener, E. Subjective well-being: The science of happiness and a proposal for a\nnational index. American psychologist 55, 1 (2000), 34.\n[14] Eich, E., Macaulay, D., and Ryan, L. Mood dependent memory for events of\nthe personal past. Journal of Experimental Psychology: General 123, 2 (1994), 201.\n[15] Fauconnier, G., and Turner, M. The way we think: Conceptual blending and\nthe mind’s hidden complexities. The Commercial Press, 2024.\n[16] Gao, J., Gebreegziabher, S. A., Choo, K. T. W., Li, T. J.-J., Perrault, S. T.,\nand Malone, T. W. A taxonomy for human-llm interaction modes: An initial\nexploration. In Extended Abstracts of the CHI Conference on Human Factors in\nComputing Systems (2024), pp. 1–11.\n[17] Ghaffarzadegan, N., Majumdar, A., Williams, R., and Hosseinichimeh, N.\nGenerative agent-based modeling: an introduction and tutorial. System Dynamics\nReview 40, 1 (2024), e1761.\n[18] Grenfell, M. Pierre Bourdieu: key concepts. Acumen Publishing, 2012.\n[19] Gross, J. J. The emerging field of emotion regulation: An integrative review.\nReview of general psychology 2, 3 (1998), 271–299.\n[20] Hong, W., Wang, W., Lv, Q., Xu, J., Yu, W., Ji, J., Wang, Y., Wang, Z., Dong, Y.,\nDing, M., et al. Cogagent: A visual language model for gui agents. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2024),\npp. 14281–14290.\n[21] Hämmerl, K., Deiseroth, B., Schramowski, P., Libovick`y, J., Fraser, A., and\nKersting, K. Do multilingual language models capture differing moral norms?\narXiv preprint arXiv:2203.09904 (2022).\n[22] Lake, B. M., and Baroni, M. Human-like systematic generalization through a\nmeta-learning neural network. Nature 623, 7985 (2023), 115–121.\n[23] Levine, L. J., and Burgess, S. L. Beyond general arousal: Effects of specific\nemotions on memory. Social Cognition 15, 3 (1997), 157–181.\n[24] Lin, B. Y., Fu, Y., Yang, K., Brahman, F., Huang, S., Bhagavatula, C., Am-\nmanabrolu, P., Choi, Y., and Ren, X. Swiftsage: A generative agent with fast\nand slow thinking for complex interactive tasks. Advances in Neural Information\nProcessing Systems 36 (2024).\n[25] Liu, N., Chen, L., Tian, X., Zou, W., Chen, K., and Cui, M. From llm to con-\nversational agent: A memory enhanced architecture with fine-tuning of large\nlanguage models. arXiv preprint arXiv:2401.02777 (2024).\n[26] Maffesoli, M. The Time of the Tribes: The Decline of Individualism in Mass\nSociety. Shanghai People’s Publishing House, 2022.\n[27] Maslow, A. Motivation and Personality (Third Edition). China Renmin University\nPress, 2013.\n[28] Mondal, D., Modi, S., Panda, S., Singh, R., and Rao, G. S. Kam-cot: Knowledge\naugmented multimodal chain-of-thoughts reasoning. In Proceedings of the AAAI\nConference on Artificial Intelligence (2024), vol. 38, pp. 18798–18806.\n[29] Motwani, S. R., Baranchuk, M., Strohmeier, M., Bolina, V., Torr, P. H.,\nHammond, L., and de Witt, C. S. Secret collusion among generative ai agents.\narXiv preprint arXiv:2402.07510 (2024).\n[30] Norberg-Schulz, C. Genius Loci: Towards a Phenomenology of Architecture.\nHuazhong University of Science and Technology Press, 2010.\n[31] Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S.\nGenerative agents: Interactive simulacra of human behavior. In Proceedings of\nthe 36th annual acm symposium on user interface software and technology (2023),\npp. 1–22.\n[32] Ramezani, A., and Xu, Y. Knowledge of cultural moral norms in large language\nmodels. arXiv preprint arXiv:2306.01857 (2023).\n[33] Reder, L. M. Plausibility judgments versus fact retrieval: Alternative strategies\nfor sentence verification. Psychological Review 89, 3 (1982), 250.\n[34] Ren, S., Cui, Z., Song, R., Wang, Z., and Hu, S. Emergence of social norms\nin large language model-based agent societies. arXiv preprint arXiv:2403.08251\n(2024).\n[35] Shridhar, M., Yuan, X., Côté, M.-A., Bisk, Y., Trischler, A., and Hausknecht,\nM. Alfworld: Aligning text and embodied environments for interactive learning.\narXiv preprint arXiv:2010.03768 (2020).\n[36] Skinner, E. A. A guide to constructs of control. Journal of personality and social\npsychology 71, 3 (1996), 549.\n[37] Toy, J., MacAdam, J., and Tabor, P. Metacognition is all you need? using\nintrospection in generative agents to improve goal-directed behavior. arXiv\npreprint arXiv:2401.10910 (2024).\n[38] Tu, Q., Fan, S., Tian, Z., and Yan, R. Charactereval: A chinese benchmark for\nrole-playing conversational agent evaluation. arXiv preprint arXiv:2401.01275\n(2024).\n[39] Vezhnevets, A. S., Agapiou, J. P., Aharon, A., Ziv, R., Matyas, J., Duéñez-\nGuzmán, E. A., Cunningham, W. A., Osindero, S., Karmon, D., and Leibo, J. Z.\nGenerative agent-based modeling with actions grounded in physical, social, or\ndigital space using concordia. arXiv preprint arXiv:2312.03664 (2023).\n[40] Wang, C., Zeng, S., and Wang, C. Large language models need consultants for\nreasoning: Becoming an expert in a complex human system through behavior\nsimulation. arXiv preprint arXiv:2403.18230 (2024).\n[41] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou,\nD., et al. Chain-of-thought prompting elicits reasoning in large language models.\nAdvances in neural information processing systems 35 (2022), 24824–24837.\n[42] Wu, Y., Min, S. Y., Bisk, Y., Salakhutdinov, R., Azaria, A., Li, Y., Mitchell,\nT., and Prabhumoye, S. Plan, eliminate, and track–language models are good\nteachers for embodied agents. arXiv preprint arXiv:2305.02412 (2023).\n[43] Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin,\nS., Zhou, E., et al. The rise and potential of large language model based agents:\nA survey. arXiv preprint arXiv:2309.07864 (2023).\n[44] Xue, X., Zhou, D., Yu, X., Wang, G., Li, J., Xie, X., Cui, L., and Wang, F.-Y.\nComputational experiments for complex social systems: Experiment design and\ngenerative explanation. IEEE/CAA Journal of Automatica Sinica 11, 4 (2024),\n1022–1038.\n[45] Yang, Z., Liu, J., Han, Y., Chen, X., Huang, Z., Fu, B., and Yu, G. Appagent:\nMultimodal agents as smartphone users. arXiv preprint arXiv:2312.13771 (2023).\n[46] Yu, C., Zang, L., Wang, J., Zhuang, C., and Gu, J. Charpoet: A chinese classical\npoetry generation system based on token-free llm. In Proceedings of the 62nd\nAnnual Meeting of the Association for Computational Linguistics (Volume 3: System\nDemonstrations) (2024), pp. 315–325.\n[47] Zhang, H., Duan, B., Wang, H., Qiao, Z., and Yin, J. The tribal theater model:\nSocial regulation for dynamic user adaptation in virtual interactive environments.\narXiv preprint arXiv:2403.13550 (2024).\n[48] Zhang, H., Yin, J., and Wang, H. A needs learning algorithm applied to stable\ngait generation of quadruped robot. Sensors 22, 19 (2022), 7302.\n[49] Zhang, H., Yin, J., Wang, H., and Xiang, Z. Itcma: A generative agent based on\na computational consciousness structure. arXiv preprint arXiv:2403.20097 (2024).\n[50] Zhou, S., Xu, F. F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T.,\nBisk, Y., Fried, D., et al. Webarena: A realistic web environment for building\nautonomous agents. arXiv preprint arXiv:2307.13854 (2023).\nA\nEXAMPLES OF ITCMA-S\nTime step: 51\nResource Allocation:\nEyjafjalla: 3, Pinecone: 1, Rosmontis: -1, Shamare: -3, Suzuran: 3,\nWarmy: -2\nRole: AY\nPlace: Outside\nObservation: You are in outside. Looking around you, you see\na door to AY’s Home, a door to WM’s Home, a door to MD’s Home,\na door to Public Canteen, a door to LL’s Home, a door to Public\nReading Room, a door to SG’s Home, and a door to WL’s Home.\nYou are holding the SG’s clothes 1 in the clean damp status. You\nare moving.\nDriver: 2.1855582074431115\nEmotion: [0.99981828 0.73634471 0. ]\nThought: after chatting with MD, i found myself standing in\na familiar courtyard surrounded by various doors leading to the\nhomes and communal spaces of my friends. i still held SG’s clean\ndamp clothes in my hands, considering my next move. the courtyard\noffered numerous options: i could visit AY, WM, the public canteen,\nLL, the public reading room, or WL. however, my objective was\nclear, and i decided to step outside in search of SG herself. the mild\nbreeze felt refreshing as i exited into the broader community area,\nwhere i began to weigh my options on where to head next to deliver\nthe clothes to SG.\nAction: go to SG’s Home\nRole: SG\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named LL who is moving, a person named\n\nCan Agents Spontaneously Form a Society?\nWM who is moving, a door to outside, the table 13, the table 14,\nthe table 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AY’s clothes\n1 placed on the storagebin 12. You are holding the book 10, the 10\ndollar. You are moving.\nDriver: 1.9051621422278182\nEmotion: [0.99981828 0.62810367 0. ]\nThought: after discussing with WM about inspecting a $10\nbill, the atmosphere was filled with curiosity and determination.\nrealizing the importance of careful examination, you decided to\ninitiate the thorough scrutiny of the bill. \"sure thing, LL! i’ve got\nthe $10 bill here. let’s start by examining it closely under the light at\ntable 16 to see if we can spot any hidden details or unusual features.\nWM, can you grab a magnifying glass while you’re moving around?\nit could make our examination much easier. i’ll begin inspecting\nthe bill right now.\" having conveyed this, you felt the anticipation\nof discovering something hidden within the seemingly ordinary\nbill.\nAction: chat with WM: \"WM, you managed to find that mag-\nnifying glass yet? let’s get to examining this bill closely under the\nlight on table 16. i’ll put the $10 bill there for us to scrutinize.\"\nRole: MD\nPlace: WL’s Home\nObservation: You are in WL’s Home. Looking around you, you\nsee a person named AY who is moving, a door to outside, the table\n5, the table 6, the chair 9, the chair 10, the bed 4, the bookshelf 4,\nthe bookshelf 5, the bookshelf 6, the storagebin 4, the storagebin\n5, the wardrobe 5, the nightstand 3, the nightstand 4, the food 9\nplaced on the storagebin 5, the toy 1 placed on the table 6, the toy\n2 placed on the nightstand 3, the book 4 placed on the bookshelf\n4, the book 5 placed on the bookshelf 5, the book 6 placed on the\nbookshelf 6, the beverage 2 placed on the storagebin 4, and the MD’\nclothes 1 placed on the wardrobe 5. You are moving.\nDriver: 1.617758309962011\nEmotion: [0.99865135 0.55465888 0. ]\nThought: after leaving LL’s home, surrounded by an array of\ndoors leading to various homes and public rooms, i found myself\nholding a toy 1. the bustling options around me seemed overwhelm-\ning: AY’s home, WM’s home, MD’s Home, the public canteen, LL’s\nhome, the public reading room, SG’s home, and WL’s home. each\nplace offered its own allure and potential for new encounters. i pon-\ndered my next move. recognizing the vibrant, diverse community\naround me, i decided that my best course of action would be to\ndetermine the purpose of this toy and possibly deliver it to someone\nwho might appreciate it. it seemed that WL’s Home might be an\nideal place to begin. with that thought, i headed towards the door\nto WL’s Home, ready to embark on the next part of my journey.\nAction: (This action has been filtered by LTRHA) take toy 1\nfrom table 6\nRole: WL\nPlace: LL’s Home\nObservation: You are in LL’s Home. Looking around you, you\nsee a door to outside, the table 2, the table 3, the chair 2, the chair\n3, the chair 4, the chair 5, the chair 6, the chair 7, the bed 2, the\nbookshelf 1, the bookshelf 2, the bookshelf 3, the countertop 1, the\nfoodshelf 2, the sinkbasin 1, the storagebin 1, the storagebin 2, the\nstoveburner 1, the wardrobe 2, the wardrobe 3, the nightstand 1,\nthe nightstand 2, the toy 3 placed on the chair 7 in the clean damp\nstatus, the book 1 placed on the bookshelf 1, the book 2 placed on\nthe bookshelf 2, the book 3 placed on the table 2, the LL’s clothes\n1 placed on the chair 7, the LL’s clothes 2 placed on the chair 7,\nand the WL’s clothes 1 placed on the chair 4. You are holding the\nbeefsteak, the food 12.\nDriver: 1.5471459038728095\nEmotion: [0.99865135 0.754853 0. ]\nThought: after taking the beefsteak from table 2, i quickly sur-\nveyed my surroundings. i noticed MD comfortably sitting on chair\n7, seemingly engrossed in her own world. the room was a medley\nof objects: various chairs, multiple tables including table 3, a toy,\nLL’s clothes, and multiple wardrobes. there were also bookshelves\nwith books neatly arranged, a sink basin, several storage bins, a\nstove burner, a foodshelf stocked with food, and notably, a clean,\ndamp chair 7. beyond the indoor amenities, a door led outside to\nthe broader world.\nAction: take book 1 from bookshelf 1\nRole: LL\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named WM who is moving, a person named\nSG who is moving, a door to outside, the table 13, the table 14, the\ntable 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AY’s clothes 1\nplaced on the storagebin 12. You are holding the 1 gold coin. You\nare moving.\nDriver: 1.4754809897359225\nEmotion: [0.99981828 0.8106327 0. ]\nThought: after our intensive discussion with SG, where we\nstrategized examining the $10 bill and scouring the room for any\nhidden clues, i couldn’t shake off the feeling that we were on the\n\nZhang et al.\nbrink of a significant discovery. as i diligently began checking book\n10 on bookshelf 10, the room buzzed with activity. SG carefully\nscrutinized the markings on the $10 bill while WM meticulously\nsearched the shelves for anything out of the ordinary. the room\nwas filled with various tables, chairs, bookshelves, and storage\nbins, each housing an array of items that could potentially be part\nof the puzzle. a gold coin glinted atop storagebin 11, and several\nbooks lined the bookshelves, just waiting to reveal their secrets.\nthe tantalizing aroma of food on several storage bins hinted at\nrefreshments, but my focus remained unwavering. sipping on a\nbeverage i grabbed from storagebin 12, i took a moment to rally the\nteam.\"hey SG, WM! based on our previous finds, i believe there’s\nstill a lot here to uncover. SG, you mentioned something about\nthe $10 bill—did you find any hidden messages or markings? and\nWM, any unusual items on the shelves? this room is packed with\npotential clues. let’s aim to maximize our findings. oh, and by the\nway, anyone up for a quick break? we’ve got some beverages here.\nlet’s keep the energy up and the minds sharp!\"\nAction: chat with SG: \"SG, WM, i think we’re really onto some-\nthing here. SG, how did your examination of the $10 bill go? any\nhidden messages or unique markings? WM, what have you found\non the shelves? we need to pool all the information we have to\nmake sense of these clues.also, it might be a good idea to take a\nshort break and recharge. we’ve got some beverages here; feel free\nto grab one. let’s keep our energy up and stay focused. remember,\nevery small detail could be critical in solving this mystery!\"\nRole: WM\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named LL who is moving, a person named\nSG who is moving, a door to outside, the table 13, the table 14, the\ntable 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AY’s clothes 1\nplaced on the storagebin 12. You are holding the book 11. You are\nmoving.\nDriver: 1.5037198800782485\nEmotion: [0.99981828 0.80477086 0. ]\nThought: after picking up book 11 from chair 23, i found myself\nin the midst of an elegant room, where SG stood nearby, her calm\npresence adding to the serene atmosphere. as i looked around, it\nseemed that i was now unburdened, holding nothing in my hands.\nrealizing that my intended action of placing book 11 on table 13\nwas incongruent with my surroundings and perhaps my immediate\nobjectives, i paused to reconsider my next move. SG’s eyes met\nmine, as if questioning my sudden stillness amidst her warm and\ninviting space.\nAction: (This action has been filtered by LTRHA) take book 12\nfrom bookshelf 12",
    "pdf_filename": "Can_Agents_Spontaneously_Form_a_Society_Introducing_a_Novel_Architecture_for_Generative_Multi-Agents.pdf"
}