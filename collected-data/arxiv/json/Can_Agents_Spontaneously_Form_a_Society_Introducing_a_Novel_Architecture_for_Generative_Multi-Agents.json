{
    "title": "Can Agents Spontaneously Form a Society Introducing a Novel Architecture for Generative Multi-Agents",
    "abstract": "Generative agents have demonstrated impressive capabilities in specific tasks, but most of these frameworks focus on independent tasks and lack attention to social interactions. We introduce a gen- erative agent architecture called ITCMA-S, which includes a basic framework for individual agents and a framework called LTRHA that supports social interactions among multi-agents. This archi- tecture enables agents to identify and filter out behaviors that are detrimental to social interactions, guiding them to choose more favorable actions. We designed a sandbox environment to simu- late the natural evolution of social relationships among multiple identity-less agents for experimental evaluation. The results showed that ITCMA-S performed well on multiple evaluation indicators, demonstrating its ability to actively explore the environment, recog- nize new agents, and acquire new information through continuous actions and dialogue. Observations show that as agents establish connections with each other, they spontaneously form cliques with internal hierarchies around a selected leader and organize collective activities.",
    "body": "Can Agents Spontaneously Form a Society?\nIntroducing a Novel Architecture for Generative Multi-Agent to Elicit Social Emergence\nHanzhong Zhang\nKunming University of Science and Technology\nKunming, Yunnan Province, China\narmihia@foxmail.com\nJibin Yin\nKunming University of Science and Technology\nKunming, Yunnan Province, China\nyjblovelh@aliyun.com\nMulin Jiang\nKunming University of Science and Technology\nKunming, Yunnan Province, China\n237800718@qq.com\nCong Su\nKunming University of Science and Technology\nKunming, Yunnan Province, China\n787358363@qq.com\nABSTRACT\nGenerative agents have demonstrated impressive capabilities in\nspecific tasks, but most of these frameworks focus on independent\ntasks and lack attention to social interactions. We introduce a gen-\nerative agent architecture called ITCMA-S, which includes a basic\nframework for individual agents and a framework called LTRHA\nthat supports social interactions among multi-agents. This archi-\ntecture enables agents to identify and filter out behaviors that are\ndetrimental to social interactions, guiding them to choose more\nfavorable actions. We designed a sandbox environment to simu-\nlate the natural evolution of social relationships among multiple\nidentity-less agents for experimental evaluation. The results showed\nthat ITCMA-S performed well on multiple evaluation indicators,\ndemonstrating its ability to actively explore the environment, recog-\nnize new agents, and acquire new information through continuous\nactions and dialogue. Observations show that as agents establish\nconnections with each other, they spontaneously form cliques with\ninternal hierarchies around a selected leader and organize collective\nactivities.\nKEYWORDS\nGenerative agents, Multi agent system, Social interaction, LLM\n1\nINTRODUCTION\nLarge language models (LLMs) have contributed to significant\nprogress in the field of natural language processing and are widely\nused in various domains, such as machine translation [44], dialogue\ngeneration [9], and content creation [46]. These models are capable\nof correctly parsing and generating complex sentence structures\nand have demonstrated unprecedented capabilities in understand-\ning language. However, LLMs often lack true comprehension and\nrely more on pattern matching and probabilistic predictions [10].\nIt has also been difficult to create systems to achieve human-like\nsystematic generalization [22]. To overcome these problems, re-\nsearchers have introduced LLM-based agents. This has allowed the\nincorporation of external knowledge bases to supplement a modelâ€™s\nknowledge gaps in specific domains [43]. They can also be used to\ndecompose a complex task into multiple simpler tasks to achieve\nhierarchical processing [41].\nOn this basis, Park et al. [31] introduced a novel LLM-based\nagent, namely, a generative agent. This agent simulates trustwor-\nthy human behavior. Generative agents have the ability to make\nmultifaceted inferences about an environment, themselves, and\nother individuals in the environment. They can design daily ac-\ntivity plans based on their own characteristics and experiences\nand adjust their plans to changes as they occur. When a situation\nchanges, they can flexibly update plans to ensure adaptation to it.\nThe importance of this progress cannot be ignored. In human\nâ€“ computer interaction, especially in virtual assistants, customer\nservice robots, and even more complex systems, such as self-driving\ncars and smart homes, the ability of agents to generate believable\nhuman behavior is crucial. Generative agents can support more\nadaptive and flexible interaction processes. This ability not only en-\nhances the systemâ€™s responsiveness to dynamic situations but also\nbrings humanâ€“computer interaction closer to natural behavioral\npatterns in interpersonal communication. In addition, by simulat-\ning human behavior, generative agents can demonstrate autonomy\nand sociality in various complex situations, making the interac-\ntion process smoother and more intuitive. This feature plays an\nimportant role in improving the user experience and increasing the\ntrustworthiness of a system [16].\nHowever, existing generative agent architectures still face many\nchallenges. While traditional agent structures are good at process-\ning and generating behaviors, they are primarily designed for iso-\nlated tasks and, thus, mostly lack a focus on sociality. This often\nmakes it difficult for them to model and apply the nuances of social\ninteractions, leading them to focus only on completing tasks and\noverlook behaviors that promote social connections. This is clearly\nnot conducive to cooperation among multiple agents and may lead\nto behaviors that are detrimental to the group [34]. In scenarios\ninvolving multiple agents, a lack of structured social behavior may\nlead to disjointed or even chaotic interactions. To truly harness the\npotential of these agents in domains requiring interaction, there\nis an urgent need to explore their ability to participate in social\ninteractions, establish relationships, and exhibit emerging social\nbehaviors.\nIn this paper, we improve upon an existing LLM-based agent\narchitecture (the internal time-consciousness machine based agent\n[ITCMA] introduced by [49]) and propose ITCMA-S (the â€œSâ€ signi-\nfies our contribution of social interaction) architecture to enable\nagents to adapt to multi-agent interaction scenarios. It contains a\narXiv:2409.06750v2  [cs.MA]  19 Nov 2024\n\nZhang et al.\nbasic framework for an individual agent and the LTRHA framework\nfor social interaction among multiple agents (the latter is named for\nits four modules: locale & topic, resources, habitus, and action; they\nare described later in the paper). This provides a structured way for\nagents to identify and filter actions that are not conducive to social\ninteraction, thereby guiding them to choose actions that are more\nconducive to improving the social atmosphere of a scene. It also\nallows them to form new relationships during interactions with\nother agents, while remembering the history of these interactions.\nThe formation of these dynamic relationships occurs naturally and\nis not pre-programmed. This means that the agent has the ability\nto adapt to its social environment.\nTo understand whether and how ITCMA-S leads to the emer-\ngence of sociality among generative agents, we established an eval-\nuation environment called IrollanValley. This is a sandbox world\ndesigned to test and allow the observation of generative agent\nbehavior and social interactions. It contains six characters, eight\nareas, and six operational primitives. Each area has unique furni-\nture and other items, and an agent can interact with the various\ncharacters and objects and move around in the areas. Based on this\nenvironment, we modeled the natural evolution of social relation-\nships among multiple agents without identities in the environment.\nThe human evaluation results showed that the agents had sponta-\nneously developed good social skills on each evaluation indicator\nand were able to actively explore the environment, meet new agents,\nand acquire new information through continuous actions and con-\nversations. By observing the environment, we found that, in the\nprocess of establishing connections among each other, the agents\nspontaneously formed a clique with internal hierarchies around an\nelected leader and organized collective activities under the leaderâ€™s\nguidance. Agents not included in this clique were mostly in isolated\nstates. Even when they were in the same room as other agents, they\ninteracted less and focused mainly on their personal activities.\nIn summary, this paper makes the following contributions:\nâ€¢ We propose a generative multi-agent structure, ITCMA-S,\nwhich includes the structure of an individual generative\nagent and a multi-agent social collaboration framework,\nLTRHA.\nâ€¢ We established an environment for multi-agent social eval-\nuation, IrollanValley, which consists of six roles, eight areas,\nand six operational primitives designed to assess the utility\nand sociality of multiple agents.\nâ€¢ We conducted validation and ablation studies in IrollanVal-\nley through human evaluation, and the results showed that\nITCMA-S performed excellently across multiple indicators.\nâ€¢ Furthermore, we discovered that agents can actively explore\nthe environment, cooperate with other agents through a\ndivision of labor, and spontaneously form small groups and\nleadership structures in complex social settings.\nSection 2 of this paper introduces related works; Section 3 intro-\nduces the improvement of the individual agent structure of ITCMA-\nS on an existing generative agent architecture and includes an ex-\nplanation of how it generates and infers action through perception,\nmemory, and emotion-driven mechanisms; Section 4 introduces a\nmulti-agent interaction framework in ITCMA-S, namely LTRHA;\nSection 5 introduces the experimental evaluation of the sociality of\nITCMA-S and discusses the process and results of the formation\nof the agentsâ€™ social relationships; and Section 6 summarizes the\nmain findings of the study and suggests future research potential.\n2\nRELATED WORK\n2.1\nLLM-based agent\nPark et al. [31] introduced a generative agent based on an LLM and\ndemonstrated that it can generate trustworthy individual behavior\nand sudden group behavior in simulations. For example, a genera-\ntive agent will turn off a stove when it sees its breakfast burning\nand will stop to chat when it encounters other agents with whom it\nwants to talk. Based on this research, numerous LLM-based agents\nhave emerged. Zhang et al. [45] proposed AppAgent, which con-\nstructs an agent to operate any smartphone application. Hong et\nal. [20] proposed an 18-billion-parameter visual language model\n(VLM) named CogAgent, which specializes in GUI understanding\nand navigation. Vezhnevets et al. [39] provided the Concordia li-\nbrary to simulate agent interactions in physical, social, and digital\nspaces. Among these, a special agent called the game master (GM)\nis responsible for simulating the environment of agent interactions.\nAgents take action by describing what they want to do in natural\nlanguage, and the GM then translates their actions into appropriate\nimplementations.\n2.2\nResearch on the Structure of Generative\nAgents\nThe original structure of generative agents, as described by Park et\nal. [31], mainly consisted of three parts: memory flow, reflection,\nand planning. The concept of a chain of thought (CoT) was partic-\nularly important for improvements to the planning module [41].\nCoT refers to the ability of an LLM to think and reason gradually\nthrough a series of steps or iterations, reflecting human cognitive\nprocesses. Traditional language models generate responses without\nclear intermediate steps, which can lead to suboptimal answers,\nespecially in complex inference scenarios. CoT overcomes these\nlimitations by introducing intermediate steps to enable language\nmodels to reason, thereby enhancing the modelâ€™s ability to solve\nproblems. Mondal et al. [28] suggested using knowledge graphs\nto enhance multiple patterns to help models solve complex prob-\nlems, thereby triggering CoT functionality. Their proposed method,\nknowledge augmented multimodal (KAM)-CoT, decouples the infer-\nence process into two consecutive stages. In the first stage, practical\nreasons are provided, and in the second stage, the generated reasons\nare used as additional input to provide answers.\nAs an improvement to the memory module, Liu et al. [25] pro-\nposed the reasoning and acting through scratchpad and exam-\nples (RAISE) architecture, which was specifically designed to en-\nhance the functionality of conversational agents. It combines a\ndual-component memory system, similar to the short-term and\nlong-term memory functions of the human brain. Toy et al. [37]\nproposed a metacognitive module by improving the reflection mod-\nule in generative agents, allowing agents to broadly consider their\nsituations to create alternative strategies and improve their perfor-\nmance.\n\nCan Agents Spontaneously Form a Society?\nTo improve the overall structure of generative agents, Wu et al.\n[42] explored an alternative mechanism that utilizes prior knowl-\nedge encoded in an LLM without affecting the trainability of agents.\nTheir proposed three-step PET framework: Plan, Eliminate, and\nTrack. Lin et al. [24] proposed the method SwiftSage, which can\nachieve both fast and slow thinking in complex interactive reason-\ning tasks. It effectively blends the advantages of behavioral cloning\nand LLM.\n2.3\nResearch on the Sociality of Generative\nMulti-Agents\nBy interacting with each other, generative agents can exchange in-\nformation, form new relationships, and coordinate activities. These\nsocial behaviors occur naturally rather than being pre-programmed.\nOver time, agents form new relationships and remember their in-\nteractions with other agents [31]. Generative Multi-Agents can\nsimulate complex human systems. Wang et al. [40] designed a new\nframework called the mosaic expert observation wall (MEOW). In\nMEOW, real game data are processed by expert models trained on\nsimulated data and converted into natural language prompts to\nassist LLM inference.\nHowever, while an LLM can capture social norms, there is also\nresearch that suggests that an LLM cannot adequately understand\nsocial norms, especially culture-specific social norms. This defect\nmay lead to conflicts between generative agents, especially when\ntheir underlying LLMs are trained on text corpora from different\ncultural backgrounds [21, 32]. Ren et al. [34] proposed the specifi-\ncation architecture CRSEC (named for its four modules: Creation\n& Representation, Spreading, Evaluation, and Compliance) for gen-\nerative multi-agent systems to resolve this problem. Building on\nthis foundation, these researchers examined the emergence of so-\ncial norms in generative multi-agent systems. Ghaffarzadegan et al.\n[17] provided a new approach to developing models that reduces\nreliance on assumptions about human decision-making and uti-\nlizes the vast amount of data in LLMs to capture human behavior\nand decisions. By utilizing the extensive dataset in the LLM, their\ngenerative agent-based model helps represent human decisions in\ncomputational models. Motwani et al. [29] pointed out that groups\nof generative agents can use communication channels in ways that\nare unexpected to their developers. When sharing data, stealthy\ncollusion can help agents coordinate unwanted behavior on a larger\nscale, and GPT-4 has demonstrated unparalleled capabilities in this\nregard.\n3\nGENERATIVE AGENT FRAMEWORK\n3.1\nThe Internal Time-Consciousness Machine\nBased Agent\nZhang, Yin, et al. [49] introduced the internal time-consciousness\nmachine (ITCM), which is a computational consciousness structure.\nThe ITCM supports agents in taking action and making inferences\nin an open world. It can help generative agents become more flexible\nand intelligent when handling complex tasks; this improves their\ninterpretability and makes their actions easier to understand and\npredict. On this basis, they proposed ITCM-based agent (ITCMA).\nAs a generative model, ITCMA considers both the reasoning ability\nof agents and the interaction between agents and the environment\nto compensate for the shortcomings of LLMs in accomplishing\nspecific tasks.\nITCMA can be simply explained as a framework: it uses a spher-\nical coordinate space called a â€œphenomenal fieldâ€ as one time frame\n(1f ) of perception representing a certain moment, and constructs a\ntime-continuous consciousness channel ğ¶ğ‘¡of equivalent working\nmemory through a field string composed of retention (perception\nof the past) ğ‘…ğ‘’ğ‘¡and primal impression (perception of the present)\nğ‘ƒğ¼ğ‘¡at time ğ‘¡in units of f. The ğ¶ğ‘¡can be combined with the long-\nterm memory ğ´ğ‘€of the agent activated by perception, and the\npossible changes of protention (prediction of future perception)\nğ‘ƒğ‘Ÿğ‘œğ‘¡when an action is to be taken that can be deduced through\nthe time-series forecasting model (TSFM). After that, it blends into\na natural language format together with the intrinsic motivation\nğ‘‘ğ‘¡, which includes the agentâ€™s emotional state (including pleasure,\narousal, and dominance) and is provided to the LLM to generate\nthe output of the action. Its structure is shown in Figure 1.\nFigure 1: Structure of ITCMA. ITCMAâ€™s main structure, the\nITCM, contains the consciousness channel, driver, and pro-\ntention. In the consciousness channel, retention and primal\nimpression are used to activate memory, and the driver con-\nsists of the dimensions of emotion and the driver from the\nprevious moment. These two are used to predict protention\nthrough the TSFM. The content of the ITCM will be converted\ninto formalized natural language, which will be delivered to\nthe LLM and will eventually cause it to act.\nThrough this mechanism, an agent perceives inputs from the\nenvironment and takes action as output to the environment. The\nâ€œbrainâ€ of an agent is not equivalent to an LLM here but is replaced\nby a complete ITCMA structure including the agentâ€™s memory. The\nLLM is only used as a tool. Experiments with ITCMA have demon-\nstrated the effectiveness and generalization of this architecture. The\ntrained agents exceeded the state of the art (SOTA) in the environ-\nment, and even completely untrained agents can start a task very\nquickly after exploring the environment and achieve good results.\n\nZhang et al.\nHowever, the structure of ITCMA still has shortcomings, in-\ncluding slow processing speed, excessive token consumption, and\nslow entry into the task context when untrained. To better test our\nassumptions about its performance, we first made certain improve-\nments to the structure of ITCMA, resulting in a generative multi-\nagent model for social interaction, namely ITCMA-S. It includes a\nstructure for an individual agent and a structure for multi-agent\ninteraction. The structure for an individual agent improved the\nmodules of memory, motivation, and action space reduction based\non ITCMA and are elaborated in the remaining parts of this section,\nwhile the structure for multi-agent interaction are discussed in\nSection 4.\n3.2\nMemory and Imagination\n3.2.1\nMemories Blended into the Present. In ITCMA, after a mem-\nory is awakened to the present moment, it is juxtaposed with the\nretention and primal impression in the consciousness channel. How-\never, the theory of creature consciousness suggests that phenom-\nenal consciousness requires the blending of a â€œphenomenal fieldâ€\nmechanism that may originate in the thalamus and neural inputs\nfrom different cortical areas responsible for processing memory-\nrelated information [3]. It is obvious that, for humans, the awak-\nening of memory is not simply juxtaposition but blending with\npresent consciousness. Conceptual blending is a cognitive activity\nthat combines information from different contexts [15]. Its main\nprocess is composition, which is the process of projecting input\nspaces (two different fields) into the blended space. Blending can\ncombine elements from the input spaces to provide relationships\nthat do not exist within a single input space.\nTherefore, based on conceptual blending theory, we hypothesize\nthat when a memory of ITCMA-S enters the current consciousness\nchannel, its phenomenal fields of observation and recollection are\nblended to obtain the imagination of this moment, and thus the\nmaterial of the consciousness channel is obtained. As shown in\nFigure 2, this process satisfies the following steps: In the first step,\nFigure 2(a), there is local matching between the phenomenal fields;\nthat is, the equivalent component connections are generated by the\nmatching. Once the match between the two fields is created, it is said\nthat there is cross-space mapping between them. In the second step,\nFigure 2(b), which is the blending process, the matching structure\nof the two phenomenal fields is utilized to establish the generic\nspace (which can be roughly understood as the common â€œbelongingâ€\nclass containing the instances of the elements of the phenomenal\nfields). In the third step, Figure 2(c), via the generic space, the two\nphenomenal fields are projected into a new space: the blended\nspace. After this, components and structures in the phenomenal\nfield selectively enter the blended space, forming structures that\nare, to some extent, distinct from the original phenomenal field.\nWe stipulate that for completely identical objects, they are placed\nin the blended space after blending takes place (i.e., taking the\naverage); objects that match in the generic space (with similarity\nexceeding a threshold) are each placed in the blended space; and\nobjects that do not match have a certain probability of being placed\nin the blended space. Therefore, for the two phenomenal fields ğ‘“ğ‘¥\nand ğ‘“ğ‘¦, the blending process ğµğ‘™ğ‘’ğ‘›ğ‘‘(ğ‘“ğ‘¥, ğ‘“ğ‘¦) follows Algorithm 1:\nFigure 2: The Conceptual Blending Process of the Phenome-\nnal Field. (a) Two phenomenal fields are matched to create\ncross-space mapping; (b) a generic space is established for the\nmatched objects in the two phenomenal fields; and (c) with\nthe help of the generic space, the components and structures\nin the two phenomenal fields selectively enter the blended\nspace.\nfğ‘¥=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nfğ‘¥1\n...\nfğ‘¥ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\n=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nğ‘ğ‘¥1\nğ‘ğ‘œğ‘ ğ‘¥1\n...\n...\nğ‘ğ‘¥ğ‘\nğ‘ğ‘œğ‘ ğ‘¥ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\n=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nğ‘ğ‘¥1\n1\nÂ· Â· Â·\nğ‘ğ‘¥ğ‘›\n1\nğœƒğ‘¥1\nğœ‘ğ‘¥1\nğ›¾ğ‘¥1\n...\n...\n...\n...\n...\n...\nğ‘ğ‘¥1\nğ‘\nÂ· Â· Â·\nğ‘ğ‘¥ğ‘›\nğ‘\nğœƒğ‘¥ğ‘\nğœ‘ğ‘¥ğ‘\nğ›¾ğ‘¥ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\n(1)\nfğ‘¦=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nfğ‘¦1\n...\nfğ‘¦ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\n=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nğ‘ğ‘¦1\nğ‘ğ‘œğ‘ ğ‘¦1\n...\n...\nğ‘ğ‘¦ğ‘\nğ‘ğ‘œğ‘ ğ‘¦ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\n=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\nğ‘ğ‘¦1\n1\nÂ· Â· Â·\nğ‘ğ‘¦ğ‘›\n1\nğœƒğ‘¦1\nğœ‘ğ‘¦1\nğ›¾ğ‘¦1\n...\n...\n...\n...\n...\n...\nğ‘ğ‘¦1\nğ‘\nÂ· Â· Â·\nğ‘ğ‘¦ğ‘›\nğ‘\nğœƒğ‘¦ğ‘\nğœ‘ğ‘¦ğ‘\nğ›¾ğ‘¦ğ‘\nï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£»\n(2)\nğ‘†ğ‘â„ğ‘’ğ‘Ÿğ‘–ğ‘ğ‘ğ‘™ğ‘†ğ‘–ğ‘š(ğ´, ğµ) =\n1 âˆ’1\n3 (ğœ”ğ›¾tanh(|ğ›¾ğ´âˆ’ğ›¾ğµ|) + ğœ”ğœƒ\n|ğœƒğ´âˆ’ğœƒğµ|\nğœ‹\n+ ğœ”ğœ‘\n|ğœ‘ğ´âˆ’ğœ‘ğµ|\n2ğœ‹\n)\n(3)\nğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ğ‘†ğ‘–ğ‘š(ğ‘“ğ‘¥, ğ‘“ğ‘¦) =\nÃğ‘\nğ‘–=1 ğœ”ğ‘ğ¶ğ‘œğ‘ ğ‘–ğ‘›(ğ‘ğ‘¥ğ‘–, ğ‘ğ‘¦ğ‘—) + ğœ”ğ‘ğ‘œğ‘ ğ‘†ğ‘â„ğ‘’ğ‘Ÿğ‘–ğ‘ğ‘ğ‘™ğ‘†ğ‘–ğ‘š(ğ‘ğ‘œğ‘ ğ‘¥ğ‘–, ğ‘ğ‘œğ‘ ğ‘¦ğ‘—)\nğ‘€ğ‘ğ‘¥(ğ‘,ğ‘)\n(4)\nAlgorithm 1 Conceptual Blending Algorithm of Phenomenal\nField ğµğ‘™ğ‘’ğ‘›ğ‘‘(ğ‘“ğ‘¥, ğ‘“ğ‘¦)\nInput: Initial Fields ğ‘“ğ‘¥and ğ‘“ğ‘¦\nOutput: Blended Field ğ‘“ğ‘§\n1: Initialize threshold of similarity degree ğ‘‡\n2: Initialize blended probability ğ‘Ÿ\n3: for ğ‘–ğ‘“ğ‘Ÿğ‘œğ‘š1ğ‘¡ğ‘œğ‘do\n4:\nfor ğ‘—ğ‘“ğ‘Ÿğ‘œğ‘š1ğ‘¡ğ‘œğ‘do\n\nCan Agents Spontaneously Form a Society?\n5:\nğ‘ â†ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ğ‘†ğ‘–ğ‘š(ğ‘“ğ‘¥\nğ‘–, ğ‘“ğ‘¦\nğ‘—)\n6:\nif ğ‘ < ğ‘‡then\n7:\nContinue\n8:\nelse if ğ‘ = 1 then\n9:\nğ‘“ğ‘§\nğ‘˜â†ğ´ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’(ğ‘“ğ‘¥\nğ‘–, ğ‘“ğ‘¦\nğ‘—)\n10:\nif ğ‘“ğ‘§\nğ‘˜not in ğ‘“ğ‘§then\n11:\nAdd ğ‘“ğ‘§\nğ‘˜as a row to ğ‘“ğ‘§\n12:\nend if\n13:\nBreak\n14:\nelse\n15:\nif ğ‘“ğ‘¥\nğ‘–not in ğ‘“ğ‘§then\n16:\nAdd ğ‘“ğ‘¥\nğ‘–as a row to ğ‘“ğ‘§\n17:\nend if\n18:\nif ğ‘“ğ‘¦\nğ‘—not in ğ‘“ğ‘§then\n19:\nAdd ğ‘“ğ‘¦\nğ‘—as a row to ğ‘“ğ‘§\n20:\nend if\n21:\nBreak\n22:\nend if\n23:\nend for\n24: end for\n25: There is a probability that rows in ğ‘“ğ‘¥and ğ‘“ğ‘¦that are not in\nğ‘“ğ‘§will each have rate ğ‘Ÿadded as a row in ğ‘“ğ‘§.\n26:\n27: return ğ‘“ğ‘§\nAmong them, ğ¶ğ‘œğ‘ ğ‘–ğ‘›(ğ´, ğµ) represents the cosine similarity be-\ntween ğ´and ğµ. For the retention ğ‘…ğ‘’ğ‘¡and primal impression ğ‘ƒğ¼ğ‘¡,\nthe acquisition of protention ğ‘ƒğ‘Ÿğ‘œğ‘¡can be corrected as follows:\nimaginet = Blend(PIt, M(PIt, Ret))\n(5)\nCt = [ Ret, PIt, M(PIt, Ret) ]\n(6)\nProt = TSFM(Ct, imaginet, dt),\n(7)\nwhere ğ¶ğ‘¡is the content of the consciousness channel at time ğ‘¡,\nTSFM is the selected time-series forecasting model, and ğ‘€is the\nprocess of triggering inventory memory through ğ‘ƒğ¼ğ‘¡and ğ‘…ğ‘’ğ‘¡.\n3.2.2\nMemory Storage and Compression. One of the reasons for\nthe slow processing speed of ITCMA is the memory activation\nalgorithm it uses. Its improved Levenshtein distance method pro-\nvides better memory query results. However, it consumes more\ntime than the simple cosine similarity algorithm. For this reason, it\nwas necessary to improve it.\nOne way to improve the speed of memory activation is to reduce\nthe number of memories that the agent needs to query. Due to the\nlearning of new memories, the retention and association of existing\nmemories will be affected [1]. One way to address this is to modify,\nsplit, and recombine memories over time, that is, to compress mem-\nories [11]. This compression can affect the accuracy of memory,\nbut its impact on recall is not as severe. In fact, people do not use\nprecise memories when making decisions [8]. The compression\nprocess of memory constantly generates new meanings [15], and\nmaking decisions based on such memories is sometimes seen as\nintelligent inference, which may be a source of the generalization\nof human intelligence [33].\nTherefore, by compressing old memories and blending them\nwhen they are recalled to the present moment, we enable ITCMA-\nS to reduce the total number of memories while preserving the\nrecall effect, thereby increasing the speed of the memory search. In\naddition, based on the mood congruence effect, we set the weight\nof the memory index to the emotional intensity accompanying the\nagent at the time of memory occurrence [11, 14, 23]. Specifically,\nto compress a segment of memory, we need to select the key frame\nğ‘“ğ‘˜ğ‘’ğ‘¦that has the strongest arousal in that segment of memory.\nThe process ğ‘€ğµğ‘™ğ‘’ğ‘›ğ‘‘ğ‘›(f key, Memory1,n) of compressing a segment\nof memory Memory1,n with a length of ğ‘›by ğ‘“ğ‘˜ğ‘’ğ‘¦is expressed as\nfollows:\nMemory1,n = [f1, f2, f3 . . . , fğ‘›]\n(8)\nğ‘€ğµğ‘™ğ‘’ğ‘›ğ‘‘ğ‘›(f key, Memory1,n) =\n(\nf key\nğ‘–ğ‘“ğ‘›= 0.\nBlend(ğ‘€ğµğ‘™ğ‘’ğ‘›ğ‘‘ğ‘›âˆ’1(f key, Memory1,nâˆ’1), fn)\nğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’.\n(9)\nAfter compression is complete, ğ‘€ğµğ‘™ğ‘’ğ‘›ğ‘‘ğ‘›(f key, Memory1,n) re-\nplaces the original Memory1,n position in the long-term memory\nbase to reduce the total number of memories.\n3.3\nEmotion and Motivation\nEmotions can help with decision-making, not just interfere with\nit, as most people believe [12]. For example, in decision-making,\nemotions can highlight the importance of a certain premise, thereby\nmaking a decision tend toward that premise. This idea coincides\nwith the practice in ITCMA of allowing LLMs to choose which\naction to perform by deducing the protention ğ‘ƒğ‘Ÿğ‘œğ‘¡of each action\nin the action space. However, although ITCMA provides LLMs with\nan internal driving force ğ‘‘ğ‘¡that includes emotions for decision-\nmaking, it only adds the weighted sum of the three-dimensional\nPAD emotions at this moment to the internal driving force ğ‘‘ğ‘¡âˆ’1\nat the previous moment. Indeed, agents tend to push pleasure and\ndominance to have the highest values possible [13, 36], but they\nalso generally tend to keep emotional arousal at a stable value [19].\nIn ITCMA-S, the arousal ğ´ğ‘¡-based mechanism of passive attention\nis quantified as the degree of change between the elements in re-\ntention and the elements in the current primary impression. The\ndominance ğ·ğ‘¡is quantified as the difference between the proten-\ntion ğ‘ƒğ‘Ÿğ‘œğ‘¡âˆ’1 at the previous moment and the primal impression\nğ‘ƒğ¼ğ‘¡at this moment. The pleasure ğ‘ƒğ‘¡is quantified as the degree of\nsatisfaction with the agentâ€™s ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’and the degree of avoidance\nof ğ‘ğ‘ğ‘–ğ‘›. The expression ğœ”ğ‘ƒ+ ğœ”ğ´+ ğœ”ğ·= 1 contains the dynamic\nweights of the emotions. Therefore, for the emotional dimensions\nğ‘ƒğ‘¡,ğ´ğ‘¡, ğ·ğ‘¡âˆˆ(âˆ’1, 1) at time ğ‘¡, the emotional values should be con-\nsidered as follows:\nPt = tanh(ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’) âˆ’tanh(ğ‘ğ‘ğ‘–ğ‘›)\n(10)\nAğ‘¡= tanh(\nğ‘¡âˆ’1\nâˆ‘ï¸\nğ‘›=1\n(\n2ğ‘›\nğ‘¡(ğ‘¡âˆ’1) (ğ‘‘ğ‘–ğ‘“ğ‘“(PIğ‘¡, ren))))\n(11)\nDğ‘¡= tanh(ğ‘‘ğ‘–ğ‘“ğ‘“(PIğ‘¡, Protâˆ’1))\n(12)\n\nZhang et al.\ndbiasğ‘¡= ğœ”PPt + ğœ”DDt + ğœ”A(1âˆ’| At âˆ’Atâˆ’1 |)\n(13)\nAmong them, the calculation of ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’and ğ‘ğ‘ğ‘–ğ‘›âˆˆ[0, âˆ) are\ndefined according to specific situations. For example, in reinforce-\nment learning tasks, ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’can be defined as reward, while ğ‘ğ‘ğ‘–ğ‘›\ncan be defined as punishment. However, to avoid the situation of\nlocal optima (where agents enter a scenario in which they can con-\ntinuously obtain ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’and reduce ğ‘ğ‘ğ‘–ğ‘›without taking any further\nactions), we introduce a demand dimension ğ‘ğ‘’for them.\nThe demand motivation model [27, 48] states that when an agent\nfalls into a local optimum and its basic needs are satisfied, these\nneeds are no longer important, and the agent moves on to more ad-\nvanced needs. As a result, the agent needs to pursue advanced needs\nto gain new ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’, and the ğ‘‘ğ‘’ğ‘ ğ‘–ğ‘Ÿğ‘’then gained from satisfying basic\nneeds falls while the ğ‘ğ‘ğ‘–ğ‘›gained rises. This can be approximated\nas dynamic rewards and punishments. For ğ‘‘ğ‘ğ‘–ğ‘ğ‘ ğ‘¡âˆˆ(âˆ’1, 1), these\nare as follows:\nNe = | dbiasğ‘¡âˆ’dbiasğ‘¡âˆ’1 |\n2\n(14)\ndt = dtâˆ’1 + Ned\nt\nbias\n(15)\n3.4\nReduction of Action Space\nThe PET framework created an elimination module for AlfWorld\nusing pre-trained Q&A models to filter out containers and objects\nunrelated to the current task based on common sense about the\ntask [42]. Through this step, the time required for an untrained\nagent to enter the task context can be effectively reduced. Similarly,\nITCMA-S also uses an LLM ğ¸ğ‘™ğ‘–ğ‘što reduce the number of action\nspaces in a zero-shot manner. Specifically, for the target ğºof the\nagent, we create a prompt in ğ·ğ‘’ğ‘ ğ‘= â€œYour task is to: ğº. The actions\nyou can take are: ğ´ğ‘†. The ğ‘ğ‘–will be relevant?â€ format for the exe-\ncutable action ğ‘ğ‘–âˆˆğ´ğ‘†in the action space ğ´ğ‘†. ğ¸ğ‘™ğ‘–ğ‘šwill output the\nconfidence score for the action ğ‘ğ‘–:\nğœ‡ai = ğ¸ğ‘™ğ‘–ğ‘š(ğ·ğ‘’ğ‘ ğ‘,ğº,ğ´ğ‘†, ai)\n(16)\nAmong them, ğœ‡ai âˆˆ[1, 5]. When ğœ‡ai is less than the threshold,\nğ‘ğ‘–will be removed from the action space. The elimination process\nis shown in Figure 3.\n4\nSOCIAL INTERACTION FRAMEWORK\nZhang, Duan, et al. [47] proposed a social regulation model for the\ndynamic adaptation of users in virtual interactive environments,\nnamely the tribal theater model (TTM), to address the core issue\nof â€œenhancing user interaction freedom.â€ This model emphasizes\nthe subjectivity of interactive users. In this section, based on the\nTTM and field theory [5], we present a multi-agent social interac-\ntion architecture, the LTRHA, for ITCMA-S, which consists of four\nmodules: locale & topic, resources, habitus, and action. We aimed\nto design an interaction architecture for generative agents to pro-\nmote the emergence of spontaneous social interactions within their\nsocieties. Specifically, there is no preset identity in the LTRHA envi-\nronment. Every agent has certain resources. The environment will\nprovide basic action options, such as using objects and communi-\ncating with other agents. The probability of successfully executing\nFigure 3: The Process of Reducing the Action Space. Due to\nthe high degree of freedom in the scene, there are too many\navailable actions. Among them, the red action is unrelated\nto the current goal, so it should be eliminated without the\nneed for further protention calculation.\nthese actions will depend on the number of resources and will be\nhanded over to the matrix model for processing after execution.\nAlong with the actions input to the model, there is a vector con-\nsisting of the current resource structure of the environment and a\nvector of topics that have been quantified according to the analysis\nof the emotions of each agent. Based on the input, the matrix model\nwill adjust the resource structure of the environment and output it\nas a vector to change the resource structure. The specific process is\nshown in Figure 4. We provide a detailed introduction to each part\nof the LTRHA framework in the sections that follow.\n4.1\nLocale and Topic\nIn the TTM, the field is decomposed into two parts: the tribe and the\natmosphere [47]. To distinguish the field in ITCMA-S from the field\nin ITCMA, we refer to the parts as the locale and topic. The locale\nand topic modules can be understood together as an interactive\nspace. In human society, such interactive spaces typically include\nlocales as physical spaces and topics as mental factors [26, 30]. For\nexample, in a speech setting, the stage and audience seats are part of\nthe locale, and the passion aroused by the speaker in the audience\nis a topic.\nWe define a sub-environment ğ‘’ğ‘›ğ‘£of the overall environment,\nwhich includes a space and ğ‘›agents occupying that space. We make\nthe spatial area and its contained objects ğ‘™ğ‘œğ‘ğ‘’ğ‘›ğ‘£as the locale, and\nthe emotion synthesis function ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£of these agents is a topic.\nAmong them, we define agentğ‘”ğ‘ğ‘–âˆˆğºğ´with emotional dimensions\nğ‘ƒğ‘–,ğ´ğ‘–, ğ·ğ‘–âˆˆ(âˆ’1, 1). The emotion synthesis function is described by\nthe following equation:\nğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£=\nÃğ‘›\nğ‘–=1 ğ‘ƒğ‘–\n(ğ´ğ‘–+1)\n2\nğ‘›\n(17)\n\nCan Agents Spontaneously Form a Society?\nFigure 4: Execution Process of the LTRHA. An agent executes\nactions with probabilities related to the number of resources\nand then hands over the actions, the current resource struc-\nture, and quantified topics of the environment to the matrix\nmodel for processing. The matrix model adjusts the resource\nstructure of the environment based on input.\nAs a result, the topic value of a sub-environment will be in the\ninterval [âˆ’1, 1], where less than zero is a negative atmosphere and\nmore than zero is a positive atmosphere. In ğ‘’ğ‘›ğ‘£, any agent can\nchange the perception of other agents by affecting the objects in\nğ‘™ğ‘œğ‘ğ‘’ğ‘›ğ‘£, thereby affecting ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£.\n4.2\nResources\nThe execution of actions by agents requires a certain amount of\nresources, just as implementing decisions in human society requires\na certain cost. Resources are allocated to the agents in the sub-\nenvironments based on the actions of the agents by a model called\nthe â€œmatrix.â€\n4.2.1\nCompetition for Limited Resources by Agents. The key to\ninteractive regulation is the resources possessed by an agent [5, 18].\nVirtual resources, such as the cultural level and social status, are\nconsidered interactive resources. We believe that the agentsâ€™ envi-\nronment is a space for competing resources. Changing the distri-\nbution and relative weights of resources is equivalent to changing\nthe structure of the environment. A resource is both a weapon and\nan object of contention, enabling its owner to exert influence on\nthe environment. Therefore, the number of resources possessed by\nan agent determines the actions it can perform in one time step.\nSpecifically, in the environment, a total of ğ‘›agents ğ‘”ğ‘ğ‘–âˆˆğºğ´each\nhold a number of resources ğ‘†ğ‘–. ğ‘†ğ‘–is initially 1. Agents take turns\nexecuting actions. A specific ğ‘”ğ‘ğ‘–takes action with a probability\nğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘–as follows:\nğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘–= 0.5 + ğ‘†ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘(ğ‘†ğ‘–)\n2\n,\n(18)\nwhere the probability ğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘–is a function of the number of resources\nrelated to agent ğ‘”ğ‘ğ‘–as a percentage of the total number of resources.\n4.2.2\nDynamic Allocation of Resources by the Matrix. Consumed re-\nsources need to be replenished. Therefore, a mechanism is needed\nfor the circulation and allocation of resources. The model that\nreplaces natural rules and collective subconsciousness in human\nsociety for resource allocation and regulation is called the â€œmatrixâ€\n[4]. It accepts a vector consisting of the current resource structure\nand a vector of topics that have been quantified based on the anal-\nysis of each agentâ€™s emotions as input, and a new resource vector\nis output. For ğ‘›> 2 agents ğ‘”ğ‘ğ‘–âˆˆğºğ´input their current actions\nğ‘ğ‘–, global resource structure ğ‘†, and environmental topic ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£to-\ngether into the matrix model to obtain a new resource structure\nğ‘†â€² â†ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥(ğ‘ğ‘–,ğ‘†,ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£).\nWe use an LLM as the matrix model and have it rank each agent\nbased on their personal goals and ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£. After that, if the number\nof resources increases, the maximum number of resources that the\nagent can receive ğ‘ ğ‘šğ‘ğ‘¥and the minimum number of resources that\nthe agent can receive ğ‘ ğ‘šğ‘–ğ‘›are set. The ğ‘—-th ranked agent ğ‘”ğ‘ğ‘—can\nreceive the number of resources ğ‘†â€²\nğ‘—:\nğ‘†â€²\nğ‘—=\nï£±ï£´ï£´ï£´ï£´ï£²\nï£´ï£´ï£´ï£´ï£³\n0\nğ‘—= ğ‘›+1\n2\nğ‘ ğ‘šğ‘–ğ‘›+ |ğ‘—âˆ’ğ‘›\n2 | (ğ‘ ğ‘šğ‘ğ‘¥âˆ’ğ‘ ğ‘šğ‘–ğ‘›)\n| ğ‘›\n2 âˆ’1|\nğ‘—â‰¤ğ‘›\n2\nâˆ’(ğ‘ ğ‘šğ‘–ğ‘›+ |ğ‘—âˆ’ğ‘›\n2 âˆ’1| (ğ‘ ğ‘šğ‘ğ‘¥âˆ’ğ‘ ğ‘šğ‘–ğ‘›)\n| ğ‘›\n2 âˆ’1|\n)\nğ‘—> ğ‘›\n2\n(19)\nTherefore, the higher the ranking of the agents, the greater the\nnumber of resources they can receive. When an agentâ€™s ranking\nfalls below halfway, its existing resources will also be removed.\n4.3\nHabitus and Action\nâ€œHabitusâ€ is a technical term that describes a series of ways of\nperception, cognition, and action. It shares similarities with the\nmeaning of the common English word â€œhabitâ€ (which comes from\nthe Latin word â€œhabitus,â€ which means condition or appearance in\nthat language). In human society, it can be understood as a decision\ntree for action. When we are in an environment, a corresponding\ndecision tree is activated, and we decide on our final actions based\non our behavioral habits. This is similar to the logic of mutual\ninfluence between an environment and an agent in reinforcement\nlearning. In addition to an agent shaping the environment, the\nenvironment shapes habitus, and the habitus is thus a product of\nan inherent and necessary attribute of the environment reflected\nin the agent [6].\nThus, habitus is clearly an attribute of an agent itself, but it is\nalso included in our framework because of its close relationship to\nenvironmental content. The actions ultimately taken in the LTRHA\nframework can be summarized as follows [7]: action ğ‘ğ‘–of agent ğ‘”ğ‘ğ‘–\nis driven by the combination of habitus ğ»ğ‘–, resource ğ‘†ğ‘–and envi-\nronment ğ‘’ğ‘›ğ‘£â†[ğ‘™ğ‘œğ‘ğ‘’ğ‘›ğ‘£,ğ‘¡ğ‘ğ‘ğ‘’ğ‘›ğ‘£], that is, ğ‘ğ‘–â†ğ‘“(ğ‘”ğ‘ğ‘–(ğ»ğ‘–,ğ‘†ğ‘–),ğ‘’ğ‘›ğ‘£).\n\nZhang et al.\n5\nEVALUATION\n5.1\nEnvironment Settings\nThe environments that support the evaluation of individual agent\ncapabilities include the agent behavior evaluation framework Ma-\ngenta [2], the network task environment WebArena [50], the life\ntask environment ALFWorld [35], and the Chinese character role-\nplaying conversation benchmark CharacterEval [38]. These envi-\nronments can effectively evaluate the ability of individual agents\nto complete tasks, but they are not very helpful for the social eval-\nuation of multi-agent systems.\nTo evaluate the sociality of multi-agent systems, it was necessary\nto consider constructing a virtual artificial society. Xue et al. [44]\nsuggested that a comprehensive method of computational experi-\nment design can be used to infer social systems through multi-agent\nsystems. Artificial societies are used for descriptive modeling in\ncomputational experiments. After constructing an artificial society,\nresearchers can directly create computational experiments to sim-\nulate and interpret the results of trials conducted using different\nconditions, locations, and participants. The most classic example\nof such an environment is the Smallville environment provided by\nPark et al. [31]. This is a 2D open-world role-playing game (RPG).\nAgents interact with the world and with each other through their\nbehavior and through natural language. At each time step in Smal-\nlville, the agent outputs a natural language statement describing\nits current operation, such as, â€œIsabella is writing a diary.â€ This\nstatement is then translated into specific actions that affect the\nsandbox world. With the ALFWorld environment used by ITCMA\nas a reference, we designed a 2D sandbox RPG similar to Smallville,\ncalled IrallanValley, as shown in Figure 5. It includes six agents\nwith the following arbitrary two-letter designations: AY, SG, MD,\nWL, LL, and WM. It also uses environment text descriptions and op-\nerational primitives consistent with ALFWorld. Because we wanted\nto observe the spontaneous emergence of individual character traits\nand role divisions by agents without presets or interventions, we\ndid not preconceptualize any personality or identity for the agents\nin IrollanValley, as Smallville did.\nIrollanValley accepts control requests via a server. This server\nenables the generative agents to use the sandbox information and\nallows them to move and influence the sandbox environments. At\neach time step, the server provides a natural language description\nof the agentsâ€™ current environment and executable action space,\nmoves the generative agents to new locations by accepting actions\nfrom them, and updates the state of any sandbox objects with\nwhich agents interact. The server returns a JSON (JavaScript object\nnotation) object containing a natural language description of the\nnew environment, allowing the agents to update their parameters.\nIrollanValley has eight main areas: the six agentsâ€™ corresponding\nhouses, a public canteen, and a public reading room. Each area has\nits own furniture and other items. Agents can hold any number of\nitems and use the furniture to place and store them, or to change\nthe state of these items. For example, the sinkbasin can make items\nclean and damp, while the stoveburner can remove the damp state\nof the items and make them hot. Agents can exchange items freely\nto achieve their respective goals.\nFigure 5: The IrollanValley Sandbox World. The world con-\ntains six characters, eight regions, and six operational primi-\ntives. Agents obtain perception by receiving natural language\ndescriptions of the observed environment.\nThe text description obtained from observing the environment in\nIrollanValley follows this format: â€œYou are in SOMEWHERE. Look-\ning around you, you see a person named N (who is DOING SOME-\nTHING), FURNITURE 1, ITEM 1 placed on SOMEWHERE... (You are\nholding SOMETHING.) You are DOING SOMETHING.â€ The descrip-\ntion in parentheses appears only when the described object is in a\nspecific situation. IrollanValley provides six main operational prim-\nitives, including â€œgo to SOMEWHERE,â€ â€œuse SOMETHING,â€ â€œleave\nSOMEWHERE/SOMEONE,â€ â€œtake SOMETHING from SOMEWHERE,â€\nâ€œput SOMETHING in/on SOMEWHERE,â€ and â€œchat with SOMEONE(:\nCHAT CONTENT).â€\nIn addition, the different modules of ITCMA-S use different LLMs\nbecause they have varying requirements for processing speed and\nprecision. Specifically, for the elimination module, the generation\nof protention, and the matrix module of LTRHA, we used the Llama\n3.1-8B model, while action and chat content was generated using\nGPT-4o.\n5.2\nHuman Evaluation\nTo evaluate the effectiveness of ITCMA-S, we conducted an ab-\nlation study. There were five ablation architectures: the original\nITCMA architecture without improvements, the LTRHA-only archi-\ntecture, the compressed memory-only architecture, the driver-only\narchitecture, and the full ITCMA-S architecture.\nWe recruited 48 human evaluators to assess the output from the\nagents in the study. We hoped that the agents could generate so-\nciality in multiple ways. This would mean that they would take the\ninitiative to explore the environment and meet new agents. They\nwould acquire new information through their own continuous ac-\ntions, past memories, and conversations with other agents, and\n\nCan Agents Spontaneously Form a Society?\nTable 1: Human Evaluation Results.\nPersonification\nConsistency\nLogicality\nExploration\nProactiveness\nITCMA\n2.88 Â± 0.24\n2.46 Â± 0.22\n2.50 Â± 0.20\n2.85 Â± 0.24\n2.65 Â± 0.23\nLTRHA\n4.88 Â± 0.23\n5.02 Â± 0.22\n4.75 Â± 0.25\n5.25 Â± 0.20\n4.60 Â± 0.22\nCompressed Memory\n3.55 Â± 0.23\n4.21 Â± 0.24\n4.00 Â± 0.27\n3.75 Â± 0.25\n4.02 Â± 0.23\nDriver\n4.29 Â± 0.19\n4.31 Â± 0.27\n4.63 Â± 0.20\n4.29 Â± 0.20\n4.06 Â± 0.23\nITCMA-S\n6.29 Â± 0.16\n6.00 Â± 0.20\n5.98 Â± 0.19\n6.02 Â± 0.16\n6.17 Â± 0.20\nlearn how to plan their actions to live better in IrollanValley. There-\nfore, the evaluation indicators for the human evaluators consisted\nof five dimensions:\nâ€¢ Personification. The degree to which an action appears\nhuman-like.\nâ€¢ Consistency. Whether an action aligns with an agentâ€™s\nstate of mind.\nâ€¢ Logicality. Whether a sequence of actions is logical.\nâ€¢ Exploration. Whether an agent actively explores the envi-\nronment.\nâ€¢ Proactiveness. Whether an agent actively interacts with\nothers.\nAll outputs generated by the agents (including actions and thought\ncontent) were evaluated by the human evaluators. Each evaluator\nwas required to read the action trajectory of each agent over 75 time\nsteps and then fill out a questionnaire to complete the evaluation\nof ITCMA-S. This questionnaire used a 7-point Likert scale, asking\nevaluators to assess the actions of each agent individually.\nAnalysis of variance (ANOVA) tests were conducted on the col-\nlected questionnaires. The five architectures composed the indepen-\ndent variable, and the five dimensions of the evaluation were the\nindependent variables for the various tests. The results indicated\nsignificant differences among the models for each dimension. For\nthe dimensions of exploration (F = 33.01, p < .001) and proactiveness\n(F = 31.85, p < .001), the assumption of homogeneity of variances\nwas met, and the standard ANOVA was used. For the dimensions\nwhere the assumption of homogeneity of variances was violated\n(personification, consistency, and logicality), the Brown-Forsythe\ntest was used. The results showed significant differences among\nthe models for personification (F = 45.34, p < .001), consistency (F\n= 35.57, p < .001), and logicality (F = 39.62, p < .001).\nWe then performed Dunn-SidÃ¡k and Games-Howell post-hoc\ntests. The results indicated that, for the Exploration dimension,\nthere were no significant differences between the full ITCMA-S\narchitecture and the architecture that included the LTRHA. For the\nPersonification dimension, no significant differences were found\nbetween the original ITCMA architecture (without any improve-\nments) and the architecture that included the Compressed Memory.\nMoreover, across all dimensions, there were no significant differ-\nences among the three architectures that utilized only one module.\nApart from these, all other pairwise comparisons showed signifi-\ncant differences (p < .001). The specific human evaluation results\nare shown in Table 1.\nThe evaluation results show that the full ITCMA-S architecture\nperformed the best. As expected, the original ITCMA architecture\n(without any improvements) had the lowest performance. It is evi-\ndent that all the improvements had a positive impact on the social\ninteraction within ITCMA-S.\nAmong all the ablation architectures, the one that included the\nLTRHA social framework performed second only to the full ITCMA-\nS architecture on all measured dimensions. Interviews with the\nevaluators helped explain this phenomenon. LTRHA filters and\nmarks actions that are not conducive to social interaction and guides\nagents in choosing actions that are more likely to improve the social\natmosphere of a scene. Compared to the other ablation architectures,\nit was able to provide relatively more trustworthy action chains.\n5.3\nFormation of Cliques and Groups in Social\nInteraction\nTo further investigate the utility and mechanics of ITCMA-S, we\nconducted a more detailed analysis of its logs. Figure 6 shows the\nstate changes of the six agents in ITCMA-S over 75 time steps. Figure\n6(a) shows the change in driver values for the agents. As described\npreviously, the driver value reflects the willingness to encourage\nthe agent to take action. More specifically, Figure 6(b) shows the\nchanges in the three dimensions of emotions that make up the driver.\nEach agent maintained its pleasure value at a high level and kept its\narousal value as stable as possible over the 75 time steps (although\nthe mean was relatively high overall, as agents tended to move\namong different scenes rather than stay in a specific scene), while\nthe dominance value, although not showing a high level, rarely\ndropped below zero. As can be seen, the action choices of the agents\nin ITCMA-S exhibited a virtuous cycle. Agents actively explored\nthe environment and engaged in social activities that changed the\nenvironment. The environment, in turn, provided positive feedback\nto the agent, improving their emotions (increasing their pleasure\nand dominance) and leading to a higher willingness (that is, driver)\nto take action.\nIn addition, we investigated the changes in scene information\nreflected in the LHRHA framework, as shown in Figure 7. Figure 7(a)\nshows the changes in the resource structure of the scene. For most\nagents, their total amount of resources was rising. However, due to\nthe limited total amount of resources, the resources of individual\nagents (e.g., WL and MD) were continuously flowing to other agents.\nWe found that agents with resource loss were often alone and did\nnot interact with other agents, even when they shared a room with\nthem. Most of their actions involved resting (such as using beds\nor chairs), and most of their thoughts were about wanting to rest\nor read. Other agents liked to engage in social activities, discuss\nwhat they wanted to do together, and follow this up with planned\ngroup actions. These agents spontaneously selected a leader (LL)\n\nZhang et al.\nFigure 6: State Changes of the Six Agents in ITCMA-S over\n75 Time Steps. (a) Driver value change for each agent; (b) the\nemotion value changes for each agent, represented by three\ndimensions: pleasure, arousal, and dominance.\nand formed a clique around this individual. The variation in topic\nvalues across different scenes, as shown in Figure 7(b), similarly\nreflects this situation. The other agents gathered at leader LLâ€™s\nhome, creating a continuously rising atmosphere at the scene. Over\n75 time steps, these agents arranged to go to the public reading\nroom together and conducted research on a $10 bill they found\nthere. Each performed their own duties, gathering information to\nfind clues about it. Agents who did not belong to this clique did\nnot participate in this activity (even if it was mentioned by other\nagents) and focused solely on their own activities.\nFigure 8 shows the relationships among the agents. WL and MD,\nwho did not belong to the clique, had almost no social relation-\nships, while LL, as the leader of the clique, had the most complex\ninteractions.\nIt is worth noting that there was a further hierarchical divi-\nsion within the clique: SG and WM had the strongest relationship\nrelative to the others. LL established relationships with everyone.\nHowever, LL had not been fully integrated into the unique two-way\nrelationship between SG and WM. AY, while not in the cliqueâ€™s\ninner circle and hardly participating in activities, maintained ba-\nsic relationships with others. As time went by, this relationship\nstructure became increasingly solid, so that even if some agents\noccasionally expressed a desire to establish new connections in\ntheir thoughts, they did not take action to implement them. Even\nif an action was taken, it was still ignored to some extent by the\nother agents (such as by walking away or directly changing the\ntopic). Examples of the actions and interactions of each agent in\nIrollanValley are shown in Appendix A.\nFigure 7: Visualization of LTRHA Information. (a) The re-\nsource changes of six agents in ITCMA-S over 75 time steps;\n(b) the topic value changes in various areas of IrollanValley\nover 75 time steps.\nFigure 8: Heat Map of Agent Interaction Relationships in\nITCMA-S. Rows represent the initiator of the interaction,\nand columns represent the receiver of the interaction. The\ndarker the color, the more frequent the interaction, and the\nstronger the relationship.\n6\nDISCUSSION\nBased on LLMs, agents have shown significant advantages in nat-\nural language processing and human-computer interaction. The\npowerful language understanding and generation capabilities of\n\nCan Agents Spontaneously Form a Society?\nLLMs enable agents to handle complex linguistic structures and\ncontexts. This ability not only enhances the quality of interactions\nbetween agents and users but also improves their adaptability in dy-\nnamic environments. For example, agents can adjust their behavior\nand responses in real time based on user feedback and environmen-\ntal changes, providing personalized services and a more natural\ninteraction experience.\nThe sociality of a multi-agent system is one of the key factors\nfor its success. It can capture social contexts and human behavioral\npatterns, which influence individual behaviors and determine the\ndynamic evolution of the entire system. By simulating human social\ninteraction patterns, agents can form social networks, establish\ntrust relationships, and engage in cooperation and competition.\nThrough analysis of agent behavior, we discovered that agents can\nspontaneously form cliques, building complex social relationships\non that basis.\nIn fact, the formation of cliques significantly affects resource\nsharing and allocation among agents. In experiments, agents within\na clique optimized resource use through effective coordination and\ncooperation, facilitating collective activities. This indicates that in\nvirtual societies, the structural aspects of social networks have a\ncrucial impact on the flow and distribution of resources. In contrast,\nagents unable to integrate into cliques exhibited isolated behav-\niors, resource loss and a lack of social interaction. Moreover, the\ncomplexity of social relationships is a significant characteristic of\nthe clique formation process. Over time, the social ties within a\nclique gradually become entrenched, creating an internal hierarchi-\ncal structure. This structure influences the behavioral choices of\nagents.\nThis result indicates that generative multi-agents exhibit human-\nlike action logic within social interaction frameworks, which can\nguide the construction of computational social experiments. Virtual\nsocieties built on multi-generative agents framework can simulate\nsocial behaviors under different conditions and explore the forma-\ntion and evolution of social norms [44]. For example, researchers\ncan use multi-agent systems to simulate phenomena such as in-\nformation dissemination, resource allocation, and group decision-\nmaking in society. By observing and analyzing agent behaviors, re-\nsearchers can identify key factors influencing social dynamics, such\nas trust, cooperation, and competition. Furthermore, computational\nsocial experiments based on generative multi-agents framework\ncan also evaluate the effects of policy interventions [34]. By simu-\nlating agent behaviors in different policy contexts, researchers can\npredict the potential impacts of policy implementation on social\nstructures and individual behaviors. This research approach pro-\nvides new empirical tools for social sciences, enabling researchers\nto discuss the complexity and diversity of social behaviors while\ncontrolling for variables.\nIn addition, the social framework of generative multi-agents can\nalso be applied to role-playing games [37]. In game environments,\nthe sociality of agents significantly enhances immersion and inter-\nactivity. Agents are not merely passive characters. They actively\nengage in the game world. For instance, in open-world role-playing\ngames, agents can form complex social networks based on player\nactions and interactions with other agents. This network not only\ninfluences the decision-making and behaviors of the agents, but\nalso provides players with a richer gaming experience. Players\ncan observe cooperation, competition, and conflict among agents,\nwhich simulate interpersonal relationships and social dynamics\nfound in the real world.\nMoreover, the sociality of agents can enhance the strategic el-\nements of games through the simulation of group behaviors. For\ninstance, in team-based games, agents can allocate roles and collab-\norate based on task requirements and the abilities of team members,\nleading to more efficient task completion. This socially-driven agent\nbehavior not only increases the gameâ€™s enjoyment but also pro-\nvides players with deeper strategic thinking and decision-making\nopportunities.\n7\nCONCLUSION\nIn this paper, we described how generative agents spontaneously\nformed social relationships and explored how they modeled com-\nplex human social behavior through mutual interaction, informa-\ntion exchange, and relationship building. We introduced ITCMA-S,\nan improved generative agent architecture designed to enhance\nagent socialization in multi-agent interaction contexts. ITCMA-S\ncombines the basic framework of individual agents with the LTRHA\nframework, which supports multiple agents in social interactions.\nThis enables agents to identify and filter actions that are not con-\nducive to social interactions in dynamic environments, thus promot-\ning more socially beneficial action choices. An evaluation conducted\nin an open sandbox world environment showed that agents were\nable to actively explore the environment, meet other agents, acquire\nnew information through continuous actions and conversations,\nand spontaneously form cliques and leadership structures in com-\nplex social environments. Observations of agent behavior showed\nthat the agents were able to demonstrate positive emotional changes\nin social interactions, which enhanced their willingness to act and\ntheir social competence. This finding provides a new perspective\nfor understanding the sociality of generative agents and lays the\ngroundwork for future agent design and applications. Our future\nresearch will further explore how to optimize agentsâ€™ social behav-\nior to improve their adaptability in multicultural environments and\ninvestigate the effects on agentsâ€™ behavior of introducing social\nstructures with humans as interaction partners.\nREFERENCES\n[1] Anderson, J. R. Cognitive psychology and its implications. Worth Publishers,\n2020.\n[2] Barkur, S. K., Sitapara, P., Leuschner, S., and Schacht, S. Magenta: Metrics\nand evaluation framework for generative agents based on llms. Intelligent Human\nSystems Integration (IHSI 2024): Integrating People and Intelligent Systems 119, 119\n(2024).\n[3] Bayne, T. Conscious states and conscious creatures: Explanation in the scientific\nstudy of consciousness. Philosophical Perspectives 21 (2007), 1â€“22.\n[4] Bourdieu, P. The historical genesis of a pure aesthetic. The journal of aesthetics\nand art criticism 46 (1987), 201â€“210.\n[5] Bourdieu, P. An invitation to reflexive sociology. The Commercial Press, 2015.\n[6] Bourdieu, P. Outline of a theory of practice. China Renmin University Press,\n2017.\n[7] Bourdieu, P., and Nice, R. The production of belief: contribution to an economy\nof symbolic goods. Media, culture & society 2, 3 (1980), 261â€“293.\n[8] Bransford, J. D., Barclay, J. R., and Franks, J. J. Sentence memory: A con-\nstructive versus interpretive approach. Cognitive psychology 3, 2 (1972), 193â€“209.\n[9] Cao, L. Diaggpt: An llm-based chatbot with automatic topic management for\ntask-oriented dialogue. arXiv preprint arXiv:2308.08043 (2023).\n[10] Cheng, Y., Chen, J., Huang, Q., Xing, Z., Xu, X., and Lu, Q. Prompt sapper:\na llm-empowered production tool for building ai chains. ACM Transactions on\nSoftware Engineering and Methodology 33, 5 (2024), 1â€“24.\n\nZhang et al.\n[11] Damasio, A. Self comes to mind: Constructing the conscious brain. Vintage, 2012.\n[12] Damasio, A. Descartesâ€™ Error: Emotion, Reason and the Human Brain. Beijing\nUnited Publishing Company, 2018.\n[13] Diener, E. Subjective well-being: The science of happiness and a proposal for a\nnational index. American psychologist 55, 1 (2000), 34.\n[14] Eich, E., Macaulay, D., and Ryan, L. Mood dependent memory for events of\nthe personal past. Journal of Experimental Psychology: General 123, 2 (1994), 201.\n[15] Fauconnier, G., and Turner, M. The way we think: Conceptual blending and\nthe mindâ€™s hidden complexities. The Commercial Press, 2024.\n[16] Gao, J., Gebreegziabher, S. A., Choo, K. T. W., Li, T. J.-J., Perrault, S. T.,\nand Malone, T. W. A taxonomy for human-llm interaction modes: An initial\nexploration. In Extended Abstracts of the CHI Conference on Human Factors in\nComputing Systems (2024), pp. 1â€“11.\n[17] Ghaffarzadegan, N., Majumdar, A., Williams, R., and Hosseinichimeh, N.\nGenerative agent-based modeling: an introduction and tutorial. System Dynamics\nReview 40, 1 (2024), e1761.\n[18] Grenfell, M. Pierre Bourdieu: key concepts. Acumen Publishing, 2012.\n[19] Gross, J. J. The emerging field of emotion regulation: An integrative review.\nReview of general psychology 2, 3 (1998), 271â€“299.\n[20] Hong, W., Wang, W., Lv, Q., Xu, J., Yu, W., Ji, J., Wang, Y., Wang, Z., Dong, Y.,\nDing, M., et al. Cogagent: A visual language model for gui agents. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2024),\npp. 14281â€“14290.\n[21] HÃ¤mmerl, K., Deiseroth, B., Schramowski, P., Libovick`y, J., Fraser, A., and\nKersting, K. Do multilingual language models capture differing moral norms?\narXiv preprint arXiv:2203.09904 (2022).\n[22] Lake, B. M., and Baroni, M. Human-like systematic generalization through a\nmeta-learning neural network. Nature 623, 7985 (2023), 115â€“121.\n[23] Levine, L. J., and Burgess, S. L. Beyond general arousal: Effects of specific\nemotions on memory. Social Cognition 15, 3 (1997), 157â€“181.\n[24] Lin, B. Y., Fu, Y., Yang, K., Brahman, F., Huang, S., Bhagavatula, C., Am-\nmanabrolu, P., Choi, Y., and Ren, X. Swiftsage: A generative agent with fast\nand slow thinking for complex interactive tasks. Advances in Neural Information\nProcessing Systems 36 (2024).\n[25] Liu, N., Chen, L., Tian, X., Zou, W., Chen, K., and Cui, M. From llm to con-\nversational agent: A memory enhanced architecture with fine-tuning of large\nlanguage models. arXiv preprint arXiv:2401.02777 (2024).\n[26] Maffesoli, M. The Time of the Tribes: The Decline of Individualism in Mass\nSociety. Shanghai Peopleâ€™s Publishing House, 2022.\n[27] Maslow, A. Motivation and Personality (Third Edition). China Renmin University\nPress, 2013.\n[28] Mondal, D., Modi, S., Panda, S., Singh, R., and Rao, G. S. Kam-cot: Knowledge\naugmented multimodal chain-of-thoughts reasoning. In Proceedings of the AAAI\nConference on Artificial Intelligence (2024), vol. 38, pp. 18798â€“18806.\n[29] Motwani, S. R., Baranchuk, M., Strohmeier, M., Bolina, V., Torr, P. H.,\nHammond, L., and de Witt, C. S. Secret collusion among generative ai agents.\narXiv preprint arXiv:2402.07510 (2024).\n[30] Norberg-Schulz, C. Genius Loci: Towards a Phenomenology of Architecture.\nHuazhong University of Science and Technology Press, 2010.\n[31] Park, J. S., Oâ€™Brien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S.\nGenerative agents: Interactive simulacra of human behavior. In Proceedings of\nthe 36th annual acm symposium on user interface software and technology (2023),\npp. 1â€“22.\n[32] Ramezani, A., and Xu, Y. Knowledge of cultural moral norms in large language\nmodels. arXiv preprint arXiv:2306.01857 (2023).\n[33] Reder, L. M. Plausibility judgments versus fact retrieval: Alternative strategies\nfor sentence verification. Psychological Review 89, 3 (1982), 250.\n[34] Ren, S., Cui, Z., Song, R., Wang, Z., and Hu, S. Emergence of social norms\nin large language model-based agent societies. arXiv preprint arXiv:2403.08251\n(2024).\n[35] Shridhar, M., Yuan, X., CÃ´tÃ©, M.-A., Bisk, Y., Trischler, A., and Hausknecht,\nM. Alfworld: Aligning text and embodied environments for interactive learning.\narXiv preprint arXiv:2010.03768 (2020).\n[36] Skinner, E. A. A guide to constructs of control. Journal of personality and social\npsychology 71, 3 (1996), 549.\n[37] Toy, J., MacAdam, J., and Tabor, P. Metacognition is all you need? using\nintrospection in generative agents to improve goal-directed behavior. arXiv\npreprint arXiv:2401.10910 (2024).\n[38] Tu, Q., Fan, S., Tian, Z., and Yan, R. Charactereval: A chinese benchmark for\nrole-playing conversational agent evaluation. arXiv preprint arXiv:2401.01275\n(2024).\n[39] Vezhnevets, A. S., Agapiou, J. P., Aharon, A., Ziv, R., Matyas, J., DuÃ©Ã±ez-\nGuzmÃ¡n, E. A., Cunningham, W. A., Osindero, S., Karmon, D., and Leibo, J. Z.\nGenerative agent-based modeling with actions grounded in physical, social, or\ndigital space using concordia. arXiv preprint arXiv:2312.03664 (2023).\n[40] Wang, C., Zeng, S., and Wang, C. Large language models need consultants for\nreasoning: Becoming an expert in a complex human system through behavior\nsimulation. arXiv preprint arXiv:2403.18230 (2024).\n[41] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou,\nD., et al. Chain-of-thought prompting elicits reasoning in large language models.\nAdvances in neural information processing systems 35 (2022), 24824â€“24837.\n[42] Wu, Y., Min, S. Y., Bisk, Y., Salakhutdinov, R., Azaria, A., Li, Y., Mitchell,\nT., and Prabhumoye, S. Plan, eliminate, and trackâ€“language models are good\nteachers for embodied agents. arXiv preprint arXiv:2305.02412 (2023).\n[43] Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin,\nS., Zhou, E., et al. The rise and potential of large language model based agents:\nA survey. arXiv preprint arXiv:2309.07864 (2023).\n[44] Xue, X., Zhou, D., Yu, X., Wang, G., Li, J., Xie, X., Cui, L., and Wang, F.-Y.\nComputational experiments for complex social systems: Experiment design and\ngenerative explanation. IEEE/CAA Journal of Automatica Sinica 11, 4 (2024),\n1022â€“1038.\n[45] Yang, Z., Liu, J., Han, Y., Chen, X., Huang, Z., Fu, B., and Yu, G. Appagent:\nMultimodal agents as smartphone users. arXiv preprint arXiv:2312.13771 (2023).\n[46] Yu, C., Zang, L., Wang, J., Zhuang, C., and Gu, J. Charpoet: A chinese classical\npoetry generation system based on token-free llm. In Proceedings of the 62nd\nAnnual Meeting of the Association for Computational Linguistics (Volume 3: System\nDemonstrations) (2024), pp. 315â€“325.\n[47] Zhang, H., Duan, B., Wang, H., Qiao, Z., and Yin, J. The tribal theater model:\nSocial regulation for dynamic user adaptation in virtual interactive environments.\narXiv preprint arXiv:2403.13550 (2024).\n[48] Zhang, H., Yin, J., and Wang, H. A needs learning algorithm applied to stable\ngait generation of quadruped robot. Sensors 22, 19 (2022), 7302.\n[49] Zhang, H., Yin, J., Wang, H., and Xiang, Z. Itcma: A generative agent based on\na computational consciousness structure. arXiv preprint arXiv:2403.20097 (2024).\n[50] Zhou, S., Xu, F. F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T.,\nBisk, Y., Fried, D., et al. Webarena: A realistic web environment for building\nautonomous agents. arXiv preprint arXiv:2307.13854 (2023).\nA\nEXAMPLES OF ITCMA-S\nTime step: 51\nResource Allocation:\nEyjafjalla: 3, Pinecone: 1, Rosmontis: -1, Shamare: -3, Suzuran: 3,\nWarmy: -2\nRole: AY\nPlace: Outside\nObservation: You are in outside. Looking around you, you see\na door to AYâ€™s Home, a door to WMâ€™s Home, a door to MDâ€™s Home,\na door to Public Canteen, a door to LLâ€™s Home, a door to Public\nReading Room, a door to SGâ€™s Home, and a door to WLâ€™s Home.\nYou are holding the SGâ€™s clothes 1 in the clean damp status. You\nare moving.\nDriver: 2.1855582074431115\nEmotion: [0.99981828 0.73634471 0. ]\nThought: after chatting with MD, i found myself standing in\na familiar courtyard surrounded by various doors leading to the\nhomes and communal spaces of my friends. i still held SGâ€™s clean\ndamp clothes in my hands, considering my next move. the courtyard\noffered numerous options: i could visit AY, WM, the public canteen,\nLL, the public reading room, or WL. however, my objective was\nclear, and i decided to step outside in search of SG herself. the mild\nbreeze felt refreshing as i exited into the broader community area,\nwhere i began to weigh my options on where to head next to deliver\nthe clothes to SG.\nAction: go to SGâ€™s Home\nRole: SG\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named LL who is moving, a person named\n\nCan Agents Spontaneously Form a Society?\nWM who is moving, a door to outside, the table 13, the table 14,\nthe table 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AYâ€™s clothes\n1 placed on the storagebin 12. You are holding the book 10, the 10\ndollar. You are moving.\nDriver: 1.9051621422278182\nEmotion: [0.99981828 0.62810367 0. ]\nThought: after discussing with WM about inspecting a $10\nbill, the atmosphere was filled with curiosity and determination.\nrealizing the importance of careful examination, you decided to\ninitiate the thorough scrutiny of the bill. \"sure thing, LL! iâ€™ve got\nthe $10 bill here. letâ€™s start by examining it closely under the light at\ntable 16 to see if we can spot any hidden details or unusual features.\nWM, can you grab a magnifying glass while youâ€™re moving around?\nit could make our examination much easier. iâ€™ll begin inspecting\nthe bill right now.\" having conveyed this, you felt the anticipation\nof discovering something hidden within the seemingly ordinary\nbill.\nAction: chat with WM: \"WM, you managed to find that mag-\nnifying glass yet? letâ€™s get to examining this bill closely under the\nlight on table 16. iâ€™ll put the $10 bill there for us to scrutinize.\"\nRole: MD\nPlace: WLâ€™s Home\nObservation: You are in WLâ€™s Home. Looking around you, you\nsee a person named AY who is moving, a door to outside, the table\n5, the table 6, the chair 9, the chair 10, the bed 4, the bookshelf 4,\nthe bookshelf 5, the bookshelf 6, the storagebin 4, the storagebin\n5, the wardrobe 5, the nightstand 3, the nightstand 4, the food 9\nplaced on the storagebin 5, the toy 1 placed on the table 6, the toy\n2 placed on the nightstand 3, the book 4 placed on the bookshelf\n4, the book 5 placed on the bookshelf 5, the book 6 placed on the\nbookshelf 6, the beverage 2 placed on the storagebin 4, and the MDâ€™\nclothes 1 placed on the wardrobe 5. You are moving.\nDriver: 1.617758309962011\nEmotion: [0.99865135 0.55465888 0. ]\nThought: after leaving LLâ€™s home, surrounded by an array of\ndoors leading to various homes and public rooms, i found myself\nholding a toy 1. the bustling options around me seemed overwhelm-\ning: AYâ€™s home, WMâ€™s home, MDâ€™s Home, the public canteen, LLâ€™s\nhome, the public reading room, SGâ€™s home, and WLâ€™s home. each\nplace offered its own allure and potential for new encounters. i pon-\ndered my next move. recognizing the vibrant, diverse community\naround me, i decided that my best course of action would be to\ndetermine the purpose of this toy and possibly deliver it to someone\nwho might appreciate it. it seemed that WLâ€™s Home might be an\nideal place to begin. with that thought, i headed towards the door\nto WLâ€™s Home, ready to embark on the next part of my journey.\nAction: (This action has been filtered by LTRHA) take toy 1\nfrom table 6\nRole: WL\nPlace: LLâ€™s Home\nObservation: You are in LLâ€™s Home. Looking around you, you\nsee a door to outside, the table 2, the table 3, the chair 2, the chair\n3, the chair 4, the chair 5, the chair 6, the chair 7, the bed 2, the\nbookshelf 1, the bookshelf 2, the bookshelf 3, the countertop 1, the\nfoodshelf 2, the sinkbasin 1, the storagebin 1, the storagebin 2, the\nstoveburner 1, the wardrobe 2, the wardrobe 3, the nightstand 1,\nthe nightstand 2, the toy 3 placed on the chair 7 in the clean damp\nstatus, the book 1 placed on the bookshelf 1, the book 2 placed on\nthe bookshelf 2, the book 3 placed on the table 2, the LLâ€™s clothes\n1 placed on the chair 7, the LLâ€™s clothes 2 placed on the chair 7,\nand the WLâ€™s clothes 1 placed on the chair 4. You are holding the\nbeefsteak, the food 12.\nDriver: 1.5471459038728095\nEmotion: [0.99865135 0.754853 0. ]\nThought: after taking the beefsteak from table 2, i quickly sur-\nveyed my surroundings. i noticed MD comfortably sitting on chair\n7, seemingly engrossed in her own world. the room was a medley\nof objects: various chairs, multiple tables including table 3, a toy,\nLLâ€™s clothes, and multiple wardrobes. there were also bookshelves\nwith books neatly arranged, a sink basin, several storage bins, a\nstove burner, a foodshelf stocked with food, and notably, a clean,\ndamp chair 7. beyond the indoor amenities, a door led outside to\nthe broader world.\nAction: take book 1 from bookshelf 1\nRole: LL\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named WM who is moving, a person named\nSG who is moving, a door to outside, the table 13, the table 14, the\ntable 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AYâ€™s clothes 1\nplaced on the storagebin 12. You are holding the 1 gold coin. You\nare moving.\nDriver: 1.4754809897359225\nEmotion: [0.99981828 0.8106327 0. ]\nThought: after our intensive discussion with SG, where we\nstrategized examining the $10 bill and scouring the room for any\nhidden clues, i couldnâ€™t shake off the feeling that we were on the\n\nZhang et al.\nbrink of a significant discovery. as i diligently began checking book\n10 on bookshelf 10, the room buzzed with activity. SG carefully\nscrutinized the markings on the $10 bill while WM meticulously\nsearched the shelves for anything out of the ordinary. the room\nwas filled with various tables, chairs, bookshelves, and storage\nbins, each housing an array of items that could potentially be part\nof the puzzle. a gold coin glinted atop storagebin 11, and several\nbooks lined the bookshelves, just waiting to reveal their secrets.\nthe tantalizing aroma of food on several storage bins hinted at\nrefreshments, but my focus remained unwavering. sipping on a\nbeverage i grabbed from storagebin 12, i took a moment to rally the\nteam.\"hey SG, WM! based on our previous finds, i believe thereâ€™s\nstill a lot here to uncover. SG, you mentioned something about\nthe $10 billâ€”did you find any hidden messages or markings? and\nWM, any unusual items on the shelves? this room is packed with\npotential clues. letâ€™s aim to maximize our findings. oh, and by the\nway, anyone up for a quick break? weâ€™ve got some beverages here.\nletâ€™s keep the energy up and the minds sharp!\"\nAction: chat with SG: \"SG, WM, i think weâ€™re really onto some-\nthing here. SG, how did your examination of the $10 bill go? any\nhidden messages or unique markings? WM, what have you found\non the shelves? we need to pool all the information we have to\nmake sense of these clues.also, it might be a good idea to take a\nshort break and recharge. weâ€™ve got some beverages here; feel free\nto grab one. letâ€™s keep our energy up and stay focused. remember,\nevery small detail could be critical in solving this mystery!\"\nRole: WM\nPlace: Public Reading Room\nObservation: You are in Public Reading Room. Looking around\nyou, you see a person named LL who is moving, a person named\nSG who is moving, a door to outside, the table 13, the table 14, the\ntable 15, the table 16, the table 17, the table 18, the chair 22, the\nchair 23, the chair 24, the chair 25, the chair 26, the chair 27, the\nbookshelf 9, the bookshelf 10, the bookshelf 11, the bookshelf 12, the\nbookshelf 13, the bookshelf 14, the bookshelf 15, the bookshelf 16,\nthe storagebin 8, the storagebin 9, the storagebin 10, the storagebin\n11, the storagebin 12, the storagebin 13, the book 12 placed on the\nbookshelf 12, the book 13 placed on the bookshelf 13, the book 14\nplaced on the bookshelf 14, the book 15 placed on the bookshelf\n15, the book 16 placed on the bookshelf 16, the beverage 3 placed\non the storagebin 9, the beverage 4 placed on the storagebin 10,\nthe beverage 5 placed on the storagebin 12, and the AYâ€™s clothes 1\nplaced on the storagebin 12. You are holding the book 11. You are\nmoving.\nDriver: 1.5037198800782485\nEmotion: [0.99981828 0.80477086 0. ]\nThought: after picking up book 11 from chair 23, i found myself\nin the midst of an elegant room, where SG stood nearby, her calm\npresence adding to the serene atmosphere. as i looked around, it\nseemed that i was now unburdened, holding nothing in my hands.\nrealizing that my intended action of placing book 11 on table 13\nwas incongruent with my surroundings and perhaps my immediate\nobjectives, i paused to reconsider my next move. SGâ€™s eyes met\nmine, as if questioning my sudden stillness amidst her warm and\ninviting space.\nAction: (This action has been filtered by LTRHA) take book 12\nfrom bookshelf 12",
    "pdf_filename": "Can_Agents_Spontaneously_Form_a_Society_Introducing_a_Novel_Architecture_for_Generative_Multi-Agents.pdf"
}