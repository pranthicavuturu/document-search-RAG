{
    "title": "Grading and Anomaly Detection for Automated Retinal Image",
    "abstract": "The significant portion of diabetic patients was affected due to major blindness caused by Diabetic retinopathy (DR). For diabetic retinopathy, lesion segmentation, and detection the comprehensive examination is delved into the deep learning techniques application. The study conducted a systematic literature review using the PRISMA analysis and 62 articles has been investigated in the research. By including CNN-based models for DR grading, and feature fusion several deep-learning methodologies are explored during the study. For enhancing effectiveness in classification accuracy and robustness the data augmentation and ensemble learning strategies are scrutinized. By demonstrating the superior performance compared to individual models the efficacy of ensemble learning methods is investigated. The potential ensemble approaches in DR diagnosis are shown by the integration of multiple pre-trained networks with custom classifiers that yield high specificity. The diverse deep-learning techniques that are employed for detecting DR lesions are discussed within the diabetic retinopathy lesions segmentation and detection section. By emphasizing the requirement for continued research and integration into clinical practice deep learning shows promise for personalized healthcare and early detection of diabetics.",
    "body": "Grading and Anomaly Detection for Automated Retinal Image\nAnalysis using Deep Learning\nSyed Mohd Faisal Malik 1 , Md Tabrez Nafis 2* , Mohd Abdul Ahad 3,\nSafdar Tanweer 4\n1Ph.D Research Scholar, Jamia Hamdard,India\n2,3,4Associate Professor,Jamia Hamdard,India\nCorresponding author: email: Tabrez.nafis@gmail.com\nEmails of Coauthors:\n1Fslmalik9@gmail.com;3itsmeahad@gmail.com;4safdartanweer@yahoo.com\nAbstract\nThe significant portion of diabetic patients was affected due to major blindness caused by Diabetic retinopathy\n(DR). For diabetic retinopathy, lesion segmentation, and detection the comprehensive examination is delved\ninto the deep learning techniques application. The study conducted a systematic literature review using the\nPRISMA analysis and 62 articles has been investigated in the research. By including CNN-based models for\nDR grading, and feature fusion several deep-learning methodologies are explored during the study. For\nenhancing effectiveness in classification accuracy and robustness the data augmentation and ensemble learning\nstrategies are scrutinized. By demonstrating the superior performance compared to individual models the\nefficacy of ensemble learning methods is investigated. The potential ensemble approaches in DR diagnosis are\nshown by the integration of multiple pre-trained networks with custom classifiers that yield high specificity.\nThe diverse deep-learning techniques that are employed for detecting DR lesions are discussed within the\ndiabetic retinopathy lesions segmentation and detection section. By emphasizing the requirement for continued\nresearch and integration into clinical practice deep learning shows promise for personalized healthcare and\nearly detection of diabetics.\nKeywords: Diabetic retinopathy, segmentation, images on retinal fundus, convolutional neural network\n1. Introduction\n\"Diabetic Retinopathy (DR)\" is specified through progressive vascular disruptions in the retina. This\ndisruption is developed by the patient with diabetes and is created by chronic hyperglycaemia based on its\nseverity. Among the adults’ work nature, has been considered the major cause of blindness worldwide. Among\ndiabetic patients, the study proved that globally, there are almost 27% of the people have DR [1]. It is expected\nthat these numbers can be increased more due to the elevating pervasiveness of diabetics in Asian countries\nlike China and India [2]. In the primary stages, although DR is totally asymptomatic. During these primary\nstages, clinically invisible microvascular transformation and neural retinal damage progress strongly[3]. Timely\nsolutions and managing of disease in an efficient way was achieved by proceeding with regular eye screening\n[4]. Furthermore, to avoid this problem, the only way is to control hypertension, hyperlipidaemia, and\nhyperglycaemia, and DR's early detection has become necessary [3]. Regarding its treatment recently, there\nhave been several available interventions, including laser photocoagulation. Suppose at the disease's primary\nstage the eyes are checked. In that case, this intervention remarkably decreases the blindness chances in\ndiabetic maculopathy and proliferative retinopathy to 98% [5]. Finally, it has been proved that from diabetic\nretinopathy, blindness prevention is possible through appropriate treatment and early detection[6].\nDR's initial diagnosis depends on functional transformation in \"retinal blood vessel caliber\", \"retinal\nblood flow\", and \"electroretinography (ERG)\"[7]. Early diagnosis relies on fundus evaluation in clinical\npractice [8]. Kwan and Fawzi[9], highlighted that fundus photography is considered a widely available, well-\ntolerated, non-invasive, and rapid imaging technique. It comprises a major applied technique to analyse the\nDR's extension. To identify DR and to predicate effects Ophthalmologists observe the lesions of the retina by\napplying fundus images at high resolution. In Highly populated countries like India and Africa, people residing\nin rural area need of images diagnosing DR manually demands a strong effort and expertise level by a\nprofessional ophthalmologist. In these countries, identification of diabetic problem, the number of individuals\nhaving DR and diabetes will enhanced dramatically, and there will be a disproportionately low number of\nophthalmologists[10]. The research community is motivated by this contradiction and decided to introduce\ncomputer-aided diagnosis that assists in reducing effort, time and cost required by an expert medical technician\nto detect DR. Apart from that, computational capabilities and resources enhancement and recent shifts in\n\"Artificial Intelligence (AI)\" have created a scope to launch applications integrated with “Deep Learning (DL)\"\nassociated with appropriate identification and types of DR. During previous few years, certain articles have\nbeen published that discussed on the methods of DL and its impact on DR[11–15]. Maximum articles emphasized\nthe particular perspectives of the modelling pipeline and data analysis.\nIn some cases, it is restricted to the model's performance reporting to the pre-processing techniques\nthat are commonly used[13,14]. The researcher indicated data sets that are publicly available, but complete\ndescription of information was not available. Therefore, a more integrated and detailed method has been\nimplemented for these fragmented efforts to evaluate application area of the study integrated with technical\ndata was considered for evaluation. The study shows a complete viewpoint regarding “analysis pipeline\".\nFurthermore, besides illustrating comparative technical data was available in the internet regarding DL models'\ndevelopment for the segmentation and classification images related to fundus, the study additionally focused\non discussing publicly available data sets' thorough analysis, the commonly applied pre-processing pipelines,\nand in the real setting of the clinic, as a models' presentation these have been used.\n2. Methodology\nThe proposed review article significantly follows the significant principles of systematic literature\nreview concerning the PRISMA guidelines. The PRISMA guidelines exploring the process of identifying the\narticles, screening of suitable documents, eligibility and inclusion of opted documents. The study successfully\nconducted systematic review through the Scopus data base, and the articles are mainly published in “IEEE,\nWiley, Springer, Hindawi, MDPI, and Science direct”. The documents are collected over based on basic\nbuilding blocks of words “Deep Learning and Diabetic Retinopathy”. The investigation results stating that\nover 38.8% full-text research articles, 47.3% of conference papers, 5.6% of conference review articles, and the\nrest of publications are from other categories (book chapters, review article, editorial, books, note, retracted,\nand erratum).\nFigure 1: Documents published over 2017 to 2024 in Scopus\nFigure 2: Documents classification over 2017 to 2024 in Scopus\nFigure 3: PRISMA framework\nThe PRISMA model of the current systematic literature review was predicated by using the diagram3.\nThe PRISMA follows “identification, screening, eligibility, and inclusion”. In the identification criteria, the\noverall records identified from the database is 1628 documents, from the 1628 documents, 125 records have\nbeen removed concerning the duplicates and 1503 articles has been processed into the screening section. In\nthe screening of records, 1503 articles have been included, from the documents, 920 articles have been\nexcluded concerning the book chapters, book series, conference reports, and erratum. In the eligibility criteria,\nthe overall studies processed are 583 documents, and 521 articles have been excluded concerning the full-text\narticles and insufficient criteria. And finally, the review included 62 documents relating towards the cloud\nbroker in the present research.\n3. Diabetic Retinopathy\nMicroaneurysms have been noticed on the retina during diabetic retinopathy's primary stages and result\nfrom loss of pericytes and degeneration that create capillary wall dilatation. Intraretinal hemorrhages occur\nwhen the microaneurysm's or capillary's wall is ruptured. There are some other lesions of \"non-proliferative\ndiabetic retinopathy\" like reduplication or venous loops, venous beading, \"intraretinal microvascular\nabnormalities (IRMA)\", and hard and soft exudates[16]. Tsiknakis[17] reported that huge \"caliber tortuous\nvessels\", IRMAs appear based on ischemia parts and indicate attempted vascular remodelling. Moreover, on\nthe neovascularization's presence, the difference between non-proliferative and proliferative therapy based on\ndetection of DR is dependent and significantly indicates the new retina vessel growth because of ischemia to\nprevious ones.\nFigure 4: Diabetic Retinopathy Lesions[17]\n\"Diabetic macular edema (DME)\"disease can be identified at any stage was stated[18]. It is contemplated\nas an endpoint for blindness. Apart from that, through abnormalities including the haemorrhages or\nmicroaneurysms of the retina within the fovea center's one-disc diameter, thickening of the retina within the\nfovea center's one-disc diameter, exudates within the \"macula\" and exudates within fovea center's one-disc\ndiameter[19]. Regarding the DR's clinical grading protocols, \"Early Treatment Diabetic Retinopathy Study\n(ETDRS) grading scheme\" considered one of best method[20]. Basically, this gold standard's application in\nclinical practice regularly is not to be practical or easy. In an effort, many substitute scales have been\nintroduced to develop communication among caregivers and screening of patients. In several countries, the\ndevelopment of these scales to evaluate the effectiveness of DR so far not caused “single international severity\nscale\". Finally, “International Clinical Diabetic Retinopathy Disease Severity Scale\" has been developed by\n“Global Diabetic Retinopathy Project Group\"[21].\n3.1 Traditional Approaches\nThe program of DR screening was developed for the first time in the \"1980s and early 1990s\"[22]. This\nprogram minimized the DR-associated vision loss cases successfully at that time. Hristova[23] conducted a\nreview on diabetic retinopathy and indicated that through the teams of mobile fundus photography, early DR\ndetection was initiated in Sweden to reduce the vision loss cases due to DR by almost 47 % every year was\nestimated with in the period of 5 years in 1990. Recently, some criteria have been provided by the\n\"International Council of Ophthalmology (ICO)\" initiates the screening DR that includes test of the retina\nwith fundus images consisting of mydriatic fundus images or non mydriatic fundus images with \"≥ 30° mono-\nor stereo photography\" or indirect or direct ophthalmoscopy[24]. The grading of fundus images is necessary to\nmeasure the DR's severity level. To an ophthalmologist, these fundus images' careful manual grading can be\nsubjective, time-consuming, and labor-intensive. In evaluating the fundus images of DR, an automated\nalgorithm has a critical role. However, the algorithms that are previously applied are basically dependent on\nthe traditional methods. These traditional techniques were involved with selecting the features of engineering\nimages manually for some classifier techniques like random forest and support vector machine[25]. For Diabetic\nRetinopathy treatment artificial neural network (ANN) was proposed [26]. This technique has the power to\ngrade DR automatically with 83% specificity and 88% sensitivity compared to an ophthalmologist.\nFurthermore, DL is regarded as a branch of AI that concentrates on learning task-specific features of DR\nimages with different images without calculating the selection of manual features. Hence, in different DR\nissues a \"convolutional neural network (CNN)\" is considered as a major solution[27]. For the DR's automatic\ndiagnosis, the application of CNN has provided improved performance.\n3.2 Manual Grading by DR\nDR-related primary care involves patients' vigilant follow-up for earlier and better treatment, screening\nof patient retina's high-quality photograph, and timely ophthalmic examination. Some common techniques,\nincluding \"monochromatic photography technique\" or \"nonmydriatic or mydriatic digital color\", \"stereoscopic\ncolor film fundus photography\", and \"direct and indirect ophthalmoscopy\" have been applied to classify and\ndetect DR. For the classification and detection of DR, the popular gold standard technique is \"stereoscopic\ncolor fundus photographs in 7 standard fields (300)\". According to the group \"Early Treatment DR Study\n(ETDRS)\", this technique is recommended[20]. Through this method, \"subtle retinal neovascularization\" and\n\"diabetic macular edema (DME)\" have been identified accurately[28]. Moreover, this technique is more\nreproducible and accurate. Still it requires a huge skilled healthcare infrastructure like equipment of good\nphotography processing, photograph readers, and photographers.\n4. Deep Learning Techniques\n\"Deep Learning (DL)\" is considered part of the methods of AI, and it relies on unnatural neural\nnetworks and is inspired by the human brain structure. DL primarily indicates mathematical representation and\nmethods of learning the intrinsic and latent connections of the information automatically. Deep learning, unlike\nconventional machine learning techniques, needs less guidance from humans as they are not dependent on\nhand-crafted features. This hand-crafted task is very time-consuming and laborious. Whereas the scale of DL\nmethods is much better compared to conventional methods of ML as the quantity of information is enhanced.\nThis section has presented a brief overview of the concept of DL[29].\nFigure 5: Diabetic Retinopathy using technique of Deep Learning[29]\nIn DR classification and detection, DL has been applied globally in recent years. This deep learning\nhas several heterogeneous sources incorporated can learn appropriately the characteristics of input data [30].\nSome common DL-based techniques like sparse coding, auto encoder, \"convolutional neural networks\n(CNNs)\", and restricted Boltzmann Machines[31]. When the training data's number increases, these methods'\nperformance also increases because of the learned features' enhancement unlike the methods of machine\nlearning [32]. In contrast, the extraction of hand-crafted features is unnecessary for DL. In the analysis of\nmedical images, CNNs are more applied methods compared to others[33].Three major basic layer included in\nthe architecture of CNN: \"fully connected layers (FC)\", convolution layers (CONV) and Pooling\nlayers.Size,layers and CNN filters are varied according to the perspective of authors. In CNN architecture,\neach layer has an influential role. Different filters included in “CONV layers\" impact picture to take out the\ncharacteristics. Whereas, to reduce the feature maps' dimensions, typically layer of CONV followed by the\npooling layer. For pooling, there are several ways but max pooling and average pooling are mostly applied [31].\nTo explain the entire input image, the FC layers are perfect. However, the most applied function of\nclassification is the SoftMax activation function. Apart from that, there are various pre-trained architectures of\nCNN on the dataset of ImageNet like He[34] suggested ResNet, Szegedy[35] indicated Inception-v3 and\nKrizhevsky[36] presented AlexNet.The emphasized transfer learning, and the authors explored that these pre-\ntrained architectures' transfer learning assists in speeding up the training, whereas for classification, other\nstudies from scratch generate their own CNN[37,38]. Finally, the pre-trained models' transfer learning strategies\ninclude training the pre-trained model's all layers or finetuning multiple layers and finetuning the last \"FC\nlayer\".\n4.1 Diabetic Retinopathy Retina Dataset\nFor the retina, many datasets are publicly available to vessels and DR detection. Furthermore, to test,\nvalidate, and train the systems these datasets are applied frequently. Apart from that, it also helps in comparing\nthe performance of the system against other systems. Abràmoff[39] proposed two classification of \"retinal\nimaging\", such as \"optical coherence tomography (OCT)\" added with “fundus color images\". OCT images\nrefer to retinas' \"2 and 3-dimensional images\" considered by applying low-coherence light. These images\ndeliver critical information regarding retina structure and thickness. In contradiction, fundus images indicate\nretinas' \"2-dimensional images\" that have been collected by applying reflected light. A few years ago, \"OCT\nretinal images\" were launched. Moreover, some diversity has been observed in the data sets of fundus images\nthat are publicly available and commonly applied. The datasets of fundus image are:\nTable 1: Classification of Dataset\nS.No Dataset Description\nWith various resolutions, it holds Eighty eight thousand seven hundered and two\n\"high-resolution images\" that range starts \"433*289 pixels to 5184*3456 pixels”,\ncaptured using different type of photo capturing devices. Information on Training\n1 Kaggle\nof images was available as open book accessible by all people. The five stages of\nDR, all images are divided. The collection of data includes storage of several images\nwith incorrect labelling and poor quality[37,40,41].\nThis dataset contains 89 retinal fundus images that are publicly available with\n\"1500*1152 pixels\" captured with \"50-degree field of view (FOV)\". Besides that,\n2 DIARETDB1\nthis contains five normal pictures and 84 images of DR illustrated using four skilled\npersonnel in the medical field[42].\nIt stores 13,673 fundus images that are presented to the five stages of DR and\n3 DDR captured at a \"45-degree FOV\". From this dataset, 757 images are annotated to the\nlesions of DR[37].\nIt is one of the popular publicly available datasets that consists of mainly two types\nsuch as E-ophtha EX and E-ophtha MA. However, 35 normal images are included\n4 E-ophtha\nin E-optha and 47 EX-related images.Additionally, E-ophtha MA focused on\ncontaining 233 normal images and 148 MA- associated images[43].\nThe dataset also provide images related to blood vessels based on segmentation. It\n5 HRF stores 45 images with \"3504*2336 pixels\". Additionally, there are 15 glaucomatous\nimages, 15 healthy images, and 15 DR images[44]\nIt consists of 1200 fundus images that are colored and illustrated to the four stages\n6 Messidor\nof DR. The images were captured at a \"45-degree FOV\"[45].\nDataset was applied for the segmentation based on blood vessels. This stores 40\nimages with \"565*584 pixels\" and is captured at a \"45-degree FOV\". Out of these\n7 DRIVE\n40 images, seven images are classified as mild DR and the rest are classified as\nnormal[46].\n8 Messidor-2 It includes 1748 pictures captured with “45-degree FOV\"[47].\nQuellec[48] suggested the DIARETDB1 datasets for detecting the lesions of DR. Similarly, Orlando[49]\nidentified red lesions, E-ophtha and DIARETDB1 applied, whereas Chudzik[50] to detect MA; applied these\ndatasets. Before using the datasets for the techniques of DL, maximum studies processed these datasets\nproperly.\n4.2 Image Pre-processing of DR\nFrom images to removing the sound, image pre-processing is a very important part. The consistency\nof the image was ensured to increase the feature of the image[51]. In this section, the researchers have discussed\nthe most popular pre-processing methods. Several scholars set the size of the captured images with specific\nresolution that will appropriate suits for network applied[48,52]. To remove the images' extra spaces, cropped\nimages were used, the pre-processing of test images are shown in the figure 6.\nFigure 6: Pre-processing of test images[51]\nIn contrast, for image normalization in the same distribution, the normalization of data was applied[53].\nThe methods of noise removal are \"NonLocal Means Denoising methods\", Gaussian filter, and median\nfilter[49,51,53]. When some classes of image were imbalanced or to enhance the size of the dataset, data\nargumentation methods were followed[53]. Moreover, these data argumentation techniques are rescaling,\ncontrast scaling, flipping, shearing, rotation, and translation. For contrast enhancement, a morphological\ntechnique was applied[50]. For feature extraction, Adem[54] applied the canny edge technique. The images are\nprepared after pre-processing them to be applied as a DL's input.\n5. Diabetic Retinopathy Classification\nDR was categorised as two types such as identification of DR and captured screenshot related to fundus\ncaused in retina.\n5.1 Grading Scale\nBy using different classification systems, the experiments regarding diabetic retinopathy (DR) grading\nare conducted during the research carried [40]. Under 2-class categorising classification, the disease presence is\nidentified. Under 3-class classification indicates not identified DR, mild DR, and severe DR. whereas under\n4-class classification various types encountered are DR with severe,DR with moderated with mild and no\noccurrence of DR. As the presence of at least moderate non-proliferative diabetic retinopathy lesions the\nreferable DR is defined. As the presence of at least proliferative diabetic retinopathy (PDR) lesions the vision-\nthreatening DR is identified. Researchers capture similar clinical manifestations across various traditional\nscaling protocols the 4-class scale is introduced [55]. Additionally researchers conducted a study among\ndiseased and healthy individuals to distinguish the development of a binary classification model[12].\nFurthermore researchers conducted a study, for classifying the images that are ungradable is used as an\nadditional class[37].\n5.2 Performance Evaluation Metrics\nBy using a confusion matrix, the binary classification model performance is illustrated. Each entry in\nmatrix are calculated based on the actual predication of the model. From these metrics, there are several\nspecialized evaluation measures like Cohen’s Kappa, Sensitivity, Accuracy, F1 Score, and Specificity\nemerged. According to curve based on receiver operating characteristic, the sensitivity of plotting against\nspecificity across several threshold settings for classification outcome. Lastly, by measuring the area under the\nROC curve the overall classifier performance is quantified by the Area Under the Curve (AUC). Across all\nclassification thresholds, a comprehensive performance assessment is provided by ensuring this curve.\n5.3 Binary Screening\nXu [52] noticed that by using CNN the Kaggle dataset is automatically classified into the normal images.\nFrom the dataset, nearly 1000 images can be used and before feeding pictures to CNN the augmented data and\nsize changed to 224*224*3 performed. Based on applying different type of transformations like translation,\nflipping augmented data and rescaling is used in increase dataset images. Layers based on 4-max pooling,\nCONV layers splitted with 8 major classification, and FC layers with 2 classification are included within the\narchitecture of CNN. For segregation, the function SoftMax is used at the CNN last layer with a value of 94.5%\nof accuracy. Based on another research conducted[48] it is noticed that by using three CNNs the pictures were\ncategorised as referable DR which indicates at moderate stage with least value, or non-referable DR which\nindicates mild stage or no DR.\nFigure 7: DCNN architecture [52]\nFrom three datasets the images are sourced and they are identified as Kaggel, private E- ophtha, and\nDiaretDB1. The size of the images are changed, normalized, and minimised to pixel of 448*448. during\npreprocessing stage. Additionally, the augmented data is generated and the Gaussian filter is applied. The\ntrained AlexNet is included within the employed CNN architectures and from solution the two networks are\nemployed.microaneurysms, hard exudates,hemorrhages and soft excludates are considered as well trained\nCNN dataset for detection. In ROC curve, an area 0.954 is achieved considered for Kaggle and 0.949 is\nachieved for datasets uses E-ophtha. According to another study conducted[56], for detecting the DR images\nand red lesions using 65*65 augmented patches the models of CNN were developed. By using one FC layer,\nfive layers of CONV, and layers with five max-pooling are pretrained VGG16 is utilized. With the help of the\nDIARETDB1 dataset, these models were trained and for classifying patches into red lesions these models were\ntested on DDR, Kaggle, and Messidor. Subsequently, as non DR or DR images were categorised based on the\nmap of test images with lesion probability. The AUC of 0.912 and the sensitivity of 0.94 is achieved for the\nMessidor dataset. However, it is not required to consider all the five stages of DR that causes crucial for\npreventing progression to blindness and determining appropriate treatment.\n5.4 Multi-Level Classification of DR\nAccording to another study conducted by Ayala[29], CNN method was used to detect retinopathy based\non diabetic and macular edema based on diabetic. For model testing the Eyepacs-1 dataset and Messidor-2\nwere utilized by CNN-based method. The images underwent normalization to the width of 299 pixels and by\nusing pretrained inception-v3 ten CNNs were effectively trained. By linear averaging functions, the final\nresults are computed. The categories like moderate or worse DR, full gradable, referable diabetic macular\nedema, and severe or worse DR are included under the image classification. In both datasets and sensitives, a\nspecificity of 93% is achieved. For Messidor-2 96.1 % is achieved and for Eyepacs-1 datasets 97.5% is\nachieved respectively.\nHowever, is noticed that the five stages of DR and non-DR images were not explicitly detected. By\ncomprising 1748 images the data augmentation is applied to the dataset based on Messidor-2. For detecting\nboth normal retina anatomy and lesions DR the multiple CNNs are integrated with the usage of Random Forest\nClassifier. The vision-threatening DR, no DR, and referable DR are included as a few of the categories under\nthe classification of images. According to the report, under the 0.980 curve, a specificity of 87.0%, and a\nsensitivity of 96.8%. Unfortunately, as no DR the images of mild DR stage are categorized and even five DR\nstages are not considered. Where another study proposed that from the Kaggle dataset, the images are classified\nby using CNN-based methods into five DR stages[28]. For 512*512 pixels the images are resized and the color\nnormalization is performed during the preprocessing. The three fully connected layers, 10 convolutional layers,\nand the eight max-pooling layers are comprised under the custom CNN architecture. As a classifier for 80,000\ntest images the function of SoftMax is served. Within CNN the dropout methods and the L2 regularization are\nemployed for controlling the overfitting. An accuracy of 75%, specificity of 95%, and sensitivity of 30% are\nexhibited by the obtained results.\n6. Related Studies on Deep Learning Approaches\nDuring the study performed one of the pioneering studies was conducted to utilize a CNN-based model\nfor mirroring the clinical grading protocol and five-class classification of diabetic retinopathy (DR). A class-\nweighted strategy is used by the author for mitigating the overfitting and updating parameters during the back\npropagation for every batch. For enhancing the proliferative diabetic retinopathy and non-proliferative diabetic\nretinopathy prediction the five-class classification problem is approached by converting it into a regression\ntask. The model performance can be boosted and the CNN feature vectors from each eye are amalgamated by\nthe devised blending network. Similarly, a CNN model was developed[57] to analyse images from eyes and for\nclassification fuse their representation. For maintaining the receptive field as possible to the original image\nsize the CNN models are advocated to use network architecture adaptations and smaller convolutions.\nBased on another study conducted by employing smaller filters in Conv2D layers especially detecting\nsmaller lesions like microaneurysms the improved DR classification performance were identified[58]. For\ncapturing lesion marks of varying sizes and capturing features at different resolutions the inception modules\nwere employed in several studies. Whereas, how the algorithm training performance is impacted by the\nadjudication grading system is investigated by another author. When compared to majority voting by noting\nslight performance enhancement and using the adjudication grading protocol the pre-trained model is fine-\ntuned on the small labelled dataset.\nFor enhancing the detection performance the attention modules are integrated into CNNs. For\nenhancing classification performance on subtle regions the bilinear strategy and attention mechanism are\nemployed by another author. The high attention regions for boosting classification accuracy are focused by\naiding Crop-network and the attention maps are generated by using the attention mechanisms. Based on the\nauthor[37] exploring inter-disease correlations and detecting diabetic retinopathy a novel architecture\nincorporating attention modules is incorporated. The original fundus image for DR severity classification is\ncomplemented and for lesion detection, the deep learning pipeline is devised[59]. For mitigating missing lesion\nannotation impact the lesion clustering method is employed during the detection phase. By attention fusion\nnetwork the detection model from lesion maps is fused with feature maps of the classification model. For\nimproving the lesion segmentation performance using image-level annotated data the attention mechanism is\nincorporated by introducing a collaborative weakly-supervised learning model[60].\n7. Ensemble Learning Approaches\nFor disease grading one ensemble model and for disease identification, another ensemble model is\ndevised[55]. The multiple pre-trained networks are integrated by these models for feature extraction and serve\nas a classifier by coupling with customer standard dense neural network. The individual ones in both tasks are\nsurpassed by ensembling these models and achieving 98.56% specificity and 98.10% sensitivity. With the\nstrength of the base learner, the performance tends to increase and in certain cases, it is identified that the dual\nensemble outperforms a single ensemble. Based on inception V3, Inception-Resnet-V2 architecture, and\nResNet152 the Adaboost classifier is employed on three models by crafting an ensemble model. The ensemble\nmodel is effectively trained on a private dataset that is developed in the collaboration with Adaboost\nclassifier[61]. By achieving 88.21% accuracy, 85.57% sensitivity, and AUC 0.946 the individual models are\noutperformed by the ensemble model. The superior specificity at 91.46% is exhibited notably by the\nInceptionV3. During the training process, the multiple iterations are exported by ensuring the training CNN\nmodel. At different training iterations, every distinct lesion type is detected optimally. By using ensemble\nlearning these saved models are combined subsequently and help in predicting the diabetic retinopathy severity\nscore.\n8. Diabetic Retinopathy Lesions Segmentation and Detection\nFor classifying and detecting certain types of diabetic retinopathy lesions there are several approaches\nare outlined within this section. The red lesions in DR images are detected exclusively by utilizing deep\nlearning methods alongside domain knowledge for feature learning[49]. After processing the images from\nDIARETDB1, MESSIDOR, and E-ophtha the Random Forest method for classification is employed. By\napplying the r-polynomial transformation, and employing multiple morphological closing functions the field\nof view is expanded by involving green band extraction. For convolutional neural network training the red\nlesion patches are augmented and resized to 32*32 pixels. The 89, 381, and 1200 images are comprised of the\nDIARETD, MESSIDOR datasets, and E-ophtha. By achieving competition metric scores of 0.4874 and 0.3683\nthe four convolutional layers, one fully connected layer, and four convolutional layers are considered within\nthe custom CNN architecture.\nFor detecting the microaneurysms from DR images the custom CNN architecture and from E-\nophths(381 images), DIARETDB1(89 images) and ROC (100 images) the datasets are utilized. The resizing,\ngreen plane, and cropping are extracted by involving the preprocessing and for employing morphological\nfunctions the Otsu thresholding is applied. The random transformations were applied and the MA patches were\nextracted. By batch normalization layer, four skip connections, three max-pooling layers, and three simple up-\nsampling layers in reported ROC score of 0.355 19 convolutional layers are comprised by the CNN. Whereas\nby integrating the enhanced pretrained LeNet architecture with a random forest classifier another study\nconducted and mainly focused on detecting DR red lesions in the DIARETDB1 dataset[62].\nBy applying the contrast-limited adaptive histogram equalization for enhancement, cropping the green\nchannel, and removing noise with a Gaussian filter the images are enhanced by the improved pretrained LeNet\narchitecture. By using U-net CNN architecture the blood vessels were segmented. The one fully connected\nlayer, four convolutional layers, and three max-pooling layers are comprised of the improved LeNet\narchitecture. By integrating handcrafted and custom CNN features with a random forest classifier lesion\ndetection in E-ophtha datasets the hard exudate lesion detection is targeted. The candidate detection using\ndynamic thresholding, color normalization, and cropping the preprocessing steps are performed. For\nclassifying and detecting DR images the remaining lesions in images after vessel extraction are essential to\nconsider. As reviewed in this section the utilized deep learning methods are studied by a few vessel\nsegmentation. Based on pre-trained DEEPLAB-COCO-LARGEFOV the modified CNN is employed to\nextract the retinal blood vessels from RGB retina images. Under ROC the area of 0.894 is achieved and 93.94%\naccuracy is achieved[55]. With patch cropping, horizontal flipping, and morphological methods the CHASE\nDB1 datasets and STARE are included under the preprocessing datasets.\n9. Conclusion\nIn conclusion, the critical assessment of deep learning methodologies help in evaluating the automated\nidentification of DR from images of retina. In the realm of diagnostics methodologies associated with deep\nlearning and medical imaging, a significant stride has been signified. While evaluating severity and accurately\ndiscerning diabetic retinopathy the remarkable potential of deep learning techniques has been underscored by\nthis comparative scrutiny. The challenges such as model interpretability, dataset heterogeneity, and\napplicability across diverse demographics the achieved progress notwithstanding. Looking ahead, the\nintegration into clinical protocols, the validation of expansive datasets, and concerted endeavors toward\nstandardization are imperative to fully harness deep learning in diabetic retinopathy diagnosis. Personalized\nhealthcare, enhanced patient outcomes in diabetic retinopathy management, and the promise of bolstering early\ndetection are held as technological advancements persist.\n10. Acknowledgement\n11. References:\n1. Thomas RL, Halim S, Gurudas S, Sivaprasad S, Owens DR. IDF Diabetes Atlas: A review of studies utilising\nretinal photography on the global prevalence of diabetes related retinopathy between 2015 and 2018. Diabetes\nResearch and Clinical Practice. 2019 Nov 1;157:107840.\n2. Ansari P, Tabasumma N, Snigdha NN, Siam NH, Panduru RVNRS, Azam S, et al. Diabetic Retinopathy: An\nOverview on Mechanisms, Pathophysiology and Pharmacotherapy. Diabetology. 2022 Mar;3(1):159–75.\n3. Safi H, Safi S, Hafezi-Moghadam A, Ahmadieh H. Early detection of diabetic retinopathy. Survey of\nOphthalmology. 2018 Sep 1;63(5):601–8.\n4. Vujosevic S, Aldington SJ, Silva P, Hernández C, Scanlon P, Peto T, et al. Screening for diabetic retinopathy:\nnew perspectives and challenges. The Lancet Diabetes & Endocrinology. 2020;8(4):337–47.\n5. Wykoff CC, Khurana RN, Nguyen QD, Kelly SP, Lum F, Hall R, et al. Risk of blindness among patients with\ndiabetes and newly diagnosed diabetic retinopathy. Diabetes care. 2021;44(3):748–56.\n6. Hill L, Makaroff LE. Early detection and timely treatment can prevent or delay diabetic retinopathy. Diabetes\nResearch and Clinical Practice. 2016 Oct 1;120:241–3.\n7. Kim M, Kim RY, Park W, Park YG, Kim IB, Park YH. Electroretinography and retinal microvascular changes\nin type 2 diabetes. Acta Ophthalmologica. 2020;98(7):e807–13.\n8. Lechner J, O’Leary OE, Stitt AW. The pathology associated with diabetic retinopathy. Vision Research. 2017\nOct 1;139:7–14.\n9. Kwan CC, Fawzi AA. Imaging and Biomarkers in Diabetic Macular Edema and Diabetic Retinopathy. Curr\nDiab Rep. 2019 Aug 31;19(10):95.\n10. Raman R, Ganesan S, Pal SS, Kulothungan V, Sharma T. Prevalence and risk factors for diabetic retinopathy in\nrural India. Sankara Nethralaya Diabetic Retinopathy Epidemiology and Molecular Genetic Study III (SN-\nDREAMS III), report no 2. BMJ Open Diabetes Research and Care. 2014 Jun 1;2(1):e000005.\n11. Nielsen KB, Lautrup ML, Andersen JKH, Savarimuthu TR, Grauslund J. Deep Learning–Based Algorithms in\nScreening of Diabetic Retinopathy: A Systematic Review of Diagnostic Performance. Ophthalmology Retina.\n2019 Apr 1;3(4):294–304.\n12. Islam MM, Yang HC, Poly TN, Jian WS, (Jack) Li YC. Deep learning algorithms for detection of diabetic\nretinopathy in retinal fundus photographs: A systematic review and meta-analysis. Computer Methods and\nPrograms in Biomedicine. 2020 Jul 1;191:105320.\n13. Asiri N, Hussain M, Al Adel F, Alzaidi N. Deep learning based computer-aided diagnosis systems for diabetic\nretinopathy: A survey. Artificial Intelligence in Medicine. 2019 Aug 1;99:101701.\n14. Badar M, Haris M, Fatima A. Application of deep learning for retinal image analysis: A review. Computer\nScience Review. 2020 Feb 1;35:100203.\n15. Grzybowski A, Brona P, Lim G, Ruamviboonsuk P, Tan GSW, Abramoff M, et al. Artificial intelligence for\ndiabetic retinopathy screening: a review. Eye. 2020 Mar;34(3):451–60.\n16. Lois N, McCarter RV, O’Neill C, Medina RJ, Stitt AW. Endothelial Progenitor Cells in Diabetic Retinopathy.\nFront Endocrinol [Internet]. 2014 Apr 9 [cited 2024 Mar 28];5. Available from:\nhttps://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2014.00044/full\n17. Tsiknakis N, Theodoropoulos D, Manikis G, Ktistakis E, Boutsora O, Berto A, et al. Deep learning for diabetic\nretinopathy detection and classification based on fundus images: A review. Computers in Biology and Medicine.\n2021 Aug 1;135:104599.\n18. Wang Y, Lin Z, Zhai G, Ding XX, Wen L, Li D, et al. Prevalence of and Risk Factors for Diabetic Retinopathy\nand Diabetic Macular Edema in Patients with Early- and Late-Onset Diabetes Mellitus. Ophthalmic Research.\n2020 Apr 30;65(3):293–9.\n19. Kalaivani K, Mission V. Risk Factors for Diabetic Retinopathy in Type 2 Diabetes Mellitus Patients. Journal of\nmedical pharmaceutical and allied sciences. 2021;10(4):3369–76.\n20. Sadda SR. Assessing the Severity of Diabetic Retinopathy: Early Treatment Diabetic Retinopathy Study Report\nNumber 10. Ophthalmology. 2020 Apr 1;127(4):S97–8.\n21. Sadda SR, Nittala MG, Taweebanjongsin W, Verma A, Velaga SB, Alagorie AR, et al. Quantitative assessment\nof the severity of diabetic retinopathy. American Journal of Ophthalmology. 2020;218:342–52.\n22. Lau HC, Voo YO, KTYeo SL, Jap A. MASS SCREENING F () R DIABETIC RETINOPATHY-A REPORT ()\nN DIABETIC RETINAI, SCREENING IN PRIMARY (CARE (CLINICS IN SINGAPORE. Singapore Med J.\n1995;36:510–3.\n23. Hristova E, Koseva D, Zlatarova Z, Dokova K. Diabetic Retinopathy Screening and Registration in Europe—\nNarrative Review. Healthcare. 2021 Jun;9(6):745.\n24. Wong TY, Sun J, Kawasaki R, Ruamviboonsuk P, Gupta N, Lansingh VC, et al. Guidelines on Diabetic Eye\nCare: The International Council of Ophthalmology Recommendations for Screening, Follow-up, Referral, and\nTreatment Based on Resource Settings. Ophthalmology. 2018 Oct 1;125(10):1608–22.\n25. Feeny AK, Tadarati M, Freund DE, Bressler NM, Burlina P. Automated segmentation of geographic atrophy of\nthe retinal epithelium via random forests in AREDS color fundus images. Computers in Biology and Medicine.\n2015 Oct 1;65:124–36.\n26. Abdelsalam MM. Effective blood vessels reconstruction methodology for early detection and classification of\ndiabetic retinopathy using OCTA images by artificial neural network. Informatics in Medicine Unlocked.\n2020;20:100390.\n27. Shah P, Mishra DK, Shanmugam MP, Doshi B, Jayaraj H, Ramanjulu R. Validation of Deep Convolutional\nNeural Network-based algorithm for detection of diabetic retinopathy – Artificial intelligence versus clinician\nfor screening. Indian Journal of Ophthalmology. 2020 Feb;68(2):398.\n28. Markan A, Agarwal A, Arora A, Bazgain K, Rana V, Gupta V. Novel imaging biomarkers in diabetic retinopathy\nand diabetic macular edema. Ophthalmol Eye Dis. 2020 Jan 1;12:2515841420950513.\n29. Ayala A, Ortiz Figueroa T, Fernandes B, Cruz F. Diabetic Retinopathy Improved Detection Using Deep\nLearning. Applied Sciences. 2021 Jan;11(24):11970.\n30. Alyoubi WL, Abulkhair MF, Shalash WM. Diabetic Retinopathy Fundus Image Classification and Lesions\nLocalization System Using Deep Learning. Sensors. 2021 Jan;21(11):3704.\n31. Guo Y, Liu Y, Oerlemans A, Lao S, Wu S, Lew MS. Deep learning for visual understanding: A review.\nNeurocomputing. 2016 Apr 26;187:27–48.\n32. Deng L, Yu D. Deep Learning: Methods and Applications. SIG. 2014 Jun 29;7(3–4):197–387.\n33. Bakator M, Radosav D. Deep Learning and Medical Diagnosis: A Review of Literature. Multimodal\nTechnologies and Interaction. 2018 Sep;2(3):47.\n34. He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: Proceedings of the IEEE\nconference on computer vision and pattern recognition [Internet]. 2016 [cited 2024 Mar 28]. p. 770–8. Available\nfrom:\nhttp://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html\n35. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the Inception Architecture for Computer\nVision. In 2016 [cited 2024 Mar 28]. p. 2818–26. Available from: https://www.cv-\nfoundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.h\ntml\n36. Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolutional neural networks.\nCommun ACM. 2017 May 24;60(6):84–90.\n37. Li T, Gao Y, Wang K, Guo S, Liu H, Kang H. Diagnostic assessment of deep learning algorithms for diabetic\nretinopathy screening. Information Sciences. 2019 Oct 1;501:511–22.\n38. Esfahani MT, Ghaderi M, Kafiyeh R. Classification of diabetic and normal fundus images using new deep\nlearning method. Leonardo Electron J Pract Technol. 2018;17(32):233–48.\n39. Abràmoff MD, Garvin MK, Sonka M. Retinal Imaging and Image Analysis. IEEE Reviews in Biomedical\nEngineering. 2010;3:169–208.\n40. Lam C, Yi D, Guo M, Lindsey T. Automated detection of diabetic retinopathy using deep learning. AMIA\nsummits on translational science proceedings. 2018;2018:147.\n41. Kaggle. Diabetic Retinopathy Detection [Internet]. 2024 [cited 2024 Mar 28]. Available from:\nhttps://kaggle.com/competitions/diabetic-retinopathy-detection\n42. Das S, Kharbanda K, M S, Raman R, D ED. Deep learning architecture based on segmented fundus image\nfeatures for classification of diabetic retinopathy. Biomedical Signal Processing and Control. 2021 Jul\n1;68:102600.\n43. Melo T, Mendonça AM, Campilho A. Microaneurysm detection in color eye fundus images for diabetic\nretinopathy screening. Computers in Biology and Medicine. 2020 Nov 1;126:103995.\n44. Ali A, Qadri S, Khan Mashwani W, Kumam W, Kumam P, Naeem S, et al. Machine Learning Based Automated\nSegmentation and Hybrid Feature Analysis for Diabetic Retinopathy Classification Using Fundus Image.\nEntropy. 2020 May;22(5):567.\n45. Baget-Bernaldiz M, Pedro RA, Santos-Blanco E, Navarro-Gil R, Valls A, Moreno A, et al. Testing a Deep\nLearning Algorithm for Detection of Diabetic Retinopathy in a Spanish Diabetic Population and with\nMESSIDOR Database. Diagnostics. 2021 Aug;11(8):1385.\n46. Mateen M, Wen J, Hassan M, Nasrullah N, Sun S, Hayat S. Automatic Detection of Diabetic Retinopathy: A\nReview on Datasets, Methods and Evaluation Metrics. IEEE Access. 2020;8:48784–811.\n47. Saxena G, Verma DK, Paraye A, Rajan A, Rawat A. Improved and robust deep learning agent for preliminary\ndetection of diabetic retinopathy using public datasets. Intelligence-Based Medicine. 2020 Dec 1;3–4:100022.\n48. Quellec G, Charrière K, Boudi Y, Cochener B, Lamard M. Deep image mining for diabetic retinopathy\nscreening. Medical Image Analysis. 2017 Jul 1;39:178–93.\n49. Orlando JI, Prokofyeva E, del Fresno M, Blaschko MB. An ensemble deep learning based approach for red\nlesion detection in fundus images. Computer Methods and Programs in Biomedicine. 2018 Jan 1;153:115–27.\n50. Chudzik P, Majumdar S, Calivá F, Al-Diri B, Hunter A. Microaneurysm detection using fully convolutional\nneural networks. Computer Methods and Programs in Biomedicine. 2018 May 1;158:185–92.\n51. Dutta S, Manideep BC, Basha SM, Caytiles RD, Iyengar N. Classification of diabetic retinopathy images by\nusing deep learning models. International Journal of Grid and Distributed Computing. 2018;11(1):89–106.\n52. Xu K, Feng D, Mi H. Deep convolutional neural network-based early automated detection of diabetic retinopathy\nusing fundus image. Molecules. 2017;22(12):2054.\n53. Wan S, Liang Y, Zhang Y. Deep convolutional neural networks for diabetic retinopathy detection by image\nclassification. Computers & Electrical Engineering. 2018 Nov 1;72:274–82.\n54. Adem K. Exudate detection for diabetic retinopathy with circular Hough transformation and convolutional\nneural networks. Expert Systems with Applications. 2018 Dec 30;114:289–95.\n55. Zhang W, Zhong J, Yang S, Gao Z, Hu J, Chen Y, et al. Automated identification and grading system of diabetic\nretinopathy using deep neural networks. Knowledge-Based Systems. 2019 Jul 1;175:12–25.\n56. Zago GT, Andreão RV, Dorizzi B, Salles EOT. Diabetic retinopathy detection using red lesion localization and\nconvolutional neural networks. Computers in biology and medicine. 2020;116:103537.\n57. de la Torre J, Valls A, Puig D. A deep learning interpretable classifier for diabetic retinopathy disease grading.\nNeurocomputing. 2020 Jul 5;396:465–76.\n58. Raju M, Pagidimarri V, Barreto R, Kadam A, Kasivajjala V, Aswath A. Development of a deep learning\nalgorithm for automatic diagnosis of diabetic retinopathy. In: MEDINFO 2017: precision healthcare through\ninformatics [Internet]. IOS press; 2017 [cited 2024 Mar 28]. p. 559–63. Available from:\nhttps://ebooks.iospress.nl/doi/10.3233/978-1-61499-830-3-559\n59. Lin Z, Guo R, Wang Y, Wu B, Chen T, Wang W, et al. A Framework for Identifying Diabetic Retinopathy\nBased on Anti-noise Detection and Attention-Based Fusion. In: Frangi AF, Schnabel JA, Davatzikos C,\nAlberola-López C, Fichtinger G, editors. Medical Image Computing and Computer Assisted Intervention –\nMICCAI 2018. Cham: Springer International Publishing; 2018. p. 74–82.\n60. Zhao Z, Zhang K, Hao X, Tian J, Chua MCH, Chen L, et al. Bira-net: Bilinear attention net for diabetic\nretinopathy grading. In: 2019 IEEE International Conference on Image Processing (ICIP) [Internet]. IEEE; 2019\n[cited 2024 Mar 28]. p. 1385–9. Available from: https://ieeexplore.ieee.org/abstract/document/8803074/\n61. Jiang H, Yang K, Gao M, Zhang D, Ma H, Qian W. An Interpretable Ensemble Deep Learning Model for\nDiabetic Retinopathy Disease Classification. In: 2019 41st Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society (EMBC) [Internet]. 2019 [cited 2024 Mar 28]. p. 2045–8.\nAvailable from: https://ieeexplore.ieee.org/abstract/document/8857160\n62. Bravo MA, Arbeláez PA. Automatic diabetic retinopathy classification. In: 13th International Conference on\nMedical Information Processing and Analysis [Internet]. SPIE; 2017 [cited 2024 Mar 28]. p. 446–55. Available\nfrom: https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10572/105721E/Automatic-diabetic-\nretinopathy-classification/10.1117/12.2285939.full",
    "pdf_filename": "Grading_and_Anomaly_Detection_for_Automated_Retinal_Image_Analysis_using_Deep_Learning.pdf"
}