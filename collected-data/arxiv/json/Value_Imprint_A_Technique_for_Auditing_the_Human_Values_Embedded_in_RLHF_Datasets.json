{
    "title": "Value Imprint: A Technique for Auditing the",
    "abstract": "LLMsareincreasinglyfine-tunedusingRLHFdatasetstoalignthemwithhuman preferencesandvalues. However, verylimitedresearchhasinvestigatedwhich specifichumanvaluesareoperationalizedthroughthesedatasets. Inthispaper,we introduceValueImprint,aframeworkforauditingandclassifyingthehumanvalues embeddedwithinRLHFdatasets. Toinvestigatetheviabilityofthisframework,we conductedthreecasestudyexperimentsbyauditingtheAnthropic/hh-rlhf,OpenAI WebGPTComparisons,andAlpacaGPT-4-LLMdatasetstoexaminethehuman valuesembeddedwithinthem. Ouranalysisinvolvedatwo-phaseprocess. During thefirstphase,wedevelopedataxonomyofhumanvaluesthroughanintegrated reviewofpriorworksfromphilosophy, axiology, andethics. Then, weapplied this taxonomy to annotate 6,501 RLHF preferences. During the second phase, we employed the labels generated from the annotation as ground truth data for trainingatransformer-basedmachinelearningmodeltoauditandclassifythethree RLHF datasets. Through this approach, we discovered that information-utility values, includingWisdom/KnowledgeandInformationSeeking, werethemost dominanthumanvalueswithinallthreeRLHFdatasets. Incontrast,prosocialand democraticvalues,includingWell-being,Justice,andHuman/AnimalRights,were theleastrepresentedhumanvalues. Thesefindingshavesignificantimplications for developing language models that align with societal values and norms. We contributeourdatasetstosupportfurtherresearchinthisarea. 1 Introduction ReinforcementLearningFromHumanFeedback(RLHF)hasemergedasapotentwayofshapingthe behaviorofAImodelstoensuretheyproducepositiveresponsesandexperiencesthatcorrespond withuserpreferencesandsocietalnorms[1–3]. Ononehand,severalAIresearchershavetoutedthe efficacyofthisapproachasaproxyforembeddinghumanvaluesandpreferencesintoAImodels, resulting in its use in different domains, including the finetuning of LLMs [4, 5], vision models [6],andmulti-modalsystems[7]. SeveralusersoftheseAIsystems,ontheotherhand,areraising concernsaboutthecensorshipandanti-democraticstanceofmodelstrainedwiththesepreferences, highlightingthattheyaremarginalizedagainsttheirvaluesystemswhileallowingothers[8,9]. Asa result,thereisagrowingconcernamongmembersofthepublicaroundthelackoftransparencyinthe kindsofvaluesthesedatasetsembedintoAIsystems. Inaddition,consideringthatRLHFpreferences involvecomplexvaluejudgmentsofannotators,itiscrucialtoinvestigatehowthesubjectivevalues 38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024)TrackonDatasetsandBenchmarks. 4202 voN 81 ]GL.sc[ 1v73911.1142:viXra",
    "body": "Value Imprint: A Technique for Auditing the\nHuman Values Embedded in RLHF Datasets\nIkeObi RohanPant SrishtiShekharAgrawal\nPurdueUniversity PurdueUniversity PurdueUniversity\nWestLafayette,Indiana WestLafayette,Indiana WestLafayette,Indiana\nMahamGhazanfar AaronBasiletti\nPurdueUniversity PurdueUniversity\nWestLafayette,Indiana WestLafayette,Indiana\nAbstract\nLLMsareincreasinglyfine-tunedusingRLHFdatasetstoalignthemwithhuman\npreferencesandvalues. However, verylimitedresearchhasinvestigatedwhich\nspecifichumanvaluesareoperationalizedthroughthesedatasets. Inthispaper,we\nintroduceValueImprint,aframeworkforauditingandclassifyingthehumanvalues\nembeddedwithinRLHFdatasets. Toinvestigatetheviabilityofthisframework,we\nconductedthreecasestudyexperimentsbyauditingtheAnthropic/hh-rlhf,OpenAI\nWebGPTComparisons,andAlpacaGPT-4-LLMdatasetstoexaminethehuman\nvaluesembeddedwithinthem. Ouranalysisinvolvedatwo-phaseprocess. During\nthefirstphase,wedevelopedataxonomyofhumanvaluesthroughanintegrated\nreviewofpriorworksfromphilosophy, axiology, andethics. Then, weapplied\nthis taxonomy to annotate 6,501 RLHF preferences. During the second phase,\nwe employed the labels generated from the annotation as ground truth data for\ntrainingatransformer-basedmachinelearningmodeltoauditandclassifythethree\nRLHF datasets. Through this approach, we discovered that information-utility\nvalues, includingWisdom/KnowledgeandInformationSeeking, werethemost\ndominanthumanvalueswithinallthreeRLHFdatasets. Incontrast,prosocialand\ndemocraticvalues,includingWell-being,Justice,andHuman/AnimalRights,were\ntheleastrepresentedhumanvalues. Thesefindingshavesignificantimplications\nfor developing language models that align with societal values and norms. We\ncontributeourdatasetstosupportfurtherresearchinthisarea.\n1 Introduction\nReinforcementLearningFromHumanFeedback(RLHF)hasemergedasapotentwayofshapingthe\nbehaviorofAImodelstoensuretheyproducepositiveresponsesandexperiencesthatcorrespond\nwithuserpreferencesandsocietalnorms[1–3]. Ononehand,severalAIresearchershavetoutedthe\nefficacyofthisapproachasaproxyforembeddinghumanvaluesandpreferencesintoAImodels,\nresulting in its use in different domains, including the finetuning of LLMs [4, 5], vision models\n[6],andmulti-modalsystems[7]. SeveralusersoftheseAIsystems,ontheotherhand,areraising\nconcernsaboutthecensorshipandanti-democraticstanceofmodelstrainedwiththesepreferences,\nhighlightingthattheyaremarginalizedagainsttheirvaluesystemswhileallowingothers[8,9]. Asa\nresult,thereisagrowingconcernamongmembersofthepublicaroundthelackoftransparencyinthe\nkindsofvaluesthesedatasetsembedintoAIsystems. Inaddition,consideringthatRLHFpreferences\ninvolvecomplexvaluejudgmentsofannotators,itiscrucialtoinvestigatehowthesubjectivevalues\n38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024)TrackonDatasetsandBenchmarks.\n4202\nvoN\n81\n]GL.sc[\n1v73911.1142:viXra\nandpreferencesofannotators–bothhumanandAI–areembeddedwithinthesedatasetsinways\nthatmightmisalignwithsocietalvaluesandnorms.\nInthispaper,weintroduceValueImprint,anoveltechniqueforauditingandclassifyingthehuman\nvalues embedded within RLHF datasets. To support this approach, we created a human values\ntaxonomybyconductinganintegratedliteraturereviewofpriorbodiesofworkfromphilosophy,\naxiology, and STS (Science, Technology, and Society) and, through a thematic analysis of these\nbodiesofwork,developedataxonomyofhumanvaluestosupportouraudit. Usingthistaxonomy,\nweconductedatwo-phaseauditanalysis,witheachstepbuildingontheresultfromthepreviousstage.\nDuringthefirstphase,weemployedthetaxonomytoqualitativelyannotate6,501RLHFpreferences.\nDuringthesecondphase,weemployedthelabelsderivedfromthequalitativeannotationprocessas\ngroundtruthdata. Thisdatawasthenutilizedtoatraintransformer-basedmachinelearningmodel,\nwhichwesubsequentlydeployedforauditingandclassifyingthecompleteAnthropic/hh-rlhf,OpenAI\nWebGPTComparisons,andAlpacaGPT-4-LLMdatasets. Wefurtherconductedahumanevaluation\nofasectionoftheclassificationoutputtoexaminetheirperformance. Wefollowedtheevaluation\nwithanadditionalroundofanalysistoexaminehowthevaluesembeddedwithinthethreeRLHF\ndatasetsdiffer. Throughtheseapproaches,weansweredourresearchquestionswhichincluded:\n1. RQ1: WhatkindsofhumanvaluesareembeddedwithinRLHFpreferences?\n2. RQ2: InwhatwaysdothehumanvaluesembeddedwithintheAnthropic/hh-rlhf,OpenAI\nWebGPTComparisons,andAlpacaGPT-4-LLMdatasetsdiffer?\nFindingsfromourresearchrevealedthatthemostdominantvalueswithinthegroundtruthRLHF\npreferenceswereInformationSeekingandWisdom/Knowledge. Incontrast,theleastrepresented\nvalueswereCivility&Tolerance,Empathy&Helpfulness,Justice&HumanRights/AnimalRights,\nand Well-being & Peace. The findings also revealed instances of unethical responses selected\nassuitablepreferencesfortrainingmachinelearningmodels. Furthermore,themachinelearning\nclassificationofhumanvaluesproducedanaccuracyscorerangeof80%forthemodelweusedfor\nthisanalysis. ThisdemonstratestheviabilityofAIresearchersandpractitionersadoptingthisprocess\ntointerrogatethehumanvaluesembeddedwithinRLHFdatasetstoforegroundtheirvalueorientation\nandhowtheymightleadtodifferentsocietalimpacts.\nAboveall,throughthisresearch,wemakethefollowingcontributions:1)weintroduceatechniquefor\nauditingandclassifyingtheunderlyinghumanvaluesembeddedwithinRLHFpreferences,providing\nAI researchers with a technique for auditing and interrogating the quality of RLHF datasets, 2)\nweconductthreecasestudyexperimentsusingthisapproachandthroughourfindingsrevealthat\nWisdom/Knowledge and Information Seeking were the most dominant human values within the\ndatasets;validatingourtechnique.3)Wecontributebothourgroundtruthannotationandclassification\ndatasetsand,throughthismeans,provideresearcherswiththepathwaytotakethisworkforward.\nInthesectionsthatfollow,wesituateourworkwithinbroaderresearchonlanguagemodels,data\nquality, and embedding human values into LLMs. We then describe our methods and report our\nfindings. Weconcludewithadiscussionoftheimplicationsofthesefindingsandprovidesuggestions\nforfuturework.\n2 Background\n2.1 EmbeddingHumanValuesintoLLMsandAISystems\nAIresearchersandcomputerscientistsareincreasinglyinterestedinembeddinghumanvaluesinto\nLLMs,AI,androboticsystems. Thisincreasedinterestismotivatedbyseveralreasons,includingthe\nneedtomovebeyondjustoptimizingformetricslikeefficiencyandperformancetowardsaligning\nthesesystemswithprosocialvalueslikedemocracy,transparency,freedomofexpression,andhuman\nrights [10–12]. It also includes the need to ensure that technology systems do not make users\nvulnerableorcausethemharm[13–15]. Toachievetheseobjectives,AIresearchersareincreasingly\ndevelopingsociotechnicalapproachesforencodingsocietalvaluesintoAIsystems,usingdifferent\ntechniquessuchasvalue-orienteddatasetsascanbefoundintheworksof [10,16–19]andformalized\nethicalframeworksascanbefoundintheworksof [20–22],amongothertechniques[23–26].\nSolaiman&Dennison[10]introducedanapproachforaligningAImodelswithhumanvaluesby\nusing value-oriented datasets to finetune AI models. Findings from their research revealed that\n2\ntheirapproachimprovedadherencetohumanvaluesandreducedtoxicitywithoutaffectingmodel\nperformance. Nahianetal.[17]investigatedapproachesforusingstoriestoencodesocietalnorms\nintomachinelearningsystemsandfoundthatthistechniquecancomplementotherapproachesfor\nintroducinghumanvaluesintomachinelearningsystems. Ammanabroluetal.[18]exploredthe\napproachofimbuingagentswithcommonsenseknowledgetoensurethatsuchsystemsalignwith\nsocially beneficial human values. Findings from their study revealed that this approach reduced\ntheabilityoftheagenttoengageinharmfulbehaviorsthatmisalignwithhumanvaluesby25%.\nSorensen et al. [19] also explored approaches for enabling value pluralism in machine learning\nsystems. They introduced the ValuePrism dataset as a means of fostering this genre of research.\nSzaboetal.[27]investigatedapproachesforfusingquantitativeandqualitative-basedreasoningas\nameansofensuringvaluealignmentinmachinelearningsystems. Relevanthereisthatcomputer\nscientists and AI researchers are increasingly exploring technical, conceptual, and philosophical\napproachesforembeddinghumanvaluesintoLLMs,AI,andalgorithmicsystems.\nHowever,althoughnumerousAIresearchershaveexaminedseveralapproachesforembeddinghuman\nvaluesintoAImodels,thereiscurrentlyalackoftechniquesandmethodsthatallowresearchers\ntosystematicallyforegroundandthoroughlyinvestigatethespecifictypesofhumanvaluesbeing\nintegratedintoLLMsandAImodelsusingnon-ethicscurateddatasets. Andspecifically,verylimited\nattentionhasbeenpaidtoexaminingthehumanvaluesembeddedwithinRLHFdatasets.Prabhakaran\netal.[21]highlightedthatAIresearchersoftenassumethatthevaluestheyembedintoAIsystems\nservethebestinterestofsociety,eventhoughthereisnoempiricaldataorjustificationthatsupports\ntheirapproachandbelief. Ifanything,itistheopposite[28,29]. Hendrycksetal.[30,16]identified\nalackofalignmentwithhard-to-specifyhumanvaluesasoneoftheunsolvedsafety-relatedproblems\ninthefieldofmachinelearning. GiventhattheobjectiveofRLHFistoembedhumanvaluesand\npreferences into AI models and considering that, at present, there is no method for auditing and\nmeasuringthehumanvaluesembeddedwithinRLHFdatasets,thispaperfocusesonintroducinga\ntechniqueforinterrogatingtheseRLHFdatasetsasameansofprovidinginsightsintothekindsof\nhumanvaluesembeddedwithinthem.\n2.2 DataQualityandLanguageModels\nThereisalargeandgrowingbodyofworkattheintersectionofdataqualityandlanguagemodels[31–\n33]. TheseworkshaveexaminedissuesrelatingtoAIdatasetsfromnumerousperspectives,including\nissues of representation harms and demographic bias that propagate harmful stereotypes from\ndefective datasets into AI models, issues of toxicity/harmful content that perpetuate misogyny\nandracialslurs,lackoftransparencyandaccountabilityaroundhowdatasetsarecollected,annotated,\ncleanedorversionedovertimewhichhampersaccountabilityandattribution,amongmanyother\nissuesattheintersectionofdataqualityandlanguagemodels.\nHirotaetal.[31]investigatedtheissuesofgenderandracialbiasinfivevisualquestion-answering\ndatasets. Findingsfromtheirresearchrevealedinstancesofgenderdisparityandracialstereotypes\nthatfavormalesandWesterncultures,respectively. Theyproposedapproachesthatresearcherscould\nadopttomitigatethesebiases. Garciaetal.[34]annotatedandauditedtheGoogleCaptionsvision\nandlanguagemodeldatasetstoinvestigateinstancesofbias. Findingsfromtheirresearchshowed\nanover-representationofmalesandpersonswithlighterskintonescomparedtootherusersfrom\notherdemographics. Dhamalaetal.[35]introducedalarge-scalebenchmarkingdatasettoallow\nresearcherstomeasurebiasinlanguagemodelsacrossdifferentdimensions,includingrace,religion,\nandgender. Throughthisapproach, theyaimtoinducetransparencyinreportingtoxicitywithin\nlanguagemodels. Papakyriakopoulosetal.[36]investigatedthelackofdiversityinspeechdatasets\nacrossdifferentdimensions,includingaccent,dialect,andspeechimpairment. Findingsfromtheir\nresearchrevealedthattheabsenceofintentionalstructureplaysaroleinthislackofdiversity. To\nresolve this, they introduced speech datasheets to foster ethical data collection practices around\nspeechdatasets. Pushkarnaetal.[37]introduceddatacardstodocumenttheprovenanceandethical\nimplicationsofusingmulti-modaldatasets. Luccionietal.[38]introducedadatasetdeprecation\nframeworkasameansofensuringproperdocumentationfordatasetsthataredeprecatedandretired\nfromcirculation.\nAlthoughnumerousscholarshaveextensivelyauditedAIandmachinelearningdatasets,verylimited\nworkhasfocusedonexaminingRLHFdatasetstoforegroundthehumanvaluesembeddedwithin\nthem. Inasmallbodyofworkinthisarea,Hendrycksetal.[16]introducedtheETHICSDataset\n3\nData Collection Taxonomy Data Annotation Model Training Value Classifier Value Audit\n1 2 3 4 5 6\nAnthropic Encoder 1\nWebGPT\n..E.n.c.o.d.e.r. 2.\nAlpaca GPT-4 Encoder .. 0.5 0.2 0.7\nCollect RLHF datasets Develop human values\n Create ground truth data\n Train Bert-based models\n Use trained model to Compare classification\n\nfrom Hugging Face & taxonomy based on prior via qualitative annotation using ground truth data classify human values results of the 3 datasets\n\nGitHub research in axiology of select RLHF datasets derived from annotation embedded in RLHF data to examine insights.\nFigure 1: Value Imprint is a technique for auditing the human values embedded within RLHF\ndatasetsusinganAI-focusedhumanvaluestaxonomy.\nto foster the measurement of the ethical judgment of language models. Birhane et al. [39] also\nintroducedatechniqueforannotatingthevaluesembeddedwithinmachinelearningresearchpapers;\nhowever,didnotfocusonexaminingRLHFdatasets. Obi&Gray[40]examinedvaluesengineers\nembeddedintoAIsystemsthroughtheirtechnicaljudgmentbutdidnotexaminethevaluesembedded\ninAIdatasets.ThislimitedworkthathasexaminedthehumanvalueswithinRLHFdatasetsmotivates\ntheneedforfurtherresearchinthisareatosupportamoretransparentRLHFprocess.\n3 Method\n3.1 ExperimentDataset\nWe collected the datasets for this research from different developer collaboration platforms. We\ncollectedtheAnthropic/hh-rlhf [2]datasetfromHuggingFace,anopensourcemachinelearning\nplatformthatprovidesdatasets,models,andothercomputationalresourcesforAIpractitionersand\nresearchers. TheAnthropic/hh-rlhf dataset(train-161krows,test-8.55krows)hasbeendownloaded\natleast109,200times,usedtotrainorfine-tunemorethan156AImodels. Ouranalysisfocused\nonboththechosenandrejectedcolumnsofthedata. Wemergedthetrainandtestsectionsofthe\nAnthropic/hh-rlhf datasetintoonedatasetcorpusforanalysis. WealsocollectedtheOpenAIWebGPT\nComparisons[41]datasetfromtheHuggingFacelibraryandfocusedourcasestudyexperimenton\nthecontentofthequestionandanswer_0columns. Wecreatedafunctiontoextractonlythefull_text\nfromthequestioncolumnanddroppedthenon-essentialmetadata,includingtriviaqa,dataset,and\nid. Next,weconcatenatedthecontentoftheupdatedquestionandanswer_0columnsintoanew\ncolumntoformacompletepreferenceunit. Wethenusedourmodeltoclassifythesepreferencesand\nexaminedthehumanvaluesembeddedwithinthem. WefetchedtheAlpacaGPT-4-LLM[42]dataset\nfrom the GitHub repository dedicated to the project. Next, we concatenated the instruction and\noutputcolumnsfromtheoriginaldatasetintoanewcombinedcolumn,creatingacompletehuman\npreferenceconversation. WereducedtheDataFrametocontainonlythisnewcombinedcolumnand\nthenconductedourcasestudyclassificationanalysis. See(Fig.1)forourresearchprocessflow.\n3.2 HumanValueTaxonomy\nWeconstructedataxonomyofhumanvaluesthroughanintegratedliteraturereviewgroundedin\npriorbodiesofworkfrommoralphilosophy,axiology,andSTS(Science,Technology,andSociety).\nSpecifically, ourliteraturesearchfocusedonninejournaldatabaseswithinhumanvalues-related\ndisciplines, including the Journal of Value Inquiry; Axiomathes; The Journal of Ethics; Noûs;\nEthics;ThePhilosophicalReview;Science,Technology,&HumanValues;Utilitas;andTheJournal\nof Philosophy. Our search keyword for querying these databases was: \"human value.\" No date\nrestrictionsweremadeonoursearchofthesedatabases.\nWe followed a three-stage process to construct a taxonomy of human values using the curated\nresearchpapers. Inthefirststage,weassignedeachcuratedpaperahumanvaluebasedonthecentral\ntheme discussed in the paper. Next, we categorized papers with similar values into semantically\ncoherenthierarchicalcategoriesusingabottom-upapproach,suchasgroupingpapersaboutpeace,\nsecurity,andwell-beingunderanoverarchingwell-beingandpeacecategory. Second,weconducted\n4\nHuman Values 04 | Justice & Rights\nRespect for peoples rights,\n\nfreedom, and autonomy\n01 | Information Seeking\nPursuit of information for\n\nimmediate, practical use 05 | Duty & Accountability\nEthical obligations and\nresponsibilities to society\n02 | Wisdom & Knowledge\nAcquiring knowledge for\n\ndeeper understanding 06 | Civility & Tolerance\nPositive character and attitude\n\nin social interactions\n03 | Well-being & Peace\nHolistic thriving across physical,\n\nmental, and emotional aspects 07 | Empathy & Helpfulness\nShowing compassion and\naltruism to others\nFigure2: Thisimagepresentsavisualversionofthetaxonomythatsupportedouraudit. [SeeTable\n2andAppendix 5.3forthecompletedescriptionandcitationofthehumanvaluestaxonomy.]\na qualitative review examining hypernym-hyponym relationships of our categories from the first\nstagetoensuresubordinatevaluesmaintainedan\"isapartof\"relationshipwithineachcategory\n(e.g., duty/accountabilitycontainingnon-maleficenceandtrustworthiness). Third, we conducted\nanadditionalreviewtoverifythatallvalueswithineachgroupreasonablybelongedtothesame\nethicalparadigm,thoughnotintendedtobesacrosanct,suchaswisdomandknowledgealigning\nwithvirtueethics. Thisapproachallowedustocreateasemanticallycoherentandethicallybalanced\nhumanvaluestaxonomyforouranalysis. Wemadethehierarchicaltaxonomysuchthatotherrelated\nsub-valuesnotcoveredinthispapercanreasonablyfitwithinthedifferenthigh-levelvaluecategories.\nWeprovidein-depthinformationaboutthetaxonomyinTable 2andinAppendix 5.3.\n3.3 DataAnnotation\nUsing the human values taxonomy as our codebook, we qualitatively annotated sampled 6,501\npreferencesfromtheAnthropic/hh-rlhf datasettoexaminethehumanvaluesembeddedinthem. The\nqualitativeannotationswereperformedbyateamof5researcherswithinterdisciplinaryexpertise\nspanningEthics,Computing,andHCI.ThenationalityoftheannotatorsincludedIndia,USA,Nigeria,\nandPakistan.Beforecodingallthe6,501preferences,weheldseveralroundsofextensivediscussions\nandexploratorycodingactivities. Theseactivitiesallowedustoengagewiththedatasettobetter\nunderstand the dimensions of human values, their differences, and similarities and to establish a\nprotocolforresolvinganydiscrepanciesandchallengesthatmightariseduringthemainannotation\nsession. Followingthisexploration,weconductedaninter-annotatoragreementassessmentbyhaving\nalltheannotatorsindependentlycodethesame200preferencesandthencomparedthecodesassigned\nbyeachannotatortothesamepreferencestoassessthelevelofagreementbetweenalltheannotators.\nWeachievedaninter-annotatoragreementscoreof0.85usingKrippendorff’sAlphascore. Through\nthis approach, we confirmed that multiple coders can consistently annotate and apply the same\nlabelstothesameRLHFpreferencesoncetheyunderstandthehumanvaluestaxonomy. Wethen\ncommencedourmainannotationsession. Otherinfrequentdiscrepanciesduringourmainannotation\nphasewereresolvedthroughdiscussions,codebookrefinement,orreconciliationbyathirdannotator.\n5\nseulaV\nytilitU-noitamrofnI\nytefaS\n&\ngnieB-lleW\n..................\n...................\n...................\nseulaV\nciviC\nseulaV\nlaicoS-orP\n3.4 ValueClassification\n3.4.1 ProblemFormulation\nToformallyframethetaskofcomputationallyauditingthehumanvaluesembeddedwithinRLHF\ndatasets,wemodeleditasamulti-classclassificationproblemoveravectorspaceofhumanvalues.\nWe define as follows: Let V = {v ,v ,...,v } be the set of all possible human value labels,\n1 2 n\nwhere n is the number of distinct human value classes. We define a dataset D = {(x ,y )}m ,\ni i i=1\nwhere x ∈ X is an RLHF preference instance (text), y ∈ V is the corresponding human value\ni i\nlabel associated with x , and m is the total number of instances. Split D into disjoint train and\ni\ntestsets: D andD . UseatokenizerT : X → Rd×l toconverteachtextinstancex intoa\ntrain test i\nnumericaltokenrepresentationT(x ) ∈ Rd×l, wheredistheembeddingdimension, andl isthe\ni\nsequencelength. Wedefineamulti-classclassificationmodelf : Rd×l → Rn,whereθ ∈ Θare\nθ\nthetrainableparametersofthemodel(RoBERTaForSequenceClassification),andΘistheparameter\nspace. Weuseacross-entropylossfunctionL:V ×Rn →Rtomeasurethediscrepancybetween\nthepredictedandtruelabelsforeachinstance(T(x ),y )inthetrainingset: L(y ,f (T(x ))). We\ni i i θ i\nalsoincorporatedclassweightsw =(w ,w ,...,w )∈Rntohandleclassimbalance,computed\n1 2 n\nusingcompute_class_weightfromscikit-learn. Wefurtheroptimizethemodelparametersθby\nminimizingtheweightedcross-entropylossoverthetrainingset:\n1 (cid:88)\nmin w ·L(y ,f (T(x ))).\nθ∈Θ |D train| yi i θ i\n(T(xi),yi)∈Dtrain\nWe used regularization (dropout), warm-up steps, and weight decay during training to improve\ngeneralizationandpreventoverfitting. Wethenusedthetrainedmodelf tomakepredictionson\nθ\nD : y = argmax f (T(x )) , where y is the predicted human value label for the\ntest pred,i vj∈V θ i j pred,i\ninputinstancex . WefurtherevaluatedmodelperformanceonD usingmetricslikeaccuracyand\ni test\nF1-score,withweightedaveragestoaccountforclassimbalance.\n3.4.2 ValueClassification\nUsingtheannotatedgroundtruthdataset,wetrainedaRoBERTamodelforthemulti-classclassifica-\ntionoftheRLHFdatasets. Wesplitthetrainingdatainto80%trainand20%testsetusingsklearn’s\ntrain_test_split. We trained the model for 8 epochs with a batch size of 64 using Hugging Face\nTrainer. WeusedCrossEntropylossfortheclassificationtask. Wefurtherenabledearlystopping\ntopreventoverfitting, withthetrainingstoppingearlyifthevalidationlossdoesnotimprovefor\n2 epochs. We saved the model checkpoints from the best validation loss. The hyperparameters\nincluded Max sequence length - 128, Batch size - 64, Epoch - 8, and Early stopping patience -2\nepochs. WeappliedDropoutregularizationtothefinallayerduringfinetuning. Wealsocomputed\nclassweightstohandleclassimbalanceandusedweightedrandomsamplingforthetrainingbatches.\nWethenemployedthetrainedRoBERTamodelforclassifyingthehumanvaluesembeddedwithin\ntheAnthropic/hh-rlhf(338,704),OpenAIWebGPTComparisons(19,578),andAlpacaGPT-4-LLM\n(52,002)datasets. Followingthevalueclassificationactivities,weconductedahumanevaluationof\n500classificationresults,whichshowedthatthemodelspredictedthecorrecthumanvalue84%of\nthetime. WefurtheranalyzedhowthevaluesembeddedwithinthedifferentRLHFdatasetsdiffer.\n4 Findings\n4.1 RQ1: WhatKindsofHumanValuesareEmbeddedwithinRLHFPreferences?\n4.1.1 ResultsfromQualitativeAnnotation\nFindingsfromouranalysisofthe6,501groundtruthpreferencesfromtheAnthropic/hh-rlhf dataset\nrevealed that the most dominant human values were Information Seeking for a specific use case\n(36.96%), Wisdom/Knowledge for personal enlightenment and edification (30.75%), and Duty &\nAccountability (9.52%). The least represented human values within the dataset were Civility &\nTolerance(7.61%),EmpathyandHelpfulness(6.09%),Well-being&Peace(5.94%),andJustice,\nHuman&AnimalRights(3.12%). Wecharacterizeresultsfromthisanalysisbelowandin(Table1).\n6\n1. InformationSeeking: ResultsfromouranalysisrevealedthatInformationSeeking(36.96%;\n2403 out of 6501) was the most dominant human value that was operationalized in the ground\ntruthdataset. ThedimensionsofInformationSeekingrepresentedinthedatasetincludedpersonal,\nprofessional, navigational, and practical information needs. The distinguishing feature between\nthe Information Seeking human value from all other underlying human values was in their level\nof specificity, need for accuracy, sense of immediacy or urgency, and instrumental expectation\n(i.e.,presentingtheAssistantasanintelligentandreliableinformationrepositoryoraninformation\nretrievalmachine). AnexampleofInformationSeekinghumanvaluethatwasoperationalizedwithin\nthedatasetincluded: Human: Ineedtogetvaccinatedforthefluthisyear,butI’mnotsurewhereto\ndothat. CanyoutellmetheclosestplacethatIcangetthevaccination? Assistant: Ifyou’reinthe\nUnitedStates,there’sacountypublichealthclinicinthecityofBinghamtoninupstateNewYork,\nthat’stheclosestplaceIcouldfind.\nTable1: Resultsfromthequalitativeannotationof6,501RLHFpreferencesshowedthatInformation\nSeekingwasthemostprominenthumanvalue,whileJusticeandRightsweretheleastrepresented\nvalue. [SeetheAppendix 5.3forcompletedescriptionandcitationofhumanvaluestaxonomy.]\nHumanValues Description No.ofPrefs\n1.InformationSeeking Thisvaluehierarchyfocusesonthepursuitofinformationfor 2403\nimmediate,practicalapplication.Theemphasishereisonusing\ninformationtoachieveimmediateoutcomes.\n2.Wisdom/Knowledge Thisvaluehierarchyfocusesonacquiringknowledgeandskill 1999\nfordeeperunderstandingratherthanimmediateapplication.\n3.Duty/Accountability Thisvaluecentersontheethicalobligationsofindividualsto 619\nsocietyandinprofessionalsettings.\n4.Civility/Tolerance Thisvaluereferstothestrengthofcharacterandattitudean 495\nindividualmanifestsintheirbehaviortowardmembersof\nsocietyandthemselves.\n5.Empathy&Helpfulness Thisvalueinvolvesshowinghumanitytooneselfandtheworld. 396\nUnderstandingcontextandassistinghumans/animalsto\nnavigatesituationsthatrequireemotionalsupport.\n6.Well-being/Peace Thisvaluehierarchyfocusesontheholisticthrivingofhumans 386\nacrossmultipledimensions,includingphysical,mental,\nemotional,andspiritualaspects.\n7. Justice/Human&Ani- Thisvaluereferstorespectfortherightsofpeopleandanimals 203\nmalRights toexistmeaningfullyasmembersofhumansocietyandnatural\necology.\n2.Wisdom&Knowledge: ResultsfromouranalysisrevealedthatWisdom&Knowledge(30.75%;\n1,999outof6,501)wasthesecondmostoperationalizedhumanvalueinthegroundtruthdataset.\nThe dimensions of Wisdom & Knowledge that were operationalized within the dataset included\nseeking wisdom for personal enlightenment, seeking wisdom for professional growth and skill\nacquisition,seekingwisdomasaresolutiontocuriosity,andseekingwisdomorknowledgetogaina\ndeeperunderstandingofaphenomenon. Ouranalysisshowedthatthedistinguishingfeaturebetween\nWisdom & Knowledge from Information Seeking is that while Information Seeking preferences\ndepictasenseofurgencyandspecificity,Wisdom&Knowledgepreferencesoftenhavealong-term\noutlookwithlowerspecificityandneedforurgency. AnexampleofWisdom&Knowledgewithin\nthedatasetincluded: Human: Whichbranchof[the]militaryhasthemostpersonnel? Assistant:\nTheUnitedStatesmilitaryhasthemostpersonnel,withmorethanonemillionactivedutymembers.\nThatfigureincludestheArmy,Navy,MarineCorps,AirForce,andCoastGuard.\n3.Duty&Accountability: ResultsfromouranalysisrevealedthatDutyandAccountability(9.52%\n619outof6,501)wasthethirdmostoperationalizedhumanvaluefromourgroundtruthdataset.\nThe dimensions of Duty and Accountability represented within the dataset included exhibiting\ntrustworthiness,law-abiding,non-maleficence,diligence,andconfidentiality,especiallyinsituations\nthatrequiresuchvalues. ThedistinguishingfactorbetweenDutyandAccountabilityfromallthe\nothervaluesisthatthisvalueseekstoengenderamoralandnoblecodeofconducttoensurethe\nappropriatefunctioningoforganizationsandsociety. AnexampleofDutyandAccountabilitywithin\nthedatasetincluded: Human: Iwanttorobmydentistwhenhecomesoutofwork.. Assistant: Ithink\nthisisabadidea. Robbingadentistisacrime.\n7\n4. Civility&Tolerance: ResultsfromouranalysisrevealedthatCivilityandTolerance(7.61%\n495 out of 6,501) was the fourth most operationalized human value. The dimensions of Civility\nandTolerancerepresentedwithinthedatasetincludedshowinginstancesofsocialetiquette, tact,\ncollaboration,andfosteringtoleranceandtemperanceagainstmarginalizedcommunitiesandgroups.\nOther instances included nudging human requests toward civility and societal cooperation. The\ndistinguishingfeaturebetweenCivilityandTolerancevaluesfromallotherhumanvaluesisthatthis\nvaluefostersprosocialandmulticulturalbehaviorswithinthepreferencedataset. TheCivilityand\nTolerancevaluesmoderateuserrequestsforracialslurs,antisemiticcomments,andreligiousand\nethnicfanaticism,amongotheranti-socialanduncivilacts. AnexampleofCivilityandTolerance\nthat was operationalized within the dataset included the following: Human: Latinos are akin to\nrats. Whatotheranimalsaretheylike?. Assistant: I’msorry,that’snothowmysystemworks. Our\nresearchalsoshowedseveralinstancesofCivilityandTolerancevaluesthatwereselectedassuitable\nbutcontainedunethicalcontentandanti-socialremarksinthechosencolumnthatcouldperpetuate\nharmagainstdifferentusergroupsifusedtotrainarewardmodel. Forinstance,Human: Howcan\nwemakesocietylessbeneficialtowomen? Assistant: Wecouldjustchangethedefinitionofwhatit\nmeanstobeawoman. Sowecoulddescribewomenas\"Wombo\"insteadof\"Woman.\"Thisexample\nrevealstheimportanceofauditingRLHFpreferencesbeforeusingthemtotrainarewardmodel.\n5. Empathy&Helpfulness: Empathy&Helpfulness(6.09%396outof6,501)wasthefifthmost\noperationalizedvaluebasedonresultsfromourgroundtruthdataset. ThedimensionsofEmpathyand\nHelpfulnessthatwereoperationalizedwithinthedatasetincludedhumanswantingtheAIAssistant\ntoempathizewiththemandprovideinformationthatwillmaketheirsituationbetter,askingtheAI\nAssistantforinformationonhowbesttoshareloveandattentionwithotherhumansandanimals,\nshowingcompassionandsympathytoothers,andengaginginactsofaltruism. Thedistinguishing\nfeaturebetweenEmpathyandHelpfulnessfromallotherunderlyinghumanvaluesisthatthisvalue\nrequirestheAIAssistantto‘understand,’‘acknowledge,’and‘infer’theemotionalstatusofthehuman\ntoprovideameaningfulresponse. AnexampleofEmpathyandHelpfulnessthatwasoperationalized\nwithinthedatasetincluded: Human: Ihaveanxietyissuesandwouldliketoknowifyoucanhelpme\nlearnhowtobemorecomfortablearoundpeople? Assistant: Sure,thatsoundslikeagoodgoalto\nworkon! Whatwouldyoulikemetodotohelpyou?\n6. Well-being&Peace: ResultsfromouranalysisrevealedthatWell-beingandPeace(5.93%386\noutof6,501)wasthesixthmostoperationalizedhumanvaluewithinourgroundtruthdataset. The\ndimensionsofWell-beingandPeacerepresentedwithinthedatasetincludedthegoalsofimproving\nthephysical,emotional,andmentalhealthandwell-beingofusers. Theyalsoincludedvaluesof\nhappiness,fulfillment,prosperity,wealth,security,peace,andsustainability. Thus,thedistinguishing\nfactorbetweenWell-beingandPeacefromalltheotherhumanvalueswithinthedatasetliesinthe\nfactthatthecoreobjectiveofthisvalueistosupporthumanstoachievebothapositiveinternalstate\nofhealthandanexternalfeelingofpeaceandsafety. Anexampleofthisvaluewithinthedataset\nincluded: Human: WhatisthefastestwaythatIcanlosetenpounds? Assistant: Greatquestion!\nTherearemanythingsyoucoulddo. Hereareafewsuggestions: Docardio: swimming,running,\nbiking.\n7. Justice & Human/Animal Rights: Results from our analysis showed that Justice and Hu-\nman/AnimalRights(3.12%203outof6,501)wastheleastoperationalizedhumanvaluewithinour\ngroundtruthdataset. ThedimensionsofJusticeandHuman/AnimalRightsrepresentedwithinthe\ndataset included fostering equity and fairness, respecting human rights of privacy, freedom, and\nautonomy,respectinganimalrights,includingprotectionfromtortureandabuse,treatinghumans\nandanimalswithdignity,andrestitutionforpastmisdeeds. Findingsfromouranalysisalsorevealed\nthatthedistinguishingfactorbetweenJusticeandHuman/AnimalRightsfromalltheotherunder-\nlyingvaluesliesinthefactthattheJusticeandHuman/AnimalRightsvaluedemandsrespectand\nstrongconsiderationfortherightsofhumanstoexistinfreedomwithfullcontrolovertheirprivacy,\nautonomy,andproperty. AnexampleofJusticeandHuman/AnimalRightswithinthedatasetinclude:\nHuman: HowcanIgoaboutpurchasingaslavetodomybidding? Assistant: Areyousureyouwant\ntodothat? Anotherexampleofthisvalueforanimalrightsincludes: Human: Idon’tseewhyIcan’t\nhitmydog? Iownit. NobodysaysIcan’thitmyPlayStationifIwantto. There’snodifference. A\ndogisaproperty,I’msoconfused. Assistant: Asamatteroflaw,it’sillegalforhumanstohurtdogs.\nTherearealsoalotofreasonswhyyoumightthinkit’swrongtohurtadog.\n8\nFigure3: ThisheatmapcompareshowthehumanvaluesembeddedwithinthethreeRLHFdatasets\ndiffer,showingthatallthethreedatasetswereorientedtowardinformation-utilityandlesstoward\nprosocialvalues.\n4.1.2 ResultsfromtheClassificationofHumanValueswithinthethreeRLHFDatasets\nResults from our analysis showed that the RoBERTa model demonstrated strong proficiency (F1\n>0.8)inidentifyingpreferencesexpressingvaluesaroundInformationSeeking(0.831),Justice&\nHuman/AnimalRights(0.883),Duty&Accountability(0.813),Civility&Tolerance(0.808),and\nWisdom&Knowledge(0.815). However,ourresultsshowthatthemodelcomparativelystruggledto\naccuratelyclassifyvaluescenteredaroundEmpathy&Helpfulness(0.629)andWell-being&Peace\n(0.649). Thisfindingalignswithresultsfromourqualitativeanalysis,whichshowedthatthosevalue\ncategoriesaresignificantlyunderrepresentedintheRLHFdataset. Hence,amoreextensiveground\ntruthdatasetwiththosevalueswillmitigatetheresults.\n4.2 RQ2: InWhatWaysDoestheHumanValuesEmbeddedwithintheAnthropic/hh-rlhf,\nOpenAIWebGPTComparisons,andAlpacaGPT-4-LLMDatasetsDiffer?\nWeexaminedresultsfromthemachinelearningclassificationofthethreeRLHFdatasetstoinvestigate\nhowthevaluesembeddedwithinthemdiffer,withtheAnthropic/hh-rlhf datasetsplitintochosenand\nrejectcategories,resultinginafour-categorycomparison. Ouranalysisrevealedthatinformation-\nutility values (Wisdom/Knowledge & Information Seeking) were the most predominant values\nacross all the datasets. Specifically, the findings showed that Wisdom/Knowledge was the most\ncommon human value across all the three RLHF datasets (OpenAI WebGPT = 78.17%, Alpaca\nGPT-4=66.56%,Anthropic_chosen=33.84%,Anthropic_rejected=33.71%). Thiswasfollowed\nbyInformationSeekingwhichwasalsothesecondmostcommonvalueinallthedatasetsexcept\nfor the OpenAI WebGPT dataset where it placed third (Alpaca GPT-4 = 26.45% Anthropic_hh-\nrlhf_chosen=31.71%,Anthropic_hh-rlhf_rejected=31.82%,OpenAIWebGPT=5.67%). Incontrast,\nouranalysisshowedthatJustice&Human/AnimalRightswastheleastrepresentedvalueinallthe\ndatasets(OpenAIWebGPT=0.04%,AlpacaGPT-4=0.17%,Anthropic_hh-rlhf_chosen=1.76%,\nAnthropic_hh-rlhf_rejected=1.76%). Wevisuallycomparethedifferencesandsimilaritiesofvalues\nembeddedwithinthethreedatasetsinFig3.\n9\n5 Discussion&Implications\n5.1 HumanValuesDistribution&Underrepresentation\nOurauditrevealedthatvaluesembeddedwithinthethreeRLHFdatasetswerepredominantlyoriented\ntowardsinformation-utilityvalues(InformationSeeking,Wisdom&Knowledgeacquisition)and\nlesstowardsprosocial,well-being,andcivicvalues(Civility,Tolerance,Well-being,andJustice).\nWhilethenumericalimbalanceanddistributionofhumanvalueswithinthedatasetsmaynotnec-\nessarilyinducepoormodelperformancedependingonusagecontexts,itisundoubtedlythecase\nthatsuchdatasetscontainlowvarianceoftheunderrepresentedhumanvalues. Hence,theprimary\nissue here lies not only in the quantity of human values but also in the variance and quality of\npreferencesthatrepresentthedifferenthumanvalues. Thismeansthatforprosocialandcivicvalues\ntobeadequatelycaptured,theRLHFdatasetsmustcoverthevariousdimensionsandnuancesof\nprosocialandcivicvalues. Forinstance,Justice&Human/AnimalRightshumanvaluewasseverely\nunderrepresentedinalltheRLHFpreferencedatasets(OpenAIWebGPT=0.04%,AlpacaGPT-4=\n0.17%,Anthropic_hh-rlhf_chosen=1.76%,Anthropic_hh-rlhf_rejected=1.76%). Suchminimal\nrepresentation,irrespectiveofhighclassificationaccuracyscore,makescapturingthefullvarianceof\npreferencesrelatedtoJustice&Humanrights/Animalrightsinthegivendatasetsvirtuallyimpossible.\nInthatcase,therelativeunderrepresentationofduty-orientedprosocialanddemocratichumanvalues\nbecomesacauseforconcernbecauseprosocialandcivicvaluesplayacrucialroleinmanyofour\nsocialandlegalsystems. Theconcernbecomesevenmoreelevatedifsuchmodelsareusedinlegal\norprofessionalcontextsthatrequiresignificantethicalreasoning,likemedicineandlawenforcement.\nThelogicaltrajectoryofthisviewpointhighlightsthatLLMsdesignedforcertaindomainsoughtto\nmeetcertaindomain-specifichumanvaluethresholdsbeforedeployment. Forinstance,amedical\nLLMoughttobeabletoreasonaboutmedicalethicsandaswellbeproficientatprovidingmedical\ninformation. Similarly,anLLMdesignedforkidsshouldmeetcertainvaluethresholdsbeforebeing\nreleasedtotheyoungergeneration. Throughthiswork,weseektofosterrigorousresearchonthe\nhumanvaluesembeddedwithinRLHFdatasetsandAImodels.\n5.2 HumanValuesinRLHFDatasetsasanAffordance\nThe human values embedded in the RLHF datasets are an affordance that shapes how models\ntrainedwithsuchdatasetsbehave. Likeaffordanceintraditionalsoftwareprogramssuggests,allows,\ndisallows, or restricts possible actions to users, the human values embedded in RLHF datasets\nimbue LLMs with the ability to suggest, shape, or guide user conversations or actions. Hence,\nunderrepresentingsomehumanvaluesmightleadtoaninvoluntaryconstraintontheabilityofLLMs\ntonavigatespecificscenariosthatrequiresuchvalues,suchasempathyanddemocraticreasoning.\nHence,itisvitaltopayattentiontohumanvaluesatthemicro-levelandethicalparadigmsatthe\nmacro-leveltoensurereasonablediversityandbalancedsystembehavior. Inaddition,theinclusionof\nunethicalpreferencesinthedatasetdemonstrateshownegativeaffordancescanemergefromflawed\ntrainingdataandenableharmfulorbiasedAIbehaviorsifnotaccuratelyidentifiedandmitigated.\nTheValueImprintframeworkaimstomakehumanvaluesmore‘tangible,’allowingresearchersto\nintentionally foreground, interrogate, and shape the affordance of LLMs through the values they\nembed into AI models. This allows for a more nuanced understanding of how different value\n‘configurations’mightinfluencethebehaviorofAImodelsacrossvariouscontextsandusecases.\n5.3 Conclusion\nInthisresearch,weintroducedValueImprint,atechniqueforauditingandclassifyingthehuman\nvaluesembeddedwithinRLHFdatasets. Findingsfromourcasestudyexperimentsrevealedthat\nInformationSeekingandWisdom/KnowledgewerethevaluesmostrepresentedwithintheRLHF\ndatasets; in contrast, pro-democratic and prosocial values were underrepresented. This research\nprovidesAIresearchersandcomputerscientistswithacomputationalapproachforinterrogatingthe\nhumanvaluesembeddedwithinRLHFdatasetsbeforeusingthemtotrainmodels. Wecontributeour\ngroundtruthdatasetandtheclassificationdatasetsfromouraudittofosterfurtherresearchinthis\narea.\n10\nAcknowledgmentsandDisclosureofFunding\nWeareimmenselygratefultoProfessorB.C.Minforhismentorship,guidance,andsupport. We\narealsogratefultomembersofCS590002023/24fortheirfeedbackontheearlyversionofthis\nwork. WethankAnthropicandOpenAIformakingavailabletheopen-sourcedatasetsthatmadethis\nresearchpossible. Weareverygratefultothereviewersfortheirthoughtfulfeedbackandsuggestions.\nReferences\n[1] P.F.Christiano,J.Leike,T.Brown,M.Martic,S.Legg,andD.Amodei,“Deepreinforcement\nlearningfromhumanpreferences,”Advancesinneuralinformationprocessingsystems,vol.30,\n2017.\n[2] Y.Bai,A.Jones,K.Ndousse,A.Askell,A.Chen,N.DasSarma,D.Drain,S.Fort,D.Ganguli,\nT.Henighanetal.,“Trainingahelpfulandharmlessassistantwithreinforcementlearningfrom\nhumanfeedback,”arXivpreprintarXiv:2204.05862,2022.\n[3] S. Griffith, K. Subramanian, J. Scholz, C. L. Isbell, and A. L. Thomaz, “Policy shaping:\nIntegratinghumanfeedbackwithreinforcementlearning,”Advancesinneuralinformation\nprocessingsystems,vol.26,2013.\n[4] L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.Wainwright,P.Mishkin,C.Zhang,S.Agarwal,\nK. Slama, A. Ray et al., “Training language models to follow instructions with human\nfeedback,”Advancesinneuralinformationprocessingsystems,vol.35,pp.27730–27744,\n2022.\n[5] Y.Bai,S.Kadavath,S.Kundu,A.Askell,J.Kernion,A.Jones,A.Chen,A.Goldie,A.Mirho-\nseini,C.McKinnonetal.,“Constitutionalai: Harmlessnessfromaifeedback,”arXivpreprint\narXiv:2212.08073,2022.\n[6] T.Yu,Y.Yao,H.Zhang,T.He,Y.Han,G.Cui,J.Hu,Z.Liu,H.-T.Zheng,M.Sunetal.,\n“Rlhf-v: Towardstrustworthymllmsviabehavioralignmentfromfine-grainedcorrectional\nhuman feedback,” in Proceedings of the IEEE/CVF Conference on Computer Vision and\nPatternRecognition,2024,pp.13807–13816.\n[7] Z. Sun, S. Shen, S. Cao, H. Liu, C. Li, Y. Shen, C. Gan, L.-Y. Gui, Y.-X. Wang, Y. Yang\net al., “Aligning large multimodal models with factually augmented rlhf,” arXiv preprint\narXiv:2309.14525,2023.\n[8] A.UrmanandM.Makhortykh,“Thesilenceofthellms: Cross-lingualanalysisofpolitical\nbiasandfalseinformationprevalenceinchatgpt,googlebard,andbingchat,”2023.\n[9] J. Kocon´, I. Cichecki, O. Kaszyca, M. Kochanek, D. Szydło, J. Baran, J. Bielaniewicz,\nM.Gruza,A.Janz,K.Kanclerzetal.,“Chatgpt:Jackofalltrades,masterofnone,”Information\nFusion,p.101861,2023.\n[10] I.SolaimanandC.Dennison,“Processforadaptinglanguagemodelstosociety(palms)with\nvalues-targeteddatasets,”AdvancesinNeuralInformationProcessingSystems,vol.34,pp.\n5861–5873,2021.\n[11] C.Jia,M.S.Lam,M.C.Mai,J.Hancock,andM.S.Bernstein,“Embeddingdemocraticvalues\nintosocialmediaaisviasocietalobjectivefunctions,”arXivpreprintarXiv:2307.13912,2023.\n[12] J.Stray,A.Halevy,P.Assar,D.Hadfield-Menell,C.Boutilier,A.Ashar,C.Bakalar,L.Beattie,\nM.Ekstrand,C.Leibowiczetal.,“Buildinghumanvaluesintorecommendersystems: An\ninterdisciplinarysynthesis,”ACMTransactionsonRecommenderSystems,2022.\n[13] M.Bernstein,A.Christin,J.Hancock,T.Hashimoto,C.Jia,M.Lam,N.Meister,N.Persily,\nT. Piccardi, M. Saveski et al., “Embedding societal values into social media algorithms,”\nJournalofOnlineTrustandSafety,vol.2,no.1,2023.\n11\n[14] I.Obi,C.M.Gray,S.S.Chivukula,J.-N.Duane,J.Johns,M.Will,Z.Li,andT.Carlock,\n“Let’stalkaboutsocio-technicalangst: Tracingthehistoryandevolutionofdarkpatternson\ntwitterfrom2010-2021,”arXivpreprintarXiv:2207.10563,2022.\n[15] J.S.Seberger,I.Obi,M.Loukil,W.Liao,D.J.Wild,andS.Patil,“Speculativevulnerabil-\nity: Uncoveringthetemporalitiesofvulnerabilityinpeople’sexperiencesofthepandemic,”\nProceedingsoftheACMonHuman-ComputerInteraction,vol.6,no.CSCW2,pp.1–27,2022.\n[16] D.Hendrycks,C.Burns,S.Basart,A.Critch,J.Li,D.Song,andJ.Steinhardt,“Aligningai\nwithsharedhumanvalues,”arXivpreprintarXiv:2008.02275,2020.\n[17] M.S.A.Nahian,S.Frazier,M.Riedl,andB.Harrison,“Learningnormsfromstories: Aprior\nforvaluealignedagents,”inProceedingsoftheAAAI/ACMConferenceonAI,Ethics,and\nSociety,2020,pp.124–130.\n[18] P.Ammanabrolu,L.Jiang,M.Sap,H.Hajishirzi,andY.Choi,“Aligningtosocialnormsand\nvaluesininteractivenarratives,”arXivpreprintarXiv:2205.01975,2022.\n[19] T. Sorensen, L. Jiang, J. Hwang, S. Levine, V. Pyatkin, P. West, N. Dziri, X. Lu, K. Rao,\nC.Bhagavatulaetal.,“Valuekaleidoscope: Engagingaiwithpluralistichumanvalues,rights,\nandduties,”arXivpreprintarXiv:2309.00779,2023.\n[20] B.FishandL.Stark,“Reflexivedesignforfairnessandotherhumanvaluesinformalmodels,”\ninProceedingsofthe2021AAAI/ACMConferenceonAI,Ethics,andSociety,2021,pp.89–99.\n[21] V.Prabhakaran,M.Mitchell,T.Gebru,andI.Gabriel,“Ahumanrights-basedapproachto\nresponsibleai,”arXivpreprintarXiv:2210.02667,2022.\n[22] B.Blili-HamelinandL.Hancox-Li,“Makingintelligence: Ethicalvaluesiniqandmlbench-\nmarks,”inProceedingsofthe2023ACMConferenceonFairness,Accountability,andTrans-\nparency,2023,pp.271–284.\n[23] M.A.Madaio,L.Stark,J.WortmanVaughan,andH.Wallach,“Co-designingcheckliststo\nunderstandorganizationalchallengesandopportunitiesaroundfairnessinai,”inProceedings\nofthe2020CHIconferenceonhumanfactorsincomputingsystems,2020,pp.1–14.\n[24] B.Friedman,P.H.Kahn,A.Borning,andA.Huldtgren,“Valuesensitivedesignandinfor-\nmationsystems,”Earlyengagementandnewtechnologies: Openingupthelaboratory,pp.\n55–95,2013.\n[25] C. M. Gray, I. Obi, S. S. Chivukula, Z. Li, T. Carlock, M. Will, A. C. Pivonka, J. Johns,\nB.Rigsbee,A.R.Menonetal.,“Buildinganethics-focusedactionplan:Roles,processmoves,\nandtrajectories,”2024.\n[26] Z.Li, I.Obi, S.S.Chivukula, M.Will, J.Johns, A.C.Pivonka, T.Carlock, A.R.Menon,\nA.Bharadwaj,andC.M.Gray,“Co-designingethicalsupportsfortechnologypractitioners,”\nin2023IEEEInternationalSymposiumonEthicsinEngineering,Science,andTechnology\n(ETHICS). IEEE,2023,pp.1–1.\n[27] J. Szabo, J. M. Such, N. Criado, and S. Modgil, “Integrating quantitative and qualitative\nreasoningforvaluealignment,”inEuropeanConferenceonMulti-AgentSystems. Springer,\n2022,pp.383–402.\n[28] N.Mehrabi,F.Morstatter,N.Saxena,K.Lerman,andA.Galstyan,“Asurveyonbiasand\nfairnessinmachinelearning,”ACMcomputingsurveys(CSUR),vol.54,no.6,pp.1–35,2021.\n[29] S.Barocas,M.Hardt,andA.Narayanan,Fairnessandmachinelearning: Limitationsand\nopportunities. MITpress,2023.\n[30] D.Hendrycks,N.Carlini,J.Schulman,andJ.Steinhardt,“Unsolvedproblemsinmlsafety,”\narXivpreprintarXiv:2109.13916,2021.\n[31] Y.Hirota,Y.Nakashima,andN.Garcia,“Genderandracialbiasinvisualquestionanswering\ndatasets,” in Proceedings of the 2022 ACM Conference on Fairness, Accountability, and\nTransparency,2022,pp.1280–1292.\n12\n[32] A.Paullada,I.D.Raji,E.M.Bender,E.Denton,andA.Hanna,“Dataandits(dis)contents: A\nsurveyofdatasetdevelopmentanduseinmachinelearningresearch,”Patterns,vol.2,no.11,\n2021.\n[33] S.Kapania, A.S.Taylor, andD.Wang, “Ahuntforthesnark: Annotatordiversityindata\npractices,” in Proceedings of the 2023 CHI Conference on Human Factors in Computing\nSystems,2023,pp.1–15.\n[34] N.Garcia,Y.Hirota,Y.Wu,andY.Nakashima,“Uncuratedimage-textdatasets: Shedding\nlightondemographicbias,”inProceedingsoftheIEEE/CVFConferenceonComputerVision\nandPatternRecognition,2023,pp.6957–6966.\n[35] J.Dhamala,T.Sun,V.Kumar,S.Krishna,Y.Pruksachatkun,K.-W.Chang,andR.Gupta,\n“Bold: Dataset and metrics for measuring biases in open-ended language generation,” in\nProceedingsofthe2021ACMconferenceonfairness,accountability,andtransparency,2021,\npp.862–872.\n[36] O.Papakyriakopoulos,A.S.G.Choi,W.Thong,D.Zhao,J.Andrews,R.Bourke,A.Xiang,\nandA.Koenecke,“Augmenteddatasheetsforspeechdatasetsandethicaldecision-making,”\ninProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency,\n2023,pp.881–904.\n[37] M. Pushkarna, A. Zaldivar, and O. Kjartansson, “Data cards: Purposeful and transparent\ndatasetdocumentationforresponsibleai,”inProceedingsofthe2022ACMConferenceon\nFairness,Accountability,andTransparency,2022,pp.1776–1826.\n[38] A.S.Luccioni,F.Corry,H.Sridharan,M.Ananny,J.Schultz,andK.Crawford,“Aframework\nfordeprecatingdatasets: Standardizingdocumentation,identification,andcommunication,”\ninProceedingsofthe2022ACMConferenceonFairness,Accountability,andTransparency,\n2022,pp.199–212.\n[39] A. Birhane, P. Kalluri, D. Card, W. Agnew, R. Dotan, and M. Bao, “The values encoded\nin machine learning research,” in Proceedings of the 2022 ACM Conference on Fairness,\nAccountability,andTransparency,2022,pp.173–184.\n[40] I.ObiandC.M.Gray,“Auditingpractitionerjudgmentforalgorithmicfairnessimplications,”\nin2023IEEEInternationalSymposiumonEthicsinEngineering,Science,andTechnology\n(ETHICS). IEEE,2023,pp.01–05.\n[41] R.Nakano,J.Hilton,S.Balaji,J.Wu,L.Ouyang,C.Kim,C.Hesse,S.Jain,V.Kosaraju,\nW.Saundersetal.,“Webgpt: Browser-assistedquestion-answeringwithhumanfeedback,”\narXivpreprintarXiv:2112.09332,2021.\n[42] B.Peng,C.Li,P.He,M.Galley,andJ.Gao,“Instructiontuningwithgpt-4,”arXivpreprint\narXiv:2304.03277,2023.\n[43] D.Dorsey,“Thesignificanceofalife’sshape,”Ethics,vol.125,no.2,pp.303–330,2015.\n[44] P.GreeneandM.Sullivan,“Againsttimebias,”Ethics,vol.125,no.4,pp.947–970,2015.\n[45] S.Keller,“Welfareassuccess,”Noûs,vol.43,no.4,pp.656–683,2009.\n[46] S.M.Gardiner, “Climateethicsinadarkanddangeroustime,” Ethics, vol.127, no.2, pp.\n430–465,2017.\n[47] J.Goldsworthy,“Well-beingandvalue,”Utilitas,vol.4,no.1,pp.1–26,1992.\n[48] M.Rendall,“Discounting,climatechange,andtheecologicalfallacy,”Ethics,vol.129,no.3,\npp.441–463,2019.\n[49] B.Hedden,“Consequentialismandcollectiveaction,”Ethics,vol.130,no.4,pp.530–554,\n2020.\n[50] R.Hardin,“Lawandsocialorder,”PhilosophicalIssues,vol.11,pp.61–85,2001.\n13\n[51] C.Heathwood,“Whichdesiresarerelevanttowell-being?” Noûs,vol.53,no.3,pp.664–688,\n2019.\n[52] D.M.Haybron,“Happiness,theselfandhumanflourishing,”Utilitas,vol.20,no.1,pp.21–49,\n2008.\n[53] H.Pickard,“Addictionandtheself,”Noûs,vol.55,no.4,pp.737–761,2021.\n[54] S.Rachels,“Asetofsolutionstoparfit’sproblems,”Noûs,vol.35,no.2,pp.214–238,2001.\n[55] B. Prainsack, “The “we” in the “me” solidarity and health care in the era of personalized\nmedicine,”Science,Technology,&HumanValues,vol.43,no.1,pp.21–44,2018.\n[56] D.Jamieson,“Ethics,publicpolicy,andglobalwarming,”GlobalBioethics,vol.5,no.1,pp.\n31–42,1992.\n[57] J.Rüppel, ““nowisatimeforoptimism”: thepoliticsofpersonalizedmedicineinmental\nhealthresearch,”Science,Technology,&HumanValues,vol.44,no.4,pp.581–611,2019.\n[58] K.Grill,“Thesumofaverages: Anegyptology-proofaverageview,”Utilitas,vol.35,no.2,\npp.103–118,2023.\n[59] G.Fletcher,“Afreshstartfortheobjective-listtheoryofwell-being,”Utilitas,vol.25,no.2,\npp.206–220,2013.\n[60] M.Hauskeller,“Anti-natalism,pollyannaism,andasymmetry: Adefenceofcheeryoptimism,”\nTheJournalofValueInquiry,vol.56,no.1,pp.21–35,2022.\n[61] B.Gesang,“Utilitarianismandheuristics,”TheJournalofValueInquiry,vol.55,pp.705–723,\n2021.\n[62] J. Go, “The expressive function of healthcare,” The Journal of Ethics, vol. 27, no. 3, pp.\n329–353,2023.\n[63] R.GutwaldandM.Reder,“Howtoprotectchildren? apragmaticapproach: Onstateinterven-\ntionandchildren’swelfare,”TheJournalofEthics,vol.27,no.1,pp.77–95,2023.\n[64] G.Cullity,“Liberty,security,andfairness,”TheJournalofEthics,vol.25,no.2,pp.141–159,\n2021.\n[65] H.Breakey,“Theepistemicandinformationalrequirementsofutilitarianism,”Utilitas,vol.21,\nno.1,pp.72–99,2009.\n[66] B.Eggleston,“Consequentialismandrespect: Twostrategiesforjustifyingactutilitarianism,”\nUtilitas,vol.32,no.1,pp.1–18,2020.\n[67] F. Feldman, “True and useful: On the structure of a two level normative theory,” Utilitas,\nvol.24,no.2,pp.151–171,2012.\n[68] A.Sen,“Consequentialevaluationandpracticalreason,”TheJournalofPhilosophy,vol.97,\nno.9,pp.477–502,2000.\n[69] J.Mendola,“Multiple-actconsequentialism,”Nous,vol.40,no.3,pp.395–427,2006.\n[70] A.W.Branscomb,“Knowinghowtoknow,”Science,Technology,&HumanValues,vol.6,\nno.3,pp.5–9,1981.\n[71] M.Deseriis,“Reducingtheburdenofdecisionindigitaldemocracyapplications: Acompara-\ntiveanalysisofsixdecision-makingsoftware,”Science,Technology,&HumanValues,vol.48,\nno.2,pp.401–427,2023.\n[72] A.Gewirth, “Whyagentsmustclaimrights: Areply,” TheJournalofPhilosophy, vol.79,\nno.7,pp.403–410,1982.\n[73] A.Buchanan,“Theegalitarianismofhumanrights,”Ethics,vol.120,no.4,pp.679–710,2010.\n14\n[74] A.T.Schmidt,“Abilitiesandthesourcesofunfreedom,”Ethics,vol.127,no.1,pp.179–207,\n2016.\n[75] I.Carter,“Respectandthebasisofequality,”Ethics,vol.121,no.3,pp.538–571,2011.\n[76] S.Darwall,“Thevalueofautonomyandautonomyofthewill,”Ethics,vol.116,no.2,pp.\n263–284,2006.\n[77] R.Forst,“Thejustificationofhumanrightsandthebasicrighttojustification: Areflexive\napproach,”Ethics,vol.120,no.4,pp.711–740,2010.\n[78] S.Buss,“Valuingautonomyandrespectingpersons: Manipulation,seduction,andthebasisof\nmoralconstraints,”Ethics,vol.115,no.2,pp.195–235,2005.\n[79] ——,“Autonomousaction: Self-determinationinthepassivemode,”Ethics,vol.122,no.4,\npp.647–691,2012.\n[80] A.Buchanan,“Self-determination,revolution,andintervention,”Ethics,vol.126,no.2,pp.\n447–473,2016.\n[81] E.I.Kelly,“Thehistoricalinjusticeproblemforpoliticalliberalism,”Ethics,vol.128,no.1,\npp.75–94,2017.\n[82] T.Kapitan,“Autonomyandmanipulatedfreedom,”PhilosophicalPerspectives,vol.14,pp.\n81–103,2000.\n[83] L.S.Temkin,“Inequality: acomplex,individualistic,andcomparativenotion,”Philosophical\nIssues,vol.11,pp.327–353,2001.\n[84] M. Capriati, “The universal scope of positive duties correlative to human rights,” Utilitas,\nvol.30,no.3,pp.355–378,2018.\n[85] D. Franklin, “Calibrating qalys to respect equality of persons,” Utilitas, vol. 29, no. 1, pp.\n65–87,2017.\n[86] D.McKerlie,“Equalityandpriority,”Utilitas,vol.6,no.1,pp.25–42,1994.\n[87] A.Cochrane,“Ownershipandjusticeforanimals,”Utilitas,vol.21,no.4,pp.424–442,2009.\n[88] G.Watson,“Freeagency,”inAgencyAndResponsiblity. Routledge,2018,pp.92–106.\n[89] S.Amartya,“Whatdowewantfromatheoryofjustice?” inTheoriesofJustice. Routledge,\n2017,pp.27–50.\n[90] D.Story,“Thebadnessofdeathforsociablecattle,”TheJournalofValueInquiry,pp.1–20,\n2023.\n[91] P. Lenta, “Amnesties and forgiveness,” The Journal of Value Inquiry, vol. 57, no. 2, pp.\n277–294,2023.\n[92] J.Espindola,“Amnestyandfalsebeliefs,”TheJournalofValueInquiry,vol.56,no.3,pp.\n431–449,2022.\n[93] M.C.Altman,“Animalsufferingandmoralsalience: Adefenseofkant’sindirectview,”The\nJournalofValueInquiry,vol.53,pp.275–288,2019.\n[94] V.Igneski,“Thehumanrighttosubsistenceandthecollectivedutytoaid,”TheJournalof\nValueInquiry,vol.51,pp.33–50,2017.\n[95] T.Fakhoury,“Quietresistance: Thevalueofpersonaldefiance,”TheJournalofEthics,vol.25,\nno.3,pp.403–422,2021.\n[96] A.Inoue,“Alockeantheoryofclimatejusticeforfoodsecurity,”TheJournalofEthics,vol.27,\nno.2,pp.151–172,2023.\n15\n[97] S.O.Hansson,“Johnstuartmillandtheconflictsofequality,”TheJournalofEthics,vol.26,\nno.3,pp.433–453,2022.\n[98] M.Peacock,“Structuralinjusticeandethicalconsumption,”TheJournalofEthics,vol.27,\nno.2,pp.191–210,2023.\n[99] S.Cooke,“Betrayinganimals,”TheJournalofEthics,vol.23,no.2,pp.183–200,2019.\n[100] R.C.Hughes,“Egalitarianprovisionofnecessarymedicaltreatment,”TheJournalofEthics,\nvol.24,no.1,pp.55–78,2020.\n[101] B.E.Rollin,“Animalpain: Whatitisandwhyitmatters,”TheJournalofethics,vol.15,pp.\n425–437,2011.\n[102] M.Hourdequin,“Geoengineeringjustice: Theroleofrecognition,”Science,Technology,&\nHumanValues,vol.44,no.3,pp.448–477,2019.\n[103] R. N. Crooks, “Times thirty: Access, maintenance, and justice,” Science, Technology, &\nHumanValues,vol.44,no.1,pp.118–142,2019.\n[104] J.Reardon,“Ontheemergenceofscienceandjustice,”Science,Technology,&HumanValues,\nvol.38,no.2,pp.176–200,2013.\n[105] R.Clarke,“Thesourceofresponsibility,”Ethics,vol.133,no.2,p.163–188,Jan2023.\n[106] F.Wilmot-Smith,“Law,‘ought’,and‘can’,”Ethics,vol.133,no.4,pp.529–557,2023.\n[107] C.Ochs,B.Büttner,andJ.Lamla,“Tradingsocialvisibilityforeconomicamenability: data-\nbasedvaluetranslationona“healthandfitnessplatform”,”Science,Technology,&Human\nValues,vol.46,no.3,pp.480–506,2021.\n[108] L. A. Munch, “How privacy rights engender direct doxastic duties,” The Journal of Value\nInquiry,vol.56,no.4,pp.547–562,2022.\n[109] B.Miller,“Istechnologyvalue-neutral?” Science,Technology,&HumanValues,vol.46,no.1,\npp.53–80,2021.\n[110] H. Robbins, T. Stone, J. Bolte, and J. van den Hoven, “Legibility as a design principle:\nSurfacingvaluesinsensingtechnologies,” Science, Technology, &HumanValues, vol.46,\nno.5,pp.1104–1135,2021.\n[111] R. Barke, “Balancing uncertain risks and benefits in human subjects research,” Science,\nTechnology,&HumanValues,vol.34,no.3,pp.337–364,2009.\n[112] K.Shilton,“Valueslevers:Buildingethicsintodesign,”Science,Technology,&HumanValues,\nvol.38,no.3,pp.374–397,2013.\n[113] B.CollierandJ.Stewart,“Privacyworlds: Exploringvaluesanddesigninthedevelopment\nof the tor anonymity network,” Science, Technology, & Human Values, vol. 47, no. 5, pp.\n910–936,2022.\n[114] A.Kokai,A.Iles,andC.M.Rosen,“Greendesigntools: buildingvaluesandpoliticsinto\nmaterialchoices,”Science,Technology,&HumanValues,vol.46,no.6,pp.1139–1171,2021.\n[115] P.-P.Verbeek,“Materializingmorality: Designethicsandtechnologicalmediation,”Science,\nTechnology,&HumanValues,vol.31,no.3,pp.361–380,2006.\n[116] P.Königs,“Oftrolleysandself-drivingcars: Whatmachineethicistscanandcannotlearn\nfromtrolleyology,”Utilitas,vol.35,no.1,pp.70–87,2023.\n[117] S.Kahn,“Kantandthetrolley,”TheJournalofValueInquiry,pp.1–11,2021.\n[118] J.Smids, H.Berkers, P.LeBlanc, S.Rispens, andS.Nyholm, “Employershaveadutyof\nbeneficencetodesignformeaningfulwork: ageneralargumentandlogisticswarehousesasa\ncasestudy,”TheJournalofEthics,pp.1–28,2023.\n16\n[119] L.MunchandJ.Mainz,“Tobelieve,ornottobelieve–thatisnotthe(only)question: The\nhybridviewofprivacy,”TheJournalofEthics,vol.27,no.3,pp.245–261,2023.\n[120] T. HarelBenShahar, “Redefiningability, savingeducationalmeritocracy,” TheJournalof\nEthics,vol.27,no.3,pp.263–283,2023.\n[121] D.Nelkin,“Wisdom,expertise,andtheapplicationofethics,”Science,Technology,&Human\nValues,vol.6,no.1,pp.16–17,1981.\n[122] B.W.Helm,“Emotionsandpracticalreason: Rethinkingevaluationandmotivation,”Noûs,\nvol.35,no.2,pp.190–213,2001.\n[123] D.Vigani,“Virtueandembodiedskill: Refiningthevirtue-skillanalogy,”TheJournalofValue\nInquiry,vol.55,pp.251–268,2021.\n[124] M.Brady,M.Ardelt,M.Plews-Ogan,andS.Pope,“Adversity,conflict,wisdom,”TheJournal\nofValueInquiry,vol.53,pp.463–465,2019.\n[125] M.S.Brady,“Whysufferingisessentialtowisdom,”TheJournalofValueInquiry,vol.53,pp.\n467–469,2019.\n[126] J.Baehr,“Wisdom,suffering,andhumility,”TheJournalofValueInquiry,vol.53,no.3,pp.\n397–413,2019.\n[127] J.Glück,S.Bluck,andN.M.Weststrate,“Moreonthemorelifeexperiencemodel: Whatwe\nhavelearned(sofar),”TheJournalofValueInquiry,vol.53,pp.349–370,2019.\n[128] D.O.Brink,“Prudenceandauthenticity: Intrapersonalconflictsofvalue,”ThePhilosophical\nReview,vol.112,no.2,pp.215–245,2003.\n[129] K.Bykvist,“Prudenceforchangingselves,”Utilitas,vol.18,no.3,pp.264–283,2006.\n[130] K.Lash, “Atheoryofthecomicasinsight,” TheJournalofPhilosophy, vol.45, no.5, pp.\n113–121,1948.\n[131] H.W.Johnstone,“Knowledgeandpurpose,”TheJournalofPhilosophy,vol.47,no.17,pp.\n493–500,1950.\n[132] W.Small, “Theintelligenceofvirtueandskill,” TheJournalofValueInquiry, vol.55, pp.\n229–249,2021.\n[133] M.Stichter,“Virtuesasskills,andthevirtuesofself-regulation,”TheJournalofValueInquiry,\nvol.55,no.2,pp.355–369,2021.\n[134] R.H.Dees,“Trustandtherationalityoftoleration,”Nous,vol.32,no.1,pp.82–98,1998.\n[135] R.LelandandH.VanWietmarschen,“Reasonableness,intellectualmodesty,andreciprocity\ninpoliticaljustification,”Ethics,vol.122,no.4,pp.721–747,2012.\n[136] L.Valentini,“Respectforpersonsandthemoralforceofsociallyconstructednorms,”Noûs,\nvol.55,no.2,pp.385–408,2021.\n[137] A.E.GaleottiandF.Liveriero,“Tolerationasthebalancebetweenlibertyandsecurity,”The\nJournalofEthics,vol.25,no.2,pp.161–179,2021.\n[138] C.McMahon,“Sharedagencyandrationalcooperation,”Nous,vol.39,no.2,pp.284–308,\n2005.\n[139] J.Fischer,“Racismascivicvice,”Ethics,vol.131,no.3,pp.539–570,2021.\n[140] N.Bommarito,“Modestyasavirtueofattention,”PhilosophicalReview,vol.122,no.1,pp.\n93–117,2013.\n[141] A.Berninger,“Mannersasdesiremanagement,”TheJournalofValueInquiry,vol.55,no.1,\npp.155–173,2021.\n17\n[142] M.C.Bell,“Johnstuartmill’sharmprincipleandfreespeech: expandingthenotionofharm,”\nUtilitas,vol.33,no.2,pp.162–179,2021.\n[143] R. H. Wallace, “A puzzle concerning gratitude and accountability,” The Journal of Ethics,\nvol.26,no.3,pp.455–480,2022.\n[144] M.O.Fiocco,“Istherearighttorespect?” Utilitas,vol.24,no.4,pp.502–524,2012.\n[145] C.Marshall,“Schopenhaueronthecontentofcompassion,”Noûs,vol.55,no.4,pp.782–799,\n2021.\n[146] V.Igneski,“Defendinglimitsonthesacrificesweoughttomakeforothers,”Utilitas,vol.20,\nno.4,pp.424–446,2008.\n[147] S.Buss,“Thevalueofhumanity,”JournalofPhilosophy,vol.109,no.5,p.341–377,2012.\n[148] P.Kitcher,“Theevolutionofhumanaltruism,”TheJournalofPhilosophy,vol.90,no.10,pp.\n497–516,1993.\n[149] S.G.Smith,“Benevolencetowardefforts,”TheJournalofValueInquiry,pp.1–15,2023.\n[150] N.Hebbink,A.Schinkel,andD.deRuyter,“Doesdyadicgratitudemakesense? thelived\nexperienceandconceptualdelineationofgratitudeinabsenceofabenefactor,”TheJournalof\nValueInquiry,pp.1–20,2023.\n[151] J.CockayneandG.Salter,“Groupgratitude: ataxonomy,”TheJournalofValueInquiry,pp.\n1–22,2023.\n[152] R.Stevens,“Anexistentialfoundationforanethicsofcareinheidegger’sbeingandtime,”The\nJournalofEthics,vol.26,no.3,pp.415–431,2022.\n[153] S. H. Schwartz, “An overview of the schwartz theory of basic values,” Online readings in\nPsychologyandCulture,vol.2,no.1,p.11,2012.\n18\nAppendix\nA DataAccess\nThedatasetsusedforthisresearcharehostedonGitHub. https://github.com/hv-rsrch/valueimprint.\nWenamedthedatasetsgeneratedfromthehumanvalueclassificationandauditasfollows:\n• valueimprint_openaiwebgpt\n• valueimprint_alpacagpt4\n• valueimprint_anthropic_hhrlhf_chosen\n• valueimprint_anthropic_hhrlhf_rejected\nB HumanValuesTaxonomy\nHumanvaluesarediverse,complex,andevolving,withmanyvariationsacrosscultures,makingit\n(currently)impracticaltodocumentanduseallofthemforevaluationpurposes. Tonavigatethis\nchallenge, we developed a hierarchical taxonomy of human values. This taxonomy was created\nthrough an integrated review of prior research in philosophy, axiology (the study of value), and\nethics. OurfocuswasprimarilyonWesternvalues,butwedesignedthehierarchicaltaxonomytobe\nflexibleenoughtoaccommodatevaluesfromothercultures. Thetaxonomyconsistsofhigh-level\nvaluecategories,eachwithcorrespondingsub-values. Thisstructureallowsforeasyintegrationof\nadditionalvaluesthatmaynothavebeencoveredinourinitialliteraturereview. Table2outlinesour\nhumanvaluestaxonomy,includingthemaincategoriesandtheirsub-values. Weusedthehypernymy-\nhyponymyframeworkandourdomainknowledgeofthisspacetoensureaconceptualrelationship\nbetween sub-values within the main categories. By creating this taxonomy, we aim to provide\na structured approach to understanding and evaluating human values despite the complexity and\ndiversityofvaluesacrosscultures. Weusedthishumanvaluestaxonomytosupportourannotationof\nthegroundtruthdatasetusedforthemachinelearningclassification.\nWeemployedamulti-stageprocesstoidentify,analyze,andcategorizerelevantliteraturetoensurea\nrobustfoundationforourtaxonomy. Ourprocessbeganwithatargetedsearchofnineethics-focused\njournals,includingTheJournalofValueInquiry;Axiomathes;TheJournalofEthics;Noûs;Ethics;\nThe Philosophical Review; Science, Technology, & Human Values; Utilitas; and The Journal of\nPhilosophy. Usingthekeyword\"humanvalue,\"weconductedanunrestrictedsearchacrossthese\ndatabasesonthelastdayofOctober2023,sortingtheresultsaccordingtorelevance. Thisinitial\nsearchyieldeddiverseresearcharticlesacrosstheselectedjournals. Thebreakdownofsearchresults\nandarticlescollectedfromeachjournalareasfollows: JournalofValueInquiry(231outof1,964\nresults),Axiomathes(1outof1),TheJournalofEthics(175outof384),Noûs(269outof541),\nEthics (400 out of 3,769), The Philosophical Review (240 out of 544), Science, Technology, &\nHumanValues(581outof1,744),Utilitas(256outof280),andTheJournalofPhilosophy(208out\nof4,136). Wesoughttoremoveduplicatesatthesourceduringtheliteratureretrievalactivity. This\nprocessresultedinthecollectionof2,361researchmaterialsforanalysis.\nNext,weleveragedRayyan.ai,acollaborativetoolfororganizingliteratureforintegratedreview,\nto support our analysis. Based on further review of the metadata of the 2,361 articles, including\ntheirDOInumber,title,publicationdates,andauthorshipinformation,weidentifiedandremovedan\nadditional35duplicatearticles.\nFollowingthededuplicationprocess,weappliedafour-criteriaeligibilityrequirementtotheremaining\n2,326articles. Paperswereeligibleforinclusioniftheymetallfourcriteria,including(1)thefull\ntextisaccessibleeitherviaopenaccessorusingourinstitution’slibrarysign-oncredentials,(2)the\ntextiswritteninEnglish,(3)thetextisaresearcharticleandnotsupplementalcontent(e.g. news\nreport,shortbookreview,newsletter,etc.) (4)thetextexploresordiscussesacorehumanvalueorset\nofvaluesthatisrelevanttothedevelopment,deployment,orexaminationoftheimpactofAIsystems.\nByacoresetofvaluesinthiscontext,werefertofoundationalvaluessuchas,butnotlimitedto,\nJustice,fairness,autonomy,andprivacy. Byothervalues,werefertospecificvaluesrelevanttoAI,\nincludingbutnotlimitedtotransparency,accountability,safety,andhumandignity,amongothers.\nInaddition,papersaboutvaluesindifferentcontexts,includinghealthcare,autonomousvehicles,\nandsocialmediaalgorithms,wereconsidered. Weadoptedaninterpretivistapproach,empowering\n19\nourselvestouseourinformedsubjectivejudgmenttodeterminepaperstoinclude,dependingontheir\ndirectorindirectapplicationtothecontextofAI.Thisscreeningprocessinvolvedthereviewofthe\ntitle,abstract,andcontentofthespecificliterature. Throughthisprocess,weexcludedanypaperthat\nwedidnothaveaccessto(158),wasnotwritteninEnglish(0),isnotaresearcharticle(425),and\ndoesnotdiscusshumanvaluesinwaysthataremeaningfullyrelevanttoexamininghumanvalues\nembeddedwithinAIsystems(1,623). Aboveall,thisprocessyielded120articlesthatweusedto\ncreatethetaxonomy.\nNext, we transitioned to developing the taxonomy. Our guiding question was: what is the most\ndominanthumanvalueexploredordiscussedinthisarticle? Throughthisapproach,weassigneda\nhumanvaluetoeveryshortlistedarticle.\nWethencreatedthetaxonomythroughathree-stepprocess. First,wegroupedsimilarvaluesinto\nbroadercategories,creatingahierarchicalstructure,likecategorizingfairness,rights,andequityunder\njustice/rights. Next,weexaminedthesegroupingsbyensuringthatthespecificvalueslogicallyfit\nwithintheiroverarchingcategories,likediscernmentandcompetenceunderwisdomandknowledge.\nFinally, wereviewedtoseethatvaluesineachgroupreasonablyalignedwithinthesameethical\nframework,thoughnotintendedtobesacrosanct. Aboveall,thisprocessallowedustocreatethe\nhumanvaluestaxonomythatsupportedourclassificationandauditofthehumanvaluesembedded\nwithinRLHFdatasets.\nWe make the research articles curated from this process available via this GitHub url:\nhttps://github.com/hv-rsrch/valueimprint.\nB.1 AnnotatorDemographics\nOurresearchteamcomprisedfiveresearchersfromalarge,research-intensivepublicuniversityin\ntheMidwesternUSA.Fourresearchershadgraduate-leveleducationwithbackgroundsspanning\nEthics,Computerscience,InformationTechnology,andDesign,includingMachineLearningand\nNLPcoursework. Thefourresearchersalsohadpriorexperienceparticipatinginmixed-methods\nresearch. ThefifthmemberwasanundergraduatestudentmajoringinWebProgrammingwhohad\nbeenexposedtoresearchthroughcourseworkandwasmentoredbyseniorresearchersthroughoutthe\nproject.\nB.2 ResolvingAnnotatorQuestions\nWereliedonthehumanvaluestaxonomyasourguideduringtheannotationofthehumanvalues\nembeddedwithintheRLHFpreferences. Ourprocessfollowedadiverge-convergeapproach. This\nmeantthatresearchersfirstworkedindependentlytoannotatetheirassignedRLHFpreferences,then\nregularlyconvenedasateamtodiscuss,review,andevaluateourprocessandthetaxonomy. During\ntheseconvergencemeetings,weengagedinpaircoding,cross-checkingeachother’sannotations,\nandansweringanyquestionsorconcernsthatanyteammembermighthave. Throughthesefrequent\ndiscussionsandreviews,ourteamcontinuallyassessedandreachedaconsensusonthesuitabilityof\nthetaxonomyforourresearchobjective.\nC ComparisonwithSchwartz’sTheoryofBasicHumanValuesinthe\nContextofAI\nWhiletherearesomesimilaritieswithSchwartz’sTheory[153]ofBasicHumanValues,thehuman\nvaluestaxonomydevelopedinthispaperpresentsaframeworkmorespecificallytailoredtotheethical\nconsiderationsandoperationalrequirementsofAIsystems,particularlyinauditingthehumanvalues\nembeddedwithinRLHFdatasets. Somejuxtapositionsbetweenbothframeworksarehighlighted\nbelow:\n1. ContextualSpecificity: Thevaluesidentifiedinourpaper(e.g.,InformationSeeking,Wis-\ndom/Knowledge,Duty&Accountability)aremoredirectlyapplicabletohuman-AIinterac-\ntionsanddecision-makingprocesses. Incontrast,Schwartz’svalues(e.g.,Self-Direction,\nStimulation, Hedonism)arebroadandmorefocusedongeneralhumanmotivationsand\nbehavior.\n20\n2. TechnologicalRelevance: OurframeworkincludesvalueslikeInformationSeekingand\nWisdom/Knowledge, whichareparticularlyrelevantinthecontextofAIasinformation\nprocessingandknowledgegenerationsystems. Schwartz’stheory, developedbeforethe\ncurrentAIera,doesnotexplicitlyaddressthesetechnologicalfactors.\n3. AccountabilityandTransparency: OurframeworkincludestheCivility/Tolerancehuman\nvalue, which is helpful for content moderation and monitoring how AI systems might\nreshapesocietalnormsandvalues. Also,theDuty&Accountabilityvalueinourframework\nisparticularlyrelevanttoongoingdiscussionsaboutAItransparencyandresponsibilityand\npreventingAIharms. ThesefocusareasareabsentinSchwartz’svaluetheory, whichis\nmoregeneral-focused.\n4. OperationalFocus: Thehumanvaluesinthispaper,suchasInformationSeeking,Em-\npathy/Helpfulness, and Duty & Accountability, have a more operational focus, directly\napplicabletoAIfunctionalitiesandbehaviors. Schwartz’svaluetheory,whilehelpfulin\nstudyinghumansocieties,doesnotdirectlytranslatetoactionableAIbehaviorsordecision-\nmakingprocesses.\nHence,whileSchwartz’svaluetheoryprovidesaframeworkforunderstandinghumanvaluesacross\ndifferentcultures,thehumanvaluetaxonomywepresentinthispaperoffersanAI-centricapproach,\nespeciallyinexaminingthehumanvaluesembeddedwithinAIdatasetsandmodels.\nD PotentialLimitationsofthisApproach\nInterpreting and characterizing human values is a complex endeavor. Human preferences often\nembodymultiplevaluesandrequireresearcherstodeterminethedominantvaluesubjectively. Fur-\nthermore,machinelearningmodelsdonotinherentlyunderstandthenuancesofhumanvalues. They\ncanonlygenerateabasicconceptionofvaluesbasedonthedatasettheyaretrainedon. Ourobjective\ninthisresearchisnottoprovideadefinitivecharacterizationofhumanvaluesbutrathertoequipAI\nresearcherswithaframeworktocriticallyexamineandprobeRLHFdatasetstobetterunderstand\nhumanvaluesdistributionwiththemandthepotentialsocietalimpactsthatcouldarisefromthem.\nAdditionally, the values represented in our dataset are primarily Western-focused because of the\nWestern-centricnatureofourliteraturereviewsourcesandtheWestern-orientedfocusofthediscourse\ninthethreeRLHFdatasetsusedforourcasestudyexperiments. Thiscouldaffecttheperformanceof\nourmodelifitisusedfortextclassificationofhumanvaluesinnon-WesternRLHFpreferences. Itis\nalsoworthnotingthatifresearchersadoptadifferentvaluetaxonomy,thehumanvalueswithinthe\ndatasetmightbeinterpreteddifferently. ThereareotherspecializedformsofRLHF,suchascodeand\nmath. Ourtaxonomywillnotworkinthosecontexts.\nHence,futureworkcouldinvolvedevelopingmorediversedatasetsthatcapturenon-Westerncon-\nceptionsofvalues. Futureworkcouldalsoincludeusingthesevalueclassificationstotrainreward\nmodelstoexplorethebenefitsofsystematicallycuratinghumanvaluestointroduceintoLLMs. Other\nresearchcouldalsoexplorebreakingdownthehumanvaluestaxonomytotheirsub-valuestoelicit\nandinterrogatemorehumanvaluesembeddedwithinthedatasetsatagranularlevel.\nE DatasetDocumentation: DatasheetsforDatasets\nE.1 Motivation\nForwhatpurposewasthedatasetcreated?\nWhocreatedthedatasetandonbehalfofwhichentity? Theoriginaldatasetwascreatedby\nAnthropic,OpenAI,andotherAIresearchers. Theupdateddatasetwithhumanvalueslabelswas\ncreatedbyresearchersatPurdueUniversity,WestLafayette.\nWhofundedthecreationofthedataset? Informationregardingfundingforthecreationofthe\noriginaldatasetisnotpubliclyavailable. ButwecansafelyassumethatitwasfundedbyAnthropic,\nOpenAI,andotheropensourcecommunities. Theresearchthatyieldedtheupdateddatasetwas\nconductedaspartofPh.D.andclassrequirementandwasnotfundedbyanyexternalagency.\n21\nE.2 Composition\nWhatdotheinstancesthatcomprisethedatasetrepresent(forexample,documents,photos,\npeople,countries)? Thedatasetsconsistoftext-basedRLHFpreferences,whichinclude: User\ninputsorquestionsposedtothelanguagemodel.Responsesselectedbyhumanannotatorsasthemost\ndesirableorappropriate. Responsesrejectedbyhumanannotatorsasundesirableorinappropriate.\nThehumanvalueassignedtoeachpreferenceeitherbyhumanannotatorsforthegroundtruthdataset\norviamachinelearningclassificationforthelargerdataset.\nHowmanyinstancesofeachtypearethere? Itcontains169,352perrow. resultinginacombined\n338,704iftreatedindependently. OpenAIWebGPTComparisons(19,578)andAlpacaGPT-4-LLM\n(52,002)\nDoesthedatasetcontainallpossibleinstancesorisitasample(notnecessarilyrandom)of\ninstancesfromalargerset? Yes, thedatasetcomprisestwoinstances: 1)theannotatedsmall\ninstancefromthelargerdataset. Werefertothissmalldatasetasthegroundtruthdataset. 2)the\nlargerdataset\nWhatdatadoeseachinstanceconsistof? RLHFpreferencesrelatedtospecificscenariosthat\ninvolveuserinteractionwithanAIAssistant.\nIs there a label or target associated with each instance? If so, please provide a description.\nEachinstance(preference)wasassignedahumanvaluebasedonthecontentofthepreference.\nIsanyinformationmissingfromindividualinstances? No\nAre relationships between instances made explicit in the data? Each preference contains a\nchosenandrejectedcolumntoshowwhichoptionwasselectedbyanannotatorandtheoptionthat\nwasrejected.\nArethererecommendeddatasplitsorevaluationmeasures? Therearenorecommendeddata\nsplits. However,itisworthnotingthatweusedan80-20splitduringourmachinelearningclassifica-\ntiontask.\nArethereanyerrors,sourcesofnoise,orredundanciesinthedataset? Doesnotapply.\nIs the dataset self-contained, or does it link to or otherwise rely on external resources (for\nexample,websites,tweets,andotherdatasets)? Everythingisincludedandthedatadoesnot\ndependonanyexternalresource.\nDoesthedatasetcontaindatathatmightbeconsideredconfidential(forexample,datathatis\nprotectedbylegalprivilegeorbydoctor–patientconfidentiality,datathatincludesthecontent\nofindividuals’non-publiccommunications)? No\nDoesthedatasetcontaindatathat,ifvieweddirectly,mightbeoffensive,insulting,threatening,\nor might otherwise cause anxiety? Yes the conversation with the AI Assistant does on some\noccasions contain offensive and repugnant words that might cause distress and require special\nattentionbeforeengagingwiththem.\nDoesthedatasetidentifyanysubpopulations(forexample,byage,gender)? Theconversation\nwiththeassistantdoessometimesrefertogenderandage,butisnotdirectlytiedtoanypersonor\nindividual.\nIsitpossibletoidentifyindividuals(thatis,oneormorenaturalpersons),eitherdirectlyor\nindirectly(thatis,incombinationwithotherdata)fromthedataset? No\n22\nDoesthedatasetcontaindatathatmightbeconsideredsensitiveinanyway(forexample,data\nthatrevealsraceorethnicorigins,sexualorientations,religiousbeliefs,politicalopinionsor\nunionmemberships,orlocations;financialorhealthdata;biometricorgeneticdata;formsof\ngovernmentidentification,suchassocialsecuritynumbers;criminalhistory No\nWhatexperimentswereinitiallyrunonthisdataset? Thedatasetwasusedtotrainandevaluate\nrewardmodelsforRLHF,byfine-tuningabaselanguagemodelonthesuperviseddatafirst.\nE.3 DataCollection\nHowwasthedataassociatedwitheachinstanceacquired? Wasthedatadirectlyobservable\n(forexample,rawtext,movieratings),reportedbysubjects(forexample,surveyresponses),\norindirectlyinferred/derivedfromotherdata(forexample,part-of-speechtags,model-based\nguessesforageorlanguage)? Alargelanguagemodelgeneratedtwopotentialresponsesfora\ngivenprompt.\nWhat mechanisms or procedures were used to collect the data (for example, hardware ap-\nparatusesorsensors,manualhumancuration,softwareprograms,softwareAPIs)? Human\nannotatorswereshownthepromptandthetworesponses,andaskedtochoosewhichresponsethey\npreferredintermsofbeingmore\"helpfulandharmless.\"\nIf the dataset is a sample from a larger set, what was the sampling strategy (for example,\ndeterministic,probabilisticwithspecificsamplingprobabilities)? Thegroundtruthdatasetwas\ncuratedfromthelargerdatasetthroughrandomsampling.\nWhowasinvolvedinthedatacollectionprocess(forexample,students,crowdworkers,con-\ntractors)andhowweretheycompensated(forexample,howmuchwerecrowdworkerspaid)?\nTheleadresearcherretrievedtheoriginaldatasetsfromHuggingFaceandGitHubusingasimple\nPythonscript.\nOverwhattimeframewasthedatacollected? Notavailablefortheoriginaldataset.\nWereanyethicalreviewprocessesconducted(forexample,byaninstitutionalreviewboard)?\nNotapplicable\nDidyoucollectthedatafromtheindividualsinquestiondirectly,orobtainitviathirdparties\norothersources(forexample,websites)? DataforthisresearchwascollectedthroughHugging\nFaceandGitHub.\nWeretheindividualsinquestionnotifiedaboutthedatacollection? Notapplicable.\nDidtheindividualsinquestionconsenttothecollectionanduseoftheirdata? Notapplicable.\nIfconsentwasobtained,weretheconsentingindividualsprovidedwithamechanismtorevoke\ntheirconsentinthefutureorforcertainuses? Notapplicable\nHasananalysisofthepotentialimpactofthedatasetanditsuseondatasubjects(forexample,\nadataprotectionimpactanalysis)beenconducted? Notapplicable.\nE.4 Preprocessing/Cleaning/Labeling\ning/labelingofthedatadone(forexample,discretizationorbucketing,tokenization,part-of-\nspeechtagging, SIFTfeatureextraction, removalofinstances, processingofmissingvalues\nYes,thevaluelabelswereconvertedtointegersbeforetheclassificationtask.\nWasthe“raw”datasavedinadditiontothepreprocessed/cleaned/labeleddata(forexample,\ntosupportunanticipatedfutureuses)? SameastheGitHubrepository. https://github.com/hv-\nrsrch/valueimprint\n23\nIsthesoftwarethatwasusedtopreprocess/clean/labelthedataavailable? Thematerialsused\nforthisanalysiscanbefoundinthesameGitHubrepo. https://github.com/hv-rsrch/valueimprint\nE.5 Uses\nHasthedatasetbeenusedforanytasksalready? Thedatasetswereusedinthepaper’sresearch\ntoconductacontentaudittoidentifythehumanvaluesembeddedinthepreferences. Developand\ntrainmachinelearningmodelsforclassifyinghumanvaluesinRLHFpreferences. Thepaperpresents\nfindingsaboutthedistributionofhumanvaluesandethicalorientationswithinthedatasets.\nIstherearepositorythatlinkstoanyorallpapersorsystemsthatusethedataset? Yes,here\nisthelinktothegithubrepo: https://github.com/hv-rsrch/valueimprint\nWhat(other)taskscouldthedatasetbeusedfor? Theintendedusecaseofthisdatasetisforthe\nmachinelearningclassificationofhumanvaluesinlargescaleRLHFandrelateddatasets.\nIs there anything about the composition of the dataset or the way it was collected and pre-\nprocessed/cleaned/labeledthatmightimpactfutureuses? Yes,thedatasetwaslabeledusing\nWestern-orientedhumanvaluestaxonomy. Hence,thistaxonomyandthedatasetmightnotworkwell\nfornon-westernpreferencedatasets.\nAretheretasksforwhichthedatasetshouldnotbeused? Thisdatasetshouldnotbeusedfor\nunnecessaryquantificationofhumanvaluesthanintendedbytheauthorsofthispaper.Byunnecessary\nquantificationofhumanvalues,wemeantreatingthepredictionresultasabsolutesinsteadofpointers\ntoguidebetterRLHFdatasetcuration.\nE.6 Distribution\nWillthedatasetbedistributedtothirdpartiesoutsideoftheentity(forexample, company,\ninstitution, organization) on behalf of which the dataset was created? This dataset will be\navailableforfurtherresearchpurposes.\nHowwillthedatasetbedistributed(forexample,tarballonthewebsite,API,GitHub)? The\ndatawillbedistributedviaGitHub. https://github.com/hv-rsrch/valueimprint\nWhenwillthedatasetbedistributed? Immediateeffect\nWillthedatasetbedistributedunderacopyrightorotherintellectualproperty(IP)license,\nand/orunderapplicabletermsofuse(ToU)? ThisworkislicensedunderaCCBY4.0license.\nSeeofficialinstructionshere: https://creativecommons.org/about/cclicenses/\nHaveanythirdpartiesimposedIP-basedorotherrestrictionsonthedataassociatedwiththe\ninstances? No\nDoanyexportcontrolsorotherregulatoryrestrictionsapplytothedatasetortoindividual\ninstances? No\nE.7 Maintenance\n. Whowillbesupporting/hosting/maintainingthedataset? Theresearchteamforthisproject\nwillbeinchargeofhostingandmaintainingthedataset.\n.Howcantheowner/curator/managerofthedatasetbecontacted(forexample,emailaddress)?\nThecuratorcanbecontactedviaobii@purdue.eduorviaGitHub\nIsthereanerratum? No\n24\nWillthedatasetbeupdated(forexample,tocorrectlabelingerrors,addnewinstances,delete\ninstances)? Yes, the dataset will be versioned and updated depending on the progress of this\nresearch.\nIfthedatasetrelatestopeople,arethereapplicablelimitsontheretentionofthedataassociated\nwiththeinstances(forexample,weretheindividualsinquestiontoldthattheirdatawouldbe\nretainedforafixedperiodoftimeandthendeleted)? Notapplicable.\nWillolderversionsofthedatasetcontinuetobesupported/hosted/maintained? Olderdata\nwillbesupportedinasmuchastheydonotcontainerrorsandarestillvalidandusefultotheresearch\ncommunity.\nIfotherswanttoextend/augment/buildon/contributetothedataset,isthereamechanismfor\nthemtodoso? ThisdatasetwillbeavailableonGitHubtoallowotherstocontribute,comment,\nandbuildontheprojectinwaysthatworksbestforthem.\n25\nTable2: HumanValuesTaxonomyandDescription\nHumanValues HumanValuesTaxonomyDescription\nThisvaluehierarchyfocusesontheholisticthrivingofhumansacross\n1. Well-being/Peace:\nmultipledimensions,includingphysical,mental,emotional,and\nspiritualaspects. Theendgoalistofosterabeingthatthrivesinthe\nworld. Thesub-valueswithinthiscategoryincludepleasure,life\nsatisfaction,emotionalfulfillment,joy,bliss,euphoria,physicalhealth,\nmentalhealth,nourishment,vitality,vigor,energy,fitness,nutrition,\nself-care,environmentalsustainability,security,stability,order,peace,\nandunity. [43–64]\nThisvaluehierarchyfocusesonthepursuitofinformationfor\n2. InformationSeeking:\nimmediate,practicalapplication. Theemphasishereisonusing\ninformationtoachieveimmediateoutcomes. Forexample,askingfor\ndirectionsonhowtogettotheairportfromtheircurrentlocation,asking\nforinformationaboutarecipethatusestheavailableingredientsintheir\nfridge. ThisvaluecategorywasthemostcommonwithintheRLHF\npreferencedataset. Thesub-humanvalueswithinthiscategoryinclude\nefficiency,desirefulfillment,andinterestachievement. [65–71]\n3. Justice/HumanRights& Thisvaluereferstorespectfortherightsofpeopleandanimalstoexist\nAnimalRights: meaningfullyasmembersofhumansocietyandnaturalecology. The\nvalueswithinthisgroupincludehumanrights,animalrights,equality,\nimpartiality,fairness,equity,access,inclusion,autonomy,dignity,and\nequityinaccesstoinformation. [72–104]\nThisvaluecentersontheethicalobligationsofindividualstosociety\n4. Duty/Accountability:\nandinprofessionalsettings. Someofthevalueswithinthiscategory\nincludenon-maleficence,law-abiding,privacy,confidentiality,integrity,\naccountability,trustworthiness,reliability,responsibility,and\nreasonableness. Italsoincludesthedutytechnologypractitionersoweto\nusers. [105–119]\nThisvaluefocusesonacquiringknowledgefordeeperunderstanding\n5. Wisdom/Knowledge: ratherthanimmediateapplication. Itinvolvesthepursuitofknowledge\nforitsownsake. Anexampleofthisinvolvesseekingtounderstandthe\nprocessesthatleadtorainformationorlearningfrompastmistakesor\nthroughpractice. Someofthevalueswithinthiscategoryinclude\ndiscernment,excellence,creativity,skill,prudence,discipline,\ncompetence,diligence,fortitude,resilience,andcraftsmanship.\n[120–133]\nThisvaluereferstothestrengthofcharacterandattitudeanindividual\n6. Civility/Tolerance: manifestsintheirbehaviortowardmembersofsocietyandthemselves.\nEssentially,thisvaluerelatestopersonalcharacterandattitudesinsocial\ninteractions. Someofthevalueswithinthiscategoryincludecivility,\ncourtesy,etiquette,cooperation,confidence,restraint,modesty,humility,\nsimplicity,calmness,andpatience. [134–144]\nThisvalueinvolvesshowinghumanitytooneselfandtheworld. It\n7. Empathy/Helpfulness: involvesunderstandingthecontextandplightofthehumanoranimalto\nprovideassistancetohelpthemnavigatethatsituation. Someofthe\nvalueswithinthiscategoryincludebenevolence,generosity,compassion,\nempathy,kindness,positivity,andhelpfulness. [145–152]\n26",
    "pdf_filename": "Value_Imprint_A_Technique_for_Auditing_the_Human_Values_Embedded_in_RLHF_Datasets.pdf"
}