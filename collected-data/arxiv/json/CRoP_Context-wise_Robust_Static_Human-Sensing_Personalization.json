{
    "title": "CRoP: Context-wise Robust Static Human-Sensing Personalization",
    "abstract": "otherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrom permissions@acm.org. ©2024AssociationforComputingMachinery. XXXX-XXXX/2024/11-ART$15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn ,Vol.1,No.1,Article.Publicationdate:November2024. 4202 voN 91 ]IA.sc[ 4v49971.9042:viXra",
    "body": "CRoP: Context-wise Robust Static Human-Sensing Personalization\nSAWINDERKAUR1,AVERYGUMP2,JINGYUXIN1,YIXIAO4,HARSHITSHARMA4,NINAR\nBENWAY3,JONATHANLPRESTON1,ASIFSALEKIN4\n1SYRACUSEUNIVERSITY 2UNIVERSITYOFWISCONSIN-MADISON 3UNIVERSITYOFMARYLAND-COLLEGEPARK 4ARIZONASTATEUNIVERSITY\nTheadvancementindeeplearningandinternet-of-thingshaveledtodiversehumansensingapplications.However,distinct\npatternsinhumansensing,influencedbyvariousfactorsorcontexts,challengethegenericneuralnetworkmodel’sperformance\nduetonaturaldistributionshifts.Toaddressthis,personalizationtailorsmodelstoindividualusers.Yetmostpersonalization\nstudiesoverlookintra-userheterogeneityacrosscontextsinsensorydata,limitingintra-usergeneralizability.Thislimitation\nisespeciallycriticalinclinicalapplications,wherelimiteddataavailabilityhampersbothgeneralizabilityandpersonalization.\nNotably,intra-usersensingattributesareexpectedtochangeduetoexternalfactorssuchastreatmentprogression,further\ncomplicatingthechallenges.Toaddresstheintra-usergeneralizationchallenge,thisworkintroducesCRoP,anovelstatic\npersonalizationapproach.CRoPleveragesoff-the-shelfpre-trainedmodelsasgenericstartingpointsandcapturesuser-specific\ntraitsthroughadaptivepruningonaminimalsub-networkwhilepreservinggenericknowledgeintheremainingparameters.\nCRoPdemonstratessuperiorpersonalizationeffectivenessandintra-userrobustnessacrossfourhuman-sensingdatasets,\nincludingtwofromreal-worldhealthdomains,underscoringitspracticalandsocialimpact.Additionally,tosupportCRoP’s\ngeneralizationabilityanddesignchoices,weprovideempiricaljustificationthroughgradientinnerproductanalysis,ablation\nstudies,andcomparisonsagainststate-of-the-artbaselines.\nAdditionalKeyWordsandPhrases:Intra-userGeneralization,Personalization,Contest-wiseRobustness\nACMReferenceFormat:\nSawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4,\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity.2024.CRoP:Context-wiseRobust\nStaticHuman-SensingPersonalization. 1,1(November2024),33pages.https://doi.org/10.1145/nnnnnnn.nnnnnnn\n1 INTRODUCTION\nRecentautomatedhumansensingapplications—likeactivityrecognition,falldetection,andhealthtracking-\nrevolutionizedailylife,especiallyinpersonalhealthmanagement[85].However,uniqueuserpatternsandnatural\ndistributionshifts[24]causedbybehaviors,physicaltraits,environment,anddeviceplacements[73,78]lead\ntotheunderperformanceofgenericsensingmodelsinpracticaluse.Totacklethis,variousdomainadaptation\ntechniqueshavebeenexplored,withpersonalizationwidelyusedtoadaptagenericmodeltothetargetuser’s\nspecificdomainornaturaldistribution[1,9,32,39,53,62,67].Inliterature,personalizationoccurseitherduring\ntheenrollmentphase(static)[10,15,45]orcontinuouslythroughoutapplicationuse,aprocessknownascontinual\nlearning[13,44,87,90].\nContinual learning methods involve retraining models with new data, either supervised or unsupervised.\nWhiletheseapproachesenablemodelstoadapttonewpatternsandchangesindatadistributionovertime,they\nAuthor’saddress: SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,Asif\nSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity.\nPermissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthat\ncopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirst\npage.CopyrightsforcomponentsofthisworkownedbyothersthanACMmustbehonored.Abstractingwithcreditispermitted.Tocopy\notherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrom\npermissions@acm.org.\n©2024AssociationforComputingMachinery.\nXXXX-XXXX/2024/11-ART$15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n,Vol.1,No.1,Article.Publicationdate:November2024.\n4202\nvoN\n91\n]IA.sc[\n4v49971.9042:viXra\n2 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\noftenfaceefficiencychallenges.AsHarunetal.[28]pointsout,thesemethods,particularlythosethatprevent\ncatastrophicforgetting[13,19,35,50,51,74,75,87,88],oftenstrugglewithmemory,computation,andstorage\nrequirementsinefficiencies,limitingtheirreal-worldapplicability.Frequentmodelupdatesonuserdevicescan\nintroducesignificantdelays.Thisisespeciallytruefordeviceswithlimitedprocessingpower,suchassmartphones\norwearables.Thesedelaysreducetheresponsivenessoftheapplication.Theyalsoleadtobatterydrainand\ninefficiencyinreal-timeapplications.Furthermore,toavoidcatastrophicforgetting,severalcontinuallearning\napproachesrelyonreplay-basedmethodswhichrequirestorageofpreviouslyencountereddata[29,80,81].\nThisnotonlyincreasesstoragerequirementsbutalsoraisesprivacyconcerns.Constantlystoringpotentially\nidentifiableinformationincreasestheriskofdatabreachesormisuse.Thisisespeciallyconcerninginregulatory\nenvironments,suchashealthcare[83].\nAdditionally, supervised continual learning approaches face the significant challenge of requiring expert-\nlabeleddataforeachnewbatchofuserinteractions,alsotermedaslabeldelay[12].Thisdemandforcontinuous,\nhigh-qualitylabelscanmakeitimpracticalformanyapplications,especiallyinsettingswhereexpertannotation\niscostlyorunavailable.Forexample,inclinicalorhealthmonitoringcontexts,eachnewdatapointmayneedto\nbevalidatedbyprofessionals,whichistime-consuminganddifficulttoscale.\nIncontrast,staticpersonalizationoffersanefficientalternativebycustomizingthemodelwithaone-time,\nlimiteddatasetcollectedduringenrollment.Thisapproachminimizescomputation,requiresnoongoingdataor\nlabelstorageorcollection,andreducesuserengagement,makingitespeciallysuitableforresource-constrained\nhuman-sensingapplications.However,existingsuchstudiesoftenoverlookintra-uservariabilityduetofactors\nlikechangesinmagneticfield[63],sensorposition[57],terrain[37],orthehealthsymptoms[55],leadingtopoor\nintra-usergeneralizabilityforcontextsnotpresentduringpersonalization.Forinstance,asmartphoneactivity\nrecognitionmodelpersonalizedwithhandhelddatamayperformpoorlywhenthephoneisinapocket.\nStaticpersonalizationisparticularlycrucialforclinicaldatasets,whichoftensufferfromdatascarcity,leading\ntoreducedrobustnessoflab-validatedmodelsforprospectivelycollectedusers[8].Itenhancesmodelaccuracy\nforclinicaluserswhosetraitsareunderrepresentedintheglobalmodel’strainingdata.Incontrast,continuous\nsupervisedpersonalizationisgenerallyinfeasibleinmanyhealthdomainssincegroundtruthsmustbevalidated\nbyclinicians,makingitimpracticalincontinuoussettings,especiallyinremoteormobilehealthapplications.\nNotably,thedistributionofclinicaldataisexpectedtoshift,evenwithinthesameindividual.Forinstance,\nin clinical speech technologies, changes in data distribution over time may occur due to the progression of\nneurodegenerativediseases,relevantfordiseasemonitoringapps[72],orthroughdesiredlearningmechanisms\nresultingfromtheuseoftechnology,asseeninautomatedspeechtherapyapps[6].Similarly,inwearable-based\nstressmonitoring,psychophysiologicaldatadistributionvariesasindividualsfacedifferentstressors[54].This\nresearchdefines‘context’astheintra-userdatadistributionformedbyvaryingfactors.\nThisresearchgapisworsenedsincestaticpersonalizationtypicallyreliesonasmallsamplesetfromthetarget\nuser,coveringlimitedcontexts—particularlyinclinicalsettingsorapplicationswithdatascarcity[6,8].Commer-\ncialhumansensingtechnologieslikeGoogleAssistant,AmazonAlexa,andApple’sSirialsostaticallypersonalize\nspeechrecognitionmodelsusinglimitedphrases[4,58,77].Similarly,theAppleWatchusesinitialcalibrationfor\nenhancedrunningactivitytracking[2,59].Thislimitedcontextduringpersonalizationisproblematic,asshown\ninSection3,wherewedemonstratethatstaticpersonalizationmayimproveperformanceintrainingcontexts\nbutcanalsosignificantlydegradeitinotherunseencontextsforthesameuser.\nTherefore,giventheimportanceofstaticpersonalizationinhumansensing,thispaperaddressesitsintra-user\ngeneralizabilitygap.Sincepersonalizedmodelsaretailoredtoindividualusersandnotintendedforusebyothers,\ninter-usergeneralizabilityisoutsidethescopeofthiswork.Anadditionalchallengeisthatseveralpersonalization\napproaches in the literature, such as EMGSense [15] and MobilePhys [45], train their own generic models,\nsometimesevenusingdatafromtargetusers.Thislimitsprivacy-preservinggenericmodelsharing,and,insome\ncases,requirestargetuserstosharesensitivedata,raisingadditionalprivacyconcerns.Italsocomplicatesadding\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 3\nPersonalization for a Specific User\nOff-the-Shelf Generic Model\nAvailable Unseen\nContext Contexts\nGeneralization:\nEvaluation on all\ncontexts\nPersonalization\nFig.1. ProblemSetting\nanewuser,asthegenericmodelmustbeupdatedandredistributed.Whilemodelredistributioniscommonin\nfederatedlearning,human-sensingpersonalizationisn’tlimitedtofederatedlearningmethods.Toaddressthis\nlimitation,thispaperonlyusespre-trained,off-the-shelfmodelsasgenericmodels,whichdonotrequiredata\nfromthetargetusers.\nInsummary,Figure1outlinesthepaper’sscopeandobjective.Thegoalistodevelopanintra-userrobust\napproachtopersonalizeanoff-the-shelfgenericmodelforaspecificuserusinglimiteddatafromlimitedcontexts.\nTheprimaryobjectiveistoensurethatthepersonalizedmodelthusobtainedexhibitsrobustgeneralization\ncapabilitiesacrossunseencontexts.Crucially,unseencontextdatatakesnopartintrainingoradjustingthe\npersonalized model outcome, and the generic model remains entirely off-the-shelf, with no accessibility for\nmodificationordesignchoices.Theseconstraintshighlightthereal-worldimpactofthisresearch,particularlyin\nclinicalsettingswhereprivacyconcernsoftenlimitdatasharing[49,61],andonlytrainedoff-the-shelfmodels\naresharedamongresearchersanddevelopers.\nToachievetheresearchobjectiveinFigure1,thispaperintroducesCRoP,anovelapproachtocreatecontext-\nwiseintra-userrobuststaticpersonalizedmodels.Thekeycontributionsare:\n(1) It facilitates utilizing readily available off-the-shelf pre-trained models with state-of-the-art accuracy,\neliminatingtheneedfortrainingcustomizedgenericmodels,thusreducingtrainingeffortandprovidinga\nstrongfoundationforpersonalization.\n(2) Personalizationwithintra-usergeneralizationhastwochallenges:i)learninguser-specificpatternsand\nii)keepinginformationaboutgenericpatternsintact.Duringpersonalization,CRoPleveragespruning\nandregularizationtocapturetheuser-specificpatternspresentintheavailable-contextdataonaminimal\nsub-networkofthemodel.Theremainingparametersofthemodelareutilizedtoretaingenericpatternsthat\narenotpresentintheavailablecontext,i.e.,personalizationdata,thusachievingintra-usergeneralizability\ntounseencontexts.Pruningiswidelyusedinotherareas,includingincontinuouslearningliterature(e.g.,\nPacknet[50],andPiggyback[51]),toobtainsub-networksforeachnewtaskwhichnotonlyrequiresdata\nfromeverytask(hereunseencontext)butalsoneedsidentificationofthetaskdifferences(i.e.,difference\namongunseencontexts)inordertoselectthesub-networkforinference.Incontrast,thisisthefirstpaper\nto use pruning with adaptive intensity to capture the user’s traits in a compressed sub-network, thus\nstriking a balance between personalization and robustness in new, unseen contexts for the same user\nwithoutidentifyingthecontexts,theirdifferences,orrequiringdatafromunseencontextsforadaptation.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n4 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n(3) ToshowcaseCRoP’sefficacy,comprehensiveevaluationswereperformedonfourhumansensingdatasets:\nPERCERT-R[7]:aclinicalspeechtherapydataset,WIDAR[94]:alab-basedWiFi-CSIdataset,ExtraSensory:\nareal-worldmobilesensingdataset[79],andastress-sensingdataset[91],whileconsideringtwodisjoint\ncontextsforeachdataset.InordertoobtaininformationaboutcontextvariationwithinPERCEP-Rand\nStress-sensing,wecollaboratedwiththeoriginalauthorsofthesetwodatasets.Thisadditionalannotation\nwillbereleasedalongsidethispublication.\n(4) On an average across all datasets, CRoP shows a personalization benefit of 35.23 percent points and\ngeneralizationbenefitof7.78percentpoints.Ascomparedtothebestbaseline(Packnet),thesegainsare\n9.18and9.17percentpointshigher,respectively.Moreover,alongsideadetailedablationstudydiscussion\ninSection8,anempiricaljustificationofCRoP’sdesignchoicesthatenableintra-usergeneralizability\namongdifferentcontextsisprovidedinSection7.1,employingGradientInnerProduct(GIP)[70]analysis.\nAdditionally,inordertodemonstratethefeasibilityofon-devicepersonalizationthroughCRoP,wecompute\ntrainingtimeandresourcerequirementsforfiveplatformsordevices.\nThepaperisarrangedindifferentsections.Section2reviewstherelatedwork,whileSection3presentsthe\nresultsofapreliminarystudyontheWIDARdatasets,whichmotivatestheproposedapproach.Section4provides\naformaldescriptionoftheproblemstatement,followedbySection5,whichoutlinesthedetailedmethodology.\nSection6coverstheexperimentalsetup,andresults.InSection7,wepresentanempiricalstudytojustifythe\napproach,andSection8offersanablationstudytosupportvariousdesignchoices.Section9discussesruntime\nanalysis,Section10exploreslimitationsandfuturedirections,andSection11addressesthebroaderimpactofthe\nwork.Finally,Section12concludesthestudy.\nTheworkisaccompaniedbyanextensiveappendix,whichprovidesdetailsofexperimentsetup,hyperparam-\neters,andlinktocodeensuringreproducibilityinAppendixA.Additionally,AppendixBprovidesadetailed\nanalysisoftheuser-specificresultsforeachdatasetalongwithadetailedablationstudy.\n2 RELATEDWORK\nAsdiscussedabove,thisworkaimstopersonalizeoff-the-shelfmodelswhileensuringintra-usergeneralizability\nleveraginglimited-contextdata.Whileexistingapproachesattempttoaddresstheseadaptationchallenges,they\noftenimposerestrictiveconditions.Manyrequirespecializedtrainingofthegenericmodelwithaccesstothe\ngeneric data, assume knowledge of the target domain, or necessitate target users to share their data from a\nnew/previous-unseencontextforadaptingthemodel,insomestudieswithlabelsorannotations.Additionally,\nsomemethodsrelyonrepetitivemodelretraining,whichhinderstheirsuitabilityforreal-worldapplicationsdue\ntoprivacyconcerns,computationalinefficiency,orexcessiveuserengagement.\nThissectionsummarizesandcritiqueskeystate-of-the-artapproacheswithsimilarobjectivestothoseaddressed\ninthiswork,highlightingtheircontributionsandlimitationsinpractical,user-centeredadaptationsettings.\n2.1 DomainAdaptationandGeneralization\nDomainadaptation(DA)andDomainGeneralization(DG)techniquesaddressperformancedropsduetodistribu-\ntionalshiftsbetweensourceandtargetdomains[36].Thesemethodsareusefulwhenmodelstrainedongeneric\ndataneedtoadapttonewusersorcontexts.ThekeydifferenceisthatwhileDAapproacheshaveaccesstotarget\ndomaindata,DGtechniquesworkwithoutanytargetdomaindata,notevenunlabeled[86].\nThedomaingeneralizationtechniquescanbecategorizedintoDataManipulation,RepresentationLearning,\nandotherlearningstrategies[86].DataManipulationapproachesincludetechniqueslikedataaugmentation\nandsyntheticdatageneration,whichareusedtoincreasedatadiversity,helpingmodelslearninvariantfeatures\nacrossdifferentdomains[68,84,95].RepresentationLearningaimstocapturedomain-invariantfeaturesusing\ntechniqueslikeadversarialtrainingandembeddinglearningtoimprovemodelrobustness,suchasInvariant\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 5\nriskminimization(IRM)[3]anddomain-adversarialneuralnetworks(DANN)[22].LearningStrategiessuchas\nmeta-learning[41]andensemblelearning[14]trainthemodelonmultiplesimulateddomainstoimproveits\nabilitytogeneralize.However,alloftheseapproachesaimtotrainthegenericmodelwhilethispaper’sscope\ndoesnotallowaccesstogenericdataandusesapre-trainedoff-the-shelfmodelforadaptation.\nSimilarly,somedomainadaptationapproachesrelyongenericmodeltrainingwhileutilizingdatafromthe\ntargetdomain[47].Ontheotherhand,certaindomainadaptationapproachesrequireaccesstothesourcedata\nusedtotrainthegenericmodelwithoutrequiringspecializedtrainingofthegenericmodel.Theseapproaches\nrely on discrepancy minimization and self-supervision to align source and target distributions by learning\ndomain-invariantrepresentations[21,42].Afewapproachesthatdonotrequireaccesstothesourcedomain\ndataorgenericmodeltrainingarereferredtoassource-freedomainadaptation(SFDA)[43].Liangetal.[43]\n(SHOT)proposedthetransferofhypothesisfromsourcebyfreezingtheparameterweightsfortheclassifierlayers\nandonlyallowingthefeatureextractionlayertobefinetunedtothenewdomain.Theapproachisapplicable\ntounsuperviseddomainadaptationscenariosandemploysself-supervisedpseudo-labelingtoalignthetarget\ndomain’srepresentationstothesourcehypothesis.\nGiventhattheproblemaddressedbySHOTalignswiththecriteriaofhavingnoaccesstogenericdataand\navoidingspecializedgenericmodeltraining,weadoptedSHOTasoneofthebaselineapproachesinthisstudy.\nHowever,itisimportanttonotethatSHOTdoesnoteffectivelytacklethelimitationsposedbyrestricted-context\ndataduringthefine-tuningprocess.Asaresult,itsperformancemaynotadequatelygeneralizetotheintra-user\nvariabilitypresentinthedata,whichisacrucialaspectofourresearchfocus.\n2.2 ContinualLearning\nContinualpersonalizationapproaches[13,19,50,51,74,75,87,88]canimproveintra-usergeneralizabilityby\ncontinuallyfine-tuningthemodelasnewdataarrives.Someoftheseapproaches[19,74,75]requirespecialized\ntraining of the generic model, limiting the use of off-the-shelf pre-trained models. Others like PackNet [50]\nandPiggyback[51]proposesupervisedmethodsthatrequirecontinuedsteamoflabeleddata,limitingtheir\napplicationinhealth-carescenarios.However,allcontinuouslearningapproachesrequirerepeatedcomputation\noverheadtoadjustthemodeloutcometonewdata[60],whichcanbeinfeasibleinreal-timeapplications,moreso\nforscalableplatformslikewearables[65],whichisprominentforhealthsensingsuchasstressorfalldetection.\nDanielsetal.[13]proposesacontinualtrainingframeworkthatiscompatiblewithedgedevicesandrequiresless\ntrainingeffort,butitusesadifferentandsmallermodelarchitectureatthepersonalizeddevicesforgenerating\nfeatureembeddings.Thushinderingthedirectusageofoff-the-shelfmodelsandincreasingthetrainingeffort.\nNevertheless,sincetheproblemsaddressedbyPacknet,andPiggybackaretheclosesttotheproblemaddressed\ninthisstudy,weconsideredtheseapproachesasbaselines.\nPacknet[50]andPiggyback[51]adaptthegenericmodelforastreamofcontinuouslychangingtasks.Packnet\nreliesonfinetuning,pruningandre-trainingthemodelforeachnewtask.Ontheotherhand,Piggybackemploys\npruningtolearnanewbinarymaskforeachnewtaskwhichisthenappliedtoagenericmodelinordertoget\ntask-specificresults.However,thisrequirescorrectidentificationofthetaskbeforechoosingthemask.Forevery\nnewtask,thesameprocedureisrepeated,hopingthatdifferentsetsofparameterswillbeimportantfordifferent\ntasks.Thisalignswellwithourinitialstudy,whereweidentifythatdifferentcontexts’datafocusondifferent\nsetsofparameters.\nNotably,allcontinuallearningapproaches,includingPackNetandPiggyback,faceasignificantlimitation:they\nnecessitateaccesstodatafromthetargetdomain,whetherinasupervisedorunsupervisedformat,inorderto\neffectivelyadaptthemodel.Whiletheseapproachessuccessfullyaddressthechallengeofcatastrophicforgetting,\ntheyprimarilyfocusoncontextsthatthemodelhaspreviouslyencountered,leavingthemill-equippedtoadapt\ntoentirelyunseendomains.Incontrast,ourresearchframeworkspecificallyexcludesaccesstodatafromthese\n,Vol.1,No.1,Article.Publicationdate:November2024.\n6 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nunseencontextsduringmodeladaptation,highlightingacriticalgapinthecapabilitiesofexistingcontinual\nlearningmethodologies.Consequently,PackNet,Piggyback,andsimilarapproacheslackthemechanismsneces-\nsarytoadapttonoveldomains,underscoringtheneedforinnovativestrategiesthatcanoperatewithoutprior\nexposuretothetargetdata.\n2.3 Test-TimeAdaptation(TTA)\nContinual learning requires repeated training cycles to adapt models to new information, demanding high\ncomputationalresources,storage,andlong-termdataretention,whichraisesprivacyconcerns[83].Thismakes\ntraditionalcontinuallearningimpracticalforsensitivedomainslikehealthcare[28].\nTest-timeadaptationoffersamoreefficientandfelxiblealternative,allowingmodelstoadaptinreal-time\nduringdeploymentbymakingadjustmentsbasedonincomingdatawithoutnecessitatingacompleteretraining\nprocess.Byfocusingonadaptingthemodelinreal-time,test-timeadaptationminimizesresourceconsumptionas\ncomparedtocontinuallearningapproaches.Wangetal.[87]reliesongeneratingpseudo-labelsusingweighted\naveragingandaugmentation-averagedpredictions,whichcanintroducebias[43].WhileWuetal.[90]achieves\ntest-timedomainadaptationbymanipulatingbatch-normalizationlayers,thusenforcingarestrictiononmodel\narchitecture.However,ContinualTestTimeDomainAdaptation(CoTTA)[88]doesnothavesuchrestrictions\nandallowstheuseofoff-the-shelfmodels.\nCoTTA[88]isanunsupervisedlearningapproachdesignedtoenhancemodeladaptationindynamicenvi-\nronments. It utilizes a teacher model, which is initially set up as a replica of the generic model, to generate\npseudo-labelsfortraining.Duringeachiteration,theteachermodelisupdatedusingcurrentmodelstatethrough\naweightedsum,allowingthemodeltoeffectivelyaccountforevolvingdatapatternsovertime.Additionally,the\ncurrentmodelstateissubjecttoastochasticrestorationofweights,implementedthroughaBernoullidistribution\nwithaverylowprobabilityofsuccess.Thisrandomizationintroducesanelementofvariabilitythathelpsprevent\noverfittingandencouragesexplorationoftheweightspace,furtherenhancingthemodel’sabilitytogeneralizeto\nunseendata.\nSinceCoTTAaddressesaproblemsettingsimilartoours,weadoptitasoneofourbaselineapproaches.In\noursetup,datafromtheavailablecontextcanbeleveragedfortest-timeadaptation,whileunseencontextdata\nisreservedsolelyforempiricalevaluation.However,test-timeadaptationmethods,includingCoTTA,tendto\nincreaseresourcedemandsduringinference,leadingtopotentialdelaysthatcanimpactreal-timeusability.This\nadditionalcomputationaloverheadhighlightsakeylimitationoftest-timeadaptationinapplicationswhere\nreal-timeresponseisessential.\n2.4 PersonalizationApproaches\nAfewstaticpersonalizationapproaches[10,15,45]aimedfortheadditionalgoalofout-of-distributionrobustness.\nHowever,thesemethodsrequireaccesstothegenericmodel—eithertomakespecificdesignchoices[10],which\nprevents them from utilizing off-the-shelf models, or to incorporate knowledge about the target user’s data\ndistributionduringthegenericmodel’strainingphase[15,45],raisingprivacyconcerns,particularlyinsensitive\nclinicalapplications.Theserequirementsdonotalignwiththeresearchobjectivesofthispaper,makingthem\nunsuitableasbaselines.\nForinstance,EMGSense[15]isconcernedwithrobustnesstodistributionalshiftsinSurfaceElectromyography\n(EMG)signalscausedbytheheterogeneityofbiologicalfactorsacrossusers.Thegenericmodelconsistsofa\nmulti-modelvotingensembleDNNthatneedstobetrainedonNsourcedistributionsandsomeunlabeleddata\nfromtargetusers.Tolearnuser-specificfeatures,thismodelundergoesmultipletrainingiterations,eachusing\nupdateduser-specificdata.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 7\nFeature→ Off-the-shelf GenericData Adaptationto Robustnessto\nApproach↓ Genericmodel unseen availablecontext unseenContext\nArjovskyetal.[3],Ganinetal.[22] ✗ ✗ -NA- ✓\nLongetal.[47] ✗ ✗ ✓ ✗\nGaninandLempitsky[21],Lietal.[42] ✓ ✗ ✓ ✗\nSHOT[43] ✓ ✓ ✓ ✗\nPacknet[50]andPiggyback[51] ✓ ✓ ✓ ✗\nCoTTA[88] ✓ ✓ ✓ ✗\nEMGSense[15]andMobilePhys[45] ✗ ✗ ✓ ✗\nPTN[10] ✓ ✓ ✓ ✗\nCRoP ✓ ✓ ✓ ✓\nTable1. SummaryofLiteraturereview\nAlso, MobilePhys [45] addresses distributional shifts that can arise due to environmental conditions (e.g.,\nlighting,motion)aswellasindividualphysiologicalandvisual(e.g.,clothing,posture)differencesincamera-based\ncontactlessPhotoplethysmography.Thegenericmodelistrainedusingmeta-learning,whichusesdatafrom\ntargetuserstoenablequickadaptationtodistributionalshiftsduringpersonalization.\nConsequently,themajordrawbackfacedbyEMGSense[15]andMobilePhys[45]istherequirementofknowl-\nedgeofthetargetuser’sdatainordertotrainthegenericmodel.Thisnecessitatesthetransferoftheuser’s\nunlabelleddatafromtheuser’sdevicetoacentralserver.Suchdatacancontainsensitiveinformation,andthus,\nitstransfersuffersfromlegalandregulatorybarriers[20].Moreimportantly,sincethetrainingofthegeneric\nmodel requires a subset of each target user’s unlabelled data, the introduction of any new user will require\nre-trainingofthegenericmodelanditsdistribution,whichisanoverhead.\nRecently, Burns et al. [10] extends the idea of triplet loss [66] to the task of personalization (PTN). The\noptimizationobjectivecombinestheminimizationoftheEuclideandistancebetweendatafromthesametarget\nclasseswhilemaximizingtheEuclideandistancebetweendifferenttargetclassesinordertolearnanembedding\noptimizedforthedesiredtask.ThefeaturesextractedusingDNNhavebeenshowntobesuperiortotheengineered\nfeatures[64].Thus,Burnsetal.[10]usesthesefeaturestotrainaKNNforthefinalpredictiontask.Theapproach\nhasbeenshowntoberobustforout-of-distributiondata.\nHowever, none of these approaches address intra-user variability in data. Since PTN allows the usage of\noff-the-shelfmodelanddoesnotrequiresharingofthepersonaldataforgenericmodeltraining,weconsider\nPTNasoneofthebaselines.\n2.5 SelectingBaselines\nTheproblemaddressedinthisworkhasthefollowingrequirements:usinganOff-the-shelfgenericmodel,having\nnoaccesstothegenericdata,andrequiringadaptationtoavailablecontextdataandrobustnesstounseendata.\nAsdiscussedintheprevioussectionsandsummarizedinTable1,theapproachesSHOT[43],PTN[10],PackNet\n[50],Piggyback[51],andContinualTestTimeDomainAdaptation(CoTTA)[88]complywiththefirstthree\nrequirements.Thus,weadapttheseapproachestotheproblemstatementaddressedinthisworkandusethemas\nourbaselines.Theseapproachestypicallyrelyontrainingdatafromaspecificcontexttoadapttothatcontext.\nHowever,thescenarioaddressedinthisworklimitstrainingdatatoonlyonecontext,withtheexpectation\nthattheapproachwillalsoperformwellinunseencontexts.Sincedatafromunseencontextsisunavailable,\nwepreventtheseapproachesfromusingitduringtraining.Instead,thedatausedfortrainingoradaptationis\nrestrictedtodatabelongingtotheavailablecontextonly,whiletheunseencontextdataisusedmerelyfortesting.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n8 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n(a)ContextC1 (b)ContextC2\nModel Generic Personalized Δ Model Generic Personalized Δ\nUser C1 C2 C1 C2 C1 C2 User C1 C2 C1 C2 C1 C2\n0 63.90 77.09 87.06 65.02 +23.16 -11.88 0 60.80 73.28 57.46 77.30 -3.34 +4.02\n1 61.80 79.78 89.38 44.38 +27.57 -35.40 1 59.58 73.18 42.38 93.75 -17.29 +20.57\n2 45.63 79.81 71.88 64.45 +29.75 -26.62 2 46.13 80.46 40.19 87.15 -5.93 +6.69\nAverage +26.82 -24.63 Average -8.85 +10.43\nTable2. PerformanceComparisonintermsofinferenceaccuracyofGenericmodelwithconventionallytrainedpersonalized\nmodel\n(a)ContextC1 (b)ContextC2\nFig.2. HeatmapfortheabsolutemagnitudeofparametersbelongingtopenultimatelayerforLeNetmodelsfinetunedusing\ndatafromcontext(a)C1and(b)C2\n3 MOTIVATION\nWhenlearningpatternsfromhumansensingdatainalimitedcontext,conventionalfine-tuningapproaches\ncanoverwritegenericknowledgethatisnotrelevanttothatspecificcontextbutapplicabletoothers,leading\ntoaperformancedropinthoseunrepresentedcontexts.Toillustratethis,weconductedapreliminarystudy\ncomparingtheperformanceofgenericandconventionally-finetuned[31]personalizedhuman-gesture-recognition\nmodelsusingtheLeNetarchitecture[94]trainedontheWIDARdataset.Datapreprocessingdetailsarediscussed\nintheSection6(Experiments).\nTable2acomparestheperformanceofgenericandconventionally-finetuned[31]personalizedmodelsoneach\nuser’sdatabelongingtocontextC1andevaluatedtothesameuser’sdisjointdatainbothC1(available)andC2\n(unseen)contexts.Itcanbeobservedthatconventionalfinetuningintroducesasignificantgainof26.82%for\ncontextC1’sdatabutatthecostof24.63%reductionincontextC2.Similarpatternsareseenwhenpersonalization\nisperformedoncontextC2asshowninTable2b.Thus,conventionalfinetuning-basedpersonalizationofthe\nmodelsusingthelimiteddatafromonecontextcansignificantlyworsenthemodel’sperformanceinanunseen\ncontext.\nToinvestigatethisdiscrepancyinperformance,wecomparethedistributionofparametermagnitudesofthe\nmodelspersonalizedoncontextsC1andC2usingconventionalfinetuning,asshownusingheatmapsinFigures\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 9\n2(a)and2(b).Notably,thereisasubstantialdifferenceinparametermagnitudesbetweenmodelstrainedin\ndifferentcontexts.Additionally,theparametersrepresentedbyblackpixelsinFigure2havemagnitudescloseto\nzero,indicatingtwocrucialaspects:(a)Theircontributiontomodelinferenceisnegligible,implyingredundancy.\n(b)Interestingly,someoftheseparametershavehighmagnitudesinthepersonalizedmodelofanothercontext,\nindicatingthatparametersconsideredunimportantinonecontextmaybecrucialinanother.\nThecriticalquestionarises:Howcanweeffectivelyretainandtransferthevaluablegenericinformationabout\nunseencontexts(e.g.,oneoftheunseencontextsisC2intheaboveexample)tothepersonalizedmodelswithoutaccess\ntotheunseencontexts? –thatthispaperaddresses.\n4 PROBLEMSTATEMENT\nGivenagenericmodelM 𝜃𝐺 ,theobjectiveistotailorapersonalizedmodelM 𝜃𝑃 𝑖𝑎 specificallyforauserU𝑖 utilizing\nthedataD 𝑖𝑎 associatedwithavailablecontextC𝑎,here𝜃 representstheparametersofthemodel.Theprimary\ngoalistoensurethatthepersonalizedmodelM 𝜃𝑃 𝑖𝑎 performsreasonablywellonU𝑖’sdata D 𝑖𝑢 derivedfrom\nunseencontextsC𝑢.Notably,thereisnooverlapbetweenthedatabelongingtotheavailableandunseencontexts,\nthatis,D𝑎∩D𝑢 =𝜙.\n𝑖 𝑖\nInotherwords,ifM 𝜃𝐶 𝑖𝑎 representsaconventionally-finetuned modeltrainedforauserU𝑖 ondataD 𝑖𝑎 ,then,\n𝑃𝑎\nthemodelstrainedusingCRoP,M 𝜃𝑖 ,mustonavg.performbetteronbothavailableC𝑎 andunseencontextC𝑢\n𝐶𝑎\nthanM 𝑖.Moreformally,thelearningobjectivecanbedefinedas:\n𝜃\nM𝑃 𝑖𝑎\n=argmin\n∑︁ ℓ(M𝐺,𝑑),\n𝜃 𝜃\n𝜃 𝑑∈D𝑎\n𝑖\nsuchthatD𝑎∩D𝑢 =𝜙 and\n𝑖 𝑖\n∑︁ 𝑃𝑎 ∑︁ 𝐶𝑎\nℓ(M 𝑖,𝑑) < ℓ(M 𝑖,𝑑),\n𝜃 𝜃\n𝑑∈{D𝑢,D𝑎} 𝑑∈{D𝑢,D𝑎}\n𝑖 𝑖 𝑖 𝑖\n𝑃𝑎\nthatis,thelossincurredbytheresultingpersonalizedmodelM 𝑖 onavg.acrossallcontexts’dataislessthan\n𝜃\n𝐶𝑎\nthelossincurredbyconventionally-finetuned modelM 𝑖.Here,ℓ representsthestandardcross-entropyloss.\n𝜃\nItisimportanttoemphasizethattheabove-mentionedoptimizationproblemrestrictstheusageofdataonlyto\ntheavailablecontextC𝑎 andhasnoknowledgeofdatafromtheunseencontextC𝑢.Hence,for𝑑 ∈ D 𝑖𝑢 (unseen\n𝑃𝑎 𝐶𝑎\ncontextdata),theinformationℓ(M 𝑖,𝑑),andℓ(M 𝑖,𝑑)isabsentduringthetrainingprocess.\n𝜃 𝜃\n5 APPROACH\n5.1 RationaleforTheCRoPApproachDesign\nAspreviouslydiscussed,thegenericmodel’sparameterscontaingeneralizableinformationacrossallcontexts.\nAddressing the problem statement requires retaining this information to the greatest extent while enabling\nfine-tuningforthetargetuser.Furthermore,ourinvestigationrevealedthatdifferentparametersholdvarying\ndegrees of importance in distinct contexts. Hence, the careful selection of subsets of model parameters for\npersonalizationandgeneralizationispivotalforthesuccessoftheapproach,forwhichthispaperleveragesthe\nmodelpruningparadigm.\nModel pruning is based on the idea that neural networks include redundant parameters, and removing\ntheseparametersminimallyimpactsthemodel’sperformance[48,96].Consequently,pruningthefine-tuned\npersonalizedmodelensurestheretentionofessentialparameterstomaintainaccuracyforcontextC𝑎,meaning,\ncapturingthetargetuser-specifictraits.However,theprunedparameterscanbereplacedwithcorresponding\nparametersfromthegenericmodel,effectivelyrestoringgenericknowledgelearnedacrossallcontextsonthose\n,Vol.1,No.1,Article.Publicationdate:November2024.\n10 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nAlgorithm1CRoP\n1: Input:M 𝜃𝐺 :GenericModel ⋄ D 𝑖𝑎 :UserU 𝑖′𝑠 dataforavailablecontextC𝑎 ⋄ 𝛼:coefficientofregularization\n⋄ 𝜏:toleranceforpruning\n2: TraintheGenericmodelonthepersonaldataD 𝑖𝑎\nM𝑃 𝑖𝑎\n=argmin\n∑︁ ℓ(M𝐺,𝑑)+𝛼∥M𝐺∥\n𝜃′ 𝜃 𝜃 1\n𝜃 𝑑∈D𝑎\n𝑖\n3: Pruneredundantparameterstoobtaintheprunedsub-structure\n𝑃𝑎 𝑃𝑎\nM 𝑖 =ToleratedPrune(M 𝑖,𝜏)\n𝜃↓ 𝜃′\n4: Copytheparametersofgenericmodelstotheprunedparametersinthepersonalizedprunedmodel,\n(cid:40) 𝑃𝑎\n𝑃𝑎 M 𝑖 ,𝜃↓ ≠0\nM 𝑖 = 𝜃↓\n𝜃′′ M𝐺 ,otherwise\n𝜃\n5: FinetunethepersonalizedmodelontheD 𝑖𝑎 usingearlystoppingwithvalidationaccuracyinC𝑎\n𝑃𝑎 ∑︁ 𝑃𝑎 𝑃𝑎\nM 𝑖 =argmin ℓ(M 𝑖,𝑑)+𝛼∥M 𝑖 ∥ ,\n𝜃 𝜃′′ 𝜃′′ 1\n𝜃 𝑑∈D𝑎\n𝑖\ngenericmodelparameters.Thisrestorationmayenhancegeneralizability,ensuringrobustperformanceinunseen\ncontextsC𝑢.Theapproachpresentedinthispaperisfoundedonthisinsightfulstrategy.\n5.2 CRoPApproach\nAlgorithm1describesthepresentedapproach,whichtakesasinput:thegenericmodelM𝐺,userU 𝑖′𝑠 dataD 𝑖𝑎\nforavailablecontextC𝑎,theinitialvalueforthecoefficientofregularization𝛼 andtoleranceforpruning𝜏;and\n𝑃𝑎\ngeneratesthetargetpersonalizedmodelM 𝑖 .Here,𝛼 and𝜏 arehyperparameterswhosevaluescanbetunedfor\n𝜃\nthegivendataandmodel.\nTheapproachinitiatesbyfinetuningthegenericmodelM𝐺 ondataD𝑎 ,concurrentlyapplyingℓ regularization\n𝜃 𝑖 1\nto penalize model parameters (line 2). This regularization encourages sparsity by specifically targeting the\nmagnitudeofredundantparameters[52].Thisstepisfollowedbythepruningofredundantweightsusingthe\n‘ToleratedPrune’module(line3).Theprunedweightsarethenreplacedbythecorrespondingweightsfromthe\ngenericmodelM𝐺 (line4)torestoregeneralizability;thishybridmodelisreferredtoasthe‘MixedModel.’This\nstepleadstothemodificationoftheactivatedpathsinthepersonalizedmodel,resultinginchangesinthemodel\ninferences.However,sincethenewlyactivatedpathsaredeterminedbyweightsretainedfromtwomodelsand\nnotlearnedfromdatapatterns,thereisaconsequentlossofaccuracy,asshownanddiscussedinSection7.2.\nTomitigatesuchaloss,asafinalstep,theMixedModelundergoesfine-tuningonceagainonthedatafromthe\navailablecontextD𝑎\n(line5).Thedetailedexplanationofeachofthesestepsisasfollows:\n𝑖\nPersonalized Finetuning with Penalty (Algorithm 1 – Step 2): The approach uses data\nD𝑎\nto finetune the\n𝑖\ngenericmodelM𝐺\n.AsshownintheSection3(Motivation),suchconventionalfinetuningenhancesthemodel’s\n𝜃\naccuracywithintheavailablecontextC𝑎.Nevertheless,itsperformanceinunfamiliarcontextsmaygetsuboptimal.\nNotably,duringthemodel’sfine-tuningprocess,weapplyℓ regularizationtopenalizethemodelweights,forcing\n1\nthemagnitudesofredundantparameterstobeclosetozero[52].Theregularizationcoefficient𝛼 isatrainable\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 11\nAlgorithm2ToleratedPrune(M,𝜏,D)\n1: Input:M𝜃:AModel ⋄ 𝜏:toleranceforpruning ⋄ D:data\n2:\nPruningAmount𝑝 =𝑘\n3:\n𝐴\n𝑜\n=𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦(M𝜃,D)\n4: repeat\n5: M 𝜃↓ =M𝜃\n6: M𝜃 =𝑃𝑟𝑢𝑛𝑒(M𝜃,𝑝)\n7:\n𝐴=𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦(M𝜃,D)\n8:\nIncrementPruningAmount𝑝 =𝑝+𝑘′\n9:\nuntil𝐴 <𝐴\n𝑜\n−𝜏\n10: returnM 𝜃↓\nparameteroptimizedduringtrainingtominimizetheoverallloss.Asaresult,theparameterswithhighmagnitudes\ncarrymostoftheinformationregardingthedatapatternsinD𝑎\n,offeringtwokeybenefits:\n𝑖\n(1) MinimallossinC𝑎accuracy:Ahighfractionofparametershaveclosetozeromagnitudes,andtheirremoval\nresultsinminimalinformationlossforcontextC𝑎;thus,theadverseimpactofpruningincontextC𝑎 is\nminimized.\n(2) Maximalgeneralization:TheinclusionofregularizationaidsToleratedPrune(discussedbelow)modulein\nefficientlypruningahighernumberofparameters,whicharethenreplacedwithweightsfromthegeneric\nmodel.Thisrestoresinformationfromthegenericmodel,contributingtoenhancedaccuracyinunseen\ncontexts.\nToleratedPruneModule(Algorithm1–Step3): Algorithm2outlinestheToleratedPrunemodule,takingamodel\nM𝜃, pruning tolerance𝜏, and the dataset D as inputs. It initiates with a modest pruning amount of𝑘 and\nincrementallyincreasesthisamountby𝑘′ untilthemodel’saccuracyexhibitsadropof𝜏 percentonD.Here,\n𝑘 and𝑘′ are hyperparameters within the range of (0,1). The module returns M 𝜃↓, representing the pruned\nstateofthemodelbeforethelastpruningiteration.Thisstateissuchthatfurtherpruningwouldresultina\nhigheraccuracylossondatasetD thanthetolerableamount𝜏.Thismoduleperformspruningleveragingthe\nconventionalmagnitude-basedunstructuredpruning[96].\n𝑃𝑎\nThus,step3inAlgorithm1generatesaprunedpersonalizedmodelstateM 𝑖 whosepredictionaccuracy\n𝜃↓\n𝑃𝑎\noncontext C𝑎 isatmost𝜏 percentlowerthanthatoftheearlierstateM 𝜃′𝑖 whileusingonlyafractionofits\noriginalparameters.Thenon-zeroweightscorrespondingtotheseparameterscontributesignificantlytomodel\n𝑃𝑎\ninferencefortheavailablecontextC𝑎.Asaresult,M 𝑖 isessentiallytheminimalsub-structureoftheearlier\n𝜃↓\n𝑃𝑎\nstatemodelM 𝜃′𝑖 ,whichiscrucialforcorrectinferenceforcontextC𝑎.Thisenablesreplacingamaximalnumber\nofzeroed-outparameterstoincorporateinformationfromunseencontextsusingthegenericmodelM𝐺\ninthe\n𝜃\nsubsequentsteps.\n𝑃𝑎\nGeneratingtheMixedModel(Algorithm1–Steps4&5): ForgeneratingtheMixedModelM 𝑖 ,thezeroedout\n𝜃′′\nparametersintheprunedmodelM𝑃 𝑖𝑎 arereplacedbythecorrespondingparametersinthegenericmodelM𝐺\n,\n𝜃↓ 𝜃\nenablinggenericknowledgerestoration.\nNotably,modelpruningisoftenfollowedbyafinetuningstep[46,48,96],wheretheprunedmodelundergoes\nre-trainingtorecovertheperformancelostduringthepruningprocess.Wehaveobservedthat,despitetheMixed\nModelexhibitingimprovedperformanceintheunseencontext,thereisanotablelossofaccuracyintheavailable\n,Vol.1,No.1,Article.Publicationdate:November2024.\n12 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\ncontextduetoinconsistentactivatedpaths,asdiscussedearlier.Thus,theresultingMixedModelisfine-tuned\nusingtheavailabledataD𝑎\n.Goyaletal.[25]suggeststhatfine-tuningprocessshouldmirrorpre-trainingfor\n𝑖\neffectivegeneralization.Therefore,ourfine-tuningobjectivealignswiththepre-trainingobjectiveusedinLine2\nforoptimalresults.\nDuringfinetuning,themodelstate,includingthemixedmodel,withthebestvalidationlossontheseencontext,\nisselected.Wefoundthatforsomeindividuals,themixedmodelischosenastheoptimalmodel,whichindicates\nthatforsomeindividuals,furtherfinetuningisnotrequired,andourapproachcanautomaticallyhandlethat\nscenario.\n6 EXPERIMENTS\nThissectiondisplaystheempiricalefficacyofthepresentedapproach.Section6.1providesadetaileddiscussion\nofthefourhumansensingdatasetsandtheirpre-processingusedinourevaluations:PERCEPT-R[7],WIDAR\n[94],ExtraSensory[79]andaStress-sensingdataset[91],andalsoexplainsthecorrespondingmodelarchitectures\nasusedinliterature.Section6.2detailsthemetricsofevaluationusedinthisworkalongwiththeirpractical\nrelevance.ThisisfollowedbyadetaileddiscussionoftheempiricalcomparisonofCRoPwithfivebaselines\nSHOT[43],Packnet[50],Piggyback[51],CoTTa[88]andPTN[10]inSection6.3.Additionally,detaileddiscussions\naboutinterestingpatterns,suchastheimpactofgenericmodelqualityonpersonalization,etc.,arealsoprovided.\nNotably, each dataset offers a varying distribution of data among different classes, necessitating different\nperformancemetricslikeinferenceaccuracyandF1score.Foreachdataset,ourevaluationstayedalignedwith\nthemetricspreviouslyusedinstudiesevaluatedonthesedatasets,withfurtherdetailsavailableintheAppendix\nA.Additionaldetailstosupportreproducibility,suchashyperparameters,linkstothecode,andcomputation\nresourcesutilized,arealsoprovidedinAppendixA.\n6.1 Datasetsandmodels\nThisworkemploysfourreal-worldhuman-sensingdatasetstodemonstratetheempiricalefficacyofCRoP,twoof\nwhichareassociatedwithhealthapplications.First,thePERCEPT-Rdatasethasbeenusedforbinaryclassification\nforpredictingthecorrectnessof/r/soundsinautomatedspeechtherapyapplication[6].Additionally,weusethe\nStressSensingdataset[91]collectedusingapsycho-physiologicalwrist-band,namedEmpaticaE4[17].Tofurther\ndemonstratetheefficacyofCRoP,weincorporatetwobenchmarkhuman-sensingdatasets,whichincludedata\nfromthesameindividualsacrossmultiplecontexts:WIDAR[94]andExtraSensory[79].Specifically,weemploy\nWIDARfora6-classclassificationfocusingongesturerecognitionusingWiFisignals,andExtraSensoryfor\nbinaryclassificationrelatedtohumanactivityrecognitionusingaccelerometerandgyroscopereadings.Details\nonthedatasets,preprocessingforpersonalizedevaluations,andgenericmodeltrainingarediscussedbelow.\nPERCEPT-R:. Thesound/r/hasbeenrecognizedasthemostfrequentlyimpactedsoundinresidualspeech\nsounddisordersinAmericanEnglish[40]andconsideredtobethemostdifficultsoundtotreat.ThePERCEPT-R\nCorpuswascollectedduring34differentcross-sectionalandlongitudinalstudiesofspeech[7]forautomated\nspeechanalysisof/r/.Thedatausedinthisstudycomefromtheprospectivelycollected[6],andcorpusversion\n2.2.2,whichincludesboththepubliclyavailableopenaccesssubset(2.2.2p)andprivatelyhelddatathatwas\nnotpublishedintheopenaccesssubsetafterareviewofconsent/assentpermissions.ItemsinthePERCEPT-R\nCorpusv2.2.2primarilyconsistofsingle-wordspeechaudiocollectedduringclinicaltrialsinvolvingchildren\nwithspeechsounddisordersaffecting/r/,alongwithage-matchedpeerswithtypicalspeech.Thefullcorpus\ncontains179,076labeledutterancesrepresenting662single-rhoticwordsandphrases.Eachaudiofileispaired\nwithaground-truthlabelrepresentinglistenerjudgmentsofrhoticity,derivedbyaveragingbinaryratings(0\n=derhotic,1=fullyrhotic)frommultiplelisteners.Forthisstudy,theheuristicthresholdforconvertingthese\naveragedratingsintobinaryground-truthlabelswas0.66.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 13\nTousethisdatasetforourpersonalizationevaluation,wecollaboratedwithclinicalexpertstoidentifyand\nacquireannotationsof16participantswhohadcorrectandincorrectpronunciationsof/r/soundatpre-treatment\n(baseline-phase)andduringdifferenttreatmentphases.AsoutlinedinSection4,theevaluationtreatspre-treatment\ndataasavailablecontextdata,whiledatafromothertreatmentphasesserveasunseencontextdata.\nWIDAR:. WIDARisadatasetcollectedforthepurposeofgesturerecognition.Itwascollectedusingoff-the-shelf\nWiFilinks(onetransmitterandatleast3receivers).17usersperformed15differentgesturesatdifferentrooms\nandorientations(oftheperson).Thechannelstateinformationiscollectedfromthesedeviceswithamplitude\nnoisesandphaseoffsetsremovedasapreprocessingstep.Thetwocontextsusedforthecurrentworkaredecided\nbasedontheorientationsofthetorsodataandroomID.Room1isaclassroomwithanumberofobjects(e.g.,\ndesksandchairs)init,andRoom2isanearlyemptyhallway.Thedissimilardatadistributionscanbeattributed\ntothedifferencesintheamountofinterruptionsinWiFisignals.Wefollowedthesamenormalizationmethods\nasYangetal.[92].\nExtraSensory: ExtraSensoryisahumanactivityrecognitiondatasetcollectedusingtheExtraSensorymobile\napplication.Anumberoffeatureswerecollectedfromdifferentcellulardevicesandsmartwatches,thoughwe\njustusedtheaccelerometerandgyroscopefeaturesobtainedfromthecellulardevices.Labelsforactivitieswere\nself-reportedbytheusersthroughthemobileapplication.ForourevaluationsonExtraSensory,5userswereleft\noutoftrainingasinglegenericmodel.Thecontextsaredecidedbasedonthelocationofthephone:hand,pocket,\nandbag.\nStressSensingDataset: ThisdatasetmeasuresthephysiologicalimpactsofvariouskindsofStress.Thedataset\nis collected using Empatica E4 Wristband to extract features such as EDA (Electrodermal Activity), a skin\ntemperaturesensor(4Hz),etc,contributingtoatotalof34features.Thedatawascollectedfrom30participants\nwithdifferentdemographics,whowereassignedthelabels‘Stressed’or‘Calm’basedonthedifferentstress-\ninducingorcalmingtaskstheyexperienced.Inordertoadaptthisdatasetfortheproblemaddressedinthiswork,\nwecollaboratedwiththeoriginalauthorstoidentifyparticipantswhoworewristbandsonbothhands,which\nwerethenchosenforthetaskofpersonalization.Additionally,duringthedatacollection,participantswereasked\ntoperformseveralactivities,afewofwhichrestrictedparticipants’movementwhileothersallowedthemto\nmove.Basedonthis,thedatawasannotatedwithmovementpatterns,thatis,stillvs.moving.Thisadditional\nannotationofthedatasetwillbemadepublicalongwiththiswork.Duringthisdataset’sevaluation,thecontext\nisdefinedbyacombinationofthehandonwhichthewristbandwaswornandwhetherornotthepersonwas\nmovingduringthedatacollection.\n6.1.1 Pre-ProcessingoftheDatasets. Wepartitionedeachdatasetintotwodisjointsetsofusers:(1)ageneric\ndatasetfortrainingagenericmodeland(2)apersonalizeddatasetfortrainingapersonalizedmodelforeach\nuser.Todemonstratethecontext-wiserobustness,wefurtherpartitionedeachuser’s(belongingtothelaterset)\npersonalizeddatasetintodifferentcontexts(i.e.,availableC𝑎 andunseencontextC𝑢).Table3presentsthedetails\nofthispartitioning.ForPRECEPT-R,weconsiderdatafromthepre-treatmentphaseastheavailablecontext,and\nthetreatmentphases,whereparticipantsundergoclinicalinterventions,areconsideredtheunseencontext.For\ntheStressSensingdataset,thecontextisdeterminedbytwofactors:thehandonwhichthesensor(EmpaticaE4\nwristband[17])waswornduringdatacollectionandthemovementstatusoftheindividual.ForWIDAR,context\nis determined by the room and torso orientation during data collection, while for the ExtraSensory dataset,\nphone’slocationontheuser’sbody(e.g.,hand,pocket,bag)definesthecontext.Theterm‘Scenario’referstothe\ncombinationofavailableC𝑎 andunseenC𝑢 contextsasoutlinedinTable3.Alldatasets,alongwithcontext-wise\nannotations,willbemadepublic.\nNotably,throughoutthetrainingofpersonalizedmodels,CRoPrefrainsfromutilizinganyinformationfromthe\nunseencontextC𝑢.Therefore,whiletheempiricalstudyindicatesanenhancementinthemodel’sperformancefor\n,Vol.1,No.1,Article.Publicationdate:November2024.\n14 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nDataset→ PERCEPT-R WIDAR ExtraSonsory StressSensing\nTotalusers 515 17 60 30\nUsers’IDfor 17,25,28,336,344,361,362,55, 0,1,2 80,9D,B7,61,7C 1,2,3\nPersonalization 586,587,589,590,591,61,67,80\nScenario1 C𝑎:BaselineStudy C𝑎:Room-1,TorsoOrientation-1,2,3 C𝑎:Hand,Pocket C𝑎:Lefthand,Still\nC𝑢:TreatmentPhase C𝑢:Room2,TorsoOrientation-4,5 C𝑢:Bag C𝑢1:Righthand,Still;C𝑢2:Righthand,Moving\nScenario2 -N/A- C𝑎:Room2,TorsoOrientation-4,5 C𝑎:Bag,Pocket C𝑎:Righthand,Moving\nC𝑢:Room-1,TorsoOrientation-1,2,3 C𝑢:Hand C𝑢1:Lefthand,Moving;C𝑢2:Lefthand,Still\nTable3. Detailsofdatausedforpersonalization\noneorafewunseencontexts,itisaproxyforallunseencontexts.Thismeansthatitisreasonabletoanticipatea\nfavorableperformanceinotherunseencontextsthatarenotavailableonthedataset.\nNotably,thestresssensingdatasethasbeenevaluatedacrosstwodifferentunseencontextvariations.InC 𝑢1,\ntherewasonechangeincontext—achangeinhandwhilekeepingthesamemovementpatternasC𝑎.InC 𝑢2,there\nweretwochanges—achangeinbothhandandmovementpatterns.\n6.1.2 TrainingoftheGenericmodels.\nPERCEPT-R. :Fortheidentified16participantsforourpersonalizationevaluation,theirspeechdatawere\ncollectedlongitudinally,meaningtheirdatacouldbeseparatedintoavailableandunseencontextsversusother\nspeakersinthecorpuswhoonlyhadspeechdataavailablefromaone-timepoint.Thegenericmodelistrained\nfortheremaining499participants(having/r/soundsdisorder)usingperson-disjointvalidationandtestsets.The\naimofthisdatasetistoidentifythecorrectnessof/r/sounds.\nModel:InlinewiththeliteratureBenwayetal.[7],wetriedseveralmodelarchitecturessuchasCNN,DNN,\nBILSTM,etc,whosenumberofparameterswereidentifiedusinggridsearch.Amongthose,thebiLSTMmodel\ncontaining4bidirectionalLSTMlayersfollowedby5linearlayers,accompaniedbyaHardswishactivationlayer,\nwasidentifiedastheonethatexhibitedthebestresultsforthegenericdataandwasusedforthisstudy.\nWIDAR:. Wechose3usersforpersonalizationsincetheseweretheonlyuserswhosedatawascollectedin\nbothrooms.SincethenumberofusersinWIDARisverysmall,theexclusionofallthe3usersfortrainingthe\ngenericmodelwouldhaveresultedinsubstandardmodels.So,Foreachuser,wegenerateddifferentgeneric\nmodelsbyusingdatafromtheother16userswitha14/2persondisjointrandomsplitforthetrainandvalidation\nset.Ourclassificationtargetwasthe6gestureclasses:0,1,2,3,5and8,correspondingtopush,sweep,clap,slide,\ndrawacircle,anddrawzigzag,respectively,asevaluatedintheoriginalwork[94].\nModel:ThemodelusedforWIDARfollowstheLeNetarchitecture[94],whichcontainsthree2Dconvolutional\nlayersfollowedbytwolinearlayers.Eachoftheselayers,exceptthefinalclassificationlayer,isfollowedbya\nReLUactivationlayer.\nExtraSensory: Wechose5usersforpersonalization,andthegenericmodelistrainedon42users,with10users\nbeingleftoutforperson-disjointvalidation.Thetwotargetclassesarewalkingandsitting.\nModel:ThemodelfollowsaCNN-GRU-basedarchitectureusedinHARliterature[23,26,69,93].Themodel\nconsists of three batch-normalized 1D convolution layers followed by a linear layer that feeds into a batch-\nnormalizedrecursive(GRU)layerandtwolinearlayerstogenerateembeddings.Fortheclassificationhead,two\nlinearlayerswereused.\nStressSensingDataset: Forthisbinarytask,threeuserswithdataacrossallcontextswereselectedforpersonal-\nization.Thegenericmodelwastrainedondatafrom21users,withsixadditionalusersfordisjointvalidationand\ntestsets.\nModel:Themodelusesasimplemulti-layer-perceptron(MLP)architecture[16,18,89]consistingof3linear\nlayerswithhiddensizeof128.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 15\n6.2 Metricsforevaluation\nToestablishtheefficacyofCRoP,wequantifytheextentofpersonalizationandgeneralizationachievedthrough\n𝑃𝑎\nthepresentedapproach.Personalizationisgaugedbycomparingourmodel’sM 𝑖 accuracyrelativetothegeneric\n𝜃\nmodelM𝐺 ,whileforgeneralization,weassesstheaccuracyofourmodelM𝑃 𝑖𝑎\nagainstconventionally-finetuned\n𝜃 𝜃\n𝐶𝑎\npersonalizedmodelsM 𝑖.\n𝜃\nTaorietal.[76]arguedthatdirectlycomparingmodelaccuraciesunderdistributionshiftsisnotideal.They\nintroduced‘effectiverobustness,’ametricthatassessesperformancerelativetoanaccuracybaseline.Sincewe\naimtocompareourmodelsagainsttwobaselines—thegenericandconventionallyfinetunedmodels—weadopt\nthe‘effectiverobustnessmetric’andintroducetwospecificmetricsforourcomparison,detailedbelow.Bothof\nthesemetricsconsiderclassificationaccuracyintheavailableC𝑎 andunseenC𝑢 contexts.\nIfA(M,D)representstheclassificationaccuracyofthemodelM fordatasetD and𝑛isthenumberofusers\nselectedforpersonalization,themetricsofevaluationscanbedescribedasfollows:\n(1) Personalization(Δ 𝑃):ItisdefinedasthesumofthedifferencebetweentheaccuracyofM 𝜃𝑃 𝑖𝑎 andM 𝜃𝐺 over\nallthecontextsaveragedoverallusers\nΔ 𝑃 = 𝑛1 ∑︁ ∑︁ (A(M 𝜃𝑃 𝑖𝑎 ,C)−A(M 𝜃𝐺,C))\nU𝑖 C∈{C𝑎,C𝑢}\n𝑃𝑎 𝐶𝑎\n(2) Generalization(Δ 𝐺):ItisdefinedasthesumofthedifferencebetweentheaccuracyofM 𝜃𝑖 andM 𝜃𝑖 over\nallthecontextsaveragedoverallusers.\n1 ∑︁ ∑︁ 𝑃𝑎 𝐶𝑎\nΔ 𝐺 = 𝑛 (A(M 𝜃𝑖,C)−A(M 𝜃𝑖,C))\nU𝑖 C∈{C𝑎,C𝑢}\nInsummary,themetricΔ 𝑃 suggestshowwellthemodelM 𝜃𝑃 𝑖𝑎 performsascomparedtothegenericmodelM 𝜃𝐺 .\nSincethegenericmodelhasnotlearnedtheperson-specificpatterns.ThismetricquantifiesCRoP’sabilitytolearn\n𝐶𝑎\nperson-specificpatterns.Ontheotherhand,conventionallyfinetunedmodelsM 𝑖 maylearnperson-specific\n𝜃\npatternsandforgetthegenericinformationofdifferentcontexts.Thus,themetricΔ 𝐺 quantifiesCRoP’sabilityto\nretaingenericinformation.\nAlltheresultsinthissectionarecomputedasanaverageofaccuracyobtainedforthreerandomseeds.\n6.3 ComparisonwithState-of-the-art\nTodemonstratetheefficacyofCRoPinachievingpersonalizationΔ 𝑃 whilemaintaininggeneralizationΔ 𝐺,we\ncompareCRoPwith5state-of-the-artapproachesSHOT[43],PackNet[50],Piggyback[51],CoTTA[88],and\nPTN[10].\nTable4comparestheperformanceofCRoPwithaforementionedbaselineapproaches.ThevaluesforΔ 𝑃 and\nΔ 𝐺 arecomputedasaverageoveralltheparticipantsusedforpersonalizationforeachdataset.Thedetailed\nresultsforparticipant-specificevaluationsforeachdatasetareprovidedinAppendixBandAppendixB.3shows\ntheerrorsbarsforourapproach.\nTable 4 shows that CRoP significantly outperforms all state-of-the-art (SOTA) methods. On average, the\npersonalizationbenefitsΔ\n𝑃\nachievedbySHOT,PackNet,PiggybackandCoTTAare2.16,26.05,18.01,9.95,and\n4.13percentpoints,respectively,whileCRoPcanachieve35.23percentpoints.However,whilecomparingΔ 𝐺,\nonecanobservethatpersonalizedtrainingusingSHOT,PackNet,PiggybackandCoTTAharmsgeneralizability\nby −25.73, −1.39, −9.43, −17.49 and −23.44 percent points respectively. On the other hand, CRoP shows an\naveragegeneralizationbenefitof7.78.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n16 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nApproach SHOT Packnet Piggyback CoTTA PTN CRoP\nDataset Scenrio Δ 𝑃 Δ 𝐺 Δ 𝑃 Δ 𝐺 Δ 𝑃 Δ 𝐺 Δ 𝑃 Δ 𝐺 Δ 𝑃 Δ 𝐺 Δ 𝑃 Δ 𝐺\nPERCEPT-R Scenario1 -3.11 -5.62 0.10 -2.41 -25.31 -27.83 -45.06 -47.58 -1.16 -3.68 5.08 2.57\nStressSensing Scenario1 -8.19 -62.16 54.70 0.70 43.89 -10.12 21.93 -32.07 1.23 -52.76 67.81 13.81\nSinglecontextChange Scenario2 8.90 -63.27 75.80 3.64 66.22 -5.94 51.47 -20.69 21.76 -50.40 85.25 13.08\nStressSensing Scenario1 -0.49 -47.24 52.46 10.08 32.40 -9.97 30.59 -11.78 6.40 -35.98 54.38 12.00\nDoublecontextChange Scenario2 3.57 -45.49 41.68 -7.36 42.76 -6.25 33.85 -15.19 12.30 -36.74 59.21 10.15\nWIDAR Scenario1 1.67 -0.48 -0.24 -2.37 0.84 -1.28 -1.05 -3.18 -1.99 -4.37 8.56 6.43\nScenario2 1.28 -0.03 -3.55 -5.16 -8.97 -10.57 1.81 0.21 0.00 -2.85 5.90 4.30\nExtraSensory Scenario1 7.63 -10.31 12.19 -5.76 5.03 -12.91 -0.6 -18.54 1.69 -16.72 17.49 -0.46\nScenario2 8.17 2.99 1.33 -3.85 5.22 0.04 -3.43 -8.62 -3.02 -7.47 13.52 8.17\nTable4. ComparisonofCRoPwithbaselineapproachesunderthemetricsofPersonalization(Δ )andGeneralization(Δ ).\n𝑃 𝐺\n(a)Perspective-models (b)Perspective-Contexts\nFig.3. DetailedresultsforStresssensingdatasetUser3underScenario1usingF1scoreastheevaluationmetric\nNotably,domainadaptationandcontinuallearningmethods,suchasSHOT,Packnet,Piggyback,CoTTA,and\nPTN,leveragedatafromnewcontextstoadaptmodelswhilepreservingknowledgefrompreviouscontextsor\ntasks.However,theproblemaddressedinthisworkrequiresthemodeltoperformreasonablywellinacompletely\nunseencontext,forwhichnodata—labeledorunlabeled—isavailableduringtraining.Asaresult,allbaseline\napproachesstrugglesignificantlyinthisscenario.SincethemetricsinSection6.2evaluateperformanceacross\nbothavailableandunseencontexts,thesubstantialperformancedropintheunseencontextnegativelyimpacts\noverallresults.Furthermore,theunsupervisedapproachesSHOT,CoTTA,andPTNachievedlowerΔ\n𝑃\nandΔ\n𝐺\nthansupervisedapproachesPacknet,Piggyback,andCRoP,whichisinlinewithliterature[82].\nThefollowingdiscussesnotablepatternsobservedinthissection’sevaluationsinTable4,insightsintothe\ncharacteristicsofstaticpersonalizationacrossvarioushuman-sensingapplications.\n6.3.1 Forstress-sensingdataset,alltheunsupervisedapproachesshowbetterperformanceondoublecontextchange\nthanthesingle-contextchange. ForScenario1,C𝑎 containssamplesofdatacollectedusingthelefthandwhile\nstayingstill.ForC 𝑢1(singlecontextchange),thehandchangestotherightwhilestayingstill,butinC 𝑢2(double\ncontextchange),bothhandandmotionstatuschanges.Since C 𝑢2 incursgreatershiftincontextthanC 𝑢1,one\ncanexpectthatamodeltrainedonC𝑎 willshowsimilarorworseresultsforC 𝑢2 ascomparedtoC 𝑢1.However,\nunsupervisedapproaches—SHOT,CoTTA,andPTN—exhibithigherΔ 𝑃 andΔ 𝐺 valuesunderC 𝑢2thanC 𝑢1.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 17\nUser-specificresults,however,indicatethatmodelsactuallyperformworseonC 𝑢2.Figure3(a)showsdetailed\nresultsintermsofF1scoreforUser3forgenericmodelM𝐺 ,conventionally-finetunedmodelM𝑃 𝑖𝑎\n,andmodels\n𝜃 𝜃\ngeneratedusingunsupervisedapproaches:SHOT,CoTTAandPTNunderScenario1.Asexpected,allmodels\nperformworsewiththedoublecontextchangeC 𝑢2(CU2=Right-move)comparedtothesinglecontextchange\nC 𝑢1(CU1=Right-still).Despitethis,theΔ 𝑃 andΔ 𝐺 valuessuggestotherwise,explainedasfollows:\nFirst,considerthe Δ 𝑃 results,withthegenericmodelastheaccuracybaseline.Figure3(b)showsthatthe\ngenericmodel’sF1scoredropssignificantlywiththedoublecontextchangeC 𝑢2comparedtothesinglecontext\nchange,C 𝑢1,depictedonthebluelines.Althoughtheperformancebenefitsusingthethreeapproachesarealmost\nsimilarinbothunseencontexts,thedifferenceintheperformanceascomparedtothegenericmodelishigherfor\ndoublecontextchange,thusresultinginhigherΔ 𝑃 Similarly,forΔ 𝐺,withtheconventionallyfinetunedmodel\nasthebaseline,thebestresultsareseenintheavailablecontext,C𝑎 (Left-still).Itsperformanceisonlyslightly\naffectedby thesingle context changebut dropssignificantly in C 𝑢2 due tomovement duringdata collection,\nresultinginahigherΔ 𝐺 forthedoublecontextchange.\nSimilarpatternswereobservedinotherusers,indicatingthatthepoorperformanceofM𝐺 andM𝑃 𝑖𝑎\nduring\n𝜃 𝜃\ndoublecontextchangedrivesthehigherΔ 𝑃 andΔ 𝐺 values,givinganillusionofbetterresultsfordoublecontext\nchangescenarios.\n6.3.2 SignificantperformancedropforPERCEPT-RusingSOTAapproaches. ForthePercept-Rdataset,personal-\nizationappliedtothe16participantsrevealsthatnotallparticipantsbenefitequally.Insomecases,theglobal\nmodelsalreadyperformwell,leavinglittletonoroomforimprovementthroughpersonalization.Insuchcases,\nperformancecanevendropduetooverfittingontheavailablecontextdata.Ourapproachmitigatesthisby\nselecting the best model based on the highest validation accuracy from the available context, thus avoiding\noverfitting.Furthermore,CRoPintroducesatrainableregularizationcoefficientduringtheinitialfinetuningphase,\nwhichpenalizesmodelparameterswhileminimizingclassificationerror(Algorithm1line2-trainableparameter\n𝛼).ThisenablesthemaximalremovaloflessimportantweightsduringtheToleratedPrunestepwithoutimpacting\nperformanceintheavailablecontext(Algorithm1line3).Additionally,wefoundthatfinetuningafterthemodel\nmixingstepwasoftenunnecessary,asthemixedmodeltypicallyemergedasthebestchoice(Algorithm1line\n5).Incontrast,thebaselineapproacheslacktheseconstraints,leadingtoperformancedegradationinboththe\navailableandunseencontexts,negativelyaffectingtheoverallresults.\n6.3.3 Inferiorgenericmodelperformanceleadstohighergaininpersonalization. ForExtraSensoryandStress-\nsensingdatasets,certainusersexperiencesub-optimalperformancewiththegenericmodelM𝐺\nandtheper-\n𝜃\nsonalized finetuning helped not only in available context but also in the unseen contexts. For instance, the\ngenericmodelshowedsuboptimalperformanceforcertainuserssuchasuser‘80’forExtraSensorydatasetunder\nScenario1anduser‘3’forStress-sensingdataset.Suchusersshowhigherbenefitevenintheunseencontext\nwhenpersonalizedusingavailablecontextdata,highlightingtheimportanceofuser-specificpatterns.Thedetails\nexplanationoftheseresultsareprovidedinAppendixB.\n6.3.4 SignificantPerformancegainsforthestress-sensingdatasetforallapproaches. Psychophysiologicalstress\nresponseisinherentlyheterogeneousininter-andintra-userscenarios[54],leadingtosubparperformanceof\nthegenericmodelwithoutpersonalization.AsdiscussedinSection6.3.3,subparperformanceofgenericmodels\nresultsinhighergainduringpersonalization.ThisisevidentfromthesignificantlyhighΔ 𝑃 valuesachievedby\nmostapproachesforthestress-sensingdatasetinTable4.\nThese evaluations confirm that models personalized with CRoP exhibit higher generalizability to unseen\ncontexts,makingthemmoreintra-userrobust.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n18 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n7 EMPIRICALJUSTIFICATIONFORCROP\nThissectionempiricallyjustifiesanddiscusseshowtheuseofdifferentcomponentsofCRoPhelpsinincorporating\npersonalization(Δ 𝑃)andgeneralization(Δ 𝐺).\n7.1 HowdifferentstepsofCRoPfacilitategeneralizability\nThissectionempiricallydiscusseshoweachstepofCRoP(Algorithm1)facilitatesintra-usergeneralizability,\nsignifyingsimilarityinthemodel’sbehaviortowardsavailableC𝑎 (availableduringpersonalizationfinetuning)\nandunseencontextsC𝑢.\nShietal.[70]introducedtheuseofgradientinnerproduct(GIP)toestimatethesimilaritybetweenamodel’s\nbehavioracrossdifferentdomains.If𝐺\n𝑖\nand𝐺\n𝑗\nrepresentthegradientincurredbythemodelforDomains𝐷\n𝑖\nand𝐷 𝑗,thenthesignoftheproduct𝐺 𝑖 ∗𝐺 𝑗 representswhetherthemodeltreatstwodomainssimilarlyornot.\nForinstance,𝐺 𝑖 ∗𝐺 𝑗 > 0signifiesthatthegradientforbothdomainshasthesamedirection.WeusedGIPto\nquantifygeneralization.AhigherGIPvalueforapersonalizedmodelacrossavailable(C𝑎)andunseencontexts(C𝑢)\nindicatesmoresimilarbehaviortowardbothdomains,indicatinghigherintra-usergeneralizability.GIPismeasured\nas:∥(cid:205) 𝑖𝐺 𝑖∥2−(cid:205)\n𝑖\n∥𝐺 𝑖∥2.\nFigure4showsthatfine-tuningthegenericmodel\n(Algorithm1–Step2)onContextC𝑎,optimizesthe\nmodelforthiscontext,leadingtoanegativeGIP,in- User 0 User 1 User 2 Average\ndicatingagreaterdiscrepancybetweentwocontexts. 20000\nSincemodelpruningresultsingeneralization[34],an\n15000\nincreaseinGIPvaluecanbeobservedinthepruned\nmodel(Step3). 10000\nOnfurtheranalysis,wefoundthatthemodelcom-\n5000\nplementarytotheprunedmodel(thatis,theparame-\ntersthatwereremoved)alsocontributedtowardsinter- 0\ncontext behavior discrepancy (negative GIP value).\n-5000\nHowever,thesameparametersinthegenericmodel Generic Finetuned Pruned Mixed Final\n(Line 2) (Line 3) (Line 4) (Line 5)\n(thatarereplacedinStep4)formedamoregeneral-\nizable set of weights, i.e., GIP ≥ 0. Thus, the model\nmixingstep(Step4)introducesfurthergeneralizability Fig.4. VariationofGIPatdifferentstagesofCRoPsignified\n(GIP≥ 0)inthepersonalizedmodel. bythelinesinAlgorithm1\nFinally, as discussed in Section 5.2 and following\nSection7.2,theobjectiveofthefinalfinetuningstepistorecovertheperformanceloss,anditdoesn’taimto\nenhancegeneralizabilityfurther,asalsoshowninFigure4.\n7.2 Justificationfortherequirementoffinalfinetuningstep(Algorithm1Line5)forsomeusers\nInSection5.2,wediscussedthattheMixedModelfromAlgorithm\n1Line4suffersaccuracylossduetoalteredactivationpaths,as\nitcombinesweightsfromthegenericandpersonalizedstages.To\nillustrate,wecomparetheperformanceandactivationmapsof\nthemodelstatesatstep2(M𝑃 𝑖𝑎𝜃′)andtheMixedModel(M𝑃 𝑖𝑎𝜃′′).\n𝑃𝑎\nTable5showsthattheMixedModelM 𝑖 doesshowanaver-\n𝜃′′\nageimprovementof14.43%ininferenceaccuracyfortheunseen\n(a)M𝑃 𝑖𝑎 (b)MixedModel\ncontextC𝑢,duetoretainmentofgenericmodelweights;however, 𝜃′\nthereissignificantlossintheavailablecontextC𝑎 ascomparedto\nFig.5. ActivationmapsinC𝑎forScenario1\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 19\nModel M𝑃 𝑖𝑎 M𝑃 𝑖𝑎 A(M𝑃 𝑖𝑎 ,C)−A(M𝑃 𝑖𝑎 ,C) M𝑃 𝑖𝑎 A(M𝑃 𝑖𝑎 ,C)−A(M𝑃 𝑖𝑎 ,C)\n𝜃′ 𝜃′′ 𝜃′′ 𝜃′ 𝜃 𝜃 𝜃′\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n0 87.06 65.02 70.93 74.64 -16.13 +9.62 83.67 69.53 -3.39 +4.51\n1 89.38 44.38 74.23 72.70 -15.15 +28.32 86.41 54.45 -2.97 +10.07\n2 71.88 64.45 60.09 69.79 -11.79 +5.34 77.02 62.63 +5.14 -1.82\nAverage -14.36 +14.43 -0.41 +4.25\nTable5. PerformanceComparisonofmodelstatesafterinitialfinetuning(Algorithm1line2),modelmixing(Algorithm1\nline4)andfinalfinetuning(Algorithm1line5)forWIDARdatasetunderScenario1\n𝑃𝑎\nthefinetunedmodelM 𝑖 .Weattributethislosstobothpruning-\n𝜃′\ninducedinformationlossandinconsistentchangesinactivation\npaths during model mixing. Figure 5 shows the change in the activation map for a sample from context C𝑎,\n𝑃𝑎\nwhichwascorrectlyclassifierbyM 𝑖 ;however,itgotmisclassifiedafterthemodelmixingstep.Significant\n𝜃′\ndifferencesinactivationmapscanbeobservedforthissample.Thishighlightstheneedforfinetuningtorecover\nlostinformationandrestoreconsistentactivationpaths.\nTable5furthershowsthatthefinalfinetuningstepindeedhelpsrecoverthelossintheavailablecontextC𝑎.\nAlthoughthismayslightlyreduceaccuracyintheunseencontextduetooverwritingsomegenericpatterns,it\nprovidesanaverageimprovementof4.25percentagepointsintheunseencontextC𝑢 ascomparedtothemodel\nachievedafterfirstfinetuning(Algorithm1Line2).Thisshowsthatthefinalfinetuningisnecessaryforsome\nuserstoregainperformancelostinavailablecontextC𝑎.\n8 DETAILSOFABLATIONSTUDY\nThis section presents evaluations showing the effectiveness of the design choices of CRoP, focusing on the\nWIDARdatasetinScenario1.Figure6comparesthecurrentdesignchoiceswithalternativeoptionsavailablein\ntheliterature.Thecomparisonisdoneforeachofthethreeuserschosenforpersonalizationunderbothavailable\nC𝑎 andunseenC𝑢 contexts.Themetricusedforthiscomparisonistheinferenceaccuracy.Similarpatternswere\nobservedinotherscenariosanddatasets.\n8.1 Pruningmechanism\nCRoPusesone-shotmagnitude-basedpruning(𝑀𝑃)[48,96]toremovethelowest-magnitudemodelparameters\nintheToleratedPrunemodule(Algorithm1,Line3).Variousotherpruningmethodsexist,mostrelevantones\nbeing:Gradient-BasedPruning(𝐺𝑃)[46],pruningtop-magnitudeweightsinsteadoflowerones(𝑀𝑃 −𝑇)[5],\nanditerativepruning(𝑀𝑃 −𝐼)[56][30].Acomparativediscussionofthesemethodsisprovidedbelow.\nMagnitude-based(𝑀𝑃)vs.Gradient-basedPruning(𝐺𝑃):Liuetal.[46]introducedgradient-basedpruning\n(𝐺𝑃),whichassignsimportancetomodelparameters(i.e.,kernelsornodes)basedontheℓ normofgradients\n1\n(computedfromthetrainingsetdata)andprunestheleastimportantones.Inliterature(e.g.,[38]),theapproach\nhasbeenshowntoworkonmodelstrainedandtestedonthedatahavingindependentandidenticaldistribution\n(IID).However,inthiswork,datafromcontextsC𝑎 andC𝑢 followdifferentdistributions.Since,accordingtothe\nproblemsetup,onlyC𝑎 dataisaccessible,usingGPinCRoPleadstooverfittingonC𝑎 andpoorperformanceon\nunseencontextsC𝑢.Incontrast,𝑀𝑃 selectsimportantparametersbasedsolelyonweightmagnitude,makingit\nmorerobustandresultinginbetterperformanceonC𝑢.AsshowninFigures6(a),𝐺𝑃 performswellonC𝑎 but\nconsistentlyunderperformscomparedto𝑀𝑃 onC𝑢 acrossallthreeusers.\nTopprune(𝑀𝑃 −𝑇)vs.lowerprune(𝑀𝑃):CRoP’sconventionalmagnitude-basedpruning(𝑀𝑃)removesa\npercentageofthelowest-magnitudeweights,whichtypicallyhaveminimalimpactonmodelinference[48,96].\n,Vol.1,No.1,Article.Publicationdate:November2024.\n20 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nMP (CROP) MP-T L1 (CRoP) L2\nGP MP-I L0 Pol\nUser0-Ca User0-Ca\n0.80\n0.75 0.8\n0.70 0.7\n0.65\nUser2-Cu 0.60 User0-Cu User2-Cu 0.6 User0-Cu\n0.55 0.5\n0.50\n0.4\n0.45\n0.3\nUser2-Ca User1-Ca User2-Ca User1-Ca\nUser1-Cu User1-Cu\n(a)PruningMechanism (b)RegularizationMechanism\nFig.6. Ablationstudyexploringdifferentalternativesfor(a)pruningand(b)regularizationmechanismsusinginference\naccuracyasthemetricofevaluation\nHowever,Bartoldsonetal.[5]suggeststhatpruningthetopweightsandretrainingthem(𝑀𝑃 −𝑇)canimprove\ngeneralizationbycreatingflatterlosslandscapes.Although𝑀𝑃 −𝑇 yieldsmodelsthatgeneralizebetterthan\ntraditionalpersonalizedmodels,Figure6(a)showsthatitperformssignificantlyinferiortoCRoPforallusersin\nbothcontexts.ThisisbecauseCRoPaimstoisolateauser-specificsub-networkthatperformswellintheavailable\ncontextC𝑎,ratherthanfindingagenericsub-network.Pruningtopweightsremovesuser-specificinformation\nlearnedinstep2oftheAlgorithm1,whichslightlyimprovesperformanceinunseencontextC𝑢 butsignificantly\ndegradesperformanceincontextC𝑎.Moreover,sincetheremovedtopweightsareimportantforC𝑎,thefinal\nfinetuningstage(step5oftheAlgorithm1)recapturesthatinformation,overwritingthegenericinformation,\nnullifyingtheapproach’seffect.\nOneshot(𝑀𝑃)vsIterativeapproach(𝑀𝑃 −𝐼)Thepresentedapproach,i.e.,𝑀𝑃,usesaone-shotapproach\nwheretheinitiallyfinetunedmodelundergoesonepassofpruning,mixing,andfinetuning.However,wecompared\nitwithaniterativevariationaswell.Toimplementtheiterativeapproach,𝑀𝑃−𝐼,weallowtheinitiallyfinetuned\nmodeltoundergomultiplepassesofpruning,mixing,andfine-tuning.AsshowninFigure6(a),𝑀𝑃 −𝐼 doesnot\nsignificantlyimprovemodelperformance,yetitincurshighcomputationalcoststhroughrepetition.\nIntheone-shotapproach,the‘ToleratedPrune’module(Algorithm1line3andAlgorithm2)calculatesthe\noptimalpruningamountbyremovingthemaximumparameterswithoutexceedingtheaccuracylossthreshold\n𝜏 forcontext C𝑎.Intheiterativeapproach,wegraduallyreachthesamepruningamountbyremovingsmall\nfractionsofparametersforeachcycle.Theseparametersarereplacedbyweightsfromthegenericmodel,but\nsincethefinetuninglossfunctionresemblestheinitialone,itdrivesthoseweightstolowermagnitudes,causing\nthemtobeprunedagaininthenextcycle.Thisrepeatsuntilthetargetpruningamountisreached,effectively\npruningasimilarsetofweightsastheone-shotmethodbutinsmallersteps.\n8.2 RegularizationMechanisms\nCRoPusesregularizationtopushmodelparameterstowardzero,makingpruningeasierinlatersteps.Weight\npenalty-based regularization methods apply different norms to the model’s weights, such as ℓ , ℓ , ℓ , and\n0 1 2\npolarization.Theℓ normisparticularlyeffectivebecauseitnotonlyreducesmodelparametersbutalsomakes\n1\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 21\nTrain\nDataset Platform Train(s) RSS(MBs)\nUsage(%)\nAMDRyzen95950X16-CoreProcessor 15.18 2787.36 24.99\nAppleM1 102.39 352 0.58\nPERCEPT-R NVIDIARTXA6000 1.94 1132.61 20\nAMDRyzen97950X16-CoreProcessor 14.22 830.97 24.9\nNVIDIAGeForceRTX4090 1.54 1279.2 36\nAMDRyzen95950X16-CoreProcessor 6.95 1469.59 24.9\nAppleM1 11.71 77 0.85\nStress-Sensing NVIDIARTXA6000 8.49 1071.14 7\nAMDRyzen97950X16-CoreProcessor 3.13 633.27 25\nNVIDIAGeForceRTX4090 4.31 1249.79 14\nTable6. ResourcerequirementforonetimetrainingusingCRoP\ntheleastsignificantparameterstozero.Thispropertyalsomakesℓ usefulforfeatureselection[27].Figure\n1\n6(b)comparesallthesepossibleregularizationchoices.Weobservedthatamongℓ ,ℓ ,ℓ andpolarization[97],\n0 1 2\nusingℓ regularizationismosteffectiveintheunseencontext.Thisisbecause,byforcingtheleastimportant\n1\nparameterweightstozero,itallowsmaximumpruningwith‘ToleratedPrune,’helpingtorecoverasmuchgeneric\ninformationaspossible.\n8.3 Fullfinetunevs.partialfinetune\nInordertokeepthezeroed-outparametersaszero,conventionalpruningapproachesfinetuneonlytheweights\nthatareretainedduringthepruningphase.However,inthepresentedapproach,thezeroed-outweightsare\nreplacedbycorrespondingweightsfromthegenericmodel.Thus,therearenozeroparameters.So,thepresented\napproachfinetunesalltheparameters.Westillevaluatedbothfinetuningapproachesandobservedthatthereis\nnosignificantdifferencebetweenthetwoapproaches.\n9 RUN-TIMEANALYSIS\nCRoPisastaticpersonalizationapproachthatrequiresone-timeon-devicetrainingofthegenericmodelduring\npersonalization.Weperformedrun-timeevaluationstoassesstheviabilityoftheCRoPframeworkacrossfive\ndifferentdeploymentplatforms:AMDRyzen95950X16-CoreProcessor,AMDRyzen97950X16-CoreProcessor,\nAppleM1,NVIDIARTXA6000andNVIDIAGeForceRTX4090.Table6showstheresourcesrequiredinthe\ntrainingphaseintermsoftrainingtime(s),processmemory(MBs),andresource,i.e.,GPU/CPUutilization(%)for\ntwohealth-relateddatasets:PERCEPT-RandStress-Sensing.Accordingtoourevaluation,exceptforthescalable\ndevice,AppleM1,thetrainingtimeisacoupleofseconds,andresourcerequirementsareminimal.Evenon\nscalabledeviceslikeAppleM1,computationtimeremainsefficient,withonlyaslightincrease,typicallyaddingat\nmostafewminutes.Sincethisisaone-timeprocess,CRoPisefficientcomparedtocontinuouslearningmethods\nthatrequirerepeatedadaptation.Particularly,thismakesCRoPpracticalforcriticalapplications,suchasclinical\nsettings,whereitincursonlyabrief,one-timecomputationoverheadduringenrollment.\n10 LIMITATIONSANDFUTUREDIRECTION\nSomelimitationsandfutureresearcharediscussedbelow:\n(1) Thepaperperformedalimitedevaluationonpruningparadigmsthroughablationstudiesasitwasnotthe\nprimaryfocusofthestudy.Section8onablationstudyjustifiesCRoP’sdesignchoicebutdoesnotestablish\nanyparticularparadigm’ssuperiorityinunseencontexts.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n22 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n(2) Astheapproachreliesonusingapre-trainedoff-the-shelfmodelasaninput,thequalityofthismodel\ncanimpacttheperformanceofthefinalpersonalizedmodels.AsdiscussedinSection6.3.3,userswith\nsuboptimalperformanceofthegenericmodelshowhighergainthroughpersonalization.Ontheother\nhand,forcertainparticipantsinthePERCEPT-Rdataset,ahigh-performingmodelleavesminimalroomfor\nimprovementthroughpersonalization.\n(3) Werestrictourstudytothemodelsbenchmarkedanddeployedfordatasetsusedinthisworkwithout\naccountingformodelvariability.However,thedifferentmodelarchitecturesemployedacrossallthedatasets\nincorporatearangeoflayerssuchasconvolutional,linear,BiLSTM,andGRU,whichintroducessome\nvariability.\n(4) Someevaluationresults,forinstance,Table4evaluationsareshownasaverage.However,themetricsΔ 𝑃\nandΔ 𝐺 arecalculatedindividuallyforeachperson.Thisisbecausemodelspersonalizedforoneusercannot\nbeappliedtootherusersinreal-worldsituations.Consequently,wefocusourevaluationsonintra-user\ngeneralizability,excludingdiscussionforinter-userorinter-datasetgeneralizability.\n11 BROADERIMPACT\nThispaperaddressesacriticalresearchgap,enhancingthepracticalutilityofhuman-sensingsolutionsinreal-\nworldapplications,particularlyinautomatedhealthcare.Next-generationhealthcaresystems,whichemploy\nneuralnetworksfortasksrangingfromdailyactivitydetection[73,78]tosafety-criticalconditionslikeatrial\nfibrillation[11],benefitfrompersonalizationduetotheheterogeneityinhealthsensingdata[33,67].CRoPoffers\nseveraladvantages:\n(1) EliminatingtheGenericModelTraining:CRoPleveragesoff-the-shelfpre-trainedmodels,eliminating\ntheneedfortraininggenericmodels.Itisespeciallyvaluableinclinicalsettingswhereprivacyconcerns\nrestrictdatasharingfortrainingpurposes[49].Thisincreasesthefeasibilityofdeployingpersonalized\nmodelsinhealthcare.\n(2) Noprivacyconcerns:CRoPoperatesonlocaldevices,eliminatingtheneedfortransferringpotentiallysen-\nsitiveinformationtoacentralserver.Todemonstratescalabilityonlocaldevices,theresourceconsumption\nforCRoPpersonalizationon5devicesisshowninSection9.\n(3) Flexibilitytouseanymodelarchitectures:Asmodelpruninghasprovenapplicabletovariousmodelarchi-\ntectures,CRoPisnotrestrictedtoanymodelarchitectureconstraints,ensuringwide-rangingapplicability.\n12 CONCLUSION\nThisstudyintroducesCRoP,anovelstaticpersonalizationapproachgeneratingcontext-wiseintra-userrobust\nmodelsfromlimitedcontextdata.Usingpruninginanovelwaytobalancepersonalizationandgeneralization,\nempiricalanalysisonfourhuman-sensingdatasetsshowsCRoPmodelsexhibitanaverageincreaseof35.23%in\npersonalizationcomparedtogenericmodelsand7.78%ingeneralizationcomparedtoconventionally-finetuned\npersonalizedmodels.CRoPutilizesoff-the-shelfmodels,reducingtrainingeffortandaddressingprivacycon-\ncerns.Withpracticalbenefitsandquantitativeperformanceenhancements,CRoPfacilitatesreliablereal-world\ndeploymentforAI-basedhuman-sensingapplicationslikehealthcare.\nREFERENCES\n[1] FarhadAhamedandFarnazFarid.Applyinginternetofthingsandmachine-learningforpersonalizedhealthcare:Issuesandchallenges.\nIn2018InternationalConferenceonMachineLearningandDataEngineering(iCMLDE),pages19–21.IEEE,2018.\n[2] Apple.Workouttypesonapplewatch.https://support.apple.com/en-us/HT207934,2023.\n[3] MartinArjovsky,LéonBottou,IshaanGulrajani,andDavidLopez-Paz.Invariantriskminimization,2020.URLhttps://arxiv.org/abs/\n1907.02893.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 23\n[4] AyoAwobajo.3tipstomakegoogleassistantyourown.https://blog.google/products/assistant/how-to-personalize-google-assistant/,\n2023.\n[5] BrianR.Bartoldson,AriS.Morcos,AdrianBarbu,andGordonErlebacher. Thegeneralization-stabilitytradeoffinneuralnetwork\npruning,2020.\n[6] N.R.BenwayandJ.L.Preston. Artificialintelligenceassistedspeechtherapyfor/r/usingspeechmotorchainingandthepercept\nengine:asinglecaseexperimentalclinicaltrialwithchainingai.,2023.URLhttps://surface.syr.edu/etd/1703.\n[7] NinaRBenway,JonathanLPreston,ElaineHitchcock,YvanRose,AsifSalekin,WendyLiang,andTaraMcAllister.Reproduciblespeech\nresearchwiththeartificialintelligence-readyPERCEPTcorpora.J.SpeechLang.Hear.Res.,66(6):1986–2009,June2023.\n[8] VisarBerisha,ChelseaKrantsevich,PRichardHahn,ShiraHahn,GautamDasarathy,PavanTuraga,andJulieLiss.Digitalmedicineand\nthecurseofdimensionality.NPJDigit.Med.,4(1):153,October2021.\n[9] MehdiBoukhechba,AnnaNBaglione,andLauraEBarnes.Leveragingmobilesensingandmachinelearningforpersonalizedmental\nhealthcare.Ergonomicsindesign,28(4):18–23,2020.\n[10] DavidBurns,PhilipBoyer,ColinArrowsmith,andCariWhyne.Personalizedactivityrecognitionwithdeeptripletembeddings.Sensors,\n22(14),2022.ISSN1424-8220.doi:10.3390/s22145222.URLhttps://www.mdpi.com/1424-8220/22/14/5222.\n[11] JonahComstock.Study:Applewatchpairedwithdeepneuralnetworkdetectsatrialfibrillationwith97percentaccuracy,2017.\n[12] BotosCsaba,WenxuanZhang,MatthiasMüller,Ser-NamLim,MohamedElhoseiny,PhilipTorr,andAdelBibi.Labeldelayinonline\ncontinuallearning,2024.URLhttps://arxiv.org/abs/2312.00923.\n[13] ZacharyA.Daniels,JunHu,MichaelLomnitz,PhilMiller,AswinRaghavan,JoeZhang,MichaelPiacentino,andDavidZhang.Efficient\nmodeladaptationforcontinuallearningattheedge,2023.\n[14] AntonioD’InnocenteandBarbaraCaputo. Domaingeneralizationwithdomain-specificaggregationmodules. InThomasBrox,\nAndrésBruhn,andMarioFritz,editors,PatternRecognition,pages187–198,Cham,2019.SpringerInternationalPublishing. ISBN\n978-3-030-12939-2.\n[15] DiDuan,HuanqiYang,GuohaoLan,TianxingLi,XiaohuaJia,andWeitaoXu.Emgsense:Alow-effortself-superviseddomainadaptation\nframeworkforemgsensing.In2023IEEEInternationalConferenceonPervasiveComputingandCommunications(PerCom),pages160–170,\n2023.doi:10.1109/PERCOM56429.2023.10099164.\n[16] MaciejDzieżyc,MartinGjoreski,PrzemysławKazienko,StanisławSaganowski,andMatjažGams.Canweditchfeatureengineering?\nend-to-enddeeplearningforaffectrecognitionfromphysiologicalsensordata.Sensors,20(22):6535,2020.\n[17] empetica.Real-timephysiologicalsignals:E4eda/gsrsensor,2015.URLhttps://www.empatica.com/research/e4/.\n[18] EdaErenandTuğbaSelcenNavruz.Stressdetectionwithdeeplearningusingbvpandedasignals.In2022InternationalCongresson\nHuman-ComputerInteraction,OptimizationandRoboticApplications(HORA),pages1–7.IEEE,2022.\n[19] EnricoFini,VictorGTurrisidaCosta,XavierAlameda-Pineda,ElisaRicci,KarteekAlahari,andJulienMairal.Self-supervisedmodels\narecontinuallearners.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,2022.\n[20] USFoodandDrugAdministration.Proposedregulatoryframeworkformondificationstoartificialintelligence/machinelearning-based\nsoftwareasamedicaldevice.USFoodandDrugAdministration:SilverSpring,MD,USA,63,2019.doi:10.1016/j.apergo.2017.04.011.\n[21] YaroslavGaninandVictorLempitsky.Unsuperviseddomainadaptationbybackpropagation.InProceedingsofthe32ndInternational\nConferenceonInternationalConferenceonMachineLearning-Volume37,ICML’15,page1180–1189.JMLR.org,2015.\n[22] YaroslavGanin,EvgeniyaUstinova,HanaAjakan,PascalGermain,HugoLarochelle,FrançoisLaviolette,MarioMarchand,andVictor\nLempitsky.Domain-adversarialtrainingofneuralnetworks.J.Mach.Learn.Res.,17(1):2096–2030,January2016.ISSN1532-4435.\n[23] TaesikGong,YeonsuKim,JinwooShin,andSung-JuLee.Metasense:few-shotadaptationtountrainedconditionsindeepmobilesensing.\nInProceedingsofthe17thConferenceonEmbeddedNetworkedSensorSystems,SenSys’19,page110–123,NewYork,NY,USA,2019.\nAssociationforComputingMachinery.ISBN9781450369503.doi:10.1145/3356250.3360020.URLhttps://doi.org/10.1145/3356250.3360020.\n[24] TaesikGong,YewonKim,AdibaOrzikulova,YunxinLiu,SungJuHwang,JinwooShin,andSung-JuLee.Dapper:Label-freeperformance\nestimationafterpersonalizationforheterogeneousmobilesensing.ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitous\nTechnologies,7(2):1–27,2023.\n[25] SachinGoyal,AnanyaKumar,SankalpGarg,ZicoKolter,andAditiRaghunathan. Finetunelikeyoupretrain:Improvedfinetuning\nofzero-shotvisionmodels. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),pages\n19338–19347,June2023.\n[26] YujiaoHao,RongZheng,andBoyuWang.Invariantfeaturelearningforsensor-basedhumanactivityrecognition.IEEETransactionson\nMobileComputing,21(11):4013–4024,2022.doi:10.1109/TMC.2021.3064252.\n[27] AminUlHaq,JianPingLi,MuhammadHammadMemon,Jalaluddinkhan,AsadMalik,TanvirAhmad,AmjadAli,ShahNazir,IjazAhad,\nandMohammadShahid.Featureselectionbasedonl1-normsupportvectormachineandeffectiverecognitionsystemforparkinson’s\ndiseaseusingvoicerecordings.IEEEAccess,7:37718–37734,2019.doi:10.1109/ACCESS.2019.2906350.\n[28] MdYousufHarun,JhairGallardo,TylerL.Hayes,andChristopherKanan. HowEfficientAreToday’sContinualLearningAlgorithms?\n.In2023IEEE/CVFConferenceonComputerVisionandPatternRecognitionWorkshops(CVPRW),pages2431–2436,LosAlamitos,CA,\nUSA,June2023.IEEEComputerSociety. doi:10.1109/CVPRW59228.2023.00241. URLhttps://doi.ieeecomputersociety.org/10.1109/\n,Vol.1,No.1,Article.Publicationdate:November2024.\n24 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nCVPRW59228.2023.00241.\n[29] TylerL.Hayes,NathanD.Cahill,andChristopherKanan. Memoryefficientexperiencereplayforstreaminglearning,2019. URL\nhttps://arxiv.org/abs/1809.05922.\n[30] TorstenHoefler,DanAlistarh,TalBen-Nun,NikoliDryden,andAlexandraPeste.Sparsityindeeplearning:Pruningandgrowthfor\nefficientinferenceandtraininginneuralnetworks.J.Mach.Learn.Res.,22(1),jan2021.ISSN1532-4435.\n[31] Jin-HyukHong,JulianRamos,andAnindK.Dey.Towardpersonalizedactivityrecognitionsystemswithasemipopulationapproach.\nIEEETransactionsonHuman-MachineSystems,46(1):101–112,2016.doi:10.1109/THMS.2015.2489688.\n[32] AndreaIaboni,SofijaSpasojevic,KristineNewman,LoriSchindelMartin,AngelWang,BingYe,AlexMihailidis,andShehrozSKhan.\nWearablemultimodalsensorsforthedetectionofbehavioralandpsychologicalsymptomsofdementiausingpersonalizedmachine\nlearningmodels.Alzheimer’s&Dementia:Diagnosis,Assessment&DiseaseMonitoring,14(1):e12305,2022.\n[33] WenhuiJi,JingyuZhu,WanxiaWu,NanxiangWang,JiqingWang,JianshengWu,QiongWu,XuewenWang,ChangminYu,Gaofeng\nWei,etal.Wearablesweatbiosensorsrefreshpersonalizedhealth/medicaldiagnostics.Research,2021.\n[34] TianJin,MichaelCarbin,DanielM.Roy,JonathanFrankle,andGintareKarolinaDziugaite.Pruning’seffectongeneralizationthrough\nthelensoftrainingandregularization.InAliceH.Oh,AlekhAgarwal,DanielleBelgrave,andKyunghyunCho,editors,Advancesin\nNeuralInformationProcessingSystems,2022.URLhttps://openreview.net/forum?id=OrcLKV9sKWp.\n[35] JamesKirkpatrick,RazvanPascanu,NeilRabinowitz,JoelVeness,GuillaumeDesjardins,AndreiA.Rusu,KieranMilan,JohnQuan,\nTiagoRamalho,AgnieszkaGrabska-Barwinska,DemisHassabis,ClaudiaClopath,DharshanKumaran,andRaiaHadsell.Overcoming\ncatastrophicforgettinginneuralnetworks.ProceedingsoftheNationalAcademyofSciences,114(13):3521–3526,2017.doi:10.1073/pnas.\n1611835114.URLhttps://www.pnas.org/doi/abs/10.1073/pnas.1611835114.\n[36] WouterM.KouwandMarcoLoog.Anintroductiontodomainadaptationandtransferlearning,2019.URLhttps://arxiv.org/abs/1812.\n11806.\n[37] DanielBKowalsky,JohnRRebula,LauroVOjeda,PeterGAdamczyk,andArthurDKuo.Humanwalkingintherealworld:Interactions\nbetweenterraintype,gaitparameters,andenergyexpenditure.PLoSOne,16(1):e0228682,January2021.\n[38] AlexKrizhevskyandGeoffreyHinton.Learningmultiplelayersoffeaturesfromtinyimages.Technicalreport,UniversityofToronto,\nToronto,Ontario,2009.URLhttps://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf.\n[39] BishalLamichhane,JoanneZhou,andAkaneSano.Psychoticrelapsepredictioninschizophreniapatientsusingapersonalizedmobile\nsensing-basedsuperviseddeeplearningmodel.IEEEJournalofBiomedicalandHealthInformatics,2023.\n[40] BarbaraALewis,LisaFreebairn,JessicaTag,AllisonACiesla,SudhaKIyengar,CatherineMStein,andHGerryTaylor.Adolescent\noutcomesofchildrenwithearlyspeechsounddisorderswithandwithoutlanguageimpairment.Am.J.Speech.Lang.Pathol.,24(2):\n150–163,May2015.\n[41] DaLi,YongxinYang,Yi-ZheSong,andTimothyM.Hospedales.Learningtogeneralize:meta-learningfordomaingeneralization.In\nProceedingsoftheThirty-SecondAAAIConferenceonArtificialIntelligenceandThirtiethInnovativeApplicationsofArtificialIntelligence\nConferenceandEighthAAAISymposiumonEducationalAdvancesinArtificialIntelligence,AAAI’18/IAAI’18/EAAI’18.AAAIPress,2018.\nISBN978-1-57735-800-8.\n[42] JingjingLi,ErpengChen,ZhengmingDing,LeiZhu,KeLu,andHengTaoShen.Maximumdensitydivergencefordomainadaptation.\nIEEETransactionsonPatternAnalysisandMachineIntelligence,43(11):3918–3930,2021.doi:10.1109/TPAMI.2020.2991050.\n[43] JianLiang,DapengHu,andJiashiFeng. Dowereallyneedtoaccessthesourcedata?sourcehypothesistransferforunsupervised\ndomainadaptation.InInternationalConferenceonMachineLearning(ICML),pages6028–6039,2020.\n[44] HanbingLiu,JinggeWang,XuanZhang,YeGuo,andYangLi. Enhancingcontinuousdomainadaptationwithmulti-pathtransfer\ncurriculum,2024.\n[45] XinLiu,YuntaoWang,SinanXie,XiaoyuZhang,ZixianMa,DanielMcDuff,andShwetakPatel.Mobilephys:Personalizedmobilecamera-\nbasedcontactlessphysiologicalsensing.Proc.ACMInteract.Mob.WearableUbiquitousTechnol.,6(1),mar2022.doi:10.1145/3517225.\nURLhttps://doi.org/10.1145/3517225.\n[46] XueLiu,WeijieXia,andZhimiaoFan.Adeepneuralnetworkpruningmethodbasedongradientl1-norm.In2020IEEE6thInternational\nConferenceonComputerandCommunications(ICCC),pages2070–2074,2020.doi:10.1109/ICCC51575.2020.9345039.\n[47] MingshengLong,JianminWang,YueCao,JiaguangSun,andPhilipS.Yu.Deeplearningoftransferablerepresentationforscalable\ndomainadaptation.IEEETransactionsonKnowledgeandDataEngineering,28(8):2027–2040,2016.doi:10.1109/TKDE.2016.2554549.\n[48] Jian-HaoLuo,JianxinWu,andWeiyaoLin.Thinet:Afilterlevelpruningmethodfordeepneuralnetworkcompression.InICCV,pages\n5058–5066,2017.\n[49] BradleyMalin,KennethGoodman,etal.Betweenaccessandprivacy:challengesinsharinghealthdata.Yearbookofmedicalinformatics,\n27(01):055–059,2018.\n[50] ArunMallyaandSvetlanaLazebnik. Packnet:Addingmultipletaskstoasinglenetworkbyiterativepruning. In2018IEEE/CVF\nConferenceonComputerVisionandPatternRecognition,pages7765–7773,2018.doi:10.1109/CVPR.2018.00810.\n[51] ArunMallya,DillonDavis,andSvetlanaLazebnik.Piggyback:Adaptingasinglenetworktomultipletasksbylearningtomaskweights.\nInVittorioFerrari,MartialHebert,CristianSminchisescu,andYairWeiss,editors,ComputerVision–ECCV2018,pages72–88,Cham,\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 25\n2018.SpringerInternationalPublishing.ISBN978-3-030-01225-0.\n[52] K.Mayank.Bxdprimerseries:Lassoregressionmodels,l1regularizationingeneralandcomparisonwithl2regularization,2023.URL\nhttps://www.linkedin.com/pulse/bxd-primer-series-lasso-regression-models-l1-general-comparison-k-/.\n[53] LakmalMeegahapola,WilliamDroz,PeterKun,AmaliaDeGötzen,ChaitanyaNutakki,ShyamDiwakar,SalvadorRuizCorrea,Donglei\nSong,HaoXu,andMiriamBidoglia.Generalizationandpersonalizationofmobilesensing-basedmoodinferencemodels:Ananalysisof\ncollegestudentsineightcountries.ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitousTechnologies,6(4):1–32,2023.\n[54] SujayNagaraj,SarahGoodday,ThomasHartvigsen,AdrienBoch,KopalGarg,SindhuGowda,LucaFoschini,MarzyehGhassemi,\nStephenFriend,andAnnaGoldenberg.Dissectingtheheterogeneityof“inthewild”stressfrommultimodalsensordata.NPJDigital\nMedicine,6(1):237,2023.\n[55] LauraPäeske,TuuliUudeberg,HiieHinrikus,JaanusLass,andMaieBachmann.Correlationbetweenelectroencephalographicmarkers\ninthehealthybrain.Sci.Rep.,13(1):6307,April2023.\n[56] MichelaPaganiniandJessicaForde.Oniterativeneuralnetworkpruning,reinitialization,andthesimilarityofmasks,2020.\n[57] WonilPark,VictorJ.Lee,ByungmoKu,andHirofumiTanaka. Effectofwalkingspeedandplacementpositioninteractionsin\ndeterminingtheaccuracyofvariousnewerpedometers.JournalofExerciseScience&Fitness,12(1):31–37,2014.ISSN1728-869X.doi:\nhttps://doi.org/10.1016/j.jesf.2014.01.003.URLhttps://www.sciencedirect.com/science/article/pii/S1728869X14000057.\n[58] DavidPhelan.Amazonadmitslisteningtoalexaconversations:Whyitmatters.https://shorturl.at/fxN78,2019.\n[59] MichaelPotuck.Howtoresetyourapplewatchfitnesscalibrationformoreaccurateworkoutandactivitydata.https://9to5mac.com/\n2021/08/26/fix-apple-watch-workout-tracking-activity-tracking/,2021.\n[60] A.Prabhu,H.AlKaderHammoud,P.Dokania,P.S.Torr,S.Lim,B.Ghanem,andA.Bibi.Computationallybudgetedcontinuallearning:\nWhatdoesmatter?In2023IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),pages3698–3707,LosAlamitos,\nCA,USA,jun2023.IEEEComputerSociety. doi:10.1109/CVPR52729.2023.00360. URLhttps://doi.ieeecomputersociety.org/10.1109/\nCVPR52729.2023.00360.\n[61] AmyRathbone,SimoneStumpf,CarolineClaisse,ElizabethSillence,LynneCoventry,RichardDBrown,andAbigailCDurrant.People\nwithlong-termconditionssharingpersonalhealthdataviadigitalhealthtechnologies:Ascopingreviewtoinformdesign.PLOSDigit.\nHealth,2(5):e0000264,May2023.\n[62] BoyuRen,EmmaGBalkind,BriannaPastro,ElanaSIsrael,DiegoAPizzagalli,HabiballahRahimi-Eichi,JustinTBaker,andChristianA\nWebb.Predictingstatesofelevatednegativeaffectinadolescentsfromsmartphonesensors:Anovelpersonalizedmachinelearning\napproach.PsychologicalMedicine,pages1–9,2022.\n[63] XavierRobert-Lachaine,HakimMecheri,ChristianLarue,andAndrePlamondon.Effectoflocalmagneticfielddisturbancesoninertial\nmeasurementunitsaccuracy.AppliedErgonomics,63:123–132,092017.doi:10.1016/j.apergo.2017.04.011.\n[64] SadiqSani,StewartMassie,NirmalieWiratunga,andKayCooper.Learningdeepandshallowfeaturesforhumanactivityrecognition.\nInGangLi,YongGe,ZiliZhang,ZhiJin,andMichaelBlumenstein,editors,KnowledgeScience,EngineeringandManagement,pages\n469–482,Cham,2017.SpringerInternationalPublishing.ISBN978-3-319-63558-3.\n[65] PhilipSchmidt,AttilaReiss,RobertDuerichen,ClausMarberger,andKristofVanLaerhoven.Introducingwesad,amultimodaldataset\nforwearablestressandaffectdetection.InProceedingsofthe20thACMInternationalConferenceonMultimodalInteraction,ICMI’18,\npage400–408,NewYork,NY,USA,2018.AssociationforComputingMachinery.ISBN9781450356923.doi:10.1145/3242969.3242985.\nURLhttps://doi.org/10.1145/3242969.3242985.\n[66] FlorianSchroff,DmitryKalenichenko,andJamesPhilbin.Facenet:Aunifiedembeddingforfacerecognitionandclustering.2015IEEE\nConferenceonComputerVisionandPatternRecognition(CVPR),Jun2015.doi:10.1109/cvpr.2015.7298682.URLhttp://dx.doi.org/10.1109/\nCVPR.2015.7298682.\n[67] JulianeRSempionatto,VictorRuiz-ValdepenasMontiel,EvaVargas,HazhirTeymourian,andJosephWang. Wearableandmobile\nsensorsforpersonalizednutrition.ACSsensors,6(5):1745–1760,2021.\n[68] ShivShankar,VihariPiratla,SoumenChakrabarti,SiddharthaChaudhuri,PreethiJyothi,andSunitaSarawagi. Generalizingacross\ndomainsviacross-gradienttraining.InICLR(Poster).OpenReview.net,2018.URLhttp://dblp.uni-trier.de/db/conf/iclr/iclr2018.html#\nShankarPCCJS18.\n[69] QiangShen,HaotianFeng,RuiSong,StefanoTeso,FaustoGiunchiglia,andHaoXu.Federatedmulti-taskattentionforcross-individual\nhumanactivityrecognition.InLudDeRaedt,editor,ProceedingsoftheThirty-FirstInternationalJointConferenceonArtificialIntelligence,\nIJCAI-22,pages3423–3429.InternationalJointConferencesonArtificialIntelligenceOrganization,72022.doi:10.24963/ijcai.2022/475.\nURLhttps://doi.org/10.24963/ijcai.2022/475.MainTrack.\n[70] YugeShi,JeffreySeely,PhilipH.S.Torr,N.Siddharth,AwniHannun,NicolasUsunier,andGabrielSynnaeve.Gradientmatchingfor\ndomaingeneralization.2021.\n[71] LeslieNSmith.Cyclicallearningratesfortrainingneuralnetworks.In2017IEEEwinterconferenceonapplicationsofcomputervision\n(WACV),pages464–472.IEEE,2017.\n[72] GabrielaMStegmann,ShiraHahn,JulieLiss,JeremyShefner,SewardRutkove,KerisaShelton,CaylaJessicaDuncan,andVisarBerisha.\nEarlydetectionandtrackingofbulbarchangesinALSviafrequentandremotespeechanalysis.NPJDigit.Med.,3(1):132,October2020.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n26 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n[73] AllanStisen,HenrikBlunck,SouravBhattacharya,ThorSiigerPrentow,MikkelBaunKjærgaard,AnindDey,TobiasSonne,and\nMadsMøllerJensen.Smartdevicesaredifferent:Assessingandmitigatingmobilesensingheterogeneitiesforactivityrecognition.In\nProceedingsofthe13thACMconferenceonembeddednetworkedsensorsystems,pages127–140,2015.\n[74] C.Tang,L.Qendro,D.Spathis,F.Kawsar,C.Mascolo,andA.Mathur.Kaizen:Practicalself-supervisedcontinuallearningwithcontinual\nfine-tuning.In2024IEEE/CVFWinterConferenceonApplicationsofComputerVision(WACV),pages2829–2838,LosAlamitos,CA,USA,\njan2024.IEEEComputerSociety.doi:10.1109/WACV57701.2024.00282.URLhttps://doi.ieeecomputersociety.org/10.1109/WACV57701.\n2024.00282.\n[75] ChiIanTang,LorenaQendro,DimitrisSpathis,FahimKawsar,AkhilMathur,andCeciliaMascolo.Balancingcontinuallearningand\nfine-tuningforhumanactivityrecognition.ArXiv,abs/2401.02255,2024.URLhttps://api.semanticscholar.org/CorpusID:266755926.\n[76] RohanTaori,AchalDave,VaishaalShankar,NicholasCarlini,BenjaminRecht,andLudwigSchmidt.Measuringrobustnesstonatural\ndistributionshiftsinimageclassification.InProceedingsofthe34thInternationalConferenceonNeuralInformationProcessingSystems,\nNIPS’20,RedHook,NY,USA,2020.CurranAssociatesInc.ISBN9781713829546.\n[77] SiriTeam.Heysiri:Anon-devicednn-poweredvoicetriggerforapple’spersonalassistant.https://machinelearning.apple.com/research/\nhey-siri,2017.\n[78] YunusEmreUstev,OzlemDurmazIncel,andCemErsoy. User,deviceandorientationindependenthumanactivityrecognitionon\nmobilephones:Challengesandaproposal.InProceedingsofthe2013ACMconferenceonPervasiveandubiquitouscomputingadjunct\npublication,pages1427–1436,2013.\n[79] YonatanVaizman,KatherineEllis,andGertLanckriet. Recognizingdetailedhumancontextinthewildfromsmartphonesand\nsmartwatches.IEEEPervasiveComputing,16(4):62–74,2017.doi:10.1109/MPRV.2017.3971131.\n[80] GidoM.vandeVenandAndreasS.Tolias.Generativereplaywithfeedbackconnectionsasageneralstrategyforcontinuallearning,\n2019.URLhttps://arxiv.org/abs/1809.10635.\n[81] GidoMvandeVen,HavaTSiegelmann,andAndreasSTolias. Brain-inspiredreplayforcontinuallearningwithartificialneural\nnetworks.Nat.Commun.,11(1):4069,August2020.\n[82] C.VarmaandPujaPrasad.Supervisedandunsupervisedmachinelearningapproaches—asurvey,022023.\n[83] TanviVerma,LiyuanJin,JunZhou,JiaHuang,MingruiTan,BenjaminChenMingChoong,TingFangTan,FeiGao,XinxingXu,DanielS.\nTing,andYongLiu.Privacy-preservingcontinuallearningmethodsformedicalimageclassification:acomparativeanalysis.Frontiersin\nMedicine,10,2023.ISSN2296-858X.doi:10.3389/fmed.2023.1227515.URLhttps://www.frontiersin.org/journals/medicine/articles/10.\n3389/fmed.2023.1227515.\n[84] RiccardoVolpi,HongseokNamkoong,OzanSener,JohnDuchi,VittorioMurino,andSilvioSavarese.Generalizingtounseendomains\nviaadversarialdataaugmentation.InProceedingsofthe32ndInternationalConferenceonNeuralInformationProcessingSystems,NIPS’18,\npage5339–5349,RedHook,NY,USA,2018.CurranAssociatesInc.\n[85] ChanWang,TianyiyiHe,HongZhou,ZixuanZhang,andChengkuoLee.Artificialintelligenceenhancedsensors-enablingtechnologies\ntonext-generationhealthcareandbiomedicalplatform.Bioelectron.Med.,9(1):17,August2023.\n[86] JindongWang,CuilingLan,ChangLiu,YidongOuyang,TaoQin,WangLu,YiqiangChen,WenjunZeng,andPhilipS.Yu.Generalizing\ntounseendomains:Asurveyondomaingeneralization.IEEETransactionsonKnowledgeandDataEngineering,35(8):8052–8072,2023.\ndoi:10.1109/TKDE.2022.3178128.\n[87] QinWang,OlgaFink,LucVanGool,andDengxinDai.Continualtest-timedomainadaptation,2022.\n[88] QinWang,OlgaFink,LucVanGool,andDengxinDai.Continualtest-timedomainadaptation.InProceedingsofConferenceonComputer\nVisionandPatternRecognition,2022.\n[89] ZhiguangWang,WeizhongYan,andTimOates.Timeseriesclassificationfromscratchwithdeepneuralnetworks:Astrongbaseline.\nIn2017Internationaljointconferenceonneuralnetworks(IJCNN),pages1578–1585.IEEE,2017.\n[90] YananWu,ZhixiangChi,YangWang,KonstantinosN.Plataniotis,andSongheFeng. Test-timedomainadaptationbylearning\ndomain-awarebatchnormalization,2024.\n[91] YiXiao,HarshitSharma,ZhongyangZhang,DessaBergen-Cico,TauhidurRahman,andAsifSalekin. Readingbetweentheheat:\nCo-teachingbodythermalsignaturesfornon-intrusivestressdetection.Proc.ACMInteract.Mob.WearableUbiquitousTechnol.,7(4),jan\n2024.doi:10.1145/3631441.URLhttps://doi.org/10.1145/3631441.\n[92] JianfeiYang,XinyanChen,DazhuoWang,HanZou,ChrisXiaoxuanLu,SumeiSun,andLihuaXie.Sensefi:Alibraryandbenchmark\nondeep-learning-empoweredwifihumansensing,2023.\n[93] ShuochaoYao,ShaohanHu,YiranZhao,AstonZhang,andTarekAbdelzaher.Deepsense:Aunifieddeeplearningframeworkfortime-\nseriesmobilesensingdataprocessing.InProceedingsofthe26thInternationalConferenceonWorldWideWeb,WWW’17,page351–360,\nRepublicandCantonofGeneva,CHE,2017.InternationalWorldWideWebConferencesSteeringCommittee.ISBN9781450349130.doi:\n10.1145/3038912.3052577.URLhttps://doi.org/10.1145/3038912.3052577.\n[94] Y.Zhang,Y.Zheng,K.Qian,G.Zhang,Y.Liu,C.Wu,andZ.Yang.Widar3.0:Zero-effortcross-domaingesturerecognitionwithwi-fi.IEEE\nTransactionsonPatternAnalysisandMachineIntelligence,44(11):8671–8688,nov2022.ISSN1939-3539.doi:10.1109/TPAMI.2021.3105387.\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 27\n[95] KaiyangZhou,YongxinYang,TimothyHospedales,andTaoXiang.Deepdomain-adversarialimagegenerationfordomaingeneralisation.\nProceedingsoftheAAAIConferenceonArtificialIntelligence,34:13025–13032,042020.doi:10.1609/aaai.v34i07.7003.\n[96] MichaelZhuandSuyogGupta.Toprune,ornottoprune:exploringtheefficacyofpruningformodelcompression,2017.\n[97] TaoZhuang,ZhixuanZhang,YuhengHuang,XiaoyiZeng,KaiShuang,andXiangLi.Neuron-levelstructuredpruningusingpolarization\nregularizer. InH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors,AdvancesinNeuralInformationProcessing\nSystems,volume33,pages9865–9877.CurranAssociates,Inc.,2020.URLhttps://proceedings.neurips.cc/paper_files/paper/2020/file/\n703957b6dd9e3a7980e040bee50ded65-Paper.pdf.\nA ENSURINGREPRODUCIBILITY\nDependingonthedistributionofthedata,differentaccuracymeasureshavebeenusedintheliteraturesuch\nasbalancedaccuracy,standardaccuracy,orF1score.Toensureconsistencywiththeoriginalbaselinepapers\nforeachdataset[7,91],wefollowtheirevaluationmetric.Detailedexplanationsandjustificationsareprovided\ninAppendixA.1.Toensurereproducibility,weprovidethehyperparametersusedinboththegeneralmodel\ntrainingphaseandthepersonalizationphaseinAppendixA.2.Thisincludeslearningrate,alpha,𝜏,epochcount,\nandothersettingsspecifictoeachdataset.AdditionallyAppendixA.3andAppendixA.4providedetailsofthe\ncodeandthecomputeresources,respectively.\nA.1 Metricsforclassificationaccuracyevaluation\nWeuseaccuracytomeasuretheperformanceofamodel.However,thecomputationofthismetricdiffersforthe\nfourdatasets.Thedetailsofthemetricsusedforallthedatasetsareasfollows:\n(1) PERCEPT-R:Forthisdataset,Benwayetal.[7]utilizedbalancedaccuracyforthebinaryclassificationtask,\nandweemployedthesamemetricsinourstudy.\n(2) WIDAR:Weusea6-classclassificationforgesturerecognition,andthedistributionofthedataamong\ntheseclassesisnearlybalanced.Thus,standardclassificationaccuracyhasbeenusedforWIDAR.\n(3) ExtraSensory:ThesubsetoftheExtrasensorydatasetusedforthisworkaimsforabinaryclassificationfor\nactivityrecognition.Weobservedthatthedatadistributionwasquiteimbalancedamongthetwoclasses,\nandtherefore,balancedclassificationaccuracywasusedforthisdataset.Balancedaccuracyiscomputedas\ntheaverageoftruepositiverateandtruenegativerate.\n(4) StressSensingDataset:Forthisbinaryclassificationproblem,F1scorehasbeenusedasaperformance\nmetricassuggestedbytheoriginalauthors[91].\nForsimplicity,weusetheterm‘accuracy’toencompassallthemetricsdiscussedabove.\nA.2 Hyperparameters\nTheapproachusesseveralhyperparametersforgenericmodeltrainingandpersonalization.Table7and8show\nthehyperparametervaluesforgenericandpersonalizedmodeltraining,respectively.Thesevaluescorrespondto\nthebestresultsobtainedforthedatabelongingtotheavailablecontextusingagridsearch.Fortrainingthegeneric\nmodel,inadditiontothenumberofepochs,‘BaseLearningRate’and‘MaxLearningRate’(theargumentsfor\nCycleLR[71])arethehyperparameters.Forthepersonalizedmodel,learningrate(fixed),𝛼,𝜏,numberofepochs\nforinitialfinetuning(InitialEpochs),andepochsforfinalfinetuning(FinalEpochs)arethehyperparameters.The\nrangeofthesehyperparametersusedforgridsearchduringpersonalizationisalsomentionedinTable8.\nAdditionally,weuse𝑘 =𝑘′ =0.05fortheToleratedPrunemoduleforPERCEPT-R,WIDAR,andExtraSensory\ndatasets,whilefortheStress-sensingdataset,𝑘 =0.05and𝑘′ =0.01isbeingused.Onemayfinddifferentvalues\ntobesuitableforotherdatasetsandmodelarchitectures.\n,Vol.1,No.1,Article.Publicationdate:November2024.\n28 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\nHyperparameter PERCEPT-R WIDAR ExtraSensory Stress-sensing\nBaseLearningRate 1e-5 1e-07 1.2e-08 5e-5\nMaxLearningRate 1e-5 5e-06 7.5e-07 5e-5\nEpochs 300 1000 150 1000\nTable7. HyperparametersforgenericModels\nHyperparameter Range PERCEPT-R WIDAR ExtraSensory StressSensing\nLearningRate 1e-6-1e-1 1e-5 1e-6 1e-6 1e-5\n𝑎𝑙𝑝ℎ𝑎 1e-6-10 0.01 0.0001 0.5 0.0001\n𝜏 0.01-0.25 0.05 0.2 0.01 0.01\nInitialEpochs 100-1000 300 600 600 1000\nFinalEpochs 100-1000 300 600 1000 1000\nTable8. HyperparametersforPersonalizedModels\nA.3 Code\nThecodeisprovidedatanonymouslinkarrangedintodataset-specificfolders.Eachfoldercontainsthepre-trained\ngeneric model, all the required modules, and the instructions to run the code. The seed values used for the\nevaluationsarealsoprovidedintheshellfiles.Thedatapartitionedintopersonalizedandcontext-wisesetswill\nbereleaseduponpublication.\nA.4 ComputeResources\nAllthecomputationshavebeenperformedonNVIDIAQuadroRTX5000with48RTCoresand16GBGDDR6\nmemory.\nB DETAILEDUSER-SPECIFICRESULTS\nThissectiondiscussestheuser-specificpatterns.AppendixB.1discussesdetailedpersonalization(Δ 𝑃)results\nwhileAppendixB.2discussesgeneralization(Δ 𝐺)results.Further,AppendixB.3showsperson-wisestandard\ndeviationvaluesforgenericM𝐺 ,conventionallyfinetunedM𝐶 𝑖𝑎 andCRoPM𝑃 𝑖𝑎\nmodels.\n𝜃 𝜃 𝜃\nB.1 DetaileddiscussionofΔ results\n𝑃\nThepersonalizedmodelsobtainedusingCRoPexhibithigherclassificationaccuracythanthegenericmodelson\ntheavailablecontext’sdataD𝑎\n,showcasingthebenefitsofpersonalization.Todemonstratetheexistenceofsuch\n𝑖\nimprovement,Tables9a-9handTable11acomparetheperformanceofgenericmodelM𝐺\nandpersonalized\n𝜃\n𝑃𝑎\nmodelsobtainedusingCRoPM 𝑖 .\n𝜃\nWIDAR:. Tables9aand9bshowthatthereisanaverageimprovementof25.25and11.88percentpointsamong\nthreeusersfortheavailablecontextC𝑎 forScenario1andScenario2,respectively.However,thisbenefitcomes\natthecostofareductioninaccuracyfortheunseencontext.Thereisanaveragereductionof16.69and5.97\npercentpointsforScenario1andScenario2,respectively,fortheunseencontextC𝑢.Notably,thelossofaccuracy\nintheunseencontextismuchlowerascomparedtotheconventionally-finetunemodelasdiscussedintheSection\n3(Motivation).\nExtraSensory: SimilarpatternscouldbeobservedfortheExtrasensorydataset.Tables9cand9dshowthat\nthereisanaverageincrementof16.40and18.37percentpointsfortheavailablecontextforScenario1and\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 29\nScenario 2, respectively. Interestingly, the performance of the personalized model for Scenario 1 on unseen\ncontextC𝑢 wasnotadverselyimpacted.ThisisattributedtothefactthattheinertialsensingpatternsofBag\nandPocketphonecarryingmodescapturetheuser’sbodymovement,whereasthephone-in-handmovement\npatternscanbedistinct.InScenario1,C𝑎 comprisespocketandC𝑢 comprisesbag,meaningbothavailableand\nunseencontextsencompasssimilarinertialpatterns,leadingtoadvantageousperformanceevenintheunseen\ncontext.Thisevaluationillustratesminimalintra-usergeneralizabilitylossonunseencontextswhenbothavailable\nandunseencontextssharesimilarusertraits.However,inScenario2,whereonlythehandbelongstotheunseen\ncontextC𝑢,thereisanaveragelossof5.02percentagepointsontheunseencontext.\nStressSensing: Thephysiologicalfeaturesusedinthisdatasetvarysignificantlyfromoneusertoother.Thus,\nTables9e-9hshowthatthegenericmodelsdonotperformwellonpersonalizeddata.Personalizedfinetuning\nenablesthemodeltolearnperson-specificpatterns,allowingthemodel’sperformancetoimprovenotonlyinthe\navailablecontextbutalsointheunseencontext.Thisresultsinaveragepersonalizationbenefit(Δ 𝑃)of67.81and\n85.25forScenario1andScenario2,respectively.ItisimportanttonotethatforeachScenario,onlyonemodelis\ntrainedfortheavailablecontextandtestedfortwodifferentunseencontexts.Moreover,doublecontextchange\n(Tables9gand9h)showslowerpersonalizationbenefitascomparedtosinglecontextchange(Tables9eand9f).\nPERCEPT-R:. Inthisdataset,theheterogeneityoffeaturesamongindividualsisreflectedthroughthedifference\ninpredictionaccuracyofthegenericmodel.ItcanbeobservedinTable11athatforsomeindividuals,thegeneric\nmodelexhibitsover90%accuracyontheavailablecontextdata,whileforothers,thegenericmodel’saccuracy\ndropstoaround60%.Thisresultsinsignificantvariabilityovergainsinavailableandunseencontexts.Overall,\nCRoPyieldsanaveragepersonalizationgainof5.09%.\nOnaverageoverallthedatasets,apersonalizationbenefit(Δ 𝑃)of35.23percentpointsareseenascompared\ntothegenericmodelsacrossthefourdatasetsunderbothscenarios.\nTheseevaluationsestablishthatthepersonalizedmodelsobtainedusingCRoPdemonstrateimprovedperfor-\nmanceovertheavailablecontextdatathanthegenericmodelsandexhibitpersonalization.\nB.2 DetaileddiscussionofΔ results\n𝐺\n𝑃𝑎\nThepersonalizedmodelsobtainedusingCRoP(M 𝑖 )areexpectedtohavehigheraccuracyonunseencontext\n𝜃\n𝐶𝑎\nC𝑢 thantheconventionally-finetunepersonalizedmodels(M 𝜃𝑖)asdiscussedinSection3.Thissectionassesses\nwhethertheresultsalignwiththeseexpectations.\n𝑃𝑎\nWIDAR:. Tables10aand10bdemonstratethatthepersonalizedmodelsM 𝑖 exhibitanaverageincrement\n𝜃\nof8.01and2.85percentpointsintheunseencontextforScenario1andScenario2,respectively.However,an\naveragelossof1.57andanaveragegainof1.44percentpointsinC 𝑎′𝑠 accuracycouldbeobservedforScenario1\nandScenario2,respectively.\nExtrasensory: SimilarpatternscouldbeobservedfortheExtraSensorydatasetwheretheaverageaccuracy\nontheunseencontextimprovedby4.97and12.61percentagepointsforScenario1andScenario2asshown\ninTables9cand10d,respectively.Asexpected,thereisalossof5.43and4.44percentpointsintheavailable\ncontextsforScenario1andScenario2,respectively.\nStressSensing: AsobservedinTables9e-9h,personalizedfinetuningimprovesmodelsperformanceonunseen\ncontextaswell,wecanclaimthatthereissomeperson-specifictraitswhicharecommoninavailableandunseen\ncontext.Whilecomparingourfinalmodelswithconventionally-finetuned models(Tables10e-10h),performance\nboost in both available and unseen context could be observed. This can be attributed to the generalization\nimprovementbenefitsofmodelpruning[34].Thisresultsinaveragegeneralizationbenefit(Δ 𝐺)of13.81and\n,Vol.1,No.1,Article.Publicationdate:November2024.\n30 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n(a)Scenario1forWIDARdataset (b)Scenario2forWIDARdataset\nModel M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C) Model M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n0 63.90 77.09 83.67 69.53 +19.77 -7.56 0 73.28 61.80 82.59 58.38 +9.31 -2.43\n1 61.80 79.78 86.41 54.45 +24.61 -25.33 1 73.18 59.58 92.44 47.90 +19.27 -11.67\n2 45.63 79.81 77.02 62.63 +31.38 -17.18 2 80.45 46.13 87.5 42.31 +7.04 -3.81\nAverage +25.25 -16.69 Average +11.88 -5.97\nΔ 𝑃 +8.55 Δ 𝑃 +5.90\n(c)Scenario1forExtraSensorydataset (d)Scenario2forExtraSensorydataset\nModel M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C) Model M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n61 78.69 69.83 82.59 69.66 +3.9 -0.17 61 76.43 80.00 87.24 73.44 +10.81 -6.56\n7C 78.91 76.41 88.00 71.63 +9.09 -4.78 7C 75.07 92.32 83.18 89.39 +8.11 -2.93\n80 55.84 26.24 82.36 38.87 +26.52 +12.63 80 54.40 88.77 84.49 81.12 +30.09 -7.65\n9D 73.74 85.63 82.81 84.72 +9.07 -0.91 9D 75.58 75.02 82.58 74.65 +7.00 -0.37\nB7 56.06 88.33 89.50 86.97 +33.44 -1.36 B7 59.73 84.58 95.56 77.01 +35.83 -7.57\nAverage +16.40 +1.08 Average +18.37 -5.02\nΔ 𝑃 +17.49 Δ 𝑃 +13.35\n(e)Scenario1forStressSensing-singlecontextchange (f)Scenario2forStressSensing-singlecontextchange\nModel M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C) Model M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 88.39 81.90 94.54 97.59 +6.15 +15.69 1 66.54 64.71 92.38 94.54 +25.84 +29.83\n2 47.40 50.0 77.12 90.47 +29.72 +40.47 2 69.10 50.70 85.26 89.65 +16.16 +38.95\n3 36.90 43.48 96.36 95.31 +59.46 +51.93 3 4.76 11.94 74.40 87.28 +69.64 +75.34\nAverage +31.78 +36.03 Average +37.21 +48.04\nΔ 𝑃 +67.81 Δ 𝑃 +85.25\n(g)Scenario1forStressSensing-doublecontextchange (h)Scenario2forStressSensing-doublecontextchange\nModel M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C) Model M𝐺 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐺,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 88.39 64.71 94.54 76.46 +6.15 +11.75 1 66.54 81.90 92.38 91.07 +25.84 +9.17\n2 47.40 50.70 77.12 63.22 +29.72 +12.52 2 69.10 50.00 85.26 62.84 +16.16 +12.84\n3 36.90 11.94 96.36 55.48 +59.46 +43.54 3 4.76 43.47 74.40 87.45 +69.64 +43.98\nAverage +31.78 +22.60 Average +37.21 +22.00\nΔ 𝑃 +54.38 Δ 𝑃 +59.21\nTable9. DetailedPersonalization(Δ )resultsforWIDAR,ExtraSensoryandStressSensingdataset\n𝑃\n13.08forScenario1andScenario2,respectively,forsinglecontextchange.Similarpersonalizationbenefitscould\nbeseenfordoublecontextchange.\nPERCEPT-R:. AsobservedinTable11b,thevariabilityingeneralizationbenefitsamongdifferentindividualsis\nlesspronouncedascomparedtopersonalizationbenefits.Onaverage,CRoPintroducesageneralizationbenefit\nof2.57%.\nOn average over all the datasets, a generalization benefit (Δ 𝐺) of 7.78% percent points are seen over the\nconventionally-finetuned personalizedmodelsacrossalldatasetsunderbothscenarios.\nB.3 ErrorBars\nTables12a-12ishowsperson-wisestandarddeviationvaluesforgenericM𝐺 ,conventionallyfinetunedM𝐶 𝑖𝑎\n𝜃 𝜃\n𝑃𝑎\nandCRoPM 𝑖 models.\n𝜃\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 31\n(a)Scenario1forWIDARdataset (b)Scenario2forWIDARdataset\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n0 87.06 65.02 83.67 69.53 -3.38 +4.5 0 77.30 57.46 82.59 58.38 +5.29 +0.92\n1 89.38 44.38 86.41 54.45 -2.97 +10.07 1 93.75 42.38 92.45 47.90 -1.30 +5.51\n2 75.39 53.19 77.02 62.63 +1.63 +9.44 2 87.15 40.19 87.5 42.31 +0.34 +2.13\nAverage -1.57 +8.01 Average +1.44 +2.85\nΔ𝐺 +6.43 Δ𝐺 +4.30\n(c)Scenario1forExtraSensorydataset (d)Scenario2forExtraSensorydataset\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n61 88.99 68.09 82.59 69.66 -6.40 +1.57 61 93.90 64.27 87.24 73.47 -6.66 +9.17\n7C 92.58 61.74 88.0 71.63 -4.58 +9.89 7C 89.19 57.13 83.13 89.39 -6.01 +32.26\n80 86.51 49.82 82.36 38.87 -4.14 -10.95 80 89.34 70.23 84.49 81.12 -4.85 +10.89\n9D 88.89 83.14 82.81 84.73 -6.07 +1.58 9D 85.53 72.95 82.58 74.65 -2.95 +1.7\nB7 95.44 64.19 89.50 86.97 -5.94 +22.78 B7 97.30 67.99 95.56 77.01 -1.74 +9.02\nAverage -5.43 +4.97 Average -4.44 +12.61\nΔ𝐺 -0.46 Δ𝐺 +8.17\n(e)Scenario1forStressSensing-singlecontextchange (f)Scenario2forStressSensing-singlecontextchange\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\nModel\nM𝐶𝑖𝑎 M𝑃𝑖𝑎 A(M𝑃𝑖𝑎,C)−A(M𝐶𝑖𝑎,C)\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 91.17 92.15 94.54 97.59 +3.37 +5.44 1 92.37 96.46 92.38 94.54 +0.01 -1.93\n2 68.93 82.81 77.12 90.48 +8.19 +7.67 2 75.57 72.47 85.26 89.65 +9.69 +17.18\n3 84.78 90.13 96.36 95.31 +11.58 +5.18 3 64.86 82.52 74.40 87.28 +9.54 +4.76\nAverage +7.71 +6.10 Average +6.41 +6.67\nΔ𝐺 +13.81 Δ𝐺 +13.08\n(g)Scenario1forStressSensing-doublecontextchange (h)Scenario2forStressSensing-doublecontextchange\nModel M\n𝜃𝐶𝑖𝑎\nM\n𝜃𝑃𝑖𝑎\nA(M\n𝜃𝑃𝑖𝑎,C)−A(M 𝜃𝐶𝑖𝑎,C)\nModel M\n𝜃𝐶𝑖𝑎\nM\n𝜃𝑃𝑖𝑎\nA(M\n𝜃𝑃𝑖𝑎,C)−A(M 𝜃𝐶𝑖𝑎,C)\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 91.17 72.10 94.544 76.46 +3.37 +4.36 1 92.37 87.22 92.38 91.07 +0.01 +3.85\n2 68.93 64.13 77.12 63.22 +8.19 -0.91 2 75.57 59.41 85.26 62.84 +9.69 +3.43\n3 84.78 46.06 96.36 55.48 +11.58 +9.42 3 64.86 83.49 74.40 87.45 +9.54 +3.75\nAverage +7.71 +4.29 Average +6.41 +3.75\nΔ𝐺 +12.00 Δ𝐺 +10.16\nTable10. DetailedGeneralization(Δ )resultsforWIDARExtraSensoryandStressSensingdatasets\n𝐺\n,Vol.1,No.1,Article.Publicationdate:November2024.\n32 • SawinderKaur1,AveryGump2,JingyuXin1,YiXiao4,HarshitSharma4,NinaRBenway3,JonathanLPreston1,AsifSalekin4\n1SyracuseUniversity 2UniversityofWisconsin-Madison 3UniversityofMaryland-CollegePark 4ArizonaStateUniversity\n(a)PersonalizationforPERCEPT-R (b)GeneralizationforPERCEPT-R\nModel M 𝜃𝐺 M 𝜃𝑃𝑖𝑎 A(M 𝜃𝑃𝑖𝑎,C)−A(M 𝜃𝐺,C) Model M 𝜃𝐶𝑖𝑎 M 𝜃𝑃𝑖𝑎 A(M 𝜃𝑃𝑖𝑎,C)−A(M 𝜃𝐶𝑖𝑎,C)\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n17 72.72 60.51 73.30 63.19 +0.58 +2.68 17 70.56 60.17 73.30 63.19 +2.74 +3.01\n25 96.79 87.16 96.30 86.83 -0.49 -0.33 25 94.91 83.8 96.30 86.83 +1.39 +3.03\n28 55.22 54.88 67.12 60.17 +11.90 +5.29 28 64.81 58.84 67.12 60.17 +2.31 +1.33\n336 100 82.03 100 66.69 0 -15.34 336 100 60.79 100 66.69 +0 +5.90\n344 77.54 67.48 81.9 65.36 +4.36 -2.12 344 82.77 64.68 81.9 65.36 -0.88 +0.68\n361 63.63 89.93 64.28 81.73 +0.64 -8.2 361 57.61 78.66 64.28 81.73 +6.67 +3.07\n362 59.03 66.23 78.52 82.51 +19.49 +16.28 362 75.44 82.9 78.52 82.51 +3.08 -0.39\n55 95.77 85.34 97.14 80.41 +1.38 -4.93 55 100 76.86 97.14 80.41 -2.86 +3.55\n586 65.85 58.25 73.17 65.87 +7.32 +7.62 586 70.94 64.46 73.17 65.87 +2.23 +1.41\n587 64.71 65.1 69.4 65.19 +4.68 +0.09 587 70.84 66.23 69.4 65.19 -1.44 -1.04\n589 66.34 60.87 63.69 62.77 -2.64 +1.90 589 67.26 60.59 63.69 62.77 -3.57 +2.18\n590 69.05 61.04 71.08 73.26 +2.03 +12.22 590 67.76 70.54 71.08 73.26 +3.32 +2.73\n591 61.91 58.68 72.03 63.44 +10.12 +4.76 591 71.83 64.2 72.03 63.44 +0.20 -0.76\n61 72.86 69.42 77.78 66.66 +4.92 -2.76 61 74.93 65.23 77.78 66.66 +2.86 +1.43\n67 80.12 77.64 81.00 72.48 +0.89 -5.15 67 79.83 74.16 81.00 72.48 +1.18 -1.68\n80 89.38 85.54 91.22 87.87 +1.85 +2.33 80 89.31 90.33 91.22 87.87 +1.92 -1.68\nAverage +4.19 +0.90 Average +1.20 +1.37\nΔ 𝑃 +5.09 Δ𝐺 +2.57\nTable11. DetailedPersonalization(Δ )andGeneralization(Δ )resultsforPERCEPT-Rdatasets\n𝑃 𝐺\n,Vol.1,No.1,Article.Publicationdate:November2024.\nCRoP:Context-wiseRobustStaticHuman-SensingPersonalization • 33\n(a)Scenario1forWIDARdataset (b)Scenario2forWIDARdataset\nModel M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎 Model M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n0 2.17 0.88 3.69 0.49 2.09 0.29 0 2.67 1.60 1.83 0.95 1.02 0.41\n1 1.49 1.73 1.94 2.97 0.70 1.94 1 1.58 0.64 2.29 0.97 2.22 0.68\n2 3.61 0.68 4.28 5.50 3.8 2.31 2 2.49 0.19 0.79 0.56 1.72 0.39\n(c)Scenario1forExtraSensorydataset (d)Scenario2forExtraSensorydataset\nModel M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎 Model M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n61 2.63 0 4.14 1.65 3.28 2.52 61 3.93 0 4.03 2.67 4.72 1.00\n7C 1.45 0 1.17 0.81 1.36 0.83 7C 2.45 0 2.35 2.50 2.85 0.45\n80 0.42 0 4.17 3.04 2.81 1.44 80 3.33 0 0.65 3.09 1.30 1.01\n9D 0.30 0 2.58 1.08 2.53 0.94 9D 4.18 0 3.22 0.88 5.54 0.80\nB7 0.74 0 3.02 7.28 2.13 3.48 B7 3.13 0 0.83 3.27 0.24 2.79\n(e)Scenario1forStressSensing-singlecon- (f)Scenario2forStressSensing-singlecon-\ntextchange textchange\nModel M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎 Model M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 3.55 0 5.78 4.53 7.94 6.17 1 4.95 0 3.02 0.66 3.02 2.34\n2 5.13 0 14.65 3.71 8.74 10.49 2 13.68 0 2.67 7.82 11.51 5.58\n3 17.61 0 8.17 4.79 15.95 3.45 3 8.25 0 21.02 7.00 17.89 6.57\n(g)Scenario1forStressSensing-doublecon- (h)Scenario2forStressSensing-doublecon-\ntextchange textchange\nModel M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎 Model M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎\n𝜃 𝜃 𝜃 𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢 User C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n1 3.55 0 5.75 3.33 7.94 4.78 1 4.95 0 3.02 3.00 3.02 2.52\n2 5.13 0 14.66 10.19 8.74 8.70 2 13.68 0 2.67 5.62 11.51 0.60\n3 17.61 0 8.17 5.52 15.95 3.58 3 8.25 0 21.02 2.23 17.89 2.07\n(i)PERCEPT-R\nModel M𝐺 M𝑃 𝑖𝑎 M𝐶 𝑖𝑎\n𝜃 𝜃 𝜃\nUser C𝑎 C𝑢 C𝑎 C𝑢 C𝑎 C𝑢\n17 7.17 0 9.75 1.64 4.18 1.11\n25 1.34 0 2.35 2.20 2.29 0.85\n28 3.38 0 15.16 0.85 15.14 0.60\n336 0 0 0 7.25 0 5.64\n344 5.50 0 4.86 1.13 4.10 1.87\n361 15.75 0 13.18 3.96 12.44 6.39\n362 3.10 0 7.59 4.46 4.53 4.83\n55 3.75 0 0 3.32 2.58 2.77\n586 4.01 0 1.09 1.77 3.26 0.22\n587 3.06 0 4.24 1.20 5.48 1.43\n589 0.45 0 2.33 2.72 1.44 0.94\n590 2.26 0 3.20 2.17 5.58 0.57\n591 3.36 0 3.11 1.11 3.91 0.74\n61 9.30 0 6.33 2.37 5.05 1.67\n67 5.50 0 3.59 2.20 3.11 2.38\n80 6.11 0 4.29 1.61 5.69 0.68\nTable12. StandardDeviationforGeneric,conventionallyfinetuneddandCRoPmodelsforWIDAR,ExtraSensoryandStress\nSensingdataset\n,Vol.1,No.1,Article.Publicationdate:November2024.",
    "pdf_filename": "CRoP_Context-wise_Robust_Static_Human-Sensing_Personalization.pdf"
}