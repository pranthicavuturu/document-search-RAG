{
    "title": "Timeline-based Planning and Execution with Uncertainty - Theory, Modeling Methodologies and Practice",
    "context": "",
    "body": "CORSO DI DOTTORATO DI RICERCA IN INFORMATICA E\nAUTOMAZIONE\nXXIX CICLO\nTIMELINE-BASED PLANNING AND EXECUTION\nWITH UNCERTAINTY:\nTHEORY, MODELING METHODOLOGIES AND\nPRACTICE\nDottorando:\nAlessandro Umbrico\n__________________\nDocenti guida:\nProf.ssa Marta Cialdea Mayer\n__________________\nDr. Andrea Orlandini\n__________________\nCoordinatore:\nProf. Stefano Panzieri\n__________________\narXiv:1905.05713v1  [cs.AI]  14 May 2019\n\n\nAbstract\nAutomated Planning is one of the main research ﬁeld of Artiﬁcial In-\ntelligence since its beginnings. Research in Automated Planning aims\nat developing general reasoners (i.e. planners) capable of automati-\ncally solve complex problems. Broadly speaking, planners rely on\na general model characterizing the possible states of the world and\nthe actions that can be performed in order to change the status of the\nworld. Given a model and an initial known state, the objective of a\nplanner is to synthesize a set of actions needed to achieve a particular\ngoal state. The classical approach to planning roughly corresponds\nto the description given above. However, many planning techniques\nhave been introduced in the literature relying on different formalisms\nand making different assumptions on the features of the model of the\nworld. The timeline-based approach is a particular planning paradigm\ncapable of integrating causal and temporal reasoning within a uniﬁed\nsolving process. This approach has been successfully applied in many\nreal-world scenarios although a common interpretation of the related\nplanning concepts is missing. Indeed, there are signiﬁcant differences\namong the existing frameworks that apply this technique. Each frame-\nwork relies on its own interpretation of timeline-based planning and\ntherefore it is not easy to compare these systems. Thus, the objective\nof this work is to investigate the timeline-based approach to planning\nby addressing several aspects ranging from the semantics of the related\nplanning concepts to the modeling and solving techniques. Specif-\nically, the main contributions of this PhD work consist of: (i) the\nproposal of a formal characterization of the timeline-based approach\ncapable of dealing with temporal uncertainty; (ii) the proposal of a\nhierarchical modeling and solving approach; (iii) the development of\na general purpose framework for planning and execution with time-\nlines; (iv) the validation of this approach in real-world manufacturing\nscenarios.\n\nAcknowledgements\nI would like to express my sincere gratitude to my advisors Prof. Marta\nCialdea Mayer and Dr. Andrea Orlandini for their continuous support\nof my Ph.D study and related research, for their patience, motivation\nand knowledge. Their guidance helped me in all the time of research\nand writing of this thesis. I could not have imagined having better\nadvisors and mentors for my Ph.D study.\nMy sincere thanks also goes to Prof. Joachim Hertzberg from Os-\nnabruck University who provided me the opportunity to join his team\nas an intern. It has been a great professional and personal experience\nfor me.\nI thank my fellow labmates and all my friends in the Institute of Cog-\nnitive Science and Technology of National Research Council of Italy.\nWithout their precious support, insightful comments and encourage-\nment it would not be possible to conduct this research. In particular, I\nam grateful to Dr. Amedeo Cesta, for enlightening me the ﬁrst glance\nof research, and to Dr. Stefano Borgo, for introducing me into the\nworld of ontologies.\nLast but not least, I would like to thank my parents and my wife for\ngiving me all the love that I need.\n\nContents\n1\nIntroduction\n1\n2\nPlanning in Artiﬁcial Intelligence\n7\n2.1\nClassical Planning . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.1.1\nSTRIPS\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.2\nPDDL\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.1.3\nHTN\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.2\nPlanning in the Real-World . . . . . . . . . . . . . . . . . . . . .\n13\n2.3\nTemporal Planning\n. . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.3.1\nPDDL2.1 . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.3.2\nHybrid Planning approaches . . . . . . . . . . . . . . . .\n16\n3\nTimeline-based Planning in a Nutshell\n17\n3.1\nEUROPA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.2\nIXTET . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.3\nAPSI-TRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4\nTemporal Formalisms . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.4.1\nThe Simple Temporal Problem . . . . . . . . . . . . . . .\n26\n3.4.2\nThe Simple Temporal Problem with Uncertainty\n. . . . .\n27\n4\nFlexible Timeline-based Planning with Uncertainty\n29\n4.1\nA Running Example: The ROVER Domain . . . . . . . . . . . . .\n30\n4.2\nDomain Speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.2.1\nState Variables . . . . . . . . . . . . . . . . . . . . . . .\n31\n4.2.2\nRestricting the Behavior of State Variables\n. . . . . . . .\n39\n4.2.3\nPlanning Domains\n. . . . . . . . . . . . . . . . . . . . .\n45\n4.3\nFlexible Plans . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n4.4\nProblem Speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . .\n52\ni\n\nCONTENTS\n4.4.1\nPlanning Goals . . . . . . . . . . . . . . . . . . . . . . .\n54\n4.4.2\nSolution Plans\n. . . . . . . . . . . . . . . . . . . . . . .\n55\n5\nThe Extensible Planning and Scheduling Library\n58\n5.1\nThe Modeling Language\n. . . . . . . . . . . . . . . . . . . . . .\n59\n5.1.1\nThe Domain Description Language\n. . . . . . . . . . . .\n60\n5.1.2\nThe Problem Description Language . . . . . . . . . . . .\n68\n5.2\nArchitectural Overview . . . . . . . . . . . . . . . . . . . . . . .\n70\n5.2.1\nRepresentation Framework . . . . . . . . . . . . . . . . .\n71\n5.2.2\nProblem Solving . . . . . . . . . . . . . . . . . . . . . .\n73\n5.2.3\nThe General Solving Procedure\n. . . . . . . . . . . . . .\n75\n5.3\nLooking for Pseudo-controllable Plans . . . . . . . . . . . . . . .\n77\n5.4\nHierarchical Planning with Timelines\n. . . . . . . . . . . . . . .\n81\n5.4.1\nHierarchical Modeling Approach\n. . . . . . . . . . . . .\n81\n5.4.2\nBuilding the Dependency Graph . . . . . . . . . . . . . .\n84\n6\nPlanning and Execution with Timelines under Uncertainty\n88\n6.1\nModel-based Control Architectures . . . . . . . . . . . . . . . . .\n88\n6.2\nExtending the EPSL framework with Execution . . . . . . . . . .\n89\n6.2.1\nThe Execution Process . . . . . . . . . . . . . . . . . . .\n91\n6.2.2\nManaging the Execution Dependency Graph\n. . . . . . .\n95\n6.2.3\nHandling Uncertainty During Execution . . . . . . . . . .\n100\n6.2.4\nThe Importance of Being (Temporally) Robust\n. . . . . .\n101\n6.3\nHuman-Robot Collaboration: a Case Study\n. . . . . . . . . . . .\n103\n6.3.1\nThe FOURBYTHREE Research Project\n. . . . . . . . . .\n104\n6.3.2\nAssembly/Disassembly Operation . . . . . . . . . . . . .\n106\n6.4\nDynamic Task Planning in FOURBYTHREE . . . . . . . . . . . .\n107\n6.4.1\nTask Planning Model for Assembly/Disassembly . . . . .\n108\n6.4.2\nFeasibility Check of the Task Planning Model . . . . . . .\n112\n6.4.3\nThe Dynamic Task Planning Module in Action . . . . . .\n114\n7\nKnowledge-based Control Loop for Flexible Controllers\n118\n7.1\nFlexible Plan-based Control Architectures . . . . . . . . . . . . .\n119\n7.1.1\nThe Manufacturing Case Study\n. . . . . . . . . . . . . .\n120\n7.1.2\nThe Use of Ontologies in Manufacturing\n. . . . . . . . .\n122\n7.2\nKnowledge and Plan-based Control in a Loop . . . . . . . . . . .\n123\n7.2.1\nThe Knowledge-based Control Loop at Runtime\n. . . . .\n125\nii\n\nCONTENTS\n7.3\nModeling Knowledge with Ontology and Contexts\n. . . . . . . .\n126\n7.3.1\nThe DOLCE Ontology . . . . . . . . . . . . . . . . . . .\n127\n7.3.2\nOntological interpretation of Agents and their Environment 129\n7.3.3\nOntology and Engineering of Functions . . . . . . . . . .\n132\n7.3.4\nContext-based Characterization\n. . . . . . . . . . . . . .\n133\n7.3.5\nApplying Ontology and Contexts to the Case Study . . . .\n134\n7.4\nThe Knowledge-Base Life Cycle . . . . . . . . . . . . . . . . . .\n137\n7.4.1\nThe Low-Level Reasoning Step\n. . . . . . . . . . . . . .\n139\n7.4.2\nThe High-Level Reasoning Step . . . . . . . . . . . . . .\n141\n7.5\nGenerating the (Timeline-based) Control Model . . . . . . . . . .\n144\n7.5.1\nBuilding State Variables from Contexts . . . . . . . . . .\n145\n7.5.2\nBuilding Decomposition Rules from Inference Trace . . .\n149\n7.5.3\nThe Resulting Timeline-based Control Model . . . . . . .\n150\n7.6\nThe Knowledge-Based Control Loop in Action\n. . . . . . . . . .\n152\n8\nConcluding Remarks\n156\niii\n\nList of Figures\n2.1\nThe state space of the Vacuum World domain\n. . . . . . . . . . . . .\n8\n3.1\nA graph representation of the STP problem described in Example 1 . . .\n26\n4.1\nState Variable speciﬁcation for the ROVER planning domain . . . . . .\n33\n5.1\nThe layered architecture of the EPSL framework\n. . . . . . . . . . .\n70\n5.2\nThe structure of the plan database in the EPSL framework architecture .\n72\n5.3\nThe structure of a planner in the EPSL framework architecture . . . . .\n74\n5.4\nHierarchical modeling of timeline-based domains\n. . . . . . . . . . .\n83\n5.5\nExtracting domain hierarchy from synchronizations’ constraints\n. . . .\n86\n6.1\nThe EPSL architecture extended with executive capabilities . . . . . .\n90\n6.2\nThe structure of the executive in the EPSL framework . . . . . . . . .\n91\n6.3\nThe structure and interactions of the executive control cycle\n. . . . . .\n93\n6.4\nManagement of the received feedback signals during the control cycle\n.\n95\n6.5\nManagement of the dispatching step during the control cycle . . . . . .\n96\n6.6\nDifferent execution state transitions for: (a) controllable tokens; (b) partially-\ncontrollable tokens; (c) fully-uncontrollable tokens. State transitions tagged\nwith \"c\" are controllable while transitions tagged with \"u\" are uncontrollable100\n6.7\nThe overall ALFA pilot production process\n. . . . . . . . . . . . . .\n106\n6.8\nThe manual procedure of the Assembly/Disassembly process of the ALFA\npilot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n107\n6.9\nThe hierarchy of the task planning domain . . . . . . . . . . . . . . .\n108\n6.10 Deﬁning the workﬂow of work-cell operations . . . . . . . . . . . . .\n109\n6.11 Assigning tasks to the robot and the human\n. . . . . . . . . . . . . .\n110\n6.12 Decomposition of the low-level tasks of the robot controller\n. . . . . .\n111\n6.13 The Gantt chart representation of the plan for the ALFA pilot with respect\nto the earliest start time of the related tokens . . . . . . . . . . . . . .\n112\niv\n\nLIST OF FIGURES\n6.14 Deliberation time on different problems with different assignment policies 113\n6.15 Process-view of the dynamic task planning control module . . . . . . .\n114\n6.16 ROS-based simulation of the dynamic task planning system . . . . . .\n117\n7.1\nA picture of a Transportation Module (on the left) of the RTS and two\npossible conﬁgurations (on the right)\n. . . . . . . . . . . . . . . . .\n121\n7.2\nThe Knowledge-based Control Loop . . . . . . . . . . . . . . . . . .\n124\n7.3\nThe DOLCE taxonomy of particulars . . . . . . . . . . . . . . . . .\n127\n7.4\nThe function ontological taxonomy and its rationale . . . . . . . . . .\n133\n7.5\nExtension of DOLCE ontology . . . . . . . . . . . . . . . . . . . .\n135\n7.6\nThe general class axiom for the TRANSPORTATION MODULE category .\n137\n7.7\nThe knowledge processing mechanism . . . . . . . . . . . . . . . . .\n138\n7.8\nRaw data received from the Diagnosis Module . . . . . . . . . . . . .\n139\n7.9\nInferring collaborators of a TM . . . . . . . . . . . . . . . . . . . .\n141\n7.10 Inferring primitive channels of a TM . . . . . . . . . . . . . . . . . .\n142\n7.11 Inferring complex channels of a TM . . . . . . . . . . . . . . . . . .\n144\n7.12 A (partial) view of the timeline-based model generated for a TM equipped\nwith one cross-transfer unit only . . . . . . . . . . . . . . . . . . . .\n151\n7.13 KB initial inference and planning domain generation . . . . . . . . . .\n152\n7.14 KB inference and planning domain generation during KBCL reconﬁgu-\nration phase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n153\n7.15 Deliberation time with increasing number of goals and different TM con-\nﬁgurations during KBCL setup phase . . . . . . . . . . . . . . . . .\n154\nv\n\nList of Algorithms\n1\nThe EPSL general solving procedure\n. . . . . . . . . . . . . . .\n76\n2\nThe EPSL pseudo-controllability aware solving procedure . . . .\n80\n3\nThe Dependency Graph building procedure\n. . . . . . . . . . . .\n85\n4\nThe EPSL executive control procedure . . . . . . . . . . . . . . .\n92\n5\nThe EPSL executive procedure for the synchronization phase . . .\n94\n6\nThe EPSL executive procedure for the dispatching phase . . . . .\n96\n7\nEDG building procedure . . . . . . . . . . . . . . . . . . . . . .\n99\n8\nThe KBCL procedure for generating the planning model . . . . . . . .\n145\n9\nThe KBCL sub-procedure for generating functional variables . . .\n146\n10\nThe KBCL sub-procedure for generating primitive variables . . .\n147\n11\nThe KBCL sub-procedure for generating external variables . . . .\n148\n12\nThe KBCL sub-procedure for generating synchronization rules . .\n150\nvi\n\nChapter 1\nIntroduction\n\"Maybe the only signiﬁcant difference between a really smart simulation\nand a human being was the noise they made when you punched them.\"\n- Terry Pratchett, The Long Earth\nA\nRTIFICIAL INTELLIGENCE (AI) is the ﬁeld of Computer Science that deals\nwith the development of techniques that aim at endowing machines with\nsome sort of intelligence. There are different research ﬁelds in AI that characterize\nintelligence in different ways and realize different types of intelligent machines\naccordingly. Broadly speaking, \"the term artiﬁcial intelligence is applied when\na machine mimics cognitive functions that humans associate with other human\nminds, such as learning and problem solving\" as stated in [Russell and Norvig,\n2003]. Automated Planning is one of the core ﬁelds of AI since its beginnings. Its\nresearch objective is to endow a machine (an artiﬁcial agent) with the capability of\nautonomously carry out complex tasks. From a practical point of view, this is a key\nenabling feature in application scenarios where direct human involvement is neither\npossible nor safe, e.g. space mission or deep sea exploration. Moreover, the recent\nand continuous improvements of robotic platforms with respect to reliability and\nefﬁciency represent a great opportunity for deploying AI-based techniques in even\nmore common application scenarios (e.g. domestic care, manufacturing, rescue\nmissions).\nA planner is a general problem solver able to automatically synthesize a set\nof actions that allow an agent to achieve some objectives (e.g. explore and gather\nscientiﬁc data about an unknown environment or accomplish some complex task\nwithin the production process of a factory). A planning system usually relies on a\n1\n\nIntroduction\nmodel which represents a general description of the world. The model character-\nizes the environment the agent is supposed to operate in, and the agent capabilities\nin terms of the actions the agent can perform to interact with the environment. The\nclassical approach to planning relies on a logical characterization of the model\nthat focuses on the causal aspects of the problem to solve. States consist of sets of\natoms asserting known facts and properties about the world, e.g. the position of a\nrobot or an object in the environment. Actions encode transitions between states\nby specifying preconditions and effects. Preconditions specify a set of conditions\nthat must be true (i.e. atoms) in order to apply the action in a particular state. Ef-\nfects specify conditions that become true (i.e. positive effects) or false (i.e. negative\neffects) after the application of the action. For example, the action of moving an\nobject from an initial location to a destination location can be applied to all states\nin which the object to move is located at initial location. The states resulting from\nthe application of the action are all those states in which the object is located at the\ndestination location. A planning goal usually consists of a logical formula repre-\nsenting the goal state to achieve, e.g. the state in which all objects of the domain\nare in a desired location. Thus, given an initial state containing a set of known\nfacts about the world (e.g. the initial locations of the objects), the planning system\nmust synthesize a set of actions needed to reach the goal state.\nSTRIPS [Fikes and Nilsson, 1971] is one of the ﬁrst planning system intro-\nduced into the literature whose language inspired the PDDL [Mcdermott et al.,\n1998] which is the standard modeling language for planning. Many planning sys-\ntems have been developed, e.g. SATPLAN [Kautz and Selman, 1992], FF [Hoff-\nmann and Nebel, 2011] or LPG [Gerevini and Serina, 2002], that rely on the classi-\ncal planning formalism and PDDL language. These planners have also shown rel-\nevant solving capabilities on toy problems during the International Planning Com-\npetitions. However, from a practical point of view, the classical planning formalism\nmakes strong assumptions on the features of the problems to model. These assump-\ntions limit the capabilities of classical planners to address real-world problems. For\nexample, classical planning paradigms use an implicit representation of time which\ndoes not allow planners to deal with concurrency, temporal constraints or durative\nactions that are crucial in real-world scenarios. Consequently, several extensions\nto classical planning have been introduced into the literature in order to overcome\nthese limitations and address more realistic problems. These extensions lead to\nthe deﬁnition of several planning paradigms that relax different assumptions of the\nclassical approach. Temporal planning represents the class of planning paradigms\n2\n\nIntroduction\nthat introduce an explicit representation of time into the modeling language.\nThe timeline-based approach is a particular temporal planning paradigm intro-\nduced in early 90’s with HSTS [Muscettola, 1994] which has been successfully\napplied to solve many real-world problems (in space-like contexts mainly). This\napproach takes inspiration from classical control theory and is characterized by\na more practical than logical view of planning. The timeline-based approach fo-\ncuses on the temporal behavior of a system and the related features that must be\ncontrolled. Speciﬁcally, a complex system (e.g. an exploration rover) is modeled\nby identifying a set of relevant features that must be controlled over time within a\nknown temporal horizon (e.g. the wheeled base of the robot or the communication\nfacility). The control process consists in the synthesis of a set of temporal behav-\niors (i.e. the timelines) that describe how the modeled features evolve over time.\nThe main advantage of planning with timelines consists in the representation ap-\nproach, which allows the planner to deal with time and temporal constraints while\nbuilding a plan. Namely, the timeline-based representation fosters a hybrid solving\nprocedure by means of which it is possible to integrate planning and scheduling in\na uniﬁed reasoning mechanism. In general, hybrid reasoning is essential to effec-\ntively address real world problems. Indeed, the key factor inﬂuencing the success-\nful application of planning technologies to real-world problems is the capability of\nsimultaneously dealing with different aspects of the problem like causality, time,\nresources, concurrency or uncertainty at solving time.\nDespite the practical success of timeline-based approach, formal frameworks\ncharacterizing this formalism have been proposed only recently. There are several\nplanning systems that have been introduced into the literature, e.g. EUROPA [Bar-\nreiro et al., 2012], IXTET [Ghallab and Laruelle, 1994], APSI-TRF [Fratini et al.,\n2011], each of which applies its own interpretation of timeline-based planning.\nMoreover, developed Planning and Scheduling (P&S) applications are strictly con-\nnected to the speciﬁc context they have been designed for. Thus, existing timeline-\nbased applications are hard to adapt to different problems. In general, there is a\nlack of methodology in modeling and solving timeline-based problems. Given the\nelements that compose a particular domain, it is not easy to design a suited model\nin order to ralize effettive P&S solutions. In addition, different systems apply dif-\nferent solving approaches and generate plans with different features. Thus, it is not\nsimple to compare different timeline-based systems and it is even more difﬁcult to\ncompare such systems with other existing approaches.\n3\n\nIntroduction\nContribution\nThe objective of this work is to investigate timeline-based planning by taking into\naccount several aspects ranging from the semantics of the main planning concepts\nto the modeling and solving approach. Thus the contribution of the work involves\n(i) the proposal of a formal characterization of the timeline-based approach which\ntakes into account also temporal uncertainty, (ii) the proposal of a hierarchical\nmodeling and solving approach, (iii) the development of a general-purpose frame-\nwork for planning and execution with timelines (EPSL - Extensible Planning and\nScheduling Library), which complies with the proposed formalization and imple-\nments the proposed hierarchical solving procedure and lastly (iv) the validation of\nEPSL and the envisaged approach to timeline-based planning in real-world manu-\nfacturing scenarios.\nThe proposed formalization deﬁnes a clear semantics of concepts like time-\nlines, timeline-based plans and state variables, representing the basic building\nblocks of a planning domain. In particular, the formalization takes into account the\ncontrollability properties in order to model the temporal uncertainty concerning\nthe uncontrollable features of a domain. This is particularly relevant for real-world\nproblems, where not all the features of the domain are controllable with respect\nto the point of view of the artiﬁcial agent. Namely, the environment has uncon-\ntrollable dynamics that may affect the behavior of the system to control and the\noutcome of its operations (e.g. the visibility of the ground station for the commu-\nnication operations of a satellite). The timeline-based plans, generated according\nto the proposed formalization, contain information about the uncertainty of the do-\nmain that can be analyzed to characterize the robustness of the plan with respect to\nits execution. There are several works in this ﬁeld [Vidal and Fargier, 1999, Morris\net al., 2001, Cesta et al., 2010] aiming at analyzing the plan in order to understand\nif, given the possible evolutions of the uncontrollable features of the domain, it is\npossible to complete the execution of the plan. With respect to planning, it is impor-\ntant to leverage the controllability information about the domain during the solving\nprocess in order to generate plans with some desired controllability properties (if\npossible) and therefore, have some information regarding their executability.\nGiven an agent to control, the proposed modeling approach follows a hierar-\nchical speciﬁcation of the domain which is similar to HTN planing [Georgievski\nand Aiello, 2015]. Speciﬁcally the approach proposes a functional characterization\nof the agent at different levels of abstraction. Broadly speaking, a primitive level\ncharacterizes the functional behavior of the physical/logical elements composing\n4\n\nIntroduction\nthe agent in terms of commands they can directly manage over time. Functional\nlevels model complex functions/operations the agent could perform over time by\nleveraging its components. Namely, functional levels model complex activities\n(i.e. complex tasks) the agent can perform by combining the available commands\n(i.e. primitive tasks). Domain rules, like methods in HTN planning, describe the\noperational constraints that allow the agent to implement tasks. They specify hi-\nerarchical decomposition of complex tasks in sets of constraints between primitive\ntasks. The resulting hierarchical structure encodes speciﬁc knowledge about the\ndomain that the planning system can leverage during solving. Speciﬁcally, this\nwork introduces search heuristics that leverages the hierarchical structure of the\nplanning domain to support the plan generation process.\nThe EPSL framework complies with both the formalization and hierarchical\nmodeling/solving approaches presented. EPSL is the major result of this study.\nIt realizes a uniform framework for planning and execution with timelines under\nuncertainty. From the planning point of view, EPSL implements a hierarchical\nsolving approach which is capable of dealing with temporal uncertainty during\nplan generation. Speciﬁcally, the solving procedure leverages information about\nthe temporal uncertainty of the planning domain in order to generate plans with\nsome properties characterizing their robustness with respect to the execution in\nthe real-world. From the execution point of view, EPSL executes the timeline of\na plan by taking into account the controllability properties of the related values\nand adapting the plans to the unexpected behaviors of the environment. EPSL\nplanning and execution capabilities have been successfully applied to real-world\nmanufacturing scenarios showing the effectiveness of the proposed approach.\nOutline\nChapter 2 provides a brief description of the background of Automated Planning in\nAI by describing the classical approaches to planning, the limit of these approaches\nin solving real-world problems and how they have been improved in order to ad-\ndress more realistic problems. Chapter 3 provides a more detailed overview of\nthe timeline-based planning approach and the related state of the art prior to this\nstudy. In particular, this chapter describes some of the most relevant timeline-\nbased systems introduced into the literature (EUROPA, IXTET and APSI-TRF)\ntogether with a brief description of the temporal formalisms this kind of systems\nusually relies on. Chapter 4 enters into the details of the contribution of the study\nby describing the proposed formalization of the timeline-based approach and the\n5\n\nIntroduction\nrelated controllability problem. Chapter 5 describes EPSL its structure and the\nimplemented hierarchical modeling and solving approach. Chapter 6 presents a\nrelevant extension of EPSL that allows the framework to execute plans while man-\naging temporal uncertainty. This chapter also describe the deployment of EPSL to\nan interesting real-world manufacturing scenario of Human-Robot Collaboration\n(HRC). In particular, HRC applications represent well-suited contexts to lever-\nage the EPSL capabilities of dealing with temporal uncertainty at planning and\nexecution time. Chapter 7 presents another interesting application of the EPSL\nframework and its integration with semantic technologies for realizing an extended\nplan-based control architecture. Speciﬁcally, the chapter presents a ﬂexible con-\ntrol architecture, called KBCL (Knowledge-based Control Loop), which has been\napplied to a real-world scenario for controlling reconﬁgurable manufacturing sys-\ntems. KBCL aims at realizing a ﬂexible control process able to dynamically adapt\nthe control model to the different situations that may affect the capabilities of the\nsystem. KBCL investigates the integration and the correlations of ontological anal-\nysis and knowledge processing with the timeline-based planning approach. Finally\nchapter 8 draws some conclusions by providing an assessment of the achieved re-\nsults and illustrates some of the most relevant open points that must be addressed\nin the near future.\n6\n\nChapter 2\nPlanning in Artiﬁcial Intelligence\nP\nLANNING is one of the most relevant research ﬁeld of AI since its beginnings.\nThe objective of a planning system is to automatically solve a problem by\nsynthesizing a set of operations (i.e. a plan) needed to reach a desired goal (i.e.\na desired state or conﬁguration). There are many practical ﬁeld like robotics or\nmanufacturing where planning technologies have provided a signiﬁcant contribu-\ntion. Let us consider, for example, planetary exploration rovers that must operate\nin a context where direct human control is not possible. In such a context, plan-\nning technologies provide the rover with the autonomy needed for navigating an\nunknown environment and gathering scientiﬁc data to communicate.\nThere are different ways to describe the fundamental elements of a planning\nsystem. Such differences have lead to different planning paradigms ranging from\nthose addressing fully observable, deterministic, static and discrete environments,\nto those that deal with partially observable stochastic environments. This chap-\nter does not aim at presenting a complete background on all the planning tech-\nnologies and systems that have been introduced into the literature. Thus, after a\nbrief overview of some classical approaches to planning in section 2.1, section 2.2\nexplains the limits of these planning paradigms and the improvements needed to\naddress real-world problems. Finally, section 2.3 focuses on a particular class of\nplanning paradigms (i.e. Temporal Planning) which extends the classical approach\nby introducing an explicit representation of time.\n2.1\nClassical Planning\nBroadly speaking, a planning system is a general problem solver whose aim is to\nsynthesize a set of operations that, given an initial state, allow the system to reach\n7\n\nPlanning in Artiﬁcial Intelligence\na desired goal state. The reasoning process relies on a model which represents a\ngeneral description of the problem to solve. The model provides a representation\nof the environment in terms of the possible states of the world and the actions the\nsystem can perform to interact with the environment. Thus, a planning process\nstarts from an initial state and iteratively moves to other states by applying the\navailable actions until a desired goal state is reached.\nAn example of a simple planning problem is represented by the Vacuum World\nproblem described in [Russell and Norvig, 2003]. The problem consists of a set of\nrooms that can be either clean or dirty, and a vacuum cleaner which can move be-\ntween (adjacent) rooms and clean the room the vacuum is located in. In this regard,\na state of the world describes the set of rooms that compose the environment, their\nconnections (i.e. whether two rooms are adjacent or not), their states (i.e. whether\nthe rooms are clean or not), and the current room of the vacuum cleaner. The goal\nstate is the state of the world where all rooms are clean. The initial state describes\nthe status of all the rooms and the particular room the vacuum cleaner is initially\nlocated in.\nFigure 2.1: The state space of the Vacuum World domain\nFigure 2.1 shows the state space for the Vacuum World problem with two ad-\njacent rooms. The state space can be seen as a directed graph where the possible\nstates of the world are the nodes and actions are the (directed) edges connecting\ntwo states of the world. Let us consider, for example, the state in Figure 2.1 where\nboth the rooms are dirty and the cleaner is located in the room on the left. The\nexecution of action R (i.e. move right) leads to the state where both the rooms are\n8\n\nPlanning in Artiﬁcial Intelligence\ndirty and the cleaner is located in the room on the right. Similarly, the execution\nof action S (i.e. clean/suck) leads to the state where the cleaner has not changed its\nposition, the room on the left is clean and the room on the right is dirty.\nGiven a state space like the one depicted in Figure 2.1 and a known initial\nstate, the planning process must ﬁnd a sequence of actions needed to reach the\nstate where both rooms are clean. The Vacuum World problem described above is\nvery simple because states are fully observable (e.g. it is always possible to know\nwhether a room is clean or dirty), actions are deterministic (i.e. there is not uncer-\ntainty about the effects of actions) and the search space is small. Thus, the planning\nprocess must simply ﬁnd a path on the graph (i.e. the search space) connecting the\ninitial state with the goal state. However, planning problems are not always fully\nobservable or deterministic and typically entail huge search spaces that cannot be\nexplicitly represented. A more compact and expressive representation/description\nof planning problems is needed and therefore several modeling languages and plan-\nning paradigms have been introduced into the literature.\n2.1.1\nSTRIPS\nSTRIPS (STanford Research Institute Problem Solver) [Fikes and Nilsson, 1971]\nis one of the ﬁrst automated planner and language used in AI. The STRIPS mod-\neling language has represented the basic formalism for many planning paradigms\nthat have been introduced successively. The formalism relies on the ﬁrst-order\npredicate calculus to represent the space of world models the planning system must\nsearch in order to ﬁnd a particular world model (i.e. a state), where a desired goal\nformula is achieved. A world model consists of a set of clauses, i.e. formulas of\nﬁrst-order predicate logic that describe a particular situation concerning the envi-\nronment and the agent. For example, considering a robotic planning problem the\nrelated world models will contain a set of formulas concerning the position of the\nrobot and all objects of the environment. Operators are particular transition func-\ntions that allow the planning system to move from one world model to others. It is\nsupposed that for each world model there exists at least one operator which could\nbe applied to \"transform\" the related world model into another. Thus the resulting\nproblem solver must ﬁnd the appropriate composition of operators that transform\nan initial world model to a \"ﬁnal\" world model which satisﬁes a goal condition (i.e.\na particular logical formula).\nThe problem space of a STRIPS problem is deﬁned by the initial world model,\nthe set of available operators and the goal states. Operators are grouped by schema\n9\n\nPlanning in Artiﬁcial Intelligence\nwhich models a set of instances of applicable operators. Let us consider for exam-\nple the operator goto, used for moving a robot between two points on a ﬂoor. In\nsuch a case, there is a distinct operator for each pair of points of the ﬂoor. There-\nfore it is more convenient to group all these possible instances into an operator\nschema goto(m, n) parametrized by the initial and ﬁnal positions (m and n respec-\ntively). Speciﬁcally, an operator schema describes the effects and the conditions\nunder which the operator is applicable. Effects specify the list of formulas that\nmust be added to the model (the add list) and a list of formulas that must be re-\nmoved (the delete list). Let us consider the example described in [Fikes and Nils-\nson, 1971] concerning a operator push(k, m, n) which models the action of pushing\nan object k from m to n. Such an operation can be modeled by the code below\nwhere ATR(m) is a predicate stating that the robot is at location m, and AT(k, m)\nis a predicate stating that the object k is at location m.\npush(k, m,n)\nprecondition:\nATR(m) ∧AT(k, m)\ndelete list:\nATR(m), AT(k, m)\nadd list:\nATR(n), AT(k, n)\n2.1.2\nPDDL\nThe Problem Domain Description Language (PDDL) is an action-based language\nintroduced in [Mcdermott et al., 1998] for the AIPS-98 planning competition.\nPDDL relies on the STRIPS formalism and aims at deﬁning a standard syntax\nfor expressing planning domains. An early design decision was to separate the de-\nscription of parametrized actions of the domain from the description of the objects,\ninitial conditions and goals that characterize problem instances. Thus the domain\ndescription deﬁnes the general rules and behaviors that characterize as speciﬁc\napplication scenario/context. Given a domain description, a problem description\ninstantiates a planning problem in terms of speciﬁc type and number of objects,\ninitial conditions and goals. In this way, a particular domain description can be\nused to deﬁne many different problem descriptions. PDDL deﬁnes parametrized\nactions by using variables denoting elements of a particular problem instance. In-\ndeed, variables are instantiated to objects of the speciﬁc problem description when\nactions are grounded for applications. Preconditions and effects of actions are log-\nical propositions constructed from predicates, arguments (i.e. objects from a prob-\nlem instance) and logical connectivities. Moreover, PDDL extends the expressive\npower of STRIPS formalism by including the ability to descirbe structured object\n10\n\nPlanning in Artiﬁcial Intelligence\ntypes, specify types for action parameters, specify actions with negative precon-\nditions and conditional effects, as well as introduce the use of quantiﬁcation in\nexpressing both pre- and post- conditions. The code below shows an example of a\nsimple PDDL action which allows a rover to move between two locations.\n(: move\n:parameters (?r - rover ?from ?to - location)\n:precondition (and (at ?r ?from)\n(path ?from ?to))\n:effect (and (not (at ?r ?from))\n(at ?r ?to))\n)\nThe action move has one parameter denoting the particular rover which is mov-\ning, and two other parameters denoting the speciﬁc locations the rover moves from\nand to. Action preconditions specify the conditions that must hold to apply actions.\nAn instance of the action move can be applied if the rover, the action refers to, is\nat the starting location (i.e. the location denoted by variable ?from) and there ex-\nists a path connecting the starting location with the destination (i.e. the location\ndenoted by variable ?to). Action effects specify the state resulting from the ap-\nplication of the action. Thus, once the action has been applied, the rover denoted\nby variable ?r, is no longer at location ?from (negative effect) but is at location\ndenoted by the variable ?to. Note that no temporal information is associated with\naction descriptions. Therefore, effects of actions become valid (i.e. true) as soon as\nactions are applied. Namely, actions in PDDL are instantaneous and there is not\nan explicit representation of time.\n2.1.3\nHTN\nHierarchical Task Network (HTN) planning [Georgievski and Aiello, 2015] is a\nparticular paradigm which relies on the PDDL-based formalism. Like PDDL,\natoms represent states of the world and actions represent deterministic state transi-\ntions. However the objective of HTN planners like SHOP2 [Nau et al., 2003, Nau\net al., 1999] or O-PLAN [Currie and Tate, 1991] is to generate a sequence of ac-\ntions that perform some tasks. A task represents an activity to perform which can\nbe either primitive or compound. Primitive tasks are accomplished by planning\noperators that, like PDDL operators/actions, describe transitions between states\nof the world. Compound tasks represent complex activity that cannot be directly\n\"executed\" and need to be further decomposed into a set of \"smaller\" tasks. In\n11\n\nPlanning in Artiﬁcial Intelligence\nHTN planning, the objective is to synthesize a set of actions (i.e. primitive tasks)\nrealizing a complex activity (i.e. a compound task) rather than reaching a desired\ngoal state like classical planners. Thus, HTN domain description consists of a set\nof operators that describe the primitive tasks and a set of methods that specify how\nto decompose complex tasks into subtasks. Methods specify the hierarchical task\ndecomposition HTN planners uses to recursively decompose tasks into a set of\nsubtasks. Methods decompose tasks until primitive tasks are found and no further\ndecomposition is needed. The resulting decomposition tree encode domain spe-\nciﬁc knowledge describing the standard operating procedures to use in order to\nperform tasks. Such a knowledge supports and guides the solving process of HTN\nplanners. Although HTN solving procedure is general and domain independent,\nmethod speciﬁcation is domain-dependent and characterizes the speciﬁc procedure\nto follow in order to realize complex tasks in the considered domain.\n(:method\n; head\n(transport-person ?p ?c2)\n; precondition\n(and (at ?p ?c1)\n(aircraft ?a)\n(at ?a ?c3)\n(different ?c1 ?c3))\n; subtasks\n(:ordered\n(move-aircraft ?a ?c1)\n(board ?p ?a ?c1)\n(move-aircraft ?a ?c2)\n(debark ?p ?a ?c2))\n)\nThe block of code above shows an simple example of a SHOP2 method deﬁned\nin [Nau et al., 2003], for a simpliﬁed versione of the ZENOTRAVEL domain of\nthe AIPS-2002 Planning Competition. The method describes how to transport a\nperson ?p by aircraft from a location ?c1 to another location ?c2 in the case that the\naircraft is not located at ?c1. The ordered keyword concerns task decomposition\nand speciﬁes the order the planner must follow to expand subtasks. Thus, ﬁrst\nthe aircraft moves to location ?c1, then the aircraft boards the person ?p, then the\naircraft moves to location ?c2 and ﬁnally the aircraft debarks the person ?p.\n12\n\nPlanning in Artiﬁcial Intelligence\n2.2\nPlanning in the Real-World\nThe modeling features of classical planning approaches rely on a set of assump-\ntions that make strong simpliﬁcations of the problems to address with respect to\nreal-world scenarios. Indeed, classical planning mainly deals with static, fully ob-\nservable and deterministic domains. It means that given any state of the environ-\nment and a particular action, it is possible to know exactly which is the next state\nof the system. Such an assumption does not hold in real-world contexts where the\nenvironment may be partially observable and something may be either unknown\nor unpredictable. In such a case the planning system should be able to handle the\nuncertainty of the domain and ﬁnd a sequence of actions that still reach the goal\nstate.\nLet us consider again for example, the Vacuum World domain of Figure 2.1,\nwhere the environment described is fully observable. At any state it is possible to\nknow where the vacuum cleaner is located or it is possible to know exactly whether\na room is clean or dirty. Similarly, the actions of the vacuum cleaner are determin-\nistic and therefore, the state resulting from the application of an action is known.\nLet us consider, for example, the state where both rooms are dirty and the vacuum\ncleaner is located in the left room. If the the Suck operation is applied to this state,\nthen the (only) successor state is the one with left room clean, the right room dirty\nand the vacuum cleaner still located in the left room. Such a simple problem can\nbe made more \"realistic\" and more challenging if one or more assumptions are re-\nmoved. Let us suppose to remove the assumption about the full observability of the\nenvironment and that it is not possible to know whether the rooms are clean or dirty.\nIn such a case, it is necessary to ﬁnd a sequence of actions that, independently from\nthe actual state of the rooms, allows the system to reach a state where certainly both\nrooms are clean. Moreover, classical planning approaches have an implicit repre-\nsentation of time. Actions are supposed to be instantaneous, which means that the\neffects of an action become true as soon as the action is applied. States and/or\ngoals are not supposed to have a temporal extension such that they hold only for a\nlimited temporal interval, or that they must be achieved within a known temporal\nbound. Again this is a signiﬁcant simpliﬁcation in real-world contexts where time,\ntemporal constraints (e.g. deadlines for goal achievement) and concurrency (e.g. a\nlimit on the number of jobs that a machine can perform simultaneously) represent\nstrong requirements that must be satisﬁed by plans.\nThere are several PDDL-based planning systems e.g. SATPLAN [Kautz and\nSelman, 1992], FF [Hoffmann and Nebel, 2011], LPG [Gerevini and Serina, 2002]\n13\n\nPlanning in Artiﬁcial Intelligence\nor LAMA [Richter and Westphal, 2010], that have shown excellent solving ca-\npabilities during the International Planning Competitions. However, all the as-\nsumptions described above limit the expressivity of classical planning systems and\ntheir efﬁcacy to address real-world problems. Consequently several planning ap-\nproaches have been developed, with the intention of overcoming these limitations\nby removing one or more of the simplifying assumptions described above. In par-\nticular, this work focuses on Temporal Planning which represents the \"class\" of\nplanning approaches capable of representing information and constraints that con-\ncern the temporal features of the domain. These kind of systems realizes problem\nsolvers that make both planning and scheduling decisions during the solving pro-\ncess. Timeline-based planning belongs to this class of planning techniques and it\nwill be further discussed in the next chapter. The following sections provide a brief\ndescription of the key modeling features of Temporal Planning, a brief description\nof PDDL2.1 [Fox and Long, 2003], the temporal extension of PDDL, and other\nhybrid approaches that present some common features with timeline-based plan-\nning like ANML [Smith et al., 2008], FAPE [Dvorák et al., 2014] and CHIMP\n[Stock et al., 2015].\n2.3\nTemporal Planning\nThe primary distinct characteristic of temporal planning paradigms is that they\nsynthesize plans by combining causal reasoning with reasoning about time and re-\nsources. They overcome the traditional division between planning and scheduling\ntechnologies. In this context, planning is intended as the generation of a system be-\nhaviour that satisﬁes certain desired conditions over a preﬁxed temporal horizon.\nTherefore, planning is not only the process of deciding which actions to perform in\norder to satisfy some desired conditions, but also deciding when to execute these\nactions in order to obtain some desired behavior of the system. Indeed, tempo-\nral planning systems try to integrate planning and scheduling in a uniﬁed solving\nprocess.\n2.3.1\nPDDL2.1\nPDDL2.1 [Fox and Long, 2003] has been designed to allow PDDL-based sys-\ntems to model and solve more realistic domains by introducing the capability of\ndealing with time. There are several planning systems that rely on this language,\ne.g. OPTIC [Benton et al., 2012], COLIN [Coles et al., 2012] POPF [Coles et al.,\n14\n\nPlanning in Artiﬁcial Intelligence\n2010], which also maintains backward compatibility with PDDL. Existing PDDL\ndomains are valid PDDL2.1 domains and valid PDDL plans are valid PDDL2.1\nplans. A relevant contribution of PDDL2.1 is the introduction of discretized du-\nrative actions with temporally annotated conditions and effects. Conditions and\neffects must be temporally annotated in order to specify when a particular propo-\nsition must hold. Speciﬁcally, a proposition (i.e. a condition or an effect) can hold\nat the start of the interval of the action (i.e. the time point at which the action is\napplied), at the end of the interval (i.e. the time point at which the effects of the\naction are asserted) or over the entire interval (i.e. invariant over the duration of\nthe action). The annotation of an effect speciﬁes whether the related effect of the\naction is instantaneous (i.e. the effect becomes true as soon as the action is ap-\nplied) or delayed (i.e. the effect becomes true when the action ﬁnishes). The code\nbelow shows a simple example of a durative action for loading a truck from the\nDock-Worker Robots domain described in [Ghallab et al., 2004].\n(:durative-action load-truck\n:parameters (?t - truck)\n(?l - location)\n(?o - cargo)\n(?c - crane)\n:duration (= ?duration 5)\n:condition (and\n(at start (at ?t ?l))\n(at start (at ?o ?l))\n(at start (empty ?c))\n(over all (at ?t ?l))\n(at end (holding ?c ?o)))\n:effect (and\n(at end (in ?o ?t))\n(at start (holding ?c ?o))\n(at start (not (at ?o ?l)))\n(at end (not (holding ?c ?o))))\n)\nInvariant conditions of a durative action hold over the entire duration of the\naction and are speciﬁed by means of the over all keyword (see the code above). It\nis worth observing that, the over all keyword excludes the start point and the end\npoint of the action interval which is considered as an open temporal interval. If a\nparticular preposition p must hold at the start, at the end and also during the entire\nduration of the action, it must be speciﬁed with three temporal constraints, i.e. (at\nstart p), (over all p) and (at end p).\n15\n\nPlanning in Artiﬁcial Intelligence\n2.3.2\nHybrid Planning approaches\nThere are other languages and planning frameworks that integrate causal and tem-\nporal reasoning without directly extending PDDL. An interesting planning lan-\nguage is the Action Notation Modeling Language (ANML) [Smith et al., 2008].\nANML has been introduced as an alternative to existing (temporal) planning lan-\nguages like PDDL2.1, the IXTET language or NDDL (the EUROPA planning\nlanguage). Broadly speaking ANML represents an high-level language whose aim\nis to uniformly support generative and HTN planning models and provide a clear\nand well-deﬁned semantics compatible with PDDL family of languages. ANML\nrelies on a strong notation of action and state, provides constructs for expressing\ncommon forms of action conditions and effects, supports rich temporal constraints\nand uses a variable/value representation.\naction Navigate (location from, to) {\nduration := 5 ;\n[all] { arm == stowed ;\nposition == from :-> to ;\nbatterycharge :consumes 2.0\n}\n}\nThe code above shows an example of an high-level navigation action for a rover\nexpressed in ANML. The action has two location parameters of type from and to\nand a ﬁxed duration (5 time units). The temporal qualiﬁer [all] means that the\nrelated statements (i.e. the statements contained by the adjacent block of code) are\nvalid all along the duration of the action. Speciﬁcally, the ﬁrst statement speciﬁes\nthat the arm of the rover is stowed over the entire action. The second statement\nspeciﬁes that the position of the rover is from at the start of the action (a condition),\nthe position is undeﬁned during action execution, and the position is to at the end of\nthe action (an effect). The last statement speciﬁes the amount of energy consumed\nby the action.\nThe Flexible Acting and Planning Environment (FAPE) is a recently intro-\nduced planning framework [Dvorák et al., 2014] which extends HTN planning\nwith temporal reasoning by implementing the ANML language. Another recent\nplanner worth to be considered is CHIMP [Stock et al., 2015]. CHIMP relies on\nits own modeling language and extends HTN planning domain representation with\ntemporal representation by leveraging the functionalities of the meta-csp [Man-\nsouri and Pecora, 2014].\n16\n\nChapter 3\nTimeline-based Planning in a\nNutshell\nT\nHE TIMELINE-BASED APPROACH is a Temporal Planning paradigm introduced\nin early 90’s [Muscettola, 1994], which takes inspiration from classical con-\ntrol theory. The main distinct factor is the centrality of time in the representa-\ntion formalism. Unlike classical approaches, timeline-based planning puts time\nto the center of the solving approach by dealing with concurrency, temporal con-\nstraints and ﬂexible durations. Timeline-based planning realizes a sort of hybrid\nrepresentation and reasoning framework which allows a solver to \"easily\" inter-\nleave planning and scheduling decisions. This hybrid view of planning is one of\nthe key characteristic for successfully addressing real-world problems. Timeline-\nbased solvers have been successfully applied in real-world contexts (especially in\nspace-like contexts) [Muscettola et al., 1992], [Jonsson et al., 2000a], [Cesta et al.,\n2007].\nThe world model of a timeline-based application is characterized by a set of\nfeatures that must be controlled over time in order to realize a complex behavior/-\ntask of a particular system to control. A complex system (e.g. a planetary explo-\nration rover) is modeled by identifying a set of features that are relevant from the\ncontrol perspective (e.g. the stereo camera or the communication facility). Each\nfeature is modeled in terms of the values it may assume over time and their related\ntemporal durations. The temporal evolution of a feature is represented as a timeline\nwhich consists of an ordered sequence of valued temporal intervals, usually called\ntokens. These tokens describe the behavior of the feature within a given temporal\nhorizon. In addition to the description of the features, the model may also specify\n17\n\nTimeline-based Planning in a Nutshell\ndomain rules that allow to further constrain the temporal behaviors of the features\nthrough temporal constraints. Such rules are necessary to achieve high-level goals\n(e.g. take and communicate pictures of a target) by coordinating different features\nproperly. For example, a rule may require that a particular value of a feature occurs\nduring a known temporal interval or that a token of a timeline must always occur\nbefore a particular token of another timeline. Thus, a timeline-based plan consists\nof a set of timelines and that must satisfy all the temporal constraints of the domain\nin order to be valid.\nIn timeline-based planning, unlike classical planning, there is not a clear dis-\ntinction between states and actions. A valued temporal interval may represent\neither an action or a state the related feature must perform or assume over a par-\nticular temporal interval. Similarly planning goals do not represent simply states\nor conditions that must be achieved. Rather, a planning goal may be either a value\nthat a particular feature is supposed to assume during a certain temporal interval,\nor a complex task (e.g. take a picture of a target) that must be performed within a\ngiven time. The solving process acts on an initial set of partially speciﬁed timelines\nrepresenting the initial known facts about the world. The process completes the be-\nhaviors of these timelines by iteratively adding values and temporal constraints ac-\ncording to desired requirements (including planning goals). Thus, timeline-based\nplanners realize a behavior-based approach to planning, whose focus is on con-\nstraining the temporal evolutions of the system rather than synthesizing a sequence\nof actions that allow to achieve a desired goal state.\nThere are several timeline-based systems that have been introduced into lit-\nerature and successfully applied to real-world problems (especially in space-like\ncontexts). EUROPA [Barreiro et al., 2012] developed by NASA, IXTET [Ghallab\nand Laruelle, 1994] developed at LAAS-CNRS, and APSI-TRF [Fratini et al.,\n2011] developed for ESA, represent some of the most known existing frameworks\nin this ﬁeld. The next sections provide a brief description of the most relevant\nfeatures of these timeline-based planning frameworks.\n3.1\nEUROPA\nThe EUROPA framework [Barreiro et al., 2012] relies on Constraint-based Tem-\nporal Planning (CBTP) [Frank and Jonsson, 2003] which is a Temporal Planning\nformalism successfully applied in many space application contexts by NASA. The\nCBTP modeling approach focuses on the temporal behaviour of the system we\n18\n\nTimeline-based Planning in a Nutshell\nwant to control and not just on the causality relationships. Therefore, a complex\nsystem (e.g. a planetary exploration rover) is modelled by identifying a set of rele-\nvant components that can independently evolve over time.\nA component models a physical or logical feature of the system to be controlled\nby specifying a (ﬁnite) set of mutually exclusive activities the related feature may\nassume over time. An activity is an atomic formula of the form:\nA(x1, ..., xn, stA, etA, δ)\nwhere (i) A is a predicate representing a particular condition of the world, (ii)\n⃗x = {x1, ..., xn} are numerical or symbolic parameters of activities, (iii) stA and\netA are temporal variables representing respectively the activity start and end times\nand (iv) δ = [δmin, δmax] is an interval representing lower and upper bounds of\nactivity’s duration.\nLet Act = {A1(⃗x1, δ1), ..., Ak)(⃗xk, δk)} be the set of activities. In CBTP\nformalism a component Ci is deﬁned by a subset Acti = {Ai,1, ..., Ai,m} of\nAct, where activities Ai,j represent possible states or actions of the component\nCi. Components statically describe the possible temporal evolutions of the ele-\nments of the system. However, it is necessary to specify additional constraints in\norder to coordinate system’s element and guarantee the overall system safeness.\nCBTP considers two types of constraints: (i) Codesignation Constraints can im-\npose equalities or inequalities between the parameters of activities; (ii) Temporal\nConstraints can model temporal constraints between activities by expressing either\ninterval-based or point-based temporal predicates.\nIn general, CBTP models temporal constraints by extending the qualitative\ntemporal interval relationships deﬁned in [Allen, 1983] with quantitative infor-\nmation. Namely, the basic temporal relations between intervals are enriched with\nmetric information, i.e. lower and upper bounds of the distances between temporal\nintervals. For example, the relation A before [10, 20] B states that the interval A\nmust precede interval B not less than 10 time units and not more than 20 time units.\nThe causal and temporal constraints of the system are modeled by means of\ndedicated rules, called compatibilities, that specify interactions between a particu-\nlar activity of a component and other activities that can either belong to the same\ncomponent (internal compatibility) or to a different component (external compat-\nibility). Compatibilities describe how a particular activity (the master) is related\nto other activities (the slave) by specifying a set of codesignation and/or temporal\nconstraints that must be satisﬁed in order to build valid plans. Conditional compat-\n19\n\nTimeline-based Planning in a Nutshell\nibilities can be deﬁned by means of guard constraints that \"extend\" the conditions\nunder which the related compatibility can be applied. If the guard constraints of\na compatibility are satisﬁed, then the related temporal and/or codesignation con-\nstraints can be applied. Given a set of activities Act, the compatibility for an activ-\nity Ai(⃗xi, stAi, etAi, δi) ∈Act is deﬁned as\nC[Ai] : G(⃗y) →T(Ai, Aj, ..., Ak) ∧P(⃗xi, ⃗xj, ..., ⃗xk)\nwhere (i) G(⃗y) ≡g1(γ1) ∧... ∧gm(γm)) is a conjunction of guard constraints,\n(ii) T(Ai, Aj, ..., Ak) ≡t1(Ai, Aj) ∧... ∧tm(Ai, Ak) is a conjunction of tempo-\nral constraints involving the activities Ai, Aj, ..., Ak and (iii) P(⃗xi, ⃗xj, ..., ⃗xk) ≡\np1(⃗xi, ⃗xj)∧...∧pn(⃗xi, ⃗xk) is a conjunction of codesignation constraints on variable\n⃗xi and variables in ∪k\nt=j(⃗xt).\nIf a compatibility C[A] speciﬁes different constraints according to the different\nvalues a particular guard variable gi(γi) may assume then, C[A] represents a dis-\njunctive compatibility. Given an activity A(⃗x, st, et, δ), a conﬁguration rule for A\nis a conjunction of compatibilities and it is deﬁned as\nR[A(⃗x, st, etA, δ)] = C1[A] ∧... ∧Cn[A]\nThe code below shows some compatibilities and conﬁguration rules for a classical\nplanning problem concerning the control of a planetary exploration rover.\nR[Unstow()] = {\n[meets Place(rock) ∧met_by Stowed()]\n}\nR[Place(rock_b)]\n=\n{\n[meets Use(inst, rock_u) ∧(rock_u\n=\nrock_b)] ∧\n[met_by Unstow()] ∧\n[contained_by MobilitySystem.At(rock_a) ∧(rock_a\n=\nrock_b)]\n}\nR[Use(inst, rock_b)] = {\n[γ = 0 →meets Stow()\nγ = 1 →meets Place(rock_p ∧(rock_p\n̸=\nrock_b)] ∧\n[met_by Place(rock_p) ∧(rock_p\n=\nrock_b)] ∧\n[contained_by MobilitySystem.At(rock_a) ∧(rock_a\n=\nrock_b)]\n}\nGiven the elements described above, a planning domain D is deﬁned by a\n20\n\nTimeline-based Planning in a Nutshell\nset of components C[D] = {C1, ..., Cn}, a set of activities Act associated with\neach component and a set of evolution rules R[D] = {R[A1], ..., R[Am]]}, the\ndomain contains an evolution rule R[Ai] for each activity Ai ∈Act. The CBTP\nplanning process aims at building a valid description of the temporal behaviors\nof the components within a temporal horizon where goal activities are scheduled\nat proper times. Thus, a planning problem consists of a planning horizon and an\ninitial conﬁguration which (partially) describes the behaviors of the components.\nA solution plan is represented by a temporal execution trace which speciﬁes for\neach time point, the activity the components are supposed to execute.\n3.2\nIXTET\nIXTET [Ghallab and Laruelle, 1994] is a temporal planning system which tries to\nintegrate plan generation and scheduling into the same planning process. Some\nof the most important features of the IXTET planning paradigm are: (i) an ex-\nplicit representation of time with different types of metric constraints between time\npoints; (ii) a powerful representation of the world through multi-valued attributes;\n(iii) the management of a large range of resource types (unsharable, sharable, con-\nsumable and producible); (iv) a task formalism allowing for the representation of\ncomplex macro-operators.\nProperties of the world are described by a set of multi-valued state attributes\nand a set of resource attributes. A state attribute describes a particular feature of the\ndomain as a key-mapping from some ﬁnite domains into a ﬁnite range (the value\nof the attribute). The code below shows an example of a domain feature modeling\nthe possible location of a robot.\nattribute position(?robot) {\n?robot ∈{robot1, robot2};\n?value ∈{RoomM, LabRoom1, LabRoom2};\n}\nA resource is deﬁned as any substance, or set of objects whose cost or availabil-\nity induces constraints on the actions that use them. So a resource can be either a\nsingle item with unit capacity (i.e. an unsharable resource) or an aggregate resource\nthat can be shared simultaneously between different actions without violating its\nmaximal capacity constraint.\n21\n\nTimeline-based Planning in a Nutshell\nresource robots(?robot) {\n?robot\n∈\n{robot1, robot2};\ncapacity = 1;\n}\nresource paper_on_robot() {\ncapacity = 3;\n}\nIXTET deﬁnes different types of state attributes that can classiﬁed as: (i) rigid\nattributes (or atemporal) representing attributes whose value does not change over\ntime (they express a structural relationship between their arguments); (ii) ﬂexible\nattributes (or ﬂuents) representing attributes whose value may change over time.\nFlexible attributes may be further classiﬁed in: (i) controllable attributes represent-\ning attribute whose change of values can be planned for (but they can even change\nindependently from the planning system); (ii) contingent attributes representing\nattributes whose changes of values cannot be controlled.\nMoreover, IXTET relies on a reiﬁed logic formalism where ﬂuents (i.e. ﬂexible\nattributes) are temporally qualiﬁed by the hold and the event (temporal) predicates.\nThe hold predicate\nhold(att(x1, ...) : v, (t1, t2))\nasserts the (temporal) persistence of the value of state attribute att(x1, ...) to v for\neach t : t1 ≤t < t2.\nThe event predicate\nevent(att(x1, ...) : (v1, v2), t)\nasserts the instantaneous change of the value of att(x1, ...) from v1 to v2 occurred\nat time t.\nSimilarly, resource availability proﬁle and the resource usage by the different\noperators are described by means of use, consume and produce predicates.\nThe use predicate\nuse(typ(r) : q, (t1, t2))\nasserts the borrowing of an integer quantity q of resource typ(r) on the temporal\ninterval [t1, t2].\nThe consume predicate\nconsume(typ(r) : q, t)\nasserts that a quantity q of resource typ(r) is consumed at time t.\n22\n\nTimeline-based Planning in a Nutshell\nThe produce predicate\nproduce(typ(r) : q, t)\nasserts that a quantity q of resource typ(r) is produced at time t.\nTemporal data representation and storage is managed by the time-map man-\nager which relies on time-points as elementary primitives [Dechter et al., 1991].\nTime is considered as a linearly ordered discrete set of instants. Time-points are\nseen as symbolic variables on which temporal constraints can be posted. IXTET\nhandles both symbolic constraints and numeric constraints expressed as a bounded\ninterval [I−, I+] on the temporal distance between time points. The time-map man-\nager is responsible for propagating constraints on time-points to check the global\nconsistency of the network and to answer queries about the relative position of\ntime-points.\nPlanning operators are represented by means of a hierarchy of tasks. A task\nis a temporal structure composed of: (i) a set of sub-tasks; (ii) a set of events\ndescribing the changes of the world the task causes; (iii) a set of assertions on\nstate attributes to express the required conditions or the protection of some fact\nbetween two task events; (iv) a set of resource usage; (v) a set of temporal and\ninstantiation constraints binding the different time-points and variables of the task.\nTasks are deterministic operators without ramiﬁcation effects that may also refer\nto other sub-tasks in order to express macro-operators. The code below shows an\nexample of elementary task (i.e. a task without sub-tasks) for a robot in charge of\nthe maintenance of a laboratory consisting in putting paper in a machine when it is\nout of paper:\ntask feed_machine(?machine) (start, end) {\nvariable ?room;\nplace(?machine, ?room);\nhold(position(robot): ?room, (start, end));\nevent(machine_state: (out_of_paper, ok), end);\nconsume(paper_on_robot(): 1, end);\nproduce(trunk_size(): 1, end);\n(end - start) in [00:01:00, 00:02:00];\n}\nThe initial plan is a particular task that describes a problem scenario by spec-\nifying: (i) the initial values for the set of instantiated state attributes (as a set of\nexplained events); (ii) the expected changes on some contingent state attributes\nthat will not be controlled by the planner (as a set of explained events); (ii) the\n23\n\nTimeline-based Planning in a Nutshell\nexpected availability proﬁle of the resources (as a set of uses); (iv) the goals that\nmust be achieved (usually, as a set of assertions).\n3.3\nAPSI-TRF\nAPSI-TRF [Fratini et al., 2011] is a software framework developed for ESA whose\naim is to support the design and development of P&S applications by leveraging\nthe timeline-based approach. The APSI-TRF framework provides the designer\nwith a ready-to-use software library for modeling planning and scheduling con-\ncepts in the form of timelines. Speciﬁcally, APSI-TRF relies on the same model-\ning assumptions of HSTS [Muscettola, 1994] and therefore, a complex system is\nmodeled by identifying a set of relevant features to control over time. The APSI-\nTRF framework makes available the modeling language and the software func-\ntionalities needed to model timeline-based domains in shape of multi-valued state\nvariables and synchronization rules.\nMulti-valued state variables model the features of the domain by describing\ntheir allowed temporal behaviors. State variables model domain features by spec-\nifying the values, the related feature may assume over time, together with the al-\nlowed durations and transitions. Thus, a state variable x is deﬁned as the tuple\nx = (V, D, T)\nwhere (i) V is the set of values the variable x can assume over time, (ii) D : V →\nR × R is a duration function specifying for each value v ∈V the minimum and\nmaximum duration and (iii) T : V →2V is a transition function specifying for\neach value v ∈V the set of allowed successors. State variables specify causal and\ntemporal constraints of the single features of a planning problem. They specify\nlocal rules that allow a planning system to build the timelines of the features com-\nposing the domain. Given a state variable x, a timeline describes the sequence of\nvalues the variable assumes over time by specifying a sequence of valued temporal\nintervals called tokens. A token is deﬁned as the tuple\nxi =\n\u0000vj, [si, s′\ni], [ei, e′\ni]\n\u0001\nwhere [si, s′\ni] and [ei, e′\ni] represent respectively the ﬂexible start and end of the\ntemporal interval during which the variable x is supposed to assume the value\nvj ∈V .\n24\n\nTimeline-based Planning in a Nutshell\nSynchronization rules model causal and temporal constraints of a planning do-\nmain by specifying global relations between tokens of different variables. In gen-\neral, whenever a particular token xi occurs on a timeline (i.e. the trigger) a syn-\nchronization rule speciﬁes a set of different tokens (i.e. the targets) that must occur\non other timelines and a set of temporal constraints between the trigger and tar-\ngets of the rule that must hold in order to build valid temporal behaviors. Indeed,\nsynchronization rules allow the planning system to further constrain the temporal\nbehaviors of the state variables in order to build timelines that satisfy some desired\nplanning goals. Temporal constraints of synchronization rules are modeled by ex-\ntending the qualitative relationships of the Allen’s interval algebra [Allen, 1983],\nwith quantitative information.\nIt is worth observing that APSI-TRF, unlike other timeline-based frameworks\n(e.g. the EUROPA and IXTET frameworks mentioned above), is not a planner but\na development library for designing planning applications. In this regard, OMPS\n[Fratini et al., 2008] represents a domain-dependent timeline-based solver which\nhas been developed on-top of the APSI-TRF modeling functionalities and suc-\ncessfully applied in space-exploration scenario [Ceballos et al., 2011].\n3.4\nTemporal Formalisms\nTemporal Planners rely on expressive temporal formalisms that allow these paradigms\nto deal with time and temporal constraints. Many timeline-based systems (includ-\ning EUROPA, IXTET and APSI-TRF) model temporal information about plans\nby extending the Allen’s interval algebra [Allen, 1983] in order to represent ex-\npressive temporal relations between the temporal elements of a plan.\nTemporal information represents additional knowledge the planner must prop-\nerly managed during the solving process. Thus, timeline-based planners must en-\ncapsulate temporal reasoning mechanisms that process temporal information in\norder to verify the (temporal) consistency of plans. Temporal reasoning mecha-\nnisms are usually implemented by leveraging the formalism of Temporal Networks\n[Dechter et al., 1991] which represents a ﬂexible representation of temporal data\nas a network of time points (i.e. the nodes of the network) and distance constraints\nbetween time points (i.e. the edges of the network).\n25\n\nTimeline-based Planning in a Nutshell\n0\n1\n[10, 20]\n4\n[60, 70]\n2\n[30, 40]\n3\n[10, 20]\n[20, 30]\nFigure 3.1: A graph representation of the STP problem described in Example 1\n3.4.1\nThe Simple Temporal Problem\nThe Simple Temporal Problem (STP) is a well-known formalism introduced in\n[Dechter et al., 1991] which consists of a set of events that may occur over known\ntemporal intervals and a set of requirement constraints that specify distance con-\nstraints on the temporal occurrences of pairs of events. The problem is to ﬁnd\na temporal allocation of the events satisfying all the requirement constraints (i.e.\nthe distance constraint). Namely, temporal reasoning mechanisms try to ﬁnd an as-\nsignment of events to time points such that all the temporal constraints are satisﬁed.\nThis concept is known as temporal consistency and is central to STPs.\nBelow is the description of a simple scenario taken from [Dechter et al., 1991],\nrepresenting an example of the type of problems and inference the STP formalism\ncan support.\nExample 1 John goes to work by car (30-40 minutes). Fred goes to work in a carpool\n(40-50 minutes). Today John left home between 7:10 and 7:20, and Fred arrived at\nwork between 8:00 and 8:10. We also know that John arrived at work about 10-20\nminutes after Fred left home. We wish to answer queries such as: \"Is the information\nin the story consistent?\", \"What are the possible times at which Fred left home?\", and\nso on.\nFigure 3.1 shows the STP problem of Example 1 in graph form. When STPs are\nshown as graphs where nodes represent events and edges represent requirement\nconstraints, they are called Simple Temporal Networks (STNs). The node \"0\" of\nFigure 3.1 represents the temporal origin of the plan/problem, the \"absolute\" time\n7:00 with respect to Example 1. Node \"1\" in Figure 3.1 is associated with the\nevent representing the time at which John leaves home. The edge between node\n\"0\" and node \"1\" labeled \"[10, 20]\" models the fact \"John left home between 7:10\n26\n\nTimeline-based Planning in a Nutshell\nand 7:20\" as a distance constraint (i.e. a requirement constraint) between the two\nrelated events. A strong limitation of the STP formalism concerns disjunctive con-\nstraints. STP cannot represent and therefore, cannot reason about disjunctive tem-\nporal intervals on events. Considering Example 1, STP cannot model disjunctive\nassertions like \"John goes to work either by car (30-40 minutes), or by bus (at\nleast 60 minutes)\". Disjunctive assertions represent alternative plans the planning\nprocess may generate accordingly by branching the search space.\nFrom a planning perspective, the temporal part of the plan can be reduced to a\nSTP by modeling the start and end times of the activities of the plan (e.g. the start\nand end times of the tokens of a timeline) as events of the STP. Temporal relations\nand/or duration constraints concerning the activities/actions of the plan can be eas-\nily translated in the STP as one or more requirement constraints involving events\nrelated to the start/end times of the activities of the plan. Thus a planning system\ncan leverage the STP formalism to post ordering constraints between activities dur-\ning the solving process and check the temporal assignment of the activities of the\nplan. Namely, a planning system can check the (temporal) consistency of a plan by\nverifying the existence of a valid schedule of all the activities.\n3.4.2\nThe Simple Temporal Problem with Uncertainty\nSTP makes the assumption that all the events of the plan are controllable. It means\nthat the planning system can decide the temporal allocation (i.e. the schedule) of\nall the events. However, this is not always possible in real-world settings. Indeed,\nthe activities of a plan usually model real-world tasks/actions whose durations can\nbe affected by exogenous factors and therefore, the planning system cannot decide\nthe temporal allocation of these activities (e.g. the planner can decide the start time\nof the execution of an action but not the end time). Such activities are called un-\ncontrollable. Thus, a more expressive temporal formalism is the Simple Temporal\nProblem with Uncertainty (STPU).\nThe STNU formalism takes into account both controllable and uncontrollable\nevents. In this formalism an event is considered uncontrollable if it is the target\nof contingent constraints that are typically used to model uncontrollable durations\nof the activities/actions of the plan. The key point of STPUs is that temporal con-\nsistency is not sufﬁcient to solve real-world problems. Temporal uncertainty in-\ntroduces the additional problem of deciding how to schedule controllable events\naccording to the observed/possible temporal occurrences of uncontrollable events,\nin order to complete the execution of the plan. Such a problem is called the con-\n27\n\nTimeline-based Planning in a Nutshell\ntrollability problem which has been fairly investigated in the literature [Vidal and\nFargier, 1999, Morris et al., 2001]. Broadly speaking, three different types of con-\ntrollability (weak, strong and dynamic controllability) have been deﬁned according\nto the different assumptions made on the uncontrollable events of a plan. Planning\nsystems may leverage the STPU formalism to generate plans with some desired\nproperties concerning the controllability of generated plans (i.e. properties con-\ncerning the execution of the generated plans in the real-world).\n28\n\nChapter 4\nFlexible Timeline-based Planning\nwith Uncertainty\nD\nESPITE the practical success of timeline-based planning, formal frameworks\ncharacterizing this paradigm have been proposed only recently. There is a\nmultitude of software frameworks that have been realized and introduced in the\nliterature, each of which applies its own interpretation of timeline-based planning.\nIn such a context, it is not easy to evaluate the modeling and solving capabilities\nof different timeline-based planning systems. It is not even easy to deﬁne bench-\nmarking domains to compare timeline-based systems, or to open the assessment to\nother planning techniques.\nThis chapter describes a complete and comprehensive formal characterization\nof the timeline-based approach which has been introduced in [Cialdea Mayer et al.,\n2016]. The proposed formalization aims at deﬁning a clear semantics of the main\nplanning concepts by taking into account the features of the most known timeline-\nbased planning frameworks. In addition, the formalization takes into account tem-\nporal uncertainty which is particularly relevant in real-world domains where not\neverything is controllable. Indeed, the execution process is not completely under\nthe control of the executive system. Exogenous events can affect or even prevent\nthe complete and successful execution of generated plans. Thus, the capability of\nrepresenting and dealing with temporal uncertainty and controllability properties\nat both planning and execution time is crucial to deploy effective timeline-based\napplications in real-world scenarios.\n29\n\nFlexible Timeline-based Planning with Uncertainty\n4.1\nA Running Example: The ROVER Domain\nIn order to support the formal deﬁnitions given below, a simple case study will be\nused as a running example. The domain takes inspiration from a typical scenario\nof AI-based control for a single autonomous agent.\nThe ROVER domain consists of an exploration rover which can autonomously\nnavigate a (partially) unknown environment, take samples of some targets (e.g.\nrocks) and communicate scientiﬁc data to a satellite. An exploration rover is a\ncomplex system endowed with several devices that must be properly controlled\nin order to achieve the desired objectives. A navigation facility allows the rover\nto move and explore the environment. A dedicated instrument facility allows the\nrover to take samples of targets that must be analyzed. A communication facility\nallows the rover to send data acquired from sampled targets to a satellite whose\norbit is known.\nA mission goal requires the rover to move towards a desired target, take a\nsample of it and communicate gathered data when possible. All the features that\ncompose the rover must be coordinated properly in order to realize the complex be-\nhavior needed to satisfy mission goals. Thus, a set of operative constraints must be\nsatisﬁed. For instance, communication of data must be performed while the rover\nis still and during some known communication windows that represent temporal\nintervals during which the target satellite is visible. Another operative constraint\nrequires that the instrument facility must be set in a safe position/conﬁguration\nwhile the rover is moving.\n4.2\nDomain Speciﬁcation\nThe timeline-based approach to planning pursues the general idea that planning\nand scheduling for controlling complex physical systems consist of the synthesis\nof desired temporal behaviors (or timelines). According to this paradigm, a domain\nis modeled as a set of features with an associated set of temporal functions on a\nﬁnite set of values. The time-varying features are usually called multi-valued state\nvariables [Muscettola, 1994]. Like in classical control theory, the evolution of the\nfeatures is described by some causal laws and limited by domain constraints. These\nare modeled in a domain speciﬁcation.\nThe task of a planner is to ﬁnd a sequence of decisions that brings the timelines\ninto a ﬁnal desired set, satisfying the domain speciﬁcation and special conditions\ncalled goals. Causal and temporal constraints specify which value transitions are\n30\n\nFlexible Timeline-based Planning with Uncertainty\nallowed, the minimal and maximal duration of each valued interval and (so-called)\nsynchronization constraints between different state variables. Moreover, a domain\nspeciﬁcation must take into account the temporal uncertainty of planning domains\nin order to model more realistic problems. In particular, two sources of uncertainty\nare considered.\nOn the one hand, the evolution of some components of the domain may be\ncompletely outside the control of the system. What the planner and the executive\nknow about them is only what is speciﬁed in the underlying planning problem. On\nthe other hand, some events may be partially controllable. In this case, the plan-\nner and the executive can decide when to start an activity, but they cannot ﬁx the\nduration of the activity. According to this characterization, two types of state vari-\nables constitute a planning domain: the planned variables model the controllable\nor partially controllable features of a domain; the external variables model the un-\ncontrollable features of a domain. Thus, the planning system or the executive must\nrespectively make planning and execution decisions, without changing the behav-\nior of external variables or making hypothesis on the actual duration of partially\ncontrollable features.\nFor the sake of generality, temporal instants and durations are taken from an\ninﬁnite set of non-negative numbers T, including 0. For instance, T can be the set\nof natural numbers N (in a discrete time framework), as well as the non-negative\nreal numbers R≥0. Sometimes, ∞is given as an upper bound to allowed numeric\nvalues, with the meaning that t < ∞for every t ∈T. The notation T∞will be\nused to denote T ∪{∞}, T>0 = T −{0} and T∞> 0 = T∞−{0}. When dealing\nwith temporal intervals, if s, e ∈T, the (closed) interval [s, e] denotes the set of\ntime points {t | s ≤t ≤e}.\n4.2.1\nState Variables\nA state variable x is characterized by four components: the set V of values the\nvariable may assume, a function T mapping each value v ∈V to the set of values\nthat are allowed to follow v, a function γ tagging each value with information about\nits controllability, and a function D which may set upper and lower bounds on the\nduration of each variable value.\nDeﬁnition 1 [State Variable] A state variable x, where x is a unique identiﬁer,\ncalled the variable name, is a tuple (V, T, γ, D), where:\n1. V , also denoted by values(x), is a non-empty set, whose elements are the\n31\n\nFlexible Timeline-based Planning with Uncertainty\nstate variable values.\n2. T : V →2V is a total function, called the state variable value transition\nfunction.\n3. γ : V →{c, u} is a total function, called the controllability tagging func-\ntion; γ(v) is the controllability tag of the value v. If γ(v) = c, then v is a\ncontrollable value, and if γ(v) = u, then v is uncontrollable.\n4. D : V →T × T∞is a total function such that D(v) = (dmin, dmax) for\nsome dmin ≥0 and dmax ≥dmin, and if γ(v) = u, then dmin > 0 and\ndmax ̸= ∞; D is called the state variable duration function.\nIf γ(v) = c, then the planning or executive system can control the value v and can\ndecide the actual duration of related activities (e.g. the executive can decide when\nto start and end the execution of these activities). If γ(v) = u, then the planning or\nexecutive system cannot control the value v and cannot decide the actual duration\nof related activities. The behaviors of these activities are under the control of the\nenvironment.\nThe intuition behind the duration function is that if D(v) = (dmin, dmax), then\nthe duration of each interval in which x has the value v is included between dmin\nand dmax inclusive, if dmax ∈T; it is not shorter than dmin and has no upper\nbound, if dmax = ∞. In practice, existing systems, such as EUROPA [Barreiro\net al., 2012] and APSI-TRF [Fratini et al., 2011], allow values to be represented\nby means of parametrized expressions In the present theoretical approach, values\nare taken to be completely instantiated in order to simplify the presentation. This\namounts to describing sets and functions by enumeration and does not diminish the\nexpressive power.\nIn what follows, it is assumed that, whenever a set of state variables SV is con-\nsidered, for every distinct pair x and y in SV , x ̸= y. The set SV is partitioned into\ntwo disjoints sets, SVP , containing the planned state variables, and SVE, the set of\nthe external ones. Every value v of an external state variable is uncontrollable, i.e.,\nγ(v) = u. An external variable represents a component of the \"external world\" that\nis completely outside the system control: the planner cannot decide when to start or\nend its activities. What is known about an external variable is speciﬁed in the plan-\nning problem. On the contrary, a planned state variable represents a component\nof the system that is under the control of the executive. Nevertheless, controllable\nsub-systems may also have uncontrollable activities (i.e., activities whose starting\ntimes can be decided by the executive, but their durations and consequently their\n32\n\nFlexible Timeline-based Planning with Uncertainty\nNot\nAvailable\n[1,100]\nAvailable\n[60,100]\nwindow\n<<external>>\nPlaced\n[1,+INF]\nSampling\n[7,18]\nPlacing\n[3,7]\nUnstowed\n[1,+INF]\nStowing\n[3,3]\ninstrument\nUnstowing\n[3,3]\nStowed\n[1,+INF]\nnavigator\nHome\n[1,+INF]\nMoving\n[14,32]\nIdle\n[1,+INF]\nTake\nSample\n[1,+INF]\nrover\nIdle\n[1,+INF]\nSendData\n[11,32]\ncommunication\nAtTarget\n[1,+INF]\nFigure 4.1: State Variable speciﬁcation for the ROVER planning domain\nending times, are not controllable). In other terms, the planner can decide when\nto start an uncontrollable activity of a planned variable (i.e. when the variable as-\nsumes an uncontrollable value), even if it cannot precisely predict how long it will\nlast. In general, every time an activity (either controllable or not) is preceded by an\nuncontrollable one, the system cannot control its start time. Indeed, the start time of\nthe activity is affected by the end of the previous activity, which is uncontrollable.\nExample 2 In the considered running example, the timeline-based speciﬁcation iden-\ntiﬁes ﬁve state variables, that will be called r (for \"rover\"), nv (for \"navigator\"), inst\n(for \"instrument\"), cm (for \"communication\") and win (for \"window\") whose values,\ntransitions and controllability properties are illustrated in Figure 4.1 (values with\ndotted borders represent uncontrollable values).\nTherefore, the set of considered state variables is SV = {r, nv, inst, cm, win} where\nSVP = {r, nv, inst, cm} are planned state variables, while SVE = {win} is an\nexternal one. For example, the state variable inst models the instrument facility\nthe rover uses to sample targets. The state variable can be deﬁned by the typle\ninst = (Vinst, Tinst, γinst, Dinst) where:\n• Vinst = {Stowed, Unstowed, Stowing, Unstowing, Placing, Placed,\nSampling};\n• Tinst is the value transition function such that\n– Tinst(Stowed) = {Unstowing},\n– Tinst(Unstowed) = {Stowing, Placing},\n33\n\nFlexible Timeline-based Planning with Uncertainty\n– Tinst(Stowing) = {Stowed},\n– Tinst(Unstowing) = {Unstowed},\n– Tinst(Placing) = {Placed},\n– Tinst(Placed) = {Placing, Unstowed, Sampling},\n– TInst(Sampling) = {Placed};\n• γinst is the controllability tagging function such that\n– γinst(Stowed) = γinst(Unstowed) = γinst(Stowing) =\nγinst(Unstowing) = γinst(Placing) = γinst(Placed) = c,\n– γinst(Sampling) = u;\n• Dinst is the value duration function such that\n– Dinst(Stowed) = Dinst(Unstowed) = Dinst(Placed) = (1, ∞),\n– Dinst(Stowing) = Dinst(Unstowing) = (3, 3),\n– Dinst(Placing) = (3, 7),\n– Dinst(Sampling) = (7, 18).\nThe state variable win, instead, is an external variable which models the availability\nof the communication channel during the satellite orbit. It can be deﬁned by the tuple\nwin = (Vwin, Twin, γwin, Dwin), where:\n• Vwin = {Available, NotAvailable};\n• γwin(V isible) = γwin(NotAvailable) = u;\n• Twin is the value transition function such that\n– Twin(Available) = {NotAvailable}\n– Twin(NotAvailable) = {Available};\n• Dwin is the duration function such that\n– Dwin(Available) = (60, 100)\n– Dwin(NotAvailable) = (1, 100).\n(Flexible) Timelines\nA timeline represents the temporal evolution of a system component up to a given\ntime. It consists of a sequence of valued intervals, called tokens, each of which\nrepresents a time slot in which the variable assumes a given value. A token repre-\nsents a temporal interval which determines the instant the variable starts executing\n34\n\nFlexible Timeline-based Planning with Uncertainty\nthe related value and the time instant the variable ends executing that value.\nHowever, planning with timelines takes into account time ﬂexibility by allowing\ntoken durations to range within given bounds. It means that the start and end time\ninstants of a token are replaced by temporal intervals. Thus, the notion of (ﬂexible)\ntimeline can be deﬁned as follows:\nDeﬁnition 2 [Timeline] If x = (V, T, γ, D) is a state variable, a token for the\nvariable x has the form:\nxi = (v, [e, e′], [d, d′], γ(v))\nwhere xi, for i ∈N, is the token name, v ∈V , e, e′, d, d′ ∈T, e ≤e′ and dmin ≤\nd ≤d′ ≤dmax, for D(v) = (dmin, dmax). The value γ(v) is called the token\ncontrollability tag; if γ(v) = c, then the token is controllable; if γ(v) = u, then the\ntoken is uncontrollable. A timeline FTLx for the state variable x = (V, T, γ, D) is\na ﬁnite sequence of tokens for x, of the form:\nx1 = (v1, [e1, e′\n1], [d1, d′\n1], γ(v1)),\n. . . ,\nxk = (vk, [ek, e′\nk], [dk, d′\nk], γ(vk)),\nwhere for all i = 1 . . . k −1, vi+1 ∈T(vi) and e′\ni ≤ei+1. The interval [ek, e′\nk]\nin the last token is called the horizon of the timeline and the number k of tokens\nmaking up FTLx is its length. If xi = (v, [e, e′], [d, d′], γ(v)) is a token in the\ntimeline FTLx, then:\n• val(xi) = v;\n• end_time(xi) = [e, e′];\n• start_time(x0) = [0, 0] and start_time(xi+1) = end_time(xi);\n• duration(xi) = [d, d′];\n• with an abuse of notation, γ(xi) denotes the token controllability tag γ(val(xi)).\nIntuitively, a token xi of the above form represents the set of valued intervals\nstarting at some s ∈start_time(xi), ending at some e ∈end_time(xi) and whose\ndurations are in the range duration(xi). The horizon of the timeline is the end\ntime of its last token.\n35\n\nFlexible Timeline-based Planning with Uncertainty\nExample 3 Let us consider the timeline FTLinst for the state variable inst, in the\nROVER domain, made of the following sequence of tokens:\ninst1 = (Stowed, [20, 28], [20, 30], c)\ninst2 = (Unstowing, [23, 31], [3, 3], c)\ninst3 = (Unstowed, [50, 55], [19, 32], c)\nThe horizon of FTLinst is [50, 55].\nAn example of non-ﬂexible timeline for the same state variable inst is made of the\nfollowing sequence of tokens:\ninst1 = (Stowed, [25, 25], [20, 30], c)\ninst2 = (Unstowing, [28, 28], [3, 3], c)\ninst3 = (Unstowed, [50, 50], [19, 32], c)\nand its horizon is [50, 50].\nIt is worth pointing out that often in the literature (e.g., [Fratini et al., 2008]), a\nﬂexible token contains also a start interval. However, once a token xi is embedded\nin a timeline, the time interval to which its start point belongs (start_time(xi)) can\nbe easily computed as shown in the deﬁnition above. Thus, including it as part of\nthe token itself is redundant.\nOn the contrary, duration restrictions alone would be inadequate to precisely\nidentify when the valued intervals represented by a given token must begin and\nend. As a matter of fact, duration and end time bounds interact when determining\nwhich legal values a token end time may assume. Let us assume, for instance, that\nthe duration of a given token xi is [20, 30] and that one may compute, from the\ndurations of the previous tokens, that its start time is [40, 50]. One can then infer\nthat the end points of the valued intervals it represents are necessarily in the range\n[60, 80] = [40 + 20, 50 + 30]. However, it may be the case that a stricter end time\nis required, for instance [65, 75]. In this case, starting xi at 50 and ending it at 80,\nthough respecting the duration bounds, would not be a legal value to \"execute\" the\ntoken, since 80 ̸∈[65, 75]. So, differently from the case of non-ﬂexible timelines,\ndurations alone are not sufﬁcient to suitably represent tokens. Analogously, end\ntime bounds do not capture all the necessary information: the above described\ntoken xi does not represent a valued interval starting at 40 and ending at 75, even\nthough it respects the start and end time bounds, it violates the duration constraint.\nControllability tags are part of token structures for a different reason. Although\nγ(xi) is equal to γ(val(xi)), such information is included in the token xi with the\n36\n\nFlexible Timeline-based Planning with Uncertainty\naim of having a self-contained representation of ﬂexible plans, encapsulating all the\nrelevant execution information. This allows the executive system to handle plans\nwith no need of considering also the description of the state variables. When con-\nsidering a set FTL of timelines for the state variables in SV , it is always assumed\nthat it contains exactly one timeline for each element of SV .\nSchedules\nA scheduled timeline is a particular case where each token has a singleton [t, t]\nas its end time, i.e. the end times are all ﬁxed. A schedule of a timeline FTLx is\nessentially obtained from FTLx by narrowing down to singletons (i.e. time points)\nthe token end times.\nThe schedule of a token corresponds to one of the valued intervals it represents\n(i.e., it is obtained by choosing an exact end point in the allowed interval, without\nchanging its duration bounds). A scheduled timeline is a sequence of scheduled\ntokens satisfying the duration requirements. Tokens, timelines and sets of timelines\nrepresent the set of their schedules.\nIn general, STLx and STL will be used as meta-variables for scheduled time-\nlines and sets of scheduled timelines, respectively, while FTLx and FTL as meta-\nvariables for generic (ﬂexible) timelines and sets of timelines. In what follows, an\ninterval of the form [t, t], consisting of a single time point, will be identiﬁed with\nthe time point t (and, with an abuse of notation, singleton intervals are allowed as\noperands of additions, subtractions, comparison operators, etc.).\nDeﬁnition 3 [Scheduled] A scheduled token is a token of the form\nxi = (v, [t, t], [d, d′], γ(v))\n(or succinctly xi = (v, t, [d, d′], γ(v))). A schedule of a token xi = (v, [e, e′],\n[d, d′], γ(v)) is a scheduled token xi = (v, t, [d, d′], γ(v)), where e ≤t ≤e′.\nA scheduled timeline STLx is a timeline consisting only of scheduled tokens and\nsuch that if k is the timeline length, then: for all 1 ≤i ≤k, if duration(xi) =\n[di, d′\ni], then di ≤end_time(xi) −start_time(xi) ≤d′\ni.\nA scheduled timeline STLx for the state variable x is a schedule of FTLx if STLx\nand FTLx have the same length k, and for all i, 1 ≤i ≤k, the token xi of STLx\nis a schedule of the token xi of FTLx.\nLet FTL be a set of timelines for the state variables in SV . A schedule STL of\n37\n\nFlexible Timeline-based Planning with Uncertainty\nFTL is a set of scheduled timelines for the state variables in SV , where each\nSTLx ∈STL is a schedule of the timeline FTLx ∈FTL.\nIn simple terms, a scheduled timeline is a timeline where every end time is\na singleton respecting the duration bounds. A schedule of a timeline is a way of\nassigning values to each token end time, so that both duration and end time bounds\nare respected. Tokens, timelines, and sets of timelines represent the set of their\nrespective schedules.\nExample 4 Let us consider the ﬂexible timeline FTLinst of example 3:\nFTLinst =\ninst1 = (Stowed, [20, 28], [20, 30], c)\ninst2 = (Unstowing, [23, 31], [3, 3], c)\ninst3 = (Unstowed, [50, 55], [19, 32], c)\nIt is worth pointing out that, since the start time of the ﬁrst token of a timeline is [0, 0],\nits end time bounds are usually equal to its duration bounds, but, like this example\nshows, it is not necessarily so.\nWhen the two intervals differ, the end point of the corresponding ﬁrst token in any\nschedule of the timeline belongs to their intersection. Each schedule of the timeline\nFTLinst represents a series of choices for the token end points, within the allowed\nintervals and respecting the allowed durations.\nFor instance, the following timeline is a schedule of FTLinst:\nSTLinst =\ninst1 = (Stowed, 25, [20, 30], c)\ninst2 = (Unstowing, 28, [3, 3], c)\ninst3 = (Unstowed, 51, [19, 32], c)\nIn fact, it satisﬁes all of the endpoint and duration bounds in FTLinst.\nClearly, not every sequence of scheduled tokens is a scheduled timeline. For instance,\nthe sequence of tokens obtained from STLinst by replacing the token inst2 with\ninst2 = (Unstowing, 31, [3, 3], c) is not a scheduled timeline at all, since it does not\nsatisfy the duration constraints for inst2: end_time(inst2) −start_time(inst2) =\n31 −25 = 6 > 3.\nLet us now consider the scheduled timeline STL′\ninst obtained from STLinst by re-\nplacing the token inst3 with inst3 = (Unstowed, 60, [19, 32], c). Although STL′\ninst\nsatisﬁes all the duration bounds, it is not a schedule of FTLinst, since the end time\nof inst3 is not in the allowed interval [50, 55] of inst3 in FTLinst.\n38\n\nFlexible Timeline-based Planning with Uncertainty\n4.2.2\nRestricting the Behavior of State Variables\nThe behavior of state variables may be restricted by requiring that time intervals\nwith given state variable values satisfy some temporal constraints. For instance, in\nthe ROVER sample domain, data can be communicated only when the communi-\ncation channel is available. In other terms, for every token cmi in the timeline for\nthe state variable cm having the value Communicating, there must exist a token\nin the timeline for win, with the value Available and bearing a given temporal re-\nlation with insti. This type of relations are expressed by means of synchronization\nrules that complete the deﬁnition of all the components of a domain speciﬁcation.\nTemporal Relations\nAs a ﬁrst step, the set of allowed temporal relations is introduced. They are either\nrelations between two intervals or relations between an interval and a time point.\nIn particular, this work considers quantitative temporal constraints. For the sake of\nsimplicity, a small set of primitive relations is chosen, all of which are parametrized\nby a (single) temporal interval.\nDeﬁnition 4 [Temporal Relation] A temporal relation between intervals is an ex-\npression of the form A ρ[lb,ub] B, where A = [sA, eA] and B = [sB, eB] are\ntime intervals, with sA, eA, sB, eB ∈T, ρ[lb,ub] ∈R = { start_before_start,\nend_before_end, start_before_end, end_before_start}, lb ∈T and ub ∈T∞.\nThe following table deﬁnes when a relation A ρ[lb,ub] B holds:\nthe relation\nholds if\nA start_before_start[lb,ub] B\nlb ≤sB −sA ≤ub\nA end_before_end[lb,ub] B\nlb ≤eB −eA ≤ub\nA start_before_end[lb,ub] B\nlb ≤eB −sA ≤ub\nA end_before_start[lb,ub] B\nlb ≤sB −eA ≤ub\nOther relations can be deﬁned in terms of the primitive relations in Deﬁnition\n4 (and their converses). These relations, like those used by EUROPA [Barreiro\net al., 2012] and APSI-TRF [Fratini et al., 2011], correspond to the quantitative\nextension of Allen’s temporal relations [Allen, 1983]. Thus, the relations in the\nleft most column of Table 4.1, are meant as abbreviations of the corresponding\nexpressions on their right.\n39\n\nFlexible Timeline-based Planning with Uncertainty\nthe relation\nis deﬁned as\nA meets B\nA end_before_start[0,0] B\nA before[lb,ub] B\nA end_before_start[lb,ub] B\nA overlaps[lb1,ub1][lb2,ub2] B\nA start_before_start[lb1,ub1] B∧\nA end_before_end[lb2,ub2] B∧\nB start_before_end[0,∞] A\nA equals B\nA start_before_start[0,0] B∧\nA end_before_end[0,0] B\nA contains[lb1,ub1][lb2,ub2] B\nA start_before_start[lb1,ub1] B∧\nB end_before_end[lb2,ub2] A\nA starts[lb,ub] B\nA start_before_start[0,0] B∧\nA end_before_end[lb,ub] B\nA ﬁnishes[lb,ub] B\nA start_before_start[lb,ub] B∧\nA end_before_end[0,0] B\nA starts_at t\nA starts_before[0,0] t\nA ends_at t\nA ends_before[0,0] t\nTable 4.1: Deﬁned temporal relations\nOnce relations on time intervals are deﬁned, they can be transposed to relations\non tokens. The expressions used to denote such relations refer to tokens by means\nof their names.\nDeﬁnition 5 [Token Relation] Let xi and yj be names of tokens belonging to\nscheduled timelines for the state variables x and y, respectively, with start_time\n\u0000xi\u0001\n= si, end_time\n\u0000xi\u0001\n= ei, start_time\n\u0000yj\u0001\n= sj, end_time\n\u0000yj\u0001\n= ej. Moreover,\nlet t, lb ∈T and ub ∈T∞. Expressions of the form xi ρ[lb,ub]yj, for ρ ∈R, and\nxi ρ[lb,ub]t, for ρ ∈R′, are called relations on tokens.\nThe relation xi ρ[lb,ub] yj holds iff [si, ei] ρ[lb,ub] [sj, ej] holds and the relation xi\nρ[lb,ub] t holds iff [si, ei] ρ[lb,ub] t holds. When a relation on two tokens xi and yj\nholds, we also say that the tokens xi and yj satisfy the relation, and that any set\nof scheduled timelines that contain xi and yj satisﬁes the relation. Analogously,\nif a relation xi ρ[lb,ub]t holds, then the token xi and any set of scheduled timelines\ncontaining xi satisfy the relation.\n40\n\nFlexible Timeline-based Planning with Uncertainty\nExample 5 Let STL = {STLcm, STLwin} be a set of timelines for the ROVER do-\nmain, including STLr, STLinst and STLnav, where STLcm contains the tokens\ncm5 = (Idle, 100, [1, 43], c)\ncm6 = (SendData, 123, [11, 32], u)\nand STLwin contains the tokens\nwin1 = (NotAvailable, 60, [60, 80], u)\nwin2 = (Available, 130, [50, 90], u)\nThe expressions win2 start_before_start[5,∞] cm6 and cm6 ends_before[30,45] 165\nare relations on tokens and they are satisﬁed by STL.\nSynchronization Rules\nA synchronization constraint can be informally considered as a statement of the\nform \"for every token . . . there exist tokens such that ...\". Namely, it represents\na kind of quantiﬁed sentence. The formal counterpart of this kind of assertions\nmakes use of variables: for every var0 ...there exist var1, . . . varn such that ....\nThe variables used to express synchronizations are called token variables. They are\ntaken from a (potentially inﬁnite) set X = {a0, a1, . . . } of names, whose elements\nare all different from variable names, values and numbers. These variables are\nintended to range over tokens in the considered set of timelines.\nMaking a step forward, it can be observed that synchronization assertions actu-\nally use a form of bounded quantiﬁcation: \"for all/exist tokens with value v in the\ntimeline for the state variable x ...\". Such token variables with restricted range will\nbe denoted by expressions of the form ai[x = v], where ai is a token variable, x\nis a state variable name, and v ∈values(x). Such expression are called annotated\ntoken variables. The next deﬁnition introduces the form of the assertions that can\nbe used to express parametrized relations on tokens.\nDeﬁnition 6 [Existential Statement] An atom is either the special constant ⊤or\nan expression of the form ai ρ[lb,ub] aj or ai ρ′\n[lb,ub] t, where ai and aj are token\nvariables, lb, t ∈T, ub ∈T∞, ρ ∈R, and ρ′ ∈R′.\nAn existential statement is an expression of the form\n∃a1[x1 = v1] . . . an[xn = vn] . C\nwhere\n41\n\nFlexible Timeline-based Planning with Uncertainty\n(i) a1, . . . , an are distinct token variables;\n(ii) for all i = 1, . . . , n, xi is a state variable and vi ∈values(xi) (i.e., ai[xi =\nvi] is an annotated token variable);\n(iii) C is a conjunction of atoms.\nThe bound variables of the statement are a1, . . . , an and any variable different from\na1, . . . , an possibly occurring in C is said to occur free in the statement.\nDisjunctions of existential statements constitute the body of synchronization\nrules.\nDeﬁnition 7 [Synchronization Rule] A synchronization rule is an expression of\nthe form\na0[x0 = v0] →E1 ∨· · · ∨Ek\n(for k ≥1) where every Ei is an existential statement whose bound variables are\nall different from a0 and where only the token variable a0 may occur free. The\nleft-hand part of the synchronization rule, a0[x0 = v0], is called the trigger of the\nrule.\nA synchronization rule with empty trigger is an expression of the form:\n⊤→E1 ∨· · · ∨Ek\n(for k ≥1) where every Ei is an existential statement with no free variables.\nIntuitively, a synchronization rule with non-empty trigger of the above form\nrequires that, whenever the state variable x0 assumes the value v0 in some interval\na0, there is at least an existential statement Ei = ∃a1[x1 = v1] . . . an[xn = vn] . C\nand tokens ai (1 ≤i ≤n) where the variable xi has the value vi, such that C\nholds (if C = ⊤, no temporal relation is required to hold). When the trigger is\nempty, the existence of the intervals ai and the relations among them have to hold\nunconditionally. Synchronization rules with empty triggers are useful to represent\ndomain invariants, as well as planning goals (both called \"facts\" in [Cimatti et al.,\n2013]). The use of token variables (which are absent in [Cimatti et al., 2013])\nallows one to refer to different intervals having the same value. Indeed, although\nthe token variables a0, . . . , an are pairwise distinct, multiple occurrences of state\nvariable names and values are allowed.\n42\n\nFlexible Timeline-based Planning with Uncertainty\nExample 6 Consider the operational constraint of the ROVER domain concerning\nthe data communication activity: the rover can send data only when the communica-\ntion channel is available and when it is not moving. A synchronization rule expressing\nthis operational constraint is the following:\na0[cm = SendData] →\n∃a1[win = Available] a2[nav = At].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\n∨∃a1[win = Available] a2[nav = Home].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\nAccording to this rule, whenever the state variable cm assumes the value SendData\nin an interval a0, the state variable win has the value Available in some interval a1\ncontaining a0, and the state variable nav must have the value At in some interval a2\ncontaining a0 or the value Home in some interval a2 containing a0. Namely the rover\ncannot move during communication tasks and communications can be performed only\nif the communication channel is available. Synchronization rules with empty triggers\nmay be useful to state known facts, such as, for instance:\n⊤→\n∃a1[nav = Home].a1 starts_at 0\nThis rule represents the fact that the rover is at the \"home\" location at the beginning\nof the mission. Synchronization rules with empty triggers are also used to represent\nplanning goals, as will be described later on.\nThe following deﬁnition introduces the semantics of synchronization on sched-\nuled timelines. Since the statement of a synchronization rule makes use of token\nvariables, each of them must be \"interpreted\", i.e., mapped to a token of the con-\nsidered timelines.\nDeﬁnition 8 [Satisﬁability of Synchronization Rules] Let FTL be a set of time-\nlines for the state variables SV . A token assignment for a set of annotated token\nvariables {a1[x1 = v1], . . . , an[xn = vn]} on FTL is a function ϕ mapping every\nai to a token of the timeline FTLxi ∈FTL and such that val (ϕ (ai)) = vi for all\ni = 1, . . . , n.\nLet C = A1 ∧· · · ∧Am be a conjunction of atoms and STL a set of scheduled\ntimelines, including a timeline for every state variable occurring in C. A token\nassignment ϕ on STL satisﬁes C if for every atom A ∈{A1, . . . , Am},\n(i) if A = ai ρ[lb,ub] aj then the relation ϕ (ai) ρ[lb,ub] ϕ (aj) holds;\n(ii) if A = ai ρ[lb,ub] t, then the relation ϕ (ai) ρ[lb,ub] t holds.\n43\n\nFlexible Timeline-based Planning with Uncertainty\nA token assignment ϕ on STL satisﬁes an existential statement of the form\n∃a1[x1 = v1] . . . an[xn = vn] . C\nif ϕ is a token assignment for a set of annotated variables including a0[x0 =\nv0], . . . , an[xn = vn] and ϕ satisﬁes C. Let\nS = a0[x0 = v0] →E1 ∨· · · ∨Ek\nbe a synchronization rule. A set of scheduled timelines STL for the state variables\nSV satisﬁes the synchronization rule S if for every token xk\n0 in STLx0 ∈STL such\nthat val(xk\n0) = v0, there exists a token assignment ϕ on STL such that ϕ(a0) = xk\n0\nand ϕ satisﬁes Ei for some i ∈{1, . . . , k}.\nA set of timelines STL for the state variables SV satisﬁes a synchronization rule\nwith empty trigger ⊤→E1 ∨· · · ∨Ek if, for some i ∈{1, . . . , k}, there exists a\ntoken assignment ϕ on STL satisfying Ei. Let SV be a set of state variables, S be a\nset of synchronization rules concerning variables in SV and STL be a set of sched-\nuled timelines for the state variables in SV . STL satisﬁes the set of synchronizations S\niff STL satisﬁes all the elements of S.\nExample 7 Consider the synchronization rule given in Example 6, that constrains\nthe rover to send data only when the communication channel is available, and to be\nstill during communication:\na0[cm = SendData] →\n∃a1[win = Available] a2[nav = At].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\n∨∃a1[win = Available] a2[nav = Home].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\nLet STLcm and STLwin be two scheduled timelines.\nAssume that the timeline for the pointing system contains a single token whose value\nis SendData, and has the form:\nSTLcm =\n. . .\ncmi−1 = (Idle, 110, [50, 80], c),\ncmi = (SendData, 130, [11, 32], u)\nIn addition, assume that the timeline STLwin (for the availability of the communica-\ntion channel) and the timeline STLnav (for the navigation system of the rover) have\n44\n\nFlexible Timeline-based Planning with Uncertainty\nthe forms:\nSTLwin =\n. . .\nwinj−1 = (NotAvailable, 80, [1, 100], u),\nwinj = (Available, 170, [60, 100], u)\nSTLnav =\n. . .\nnavk−1 = (Moving, 95, [14, 32], u),\nnavk = (At, 185, [34, 95], c)\nThe synchronization rule is satisﬁed by the scheduled timelines {STLcm, STLwin,\nSTLnav}. In fact, cmi is the only token in STLcm whose value is SendData, and\nthe token assignment ϕ, such that ϕ(a0) = cmi and ϕ(a1) = winj, satisﬁes the ex-\nistential statement ∃a1[win = Available] . a1 contains[0,∞][0,∞] a0: val(ϕ(a1)) =\nAvailable and ϕ satisﬁes a1 contains[0,∞][0,∞] a0. The latter assertion holds be-\ncause ϕ(a1) contains[0,∞][0,∞] ϕ(a0) – i.e., winj contains[0,∞][0,∞] cmi – holds,\nsince [80, 170] contains[0,∞][0,∞] [110, 130] holds.\n4.2.3\nPlanning Domains\nA planning domain is described by specifying a set of state variables and a set\nof synchronization rules. The formal deﬁnition of planning domains is given next,\ntogether with the notion of a set of scheduled timelines respecting the requirements\nof the domain.\nDeﬁnition 9 [Planning Domain] A planning domain is a triple (SVP , SVE, S),\nwhere:\n• SVP is a set of planned state variables;\n• SVE is a set of external state variables (with SVP ∩SVE = ∅);\n• S is a set of synchronization rules involving state variables in SVP ∪SVE.\nA set of scheduled timelines STL for the state variables in SV is valid with respect\nto the planning domain D = (SVP , SVE, S) if SV = SVP ∪SVE and STL satisﬁes\nthe set of synchronizations S.\nExample 8 Let us consider the planning domain D = (SVP , SVE, S} where SVP =\n{r, inst, nav, cm}, SVE = {win} – for the state variables described in Example\n2 – and S contains the following synchronization rules, modeling the operational\nconstraints described in Section 4.1:\n45\n\nFlexible Timeline-based Planning with Uncertainty\na0[cm = SendData] →\n∃a1[win = Available] a2[nav = At].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\n∨∃a1[win = Available] a2[nav = Home].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\na0[nav = Moving] →\n∃a1[inst = Stowed].a1 contains[0,∞][0,∞] a0\na0[r = TakeSample] →\n∃a1[inst = Sampling] a2[nav = At].\na0 contains[0,∞][0,∞] a1 ∧a2 contains[0,∞][0,∞] a1\nLet moreover STL be the set of timelines containing\nSTLr =\nr1 = (Idle, 23, [11, 200], c),\nr2 = (TakeSample, 55, [1, 70], c),\nr3 = (Idle, 200, [23, 178], c)\nSTLinst =\ninst1 = (Stowed, 28, [9, 45], c),\ninst2 = (Unstowing, 31, [3, 3], c),\ninst3 = (Unstowed, 32, [1, 30], c),\ninst4 = (Placing, 35, [3, 7], c),\ninst5 = (Sampling, 42, [7, 18], u),\ninst6 = (Unstowed, 200, [1, 200], c)\nSTLnav =\nnav1 = (Home, 5, [5, 5], c),\nnav2 = (Moving, 27, [19, 37], u),\nnav3 = (At, 200, [1, 200], c)\nSTLcm =\ncm1 = (Idle, 65, [50, 80], c),\ncm2 = (SendData, 83, [11, 32], u),\ncm3 = (Idle, 200, [1, 200], c)\nSTLwin =\nwin1 = (NotAvailable, 54, [23, 88], u),\nwin2 = (Available, 142, [60, 100], u),\nwin3 = (NotAvailable, 200, [1, 100], u)\nThe set STL is valid with respect to the planning domain D: it contains exactly one\ntimeline for each state variable in SVP ∪SVE and it satisﬁes all the synchronization\nrules of the domain.\n4.3\nFlexible Plans\nThe main component of a ﬂexible plan is a set FTL of timelines, representing dif-\nferent sets STLi of scheduled timelines. It may be the case that not every STLi\nsatisﬁes the synchronization rules of the domain. We aim at deﬁning plans so that\n46\n\nFlexible Timeline-based Planning with Uncertainty\nthey contain all the information needed to execute them, without having to check\nhow the behavior of state variables and timelines is constrained by the planning\ndomain.1 Consequently, a ﬂexible plan Π must be equipped with additional in-\nformation in order to guarantee that every set of scheduled timelines is valid with\nrespect to the domain speciﬁcation. Such information represent temporal relations\nthat have to hold in order to satisfy the synchronization rules of the domain.\nAs a schematic example showing why a set of timelines does not convey enough\ninformation to represent a ﬂexible plan, let us consider a domain with a synchro-\nnization rule S of the form a0[x = v] →∃a1[y = v′]. a0 meets a1 and time-\nlines for the state variables x and y containing, respectively, the tokens xi =\n(v, [30, 50], [20, 30], γ(v)) and yj, with val(yj) = v′ and start_time(yj) = [30, 50].\nNot every pair of schedules of xi and yj satisﬁes S. Thus, the representation of a\nﬂexible plan must also include information about the relations that must hold be-\ntween tokens in order to satisfy the synchronization rules of the planning domain.\nIn the example above, it would include the relation xi meets yj. In general, a\nﬂexible plan includes a set of relations on tokens.\nWhen there are different ways to satisfy a synchronization rule by the same set\nFTL of ﬂexible timelines, there are also different (valid) ﬂexible plans with the\nsame set of timelines FTL. Thus, a ﬂexible plan represents the set of its instances.\nDeﬁnition 10 [Flexible Plan] A ﬂexible plan Π is a pair (FTL, R), where FTL\nis a set of timelines and R is a set of relations on tokens involving token names\nin some timelines in FTL. An instance of the ﬂexible plan Π = (FTL, R) is any\nschedule of FTL that satisﬁes every relation in R.\nIn order to determine when a plan is valid with respect to a planning domain,\nthe semantics of synchronizations on ﬂexible plans must be deﬁned. Essentially, a\nplan Π = (FTL, R) satisﬁes a synchronization rule S if the constraints represented\nby S are guaranteed to hold for any schedule of FTL satisfying the relations in R.\nIn other terms, R represents a possible way to satisfy S. The intuition underlying\nthe formal deﬁnition can be explained as follows.\nWhen considering a plan Π = (FTL, R), a mapping is used to assign the an-\nnotated token variables occurring in the synchronization to token names occurring\nin FTL. Let us consider, for instance a rule of the form\na0[x = v] →∃a1[y = v′].a1 end_before_start[10,20] a0.\n1For the same reason controllability tags are included in token descriptions.\n47\n\nFlexible Timeline-based Planning with Uncertainty\nLet us moreover assume that x3 is a token in the timeline for x in FTL with\nval(x3) = v, and that the timeline for y in FTL contains exactly two tokens y5\nand y8 having value v′. In order for the rule to be satisﬁed, FTL must be con-\nstrained by requiring that x3 starts from 10 to 20 time units after the end of either\ny5 or y8. The plan Π commits to one of the two alternatives: binding a1 to either\ny5 or y8.\nExample 9 Let Π = (FTL, R), where:\n• FTL contains the timelines\nFTLr =\nr1 = (Idle, [16, 32], [11, 200], c)\nr2 = (TakeSample, [45, 102], [1, 70], c)\nr3 = (Idle, [200, 200], [23, 178], c)\nFTLinst =\ninst1 = (Stowed, [13, 38], [9, 45], c)\ninst2 = (Unstowing, [16, 41], [3, 3], c)\ninst3 = (Unstowed, [25, 70], [1, 30], c)\ninst4 = (Placing, [28, 75], [3, 7], c)\ninst5 = (Sampling, [33, 90], [7, 18], u)\ninst6 = (Unstowed, [200, 200], [1, 200], c)\nFTLnav =\nnav1 = (Home, [5, 5], [5, 5], c)\nnav2 = (Moving, [24, 35], [19, 37], u)\nnav3 = (At, [200, 200], [1, 200], c)\nFTLcm =\ncm1 = (Idle, [58, 77], [50, 80], c)\ncm2 = (SendData, [70, 105], [11, 38], u)\ncm3 = (Idle, [200, 200], [1, 200], c)\nFTLwin =\nwin1 = (NotAvailable, [32, 75], [23, 88], u)\nwin2 = (Available, [95, 155], [60, 100], u)\nwin3 = (NotAvailable, [200, 200], [1, 100], u)\n• R contains the temporal relations\nwin2 contains[0,∞][0,∞] cm2\nnav3 contains[0,∞][0,∞] cm2\ninst1 contains[0,∞][0,∞] nav2\nr2 contains[0,∞][0,∞] inst5\nnav3 contains[0,∞][0,∞] inst5\nr2 before[0,∞] cm2\nΠ is a ﬂexible plan, and the set STL of scheduled timelines containing\n48\n\nFlexible Timeline-based Planning with Uncertainty\nFTLr =\nr1 = (Idle, 18, [11, 200], c)\nr2 = (TakeSample, 65, [1, 70], c)\nr3 = (Idle, 200, [23, 178], c)\nFTLinst =\ninst1 = (Stowed, 42, [9, 45], c)\ninst2 = (Unstowing, 45, [3, 3], c)\ninst3 = (Unstowed, 46, [1, 30], c)\ninst4 = (Placing, 50, [3, 7], c)\ninst5 = (Sampling, 57, [7, 18], u)\ninst6 = (Unstowed, 200, [1, 200], c)\nFTLnav =\nnav1 = (Home, 5, [5, 5], c)\nnav2 = (Moving, 40, [19, 37], u)\nnav3 = (At, 200, [1, 200], c)\nFTLcm =\ncm1 = (Idle, 70, [50, 80], c)\ncm2 = (SendData, 93, [11, 38], u)\ncm3 = (Idle, 200, [1, 200], c)\nFTLwin =\nwin1 = (NotAvailable, 63, [23, 88], u)\nwin2 = (Available, 125, [60, 100], u)\nwin3 = (NotAvailable, 200, [1, 100], u)\nis an instance of Π, since {STLr, STLinst, STLnav, STLcm, STLwin} is a schedule\nof FTL and it satisﬁes all the temporal relations in R.\nIf however, the end time of inst5 in STLinst is replaced by 68, the so obtained set of\nscheduled timelines is not an instance of Π, although it is a schedule of FTL, because\nthe relation\n{r2 contains[0,∞][0,∞] inst5} ∈R\nis not satisﬁed.\nThe correspondence between token variables and token names is established by\nuse of a function ϕ mapping a1 to either y5 or y8. According to the chosen option,\nthe set of relations R in the plan contains either y5 end_before_start[10,20] x3 or\ny8 end_before_start[10,20] x3.\nDeﬁnition 11 [Plan Satisﬁability] Let C = A1 ∧· · · ∧Am be a conjunction of\natoms, Π = (FTL, R) a ﬂexible plan, where FTL contains a timeline for every\nstate variable occurring in C, and ϕ a token assignment on FTL. The plan Π\nsatisﬁes C with ϕ if for every atom A ∈{A1, . . . , Am}, (i) if A = ai ρ[lb,ub] aj,\nthen ϕ (ai) ρ[lb,ub] ϕ (aj) ∈R, and (ii) if A = ai ρ[lb,ub] t, then ϕ (ai) ρ[lb,ub] t ∈R.\nLet\nE = ∃a1[x1 = v1] . . . an[xn = vn] . C\n49\n\nFlexible Timeline-based Planning with Uncertainty\nbe an existential statement and ϕ be a token assignment on FTL. The ﬂexible plan\nΠ satisﬁes E with ϕ if ϕ is an assignment for a set of annotated token variables\nincluding a0[x0 = v0], . . . , an[xn = vn] and Π satisﬁes C with ϕ.\nThe plan Π satisﬁes a synchronization rule with non-empty trigger\na0[x0 = v0] →E1 ∨· · · ∨Ek\nif for every ﬂexible token xm\n0 of the timeline FTLx0 ∈FTL such that val(xm\n0 ) =\nv0, there exists a token assignment ϕ on FTL such that ϕ(a0) = xm\n0 and Π satisﬁes\nEi with ϕ, for some i ∈{1, . . . , k}.\nThe plan Π satisﬁes a synchronization rule with empty trigger\n⊤→E1 ∨· · · ∨Ek\nif, for some i ∈{1, . . . , k}, there exists a token assignment ϕ on FTL such that Π\nsatisﬁes Ei with ϕ.\nExample 10 Let us consider the ﬂexible timelines FTLcm, FTLnav and FTLwin of\nExample 9. The ﬂexible plan Π = (FTL, R), where FTL = { FTLcm, FTLnav,\nFTLinst, FTLwin} and R containing the temporal relations\n{win2 contains[0,∞][0,∞] cm2, nav3 contains[0,∞][0,∞] cm2}\nsatisﬁes the synchronization rule with trigger SendData, given in Example 8:\na0[cm = SendData] →\n∃a1[win = Available] a2[nav = At].\na1 contains[0,∞][0,∞] a0 ∧a2 contains[0,∞][0,∞] a0\nConsidering the deﬁnition of the relation contains given in Table 4.1, the two tempo-\nral constraints of the synchronization rule can be rewritten as:\n(a1 start_before_start[0,∞] a0 ∧a0 end_before_end[0,∞] a1),\n(a2 start_before_start[0,∞] a0 ∧a2 end_before_end[0,∞] a0).\nThe set R contains the atoms\nϕ(a1) start_before_start[0,∞] ϕ(a0), ϕ(a0) end_before_end[0,∞] ϕ(a1),\nϕ(a2) start_before_start[0,∞] ϕ(a0), ϕ(a0) start_before_start[0,∞] ϕ(a2)\nfor the token assignment ϕ such that ϕ(a0) = cm2, ϕ(a1) = win2 and ϕ(a2) =\n50\n\nFlexible Timeline-based Planning with Uncertainty\nnav3. Clearly, there might be schedules of the set of timelines FTL that do not satisfy\nall the requirements. For example the requirement win2 contains[0,∞] [0, ∞]cm2 is\nnot satisﬁed by the schedules where start_time(cm2) = 70, end_time(cm2) = 108,\nstart_time(win2) = 30 and end_time(win2) = 90, which consequently are not\ninstances of the ﬂexible plan Π.\nHowever, if schedules like those in Example 9 satisfy all the requirements, then such\nschedules of FTL are also instances of Π. As a further example showing how a plan\ncommits to a choice among the possibly different ways to satisfy a synchronization\nrule, let us consider a set FTL of timelines and a rule S of the form\na0[x = v] →\n∃a1[y = v′]. a1 end_before_start[10,20] a0\n∨∃a1[z = v′′]. a0 end_before_start[5,∞] a1\nLet us moreover assume that x3 and x7 are the only tokens with value v in the timeline\nFTLx for x in FTL, that the timeline FTLy for y in FTL contains exactly one token\ny5 having value v′, and that FTLz contains exactly one token z8 with value v′′.\nIn order to satisfy the rule S:\n1. R must contain the constraints\n{y5 end_before_start[10,20] x3, x3 end_before_start[5,∞] z8}\nIn fact the plan has to satisfy either ∃a1[y = v′].a1 end_before_start[10,20] a0\nor ∃a1[z = v′′].a0 end_before_start[5,∞] a1 with a token assignment ϕ such\nthat ϕ(a0) = x3. If R contains y5 end_before_start[10,20] x3, then the plan\nsatisﬁes the existential statement (i) with ϕ, when ϕ(a1) = y5. If it contains x3\nend_before_start[5,∞] z8, then the plan satisﬁes (ii) with ϕ, when ϕ(a1) = z8.\n2. R must contain the constraints\ny5 end_before_start[10,20] x7, x7 end_before_start[5,∞] z8\nThe reasoning is the same as above, just replacing x7 for x3.\nTherefore, for instance, both plans\n(FTL, {y5 end_before_start[10,20] x3, x7 end_before_start[5,∞] z8})\n(FTL, {x3 end_before_start[5,∞] y5, y5 end_before_start[10,20] x7})\nsatisfy S\nThe notions of plan validity and consistency can now be deﬁned.\nDeﬁnition 12 [Plan Validity] A ﬂexible plan Π = (FTL, R) is valid with respect\nto a planning domain D = (SVP , SVE, S) iff:\n51\n\nFlexible Timeline-based Planning with Uncertainty\n1. FTL is a set of timelines for the state variables SV = SVP ∪SVE;\n2. Π satisﬁes all the synchronization rules in S;\n3. for each planned state variable x = (V, T, γ, D) ∈SVP , and each un-\ncontrollable token xi in FTLx ∈FTL, if D(val(xi)) = (dmin, dmax) and\nstart_time(xi) = [s, s′], then duration(xi) = [dmin, dmax] and end_time(xi)\n= [s + dmin, s′ + dmax].\nThe plan Π is consistent if there exists at least one instance of Π.\nThe last condition required for a plan to be valid guarantees that the plan does\nnot make any hypothesis on the duration of uncontrollable values of planned vari-\nables. The restriction is not applied to external variables, since the planner is not\nallowed to control them at all: their behavior is described in the planning problem\nas a sort of observation of the external world.\nIt is important to point out that plan consistency is a minimal requirement for a\nplan to be considered meaningful, although, when the domain includes uncontrol-\nlable elements, it is not enough to guarantee its executability. In this regards, the\nwork [Cialdea Mayer et al., 2016] proves a result showing that there exists a set\nΘ of ﬂexible plans for which an effective consistency check procedure exists, yet\nevery scheduled valid plan is an instance of some ﬂexible plan in Θ. Intuitively,\neach plan Π ∈Θ is such that the sequence of scheduled tokens, obtained by ﬁxing\nevery token end point to the lower bound of the respective end time interval, is an\ninstance of Π (i.e., it is a scheduled timeline respecting the relations in Π). The\nmentioned result implies that, when searching for a consistent plan, it is sufﬁcient\nto consider candidate plans in Θ, respecting the above condition.\n4.4\nProblem Speciﬁcation\nIn timeline-based planning, a planning problem typically includes a planning hori-\nzon, i.e., the time by which the system behavior has to be planned. Finally, since\nthe external state variables are not under the system control, the problem must in-\nclude information about their behavior up to the given horizon. Such information\nis given in the form of a set of ﬂexible timelines and temporal relations on their\ntokens.\n52\n\nFlexible Timeline-based Planning with Uncertainty\nDeﬁnition 13 [Planning Problem] A planning problem is a tuple (D, G, O, H),\nwhere D = (SVP , SVE, S) is a planning domain, G a planning goal for D, H ∈\nT>0 is the planning horizon, and O = (FTLE, RE), where\n(i) FTLE is a set containing exactly one ﬂexible timeline for each external state\nvariable in SVE;\n(ii) the horizon of every timeline in FTLE is [h, h′] for some h ≥H;\n(iii) RE is a set of temporal relations on tokens of timelines in FTLE;\n(iv) (FTLE, RE) is consistent, i.e., there is at least one schedule of FTLE satis-\nfying the relations in RE.\nThe pair O, called the observation, speciﬁes the behavior of external state vari-\nables up to a time point not less than the planning horizon. Item (iv) rules out\ninconsistent observations, i.e., descriptions of the behavior of the external state\nvariables with no instances. The pair (FTLE, RE) can be viewed as a ﬂexible\nplan. In particular, even when RE = , the set of timelines FTLE must have at least\none schedule.\nThe planner must respect what is speciﬁed by the set of timelines FTLE, with-\nout taking any autonomous decision: this requirement is fulﬁlled simply when the\ntimeline for each external variable in the plan is exactly the timeline for the same\nstate variable in FTLE. The relations in RE represent known facts about the exter-\nnal world.\nIt is worth pointing out that, since FTLE is a set of timelines, the planner\nknows how the external components evolve, i.e., the sequence of activities/states\nconstituting their behavior, the only uncertainty being the duration of such states.\nThis rules out, for instance, scenarios where the uncontrollable events might occur\nan unknown number of times within the given horizon.\nExample 11 For instance, a planning problem for our sample domain can be the\nproblem Π = (D, G, O, H), where\n• D is the planning domain of Example 2, i.e., D = (SVP , SVE, S} where\nSVP = {r, inst, nav, cm}, SVE = {win} and S contains the synchronization\nrules of Example 8\n• G = (Γ, ∆) – see Example 12 – where\nΓ = {g1 = (r, TakeSample), g2 = (cm, SendData)}\n53\n\nFlexible Timeline-based Planning with Uncertainty\nand\n∆= g1 before[0,65] g2\n• O = ({FTLwin}, RE), where\nFTLwin =\nwin1 = (NotAvailable, [32, 75], [23, 88], u)\nwin2 = (Available, [95, 155], [60, 100], u)\nwin3 = (NotAvailable, [200, 200], [1, 100], u)\n• H = 200.\n4.4.1\nPlanning Goals\nA planning problem includes the description of the underlying planning domain\nand of a desired goal to be accomplished. This work considers temporally ex-\ntended goals: a planning goal speciﬁes that some planned variables have to assume\nsome given values in some intervals, possibly satisfying some temporal relations.\nDisjunctive goals are also allowed.\nDeﬁnition 14 [Planning Goal] A planning goal G for a domain D = (SVP , SVE, S)\nis a pair (Γ, ∆), where:\n(i) Γ is a set of accomplishment goals, i.e., expressions of the form g = (x, v),\nwhere g is a token variable, called the goal name, x ∈SVP , and v ∈\nvalues(x);\n(ii) ∆, called a relational goal, is a disjunction D1 ∨· · · ∨Dk, where each Di is\na conjuntion of atoms containing only goal names occurring in Γ.\nA planning goal G = (Γ, ∆), with Γ = {g1 = (x1, v1), . . . , gn = (xn, vn)} and\n∆= D1∨· · ·∨Dk, is represented by a synchronization rule SG with empty trigger,\nof the form:\n⊤→\n∃g1[x1 = v1] . . . gn[xn = vn]. D1\n∨· · · ∨\n∃g1[x1 = v1] . . . gn[xn = vn]. Dk\nIt is worth pointing out that restrictions on the start and end intervals of a given\ngoal (like in [Cimatti et al., 2013, Cesta et al., 2009]) can be expressed by means of\nrelational goals. In particular, if the start point of a given goal g is required to be in\nthe interval [s, s′] and its end point in [e, e′], then such restrictions can be expressed\nby the relational goal (g starts_after[0,s′−s] s) ∧(g ends_after[0,e′−e] e).\n54\n\nFlexible Timeline-based Planning with Uncertainty\nExample 12 A simple planning goal for the ROVER domain may be that, in order to\naccomplish the mission, the rover has to take a sample of a target to be analyzed and\nthen communicate the scientiﬁc results no later than 65 time units after the completion\nof the sampling task. Such a goal is is represented by the pair (Γ, ∆), where\nΓ = {g1 = (r, TakeSample), g2 = (cm, SendData)}\nand\n∆= g1 before[0,65] g2\nwhich can be turned into the synchronization rule\n⊤→\n∃g1[r = TakeSample] g2[cm = SendData].\ng1 before[0,65] g2\nAnalogously, if the rover has to come back \"home\" (a known initial position) to com-\nplete the mission and we want to specify an alternative ordering constraint for the\ncommunication task, i.e., the rover may communicate scientiﬁc data either before\ngoing back \"home\" or immediately after, the goal is the goal is G = (Γ, ∆), where\nΓ = {g1 = (r, TakeSample), g2 = (cm, SendData), g3 = (nav, Home)},\nand\n∆= (g1 before[0,∞] g3 ∧g3 meets g2) ∨(g1 before[0,65] g2 ∧g2 before[0,∞] g3).\nThe corresponding synchronization rule is:\n⊤→\n∃g1[r = TakeSample] g2[cm, SendData] g3[nav, Home].\n(g1 before[0,∞] g3 ∧g3 meets g2)\n∨∃g1[r = TakeSample] g2[cm = SendData] g3[nav, Home].\n(g1 before[0,65] g2 ∧g2 before[0,∞] g3)\nThe next deﬁnition introduces the notion of goal fulﬁlment for scheduled time-\nlines.\nDeﬁnition 15 [Goal Satisﬁability] A set of scheduled timelines STL fulﬁls the\nplanning goal G if it satisﬁes the synchronization rule SG representing G.\n4.4.2\nSolution Plans\nDeﬁnition 16 [Solution Plan] Let P = (D, G, O, H) be a planning problem and\nΠ = (FTL, R) be a ﬂexible plan. Π is a ﬂexible solution plan for P if:\n55\n\nFlexible Timeline-based Planning with Uncertainty\n1. for every planned state variable x, the horizon of FTLx ∈FTL is [H, H];\n2. Π is valid with respect to D;\n3. Π satisﬁes the synchronization rule SG representing G;\n4. If O = (FTLE, RE), then FTLE ⊆FTL.\nThe ﬁrst condition above guarantees that the behavior of the planned state vari-\nables is determined exactly up to the horizon of the planning problem, henceforth\n(condition 3) all the planning goals are achieved in due time. It is worth pointing\nout that condition 1 implies that the last token of each planned timeline must be\ncontrollable. Condition 4 ensures that the plan does not make any assumption on\nexternal variables, except for what is implied by the state variable deﬁnition and\nthe observation.\nExample 13 Let us consider, for instance, the problem P of Example 11 and the\nﬂexible plan Π = (FTL, R), where:\n• FTL = {FTLr, FTLinst, FTLnav, FTLcm, FTLwin}, where the timelines\nare those of the Example 9:\nFTLr =\nr1 = (Idle, [16, 32], [11, 200], c)\nr2 = (TakeSample, [45, 102], [1, 70], c)\nr3 = (Idle, [200, 200], [23, 178], c)\nFTLinst =\ninst1 = (Stowed, [13, 38], [9, 45], c)\ninst2 = (Unstowing, [16, 41], [3, 3], c)\ninst3 = (Unstowed, [25, 70], [1, 30], c)\ninst4 = (Placing, [28, 75], [3, 7], c)\ninst5 = (Sampling, [33, 90], [7, 18], u)\ninst6 = (Unstowed, [200, 200], [1, 200], c)\nFTLnav =\nnav1 = (Home, [5, 5], [5, 5], c)\nnav2 = (Moving, [24, 35], [19, 37], u)\nnav3 = (At, [200, 200], [1, 200], c)\nFTLcm =\ncm1 = (Idle, [58, 77], [50, 80], c)\ncm2 = (SendData, [70, 105], [11, 38], u)\ncm3 = (Idle, [200, 200], [1, 200], c)\nFTLwin =\nwin1 = (NotAvailable, [32, 75], [23, 88], u)\nwin2 = (Available, [95, 155], [60, 100], u)\nwin3 = (NotAvailable, [200, 200], [1, 100], u)\n56\n\nFlexible Timeline-based Planning with Uncertainty\n• R contains the two relations on tokens\nwin2 contains[0,∞][0,∞] cm2\nnav3 contains[0,∞][0,∞] cm2\ninst1 contains[0,∞][0,∞] nav2\nr2 contains[0,∞][0,∞] inst5\nnav3 contains[0,∞][0,∞] inst5\nr2 before[0,∞] cm2\nThe plan Π is a ﬂexible solution plan for the planning problem P because:\n• the horizon is 200 for all the timelines of the planned variables;\n• Π is valid with respect to D:\n– FTL contains the timelines for r, inst, nav, cm and win;\n– Π satisﬁes the synchronization rule of the domain;\n– all uncontrollable tokens satisfy the duration constraints of the related\nvalues\n• Π satisﬁes the synchronization rule SG representing G: the tokens pm3 and\npm6 have values Science and Comm, respectively, and R contains the rela-\ntion pm3 before[0,65] pm6.\n• FTLgv ∈FTL.\nThe next result proves that information encoded by a ﬂexible solution plan Π\nfor a given planning problem is sufﬁcient to ensure that every instance of Π is valid\nwith respect to the planning domain and it fulﬁls the goal. Although the proof\nof this result is a straightforward consequence of the deﬁnitions, it deserves to be\nstated explicitly, since ﬂexible plans without such a property would be meaning-\nless.\nTheorem 1 If the plan Π is a ﬂexible solution plan for the problem\nP = (D, G, O, H),\nthen every instance of Π is valid with respect to D and fulﬁls the goal G.\n57\n\nChapter 5\nThe Extensible Planning and\nScheduling Library\nT\nIMELINE-BASED APPLICATIONS are problem solvers capable of taking into\naccount several features of a problem as well as integrating different tech-\nniques into the reasoning process (e.g. planning and scheduling integration). The\ndesign and implementation choices made to realize this kind of applications are re-\nally complex and closely connected to the speciﬁc characteristics of the particular\nproblem to address. These choices are difﬁcult to replicate and therefore it is not\neasy to leverage past experience and deploy existing applications to different con-\ntexts. Typically, it is necessary to start developing new applications from scratch\nin order to solve new types of problem.\nThe Extensible Planning and Scheduling Library (EPSL) [Umbrico et al.,\n2015, Cesta et al., 2013] is the result of a research effort which aims at realiz-\ning a general purpose timeline-based framework capable of supporting the design\nof P&S applications. The modeling features of EPSL concerning the representa-\ntion and management of timelines take inspiration from APSI-TRF. Nevertheless,\naccording to the formalization described in [Cialdea Mayer et al., 2016], EPSL ex-\ntends the APSI-TRF representation by introducing temporal uncertainty in shape\nof uncontrollable activities and external features of a planning domain. Tempo-\nral uncertainty allows EPSL to address planning problems in which not all the\nfeatures of the domain are under the control of the system. Thus, EPSL-based\nsolvers generate, if possible, plans with some desired property concerning tempo-\nral controllability [Morris et al., 2001, Vidal and Fargier, 1999]. The validity of a\nplan with respect to the domain speciﬁcation does not represent a sufﬁcient con-\n58\n\nThe Extensible Planning and Scheduling Library\ndition to guarantee its executability in the real-world. Namely, the uncontrollable\ndynamics of the environment may prevent the complete and correct execution of\nplans. Thus, from the planning perspective, it is important to generate plans with\nsome minimum controllability properties. EPSL takes into account the pseudo-\ncontrollability property which represents a necessary but not sufﬁcient condition\nfor dynamic controllability [Morris et al., 2001] of plans.\nBroadly speaking, the solving approach is a general plan reﬁnement procedure\nwhich iteratively detects a set of ﬂaws on the current plan and selects the most\npromising ﬂaw to solve according to certain evaluation criteria. The actual be-\nhavior of the solving procedure is determined by the speciﬁc conﬁguration of an\nEPSL-based solver in terms of the particular strategy and the particular evaluation\ncriteria applied during the search. In this context, the EPSL modular architecture\nallows to ﬁnd the planner conﬁguration which best meets the speciﬁc features of\nthe problem to address. In particular, this work presents a modeling and solving\napproach which allows to realize a hierarchical reasoning with timelines [Umbrico\net al., 2015].\n5.1\nThe Modeling Language\nEPSL takes inspiration from the APSI-TRF representation functionalities and\nuses the Domain Description Language (DDL) which is the modeling language\nthat also APSI-TRF uses to model planning domains. DDL is a structured mod-\neling language introduced in [Cesta and Oddi, 1996]. It provides the syntactic\nelements needed to describe timeline-based domains, i.e. state variables and syn-\nchronization rules. In addition, the Problem Description Language (PDL) is a\nlanguage dedicated to describe problem instances.\nThus, an EPSL-based planner takes as input, a DDL and a PDL ﬁles repre-\nsenting respectively the description of a timeline-based domain and the description\nof a particular problem to solve. Given such input, an EPSL-based planner gen-\nerates (if possible) a valid solution plan as output. In particular, EPSL relies on\nan extended syntax of DDL in order to comply with the formal characterization\nof timelines introduced in [Cialdea Mayer et al., 2016]. Speciﬁcally, EPSL in-\ntroduces the syntactic constructs that allow users to specify controllability proper-\nties of state variable values (i.e. whether a value is controllable or uncontrollable)\nand the type of modeled state variables (i.e. whether a state variable is planned or\nexternal). Thus, the following sections provide a detailed description of the ex-\n59\n\nThe Extensible Planning and Scheduling Library\ntended DDL/PDL language by exploiting the ROVER planning domain introduced\nin Chapter 4.\n5.1.1\nThe Domain Description Language\nThe Domain Description Language (DDL) is the language EPSL uses for domain\nmodeling. The DDL provides the syntactic constructs needed to describe state\nvariables, synchronization rules and all the information needed to characterize a\ntimeline-based planning domain. This section introduces the \"extended\" DDL\nsyntax by describing a timeline-based model designed for the ROVER planning\ndomain. In general, a DDL model is composed by the following parts: (i) gen-\neral declaration; (ii) state variable speciﬁcation; (iii) component speciﬁcation; (iv)\nsynchronization speciﬁcation.\nThe code below shows the general domain declaration for the ROVER planning\ndomain. It declares the name of the planning domain, the temporal horizon and\nthe types of parameters that the values of the components may assume. Specif-\nically, the location parameter models the set of physical locations the rover can\nmove to. In this speciﬁc domain the possible locations are discretized and modeled\nas symbols rather than as coordinates on a two-dimensional or three-dimensional\nspace. Thus, location is an enumeration parameter whose values are included in\na discrete set of symbols. The ﬁle parameter models the data ﬁles that the rover\ncan communicate to share scientiﬁc information. The parameter is modeled as a\nnumeric parameter whose values range within the interval [0, 100].\nDOMAIN Rover\n{\nTEMPORAL_MODULE tm = [0, 100];\nPAR_TYPE\nEnumerationParameter location = {\nhome, location1, location2, location3, location4\n}\nPAR_TYPE\nNumericParameter file = [0, 100];\n...\n}\nThe state variable speciﬁcation of a DDL model describes the features of the\nplanning domain that must be controlled over time and their possible temporal\nevolutions. Considering the ROVER example, the domain speciﬁcation must model\n60\n\nThe Extensible Planning and Scheduling Library\nthe navigation facility that allows the rover to move, the communication facility\nthat allows the rover to communicate scientiﬁc data and the instrument that allows\nthe rover to take samples to be analyzed. In addition, the domain speciﬁcation must\nmodel the available communication windows during which the rover may actually\nsend data.\nThe following code shows the state variable declaration modeling the func-\ntional and abstract behavior of the whole system to control, i.e. the planetary ex-\nploration rover. The RoverType state variable models the high-level tasks or states\nthe rover may perform or assume over time. The value Idle() represents the fact\nthat the rover is not operating and therefore it can receive goals, i.e. tasks to be per-\nformed. The value TakeSample(?location, ?ﬁle) represents a mission goal which\nasks the rover to take a sample at a speciﬁc ?location, perform some analysis on the\ngathered samples and communicate data (i.e. ?ﬁle) to the ground station. Both val-\nues are controllable and the related duration constraints do not bound them to some\nintervals. Consequently, the planner can dynamically decide the actual duration of\nthese values according to the speciﬁc needs of the generated plans.\nCOMP_TYPE\nStateVariable RoverType (\nIdle(),\nTakeSample(location, file))\n{\nVALUE Idle()\n[1, +INF]\nMEETS {\nTakeSample(?location, ?file);\n}\nVALUE TakeSample(?location, ?file)\n[1, +INF]\nMEETS {\nIdle();\n}\n}\nThe code below shows the state variable speciﬁcation for the navigation facility\nof the rover. The NavigationType state variable models the states and actions that\nthe navigation module of the rover can assume or perform over time. The value\nAt(?location) models the fact that the rover is still at a known ?location. This\nvalue is controllable and represents a temporally stable state because the related\nduration constraint does not specify a bound for the value. The transition function\nrequires that a value GoingTo(?destination) follows a value At(?location) and that\nthe parameter constraint ?location != ?destination holds. The parameter constraint\n61\n\nThe Extensible Planning and Scheduling Library\nguarantees that the rover does not move in case that the current location coincides\nwith the desired destination.\nThe value GoingTo(?location) models the moving action of the rover. In this\ncase the value is uncontrollable and a duration bound is speciﬁed [5, 11]. Thus, the\nsystem knows the estimated duration of the action, but it cannot completely control\nit. Namely, the rover can decide when to start moving towards a destination, but\nit cannot predict the time needed to reach the destination. Indeed, external factors,\nsuch as obstacles or the features of the ground, may affect the speed of the rover and\ntherefore the time the rover takes to complete the GoingTo(?location) activity/task.\nMoreover, the related transition constraint requires that a value At(?destination)\nfollows a value GoingTo(?location) and that the parameter constraint ?destination\n= ?location holds. Namely, the the rover is actually located at ?location (i.e. the\ndesired destination) after the successful execution of theGoingTo(?location).\nCOMP_TYPE\nStateVariable NavigationType (\nAt(location),\nGoingTo(location))\n{\nVALUE At(?location)\n[1, +INF]\nMEETS {\nGoingTo(?destination);\n?location != ?destination;\n}\nVALUE\nuncontrollable GoingTo(?location)\n[5, 11]\nMEETS {\nAt(?destination);\n?destination = ?location;\n}\n}\nThe next block of code describes the state variable modeling the instrument\npayload of the rover. The InstrumentType state variable models the position the\ninstrument assumes and the operations it may perform over time. It is a planned\nvariable with both controllable and uncontrollable values. The values Unstowed()\nand Stowed() are temporally stable values that model respectively the idle state of\nthe instrument and the operating state of the instrument. Namely, the instrument\nis not operative and cannot be used to take samples during Stowed(). Conversely,\nthe instrument is operative and ready to take samples during Unstowed() . The\ntransitions between the two states are modeled through values Unstowing() and\n62\n\nThe Extensible Planning and Scheduling Library\nStowing(). They are both controllable values and their durations are ﬁxed. Thus\nthe system knows exactly how long the instrument takes to change from an idle\nstate to an operative state and vice versa.\nAfter activation through unstowing, the instrument must be placed over a tar-\nget in order to take samples. Thus, the value Placing(?location) similarly to the\nGoingTo(?location) value, models the transition between the Unstowed and the\nPlaced(?location) values. However, the Placed(?location), differently from the\nGoingTo(?location) value, is modeled as a controllable value with ﬂexible dura-\ntion. Indeed, the instrument is supposed to move among the reachable position\nwithout ﬁnding obstacles or any sort of external elements that may slow-down or\neven prevent the motion. Thus, it can be modeled as a controllable process whose\nﬂexible duration is determined by the minimum and maximum time needed by the\ninstrument to reach the possible targets.\nThe value Placed(?location) models the fact that the instrument has been actu-\nally placed on a target and therefore it is ready to perform any operation on it. The\nSampling value models the operation which allows the instrument to take samples\nof the target it is placed on. Such operation is uncontrollable because the time the\ninstrument takes to take samples is affected by the particular shape and size of the\ntarget. This is a source of uncertainty of the environment and therefore the sam-\npling operation is modeled as an uncontrollable process with an estimated lower\nand upper bounds for the duration.\nCOMP_TYPE\nStateVariable InstrumentType (\nUnstowed(),\nStowing(),\nStowed(),\nUnstowing(),\nPlacing(location),\nPlacec(location),\nSampling(location))\n{\nVALUE Unstowed()\n[1, +INF]\nMEETS {\nStowing();\nPlacing(?location);\n}\nVALUE Stowing()\n[3, 3]\nMEETS {\nStowed();\n63\n\nThe Extensible Planning and Scheduling Library\n}\nVALUE Stowed()\n[1, +INF]\nMEETS {\nUnstowing();\n}\nVALUE Unstowing()\n[3, 3]\nMEETS {\nUnstowed();\n}\nVALUE Placing(?location)\n[3, 7]\nMEETS {\nPlaced(?target);\n?target = ?location;\n}\nVALUE Placed(?location)\n[1, +INF]\nMEETS {\nSampling(?target);\n?target = ?location;\nPlacing(?newTarget);\n?newTarget != ?target;\nUnstowed();\n}\nVALUE\nuncontrollable Sampling(?target)\n[5, 18]\nMEETS {\nPlaced(?location);\n?location = ?target;\n}\n}\nThe communication facility of the rover is modeled by means of the CommType\nstate variable. As the code below shows, the variable is composed by two values\nonly. The Idle value models the fact that the communication facility is available for\ncommunicating data. The SendData value models the fact that the communication\nfacility is actually sending data and cannot be used for other operation until the\ndata transfer is complete. The communication task is modeled as an uncontrollable\nprocess whose actual duration is affected by external factors like the quality of the\ncommunication signal available and the size of the amount of data to be transferred.\nThus, the time the rover takes to send data cannot be decided and therefore the\n64\n\nThe Extensible Planning and Scheduling Library\nrelated value is uncontrollable.\nCOMP_TYPE\nStateVariable CommType (\nIdle(),\nSendData(file))\n{\nVALUE Idle()\n[1, +INF]\nMEETS {\nSendData(?file);\n}\nVALUE\nuncontrollable SendData(?file)\n[11, 32]\nMEETS {\nIdle();\n}\n}\nFinally, the availability of the communication channel during the mission of\nthe rover is modeled by means of the WindowType external state variable. All\nthe values of an external variable are uncontrollable by deﬁnition and therefore the\nuncontrollable tag is not needed. The Available value models the fact that the com-\nmunication channel is supposed to be available and data can be actually transferred\nduring the related (ﬂexible) temporal interval. Conversely, the NotAvailable value\nmodels the fact that the communication channel is supposed to be not available and\nno data can be transferred during the related (ﬂexible) temporal interval.\nAs formally described in Chapter 4, external variables model features of the\nenvironment that are completely outside the control of the system. However, these\nfeatures are relevant from the control and planning perspectives because their be-\nhaviors may directly or indirectly affect the behavior of the system. In this speciﬁc\ncase, the availability of the communication channel affects the scheduling of the\ncommunication tasks of the rover. Clearly, the rover can neither decide or make\nhypothesis on the availability of the signal. Thus, according to Section 4.4, the\nbehaviors of these features must be known and provided with the observations of\nthe problem speciﬁcation.\nCOMP_TYPE\nStateVariable\nexternal WindowType (\nAvailable(),\nNotAvailable())\n{\nVALUE Available()\n[1, +INF]\nMEETS {\n65\n\nThe Extensible Planning and Scheduling Library\nNotAvailable();\n}\nVALUE NotAvailable()\n[1, +INF]\nMEETS {\nAvailable();\n}\n}\nAfter state variable declaration, the component speciﬁcation of a DDL model\naims at declaring the set of state variable instances that constitute the planning do-\nmain. The components of the DDL represent the instantiated data structure the\nplanning system actually deals with in order to ﬁnd plans. In this case, the DDL\nspeciﬁcation is composed by a component for each type of state state variable de-\nﬁned. The RoverController component represents an instance of the RoverType\nstate variable. The Navigation component represents an instance of the Naviga-\ntionType state variable. The Instrument component represents an instance of the\nInstrumentType state variable. The Communication component represents an in-\nstance of the CommType state variable. Finally, the Channel component represents\nan instance of the WindowType external state variable.\nCOMPONENT RoverController : RoverType;\nCOMPONENT Navigation : NavigationType;\nCOMPONENT Instrument : InstrumentType;\nCOMPONENT Communication : CommType;\nCOMPONENT Channel : WindowType;\nThe last part of a DDL planning model concerns the synchronization rule spec-\niﬁcation. While the state variable speciﬁcation constrains the behaviors of the sin-\ngle features of the domain, synchronization rules specify global constraints aiming\nat coordinating domain components in order to realize complex behaviors of the\nsystem. The key point of the timeline-based modeling is that synchronization rules,\ndifferently from actions of classical planning, do not explicitly consider causal re-\nlationships among tokens of the timelines. Such rules \"simply\" specify additional\nconstraints on the behaviors of state variables the planner must take into account\nwhen building the related timelines. The following code shows the synchronization\nrules deﬁned for the ROVER domain. These rules model the operational constraints\nintroduced in Section 4.1 that allow the rover to successfully complete the mission.\nThe rule deﬁned on the value TakeSample of component RoverController mod-\nels the operational requirements the rover must follow to complete a mission goal.\n66\n\nThe Extensible Planning and Scheduling Library\nSpeciﬁcally, the rule requires the rover to be located at the target position when\nperforming sampling operations. Then, when the TakeSample task is completed\nthe rover must send resulting data through the communication facility. According\nto these rules, the following temporal constraints must hold in the generated plans:\nTakeSample(?t, ?f) during[0,∞][0,∞] Navigation.At(?t)\nTakeSample(?t, ?f) contains[0,∞][0,∞] Instrument.Sampling(?t)\nTakeSample(?t, ?f) before[0,∞] Communication.SendData(?f)\nSimilarly, the synchronization rule on the value SendData of the component\nCommunication models the operational requirements the rover must follow to suc-\ncessfully send data to the satellite. Speciﬁcally, the rule requires the rover to be\nstill for the entire duration of the communication which in turn must be performed\nwhen the channel is available. Thus, the planner must generate plans that satisfy\nthe following temporal constraints:\nSendData(?f) during[0,∞][0,∞] Navigation.At(?location)\nSendData(?f) during[0,∞][0,∞] Channel.Available()\nFinally, in addition to operational requirements, sycnhronization rules may also\nmodel safety constraints. Namely, constraints needed to guarantee the safety of\nthe system but not essential for the mission. The synchronization rule on value\nGoingTo of the Navigation component represents an example of such constraints.\nThe rule requires the rover to keep the instrument stowed while moving in order to\navoid collisions and preserve the safety of the device. Thus, every time the rover\nmoves between two locations, following temporal constraint must hold:\nNavigation.GoingTo(?t) during[0,∞][0,∞] Instrument.Stowed()\nSYNCHRONIZE RoverController\n{\nVALUE TakeSample(?target, ?file)\n{\ncd0 Navigation.At(?location);\ncd1 Instrument.Sampling(?target1);\ncd2 Communication.SendData(?file2);\nDURING [0, +INF] [0, +INF] cd0;\nCONTAINS [0, +INF] [0, +INF] cd1;\n67\n\nThe Extensible Planning and Scheduling Library\nBEFORE [0, +INF] cd2;\n?target1 = ?target;\n?file2 = ?file;\n}\n}\nSYNCHRONIZE Communication\n{\nVALUE SendData(?file)\n{\ncd0 Channel.Available();\ncd1 Navigation.At(?location);\nDURING [0, +INF] [0, +INF] cd0;\nDURING [0, +INF] [0, +INF] cd1;\n}\n}\nSYNCHRONIZE Navigation\n{\nVALUE GoingTo(?destination)\n{\ncd0 Instrument.Stowed();\nDURING [0, +INF] [0, +INF] cd0;\n}\n}\n5.1.2\nThe Problem Description Language\nThe Problem Description Language (PDL) is the language EPSL uses for problem\nmodeling. Given a domain speciﬁcation, the PDL provides the syntax constructs\nneeded to specify known facts about the world, the observations concerning the\nexternal variables of the domain (if any) and planning goals.\nThe following block of code represents a part of problem speciﬁcation which\ndeclares the name of the problem instance, the planning domain it relies on and a\nset of known facts. In timeline-based planning, facts represent a partial descrip-\ntion of the timelines of the domain components. Namely, they partially constrain\nthe temporal behaviors of components by specifying a set of values the related\nvariables can assume within known temporal bounds. Thus, the planning system\nbuilds the temporal behaviors of domain components by taking into account also\n68\n\nThe Extensible Planning and Scheduling Library\nthe related known facts of the PDL.\nThese facts represent tokens on domain timelines and characterize the initial\n(partial) plan of the planning process. Namely, such tokens (partially) constrain\nthe temporal behaviors of domain components and the solution plan must be built\naccordingly. For example, the token f0 in the block of code below speciﬁes the\nstarting position (i.e. the home location) of rover mission. Similarly, facts f1 and\nf2 specify respectively that the instrument and the communication facility of the\nrover are stowed and in idle state when the mission starts.\nPROBLEM Rover_1task ( DOMAIN Rover)\n{\nf0\nfact Navigation.At(?startLocation)\nAT [0, 0] [1, +INF] [1, +INF];\nf1\nfact Instrument.Stowed()\nAT [0, 0] [1, +INF] [1, +INF];\nf2\nfact Communication.Idle()\nAT [0, 0] [1,+INF] [1,+INF];\n...\n?startLocation = home;\n}\nIf a planning domain contains external variables the PDL must specify the re-\nlated observations. According to Deﬁnition 13, observations must completely de-\nscribe the temporal behaviors of external variables. Namely, they must specify the\ncomplete sequence of tokens that compose the timelines. The code below shows\nan example of observations for the external variables of the ROVER planning do-\nmain. Speciﬁcally, the observations describe the sequence of (ﬂexible) tokens that\ncompose the timeline of the Channel component which models the availability of\nthe communication signal during the mission.\no1\nfact Channel.NotAvailable()\nAT [0, 0] [25, 30] [25, 30];\no2\nfact Channel.Available()\nAT [25, 30] [80, 85] [55, 60];\no3\nfact Channel.NotAvailable()\nAT [80, 85] [100, 100] [15, 20];\nFinally, the PDL ﬁle contains the goal speciﬁcation that, similarly to facts,\nrepresent a set of constraints concerning the temporal behaviors of domain compo-\nnents. Given such constraints (i.e. facts and goals), the planning system must build\nvalid temporal behaviors (i.e. timelines) in order to complete a mission. Namely,\nthe solving process is triggered by planning goals that represent requirements that\nsolution plans must satisfy. The code below represents an example of a planning\ngoal for the ROVER domain. In this example, the goal g0 requires the rover to\nperform a TakeSample task within some temporal bounds.\n69\n\nThe Extensible Planning and Scheduling Library\ng0\ngoal Rover.TakeSample(?tl, ?f)\nAT [0, 35] [22, 65] [1, 45];\n?tl = location5;\n?f = 1;\n5.2\nArchitectural Overview\nEPSL deﬁnes a ﬂexible software framework to support the design and develop-\nment of timeline-based applications. It is organized according to the Multilayered\narchitectural pattern1 [Buschmann et al., 1996]. The framework addresses the de-\nsign and development of a timeline-based application from different perspectives\nranging from the temporal reasoning mechanism to the deﬁnition of search strate-\ngies and heuristics. Each layer provides a set of ready-to-use algorithms and data\nstructures that can be combined together to develop new planning instances. The\nmodularity of the architecture allows users to easily integrate new features and im-\nprove the reasoning and representation capabilities of the framework. Figure 5.1\nshows the main architectural elements that compose the EPSL framework. In gen-\neral the system is composed of two macro layers, (i) the Representation layer and\n(ii) the Deliberative layer.\nDeliberative\nPlanner\nStrategy\nSolver\nHeuristics\nRepresentation\nPlan Database\nDomain Component\nResolver\nTemporal Database\nParameter Database\nFigure 5.1: The layered architecture of the EPSL framework\n1A multi-layered architecture is a software architecture that uses many layers for allocating the\ndifferent responsibilities of a software product\n70\n\nThe Extensible Planning and Scheduling Library\n5.2.1\nRepresentation Framework\nThe Representation layer is responsible for encapsulating and providing all the in-\nformation and functionalities the solver needs to build timeline-based plans. The\nTemporal DataBase provides temporal reasoning mechanisms for checking the\ntemporal consistency and inferring additional knowledge about the temporal re-\nlations of the plan. Similarly, the Parameter DataBase provides CSP-based rea-\nsoning mechanism for managing variable declaration and constraint propagation.\nOn top of these mechanisms resolvers and components provide a set of ready-\nto-use data structures and algorithms. These elements encapsulate the functional-\nities needed to manage timelines and timeline-based plans. In particular resolvers\nare the basic architectural elements for building timeline-based plans. They en-\ncapsulate the logic for managing plan ﬂaws during the planning process. A ﬂaw\nrepresents a particular issue concerning the plan which must be solved in order to\nﬁnd a solution. There are two types of ﬂaws that must be managed: (i) planning\ngoals represent ﬂaws affecting the completion of the plan; (ii) threats represent\nﬂaws affecting the validity of the plan. Thus, each resolver is a dedicated algo-\nrithm responsible for detecting and solving a speciﬁc type of ﬂaw.\nDomain Components represent data structures modeling the different types of\nfeatures of a planning domain. Speciﬁcally, each component aggregates a set of\nresolvers that determine the resulting behavior in terms of possible ﬂaws that may\nconcern the particular feature of the domain. Namely, the set of resolvers related\nto a component determine the conditions that must be solved in order to build valid\ntemporal behaviors of the related feature (i.e. the timelines). Given this structure,\nthe representation capability of the EPSL framework can be \"easily\" extended by\nintroducing new domain components and new resolvers for building the related\ntemporal behaviors. The higher the number of types of resolvers and components\navailable the more the expressivity of the framework.\nAll the functionalities and information of the Representation layer are made\navailable through the PlanDataBase interface which is a compound element encap-\nsulating the complexity of plan management. Figure 5.2 provides a more detailed\nrepresentation of the elements that compose the plan database and their relation-\nships.\nDomainComponents model the different types of feature the planning system\ncan reason about. The PlanDataBaseComponent is a particular type of component\nwhich encapsulates other components of the domain (see the Composite design\npattern [Gamma et al., 1995]) and provides access to the information of the plan\n71\n\nThe Extensible Planning and Scheduling Library\nFigure 5.2: The structure of the plan database in the EPSL framework architecture\nthrough the PlanDataBase interface. The PlanDataBaseComponent uses the Plan-\nReﬁnement resolver which is responsible for managing planning goals during the\nsolving process. Speciﬁcally, the resolver provides functionalities for managing the\nexpansion and/or uniﬁcation of goals during plan reﬁnement. Goal expansion re-\nﬁnes the plan by creating and adding new tokens to timelines and applies the related\nsynchronization rules that decompose the goal into a subset of sub-goals. Goal uni-\nﬁcation reﬁnes the plan by \"merging\" goals with already existing and compatible\ntokens on the timelines. Thus, uniﬁcation does not require goal decomposition and\nthe consequent generation of sub-goals.\nStateVariables represent the basic data structures modeling the features of a\nplanning domain. EPSL complies with the formalization described in Chapter\n4. Therefore, state variables encapsulate information concerning the values the re-\nlated feature may assume over time, the allowed transitions, their ﬂexible durations\nand controllability properties. There are three types of state variables available: (i)\nExternalStateVariable; (ii) FunctionalStateVariable; (iii) PrimitiveStateVariable.\nExternalStateVariables model features of the domain that are completely uncon-\ntrollable. They use the ObservationChecker resolver which is responsible for ver-\nifying the observations provided as input through the problem speciﬁcation. The\nresolver veriﬁes that the observations represent a complete and valid temporal be-\nhavior satisfying the domain constraints of the related external variable (i.e. the\nvalue transition function).\nFunctionalStateVariables and PrimitiveStateVariables are both planned vari-\nables. The former type of state variable models complex tasks/activities of the\n72\n\nThe Extensible Planning and Scheduling Library\nproblem that must be further decomposed through synchronization rules. The lat-\nter type of state variable models tasks/activities that can be directly executed by the\nsystem. These two types of state variable use StateVariableGapSolver and State-\nVariableScheduling resolvers to build timelines. StateVariableScheduling resolvers\nare responsible for handling scheduling threats of the plan in order to avoid tem-\nporally overlapping tokens on the timelines. StateVariableGapSolver resolvers are\nresponsible for handling gap threats of the plan in order to avoid \"empty\" tempo-\nral intervals on the timelines. Finally, the BehaviorChecker resolver is responsible\nfor checking the resulting temporal behaviors with respect to the value transition\nfunction of the related state variable speciﬁcation.\n5.2.2\nProblem Solving\nThe Deliberative layer in Figure 5.1 deals with problem resolution. It relies on\nthe representation functionalities of the Representation layer and encapsulates the\nlogic for solving timeline-based problems. In particular, it provides a set of ready-\nto-use search strategies, heuristics and solving algorithms that can be composed in\norder to deﬁne new planning instances. Indeed, the key point of EPSL ﬂexibility is\nthe interpretation of a planner as a “modular” solver which carries out the reasoning\nprocess by combining several elements.\nThe Solver encapsulates the particular structure of the reasoning process. Broadly\nspeaking, the reasoning process is a general plan reﬁnement algorithm which is\nsupported by a Strategy and Heuristics encapsulating some criteria to guide the\nsearch. The former provides criteria for managing the fringe of the search space\nand selecting the \"best\" (partial)plan to expand next. The latter encapsulates cri-\nteria for managing the ﬂaws of the plan and selecting the most promising ﬂaws to\nsolve. Figure 5.3 shows the main architectural elements that compose an EPSL-\nbased planner and their relationships.\nSimilarly to classical planning, the planning process can be summarized as the\nsearch of a solution plan with some desired features on a space of possible plans.\nThe search tree is composed by a set of search nodes that encapsulates a particular\nplan representing a possible status of the system in terms of temporal behaviors.\nThe fringe of the search tree consists of the subset of nodes not visited yet. The\nSearchStrategy is responsible for managing the fringe of the search space by encap-\nsulating some particular criteria for assessing the nodes composing the fringe. The\nplanning process ﬁnds the \"best\" solution according to the particular search strat-\negy used. The EPSL framework provides the user with two search strategies. The\n73\n\nThe Extensible Planning and Scheduling Library\nFigure 5.3: The structure of a planner in the EPSL framework architecture\nDepthFirst strategy (DFS) realizes a blind search where the planning process is\nsimply guided towards the last-generated nodes of the search (i.e. the deepest ones\nin the search space). The MakespanOptimization strategy analyzes the temporal\ninformation of different pans in order to ﬁnd the solution plan with the minimum\nmakespan. Namely, this strategy tries to generates the most temporal efﬁcient plan\npossible.\nThe FlawSelectionHeuristic encapsulates the logic for managing and assessing\nﬂaws of a plan detected during the reﬁnement process. Speciﬁcally, a FlawSelec-\ntionHeuristic relies on a set of FlawFilters that select the \"most relevant\" ﬂaws the\nplanning process must consider for plan reﬁnement. Each FlawFilter encapsulates\na particular criterion for assessing ﬂaws of a plan. The TypeFilter and the Fail-\nFirstFilter represent two straightforward selection criteria that take into account\ninformation concerning the particular ﬂaws detected. The former ﬁlters ﬂaws ac-\ncording to their type. The ﬁlter structures the planning process by requiring to\naddress all planning goals ﬁrst, than, scheduling threats and lastly, gap threats.\nThe latter encapsulates the fail-ﬁrst principle of constraint programming according\nto which the ﬂaws with the minimum number of available solutions are selected\nﬁrst (i.e. the hardest ﬂaws to solve). HierarchyFilter and SemanticFilter represents\nmore complex selection criteria that will be explained in more detail in the next sec-\ntion. Broadly speaking, these two types of ﬁlters want to provide selection criteria\nthat make decisions according to relationships and features that can be extracted\nby analzying the domain speciﬁcation.\n74\n\nThe Extensible Planning and Scheduling Library\n5.2.3\nThe General Solving Procedure\nThe Solver element of Figure 5.3 manages the structure of the planning process by\n\"coordinating\" the particular strategy and the particular heuristics used to search\nsolutions. In general, EPSL-based planners follow a general plan reﬁnement search\nprocedures where an initial plan is iteratively reﬁned by solving ﬂaws until a solu-\ntion plan is found. There are two available implementations the EPSL framework\nprovides. The BestFirst solver represents a simple implementation of the plan-\nning process, which returns the \"best\" solution found according to the particular\nsearch strategy adopted. The PseudoControllabilityAware extends the behavior\nof the \"best-ﬁrst\" solver by adding the assessment of the pseudo-controllability\nproperty of the plan during the planning process. Speciﬁcally, the PseudoControl-\nlabilityAware solver returns a pseudo-controllable plan if possible, or the \"best\"\nnon-pseudo-controllable plan (if pseudo-controllability cannot be satisﬁed). Be-\nfore entering into the details of the motivations for pseudo-controllable plans and\nits implications with respect to the planning process, this section provides a de-\ntailed description of the best-ﬁrst solving procedure of an EPSL-based planner.\nAlgorithm 1 describes the abstract solving procedure of an EPSL-based plan-\nner. Basically, the reasoning process performs a plan reﬁnement procedure which\niteratively reﬁnes the current plan π by detecting and solving ﬂaws. EPSL instan-\ntiates the planner solving process over the tuple ⟨P, S, H⟩where P is the speciﬁ-\ncation of a timeline-based problem to solve, S is the search strategy the planner\nuses to expand the search space, and H is the heuristic function the planner uses to\nselect the most promising ﬂaw to be solved.\nThe plan database π is initialized on the problem description P (row 2) and\nthe procedure iteratively reﬁnes the plan until a solution or a failure is detected\n(rows 6-32). At each iteration (rows 8-25) the procedure analyzes the current plan\ndatabase π by detecting ﬂaws that must be solved φ0(π) (row 9). Then the set of\ndetected ﬂaws Φ0 is ﬁltered by applying the selected heuristic function H and the\nsubset of equivalent ﬂaws is extracted Φ∗⊆φ0 (row 11). Each ﬂaw φ∗\ni ∈Φ∗may\nhave one or more solution Nφ∗\ni = {n1, ..., nt} (row 15). If no solution is found\nfor a particular ﬂaw |Nφ∗\ni | = 0 then the ﬂaw is unsolvable and backtrack is needed\n(rows 17-19). Otherwise each available solution represents a branch of the search\nand is added to the fringe (rows 21-24). The iteration ends by selecting a node\nfrom the fringe and reﬁning the plan π accordingly (row 31). The search goes on\nuntil a plan with no ﬂaws is found, i.e. a solution plan (row 7).\n75\n\nThe Extensible Planning and Scheduling Library\nAlgorithm 1 The EPSL general solving procedure\n1: function SOLVE(P, S, H)\n2:\n// initialize the plan database\n3:\nπ ←InitialPlan (P)\n4:\n// initialize the fringe\n5:\nF ←∅\n6:\n// check if the current plan is complete and ﬂaw-free\n7:\nwhile ¬IsSolution (π) do\n8:\n// detect the ﬂaws of the current plan\n9:\nΦ0 = {φ1, ..., φk} ←DetectFlaws (π)\n10:\n// apply the heuristic to ﬁlter detected ﬂaws\n11:\nΦ∗= {φ∗\n1, ..., φ∗\nm} ←SelectFlaws\n\u0000Φ0, H\n\u0001\n12:\n// compute possible plan reﬁnements\n13:\nfor φ∗\ni ∈Φ∗do\n14:\n// compute ﬂaw’s solutions\n15:\nNφ∗\ni = {n1, ..., nt} ←HandleFlaw (φ∗\ni , π)\n16:\n// check if the current ﬂaw can be solved\n17:\nif Nφ∗\ni = ∅then\n18:\n// unsolvable ﬂaw found\n19:\nBacktrack(π, Dequeue(F))\n20:\nend if\n21:\nfor nj ∈Nφ∗\ni do\n22:\n// expand the search space with possible plan reﬁnements\n23:\nfringe ←Enqueue (nj, S)\n24:\nend for\n25:\nend for\n26:\n// check the fringe of the search space\n27:\nif IsEmpty (F¬pc) then\n28:\n// search failure return Failure\n29:\nend if\n30:\n// reﬁne the plan\n31:\nπ ←Refine(π, Dequeue(F))\n32:\nend while\n33:\n// get solution plan\n34:\nreturn π\n35: end function\n76\n\nThe Extensible Planning and Scheduling Library\nFlaw Filtering\nIn general, ﬂaw selection is not a backtracking point of the search but it can strongly\naffect the performance of the planning process. From the search point of view, each\nsolution of a ﬂaw determines a branch of the search tree. Thus a \"good\" selection of\nthe next ﬂaw to solve can prune the search space by cutting off branches that would\nlead to unnecessary or redundant reﬁnements of the plan. Considering a particular\nbranch of the search tree, a FlawSelectionHeueristic determines an \"ordering\" in\nﬂaw resolution the planner must follow in order to reduce the branching factor and\navoid an exhaustive expansion of the search tree. The EPSL framework provides\nFlawSelectionHeuristics in shape of a pipeline of FlawFilters which is structured\nas follows:\nφ0...\nfi(π,φi−1)\n−−−−−−→φi fi+1(π,φi)\n−−−−−−→φi+1...\nfk(π,φk−1)\n−−−−−−−→φ∗⊆φ0\nThe pipeline represents a quite ﬂexible structure which can be easily adapted or\nextended by taking into account different types of ﬁlters and also different combi-\nnations of the same set of ﬁlters. Each speciﬁc conﬁguration of the pipeline results\nin a different behavior of the solving process. Given a partial plan π with an initial\nset of ﬂaws φ0, a sequence of ﬁlters fi, with i = 1, ..., k, is applied in order to\nextract the subset of relevant ﬂaws to consider for plan reﬁnement, φ∗⊆φ0.\nThe ﬂaws composing the last set represent equivalent choices from the heuristic\npoint of view, therefore they are all taken into account for plan reﬁnement. The\namount of information a particular heuristics function provides to the search can\nbe estimated by checking the number of ﬂaws actually ﬁltered with respect to the\ninitial set. If the set of ﬂaws obtained by the application of a heuristic function\nh(π) is equal to the initial set, i.e. φ∗= φ0, then it is possible to argue that the\nheuristic function h(π) is not informed. Indeed, in such a case the heuristics does\nnot provide any useful information to problem resolution, therefore the resulting\nbehavior of the solving process is a blind search.\n5.3\nLooking for Pseudo-controllable Plans\nAs discussed previously, EPSL relies on the formal characterization of the tem-\nporal uncertainty and controllability problem with respect to timelines given in\n[Cialdea Mayer et al., 2016]. Therefore the framework can represent and reason\nabout the temporal uncertainty of the planning domain by taking into account the\nuncontrollable values and external features in order to generate plans with some\n77\n\nThe Extensible Planning and Scheduling Library\ndesired properties concerning their execution. In general, the execution of a plan is\na complex and hard task which requires the system to actually interact with the en-\nvironment. There are many factors that may affect the executive process and even\nprevent the complete execution of the plan. The system must be able to handle the\nobservations concerning the uncontrollable dynamics of the environment in order\nto dynamically adapt the plan as needed and complete the execution.\nObservations allow the system to check whether the execution is diverging\nfrom the expected plan or not. If the execution is diverging, then the system must\nmanage the plan and react to exogenous events accordingly. In the best case ob-\nservations comply with the expected plan and no change is needed. Sometimes\ninstead, it may happen that the system must dynamically adapt the ongoing plan\nto the observations in order to proceed with the execution (e.g. a delay of the ex-\necution of an uncontrollable activity which propagates to the not executed portion\nof the plan). In the worst case, the observations and the plan are incompatible and\nreplanning is required. It means that the execution is stopped in order to produce\na new plan starting from the current situation. Once the deliberative process has\ngenerated the plan, the execution can start over again.\nIn this regard, a robust executive system must cope with the uncertainty of the\nenvironment and complete the process by adapting the plan to any expected ex-\nogenous event and perform replanning only if needed. There are many works in\nthe literature that take into account temporal uncertainty and study the controlla-\nbility property of a plan [Vidal and Fargier, 1999, Morris et al., 2001, Cesta et al.,\n2010, Cialdea Mayer and Orlandini, 2015, Nilsson et al., 2016]. Speciﬁcally three\ntypes of controllability properties have been deﬁned: (i) weak controllability; (ii)\nstrong controllability; (iii) dynamic controllability.\nDynamic controllability is the most relevant property with respect to planning\nand execution in the real world. Broadly speaking, dynamic controllability con-\ncerns with the capability of an executive system to ﬁnd a valid execution strategy\nwhich takes feasible dispatching decisions (i.e. it schedules the start of plan’s ac-\ntivities) by reasoning only on the past history and the received observations. It\nis not easy to deal with these properties during the planning process. They are\nusually checked with a post-processing step after the planning phase and before\nstarting the execution of the plan. With respect to planning, an interesting property\nworth to be considered, is the pseudo-controllability property. Indeed, the pseudo-\ncontrollability property of a plan represents a necessary but not sufﬁcient condition\nfor its dynamic controllability [Morris et al., 2001].\n78\n\nThe Extensible Planning and Scheduling Library\nThe pseudo-controllability property of a plan aims at verifying that the plan-\nning process does not make hypotheses on the actual duration of the related uncon-\ntrollable activities. Speciﬁcally, pseudo-controllability veriﬁes that the planning\nprocess does not reduce the duration of uncontrollable values of the domain dur-\ning plan generation. Thus, a timeline-based plan is pseudo-controllable if all the\nﬂexible durations of uncontrollable tokens composing the timelines have not been\nchanged with respect to the domain speciﬁcation. Although, pseudo-controllability\ndoes not convey enough information to assert the dynamic controllability of a plan,\nit represents a useful property that can be exploited for validating the planning do-\nmain with respect to temporal uncertainty. Indeed, if the planner cannot generate\npseudo-controllable plans, then the planner cannot generate dynamically control-\nlable plans.\nThe PseudoControllabilityAware solver of the EPSL framework (see Figure\n5.3) is responsible for generating pseudo-controllable plans (if possible). In this\nway, EPSL realizes an planning framework capable of taking into account (part)\nof the controllability problem by generating pseudo-controllable plans that can be\nfurther investigated. Such an integration between planning and execution, envis-\nages a uniﬁed framework which allows plan-based controllers to rely on a common\nrepresentation of the problem. The deliberative and executive capabilities share the\nsame formal representation of the plan enabling a more ﬂexible and effective man-\nagement of the control process. This objective represents an ongoing development\nfor the EPSL framework which has been partially addressed already as Chapters 6\nshows.\nAlgorithm 2 describes the \"extended\" solving procedure implemented by Pseu-\ndoControllabilityAware solver. Similarly to Algorithm 1, the solving procedure is\nan iterative partial plan reﬁnement which searches pseudo-controllable plans. If no\npseudo-controllable plans can be found, the procedure tries to ﬁnd a non pseudo-\ncontrollable plan before ending. Thus the procedure returns a failure if neither\na pseudo-controllable plan nor a non pseudo-controllable plan have been found.\nSimilarly to Algorithm 1, the procedure is instantiated on the tuple ⟨P, S, H⟩whose\nelements represent the problem description, the search strategy and the ﬂaw selec-\ntion heuristic respetively.\nThe plan database π is initialized on the problem description P (row 3). The\nprocedure manages two distinct fringes during the search (initialized at row 5\nand row 6). The pseudo-controllable fringe Fpc is the fringe used when search-\ning for pseudo-controllable plans. The non pseudo-controllable fringe F¬pc is the\n79\n\nThe Extensible Planning and Scheduling Library\nAlgorithm 2 The EPSL pseudo-controllability aware solving procedure\n1: function SOLVE_PC(P, S, H)\n2:\n// initialize the plan database\n3:\nπ ←InitialPlan (P)\n4:\n// initialize \"regular\" and \"non pseudo-controllable\" fringe\n5:\nFpc ←∅\n6:\nF¬pc ←∅\n7:\n// check if the current plan is complete and ﬂaw-free\n8:\nwhile ¬IsSolution (π) do\n9:\n// get uncontrollable values of the plan\n10:\nU = {u1, ..., un} ←GetUncertainty (π)\n11:\n// check durations of uncontrollable values\n12:\nif ¬Squeezed(U) then\n13:\n// detect the ﬂaws of the current plan\n14:\nΦ0 = {φ1, ..., φk} ←DetectFlaws (π)\n15:\n// apply the heuristic to ﬁlter detected ﬂaws\n16:\nΦ∗= {φ∗\n1, ..., φ∗\nm} ←SelectFlaws\n\u0000Φ0, H\n\u0001\n17:\n// compute possible plan reﬁnements\n18:\nfor φ∗\ni ∈Φ∗do\n19:\n// compute ﬂaw’s solutions\n20:\nNφ∗\ni = {n1, ..., nt} ←HandleFlaw (φ∗\ni , π)\n21:\n// check if the current ﬂaw can be solved\n22:\nif Nφ∗\ni = ∅then\n23:\nBacktrack(π, Dequeue(Fpc))\n24:\nend if\n25:\nfor nj ∈Nφ∗\ni do\n26:\n// expand the search space\n27:\nFpc ←Enqueue (nj, S)\n28:\nend for\n29:\nend for\n30:\nelse\n31:\n// non pseudo-controllable plan\n32:\nF¬pc ←Enqueue (makeNode (π) , S)\n33:\nend if\n34:\n// check the fringe of the search space\n35:\nif IsEmpty (Fpc) ∧¬IsEmpty (F¬pc) then\n36:\n// try to ﬁnd a non pseudo-controllable solution\n37:\nπ ←Refine (π, Dequeue (F¬pc))\n38:\nelse if ¬IsEmpty (Fpc) then\n39:\n// go on looking for a pseudo-controllable plan\n40:\nπ ←Refine (π, Dequeue (Fpc))\n41:\nelse\n42:\nreturn Failure\n43:\nend if\n44:\nend while\n45:\n// get solution plan\n46:\nreturn π\n47: end function\n80\n\nThe Extensible Planning and Scheduling Library\nfringe used when no pseudo-controllable plans have been found by the search.\nThe solving procedure iteratively reﬁnes the plan until a solution is found (rows\n8-47). At each iteration, the solving process checks the current plan for pseudo-\ncontrollability by analyzing the temporal uncertainty features of the domain (rows\n10-12), i.e. uncontrollable and external values. If the ﬂexible duration of uncon-\ntrollable values has not been changed (row 12) then the procedure starts reﬁning\nthe current plan as in the regular procedure described previously in Algorithm 1.\nIf the pseudo-controllability condition does not hold (row 32) then the current plan\nis placed into the non pseudo-controllable fringe F¬pc, the procedure skips the re-\nﬁnement of the plan and the search goes on by extracting the next plan from the\nfringe (rows 38-40). However, if the fringe is empty then no pseudo-controllable\nplans can be found. Consequently, the search goes on by extracting nodes from the\nnon pseudo-controllable fringe F¬pc (rows 35-37). In such a case, it means that if a\nsolution exists, then the plan is not pseudo-controllable and therefore the plan can-\nnot be dynamically controllable. If both the fringes are empty then the procedure\nreturns a failure (row 42), otherwise the search will end with a solution plan which\ncan be either pseudo-controllable or not.\n5.4\nHierarchical Planning with Timelines\nIn general, the design of effective models capable of capturing all the relevant fea-\ntures of a particular system is an issue in plan-based controller development. In-\ndeed, a model must capture all (and only) the information about the system and the\nworking environment that are really relevant with respect to the objectives of a par-\nticular application. Given a particular planning technique, it is not easy to ﬁnd the\nappropriate abstraction level and structure the model accordingly. Typically, struc-\ntured models support the solving process by encoding domain-speciﬁc knowledge\nabout the problem. In this regard, hierarchical approaches like HTN have been\nsuccessfully applied especially in real-world scenarios. This section introduces a\nhierarchy-based methodology for the design of timeline-based applications which\ntakes inspiration from HTN approaches. In addition, a domain independent heuris-\ntics capable of leveraging the resulting structure of planning domains is presented.\n5.4.1\nHierarchical Modeling Approach\nIn plan-based control systems the focus is usually on controlling an autonomous\nagent in order to perform complex tasks in a speciﬁc working environment (e.g. an\n81\n\nThe Extensible Planning and Scheduling Library\nindustrial robot in a manufacturing work-cell). An effective timeline-based model\nmust capture all the features and the related operational constraints that are rele-\nvant with respect to the control problem. The timeline-based model must describe\nthe available capabilities that allow the system to actually interact with the en-\nvironment and perform operations (e.g. actuators, sensors, tools), the features of\nthe environment that may affect the behavior of the system, as well as the result-\ning high-level tasks (i.e. complex activities) the system can perform. Thus, it is\npossible to organize the information a timeline-based model must capture in three\ndifferent levels of abstraction:\n• The functional level concerns the high level tasks the agent can perform. It\ncharacterizes the high-level goals the timeline-based system can plan for.\n• The primitive level concerns the internal elements that compose the agent. It\ncharacterizes the capabilities of the system in terms of the low-level tasks, or\ncommands the agent’s components can directly execute. Namely, the primi-\ntive level deals with the representation of devices and facilities the system is\nendowed with (e.g. actuators or sensors) that can be actually used to solve a\nproblem.\n• The external level concerns the environment the agent must care about. It is\northogonal with respect to other levels and characterizes the dynamics of the\nenvironment the agent must interact with. Namely external level concerns\nthe element of the domain that are outside the control of the agent but whose\nbehavior may affect the outcomes of the activities needed to solve a problem.\nAccording to this organization, Figure 5.4 shows the general structure of a\ntimeline-based domain. The functional and primitive levels are directly related\neach other. The external level instead is orthogonal to the others as it may have\nimplications at both levels. Within this structure, the model must specify a hier-\narchical decomposition of high-level tasks in terms of relations between low-level\ntasks. Such relationships may require several decomposition levels according to\nthe complexity of the considered domain. In any case, the hierarchical decomposi-\ntion starts with a high-level task representing a planning goal, and ends with a set\nof primitive tasks that can be directly executed by the system. The arrows in Figure\n5.4 represent such a decomposition. Some arrows (the red dotted ones) specify re-\nlations between functional (or even primitive) values and external values. In these\ncases, the arrows represent condition checking rather then decomposition. Namely\n82\n\nThe Extensible Planning and Scheduling Library\nFunctional\nPrimitive\nExternal\nGoals/High-level tasks\nObservations\nPlan/Commands\nFigure 5.4: Hierarchical modeling of timeline-based domains\nthey represent conditions that must hold in the plan with respect to some features\nof the environment, rather then activities to perform. Following the three abstrac-\ntion levels, the envisaged hierarchical modeling approach identiﬁes three types of\nstate variables composing a timeline-based domain. They are the (i) the functional\nvariables, (ii) the primitive variables and (iii) the external variables.\nFunctional variables provide a logical representation of the agent in terms of\nthe high-level task the agent can perform, notwithstanding its internal composition.\nThe values of this type of variables are controllable and represents the high-level\nplanning goals the related timeline-based system can plan for. With regards to the\nROVER domain, the Rover planned state variable is a functional variable which\nmodels the high-level tasks the rover can perform. Speciﬁcally, it models the rover\nin terms of the TakeSample activities that represent the planning goals of the prob-\nlem.\nPrimitive variables model a speciﬁc physical/logical component of the system.\nThe values of this type of variables represent state/actions the related component\nof the system is actually able to assume/perform over time. These values may have\nbounded ﬂexible durations and may be either controllable or not. If such a value is\ntagged as uncontrollable, it means that the system cannot decide the actual duration\nof the related activity during execution (speciﬁcally the system can decide when to\nstart the activity but not when the activity ends). These are the values the planning\n83\n\nThe Extensible Planning and Scheduling Library\nprocess looks for in order to check if the pseudo-controllability property of the plan\nis satisﬁed. For example, the SendData value of Communication variable is tagged\nas uncontrollable because the actual duration of the communication activities is\naffected by factors that are not under the control of the rover (e.g. the size of the\ndata ﬁle, or the quality of the communication channel).\nExternal variables model the features of the environment that are completely\nuncontrollable and whose behaviors may affect the operations of the system. Namely\nsuch variables model conditions that must hold in order to successfully carry out\nthe tasks of the system. These variables can only be observed and the related\ntimelines are included into the description of the problem. Therefore, the plan-\nning system must adapt the plan to the particular observations received (again,\nwithout making any hypothesis on their actual durations in order to comply with\npseudo-controllability property). With regards to the ROVER planning domain, the\ngenerated plan must comply with the observations concerning the communication\nchannel such that the SendData activity is performed when the channel is supposed\nto be available.\nTask decomposition is realized by means of synchronization rules that, like\nmethods in HTN, connect adjacent abstraction levels of the domain by specifying\nrelationships between different tasks. Namely, synchronization rules describe a\ntop-bottom task decomposition specifying how the high-level tasks (i.e. functional\nvalues) are implemented by the internal components of the system (i.e. the prim-\nitive values) and how their execution is related to the environment (i.e. external\nvalues).\n5.4.2\nBuilding the Dependency Graph\nIt is possible to observe that a synchronization rule basically represents a depen-\ndency between two or more variables of the domain. It means that variables affect\nthe temporal behavior of other variables through synchronization rules and the re-\nlated temporal constraints between tokens. Let us consider a synchronization rule\nSvA,i which applies to value i of a state variable A (vA,i) and contains a temporal\nconstraint between vA,i and a value j of a state variable B (vB,j). Such a temporal\nconstraint affects the behavior of state variable B and consequently the building\nprocess of the related timeline (i.e. the timeline of state variable B). Thus, the\nsynchronization rule SvA,i determines a dependency between state variable A and\nstate variable B. Namely, the tokens that compose timeline A and their temporal\nallocation affect the token that compose timeline B and their temporal allocation.\n84\n\nThe Extensible Planning and Scheduling Library\nAccording to this observation, it is possible to analyze the synchronization rules\nof a domain speciﬁcation in order to build a Dependency Graph (DG) encoding\nthe relationships between domain components. Speciﬁcally, a DG is a directed\ngraph which provides a relaxed representation of the dependencies between the\ncomponents of a planning domain.\nDeﬁnition 17 A dependency graph DG is a directed acyclic graph deﬁned by the\npair ⟨V, Rd⟩where: (i) V is the set of nodes of the graph representing the compo-\nnents of the planning domain; (ii) Rd is the set of (directed) edges between nodes\nrepresenting dependency relationships between domain components\nAlgorithm 3 The Dependency Graph building procedure\n1: function BUILD_DEPENDENCY_GRAPH(Π)\n2:\n// Initialize the DG with the state variables of the domain\n3:\nGdg ←Create (GetStateV ariables (Π))\n4:\n// get synchronization rules\n5:\nS = {..., SvM,n, ...} ←GetSynchronizationRules (Π)\n6:\nfor SvA,i ∈S do\n7:\n// check synchronization’s constraints\n8:\nfor rk ∈GetConstraints\n\u0000SvA,i\n\u0001\ndo\n9:\n// check if reﬂexive relation\n10:\nif ¬IsReflexive (rk) then\n11:\n// get reference domain component\n12:\nCs ←Reference (rk)\n13:\n// get target domain component\n14:\nCt ←Target (rk)\n15:\n// add dependency to the graph\n16:\nGdg ←AddDependency (Cs, Ct)\n17:\n// look for cycles in the graph\n18:\nif HasCycle (Gdg) then\n19:\n// remove last added dependency\n20:\nGdg ←RemoveDependency (Cs, Ct)\n21:\nend if\n22:\nend if\n23:\nend for\n24:\nend for\n25:\n// return the computed DG\n26:\nreturn Gdg\n27: end function\nAlgorithm 3 describes the building procedure of the DG. The procedure takes\nas input the planning domain and initializes the dependency graph Gdg on the set\nof state variables of the domain (row 3). The dependencies between components\nare generated by analyzing the synchronization rules of the domain (rows 6-24).\n85\n\nThe Extensible Planning and Scheduling Library\nFor each synchronization rule SvA,i, where variable vA,i represents the triggerer of\nthe synchronization (A the component the value belongs to, i the id of the value),\nthe related temporal constraints are taken into account to compute dependencies\n(rows 8-21). For each temporal constraint rk the algorithm checks if the relation\nis reﬂexive (row 10). If a temporal constraint involves two values belonging to the\nsame component (i.e. it represents a reﬂexive dependency relation) then the con-\nstraint is ignored. Otherwise a new dependency is added to the graph concerning\nthe reference and the target components of the relations (rows 11-16). Every time\na new edge is added, the graph is checked for cycles (row 18). If a cycle is de-\ntected, it is caused by the last added dependency which is discarded and removed\nfrom the graph (row 20). The procedure continues until all synchronization’s tem-\nporal constraints have been analyzed and the resulting dependency graph Gdg is\nreturned.\nThe DG the procedure generates, is acyclic for construction. Indeed, the pro-\ncedure discards edges (i.e. temporal relations) that introduce cyclic dependencies\ninto the graph. Thus, the DG relaxes the dependency relationships of the domain\nby considering only an acyclic subset of them. A DG is said to be complete if all\nthe dependencies of the domain are modeled. Often, given the hierarchical model-\ning approach described in the previous section, the dependencies of the domain are\nacyclic. The resulting DG is complete and encodes the hierarchy of the planning\ndomain which can be easily extracted by analyzing the graph (e.g. by means of a\ntopological sort algorithm if the DG does not contain cycles).\nC4\nv41\nv42\nv43\nC1\nv11\nv12\nv13\nC2\nv21\nv22\nv23\nC3\nv31\nv32\nv33\nbefore\ncontains\nduring\ncontains\nduring\nequals\nmeets\nduring\nDEPENDENCY GRAPH\nHIERARCHY\n{C1} < {C2, C4} < {C3}\nC1\nC2\nC4\nC3\nFigure 5.5: Extracting domain hierarchy from synchronizations’ constraints\nFigure 5.5 shows a general example concerning the hierarchy extraction pro-\ncess from domain synchronizations. Each synchronization rule speciﬁes temporal\nconstraints that may involve values of different state variables. Temporal con-\n86\n\nThe Extensible Planning and Scheduling Library\nstraints of different synchronizations can be distinguished according to their color\nin Figure 5.5 (i.e. temporal constraints with the same color belong to the same\nsynchronization rule). Each temporal constraint between values of different com-\nponents vA,i ∈CA and vB,j ∈CB determines a dependency relation between\nCA (the source of the relation) and CB (the target of the relation). Thus such a\nconstraint is encoded by an edge rA,B ∈Rd of the DG, where A, B ∈V .\nGiven the DG, it is possible to extract the hierarchy of the domain as shown in\nFigure 5.5. Indeed, an edge connecting a node A to a node B in the DG, implies\nthat component B depends on component A. Thus the component A is higher\nthan component B with respect to the hierarchy. Otherwise, If there is not a direct\npath connecting a node A to a node B in the DG, then no implications can be\nmade concerning their relationship. In such a case, the related domain components\nare supposed to be at the same level of the hierarchy. Such a hierarchy can guide\nthe solving procedure to search for solutions. In this regard, the HierarchyFilter\nelement of Figure 5.3 encapsulates a ﬂaw selection criterion which selects ﬂaws\naccording to the hierarchical level of the component they belong to. The rationale\nof the selection criteria is that, given a set of ﬂaws to solve, the \"best\" choice is to\nstart solving ﬂaws that belong to the most independent component of the domain.\nSolving dominant ﬂaws of the plan may implicitly solve other secondary ﬂaws of\nthe plan or even prune the search space by removing redundant or unfeasible ﬂaw\nsolutions.\n87\n\nChapter 6\nPlanning and Execution with\nTimelines under Uncertainty\nP\nLAN GENERATION is only a part of the problem when controlling a complex\nsystem with plan-based technologies in AI. The execution of a plan is a com-\nplex process which can fail even if the plan is valid with respect to the domain spec-\niﬁcation. During execution, the system must interact with the environment, which\nis uncontrollable and therefore the execution of the activities can be affected by\nexternal factors. A robust executive system must cope with such exogenous events\nand dynamically adapt the plan accordingly during execution. In order to deploy\ntimeline-based applications in real-world scenarios, the EPSL planning framework\nhas been extended by introducing executive capabilities. The executive relies on\nthe same semantics of timelines the planning process relies on. Thus, the executive\nleverages information about the temporal uncertainty of the problem in order to\nproperly manage the execution of the plan. In this way, EPSL realizes a uniform\nsoftware framework for planning and execution with timelines under uncertainty.\nThis chapter provides a detailed description of the extended EPSL framework and\nthe related approach to execution. Moreover, the chapter introduces a real-world\nmanufacturing scenario for Human-Robot Collaboration (HRC) where EPSL and\nthe related planning and execution capabilities have been successfully applied.\n6.1\nModel-based Control Architectures\nThe classical approach for building model-based controllers relies on the three-\nlayered architecture described in [Gat, 1997]. These three layers are (starting from\n88\n\nPlanning and Execution with Timelines under Uncertainty\nthe bottom) the functional layer, the executive layer and the planning/scheduling\nlayer. Traditional autonomous control architecture follow this structure and the\nmost relevant works concern: IPEM [Ambros-Ingerson and Steel, 1988], CPEF\n[Myers, 1999], the LAAS architecture [Alami et al., 1998] which relies on the\nIXTET-EXEC [Lemai and Ingrand, 2004], the Remote Agent Experiment [Jon-\nsson et al., 2000b] and ASE [Chien et al., 1999]. Each layer usually requires\ndifferent reasoning and representation technologies. The integration of such differ-\nent technologies is usually an issue for developing this type of controllers. Often,\nthe planning cycle is monolithic making scalability and fast reaction time another\nissue of this type of controllers.\nOther approaches like CLARATY [Nesnas et al., 2008], try to overcome some\nof these drawbacks using an architecture with only two layers. A functional layer\nand a decision layer. The decision layer integrates planning and execution through\na shared data structure (i.e. the plan database) synchronizing planning and execu-\ntion data that rely on two different representations, i.e. CASPER [Knight et al.,\n2001] for planning and TDL [Simmons and Apfelbaum, 1998] for execution.\nCIRCA [Goldman et al., 2002] proposes an intelligent controller in hard real-time\nwhich leverages reactive planning to implement automatic controller synthesis.\nIDEA [Muscettola et al., 2002, Aschwanden et al., 2006] was the ﬁrst agent\ncontrol architecture utilizing a collection of controllers, each interleaving planning\nand execution in a common framework. The main drawbacks of IDEA are the\nlack of a clear conﬂict-resolving policy between controllers and the lack of an\nefﬁcient planning algorithm for integrating the current states of controllers. The\nTeleo-Reactive Executive (T-REX) [Py et al., 2010] was designed to overcome\nthese restrictions using a collection of controllers (called reactors) implemented\nas different instances of EUROPA planner [Barreiro et al., 2012]. The novelty of\nT-REX was the capability of realizing a systematic infrastructure which deﬁnes the\ninteractions among reactors.\n6.2\nExtending the EPSL framework with Execution\nThe executive system is responsible for managing the execution of timeline-based\nplans by iteratively sending commands to the system and receiving observations\nconcerning the actual state of the environment. Thus, the executive must verify\nwhether the perceived behavior of the world (i.e. the system and the environment)\ncomplies with the expected plan and must react accordingly in case of conﬂicts.\n89\n\nPlanning and Execution with Timelines under Uncertainty\nDeliberative\nRepresentation\nExecutive\nExecutive\nMonitor\nClock\nDispatcher\nExecutive Plan Database Manager\nFigure 6.1: The EPSL architecture extended with executive capabilities\nFigure 6.1 shows the extended architecture of the EPSL framework with the\nmain architectural elements. The executive relies on the same representation func-\ntionalities the deliberative relies on. Therefore, the system can manage the execu-\ntion of the activities of the plan according to their controllability properties. The\nobtained EPSL framework represents a uniﬁed tool capable of seamlessly dealing\nwith planning and execution of timelines with uncertainty. Plan execution man-\nages particular information representing states and conditions that must be mon-\nitored during the execution of timelines. The Executive Plan Database Manager\nencapsulates this kind of information by extending the functionalities of the Rep-\nresentation layer. Speciﬁcally, it manages information concerning the execution\nstate of plan’s tokens and the related execution dependencies. The temporal con-\nstraints of a timeline-based plan entail dependencies determining whether a token\ncan actually start/end execution or not. Given a timeline-based plan to execute,\nthe Executive Plan Database Manager extracts execution dependencies dynami-\ncally and encodes this information into a dedicated data structure called Execution\nDependency Graph (EDG).\nFigure 6.2 shows the elements composing a general EPSL executive and their\nrelationships. In particular, the ﬁgure shows the additional elements the executive\nneeds to exchange information/signals with the speciﬁc environment and robotics\nplatform. The MoveItConnector and the MoveItListener represent two elements\nused within the research project FOURBYTHREE described in Section 6.3. They\nencapsulate the complexity of the remote communication with the robot and pro-\nvide the EPSL executive with a set of local execution services (see the Proxy de-\nsign pattern [Gamma et al., 1995]). In particular, the MoveItConnector encapsu-\nlates the set of low-level commands the robot can execute according to the oper-\national interface of system. The MoveItListener instead, allows the executive to\n90\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.2: The structure of the executive in the EPSL framework\nreceive asynchronous messages from the system as well as the environment con-\ncerning the results of execution requests (i.e. feedbacks).\n6.2.1\nThe Execution Process\nThe execution process consists of control cycles whose frequency determines the\nreactivity of the executive and the advancement of time. Given the temporal hori-\nzon of the plan, the execution process discretizes the temporal axis by means of\na number of temporal units, called ticks, according the needed frequency. Each\ncontrol cycle of the process is associated with a tick and realizes the execution\nprocedure. Broadly speaking, the execution procedure is responsible for detect-\ning the actual behavior of the system (closed-loop architecture), for verifying if\nthe system and also the environment behave as expected from the plan and for for\nstarting the execution of the activities of the plan. The procedure is composed by\ntwo distinct phases, the synchronization phase and the dispatching phase. At each\ntick (i.e. control cycle) the synchronization phase manages the received execution\nfeedbacks/signals in order to build the current status of the system and the envi-\nronment. If the current status is valid with respect to the plan, then the dispatching\nphase decides the next activities to be executed. Otherwise, if the current status\ndoes not ﬁt the plan, an execution failure is detected and replanning is needed.\nIndeed, the current plan does not represent the actual status of the system and the\n91\n\nPlanning and Execution with Timelines under Uncertainty\nenvironment and therefore replanning allows the executive to continue the execu-\ntion process with a new plan, which has been generated according to the observed\nstatus and the executed part of the original plan.\nAlgorithm 4 The EPSL executive control procedure\n1: function EXECUTE(Π, C)\n2:\n// initialize executive plan database\n3:\nπexec ←Setup (Π)\n4:\n// check if execution is complete\n5:\nwhile ¬CanEndExecution (πexec) do\n6:\n// wait a clock’s signal\n7:\nτ ←WaitTick (C)\n8:\n// handle synchronization phase\n9:\nSynchronize (τ, πexec)\n10:\n// handle dispatching phase\n11:\nDispatch (τ, πexec)\n12:\nend while\n13: end function\nAlgorithm 4 describes the general control procedure of the executive and its re-\nlated sub-procedures. The procedure takes as input the plan Π to be executed and\nthe clock C which determines the frequency of the control cycles. First of all, the\nprocedure analyzes the plan Π in order to identify execution dependencies among\ntokens of the timelines. This information is encapsulated by a dedicated structure\nπexec (row 3) the procedure uses during execution. The procedure iteratively exe-\ncutes the plan until all the tokens have been executed (rows 5-12). The timing of\nthe iterations of the procedure is determined by the clock C. Indeed, the proce-\ndure waits a signal from C which communicates the current execution time τ (row\n7). Then, the procedure checks the status of the execution by calling the Synchro-\nnize sub-procedure (row 9) and ends the execution cycle by calling the Dispatch\nsub-procedure (row 11).\nFigure 6.3 shows the runtime behavior of an EPSL executive and its inter-\nactions with Clock, PlanMonitor and PlanDispatcher elements shown in Figure\n6.2. The Executive manages the structure of the control cycle by coordinating\nthe synchronization and dispatching steps. The Clock iteratively generates control\nevents by sending onTick(tick) signals to the Executive, according to the desired\nfrequency. The higher is the frequency of the clock the higher is the reactiveness\nof the control process. Clearly, the clock’s frequency must be compatible with the\nresponse time of the system. The PlanDispatcher and the PlanMonitor are the el-\nements responsible for managing respectively the dispatching and synchronization\n92\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.3: The structure and interactions of the executive control cycle\nsteps within the control cycle. Thus, as Figure 6.3 shows, every time the Executive\nreceives a signal from the Clock, it coordinates the PlanMonitor and the PlanDis-\npatcher in order to complete the control cycle. Speciﬁcally, the Executive calls the\nPlanMonitor to handle the synchronization step and build the current pereceived\nstate of the system and the environment (i.e. the current situation). Then, the Ex-\necutive calls the PlanDispatcher to handle the dispatching step according to the\ncurrent situation and the current execution time.\nThe Synchronization Phase\nThe synchronization phase monitors the execution of the plan by determining if\nsome divergencies occur between the expected plan and the observed behavior\nof the system and the environment. Namely, at each iteration the synchroniza-\ntion phase builds the current situation by taking into account the current execution\ntime, the expected plan and the feedbacks received during execution. Figure 6.4\nshows the elements involved within the synchronization phase and their interac-\ntions. The PlanMonitor is responsible for propagating observations concerning the\nactual duration of the dispatched activities and detecting discrepancies between\nthe real-world and the plan. The Executive receives feedbacks about the success-\nful execution of dispatched commands or failure. The PlanMonitor manages these\nfeedbacks in order to detect if the actual duration of tokens comply with the plan.\n93\n\nPlanning and Execution with Timelines under Uncertainty\nIf the feedbacks comply with the plan then, the status of the related tokens can\nchange from in-execution to executed. Otherwise, an inconsistency is detected (i.e.\nthe current situation does not ﬁt the expected plan) and a failure is notiﬁed to the\nExecutive which must react accordingly (e.g. by re-planning).\nAlgorithm 5 The EPSL executive procedure for the synchronization phase\n1: function SYNCHRONIZE(τ, πexec)\n2:\n// manage observations\n3:\nO = {o1, ..., on} ←GetObservations (πexec)\n4:\nfor oi ∈O do\n5:\n// propagate the observed end time\n6:\nπexec ←PropagateObservation (τ, oi)\n7:\nend for\n8:\n// check if observations are consistent with the current plan\n9:\nif ¬IsConsistent (πexec) then\n10:\n// execution failure\n11:\nreturn Failure\n12:\nend if\n13:\n// manage controllable activities\n14:\nA = {ai, ..., am} ←GetControllableActivities (πexec)\n15:\nfor ai ∈A do\n16:\n// check if activity can end execution\n17:\nif CanEndExecution (τ, ai, πexec) then\n18:\n// propagate the decided end time\n19:\nπexec ←PropagateEndActivity (τ, ai)\n20:\nend if\n21:\nend for\n22: end function\nThe Dispatching Phase\nThe dispatching phase manages the actual execution of the plan. Given the cur-\nrent situation and the current execution time, the dispatching step analyzes the plan\nπexec in order to ﬁnd the tokens that can start execution and dispatches the related\ncommands to the underlying system. Namely, the dispatching step allows the Ex-\necutive to advance execution by deciding the next tokens to execute. Figure 6.5\nshows the elements involved within the dispatching steps and their interactions.\nThe PlanDispatcher is responsible for making dispatching decisions of plan’s to-\nkens. For each token, the PlanDispatcher checks the related start condition by\nanalyzing the token’s scheduled time and any dependency with other tokens of the\nplan. If the start condition holds, then the PlanDispathcher can decide to start ex-\necuting the token (i.e. the dispatcher propagates the scheduled start time into the\n94\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.4: Management of the received feedback signals during the control cycle\nplan). After dispatching, the status of the involved token changes from waiting to\nin-execution.\n6.2.2\nManaging the Execution Dependency Graph\nA valid timeline-based plan consists of a set of timelines whose tokens represent\nvalued temporal intervals satisfying all the constraints of the domain speciﬁcation.\nAccording to the formal characterization given in Chapter 4, each token of a time-\nline is described by a duration and an end time (interval) satisfying the constraints\nof the plan. However, this information is not sufﬁcient to properly manage plan\nexecution. Temporal relations entail dependencies among tokens of a plan the ex-\necutive must take into account during execution. For example a temporal relation\nof the form A meets B, entails that execution of token B must start as soon as exe-\ncution of token A ends. As described in Chapter 5, such dependencies are encoded\nby the underlying temporal network and the inferred temporal bounds of the re-\nlated temporal intervals, but the executive must explicitly model these relationships\nin order to \"validate\" the plan during execution. Timeline tokens represent ﬂexible\nintervals and therefore, each token is characterized by a start execution condition\n95\n\nPlanning and Execution with Timelines under Uncertainty\nAlgorithm 6 The EPSL executive procedure for the dispatching phase\n1: function DISPATCH(τ, πexec)\n2:\n// manage the start of (all) plan’s activities\n3:\nA = {ai, ..., am} ←GetActivities (πexec)\n4:\nfor ai ∈A do\n5:\n// check if activity can start execution\n6:\nif CanStartExecution (τ, ai, πexec) then\n7:\n// propagate the decided start time\n8:\nπexec ←PropagateStartActivity (τ, ai)\n9:\n// actually dispatch the related command to the robot\n10:\nSendCommand (ai)\n11:\nend if\n12:\nend for\n13: end function\nFigure 6.5: Management of the dispatching step during the control cycle\n96\n\nPlanning and Execution with Timelines under Uncertainty\nand an end execution condition that allow the executive to decide their actual start\nand end times.\nThe Executive Plan Database Manager of Figure 6.1, extends information of\nthe plan data-base in order to properly manage execution of timelines by means of\nEDG. An EDG is a data structure encapsulating information about the execution\ndependencies, the executive process relies on to make decisions about the execution\nof tokens. An EDG is a directed graph built by analyzing temporal relationships\nof the plan being executed. The nodes of the graph represent the tokens of the\ntimelines composing the plan. Each node is associated with the current execution\nstatus of the related token of the plan. The (directed) edges represent execution\ndependencies between nodes (i.e. tokens). The tokens of a plan represent ﬂexible\ntemporal intervals and therefore there are two types of edges modeling execution\nconditions. The start/end execution conditions model conditions that allow the\nexecutive to decide the actual start/end of a token during execution.\nDeﬁnition 18 An Execution Dependency Graph (EDG) is a directed graph rep-\nresenting execution dependencies among the tokens of a plan. An EDG can be\nformally deﬁned as follows:\n⟨V, E, Γ, ρ, ξ⟩\nwhere:\n• V is the set of nodes of the graph each of which encapsulates a token of the\nplan.\n• E = Es ∪Ee ⊆{(vi, vj) : vi, vj ∈V ∧vi ̸= vj} is the set of edges of\nthe graph representing execution dependencies between two (distinct) tokens\nof the timelines. The set E is partitioned into two subsets: (i) Es contains\nthe edges representing token start dependencies; (ii) Ee contains the edges\nrepresenting token end dependencies.\n• Γ = {waiting, starting, inexecution, executed} is a set of constants rep-\nresenting the possible execution status the tokens of the plan may assume:\n(i) a token is in waiting status if the related start conditions are not satisﬁed\nand the executive must wait for its execution; (ii) a token is in starting sta-\ntus if the related start conditions are satisﬁed and the executive can actually\nstart its execution (this status is particularly relevant for fully uncontrollable\ntokens as section 6.2.3 will describe); (iii) a token is in inexecution status if\nthe executive is actually executing the token. It means that the executive has\n97\n\nPlanning and Execution with Timelines under Uncertainty\nstarted the execution of the token (i.e. the executive has dispatched the start\ntime of the token) but cannot end its execution because the related end con-\nditions are not satisﬁed yet; (iv) a token is in executed status if its execution\nis complete. It means that, the end conditions of the token have been satisﬁed\nand the executive has ended its execution.\n• ρ : V →Γ is a status function mapping each node vi ∈V (i.e. a token\nof the plan) to its current execution status ρ(vi) = γi ∈Γ. For example\nρ(vi) = waiting means that the current status of the token related to vi ∈\nV , is waiting.\n• ξ : E →Γ is a dependency function mapping each edge of the graph (i.e. an\nexecution dependency) to the required status of the destination node. Specif-\nically, considering start execution conditions, given an edge (vi, vj) ∈Es,\nthe condition ξ (vi, vj) = executed, means that the start condition of the\nnode vi is satisﬁed if the status of node vj is executed. The executive can\nstart the execution of the token related to node vi iff the execution of the\ntoken related to node vj is ended. The condition ξ (vi, vj) = inexecution\nmeans that the start condition of the node vi is satisﬁed if the status of node\nvj is inexecution. The executive can start the execution of the token re-\nlated to node vi iff the executive is still executing the token related to node\nvj. The condition ξ (vi, vj) = waiting means that the start condition of the\nnode vi is satisﬁed if the status of node vj is waiting. The executive can\nstart the execution of the token related to node vi iff the executive has not yet\nstarted the execution of the token related to node vj. Finally, the condition\nξ (vi, vj) = starting means that the start condition of the node vi is satis-\nﬁed if the status of node vj is starting. Analogous interpretations hold for\nend execution conditions represented by edges (vi, vj) ∈Ee.\nThe EDG is built from the plan before starting execution. The executing con-\nditions, are dynamically extracted from the timeline-based plan by analyzing the\ntemporal relations. Speciﬁcally, the graph generation procedure encodes Allen’s\ntemporal relations [Allen, 1983] in a set of start and end execution conditions be-\ntween the involved tokens of the plan (i.e. nodes of the graph). For example, given\nA and B two tokens of a plan, the temporal relation A during B can be encoded\ninto the EDG graph by adding two execution conditions. A start execution con-\ndition asserting that A can start execution iff B is \"currently\" in execution and, an\nend execution condition asserting that A can end execution iff B is \"currently\" in\n98\n\nPlanning and Execution with Timelines under Uncertainty\nexecution. These two conditions are encoded by two edges, both of which have the\nnode related to the token A as the source, and the node related to the token B as the\ntarget.\nAlgorithm 7 EDG building procedure\n1: function BUILDEXECUTIONDEPENDENCYGRAPH(Π)\n2:\n// initialize the EDG graph\n3:\nEDG ←∅\n4:\n// create nodes from the tokens of the timelines\n5:\nFTL ←GetTimelines (Π)\n6:\nfor ti ∈FTL do\n7:\n// add a new node with the default execution status waiting ∈Γ\n8:\nnti ←CreateNode (ti, waiting)\n9:\nEDG ←AddNode (nti)\n10:\nend for\n11:\n// create nodes from the tokens of the observations\n12:\nFTL ←GetObservations (Π)\n13:\nfor oi ∈FTL do\n14:\n// add a new node with the default execution status waiting ∈Γ\n15:\nnoi ←CreateNode (oi, waiting)\n16:\nEDG ←AddNode (noi)\n17:\nend for\n18:\n// create edges from the temporal relations of the plan\n19:\nR ←GetRelations (Π)\n20:\nfor r ∈R do\n21:\n// encode temporal relation as a set of execution conditions\n22:\n{..., (nh,i, nh,j, ch,k) , ...} ←GetStartConditions (r)\n23:\n// add start conditions as edges to the graph\n24:\nEDG ←addStartConditions ({..., (nh,i, nh,j, ch,k) , ...})\n25:\n// encode temporal relation as a set of execution conditions\n26:\n{..., (nh,i, nh,j, ch,k) , ...} ←GetEndConditions (r)\n27:\n// add end conditions as edges to the graph\n28:\nEDG ←addEndConditions ({..., (nh,i, nh,j, ch,k) , ...})\n29:\nend for\n30:\nreturn EDG\n31: end function\nAlgorithm 7 describes the procedure building the EDG from the timeline-based\nplan to be executed. The procedure ﬁrst initializes the graph (row 3). The nodes of\nthe graph represent tokens of the plan with their current execution status. The pro-\ncedure creates a new node for each token of the timelines (rows 5-10) and for each\ntoken of the external timelines (i.e. the observations) composing the plan (rows 12-\n17). The edges of the graph are generated by encoding the temporal relations of\nthe plan (rows 19-29). Each temporal relation is \"translated\" into a set of start and\nend execution conditions the procedure adds to EDG as edges (rows 21-28). Each\n99\n\nPlanning and Execution with Timelines under Uncertainty\nexecution condition (nh,i, nh,j, ch,lk) represents an (directed) edge of the graph.\nThe source node (nh,i) represents the token the dependency relation refers to. The\ntarget node (nh,j) represents the token the source of the relation depends on. The\ncondition (ch,k) represents the execution status of the target token enabling the\nexecution of the source token. The procedure ends by returning a complete EDG.\n6.2.3\nHandling Uncertainty During Execution\nAn EDG encapsulates temporal dependencies between tokens of the timeline-\nbased plans. However, the executive must also take into account controllability\ninformation concerning the values the tokens of the timelines are related to. There\nare different types of tokens the executive must deal with according to the con-\ntrollability properties of the related value of the domain. Different types of tokens\nentail different execution policies and therefore, different state transitions that may\nbe either controllable or not. Speciﬁcally, there are three types of tokens the exec-\nutive must manage during execution. Figure 6.6 shows the state transitions of the\ncontrollable, partially-controllable and fully-uncontrollable tokens.\nwaiting\nin-execution\n c \nexecuted\n c \nwaiting\nin-execution\n c \nexecuted\n u \nwaiting\nstarting\n c \nin-execution\n u \nexecuted\n u \n(a)\n(b)\n(c)\nFigure 6.6: Different execution state transitions for: (a) controllable tokens; (b) partially-\ncontrollable tokens; (c) fully-uncontrollable tokens. State transitions tagged with \"c\" are\ncontrollable while transitions tagged with \"u\" are uncontrollable\nControllable tokens whose state transitions are shown in Figure 6.6 (a), are\ncompletely under the control of the executive. The executive can decide the actual\n100\n\nPlanning and Execution with Timelines under Uncertainty\nstart time of the token and its duration. Thus, the state transition between wait-\ning state and in-execution state, as well as the state transition between in-execution\nstate and executed state are both controllable. In this case, the executive can actu-\nally dispatch the signals for starting/ending the execution of the related command.\nPartially-controllable tokens whose state transitions are shown in Figure 6.6\n(b), represent tokens the executive cannot completely control. The executive can\ndecide the start time of this type of tokens and therefore the state transition between\nwaiting state and in-execution state is controllable. However, the actual execution\nof this type of token is not controllable and therefore, the system can only observe\nthe execution by waiting for a signal from the environment concerning the end\nof token execution (i.e. the executive cannot control the end of the execution of\nthis type of tokens). When the end signal is received, the executive veriﬁes the\nconsistency of the plan with respect to the observation (i.e. the system checks if the\nend conditions and the schedule of the token comply with the observed behavior)\nand, the uncontrollable transition between in-execution state and executed state is\ntriggered.\nFully-uncontrollable tokens whose state transitions are shown in Figure 6.6\n(c), are completely outside the control of the executive. The executive may sup-\npose when the token is about to start according to its schedule, but cannot decide\nits actual start time. Thus, a state transition between waiting state and starting state\nis controllable but it means that the executive is waiting for a signal from the en-\nvironment which notiﬁes the start of the execution of the token. The system can\nonly observe the start of the execution and check if the signal (i.e. the exogenous\nevent) received complies with the plan (i.e. the start execution dependencies and\nthe schedule of the token are satisﬁed). When the executive receives the start signal\nfrom the environment, the uncontrollable state transition between starting state and\nin-execution state is triggered. Then, similarly to partially-controllable tokens, the\nexecutive waits the signal concerning the end of the execution of the token. When\nthe signal is received, again the executive checks the consistency with respect to\nthe plan and the related (end) execution dependencies and the uncontrollable state\ntransition between the in-execution state and the executed state is triggered.\n6.2.4\nThe Importance of Being (Temporally) Robust\nTimeline-based plans are temporally ﬂexible, hence associated with an envelope of\npossible execution traces. Temporal ﬂexibility allows the executive to be less brittle\nduring execution because the system is able to manage the temporal uncertainty of\n101\n\nPlanning and Execution with Timelines under Uncertainty\nthe activities of the plan. The ﬂexible temporal intervals of the tokens composing\nthe timelines of the plan allow the executive to \"easily\" absorb execution delays\nwithin the speciﬁed bounds.\nHowever, it is not always possible to complete the execution without changing\nor adapting the plan. Temporal uncertainty and uncontrollability features of the\nenvironment may lead to uncontrollable behaviors the timeline-based plan is not\nable to \"capture\" and therefore, the control system is forced to generate a new plan\naccording to the perceived situation in order to complete the execution. Indeed,\nthe plan-based controller relies on a model which tries to describe the (ﬂexible)\nbehavior of the uncontrollable features of the domain. Uncontrollability may cause\nbehaviors that do not comply with the plan. For example, the execution of an\nuncontrollable activity may last longer than expected from the model, or it can\nstart later than expected from the plan. In such cases, the executive interrupts the\ncurrent execution and starts a re-planning phase which tries to generate a new plan\nfrom the observed situation.\nRe-planning takes into account the primitive variables of the domain for build-\ning the stable state (i.e. the problem speciﬁcation) the planning process starts from\nin order to generate the new plan. The executive analyzes the timelines of primitive\nvariables by setting the executed tokens with the related temporal information as\nfacts of the problem speciﬁcation. Also, the tokens generated from the observation\nthat caused the execution failure are added to the facts of the problem together with\ntheir temporal information. Moreover, if the executive was executing some uncon-\ntrollable tokens when the failure was detected (e.g. the rover was moving between\ntwo locations), then (supposing the related activities are non-interruptible) the sys-\ntem can wait for the end of their execution and add the related facts to the problem\nspeciﬁcation. Given the resulting problem speciﬁcation, a new plan is generated\nand the execution can continue starting from the point at which it was interrupted\n(i.e. execution failure).\nRe-planning is needed because the execution of these plans is decided on the\nﬂy. Without an execution policy, a valid plan may fail due to wrong dispatching or\nenvironmental conditions (controllability problem [Vidal and Fargier, 1999]). It is\npossible to address this issue in a more robust way by leveraging recent research\nresults exploiting formal methods to generate a plan controller suitable for the ex-\necution of a ﬂexible temporal plan [Orlandini et al., 2013]. Namely, UPPAAL-\nTIGA, a model checker for Timed Game Automata (TGA), can be exploited to\nsynthesize robust execution controllers of ﬂexible temporal plans. A TGA-based\n102\n\nPlanning and Execution with Timelines under Uncertainty\nmethod for the generation of ﬂexible plan controllers can be integrated within the\nexecutive. In this case, the UPPAAL-TIGA engine is embedded within the plan-\nning and execution cycle generating plan controllers that guarantee a correct and\nrobust execution. This is an important feature of the FOURBYTHREE Task Plan-\nner as it enforces a safe plan execution further enforcing that all the production\nrequirements and human preferences are properly respected.\n6.3\nHuman-Robot Collaboration: a Case Study\nHuman-Robot Collaboration (HRC) in manufacturing represents an interesting\nand quite complex application context which requires a tight interaction between a\nhuman operator and a robotic device (e.g. a robotic arm) to perform some factory\noperations. From the perspective of a plan-based control system, the envisaged en-\nvironment is composed of two autonomous agents that share the same working en-\nvironment and may operate independently or may collaborate by supporting each\nother. This type of application presents several challenges a plan-based control sys-\ntem must cope with in order to control the robot and guarantee a safe collaboration\nwith the human. In general, there are three important features the control system\nmust deal with in order to generate effective plans:\n• Supervision, to represent and satisfy the production requirements needed to\ncomplete the factory processes.\n• Coordination, to represent the activities the human operator and the robot\nmust perform according to the Human-Robot Collaboration settings.\n• Uncertainty, to manage the temporal uncertainty about the activities of the\nhuman operator that the system cannot control.\nA key enabling feature is the capability to model and manage the temporal un-\ncertainty concerning the behavior of the human operator. The human is an active\n\"part\" of the environment which is not under the control of the robot. The control\nsystem must take into account the (expected) behavior of the human in order to\nproperly manage operations of the robot. Thus, HRC represents a relevant appli-\ncation context to leverage the feature of the timeline-based planning and execution\nframework described above. The following sections deal with the development of\nan EPSL-based dynamic task planing system within the FOURBYTHREE research\nproject, for planning and execution in real-world HRC manufacturing scenarios.\n103\n\nPlanning and Execution with Timelines under Uncertainty\n6.3.1\nThe FOURBYTHREE Research Project\nIndustrial robots have demonstrated their capability to meet the needs of many ap-\nplication domains, offering accuracy, efﬁciency and ﬂexibility of use. A relevant\nresearch challenge is the co-presence of robot and human in the same environment\ncollaborating in a common goal. In general, when robot-worker collaboration is\nneeded, there are a number of open issues to be taken into account, ﬁrst of those\nis human safety that needs to be enforced in a comprehensive way. A key open\ntrend in manufacturing is the design of shared fenceless working spaces in which\nsafe human-robot collaboration is seamlessly implemented. The FOURBYTHREE\nresearch project1 [etf, 2016] aims at designing, building and testing robust and\nconﬁgurable robotic solutions capable of collaborating safely and efﬁciently with\nhuman operators in industrial manufacturing companies. The overall aim of the\nproject is to create a new generation of robotic solutions, based on innovative hard-\nware and software, which present four main characteristics: modularity, safety,\nusability and efﬁciency. The envisaged robot services take into account the co-\npresence of three different actors: humans, robots and the environment.\nA human-robot collaboration workcell is a bounded connected space with two\nagents located in it, a human and a robot system, and their associated equipment\n[Marvel et al., 2015]. The robot system consists of a robotic arm with its tools,\nits base and possibly additional support equipment. The workcell also includes\nthe workpieces and any other tool associated with the targeted task and dedicated\nsafeguards (physical barriers and sensors such as, e.g., monitoring video cameras).\nIn such a working environment, four different degrees of interaction between a\nhuman operator and the robot can be deﬁned [Helms et al., 2002]. In all these\ncases, it is assumed that the robot and the human may need to occupy the same\nspatial location and interact according to different modalities:\n• Independent, the human and the robot operate on separate workpieces with-\nout collaboration, i.e. independently from each other;\n• Synchronous, the human and the robot operate on sequential components of\nthe same workpiece, i.e. one can start a task only after the other has com-\npleted a preceding task;\n• Simultaneous, the human and the robot operate on separate tasks on the same\nworkpieces at the same time;\n1http://www.fourbythree.eu\n104\n\nPlanning and Execution with Timelines under Uncertainty\n• Supportive, the human and the robot cooperate to complete the processing\nof a single workpiece, i.e. they work simultaneously on the same task.\nDifferent interaction modalities entail the robot to be endowed with different safety\n(hardware and control) settings while executing tasks.\nIn FOURBYTHREE four different pilots are taken into account covering differ-\nent production processes, i.e. assembly/disassembly of parts, welding operations,\nlarge parts management and machine tending. Among these, the ALFA Pilot is\nparticularly relevant from the HRC perspective. This case study corresponds to\na production industry (the ALFA PRECISION CASTING1) which represents a real\nworking scenario with different relevant features (e.g. space sharing, collaboration\nor interaction needs). The overall production process (summarized in Fig. 6.7) con-\nsists of a metal die which is used to produce a wax pattern in a injection machine.\nOnce injected, the pattern is taken out of the die. Several patterns are assembled\nto create a cluster. The wax assembly is covered with a refractory element, creat-\ning a shell (this process is called investing). The wax pattern material is removed\nby the thermal or chemical means. The mould is heated to a high temperature to\neliminate any residual wax and to induce chemical and physical changes in the\nrefractory cover. The metal is poured into the refractory mould. Once the mould\nhas cooled down sufﬁciently, the refractory material is removed by impact, vibra-\ntion, and high pressure water-blasting or chemical dissolution. The casting are then\ncut and separated from the runner system. Other post-casting operations (e.g. heat\ntreatment, surface treatment or coating, hipping) can be carried out, according to\ncustomer demands.\nGiven this production process, the ﬁrst step (preparation of the die for wax\ninjection and extraction of the pattern from the die) has a big impact on the ﬁnal\ncost of the product, and it represents a relevant application scenario. Thus, the\ninvolvement of a collaborative robot has been envisaged to help the operator in\nthe assembly/disassembly operation. The operation consists of the following steps:\n(i) mount the die; (ii) inject the wax; (iii) open the die and remove the wax; (iv)\nrepeat the cycle for a new pattern starting back from step (i). The most critical\nsub-operation is the opening of the die because it has a big impact on the quality\nof the pattern.\n1ALFA is a medium sized company producing aluminium parts for different industries for ap-\nplications that are characterized by low size production batches and requiring tight tolerance and\ndimensional precision.\n105\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.7: The overall ALFA pilot production process\n6.3.2\nAssembly/Disassembly Operation\nDue to the small size of the dies and the type of operations done by the worker\nto remove the metallic parts of the die, it is very complex for the robot and the\nworker to operate on the die simultaneously. Figure 6.8 shows some of the steps of\nthe overall (manual) operation. However, they can cooperate in the sub-operations\nconcerning the assembly/disassembly of the die. Once the injection process has\nﬁnished, the die is taken to the workbench by the worker. The robot and the worker\nunscrew the bolts holding the top cover. There are nine bolts, the robot starts\nremoving those closer to it, and the worker the rest. The robot unscrews the bolts\non the cover by means of a pneumatic screwdriver. The worker removes the top\ncover and leaves it on the assembly area (a virtual zone that will be used for the re-\nassembly of the die). The worker turns the die to remove the bottom die cover. The\nrobot unscrews the bolts on the bottom cover by means of a pneumatic screwdriver.\nMeanwhile the operator unscrews and removes the threaded pins from the two\nlateral sides to release the inserts. The worker starts removing the metallic inserts\nfrom the die and leaves them on the table. Meanwhile, the robot tightens the parts\nto be assembled/reassembled together screwing bolts. The worker re-builds the\ndie. The worker and the robot screw the closing covers. The human and the robot\nmust collaborate to perform assembly/disassembly on the same die by suitably\nhandling different parts of the die and screwing/unscrewing bolts. Speciﬁcally, the\nhuman worker has the role of leader of the process while the robot has the role of\nsubordinate with some autonomy.\n106\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.8: The manual procedure of the Assembly/Disassembly process of the ALFA\npilot\n6.4\nDynamic Task Planning in FOURBYTHREE\nIn FOURBYTHREE and more in general in HRC applications, the envisaged dy-\nnamic task planning system must realize a human aware planning and execution\nmechanism capable of allowing a robot to safely interact with an operatore. The\ncontrol mechanism must adapt robot plan and motions according to the expected\nand observed behaviors of the related human operator [Cesta et al., 2016, Pelle-\ngrinelli et al., 2017]. In this sense, the dynamic task planning system applies and\nextends the hierarchical timeline-based modeling approach by introducing super-\nvision and coordination issues. Supervision models the operational requirements\nof the production processes. It models the high-level tasks to perform in order\nto complete the process and the related precedence constraints that must be sat-\nisﬁed. Coordination models the possible decompositions of the high-level tasks\nin low-level tasks the human and the robot can directly perform and the possible\nassignments. Moreover, the human is an active element of the environment that\n107\n\nPlanning and Execution with Timelines under Uncertainty\ncannot be directly controlled by the robot and therefore the human is modeled as\na variable of the domain whose values (i.e. the low-level tasks the operator can di-\nrectly perform) are all uncontrollable. The dynamic task planning framework must\nplan for the tasks the human and the robot must perform by coordinating them and\nby taking into account the temporal uncertainty of the human. Human activities are\nuncontrollable and therefore the system must generate and execute plans without\nmaking any hypothesis on the actual duration of the tasks assigned to the human.\nImplementation \nLevel\nRobot\nArm\nController\nScrewdriver\nController\nSupervision Level\nAssembly\nProcess\nALFA\nPilot\nCoordination \nLevel\nHuman\nRobot\nController\nCollaboration\nType\nFully Uncontrollable\nPartially Uncontrollable\nFigure 6.9: The hierarchy of the task planning domain\n6.4.1\nTask Planning Model for Assembly/Disassembly\nFigure 6.9 shows the hierarchical structure of the control model for the assem-\nbly/disassembly production process of the ALFA pilot of the project. The su-\npervision layer represents the elements describing the processes of the work-cell.\nThe ALFA state variable modes the general ALFA pilot and the related processes.\nSpeciﬁcally, each value of the state variable represents a speciﬁc process (e.g. the\nAssembly operation) the human and the robot can perform in the pilot. The Assem-\nblyProcess state variable models the assembly/disassembly operation by specifying\nthe set of high-level tasks required. As shown in Figure 6.10 a set of constraints\nspeciﬁes the operational requirements that guarantee a correct execution of the pro-\n108\n\nPlanning and Execution with Timelines under Uncertainty\ncess. For example, these requirements may specify ordering constraints between\nthe high-level tasks or may specify different procedures for performing the process\n(e.g. alternative sequences of high-level tasks). In this speciﬁc case, the operational\nrequirement of the supervision layer speciﬁes a total ordering among the high-level\ntasks composing the Assembly process of the case study.\nCONTAINS\nFigure 6.10: Deﬁning the workﬂow of work-cell operations\nIt is worth observing that the control model is not considering coordination\nfeatures at this abstraction level. Each high-level task represents a complex proce-\ndure which must be further decomposed in (primitive/atomic) low-level tasks the\nhuman and the robot can directly handle. Some primitive tasks can be performed\neither by the human or by the robot and it is up to the task planner deciding who\nmust execute them. Moreover, given a high-level task, the system must coordi-\nnate human and robot activities according to the type of collaboration desired for\nthe speciﬁc collaboration scenario. Different types of collaboration entail different\nsafety settings and therefore different conﬁgurations of the robot for performing\ntasks.\nFigure 6.11 shows an example of coordination requirements between the robot\nand the human with respect to the high-level task named BaseRemoval of the As-\nsembly process. The model describes the sequence of low-level tasks needed to\nproperly complete the BaseRemoval task with their assignments. The robot and\nthe human simultaneously unscrew the bolts of the base of the die and therefore\nthe type of collaboration required is simultaneous in this speciﬁc case (the human\nand the robot work on the same workpiece while performing different tasks, i.e.\n109\n\nPlanning and Execution with Timelines under Uncertainty\nCollaboration\nType:\nSimultaneous\nFigure 6.11: Assigning tasks to the robot and the human\nunscrewing bolts). Again, the control system (and the robot) must be aware of\nthe human and adapt its tasks according to the human-robot collaboration process\ndeﬁned.\nFinally, the low-level tasks of the robot must be further decomposed in order\nto synthesize the set of commands/signals to be dispatched for execution. For ex-\nample, the Screw task of the RobotController in Figure 6.11, requires to set the\narm on the bolt to screw and then activate the tool (i.e. the screwdriver) in order\nto actually screw the bolt and complete the task. According to this description,\nthe Screw task must be decomposed in terms of commands that allow the robot to\nassume the desired pose and activate/deactivate the tool. Speciﬁcally, the related\nsynchronization rule of the model, constrains the behavior of the RobotArmCon-\ntroller and the ScrewDriverController (see Figure 6.12) by specifying the values\nthey must assume (i.e. tokens) and the related temporal constraints that must be\nsatisﬁed. The OnTarget value of the RobotArmController sets the arm on the target\nbolt. The Operating value of the ScrewDriverController activates the tool in order\nto start screwing the bolt. The temporal constraints shown in Figure 6.12, allow\n110\n\nPlanning and Execution with Timelines under Uncertainty\nDURING\nDURING\nFigure 6.12: Decomposition of the low-level tasks of the robot controller\nthe arm to keep the position for the entire duration of the task.\nFigure 6.13 shows an excerpt of a hierarchical timeline-based plan for the As-\nsembly process of the ALFA case study. The horizontal sections (i.e. bars with\ndifferent colors) partition the plan according to the hierarchy depicted in Figure\n6.9. The vertical section (in red) depicts an example of high-level task decom-\nposition and application of the synchronization rules of the domain. Namely, the\ndecomposition of the BaseRemoval high-level task of the Assembly process: the\nBaseRemoval task requires the human operator and the robot to simultaneously un-\nscrew some bolts from two lateral sides of the work-piece, then the human should\nrotate the piece and ﬁnally, the operator and the robot unscrew bolts from two\nlateral sides of the piece. Figure 6.13 shows that the plan satisﬁes the production\nrequirements of the high-level task. Indeed, a synchronization rule requires that the\nlow-level tasks for unscrewing bolts should be executed during the BaseRemoval\ntask. Moreover, the ﬁrst unscrew tasks must be performed before the operator\nrotates the piece, while the second unscrew tasks must be performed after the op-\n111\n\nPlanning and Execution with Timelines under Uncertainty\nFigure 6.13: The Gantt chart representation of the plan for the ALFA pilot with respect\nto the earliest start time of the related tokens\nerator rotates the piece. It is also possible to observe that robot’s tasks are further\ndecomposed in order to synthesize a more detailed representation of the activities\nthe robot must perform to actually carry out the low-level tasks. For instance, the\nrobot must set the arm on a speciﬁc target and then must activate the tool in order to\nperform an unscrew operation. Again, in Figure 6.13, a during temporal constraint\nholds between the Unscrew low-level task token and the OnTarget and Operating\ntokens.\n6.4.2\nFeasibility Check of the Task Planning Model\nDeliberation time i.e. the time spent by the dynamic task planning system to gen-\nerate a plan for the considered production process, has been considered as the ﬁrst\nkey performance indicator to be assessed in order to test the performance of the\ndynamic task planning system. Thus, with respect to the planning model of the as-\nsembly/disassembly process described in the previous section, different planning\nscenarios have been considered by varying the complexity of the dimensions of the\nproblems:\n• Production process complexity - three different production procedures have\nbeen analyzed by taking into account an increasing number of tasks needed\nto complete the assembly/disassembly process: the small procedure consists\nof 6 tasks; the medium procedure consists of 10 tasks; the large procedure\n112\n\nPlanning and Execution with Timelines under Uncertainty\nconsists of 15 tasks.\n• Human-Robot effort - for each production procedure an increasing involve-\nment of the robot has been considered in order to increase the number of\ntasks the robot must perform to complete the process and consequently de-\ncrease the effort of the human\n0\n0,5\n1\n1,5\n2\n2,5\nsmall-30\nsmall-50\nsmall-70\nmedium-30\nmedium-50\nmedium-70\nlarge-30\nlarge-50\nlarge-70\nPlanning time (in seconds)\nFigure 6.14: Deliberation time on different problems with different assignment policies\nFigure 6.14 shows the deliberation times of the dynamic task planning system\nfor the considered scenarios. In general, the higher is the number of tasks needed\nfor the process, the higher is the number of tasks that can be assigned to the robot\nand, consequently, the higher is the complexity of the resulting problem with re-\nspect to deliberation. As the results in Figure 6.14 show, an increasing complexity\nof the scenario entails higher deliberation times. Nevertheless, planning costs re-\nsult to be compatible with the latency of the production environment. Indeed, the\nperformance is compatible with the latency usually involved in this type of manu-\nfacturing applications. In particular, the experimentation emphasizes the ﬂexibility\nof the envisaged approach to planning which is capable to adapt the assignment\nand coordination strategies to different human-robot collaboration settings.\n113\n\nPlanning and Execution with Timelines under Uncertainty\n6.4.3\nThe Dynamic Task Planning Module in Action\nThe dynamic task planning system has been tested on a ROS-based simulator1\nwhich provides an implementation of the functional control level of a generic\nrobotic arm. Figure 6.15 shows the process architectural view [Kruchten, 1995]\nof the dynamic task planning module describing the main elements composing the\nmodule at runtime (i.e. the processes) and their interactions. The process archi-\ntectural view aims at describing how the control ﬂow is structured and how the\ndeliberative and executive processes (both relying on EPSL-based planning and\nexecution capabilities) interact. In particular, this view describes the management\nof plan execution failures and the related replanning mechanism. The execution\ndecisions of the dynamic task planning module, shown in Figure 6.15, are taken\non the ﬂy during execution. Without an execution policy a valid plan may fail due\nto wrong dispatching or environmental conditions (controllability problem [Vidal\nand Fargier, 1999]) and therefore replanning is the basic mechanism which allows\nthe module to deal with exogenous events and complete the execution of a plan.\nDeliberative\nbuffered\nplanned\nFailure\nManager\nExecutive\nDispatcher\nMonitor\nfailure\nexecuted\nre-planning\nSystem/ROS-based Simulator\nsend command\nfeedback\nfeedback\nsend command\nFigure 6.15: Process-view of the dynamic task planning control module\nThe processes of the dynamic task planning module exchange information con-\ncerning the task to be managed through queues. The different queues of Figure 6.15\nrepresent the states composing the task lifecycle within the module. The task life-\ncycle models the control ﬂow of the dynamic task planning module. The buffered\nqueue is the entry point of the module, it contains the high-level task requests the\n1\"The Robot Operating System (ROS) is a collection of tools, libraries, and conventions that\naim at simplifying the task of creating complex and robust robot behavior across a wide variety of\nrobotic platforms\" - from: http://www.ros.org/about-ros/\n114\n\nPlanning and Execution with Timelines under Uncertainty\nmodule must manage i.e. requests of performing a particular process of the factory\n(e.g. the assembly/disassembly process).\nThe Deliberative process takes a task request from the buffered queue and syn-\nthesizes a (pseudo-controllable) plan for the task. The generated plan represents a\nsuitable set of (low-level) tasks the human and the robot must execute according\nto the desired operational requirements. Thus, the task (i.e. the high-level task re-\nquest) is ready for execution and therefore the task with the related plan is added\nto the planned queue.\nThe Executive process takes a task request from the planned queue and starts\nexecuting the related plan by sending commands to the system (or a ROS-based\nsimulator) through the Dispatcher and receiving feedbacks about command exe-\ncution through the Monitor. As described in Section 6.2.1, the Dispatcher is re-\nsponsible for deciding the start of token execution according to their controllability\nproperties (see Section 6.2.3). The Monitor is responsible for managing execution\nfeedbacks from the environment (or the ROS-based simulator) in order to verify\nthe correctness of the plan with respect to the actual behavior of the system. If no\ninconsistency is detected the execution continues until the plan is ended and the\ntask request, with the resulting plan, is added to the executed queue. Otherwise, if\nan inconsistency is found then the executive interrupts the execution and the task\nrequest with the interrupted plan is added to the failure queue.\nExecution fails every time the uncontrollable dynamics of the environment do\nnot comply with the plan and the \"expected\" uncertainty of the domain. As de-\nscribed in Section 6.2.4, temporal ﬂexibility allows the executive to capture an\nenvelope of possible (temporal) behaviors of the environment. Different temporal\nbehaviors can be easily managed by the executive by temporally adapting the plan,\nif such behaviors comply with the model. However, if the observed dynamics of\nthe environment do not comply with the expected uncertainty then the plan can-\nnot capture these behaviors and replanning is needed. For example, human tasks\nare (fully) uncontrollable and therefore the executive cannot make any hypothe-\nsis on their actual duration. The model provides an estimation of the durations of\nsuch tasks in terms of minimum and maximum expected duration. The deliberative\ngenerates plans according to this estimation (pseudo-controllable plans), thus the\nexecutive can execute them if the observed behavior of the environment complies\nwith the model (i.e. the actual duration of uncontrollable tasks comply with the\nexpected durations). Thus, if the observed duration of a human task is higher than\nthe expected maximum, then the plan cannot be adapted and a new plan is needed\n115\n\nPlanning and Execution with Timelines under Uncertainty\nin order to address the real situation.\nThe Failure Manager process is responsible for managing the interruption of\nthe execution in order to set a stable state before generating a new plan. The pro-\ncess takes the interrupted task with the related execution trace (i.e. the executed\nportion of the plan) from the failure queue and interacts with the environment (the\nROS-based simulator in this case) in order to set the robot in a stable state. As\nbroadly described in Section 6.2.4, the Failure Manager analyzes the timelines\nconcerning the primitive variables of the domain in order to set the situation the\nDeliberative will replan from. In this speciﬁc case, if the execution is interrupted\nwhile the robotic arm is moving, the Failure Manager waits the execution feed-\nback of the motion in order to let the Deliberative start replanning with the robotic\narm set in a stable position. Another possible approach would allow the Failure\nManager to interrupt the motion and send the commands needed to set the robotic\narm in a known (initial) position. In general, the logic implemented by the Fail-\nure Manager cannot be generalized because it is strictly connected to the speciﬁc\nrobotic platform considered and the related functional level (i.e. the set of sensing\nand action primitives available for interacting with the robotic platofrm).\nWhen a stable state is reached i.e. both the robot and the human are in a known\nstable state, the Failure Manager leverages the execution trace of the interrupted\nplan and the current situation of the robot and the environment to build the prob-\nlem speciﬁcation for the new plan. The interrupted task with the related problem\nspeciﬁcation is added to the replanning queue and the Deliberative starts generat-\ning a new plan by ﬁtting the related problem speciﬁcation.\nExperimental evaluation on a ROS-based simulator\nFigure 6.16 shows a screenshot of a simulation for the assembly/disassembly pro-\ncess. The left-hand side of Figure 6.16 shows a portion of the plan of Figure 6.13\nduring execution. It shows the Gantt chart representing the timeline of the Hu-\nman (the sequence of red tasks), the timeline of the RobotController (the sequence\nof blue tasks) and the timeline of the RobotArmController (the sequence of green\ntasks). The right-hand side of Figure 6.16 shows a simple 3D model of the workcell\ncomposed by a robotic arm and the workpiece. The colored blocks of the work-\npiece represent the bolts the robot and the human are supposed to unscrew within\nthe assembly/disassembly process. Speciﬁcally, the blue blocks represent the bolts\nthe Deliberative has assigned to the robot, and the red blocks represent the bolts\nthe Deliberative has assigned to the human.\n116\n\nPlanning and Execution with Timelines under Uncertainty\nRobot’s motion tasks\nHuman’s assigned tasks\nFigure 6.16: ROS-based simulation of the dynamic task planning system\nSimulations have shown the capability of the dynamic task planning system of\ncoordinating the human and the robot in order to perform assembly operations. The\ncoordination takes into account the expected duration bounds of the tasks (espe-\ncially the task of the human) that are assigned by taking into account the makespan\nof the plan. Namely, the dynamic task planning system generates timeline-based\nplans that minimize the expected duration of the overall process and therefore op-\ntimize/maximize the throughput of the factory. Simulations have also shown the\ncapability of the dynamic task planning system of adapting the execution of robot\ntasks to the observed behavior of the human operator. Leveraging temporal ﬂexi-\nbility, the system easily captures the possible behavior of the human by dispatching\nrobot tasks accordingly. However, if the observed behavior of the human does not\ncomply with the expected one (i.e. with the model) the system cannot proceed with\nthe execution and the plan is interrupted (execution failure). In this case, simu-\nlations have shown the capability of the system of generating a new plan through\nreplanning. Speciﬁcally, the Failure Manager sets the robot in a stable state by\nwaiting for execution feedbacks of not completed motion tasks or any uninterrupt-\nible operation. Then, the Deliberative generates a new plan by taking into account\nexecuted tasks and reassigning missing tasks to the human and to the robot. Once\nthe new plan has been generated, the Executive resumes plan execution starting\nwith the reassigned tasks.\n117\n\nChapter 7\nKnowledge-based Control Loop\nfor Flexible Controllers\nT\nHE ideal robot is an artiﬁcial entity (an agent) capable of setting its own goals\nand of planning actions to achieve them. The research community in robotics\nand AI has been building many types of robots applying different techniques but\nyet is still far from anything ideal. There is still a limited understanding of what\nare the essential characteristics of artiﬁcial agent like robots. From a local point\nof view, robot software or hardware parts and modules, like sensors, reasoning en-\ngines, etc., present several limitations when compared to the capabilities of similar\nparts in the human being. Similarly, from a global point of view, there is not a\nclear vision of how to integrate different parts together in order to realize an agent\ncapable of autonomously operate in the environment by understanding the current\nsituation and \"act\" accordingly by properly manage the dynamics of the \"world\".\nThese philosophical problems are not just theoretical but they are also present in\npractical and speciﬁc areas like industrial robots. In particular there are several\nresearch initiatives that focus on the construction of robots that can quickly adapt\nchanges in the production environments [Wiendahl et al., 2007]. Traditional sys-\ntems, based on centralized or hierarchical control structures, like the plan-based\napproach described in the previous chapter, typically require major overhauls of\ntheir control code when some sort of system adaptation and reconﬁguration is re-\nquired.\nDynamic working environments like Reconﬁgurable Manufacturing Systems\n(RMSs) [Koren et al., 1999] require control processes with an high level of ﬂexi-\nbility. The actual capabilities of an agent and even the production processes of the\n118\n\nKnowledge-based Control Loop for Flexible Controllers\nfactory may change quickly in such contexts. Different conﬁgurations of the shop-\nﬂoor or the introduction of different production goals may change the type and/or\nthe ways agents carry out their tasks. Classical plan-based controllers usually rely\non a well-deﬁned and static model of the world which could become obsolete very\nsoon. The domain model would require a great design effort to be as stable as\npossible and a continuous maintenance which would negatively affect the produc-\ntivity of the factory. The pursued solution is to extend classical plan-based control\narchitectures by introducing knowledge representation and reasoning mechanisms\ninto the control loop. Semantic technologies provide the ﬂexibility needed to dy-\nnamically adapt the control model (i.e. the planning model) to different production\nsettings. Thus, this chapter presents the Knowledge-based Control Loop (KBCL)\nwhich proposes an extension to classical plan-based control architectures suitable\nfor artiﬁcial agents in general and robotics in particular. The proposed solution\nrelies on an ontological approach for knowledge classiﬁcation and management\nstructuring information about the capabilities of an agent and the related working\nenvironment (e.g. an industrial robot in a manufacturing environment). This chap-\nter describes how the knowledge of the agent is structured and how such knowledge\ncan be exploited to dynamically generate a timeline-based planning model used to\nplan and executive the activities of the agent.\n7.1\nFlexible Plan-based Control Architectures\nThe integration of knowledge reasoning and planning is today critical. Indeed, the\nintegration of these two technologies involves the manipulation of symbolic infor-\nmation at different levels of abstraction and its translation into different structures\nfor controlling the state of the different components of the agent and, consequently,\ntheir interaction with the environment.\nDespite the variety of uses of ontologies in robotic applications, the organi-\nzation and management of the information needed to act at run-time remains an\nopen problem. This is a challenging problem to face in order to develop adaptive\nautonomous robots. The pursued solution aims at integrating knowledge reasoning\nand planing techniques in order to provide the control process with the ﬂexibility\nneeded to dynamically adapt the control model to the actual state of the system and\nthe environment. The proposed approach relies on two elements: a foundational\nontology which organizes the information, and control process which continuously\nupdates data and manages the ﬂow of information needed to plan and execute ac-\n119\n\nKnowledge-based Control Loop for Flexible Controllers\ntivities of the agent.\nThe ontology deﬁnes the structure of the general information the ﬂexible con-\ntrol module must deal with. The ontology provides a semantics for the concepts\nand the general properties characterizing the application domain. The control pro-\ncess leverages the ontology to generate and manage the knowledge of the speciﬁc\nagent to control. Speciﬁcally, the ontology guides the interpretation of data con-\ncerning the agent and the environment, and allows the control process to dynam-\nically instantiate such information into a Knowledge Base (KB) which describes\nthe speciﬁc capability of the agent and the speciﬁc working environment. On the\nbasis of the obtained KB, the control process can dynamically generate the plan-\nning model tailored to the actual state of the the actual state of the agent and the\nrelated working environment. Then, the control process continuously monitor the\nagent and the environment in order to maintain the KB and also the control model\nupdated.\n7.1.1\nThe Manufacturing Case Study\nThe ﬂexible control architecture described in this chapter has been designed in\norder to work in the context of a pilot case from the GECKO project [Borgo et al.,\n2014a]. The pilot case consists in a Reconﬁgurable Manufacturing System (RMS)\nfor recycling Printed Circuit Boards (PCB). The plant is composed of different\nmachines for loading/unloading, testing, repairing and shredding of PCBs and of\na conveyor system that connects them. The conveyor is implemented through a\nReconﬁgurable Transportation System (RTS) composed of a set of reconﬁgurable\nmechatronic components, called Transportation Modules (TM), see Fig. 7.1. The\ngoal of the plant is to analyze defective PCBs, to automatically diagnose their faults\nand, depending on the type of the malfunctions, attempt an automatic repair or send\nthem to waste.\nThe proposed agent architecture is wrapped around each of the TMs hence\nits functionalities are introduced with more details. Each of the TMs combines\nthree Transportation Units (TUs). The units may be unidirectional or bidirectional,\nwith bidirectional units enabling also movements from side to side (cross-transfers)\nfrom/to other TMs, see Fig. 7.1. The TM can support two main transfer services,\nforward and backward, and zero to many cross-transfer services. Different con-\nﬁgurations can be deployed varying the number of cross-transfers components and\nthus enabling multiple I/O ports. TMs can be connected back to back to form a set\nof different conveyor layouts.\n120\n\nKnowledge-based Control Loop for Flexible Controllers\nFigure 7.1: A picture of a Transportation Module (on the left) of the RTS and two possible\nconﬁgurations (on the right)\nThe manufacturing process requires each PCB to be loaded on a ﬁxturing sys-\ntem (a pallet) in order to be transported by the TMs and processed by the various\nmachines of the RMS. The transportation system can move one or more pallets\n(i.e., a number of pallets can simultaneously traverse the system) and each pal-\nlet can be either empty or loaded with a PCB. At each point in time a pallet is\nassociated with a given destination and the RTS allows for a number of possible\nrouting solutions. The next destination of a pallet carrying a PCB can change over\ntime as operations are executed (e.g., by the test station, the shredding station, the\nloading/unloading cell). The new destination is available only at execution time.\nThe GECKO proposal was to realize a distributed control infrastructure com-\nposed by a community of autonomous agents [Borgo et al., 2014a] able to cooperate\nin order to deﬁne the paths the pallets must follow to reach their destinations. Thus,\nthese paths are to be computed at runtime, according to the actual status and the\noverall conditions of the shop ﬂoor, i.e.. no static routes are used to move pallets.\nThe decisions of the coordination algorithm [Carpanzano et al., 2016] act as goal\ninjection for the planning mechanism of each agent. Hence according to our pur-\nsued abstraction, the plant is a set of TMs endowed with independent capabilities\nto carry on their goals, by analyzing the current situation, synthesizing a planning\ndomain and problem, then planning and executing the plan for such goals.\nIt is worth observing that a plan-based controller can endow an agent with the\ndesired autonomy (i.e., deliberative capabilities), but given the particular dynamic\nnature of RTSs it does not guarantee a continuous control process capable to face all\n121\n\nKnowledge-based Control Loop for Flexible Controllers\nthe particular situations/conﬁgurations. Indeed it is not easy (or hardly possible)\nto capture all the dynamics of the production environment in a unique planning\ndomain. The speciﬁc capabilities of a TM in the RTS are affected by many factors,\ne.g., a partial failure of the internal elements of a TM, a reconﬁguration of the RTS\nplant or maintenance activities of some TMs of the plant. Thus, it is not always\npossible to design a plan-based controller which is able to efﬁciently handle all\nthese situations. The higher is the complexity of the planning domain the higher is\nthe time needed to synthesize the plans and the latency of the control architecture\nmust be compatible with the latency of the plant.\nThus, the key direction in GECKO project has been the one of endowing the\nplan-based controller of a TM (i.e. an agent) with a knowledge reasoning mech-\nanism capable to build the actual state of the production context by dynamically\ninferring the actual capabilities of the TM with respect to the detected conﬁgura-\ntion of the plant. In this way, the plan-based controller can automatically generate\nand continuously maintain updated the timeline-based model of the TM according\nto the inferred knowledge.\n7.1.2\nThe Use of Ontologies in Manufacturing\nIn robotics and more generally in manufacturing, the use of ontologies is cru-\ncial to improve the adaptability and the ﬂexibility of classical approaches [Turaga\net al., 2008]. In several works, ontologies have been exploited to design more au-\ntonomous, ﬂexible, adaptive and proactive artiﬁcial agents. Since researchers have\napplied ontologies to solve or at least mitigate a variety of problems, applications\ndiffer in their assumptions and goals.\nIn [Suh et al., 2007], a Robot knowledge framework (OMRKF) is exploited,\nOMRKF contains a series of ontology layers, includinga robot-centered and a\nhuman-centered ontology. Beside a perception layer, needed for the sensory data,\nthe system is composed by an object layer (model), a context layer and an activity\nlayer. The framework lacks of a foundational approach as can be seen in the object\nclassiﬁcation where, for example, the \"living room\" is classiﬁed as a space region\nand not as the role of the region (the problem becomes clear by observing that a\nregion of space is ﬁxed while the living room can be located in different parts of\nthe building at different times, and can even disappear from the building).\nRelatively to the connection between the KB and the planning module, the\nwork [Hartanto and Hertzberg, 2008] exploits a model ﬁltering approach based on\na Hierarchical Task Network (HTN). The agent’s knowledge of the environment\n122\n\nKnowledge-based Control Loop for Flexible Controllers\nis stored in a ﬁxed ontology and some ﬁlters on this knowledge are set up. Given\na planning task, the system selects one of the ﬁlters to isolate a suitable subset\nof the system’s knowledge and uses this subset to constrain the plan by deleting\nnon-reachable constants. While this technique can be efﬁcient in terms of plan\nadaptation, the knowledge is only ﬁltered, thus cannot be augmented nor modiﬁed,\nnot even contextualized to the speciﬁc problem.\nOther research projects, like KnowRob [Tenorth and Beetz, 2009] and ORO\n[Lemaignan et al., 2010] focus on learning and symbol grounding and use on-\ntologies for obtaining an action-based knowledge representation able to support\ncognitive functionalities. At the ontological level, these knowledge systems show\nproblems similar to those discussed earlier (e.g. functionality is confused with ac-\ntivity so that it is not possible to \"discover\" new ways to perform a function).\n7.2\nKnowledge and Plan-based Control in a Loop\nThe Knowledge-based Control Loop (KBCL) represents the envisaged ﬂexible\ncontrol architecture which integrates a knowledge processing mechanism with plan-\nning and execution in order to dynamically generated and adapt the timeline-based\nmodel needed to actually control an agent (i.e. a TM of the plant in the GECKO\nproject). Figure 7.2 shows the key integration of distinct cognitive functions com-\nposing the architecture. At a higher abstraction, the ﬁgure shows the integration of\ntwo \"big boxes\" called here Knowledge Manager, that contains the know-how of\nthe agent, and Deliberative Controller that represents the EPSL-based controller\nwhich plans and executes the activities of the agent. To make the whole idea op-\nerational we need to open the boxes and describe what is needed to allow the two\nfunctionalities to work together.\nThe goal of KBCL is to have a coherent and continuous ﬂow of information\nfrom the Knowledge Manager to the Deliberarive Controller and to extend the\ncapabilities of the overall system by exploiting reasoning capabilities. Following a\ncareful analysis of the reasoning needs, the Knowledge Manager relies on a suited\nontology which models the general knowledge of manufacturing environments.\nThe ontology contains (i) a classiﬁcation of relevant information in three distinct\nContexts – namely Global, Local and Internal (see later) – and (ii) a Taxonomy of\nFunctions which classiﬁes the set of functions the agents can perform according to\ntheir effects in the environment (see later).\nThe Knowledge Manager exploits the ontology to build and manage the KB of\n123\n\nKnowledge-based Control Loop for Flexible Controllers\nDelibera(ve\t\r  Controller\t\r  \n2. MODEL GEN. \nMechatronic\t\r  Module/Controller\t\r  \nDiagnosis\t\r  Module\t\r  \nPlanning\t\r  Framework\t\r  \nPlanner\t\r  \nPlanning\t\r  \nProblem\t\r  \nPlanning\t\r  \nDomain\t\r  \n3. PLAN \nExecu6ve\t\r  System\t\r  \n1. SETUP \n5. RECONF \n4. EXEC \nKnowledge\t\r  Manager\t\r  \nRule-­‐based\t\r  \t\r  \nInference\t\r  Engine\t\r  \nRules\t\r  \nKnowledge\t\r  Base\t\r  \nContexts \nTaxonomy of  \nFunction \nFigure 7.2: The Knowledge-based Control Loop\nthe particular agent to control. The KB represents an abstract description of the\nstructure and the capabilities of the agent and also of the production environment\n(from the agent’s point of view). Namely, the KB represents the \"instantiation\" of\nthe general knowledge to the particular agent to control. In this context the Rule-\nbased Inference Engine is a speciﬁc module which is responsible for processing KB\ninformation by inferring additional knowledge about the functional capabilities the\nagent is actually able to perform (see later for further details). Thus, given a TM of\nthe RTS of the case study, the KB contains information concerning the devices that\ncompose the TM (e.g. the cross transfers, the conveyor engines, the port sensors),\nthe set of other TMs and/or working machines directly connected (i.e. the set\nof collaborators) and information concerning the whole production environment\nfrom the agent perspective (e.g. the topology of the shop ﬂoor). Then the Inference\nEngine analyzes the structure of the TM and its collaborators in order to add to the\nKB information about the set of transportation functions the TM is actually able to\nperform.\nThe Planning Framework provides timeline-based deliberative features relying\non the planning model generated from the KB to actually control the mechatronic\ndevice. More speciﬁcally, it is a wrapper of the planning and execution system\nemployed to provide deliberative capabilities. It is responsible to integrate KB in-\nformation with planning by automatically generating the model of the mechatronic\n124\n\nKnowledge-based Control Loop for Flexible Controllers\ndevice to control. Indeed, planning domain and problem speciﬁcations are dynam-\nically generated from the KB and an off-the-shelf planning and execution system is\nactivated to synthesize signals for the actuators that control the mechatronic device.\nThe Mechatronic Module is the composition of a Control Software and a Mecha-\ntronic Component (e.g., a transportation module, a working machine, etc.). In our\ncase the control software is based on standard reference models (e.g., IEC61499)\nand each mechatronic component is then represented by dedicated hardware/soft-\nware resources encapsulating the module control logic.\nThe Knowledge-based Control Loop (KBCL) represents the overall process\nwhich allows the integration of the elements described above in a unique control\ninfrastructure. The resulting control process enables an agent to dynamically rep-\nresent its capabilities, the detected environmental situation and to infer the set of\navailable functions on which a coherent planning model is generated.\n7.2.1\nThe Knowledge-based Control Loop at Runtime\nThe management of the KB, the generation of the planning domain, the continuous\nmonitoring of the information concerning the agent and the environment, represent\nthe rather complex activities the KBCL process must properly manage at runtime.\nIn this regard, the KBCL process consists of the following phases: (i) the setup\nphase; (ii) the model generation phase; (iii) the plan and execution phase; (iv) the\nreconﬁguration phase.\nThe setup phase generates the KB of the agent by processing the raw data\nreceived from the Mechatronic device through a Diagnosis Module. The resulting\nKB completely describes the structure of the particular module to control, the set of\nTMs the module can cooperate with and the set of functions the module is actually\nable to perform in order to support the production ﬂow. Then, the model generation\nphase exploits the KB of the agent to generate the timeline-based planning model\nthe Deliberative Controller needs to actually control the device.\nWhen the planning domain is ready the planning and execution phase starts,\nand the Deliberative Controller continuously builds and executes plans. During\nthis phase the KBCL process behaves like classical plan-based control systems.\nThe Planning Framework builds the plan according to some tasks to perform. Soft\nchanges in the plan execution are directly managed by the Deliberative Controller,\ne.g. temporal delays of some planned activities. Conversely whenever the Diagno-\nsis Module detects a structural change of the agent and/or of its collaborators e.g. a\ntotal or partial failure of a cross transfer of the TM to control (i.e. Hard changes),\n125\n\nKnowledge-based Control Loop for Flexible Controllers\nthe reconﬁguration phase starts.\nThe reconﬁguration phase determines a new iteration of the KBCL process\ncycle. The KB of the agent is updated by detecting the new state of the mecha-\ntronic device and its production environment as well as inferring the updated set of\nfunctions the TM can perform according to the new state. As before, once the KB\nof the agent is complete, the planning model of the Deliberative Controller is also\nupdated with respect to the new state of the module. It is worth observing that the\nKB and the planning model are updated only when structural changes that impede\nthe execution of the plan are detected.\n7.3\nModeling Knowledge with Ontology and Contexts\nIn a changing environment the agents must coherently share information relevant to\nthe tasks. Thus an ontological analysis allows to build reliable systems that exploit\ndifferent information types and contexts. The aimed generality lead to a structure a\nthat is neither tailored to a speciﬁc type of agent nor to a speciﬁc type of situation.\nIt is not based on an information model at the enterprise or shop ﬂoor level nor\ndeveloped for some speciﬁc type of action. The result is a general mechanism to\ndynamically generate a high-level description of agent’s capabilities and system’s\nsituations.\nThe ﬁrst result of this analysis is the separation of two layers of information:\norganizational knowledge and factual knowledge. The organization knowledge is\nthe foundational knowledge, i.e., the knowledge about the basic assumptions in\nthe domain like the notion of object, agent, production, etc., including their re-\nlationships. This knowledge ﬁxes what kind of entities, events and interactions\nthere can be in general. Factual knowledge, instead, identiﬁes how the actual sce-\nnarios is, out of all the possible conﬁgurations: which objects are presents and\nwhere, which actions are executed and by which agent, which changes occur and\nto which object. Factual knowledge can be extended (without changing the founda-\ntional knowledge) as needed, e.g., to include knowledge about new devices (tools,\nmachines) or changes in the shop ﬂoor layout. Changes in these two parts of the\nknowledge framework follow different principles and have different consequences.\nBy keeping them apart, we can make them interoperate covering all the knowledge\nneeded in the production systems [Chandrasegaran et al., 2013].\nFor the organizational knowledge the proposed approach relies on the founda-\ntional ontology DOLCE the Descriptive Ontology for Linguistic and Cognitive\n126\n\nKnowledge-based Control Loop for Flexible Controllers\nQ\nQuality\nPQ\nPhysical\nQuality\nAQ\nAbstract\nQuality\nTQ\nTemporal\nQuality\nPD\nPerdurant\nEV\nEvent\nSTV\nStative\nACH\nAchievement\nACC\nAccomplishment\nST\nState\nPRO\nProcess\nPT\nParticular\nR\nRegion\nPR\nPhysical\nRegion\nAR\nAbstract\nRegion\nTR\nTemporal\nRegion\nT\nTime\nInterval\nS\nSpace\nRegion\nAB\nAbstract\nSet\nFact\n…\n…\n…\n…\nTL\nTemporal\nLocation\nSL\nSpatial\nLocation\n…\n…\n…\nASO\nAgentive\nSocial Object\nNASO\nNon-agentive\nSocial Object\nSC\nSociety\nMOB\nMental Object\nSOB\nSocial Object\nF\nFeature\nPOB\nPhysical\nObject\nNPOB\nNon-physical\nObject\nPED\nPhysical\nEndurant\nNPED\nNon-physical\nEndurant\nED\nEndurant\nSAG\nSocial Agent\nAPO\nAgentive\nPhysical\nObject\nNAPO\nNon-agentive\nPhysical\nObject\n…\nAS\nArbitrary\nSum\nM\nAmount of\nMatter\n…\n…\n…\n…\nFigure 7.3: The DOLCE taxonomy of particulars\nEngineering [Masolo et al., 2002]. This is a domain-independent top-level ontol-\nogy that has been exploited at different levels in the engineering and industrial do-\nmains, e.g., [Borgo, 2014, Prestes et al., 2013, Borgo and Leitão, 2004]. DOLCE\nfurnishes the basic structure of the knowledge the KBCL relies on and it will be\nenriched with domain knowledge, for instance adding the notions of artiﬁcial agent\nand engineering function. The knowledge framework available to an agent, will be\nan extension of this ontological system. Since DOLCE is based on a ﬁrst-order\nlanguage with formal semantics, the ontology and the resulting knowledge base\ncan be exploited via automatic reasoning\n7.3.1\nThe DOLCE Ontology\nThe DOLCE ontology is a formal system built according to an explicit set of philo-\nsophical principles that guide its use and extension [Masolo et al., 2002]. DOLCE\nfocuses on particulars, as opposed to universals. Roughly speaking, a universal is\nan entity that is instantiated or concreted by other entities (like the property \"being\na tool\" or \"being a production process\"). A particular, an element of the cate-\ngory PARTICULAR, is an entity that is not instantiated by other entities (like Eiffel\nTower in Paris or Barack Obama). PARTICULAR includes physical entities, abstract\nentities, events and even qualities as shown below.\nThe DOLCE ontology formalizes the distinction between things like a car and\nan organization (this category is called ENDURANT), and events like transporting\nby means of a car and resting (category PERDURANT), see 7.3. The term \"object\"\nis used in the ontology to capture a notion of unity as suggested by the partition of\n127\n\nKnowledge-based Control Loop for Flexible Controllers\nthe category PHYSICAL ENDURANT (a subcategory of ENDURANT) into categories\nAMOUNT OF MATTER, like the plastic with which a water bottle is made, PHYS-\nICAL OBJECT, like a car, and FEATURE. Features are entities that existentially\ndepend on other objects, e.g., a bump on a road or the workspace for a robotic\narm. There are other two subcategories of PHYSICAL OBJECT, namely, AGENTIVE\nPHYSICAL OBJECT, e.g. a person, and NON-AGENTIVE PHYSICAL OBJECT, e.g.,\na drill.\nDOLCE also provides a structure for individual qualities (elements of the cat-\negory QUALITY like the weight of a given car), quality types (weight, color and the\nlike), quality spaces (spaces to classify weights, colors, etc.), and quality positions\nor qualia (informally, locations in quality spaces). These, together with measure\nspaces (where the quality positions get associated to a measure system and to num-\nbers), are important to describe and compare devices and processes. The exact list\nof qualities may depend on the entity: shape and weight are usually taken as qual-\nities of physical endurants, duration and direction as qualities of perdurants. An\nindividual quality, e.g., the weight of an hammer, is associated with one and only\none entity; it can be understood as the particular way in which the hammer instan-\ntiates the general property \"having weight\". That individual weight quality is what\ncan be measured when the hammer is put on a scale (if we put another hammer, no\nmatter how similar, another individual quality would be measured, i.e., that of the\nsecond hammer even if the scale indicates exactly the same value). The change of\nan endurant in time is explained in DOLCE through the change of some of its in-\ndividual qualities. For example, with the substitution or damaging of a component,\nthe value of the weight quality of a car may change.\nDOLCE’s taxonomic structure is depicted in Figure 7.3. Each node in the\ngraph is a category of the ontology. A category is a subcategory of another if the\nlatter occurs higher in the graph and there is an edge between the two. PARTIC-\nULAR is the top category. The direct subcategories of a given category form a\npartition. In the graph, dots indicate that not all the subcategories of that category\nare listed. Some relations are particularly relevant in this context, e.g., the part-\nhood relation: \"x is part of y\" (written: P(X,Y)), with its cognates the proper part\n(written: PP(X, Y)) and overlap relations (written: O(X, Y)). It applies to pairs\nof endurants (e.g., the joint is part of the robotic arm) as well as to paris of per-\ndurants (e.g., riveting is part of the assembling process). On endurants parthood\nhas an additional temporal argument since and endurant may loose or gain parts\nthroughout its existence (e.g., after substituting a switch in a radio, the old switch\n128\n\nKnowledge-based Control Loop for Flexible Controllers\nis not part of the radio). Another important relation is constitution, indicated by K:\nK(X, Y, T) stands for \"entity x constitutes y at time t\", e.g., the amount of iron x\nconstitutes the robot y at time t (this relation allows to say that part or all the iron\nx may be substituted over time without changing the identity of robot y like when\nsubstituting a worm component).\n7.3.2\nOntological interpretation of Agents and their Environment\nRecently there has been an increasing interest in the ontological modeling of arti-\nﬁcial agents, and robots in particular [Prestes et al., 2013], which led to an IEEE\nstandard (ORA – Ontologies for Robotics and Automation). Today’s approaches to\nrobot modeling are interesting but further work si needed. For instance, it is unsat-\nisfactory to take the characterization \"being a robot\" as a role (this is the choice in\nthe IEEE standard ORA) since this implies that robots are such only when active,\ni.e., they appear and disappear by switching them on and off. While this avoids the\nproblem of characterizing the essence of robots, the choice goes against common-\nsense. Robots do not seem to qualify as agentive entities in the strong sense since\nthey lack intentional states, and it is dubious if they even qualify in the weak sense\nin most cases they have only conventional stimulus-response behavior. Up to today,\nany attempt to draw the line between artefactual tools and robots has met important\ncriticisms. The following sections propose an extension of the DOLCE ontology\nto include robots, robotic parts and tools. The goal of this extension is to start\nfrom the notions of artefact and of agent, as introduced in foundational ontologies,\nand to propose a way to descriminate among types of artefacts as needed to model\nindustrial scenarios.\nOntological speaking, following the analysis in [Borgo and Vieu, 2009], a\nrobot is an artefact: it is intentionally selected (via construction) and has attributed\ntechnical capacities. Technical capacities can vary considerably depending on the\nrobots: they can be quite limited, like in ant robots, or ﬂexible and multipurpose\nlike in industrial or humanoids robots. Since the focus is on industrial settings,\nthus on robotic arms, transportation modules and the like, the modeled robots are\nactually technological artefacts [Borgo et al., 2014b]: they are manufactured by\nfollowing precise production plans and selected via dedicated quality tests. Thus,\nfrom the formal viewpoint industrial robots can be classiﬁed as (technological)\nartefacts i.e., elements of the ARTEFACT subcategory of NON-AGENTIVE PHYSI-\nCAL OBJECT [Borgo and Vieu, 2009].\nThe typical robots in the production scenarios are rational, reactive and may\n129\n\nKnowledge-based Control Loop for Flexible Controllers\npresent some degree of autonomy. Today, they are rarely adaptive and embedded\nalthough these are desirable features. They can also be proactive: they have goals,\ntypically provided by the production system to which they belong, and can some-\ntimes choose, or at least reschedule, plans to optimize their achievements. In short,\nthese robots are artefacts whose behaviors resemble agents’ behavior for the same\ngoal(s). Since this behavior is expected from them, we propose to see a robot as\nan artefact whose attributed quality is to behave agent-like. It is important to point\nout that this modeling choice keeps agents and robots apart: a member of the latter\ngroup just mimics agents. The behavior can range from basic stimulus-response\nactions to activities controlled by sophisticated planning and goal adaptations, de-\npending on what kind of agentivity the robot can behaviorally simulate. This is\ndeﬁnitely acceptable for today’s robots and it does not exclude that future genera-\ntions of robots might be considered as full-ﬂedge agents.\nThe rest of the section refers to robots as agents. The symbol ROBOT is used for\nthe predicate \"being a robot\" and BehSp for the generic space of behaviors. Speciﬁ-\ncally, using the language of DOLCE from [Masolo et al., 2002, Borgo and Masolo,\n2009, Borgo and Vieu, 2009], it is possible to formally model the ontological status\nof robots as follows:\nROBOT(r) →ARTEFACT(r)\n(7.1)\nROBOT(r) ∧AttribCap(a)∧\nqt(a, r) ∧ql(v, a, t) →Loc(v, BehSp)\n(7.2)\nThe ﬁrst formula says that a robot is an artefact. The second states what dis-\ntinguishes a robot from other artefacts: the capacity attributed to the robot (At-\ntribCap(a) ∧qt(a,r)) has values (ql(v, a, t)) that belong to the space of behaviors\n(Loc(v, BehSp))1.\nRobot’s parts are themselves artefacts, thus elements of the ARTEFACT cate-\ngory. These are typically not robots, so their attributed qualities are of different\ntypes. The main distinction here is between the parts that are components, i.e. that\nconstitute the robot like the engines that move the robotic arm structure and the\nstructural pieces that are moved by the engines; and the parts that are tools used by\nthe robot like the different types of gripper that can be substituted depending on the\ntask to execute. These types of parts are isolated for their functional or structural\n1The existence of quality a is enforced by formula 7.1 and the theory [Borgo and Vieu, 2009].\nThe characterization of the space of behaviors is stil under investigation\n130\n\nKnowledge-based Control Loop for Flexible Controllers\ncontribution. There are, of course, also arbitrary parts like the upper half of the\nskeletal frame, which do not have special properties or functionalities and thus are\nnot relevant in terms of knowledge and planning.\nComponents (tools) can be in an active/inactive (available/non-available) state\nfor the robot. Sensors are listed among the components but the proposed charac-\nterization does not distinguish between sensors and actuators since these are seen\nas roles of the agent’s components (a drill can play both of them at the same or at\ndifferent times). Finally, an object that is a component is such until substituted (or\ndismantled) while a tool may remain such even if substituted.\nIn the case of agents, the environment represents the area of interest in which\nthe agent could act. For artiﬁcial agents, the environment might also include the\nrequirements and speciﬁcations about the software components and their devel-\nopment. Since the reasoning mechanism deals with languages and software con-\nstraints in terms of contexts, the considered notion of environment focuses on the\nnotion of location. Thus, at each point in time, the robot’s environment is described\nin terms of robot’s location including the elements the location contains plus en-\ntities that, even though not in the location, can interact (positively or negatively)\nwith the robot’s activities and goals.\nThis view is fairly general and assumes that the environment depends on the\nrobot’s features as well as on the features of the other entities. It is important to\npoint out that the environment can change whenever the robot or its location or the\nentities there change. In the case of production scenarios, the robot’s environment\ncan be identiﬁed with the collection of physical entities that are within a certain\nrange from the robot (where the range may be bounded by physical barriers like\nﬂoor, walls, ceiling, fences, etc). The environment is not necessarily limited to a\nprecise region of space; it includes also entities with which the robot can interact\nin some ways (e.g., via wireless communication). In ontological terms, the envi-\nronment is a compound physical object composed by all the physical objects that\nare within the interaction range (workspace) of the robot. The location of the en-\nvironment corresponds to the location of the objects in the environment plus the\nlocations reachable by the robot itself 1.\n1The location is ﬁxed for robots like robotic arms, it is parametric (in particular, it may depend\non the task) for mobile robots\n131\n\nKnowledge-based Control Loop for Flexible Controllers\n7.3.3\nOntology and Engineering of Functions\nThe classiﬁcations of the robots, the physical entities that may interact with them\nand their environments take care of the \"static\" part of the problem. Since a robot\nis supposed to act in order to reach its goals, it must also have the conceptual ma-\nchinery to know what it can do and how, thus to plan its actions. In this regard,\nreasoning on (engineering) functions is unavoidable. The formalization of func-\ntions in robotics is rarely addressed and is too often confused with the notion of\naction, i.e., the performance of a function.\nTo overcome this problem, the proposed approach extends the DOLCE ontol-\nogy with an ontology of high-level functions. This function ontology is integrated,\nvia DOLCE, with the ontology of the robot and robot’s parts making it possible\nto model what a robot can do and how. Speciﬁcally, the interpretation of functions\nrelies on the notion of function-as-effect (see Figure 7.4) which has been adapted\nborrowing from well-known functional approaches in engineering design like the\nFOCUS/TX [Kitamura et al., 2011] (for the distinction \"what to\" vs. \"how to\" and\nthe notion of behavior), the Functional Basis [Pahl et al., 2007, Hirtz et al., 2002]\n(for the idea of a function list), and the Function Representation [Chandrasekaran\nand Josephson, 2000] (for the distinction between environment-centric and device-\ncentric function). The guiding idea is to make it possible the identiﬁcation of the\nhigh-level function (or sequence of functions) that need to be executed to reach a\ngiven goal. For this, it can be taken into account the difference between the actual\nstate and the desired state, and identify the changes to be made. From this infor-\nmation, the robot can travel the taxonomy to identify the effects of the high-level\nfunctions and ﬁnd a suitable combination.\nFigure 7.4 show the top-level ontological functions organized in ﬁve brenches:\nfunctions to collect information, functions to change the operand’s qualities, func-\ntions to change the qualityrelationships, and functions to share information. For\ninstance, \"reclassify\" stands for the function to change the classiﬁcation of an\noperand, e.g. when, after a test, a workpiece is classiﬁed as malfunctioning; \"change-\nover\" applies when, e.g., a robot acts on itself to activate/deactivate some com-\nponent; \"channel\" stands for the moving of an operand (change of its location);\n\"stabilize\" for maintaining relational parameters like when tuning electronic com-\nponents to regulate the input-output relationship; \"sense\" for the operand testing\nfunction, i.e., to acquire information without altering the status or the qualities of\nthe operand; ﬁnally, \"send\" stands for the function to output information like a\nsignal that a workpiece is going to be transferred or that a failure occurred.\n132\n\nKnowledge-based Control Loop for Flexible Controllers\nFUNCTION\n(as effect)\nACTION\nTEST\nSENSE\nchange of \noperand(s)\nchange on \nqualities\nchange on \nrelations\ninformation \ncollection\ninformation\nsharing\nCOMMUNICATION\nSEND\nRECEIVE\nCONVERT\nBRANCH\nJOIN\nCHANGE \nOVER\nRECLASSIFY\nCHANNEL\nCHANGE\nMAGNITUDE\nSTORE\nCOLLECT\nRELEASE\nSTABILIZE\nINCREASE\nDECREASE\nFigure 7.4: The function ontological taxonomy and its rationale\nOf course, this information is not enough since it would model just the ideal ca-\npacities of the robot. Aiming to have a robot adapting its plan at run-time, we have\nto model the actual capacities of the robot, which implies to take malfunctioning\nand/or missing parts or even deteriorated behaviors into account. This information\ndepends on the capacities of self-inspection built-in in the robot as well as on the\npossibility to compare the ideal action’s descriptions and the actual performances.\n7.3.4\nContext-based Characterization\nAn ontology is a conceptual tool used to structure information. Ontologies deal\nmainly with necessary information like the properties that an object must manifest\n(shape, weight, mass, etc) or the types of event (states, actions, processes and son\non). Factual information, being information that depends on contingent data (like\nspatio-temporal location, agent’s setting, goals, etc), is generally characterized at\nthe level of knowledge-bases. While this distinction might not be fully justiﬁed\n(and not even sharp), it remains important not to structure the ontology relying\non factual knowledge. This principle is rarely recognized in applications and in\nparticular in the development of ontologies for industrial application.\nThe distinction between necessary and contingent information concerns only\nthe development of the ontology structure: it is important that factual information\nﬁnds its place in the factory information system. This allows the system to classify\nand reason on factual information, for example, to understand the actual scenario\nand possible evolutions, to evaluate optimal production plans out of those that are\n133\n\nKnowledge-based Control Loop for Flexible Controllers\nactually possible, and even to establish the status of the resources or maintenance\nschedule. To act in real and evolving scenarios, factual information is thus essen-\ntial. In the proposed approach, factual information is included in the KB (built on\ntop of the ontology) and is organized into main categories called contexts. Con-\ntextualization enables to manage factual information with an ontologically sound\napproach. It gives also an advantage at the reasoning level: it allows to differenti-\nate types of information depending on their usefulness in reasoning on a situation\nor task. After an ontological analysis based on [Borgo, 2007, Borgo and Masolo,\n2009], it is possible to identify three contextual models dedicated to factual knowl-\nedge, and use them with the ontological framework. In particular, these contexts\nprovide the time-dependent information needed to select how to execute high-level\nfunctions in the actual scenario.\nThe three context types are called global, local and internal, respectively. The\nglobal context collects information the agent cannot control nor modify like the\nshared language of the system, the agents present in the system, the system’s per-\nformance parameters. The local context collects information on the relationship\nbetween the agent and its neighbor elements (typically the human and artiﬁcial\nagents directly interacting with it), thus providing a local view of the topological\nsetting. Finally, the internal context collects the information the agent has about\nitself as well as its capabilities towards itself (change-over) and towards the envi-\nronment (communication and manipulation) [Borgo et al., 2015].\n7.3.5\nApplying Ontology and Contexts to the Case Study\nGiven a particular application like the manufacturing scenario of the case study, it\nis necessary to deﬁne the general knowledge the KBCL process must deal with\nin order to dynamically infer the speciﬁc capabilities of an agent and adapt the\ncontrol model accordingly. Thus, the DOLCE ontology has been extended with\nthe type of information needed by applying the context-based and the functional\ncharacterization described above.\nBroadly speaking, the extended ontology aims at characterizing the knowledge\nconcerning the general structure of a TM of the plant, the related working envi-\nronment and the general functional capabilities of TMs in such a context. This\ninformation represents the general knowledge (i.e. the TBox) a KBCL process in-\nstantiates according to the speciﬁc features of the TM to be controlled, in order to\ngenerate the envisaged KB of the TM (i.e. the ABox).\nFigure 7.5 shows the extension of the DOLCE taxonomy of particulars with\n134\n\nKnowledge-based Control Loop for Flexible Controllers\nFigure 7.5: Extension of DOLCE ontology\nrespect to the NON-AGENTIVE PHYSICAL OBJECT category. According to the\nDOLCE interpretation of artifacts, robots and robot’s parts are modeled as sub-\ncategorires of ARTIFACT, as the taxonomy in Figure 7.3 shows. Robot’s parts can\nbe further distinguished into robot’s components, i.e. parts that constitute the struc-\nture of the robot, and tools. These entities are modeled as subcategories of PART.\nThey represent artifacts with different attributed qualities with respect to robots as\nartifacts. Following DOLCE interpretation, the taxonomy can be extended by in-\ntroducing the PORT, CONVEYOR and CROSS TRANSFER concepts as subcategories\nof COMPONENT category, the concept of TRANSPORTATION MODULE as subcate-\ngory of ROBOT category.\nThe PORT, CONVEYOR and CROSS TRANSFER categories classify the elements\ncharacterizing the internal structure of a TM. The COMPONENT category collects\nthe elements that compose a robot. These components have a SPATIAL LOCATION\nwithin the robot structure (this would not be enforced for tools since they can be\nexternal to the robot). Collaborating components for the Channel function must\nbe spatially connected. In the case of the TM, the internal structure for this kind\n135\n\nKnowledge-based Control Loop for Flexible Controllers\nof functionality is determined by the connections of the components’ locations.\nThe choice of modeling the elements of a TM with different categories rather then\nusing the general COMPONENT category, relies on the different properties these\nelements bring to implement functional capabilities (as it will be described in the\nnext sections). The PORT category models the structural elements that allow a TM\nto connect with other TMs in its local contexts. These elements have a communi-\ncation capacity which allows a TM to send and receive pallets to and from other\nTMs of the plant. The CONVEYOR category models the engine elements that allow\na TM to move pallets. They have a channel capacity which allows TMs to actually\nmove a pallet between two spatial locations connected via that component. The\nCROSS TRANSFER category models engine elements that allow a TM to change its\nphysical conﬁguration. They have a change over capacity which allows a TM to\nchange its internal connections and enable the different paths the pallets can follow\n(internally).\nThe TRANSPORTATION MODULE category characterizes TMs from a func-\ntional point of view. Namely, TMs are modeled as elements fo the ROBOT category\nthat can perform some CHANNEL functions and that have as components some ele-\nments of the PORT category, some elements of the CONVEYOR category and some\nelements of the CROSS TRANSFER category. In the manufacturing environment\nconsidered, elements of the CHANNEL category are functions that classify changes\nin the spatial location quality of an operand (i.e., a pallet). The execution of such\na function changes the location of the pallet from the start location to the end lo-\ncation. The Figure 7.6 shows a graphical representation of the general class axiom\ndeﬁning the TRANSPORTATION MODULE category.\nThe (working) environment of a TM is described in terms of the available col-\nlaborators. A TM collaborates with other TMs and machines of the plant by ex-\nchanging pallets through their connected ports. Thus, the subset of the plant’s\nagents that are directly connected to the TM and with which the TM can actually\nexchange pallets, constitutes the environment of the TM. In such a context, a col-\nlaborator is a relative concept which depends on the particular conﬁguration of the\nTM considered. It represents a relationship between a TM and the directly con-\nnected agents. Thus, the concept of COLLABORATOR is modeled as a role that an\nagent, e.g., another TM, plays according to its local connections.\n136\n\nKnowledge-based Control Loop for Flexible Controllers\nFigure 7.6: The general class axiom for the TRANSPORTATION MODULE category\n7.4\nThe Knowledge-Base Life Cycle\nThe Knowledge Manager module (KM) in Figure 7.2 is responsible for managing\nthe lifecycle of the KB within the KBCL process. In the speciﬁc manufacturing\ncase study, the KB models the particular TM to be controlled by specifying its\ninternal structure, its connections with other TMs and the related functional capa-\nbilities. The management of the KB relies on a knowledge processing mechanism\nimplemented by means of a rule-based inference engine which leverages a set of\ninference rules to build the KB of the agent.\nThe knowledge processing mechanism dynamically builds the KB elaborating\nraw data received from the Diagnosis Module and infers knowledge concerning\nthe structure, the working environment and the functional capabilities of the agent.\nAs Figure 7.7 shows, this mechanism involves two reasoning steps: the (i) the low-\nlevel reasoning step, and the (ii) high-level reasoning step. Speciﬁcally, these two\nsteps iteratively reﬁne the KB by combining a set of dedicated inference rules with\nthe general knowledge of contexts and functions of the described ontology.\nThe ﬁrst reasoning step, called the low-level reasoning, aims at characterizing\nthe TM in terms of the components that actually compose the module (e.g., the\nports, conveyors, etc.) and its collaborators. It leverages the internal and local\n137\n\nKnowledge-based Control Loop for Flexible Controllers\nKnowledge\t\r  Processing\t\r  Mechanism\t\r  \nkb0 \nMechatronic\t\r  \nModule/Controller\t\r  \nDiagnosis\t\r  Module\t\r  \nd: sensor  \ndata \nkb: agent's  \nknowledge \nLow-­‐level\t\r  Reasoning\t\r  \nContexts\t\r  \nClassiﬁca.on\t\r  Rules\t\r  \nHigh-­‐level\t\r  Reasoning\t\r  \nTaxonomy\t\r  \t\r  \nof\t\r  Func.ons\t\r  \nCapability\t\r  \t\r  \nInference\t\r  Rules\t\r  \nFigure 7.7: The knowledge processing mechanism\ncontexts of the ontology as well as the classiﬁcation rules to generate the initial in-\nstance of the KB which describes the structure of the agent and the related working\nenvironment. Thus, this initial KB describes the agent in terms of its internal and\nlocal contexts.\nThe second reasoning step, called the high-level reasoning, starts from the KB\nelicited after the previous step and generates further knowledge concerning the\nfunctional capabilities of the agent. Speciﬁcally, the high-level reasoning step re-\nlies on the taxonomy of functions and a set of domain-dependent inference rules,\ncalled capability inference rules, to complete the knowledge processing mecha-\nnism. The KB the high-level reasoning starts from, encodes the particular internal\nand local context of the agent. The inference mechanism can infer the set of func-\ntions the agent can actually perform by analyzing its structure and its working\nenvironment.\nThe output of the second reasoning step (and the overall knowledge processing\nmechanism), is the ﬁnal KB which encodes a complete description of the structure\nof the agent, an interpretation of the working environment from the agent per-\nspective and a description of the related functional capabilities of the agent. Such\nknowledge is then exploited in the KBCL process to generate the plan-based con-\ntrol model. The next two subsections provide a more detailed discussion of the two\nreasoning steps constituting the knowledge processing mechanism.\n138\n\nKnowledge-based Control Loop for Flexible Controllers\nINTERNAL CONTEXT\nLOCAL CONTEXT\nGLOBAL CONTEXT\nmodule-t3\nport-f\nport-b\nconveyor\nmodule-t1\nhasLoc\nhasLoc\nhasLoc\nhasPart\nhasPart\nhasPart\nconnection\nconnection\nconnection\nconnection\nconnection\nhasLoc\nmodule-t2\nhasLoc\nmodule-t7\nhasLoc\nmodule-t4\nconnection\nconnection\nFigure 7.8: Raw data received from the Diagnosis Module\n7.4.1\nThe Low-Level Reasoning Step\nThe low-level reasoning step is responsible for inferring information concerning\nthe internal and local contexts of the TM. Namely, the result of this inference step\nis an initial KB describing the operating devices that compose the TM (i.e., the\ncomponents) and the available collaborators. It builds an initial version of the KB\nby classifying data received from the Diagnosis Module on the basis of contexts\ncategorization.\nInput data consists of a set of individuals representing information about the\nparts that compose the TM, their connections and their capabilities. Figure 7.8\nprovides a (partial) graphical representation of a possible set of individuals (the\nnodes of the graph) and predicates (the edges of the graph) the knowledge pro-\ncessing mechanism receives from the Diagnosis Module. In particular, the ﬁgure\nshows the different contexts the individuals belong to, the reasoning step leverages\nto provide these data with additional semantics.\nGiven this set of data, the ﬁrst rule the low-level reasoning step applies, aims at\nidentifying the set of operative parts the TM can actually use to perform functions.\nThese set of operative parts are represented as TM’s components. According to the\nontological interpretation of the COMPONENT category, a component is a structural\npart of a robot which has an operative state and may have some functional capabil-\nities. The rule follows this functional interpretation of components and therefore,\n139\n\nKnowledge-based Control Loop for Flexible Controllers\ncan be formally deﬁned as follows:\nROBOT(r) ∧P(p, r)∧\nhasCapacity(p, f) →COMPONENT(p)\n(7.3)\nwhere P(p, r) is a predicate asserting that the part p is a structural element of robot\nr and hasCapacity(p, f) is a predicate asserting that the part p has the functional\ncapacity of performing some function f. According to the ontology, being p a\nstructural part of a robot r, with the capability of performing some function f, it is\npossible to infer that p is an element of the COMPONENT category. Consequently,\nthe predicate COMPONENT(p) is true.\nThe applied ontological approach models the different types of components\nthat may compose a TM as Figure 7.5 shows. These components are modeled\naccording to the different types of functional capabilities they have. Leveraging\nthis interpretation, it is possible to deﬁne two additional rules that infer the speciﬁc\ntype of component a particular part represents by taking into account the type of\nthe associated functional capability:\nROBOT(r) ∧P(p, r)∧\nhasCapacity(p, f) ∧CHANNEL(f) →CONVEYOR(p)\n(7.4)\nROBOT(r) ∧P(p, r)∧\nhasCapacity(p, f) ∧COMMUNICATION(f) →PORT(p)\n(7.5)\nThe rules 7.4 and 7.5 infer conveyor and port components as structural parts of\na robot, that have channel and communication capabilities respectively.\nGiven the components of the TM, the low-level reasoning step is completed by\ninferring the set of collaborators available. Similarly to components, the collabo-\nrators of TM are directly connected TMs of the plant that are in an operative state\nand therefore, can actually exchange pallets with the TM. The rule that allow to\ninfer this information can be formally deﬁned as follows:\nROBOT(r) ∧PORT(p)∧\nhasLoc(p, lp) ∧P(p, r)∧\nhasOpStat(p, active) ∧ROBOT(c)∧\nhasLoc(c, lc) ∧connection(lp, lc) →hasCollab(r, c)\n(7.6)\nwhere connection(lp, lc) is a predicate asserting that the location of the TM’s port\n140\n\nKnowledge-based Control Loop for Flexible Controllers\nport-f\nport-b\nmodule-t1\nhasLoc\nhasOpStat\nhasOpStat\nhasComp\nconnection\nhasComp\nrobot-1\nactive\nrobot-3\nconnection\nhasOpStat\nhasLoc\nhasLoc\nhasLoc\nconnection\nrobot-2\nhasLoc\nhasCollab\nhasCollab\nFigure 7.9: Inferring collaborators of a TM\np is connected with the robot c. Figure 7.9 provides a (simpliﬁed) graphical rep-\nresentation of a possible KB resulting from the application of rule 7.6 (the dotted\narrows represent the inferred properties concerning collaborators).\n7.4.2\nThe High-Level Reasoning Step\nThe high-level reasoning step extends the KB elicited at the previous step to infer\nthe actual capabilities of the TM on the basis of its current status and the current\nproduction environment. Given the information concerning components and col-\nlaborators of a TM, the ﬁrst rule the high-level reasoning step applies, aims at\ninferring the primitive channels the TM can perform according to its internal struc-\nture. Indeed, operative components can be used by a robot to perform functions.\nWith regard to TMs, a (operative) conveyor allows a TM to perform channel func-\ntions. According to this interpretation it is possible to deﬁne a rule to infer the set\n141\n\nKnowledge-based Control Loop for Flexible Controllers\nport-f\nport-b\nconveyor\nmodule-t1\nhasLoc\nhasLoc\nhasLoc\nhasComp\nhasComp\nhasComp\nconnection\nconnection\nchannel-1\ncStart\ncEnd\ncConnect\nhasCapacity\nFigure 7.10: Inferring primitive channels of a TM\nof primitive channels a TM can perform as follows:\nROBOT(r) ∧CONVEYOR(c1)∧\nhasOpStat(c1, active) ∧COMPONENT(c2)∧\nCOMPONENT(c3) ∧hasLoc(c1, l1)∧\nhasLoc(c2, l2) ∧hasLoc(c3, l3)∧\nconnection(l2, l1) ∧connection(l1, l3) →CHANNEL(f)∧\nhasCapacity(r, f)∧\ncStart(f, l2)∧\ncEnd(f, l3)∧\ncConnected(l2, l3)\n(7.7)\nwhere CONVEYOR(c1)∧hasOpStat(c1, active) asserts that c1 is a conveyor com-\nponent of the TM whose operative state is active. Namely, the conveyor c1 is an\noperative component of the Tm and therefore, it can be actually used to perform\nfunctions. Figure 7.10 shows a (simpliﬁed) graphical representation of the KB\nresulting from the application of rule 7.7. In particular, the ﬁgure represents pred-\nicates (the dotted arrows) and the individual (the \"channel-1\" onde) inferred and\nadded to the KB.\nThe rationale of rule 7.7 relies on the functional interpretation of the CON-\nVEYOR category as the set of components that can perform channel functions.\nThus, if an operative conveyor component connects two components of the TM\n142\n\nKnowledge-based Control Loop for Flexible Controllers\nthrough its spatial location, see the clause connection(l2, l1)∧connection(l1, l3)\nin 7.7, then the conveyor can perform a primitive channel function between the\ncomponents’ locations. Moreover, the cConnect(l2, l3) is a transitive predicate\nwhich allows to \"connect\" and compose different channel functions. Indeed, if two\nspatial locations are connected through the cConnect predicate, it means that there\nexists a composition of primitive channel functions that connect them.\nA primitive channel involves components of a TM only. However, the channel\ncapabilities the knowledge processing mechanism aims at inferring are those that\ninvolve the collaborators of a TM. Namely, channel functions that allow a TM to\nexchange pallets with other TMs of the plant. Such channels are called complex\nchannels and can be inferred by applying the following rule:\nROBOT(r) ∧ROBOT(rc1)∧\nROBOT(rc2) ∧hasCollab(r, rc1)∧\nhasLoc(rc1, rl1) ∧hasCollab(r, rc2)∧\nhasLoc(rc2, rl2) ∧PORT(c1)∧\nhasOpStat(c1, active) ∧hasLoc(c1, l1)∧\nPORT(c2) ∧hasOpStat(c2, active)∧\nhasLoc(c2, l2) ∧connection(l1, rl1)∧\nconnection(l2, rl2) ∧cConnect(l1, l2) →CHANNEL(f)∧\nhasCapacity(r, f)∧\ncStart(f, rl1)∧\ncEnd(f, rl2)\n(7.8)\nA key point of the rule 7.8 is that a complex channel function is interpreted\nas the composition of primitive channels the TM can perform internally. This is\na quite ﬂexible and general interpretation of a channel function. If one or more\nparts of a TM stop working (i.e., their operational status changes from active to\ninactive), then the TM will not be able to perform the related primitive channels\nand therefore, the high-level reasoning step will not be able to infer all the complex\nchannels that depends on these parts. Similarly, if new components are added to\nthe TM then, the high-level reasoning step will be able to inter additional primitive\nand also complex channels according to the resulting structure of the TM.\n143\n\nKnowledge-based Control Loop for Flexible Controllers\nrobot-1\nhasLoc\nport-f\nhasLoc\nhasComp\nconnection\nport-b\nmodule-t1\nhasComp\ncConnect\nhasCollab\ncStart\ncEnd\nchannel-f-b\nhasLoc\nhasCapacity\nhasCollab\nconnection\nhasLoc\nrobot-2\nFigure 7.11: Inferring complex channels of a TM\n7.5\nGenerating the (Timeline-based) Control Model\nA key role for the dialogue between the Knowledge Manager and the Delibera-\ntive Controller is played by the Model Generation process (Step 2 in Figure 7.2).\nThe KB resulting from the knowledge processing mechanism provides an abstract\nrepresentation of the capabilities, the structure and the working environment of\nthe agent. The model generation process analyzes the KB to generate the related\ncontrol model as a timeline-based planning speciﬁcation of the agent.\nThe model generation process encodes the hierarchical modeling methodology\ndescribed in Chapter 5 and builds the control model by leveraging the context-\nbased characterization of the KB. The information concerning the global context\nand the taxonomy of function deﬁne the functional state variables that provide a\nfunctional view of the agent as a whole. These state variable describe the high-level\ntasks the agent can perform over time. The internal context contains structural in-\nformation about the agent and therefore it is suited to generate the primitive state\nvariables. These variables describe the behaviors of the physical/logical features\nthat compose the agent. Usually the values of this type of variables directly corre-\nspond to states or actions the related domain features may assume or perform over\ntime. The local context manages information concerning the working environment\nof the agent and therefore it is suited to build the set of external variables of the\nmodel. These variables model the collaborating agents (i.e. the directly connected\nTMs of the plant) whose behavior may affect the capabilities of the agent, even if\nnot directly controllable.\n144\n\nKnowledge-based Control Loop for Flexible Controllers\nAlgorithm 8 The KBCL procedure for generating the planning model\n1: function BUILDCONTROLMODEL(KB)\n2:\n// extract agent’s information and initialize the P&S model\n3:\nagent ←getAgentInformation (KB)\n4:\nmodel ←inititalize (KB, agent)\n5:\n// deﬁne components of the model\n6:\nsvs ←buildFunctionalComponents (KB, agent)\n7:\nsvs ←buildPrimitiveComponents (KB, agent)\n8:\nsvs ←buildExternalComponents (KB, agent)\n9:\n// build the set of task decomposition rules\n10:\nS ←buildSynchronizationRules (KB, agent)\n11:\n// update the P&S model\n12:\nmodel ←update (model, svs, S)\n13:\nreturn model\n14: end function\nAlgorithm 8 describes the overall procedure of the generation process. Broadly\nspeaking, the procedure consists of four speciﬁc procedures that analyze different\nareas of the knowledge about the agent in order to generate different parts of the\ncontrol model. The procedure starts by extracting information related to the agent\nand initializing the P&S model (rows 3-4). According to the hierarchical timeline-\nbased approach described in Chapter 5, a set of functional, primitive and external\nstate variables is generated (rows 6-8). Finally, the hierarchical decomposition of\nfunctional values (i.e. values of functional state variables) is described by means of\na suitable set of generated synchronization rules (row 10). The resulting timeline-\nbased model is then composed and returned as the outcome of the procedure (row\n12-13).\nThus, the buildControModel procedure allows the model generation process to\nautomatically build the timeline-based speciﬁcation by leveraging the knowledge\nabout the agent. As described in [Borgo et al., 2016], every time a change occurs\nin the KB, a new instance of the model generation process is triggered in order\nto generate an updated control model of the agent. The next subsections provide\nsome details about the (sub)procedures the model generation process relies on,\nand provide an example of a possible timeline-based control model that can be\ngenerated for a TM of the plant case study.\n7.5.1\nBuilding State Variables from Contexts\nAlgorithms 9, 10, 11 below describe the information extraction procedures that\nallow the model generation process to build the functional, primitive and external\n145\n\nKnowledge-based Control Loop for Flexible Controllers\nstate variables respectively.\nBuilding Functional Variables\nAlgorithm 9 describes the procedure which builds the functional state variables\nof the timeline-based control model. The buildFunctionalComponents procedure\ngenerates the set of state variables concerning the functional capabilities of the\nagent. The procedure relies on the set of capabilities the knowledge processing\nmechanism has inferred by applying rules 7.7 and 7.8. The procedure generates\na state variable for each function of the taxonomy (see Figure 7.4) the agent can\nperform. Namely, given a particular function f of the taxonomy, if the KB contains\nat least one individual for that function f (i.e., if the knowledge processing mecha-\nnism has inferred at least one way for the agent to perform f), then a state variable\nsv for f is added to the model. The individuals of f in the KB represent all the\npossible implementations of f the agent can perform (i.e., all the capabilities of\nthe agent with respect to f). Thus, for each inferred individual of f the procedure\nadds a value to the related (functional) state variable sv.\nAlgorithm 9 The KBCL sub-procedure for generating functional variables\n1: function BUILDFUNCTIONALCOMPONENTS(KB, agent)\n2:\n// initialize the list of functional variables\n3:\nsvs ←∅\n4:\n// get types of functions according to the Taxonomy in the KB\n5:\ntaxonomy ←getTaxonomyOfFunctions (KB)\n6:\nfor all function ∈taxonomy do\n7:\n// check if the KB contains individuals of function\n8:\ncapabilities ←getCapabilities (KB, agent, function)\n9:\nif ¬ IsEmpty (capabilities) then\n10:\n// create functional variable\n11:\nsv ←createFunctionalV ariable (function)\n12:\n// add a value for each \"inferred\" capability\n13:\nfor all capability ∈capabilities do\n14:\nsv ←addV alue (sv, capability)\n15:\nend for\n16:\n// add created state variable\n17:\nsvs ←addV ariable (svs, sv)\n18:\nend if\n19:\nend for\n20:\nreturn svs\n21: end function\nThe procedure ﬁrst initializes the set of functional state variables of the domain\n(row 3). Then, it reads the taxonomy of function from the KB and, for each func-\n146\n\nKnowledge-based Control Loop for Flexible Controllers\ntion, checks the available capabilities of the agent (rows 6-20). Given a function, if\nthe KB contains at least one capability for that function, then the procedure creates\na functional state variable (rows 9-11). Each capability found in the KB is mod-\neled as a value of the related state variable (rows 12-15). The procedure ends by\nreturning the set of obtained variables.\nBuilding Primitive Variables\nAlgorithm 10 describes the procedure which builds the primitive state variables of\nthe timeline-based control model. The buildPrimitiveComponents procedure gen-\nerates the set of state variables concerning the structural components of the agent.\nThe procedure relies on a functional interpretation of components as elements that\nallow the agent to perform functions. Thus, according to the inference rules 7.3,\n7.4 and 7.5, the components of an agent are modeled in terms of their capabilities.\nThe procedure adds a primitive state variable to the model for each component\nfound in the KB. According to the inference rule 7.7, the values of these variables\nrepresent the primitive functions of the agent.\nAlgorithm 10 The KBCL sub-procedure for generating primitive variables\n1: function BUILDPRIMITIVECOMPONENTS(KB, agent)\n2:\nsvs ←∅\n3:\n// get agent’s operative components\n4:\ncomponents ←getActiveComponents (KB, agent)\n5:\nfor all component ∈components do\n6:\n// check if component can perform some functions\n7:\ncapabilities ←getCapabilities (KB, component)\n8:\nif ¬ IsEmpty (capabilities) then\n9:\n// create primitive variable for component\n10:\nsv ←createPrimitiveV ariable (component)\n11:\n// check component’s functional capabilities\n12:\nfor all capability ∈capabilities do\n13:\nsv ←addV alue (sv, function)\n14:\nend for\n15:\nsvs ←addV ariable (svs, sv)\n16:\nend if\n17:\nend for\n18:\nreturn svs\n19: end function\nAlgorithm 10 ﬁrst initializes the set of primitive state variables of the domain\n(row 2). Then, the procedure reads the set of the inferred components from the\nKB (row 4). Given a component, if the KB contains at least one primitive function\nthe agent can perform through that component, then a primitive variable is created\n147\n\nKnowledge-based Control Loop for Flexible Controllers\n(rows 5 -10). The values added to the variable model the capabilities of the related\ncomponent. Namely, the values model the primitive functions the agent can per-\nform by means of the considered component (rows 11-16). The procedure ends by\nreturning the set of generated state variables.\nBuilding External Variables\nAlgorithm 11 describes the procedure which builds the external state variables of\nthe timeline-based control model. The buildExternalComponents procedure gen-\nerates the set of state variables concerning the collaborators of the agent. The\nprocedure generates a set of state variables representing the collaborators of the\nagent. Speciﬁcally, a state variable is created for each individual found in the KB\nthat, according to the inference rule 7.6, has been classiﬁed as collaborator. The\nvalues of these state variables represent the operative states the collaborators may\nassume over time.\nAlgorithm 11 The KBCL sub-procedure for generating external variables\n1: function BUILDEXTERNALCOMPONENTS(KB, agent)\n2:\nsvs ←∅\n3:\n// get agent’s collaborators\n4:\ncollaborators ←getCollaborators (KB, agent)\n5:\nfor all collaborator ∈collaborators do\n6:\n// create an external variable to model the collaborator\n7:\nsv ←createExternalV ariable (collaborator)\n8:\n// model the possible behaviors of collaborators\n9:\nstates ←getOperativeStates (collaborator)\n10:\nfor all state ∈states do\n11:\nsv ←addV alue (sv, state)\n12:\nend for\n13:\nsvs ←addV ariable (svs, sv)\n14:\nend for\n15:\nreturn svs\n16: end function\nThe procedure ﬁrst initializes the set of external variables of the domain (row\n2). Then, the procedure reads the set of inferred collaborators from the KB (row\n4). For each collaborator found, a state variable is created (rows 5-7) and for each\noperative state the collaborator may assume over time, a value is added to the\ncreated variable (rows 9-14). The procedure ends by returning the set of generated\nvariables.\n148\n\nKnowledge-based Control Loop for Flexible Controllers\n7.5.2\nBuilding Decomposition Rules from Inference Trace\nWhen all the state variables and their values have been generated, it is necessary\nto build the synchronization rules of the domain in order to coordinate the tem-\nporal behavior of the state variables and achieve the desired goals. The buildSyn-\nchronizationRules procedure generates the decomposition rules by leveraging the\ninference trace of the KB. The inference trace represents intermediate knowledge\ngenerated by the application of inference rules. Such knowledge manages interme-\ndiate information necessary to complete the knowledge inference mechanism and\ntherefore build the KB. For instance, besides primitive channels, the inference rule\n7.7 generates cConnect properties. These properties do not represent speciﬁc infor-\nmation about the agent but are necessary to generate the set of complex channels,\nas shown in the inference rule 7.8. These properties encode functional dependen-\ncies among the components of a TM. In particular, they encode these dependencies\nin terms of primitive channels needed to implement complex channels.\nThe inferred cConnect properties can be analyzed in order to build a particu-\nlar data structure, called functional graph, that correlates functional dependencies\namong components, primitive and complex channels. The graph is built according\nto the inferred cConnect properties. Thus, the possible implementations of complex\nchannels can be found by traversing the functional graph. This set of information\nis necessary to build the set of synchronization rules specifying how the agent must\nexecute complex channels. Indeed, synchronization rules are generated by analyz-\ning the paths on the functional graph that connect the start with the end locations\nof complex channels. These paths can be easily expressed in terms of precedence\nconstraints between primitive channels of the involved components.\nAlgorithm 12 describes the procedure for building the synchronization rules\nof the timeline-based domain with respect to the (complex) channel function the\nrelated TM can perform. The procedure ﬁrst initializes the set of rules (row 2) and\nthen analyzes the KB to generate the functional graph concerning channel func-\ntions (row 4). For each complex channel, the procedure extracts the available im-\nplementations from the functional graph (rows 6-9). Each implementation encodes\na set of temporal constraints between the primitive channels of the agent. Thus,\ngiven a possible implementation of a complex channel, a new synchronization rule\nis created and added to the model (rows 10-14). The procedure ends by returning\nthe set of generated synchronizations.\n149\n\nKnowledge-based Control Loop for Flexible Controllers\nAlgorithm 12 The KBCL sub-procedure for generating synchronization rules\n1: function BUILDSYNCHRONIZATIONRULES(KB, agent)\n2:\nrules ←∅\n3:\n// create the functional graph for channel functions\n4:\ngraph ←buildChannelFunctionalGraph (KB, agent)\n5:\n// get inferred complex channels\n6:\nchannels ←getChannels (KB, agent)\n7:\nfor all channel ∈channels do\n8:\n// get available implementations\n9:\nimplementations ←getImplementation (graph, channel)\n10:\nfor all implementation ∈implementations do\n11:\n// create synchronization rule from implementation\n12:\nrule ←createSynchronizationRule (KB, implementation)\n13:\nrules ←addRule(rule)\n14:\nend for\n15:\nend for\n16:\nreturn rules\n17: end function\n7.5.3\nThe Resulting Timeline-based Control Model\nThe procedures that have been described in the previous sections encode the model\ngeneration process which relies on the context-based characterization of the KB.\nAccording to this structure, the process generates a hierarchical domain speciﬁca-\ntion modeling the complex functions of the agent in terms of the primitive functions\nthat internal components can directly handle according to the status of the involved\ncollaborators.\nFigure 7.12 shows a (partial) example of a timeline-based control model gen-\nerated for a TM composed by one cross-transfer unit only. The model provides\na functional characterization of the TM according to functional, primitive and ex-\nternal levels cited above. The primitive state variables model the active parts of\nthe TM that can actually perform some (primitive) functions. These state variables\nmodel the functional capabilities of elements that compose the TM. For example,\nthe component Conveyor1 can perform the primitive channel ChannelF-Down to\nmove a pallet between the location of component PortF and location Down of com-\nponent Cross1. Similarly, the component Cross1 can perform the primitive channel\nChannelDown-Up to move a pallet from the location Down to the location Up of\nthe same component Cross1. The external state variables model the inferred col-\nlaborators that can directly interact with the considered TM. The values of these\nvariables represent the operative states that collaborators may assume over time.\nFigure 7.12 shows the external state variables concerning two of four collaborators\n150\n\nKnowledge-based Control Loop for Flexible Controllers\nTM\n<<functional>>\nChannel\nF-B\nChannel\nB-F\nChannel\nF-R\nIdle\n…\nConveyor1\n<<primitive>>\nChannel\nF-Down\nChannel\nDown-B\nIdle\n…\nCross1\n<<primitive>>\nChannel\nUp-Down\nChannel\nDown-Up\nIdle\nConveyor2\n<<primitive>>\nChannel\nUp-R\nIdle\n…\nCollaboratorR\n<<external>>\nAvailable\nNot\nAvailable\nCollaboratorF\n<<external>>\nAvailable\nNot\nAvailable\nduring\nduring\nbefore\nbefore\ncontains\ncontains\ncontains\nChannel\nUp-L\nFigure 7.12: A (partial) view of the timeline-based model generated for a TM equipped\nwith one cross-transfer unit only\navailable. Speciﬁcally, the state variables model the behaviors of CollaboratorF\nand CollaboratorR i.e. the collaborators connected to the TM through components\nPortF and PortR respectively. The functional state variables model the inferred\nchannel functions the TM can perform by combining internal (i.e. primitive) chan-\nnel functions. For example, according to this interpretation, ChannelF-R can be\nseen as the composition of the following primitive channels:\nChannelF-R\nz\n}|\n{\nChannelF-Down\n|\n{z\n}\nConveyor1\n◦ChannelDown-Up\n|\n{z\n}\nCross1\n◦ChannelUp-R\n|\n{z\n}\nConveyor2\nSuch a composition represents a particular implementation of the ChannelF-\nR function. Implementations are modeled by means of synchronization rules that\nspecify a suited set of temporal constraints (the red arrows in Figure 7.12). These\ntemporal constraints encode also the functional dependencies between the TM and\nits collaborators. Indeed, CollaboratorF and CollaboratorR must be available dur-\ning the execution of the ChannelF-R function. The generated timeline-based plan-\nning model provides a functional characterization of TMs of the plant where plan-\nning goals represent functions the considered TM must performpri. These func-\ntions are described in terms of the atomic operations (i.e. primitive functions) the\nTM is capable to perform by means of its components and its available collabora-\ntors.\n151\n\nKnowledge-based Control Loop for Flexible Controllers\n7.6\nThe Knowledge-Based Control Loop in Action\nThis section reports on a set of tests on the KBCL with different TM conﬁgurations.\nAll the different physical conﬁgurations of a TM have been considered, from zero\nto three cross-transfer modules. These conﬁgurations are referred to as simple,\nsingle, double and full, respectively. Each conﬁguration also entails a different\nnumber of connected TM neighbors. Clearly, the more complex scenario is the one\nwith the highest number of cross-transfers (the full TM) and neighbors. Also, three\nreconﬁguration scenarios (reconf-a, reconf-b and reconf-c) have been developed\nconsidering different external events, namely an increasing number (from 1 to 3) of\nTM neighbors momentarily unable to exchange pallets, plus two scenarios related\nto internal failures (reconf-d and reconf-e) due to a cross-transfer engine failure\nand to a local failure on a speciﬁc port.\nThe experiments were carried out to evaluate the performance of the following\naspects of a TM: (i) the knowledge processing mechanism; (ii) the planning model\ngeneration; (iii) the synthesis of plans to manage a set of pallet requests. The\nﬁnal aim is to evaluate the feasibility of the KBCL approach by showing that the\nperformance are compatible with execution latencies of the RMS1.\n0\n1\n2\n3\n4\n5\ninference\nmapping\nSetup\nTime (in seconds)\nfull\ndouble\nsingle\nsimple\nFigure 7.13: KB initial inference and planning domain generation\nFigure 7.13 shows the timings in the Setup phase for the KBCL module op-\n1All the experiments have been performed on a workstation endowed with an Intel Core2 Duo\n2.26GHz and 8GB RAM\n152\n\nKnowledge-based Control Loop for Flexible Controllers\neration, i.e. to build the KB exploiting the classiﬁcation and capability inference\nprocess (the \"inference\" side of Figure 7.13), and to generate the timeline-based\nplanning speciﬁcation for the TM (the \"mapping\" side of Figure 7.13). On the one\nhand, the results show that an increase in the complexity of the TM conﬁgurations\ndoes not entail a degeneration of the knowledge processing mechanism: the infer-\nence costs are almost constant (around 1.3 secs). This behavior was expected since\nthe number of instances/relationships in the KB is rather low notwithstanding the\nphysical conﬁguration of the TM; thus, the performance of the inference engine\ndeployed here is not particularly affected. On the other hand, the model genera-\ntion is strongly affected spanning from 0.8 secs in the simple conﬁguration, up to\na maximum of 2.2 seconds in the full conﬁguration. The model generation process\nentails a combinatorial effect on the number of instances/relationships needed to\ngenerate components and synchronizations leading to larger planning models and,\nthus, to higher process costs.\n0\n1\n2\n3\n4\n5\ninference\nmapping\nReconf\nTime (in seconds)\nfull\ndouble\nsingle\nsimple\nFigure 7.14: KB inference and planning domain generation during KBCL reconﬁguration\nphase\nWhen a reconﬁguration scenario occurs, the knowledge processing costs are\nnegligible. Among all the considered reconﬁguration cases (i.e., reconf-a-b-c-d-e),\nthe time spent by the knowledge processing mechanism to (re)infer the enabled\nfunctionalities is just a few milliseconds. In fact, both the classiﬁcation and ca-\npability inference steps are applied to a slightly changed KB and, then, minimal\nchanges in the functionalities can be quickly inferred and represented in the new\n153\n\nKnowledge-based Control Loop for Flexible Controllers\nKB. For what concerns the planning model generation after a reconﬁguration, each\nreconﬁguration scenario (both external and internal) leads to a strong reduction of\nfunctionalities and, thus, the related costs are relatively small. Figure 7.14 shows\nthe time spent to generate the planning model in the full TM conﬁguration (i.e.,\nthe more complex conﬁguration) is depicted and compared with respect to the time\nspent in the setup phase. In general, the time needed to regenerate the planning\nmodel speciﬁcation is also dependent on reconﬁguration scenarios but still negli-\ngible.\n0\n5\n10\n15\n20\n25\n30\n1g\n2g\n3g\n4g\n5g\n6g\n7g\n8g\n9g\n10g\nSetup\nSolving time (in seconds)\nfull\ndouble\nsingle\nsimple\nFigure 7.15: Deliberation time with increasing number of goals and different TM conﬁg-\nurations during KBCL setup phase\nFinally, we evaluate the planning costs when facing both setup and reconﬁg-\nuration scenarios.Figure 7.15 shows the trend of the planning time in the Setup\nscenario considering all the TM conﬁgurations and an increasing number of pal-\nlet requests (randomly generated), i.e., planning goals, to be fulﬁlled. Planning\ncosts span from few seconds up to nearly 30 seconds when planning for 10 pallet\nrequests within a 15 minutes horizon. In general, the more complex the planning\nmodel, the harder the plan synthesis problem. Thus, the planning costs follow the\ncomplexity of the conﬁgurations of the speciﬁc TM agent.\nThe experimental results show the practical feasibility of the KBCL approach\nin increasingly complex instances of a real-world manufacturing case study. The\ncollected data for the initialization (or the update) of a generic agent’s KB (consid-\nering both knowledge processing and model generation) and the cost for planning\n154\n\nKnowledge-based Control Loop for Flexible Controllers\nsynthesis have a low impact on its performance during operation. In fact, in or-\nder to face production periods of 15 minutes –and the management of 10 pallet\nrequests– no more than 5 seconds are required by the Knowledge Manager while\nless than 30 seconds are required by the Planner to generate a suitable plan. Such\nperformances are compatible with the system latency usually involved in this type\nof manufacturing applications.\nImplementation Notes\nMost of the inferences at runtime are done in the Web Ontology Language (OWL)\nversion of the KB to exploit primarily the contextual classiﬁcation and relation-\nships. The ontology editor PROTÉGÉ1 has been used fo KB design and testing. For\nruntime reasoning within the Knowledge Manager, the Ontology and RDF APIs\nand Inference APIs provided by the Apache Jena Software Library2 has been used.\n1http://protege.stanford.edu\n2http://jena.apache.org\n155\n\nChapter 8\nConcluding Remarks\nT\nHIS THESIS has presented a complete characterization of the timeline-based\napproach ranging from a formalization of timeline-based planning to plan-\nning and execution of timelines by taking into account temporal uncertainty. After\nthe ﬁrst introductory chapters, Chapter 4 presented the formalization which de-\nﬁnes a clear semantics of the main planning concepts like timelines, state vari-\nables, plans and goals, and taking into account the domain controllability features.\nChapter 5 introduced EPSL a general framework for planning and execution with\ntimelines which complies with the formalization and, is therefore capable of deal-\ning with temporal uncertainty. The effectiveness of the envisaged approach has\nbeen shown by applying EPSL to real-world manufacturing scenarios within the\nresearch projects FOURBYTHREE and GECKO as described in Chapter 6 and 7 re-\nspectively. Speciﬁcally, the FOURBYTHREE project has shown how the envisaged\ntimeline-based approach and the EPSL capabilities of dealing with temporal un-\ncertainty both at planing and execution time, as well as the hierarchical approach,\nrepresent an effective solution for controlling a robot in scenarios where temporal\nuncertainty plays a relevant role, like Human-Robot Collaboration requiring a tight\ninteraction between a controllable agent (i.e. the robot) and an uncontrollable agent\n(i.e. the human). The GECKO project has shown some promising results concern-\ning the design of a ﬂexible control architecture capable of dynamically inferring the\ncontrol model by integrating knowledge reasoning techniques with timeline-based\nplanning.\nThe main concern all along this work was not to design the most performing\nplanning algorithm ever made, but rather the objective was to design and develop\nnew and effective solutions for real-world scenarios. Thus, the key point has been\nto understand the features and the problems that must be considered and solved\n156\n\nConcluding Remarks\nin order to effectively apply these techniques in real-world applications. For this\nreason, the importance of a ﬂexible control system capable of (robustly) managing\nand adapting control strategies to the uncontrollable dynamics of the environment\nhas come to light within the research projects FOURBYTHREE and GECKO.\nFor example, the FOURBYTHREE project shows that ﬂexibility is needed to\ncontrol the robot and dynamically adapt its behavior to the observed behavior of\nthe human. In this case, the pursued solution consists in designing planning and\nexecution applications capable of properly dealing with temporal uncertainty at dif-\nferent levels. From the planning point of view, the formal characterization of the\ntimeline-based approach introduces the representation of the uncontrollable dy-\nnamics of the domain in shape of temporal uncertainty. Leveraging this formaliza-\ntion, the general hierarchy-based solving procedure of the EPSL framework has\nbeen extended by introducing temporal uncertainty in order to synthesize plans ac-\ncordingly. In this way, EPSL can generate plans that have some desired properties\n(i.e. the pseudo-controllability property) characterizing their (temporal) robustness\nat execution time. From the execution point of view, once a plan has been gener-\nated it must be executed. The EPSL framework has been extended by introducing\nexecutive capabilities that rely on the same representation of the planner. Thus,\nEPSL can execute plans by taking into account the controllability properties of the\ndomain and dynamically adapt the execution of the plan to the observed behavior\nof the environment and the related uncontrollable features.\nPlan-based control architectures and also the EPSL-based control architecture\ntypically rely on a well-deﬁned and static model of the world. The GECKO project\nshows that another type of ﬂexibility needed in real-world scenarios is the capabil-\nity of dynamically adapting the control model of the plan-based controller to the\nspeciﬁc conﬁguration/state of the working environment and the robot (i.e. the agent\nto control). In this case, the pursued solution consists in designing an extended\nplan-based control architecture which integrates knowledge reasoning and plan-\nning. Semantic technologies introduce the capability of representing and reasoning\nabout the state of the agent and the related working environment. Such a reasoning\nmechanism, embedded in the control architecture, allows for dynamically building\nand maintaining updated the knowledge concerning the actual functional capabil-\nities of a particular agent. Such a knowledge is then exploited to automatically\ngenerate a control model that a plan-based controller (e.g. an EPSL-based con-\ntroller) utilizes to actually plan and execute operations.\nEPSL represents the main result of this work. It represents a uniform frame-\n157\n\nConcluding Remarks\nwork for planning and execution with timelines under uncertainty. In addition, the\napplication of EPSL to the research projects FOURBYTHREE and GECKO has\nshown the effectiveness and the ﬂexibility of the envisaged approach to solve real-\nworld problems. However this is just a ﬁrst step, there are several aspects to take\ninto account in order to further improve the capabilities of the EPSL framework.\nA short-term objective concerns the introduction of a ﬂexible management of\ndifferent types of resource in EPSL. In general, the objective is to enrich the types\nof domain element (in addition to state variables) the framework can deal with. The\nintroduction of different types of resources (e.g. renewable resources and consum-\nable resources) would allows EPSL and the envisaged timeline-based approach to\naddress more realistic problems. This implies also that the solving capabilities of\nEPSL must be extended in order to synthesize ﬂexible proﬁles for the different\ntypes of resources considered. An initial idea is to leverage temporal ﬂexibility in\norder to synthesize optimistic temporal proﬁles of resources [Laborie, 2003, Cesta\nand Stella, 1997, Drabble and Tate, 1994].\nTimeline-based planning systems, usually rely on a careful engineering of do-\nmain together with domain-dependent heuristics in order to control the search pro-\ncess. Nevertheless, there are different domain-independent heuristics that have suc-\ncessfully applied in classical planning showing impressive results e.g. [Hoffmann\nand Nebel, 2011, Blum and Furst, 1997, Helmert, 2011]. Unfortunately, the appli-\ncation/adaption of these techniques to timeline-based systems is neither simple nor\npossible. There are signiﬁcant differences between the timeline-based approach\nand the classical approach in terms of problem representation and resolution that\nprevent a straightforward adaptation of these heuristics. Thus, an additional short-\nterm objective is to investigate the design of domain-independent heuristics by\nborrowing ideas and concepts from classical as well as similar works in the litera-\nture e.g., [Bernardini and Smith, 2008]. The hierarchy-based technique introduced\nin this work represents just an initial step towards the achievement of this research\nobjective.\nAlso the comparison of EPSL with other existing timeline-based systems is a\nrelevant research objective to pursue in the near future. More in general, the ob-\njective is to compare the timeline-based approach with other temporal and hybrid\nplanning approaches. A ﬁrst contribution is represented by the work [Umbrico\net al., 2016] which provides an initial comparison between EPSL and EUROPA\nby taking into account modeling and solving features of these two frameworks. The\ngoal is to deﬁne a set of benchmarking problems that can be used to compare mod-\n158\n\nConcluding Remarks\neling and solving capabilities of EPSL with EUROPA, IXTET and other relevant\nplanning systems like OPTIC [Benton et al., 2012], COLIN [Coles et al., 2012],\nFAPE [Dvorák et al., 2014], CHIMP [Stock et al., 2015] and HATP [Lallement\net al., 2014].\nA medium-term objective is to further exploit temporal uncertainty at plan-\nning and execution time. With respect to planning, the objetive is to enhance the\nEPSL solving procedure in order to synthesize dynamically controllable plans.\nPseudo-controllabiliy is a useful property but it does not provide enough informa-\ntion about the controllability of a plan. Indeed, pseudo-controllability is a neces-\nsary but not sufﬁcient property for dynamically controllability. Thus, the idea is to\nfurther analyze information about the temporal uncertainty of the domain during\nthe planning process in order to generate plans with more relevant properties char-\nacterizing their execution, i.e. dynamic controllability. With respect to execution,\nthe objective is to integrate the synthesis and management of execution strategies\n[Orlandini et al., 2013, Orlandini et al., 2011], as well as validation and veriﬁcation\ntechniques [Cesta et al., 2010] in order to execute timeline-based plans in a more\nrobust way. As it is, the executive takes execution decisions on the ﬂy without rea-\nsoning on the overall plan and the observed behavior of the environment. The use\nof an execution strategy would allow EPSL to take more accurate decisions and\nimprove the robustness of plan execution.\nFinally, a long-term objective is to further investigate the integration of knowl-\nedge reasoning techniques with planning and the automatic synthesis of control\nmodels. Speciﬁcally the idea is to realize a powerful knowledge engineering tool\nwhich leverages semantic technologies in order to allow users that are not expert of\nplanning technologies but rather expert of the domain, to use and deploy (timeline-\nbased) planning applications. Knowledge engineering tools provide a standard and\nexpressive interface which allows users to model the particular domain abstracting\nfrom the details of planning and problem resolution. Then, the resulting knowl-\nedge can be exploited in order to dynamically generate the planning model used to\nactually plan and execute operations as shown in Chapter 7.\n159\n\nBibliography\n[etf, 2016] (2016).\nFourbythree: Imagine humans and robots working hand in\nhand. In 2016 IEEE 21st International Conference on Emerging Technologies\nand Factory Automation (ETFA), pages 1–8. 104\n[Alami et al., 1998] Alami, R., Chatila, R., Fleury, S., Ghallab, M., and Ingrand,\nF. (1998). An architecture for autonomy. International Journal of Robotics\nResearch, Special Issue on Integrated Architectures for Robot Control and Pro-\ngramming, 17(4):315–337. 89\n[Allen, 1983] Allen, J. F. (1983). Maintaining knowledge about temporal inter-\nvals. Commun. ACM, 26(11):832–843. 19, 25, 39, 98\n[Ambros-Ingerson and Steel, 1988] Ambros-Ingerson, J. and Steel, S. (1988). In-\ntegrating Planning, Execution and Monitoring, volume 1, pages 83–88. AAAI\nPress. 89\n[Aschwanden et al., 2006] Aschwanden, P., Baskaran, V., Bernardini, S., Fry, C.,\nMoreno, M., Muscettola, N., Plaunt, C., Rijsman, D., and Tompkins, P. (2006).\nModel-uniﬁed planning and execution for distributed autonomous system con-\ntrol.\nIn Proceedings of the AAAI Fall Symposium on Spacecraft Autonomy:\nUsing AI to Expand Human Space Exploration. 89\n[Barreiro et al., 2012] Barreiro, J., Boyce, M., Do, M., Frank, J., Iatauro, M.,\nKichkaylo, T., Morris, P., Ong, J., Remolina, E., Smith, T., and Smith, D.\n(2012). EUROPA: A Platform for AI Planning, Scheduling, Constraint Pro-\ngramming, and Optimization. In ICKEPS 2012: the 4th Int. Competition on\nKnowledge Engineering for Planning and Scheduling. 3, 18, 32, 39, 89\n[Benton et al., 2012] Benton, J., Coles, A. J., and Coles, A. (2012). Temporal\nplanning with preferences and time-dependent continuous costs. In Proceed-\nings of the Twenty-Second International Conference on Automated Planning\n160\n\nBIBLIOGRAPHY\nand Scheduling, ICAPS 2012, Atibaia, São Paulo, Brazil, June 25-19, 2012. 14,\n159\n[Bernardini and Smith, 2008] Bernardini, S. and Smith, D. E. (2008). Automat-\nically generated heuristic guidance for europa2. In Proceedings of the Ninth\nInternational Symposium on Artiﬁcial Intelligence, Robotics and Automation\nfor Space (iSAIRAS-08). 158\n[Blum and Furst, 1997] Blum, A. and Furst, M. L. (1997). Fast planning through\nplanning graph analysis. Artif. Intell., 90(1-2):281–300. 158\n[Borgo, 2007] Borgo, S. (2007). How Formal Ontology can help Civil Engineers,\npages 37–45. Springer Berlin Heidelberg, Berlin, Heidelberg. 134\n[Borgo, 2014] Borgo, S. (2014). An ontological approach for reliable data inte-\ngration in the industrial domain. Computers in Industry, 65(9):1242 – 1252.\nSpecial Issue on The Role of Ontologies in Future Web-based Industrial Enter-\nprises. 127\n[Borgo et al., 2014a] Borgo, S., Cesta, A., Orlandini, A., Rasconi, R., Suriano, M.,\nand Umbrico, A. (2014a). Towards a cooperative knowledge-based control ar-\nchitecture for a reconﬁgurable manufacturing plant. In 19th IEEE International\nConference on Emerging Technologies and Factory Automation (ETFA). IEEE.\n120, 121\n[Borgo et al., 2015] Borgo, S., Cesta, A., Orlandini, A., and Umbrico, A. (2015).\nAn ontology-based domain representation for plan-based controllers in a re-\nconﬁgurable manufacturing system. In The Twenty-Eighth International Flairs\nConference. 134\n[Borgo et al., 2016] Borgo, S., Cesta, A., Orlandini, A., and Umbrico, A. (2016).\nA planning-based architecture for a reconﬁgurable manufacturing system. In\nThe 26th International Conference on Automated Planning and Scheduling\n(ICAPS). 145\n[Borgo et al., 2014b] Borgo, S., Franssen, M., Garbacz, P., Kitamura, Y., Mi-\nzoguchi, R., and Vermaas, P. E. (2014b). Technical artifacts: An integrated\nperspective. Applied Ontology, 9(3-4):217–235. 129\n161\n\nBIBLIOGRAPHY\n[Borgo and Leitão, 2004] Borgo, S. and Leitão, P. (2004).\nThe Role of Foun-\ndational Ontologies in Manufacturing Domain Applications, pages 670–688.\nSpringer Berlin Heidelberg, Berlin, Heidelberg. 127\n[Borgo and Masolo, 2009] Borgo, S. and Masolo, C. (2009). Foundational choices\nin dolce. In Handbook on ontologies, pages 361–381. Springer. 130, 134\n[Borgo and Vieu, 2009] Borgo, S. and Vieu, L. (2009). Artefacts in formal ontol-\nogy. 129, 130\n[Buschmann et al., 1996] Buschmann, F., Meunier, R., Rohnert, H., Sommerlad,\nP., and Stal, M. (1996). Pattern-Oriented Software Architecture - Volume 1: A\nSystem of Patterns. Wiley Publishing. 70\n[Carpanzano et al., 2016] Carpanzano, E., Cesta, A., Orlandini, A., Rasconi, R.,\nSuriano, M., Umbrico, A., and Valente, A. (2016). Design and implementation\nof a distributed part-routing algorithm for reconﬁgurable transportation systems.\nInt. J. Computer Integrated Manufacturing, 29(12):1317–1334. 121\n[Ceballos et al., 2011] Ceballos, A., Bensalem, S., Cesta, A., de Silva, L., Fratini,\nS., Ingrand, F., Ocon, J., Orlandini, A., Py, F., Rajan, K., Rasconi, R., and van\nWinnendael, M. (2011). A Goal-Oriented Autonomous Controller for Space\nExploration. In ASTRA-11. 11th Symposium on Advanced Space Technologies\nin Robotics and Automation. 25\n[Cesta et al., 2009] Cesta, A., Cortellessa, G., Fratini, S., and Oddi, A. (2009). De-\nveloping an End-to-End Planning Application from a Timeline Representation\nFramework. In IAAI-09. Proc. of the 21st Innovative Application of Artiﬁcial\nIntelligence Conference, Pasadena, CA, USA. 54\n[Cesta et al., 2007] Cesta, A., Cortellessa, G., Fratini, S., Oddi, A., and Policella,\nN. (2007). An innovative product for space mission planning – an a posteriori\nevaluation. In Proc. of the 17th International Conference on Automated Plan-\nning & Scheduling (ICAPS-07). 17\n[Cesta et al., 2010] Cesta, A., Finzi, A., Fratini, S., Orlandini, A., and Tronci, E.\n(2010). Validation and Veriﬁcation Issues in a Timeline-Based Planning System.\nKnowledge Engineering Review, 25(3):299–318. 4, 78, 159\n[Cesta and Oddi, 1996] Cesta, A. and Oddi, A. (1996). DDL.1: A Formal De-\nscription of a Constraint Representation Language for Physical Domains,. In\n162\n\nBIBLIOGRAPHY\nGhallab, M. and Milani, A., editors, New Directions in AI Planning. IOS Press:\nAmsterdam. 59\n[Cesta et al., 2016] Cesta, A., Orlandini, A., Bernardi, G., and Umbrico, A.\n(2016). Towards a planning-based framework for symbiotic human-robot col-\nlaboration. In 21th IEEE International Conference on Emerging Technologies\nand Factory Automation (ETFA). IEEE. 107\n[Cesta et al., 2013] Cesta, A., Orlandini, A., and Umbrico, A. (2013). Toward\na general purpose software environment for timeline-based planning. In 20th\nRCRA International Workshop on \"Experimental Evaluation of Algorithms for\nsolving problems with combinatorial explosion\". 58\n[Cesta and Stella, 1997] Cesta, A. and Stella, C. (1997).\nA time and resource\nproblem for planning architectures. In Steel, S. and Alami, R., editors, Re-\ncent Advances in AI Planning, 4th European Conference on Planning, ECP’97,\nToulouse, France, September 24-26, 1997, Proceedings, volume 1348 of Lec-\nture Notes in Computer Science, pages 117–129. Springer. 158\n[Chandrasegaran et al., 2013] Chandrasegaran, S. K., Ramani, K., Sriram, R. D.,\nHorváth, I., Bernard, A., Harik, R. F., and Gao, W. (2013).\nThe evolution,\nchallenges, and future of knowledge representation in product design systems.\nComputer-Aided Design, 45(2):204 – 228. Solid and Physical Modeling 2012.\n126\n[Chandrasekaran and Josephson, 2000] Chandrasekaran, B. and Josephson, J. R.\n(2000).\nFunction in device representation.\nEngineering with Computers,\n16(3):162–177. 132\n[Chien et al., 1999] Chien, S., Knight, R., Stechert, A., Sherwood, R., and Ra-\nbideau, G. (1999). Integrated Planning and Execution for Autonomous Space-\ncraft, volume 1, pages 263–271. IEEE Aerospace. 89\n[Cialdea Mayer and Orlandini, 2015] Cialdea Mayer,\nM. and Orlandini,\nA.\n(2015). An executable semantics of ﬂexible plans in terms of timed game au-\ntomata. In The 22nd International Symposium on Temporal Representation and\nReasoning (TIME). IEEE. 78\n[Cialdea Mayer et al., 2016] Cialdea Mayer, M., Orlandini, A., and Umbrico, A.\n(2016). Planning and execution with ﬂexible timelines: a formal account. Acta\nInf., 53(6-8):649–680. 29, 52, 58, 59, 77\n163\n\nBIBLIOGRAPHY\n[Cimatti et al., 2013] Cimatti, A., Micheli, A., and Roveri, M. (2013). Timelines\nwith temporal uncertainty. In 27th AAAI Conference on Artiﬁcial Intelligence\n(AAAI). 42, 54\n[Coles et al., 2010] Coles, A. J., Coles, A., Fox, M., and Long, D. (2010).\nForward-chaining partial-order planning.\nIn Proceedings of the 20th Inter-\nnational Conference on Automated Planning and Scheduling, ICAPS 2010,\nToronto, Ontario, Canada, May 12-16, 2010, pages 42–49. 15\n[Coles et al., 2012] Coles, A. J., Coles, A., Fox, M., and Long, D. (2012). COLIN:\nplanning with continuous linear numeric change. J. Artif. Intell. Res. (JAIR),\n44:1–96. 14, 159\n[Currie and Tate, 1991] Currie, K. and Tate, A. (1991). O-plan: The open planning\narchitecture. Artiﬁcial Intelligence, 52(1):49 – 86. 11\n[Dechter et al., 1991] Dechter, R., Meiri, I., and Pearl, J. (1991). Temporal con-\nstraint networks. Artiﬁcial Intelligence, 49(1):61 – 95. 23, 25, 26\n[Drabble and Tate, 1994] Drabble, B. and Tate, A. (1994). The use of optimistic\nand pessimistic resource proﬁles to inform search in an activity based planner.\nIn Hammond, K. J., editor, Proceedings of the Second International Conference\non Artiﬁcial Intelligence Planning Systems, University of Chicago, Chicago,\nIllinois, USA, June 13-15, 1994, pages 243–248. AAAI. 158\n[Dvorák et al., 2014] Dvorák, F., Barták, R., Bit-Monnot, A., Ingrand, F., and\nGhallab, M. (2014). Planning and acting with temporal and hierarchical de-\ncomposition models. In 2014 IEEE 26th International Conference on Tools\nwith Artiﬁcial Intelligence (ICTAI), pages 115–121. 14, 16, 159\n[Fikes and Nilsson, 1971] Fikes, R. E. and Nilsson, N. J. (1971). Strips: A new\napproach to the application of theorem proving to problem solving. Artiﬁcial\nintelligence, 2(3-4):189–208. 2, 9, 10\n[Fox and Long, 2003] Fox, M. and Long, D. (2003). PDDL2.1: an extension to\nPDDL for expressing temporal planning domains. J. Artif. Intell. Res. (JAIR),\n20:61–124. 14\n[Frank and Jonsson, 2003] Frank, J. and Jonsson, A. (2003). Constraint Based\nAttribute and Interval Planning. Journal of Constraints, 8(4):339–364. 18\n164\n\nBIBLIOGRAPHY\n[Fratini et al., 2011] Fratini, S., Cesta, A., De Benidictis, R., Orlandini, A., and\nRasconi, R. (2011). APSI-based deliberation in Goal Oriented Autonomous\nControllers. In ASTRA-11. 11th Symposium on Advanced Space Technologies\nin Robotics and Automation. 3, 18, 24, 32, 39\n[Fratini et al., 2008] Fratini, S., Pecora, F., and Cesta, A. (2008). Unifying Plan-\nning and Scheduling as Timelines in a Component-Based Perspective. Archives\nof Control Sciences, 18(2):231–271. 25, 36\n[Gamma et al., 1995] Gamma, E., Helm, R., Johnson, R., and Vlissides, J. (1995).\nDesign Patterns: Elements of Reusable Object-oriented Software. Addison-\nWesley Longman Publishing Co., Inc., Boston, MA, USA. 71, 90\n[Gat, 1997] Gat, E. (1997). On Three-Layer Architectures. In Artiﬁcial Intelli-\ngence and Mobile Robots. MIT Press. 88\n[Georgievski and Aiello, 2015] Georgievski, I. and Aiello, M. (2015). HTN plan-\nning: Overview, comparison, and beyond. Artif. Intell., 222:124–156. 4, 11\n[Gerevini and Serina, 2002] Gerevini, A. and Serina, I. (2002). LPG: A planner\nbased on local search for planning graphs with action costs. In Proceedings of\nthe Sixth International Conference on Artiﬁcial Intelligence Planning Systems,\nApril 23-27, 2002, Toulouse, France, pages 13–22. 2, 13\n[Ghallab and Laruelle, 1994] Ghallab, M. and Laruelle, H. (1994). Representation\nand control in ixtet, a temporal planner. In 2nd Int. Conf. on Artiﬁcial Intelli-\ngence Planning and Scheduling (AIPS), pages 61–67. 3, 18, 21\n[Ghallab et al., 2004] Ghallab, M., Nau, D. S., and Traverso, P. (2004). Automated\nplanning - theory and practice. Elsevier. 15\n[Goldman et al., 2002] Goldman, R. P., Musliner, D. J., and Pelican, M. J. (2002).\nExploiting implicit representations in timed automaton veriﬁcation for con-\ntroller synthesis. In HSCC-02. Proc. of the Fifth Int. Workshop on Hybrid Sys-\ntems: Computation and Control. 89\n[Hartanto and Hertzberg, 2008] Hartanto, R. and Hertzberg, J. (2008). Fusing DL\nReasoning with HTN Planning. In Dengel, A., Berns, K., Breuel, T., Bomar-\nius, F., and Roth-Berghofer, T., editors, KI 2008: Advances in Artiﬁcial In-\ntelligence, volume 5243 of Lecture Notes in Computer Science, pages 62–69.\nSpringer Berlin Heidelberg. 122\n165\n\nBIBLIOGRAPHY\n[Helmert, 2011] Helmert, M. (2011). The fast downward planning system. CoRR,\nabs/1109.6051. 158\n[Helms et al., 2002] Helms, E., Schraft, R. D., and Hagele, M. (2002). rob@work:\nRobot assistant in industrial environments. In Proceedings. 11th IEEE Interna-\ntional Workshop on Robot and Human Interactive Communication, pages 399–\n404. 104\n[Hirtz et al., 2002] Hirtz, J., Stone, R. B., McAdams, D. A., Szykman, S., and\nWood, K. L. (2002). A functional basis for engineering design: Reconciling\nand evolving previous efforts. Research in Engineering Design, 13(2):65–82.\n132\n[Hoffmann and Nebel, 2011] Hoffmann, J. and Nebel, B. (2011). The FF planning\nsystem: Fast plan generation through heuristic search. CoRR, abs/1106.0675.\n2, 13, 158\n[Jonsson et al., 2000a] Jonsson, A., Morris, P., Muscettola, N., Rajan, K., and\nSmith, B. (2000a). Planning in Interplanetary Space: Theory and Practice. In\nAIPS-00. Proceedings of the Fifth Int. Conf. on AI Planning and Scheduling. 17\n[Jonsson et al., 2000b] Jonsson, A., Morris, P., Muscettola, N., Rajan, K., and\nSmith, B. (2000b). Planning in Interplanetary Space: Theory and Practice. In\nAIPS-00. Proc. of the Fifth Int. Conf. on Artiﬁcial Intelligence Planning and\nScheduling, pages 177–186. 89\n[Kautz and Selman, 1992] Kautz, H. A. and Selman, B. (1992). Planning as satis-\nﬁability. In ECAI, pages 359–363. 2, 13\n[Kitamura et al., 2011] Kitamura, Y., Segawa, S., Sasajima, M., and Mizoguchi,\nR. (2011). An ontology of classiﬁcation criteria for functional taxonomies. In\nASME 2011 International Design Engineering Technical Conferences and Com-\nputers and Information in Engineering Conference, pages 297–306. American\nSociety of Mechanical Engineers. 132\n[Knight et al., 2001] Knight, R., Rabideau, G., Chien, S. A., Engelhardt, B., and\nSherwood, R. (2001). Casper: Space exploration through continuous planning.\nIEEE Intelligent Systems, 16(5):70–75. 89\n166\n\nBIBLIOGRAPHY\n[Koren et al., 1999] Koren, Y., Heisel, U., Jovane, F., Moriwaki, T., Pritschow, G.,\nUlsoy, G., and Brussel, H. V. (1999). Reconﬁgurable manufacturing systems.\nCIRP Annals - Manufacturing Technology, 48(2):527 – 540. 118\n[Kruchten, 1995] Kruchten, P. B. (1995). The 4+1 view model of architecture.\nIEEE Software, 12(6):42–50. 114\n[Laborie, 2003] Laborie, P. (2003).\nAlgorithms for propagating resource con-\nstraints in AI planning and scheduling: Existing approaches and new results.\nArtif. Intell., 143(2):151–188. 158\n[Lallement et al., 2014] Lallement, R., de Silva, L., and Alami, R. (2014). HATP:\nan HTN planner for robotics. CoRR, abs/1405.5345. 159\n[Lemai and Ingrand, 2004] Lemai, S. and Ingrand, F. (2004). Interleaving Tempo-\nral Planning and Execution in Robotics Domains. In AAAI-04, pages 617–622.\n89\n[Lemaignan et al., 2010] Lemaignan, S., Ros, R., Mosenlechner, L., Alami, R.,\nand Beetz, M. (2010). ORO, a knowledge management platform for cogni-\ntive architectures in robotics. In Intelligent Robots and Systems (IROS), 2010\nIEEE/RSJ International Conference on, pages 3548–3553. 123\n[Mansouri and Pecora, 2014] Mansouri, M. and Pecora, F. (2014). More knowl-\nedge on the table: Planning with space, time and resources for robots. In 2014\nIEEE International Conference on Robotics and Automation, ICRA 2014, Hong\nKong, China, May 31 - June 7, 2014, pages 647–654. IEEE. 16\n[Marvel et al., 2015] Marvel, J. A., Falco, J., and Marstio, I. (2015). Character-\nizing task-based human #x2013;robot collaboration safety in manufacturing.\nIEEE Transactions on Systems, Man, and Cybernetics: Systems, 45(2):260–\n275. 104\n[Masolo et al., 2002] Masolo, C., Masolo, C., Borgo, S., Gangemi, A., Guarino,\nN., Oltramari, A., and Schneider, L. (2002). The wonderweb library of founda-\ntional ontologies. 127, 130\n[Mcdermott et al., 1998] Mcdermott, D., Ghallab, M., Howe, A., Knoblock, C.,\nRam, A., Veloso, M., Weld, D., and Wilkins, D. (1998). PDDL - The Plan-\nning Domain Deﬁnition Language.\nTechnical report, CVC TR-98-003/DCS\nTR-1165, Yale Center for Computational Vision and Control. 2, 10\n167\n\nBIBLIOGRAPHY\n[Morris et al., 2001] Morris, P. H., Muscettola, N., and Vidal, T. (2001). Dynamic\nControl of Plans With Temporal Uncertainty. In International Joint Conference\non Artiﬁcial Intelligence (IJCAI), pages 494–502. 4, 28, 58, 59, 78\n[Muscettola, 1994] Muscettola, N. (1994).\nHSTS: Integrating Planning and\nScheduling. In Zweben, M. and Fox, M.S., editor, Intelligent Scheduling. Mor-\ngan Kauffmann. 3, 17, 24, 30\n[Muscettola et al., 2002] Muscettola, N., Dorais, G. A., Fry, C., Levinson, R., and\nPlaunt, C. (2002). Idea: Planning at the core of autonomous reactive agents. In\nProc. of NASA Workshop on Planning and Scheduling for Space. 89\n[Muscettola et al., 1992] Muscettola, N., Smith, S., Cesta, A., and D’Aloisi, D.\n(1992). Coordinating Space Telescope Operations in an Integrated Planning\nand Scheduling Architecture. IEEE Control Systems, 12(1):28–37. 17\n[Myers, 1999] Myers, K. L. (1999). Cpef: A continuous planning and execution\nframework. AI Magazine, 20(4):63–69. 89\n[Nau et al., 2003] Nau, D., Au, T. C., Ilghami, O., Kuter, U., Murdock, W., Wu,\nD., and Yaman, F. (2003). SHOP2: An HTN Planning System. Journal on\nArtiﬁcial Intelligence Research, 20. 11, 12\n[Nau et al., 1999] Nau, D., Cao, Y., Lotem, A., and Munoz-Avila, H. (1999).\nShop: Simple hierarchical ordered planner. In Proceedings of the 16th Inter-\nnational Joint Conference on Artiﬁcial Intelligence - Volume 2, IJCAI’99, pages\n968–973, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. 11\n[Nesnas et al., 2008] Nesnas, I., Simmons, R., Gaines, D., Kunz, C., Diaz-\nCalderon, A., Estlin, T., Madison, R., Guineau, J., McHenry, M., Shu, I., and\nApfelbaum, D. (2008). Claraty: Challenges and steps toward reusable robotic\nsoftware. International Journal of Advanced Robotic Systems. 89\n[Nilsson et al., 2016] Nilsson, M., Kvarnström, J., and Doherty, P. (2016). Efﬁ-\ncient processing of simple temporal networks with uncertainty: algorithms for\ndynamic controllability veriﬁcation. Acta Inf., 53(6-8):723–752. 78\n[Orlandini et al., 2011] Orlandini, A., Finzi, A., Cesta, A., and Fratini, S. (2011).\nTga-based controllers for ﬂexible plan execution.\nIn KI 2011: Advances in\nArtiﬁcial Intelligence, 34th Annual German Conference on AI., volume 7006 of\nLecture Notes in Computer Science, pages 233–245. Springer. 159\n168\n\nBIBLIOGRAPHY\n[Orlandini et al., 2013] Orlandini, A., Suriano, M., Cesta, A., and Finzi, A. (2013).\nController synthesis for safety critical planning. In IEEE 25th International\nConference on Tools with Artiﬁcial Intelligence (ICTAI 2013), pages 306–313.\nIEEE. 102, 159\n[Pahl et al., 2007] Pahl, G., Beitz, W., Feldhusen, J., and Grote, K. (2007). En-\ngineering design: a systematic approach. Springer, London, UK, 3rd edition\nedition. 132\n[Pellegrinelli et al., 2017] Pellegrinelli, S., Orlandini, A., Pedrocchi, N., Umbrico,\nA., and Tolio, T. (2017).\nMotion planning and scheduling for human and\nindustrial-robot collaboration.\n{CIRP} Annals - Manufacturing Technology,\npages –. 107\n[Prestes et al., 2013] Prestes, E., Carbonera, J. L., Fiorini, S. R., Jorge, V. A. M.,\nAbel, M., Madhavan, R., Locoro, A., Goncalves, P., Barreto, M. E., Habib, M.,\nChibani, A., GÃ c⃝rard, S., Amirat, Y., and Schlenoff, C. (2013). Towards a\ncore ontology for robotics and automation. Robotics and Autonomous Systems,\n61(11):1193 – 1204. Ubiquitous Robotics. 127, 129\n[Py et al., 2010] Py, F., Rajan, K., and McGann, C. (2010). A systematic agent\nframework for situated autonomous systems. In AAMAS, pages 583–590. 89\n[Richter and Westphal, 2010] Richter, S. and Westphal, M. (2010). The LAMA\nplanner: Guiding cost-based anytime planning with landmarks. J. Artif. Intell.\nRes. (JAIR), 39:127–177. 14\n[Russell and Norvig, 2003] Russell, S. J. and Norvig, P. (2003). Artiﬁcial Intelli-\ngence: A Modern Approach. Pearson Education, 2 edition. 1, 8\n[Simmons and Apfelbaum, 1998] Simmons, R. and Apfelbaum, D. (1998). A task\ndescription language for robot control. In in Proceedings of the Conference on\nIntelligent Robots and Systems (IROS. 89\n[Smith et al., 2008] Smith, D. E., Frank, J., and Cushing, W. (2008). The anml\nlanguage. Proceedings of ICAPS-08. 14, 16\n[Stock et al., 2015] Stock, S., Mansouri, M., Pecora, F., and Hertzberg, J. (2015).\nOnline task merging with a hierarchical hybrid task planner for mobile service\nrobots. In Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International\nConference on, pages 6459–6464. 14, 16, 159\n169\n\nBIBLIOGRAPHY\n[Suh et al., 2007] Suh, I. H., Lim, G. H., Hwang, W., Suh, H., Choi, J.-H., and\nPark, Y.-T. (2007). Ontology-based multi-layered robot knowledge framework\n(OMRKF) for robot intelligence. In Intelligent Robots and Systems, 2007. IROS\n2007. IEEE/RSJ International Conference on, pages 429–436. 122\n[Tenorth and Beetz, 2009] Tenorth, M. and Beetz, M. (2009). Knowrob - knowl-\nedge processing for autonomous personal robots. In Intelligent Robots and Sys-\ntems, 2009. IROS 2009. IEEE/RSJ International Conference on, pages 4261–\n4266. 123\n[Turaga et al., 2008] Turaga, P., Chellappa, R., Subrahmanian, V. S., and Udrea,\nO. (2008). Machine recognition of human activities: A survey. IEEE Transac-\ntions on Circuits and Systems for Video Technology, 18(11):1473–1488. 122\n[Umbrico et al., 2016] Umbrico, A., Cesta, A., Mayer, M. C., and Orlandini, A.\n(2016). Steps in assessing a timeline-based planner. In Adorni, G., Cagnoni, S.,\nGori, M., and Maratea, M., editors, AI*IA 2016: Advances in Artiﬁcial Intelli-\ngence - XVth International Conference of the Italian Association for Artiﬁcial\nIntelligence, Genova, Italy, November 29 - December 1, 2016, Proceedings,\nvolume 10037 of Lecture Notes in Computer Science, pages 508–522. Springer.\n158\n[Umbrico et al., 2015] Umbrico, A., Orlandini, A., and Cialdea Mayer, M. (2015).\nEnriching a temporal planner with resources and a hierarchy-based heuristic.\nIn AI*IA 2015, Advances in Artiﬁcial Intelligence, pages 410–423. Springer\nInternational Publishing. 58, 59\n[Vidal and Fargier, 1999] Vidal, T. and Fargier, H. (1999). Handling Contingency\nin Temporal Constraint Networks: From Consistency To Controllabilities. JE-\nTAI, 11(1):23–45. 4, 28, 58, 78, 102, 114\n[Wiendahl et al., 2007] Wiendahl, H.-P., ElMaraghy, H., Nyhuis, P., Zäh, M.,\nWiendahl, H.-H., Dufﬁe, N., and Brieke, M. (2007). Changeable manufacturing\n- classiﬁcation, design and operation. CIRP Annals - Manufacturing Technol-\nogy, 56(2):783 – 809. 118\n170",
    "pdf_filename": "Timeline-based Planning and Execution with Uncertainty - Theory, Modeling Methodologies and Practice.pdf"
}