{
    "title": "Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN",
    "context": "The fast development of location-based social networks (LBSNs) has led to significant changes in society, resulting in popular studies of using LBSN data for socioeconomic prediction, e.g., regional pop- ulation and commercial activity estimation. Existing studies design various graphs to model heterogeneous LBSN data, and further apply graph representation learning methods for socioeconomic prediction. However, these approaches heavily rely on heuristic ideas and expertise to extract task-relevant knowledge from diverse data, which may not be optimal for specific tasks. Additionally, they tend to overlook the inherent relationships between different indicators, limiting the prediction accuracy. Motivated by the re- markable abilities of large language models (LLMs) in commonsense reasoning, embedding, and multi-agent collaboration, in this work, we synergize LLM agents and knowledge graph for socioeconomic prediction. We first construct a location-based knowledge graph (LBKG) to integrate multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to identify relevant meta-paths in the LBKG for each type of socioeconomic prediction task, and design a semantic-guided attention module for knowledge fusion with meta-paths. Moreover, we introduce a cross-task communi- cation mechanism to further enhance performance by enabling knowledge sharing across tasks at both LLM agent and KG levels. On the one hand, the LLM agents for different tasks collaborate to generate more diverse and comprehensive meta-paths. On the other hand, the embeddings from different tasks are adaptively merged for better socioeconomic prediction. Experiments on two datasets demonstrate the effectiveness of the synergistic design between LLM and KG, providing insights for information sharing across socioeconomic prediction tasks. Keywords Large language models, knowledge graph, location-based social network, socioeconomic prediction âˆ—Corresponding Author. 1 The development of location-based social networks (LBSNs) has significantly advanced socioeconomic prediction with rich web- sourced LBSN data such as user-generated content on review plat- forms. Socioeconomic indicators like regional population, user ac- tivity, and rating, provide a more comprehensive description of LBSN in turn, which can be leveraged by various web applica- tions to offer enhanced services such as location recommendation, web page description, and personal assistants. As a result, socioe- conomic prediction in the context of LBSN has become increas- ingly important, leading to a growing body of research in this field [3, 7, 9, 17, 23, 24, 30, 32â€“35, 37] Traditionally people collect socioeconomic indicators from sur- veys, which are costly and time-consuming. Recently, data-driven methods have become popular, which use machine learning models to predict the socioeconomic indicators based on various LBSN data. The LBSN data comes from various sources and is heterogeneous. Existing studies have widely used graph structure to model the com- plex relationships within LBSN data, and predict the socioeconomic indicators through graph representation learning methods. They construct either multi-view graphs [9, 30, 35] or knowledge graphs (KGs) [16, 37] to model different factors in LBSN data like mobility, spatial proximity, and functionality. However, These approaches highly rely on heuristic ideas and expertise to extract knowledge related to the tasks from LBSN data, such as the construction of sub- graphs or definition of meta-structures, which may be sub-optimal for different indicator prediction tasks. Moreover, the intrinsic cor- relations and potential for knowledge sharing across different so- cioeconomic prediction tasks are often overlooked, limiting the overall prediction accuracy. The recently emerged large language models (LLMs) provide a promising solution to these limitations. LLMs have demonstrated several remarkable abilities which could help socioeconomic pre- diction [28]: (1) Latent semantic embedding. At the foundational level, LLMs are able to generate text embeddings with rich seman- tic information, which makes it possible to integrate LLM with deep learning models to improve the performance by leveraging the inherent semantic information in the LBSN data. (2) Explicit arXiv:2411.00028v2  [cs.CL]  19 Nov 2024",
    "body": "Synergizing LLM Agents and Knowledge Graph for\nSocioeconomic Prediction in LBSN\nZhilun Zhou\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity\nBeijing, China\nzzl22@mails.tsinghua.edu.cn\nJingyang Fan\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity\nBeijing, China\nsiemprestr@gmail.com\nYu Liu\nUniversity of Oxford\nOxford, United Kingdom\nliuyu2419@126.com\nFengli Xuâˆ—\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity\nBeijing, China\nfenglixu@tsinghua.edu.cn\nDepeng Jin\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity\nBeijing, China\njindp@tsinghua.edu.cn\nYong Li\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity\nBeijing, China\nliyong07@tsinghua.edu.cn\nAbstract\nThe fast development of location-based social networks (LBSNs)\nhas led to significant changes in society, resulting in popular studies\nof using LBSN data for socioeconomic prediction, e.g., regional pop-\nulation and commercial activity estimation. Existing studies design\nvarious graphs to model heterogeneous LBSN data, and further\napply graph representation learning methods for socioeconomic\nprediction. However, these approaches heavily rely on heuristic\nideas and expertise to extract task-relevant knowledge from diverse\ndata, which may not be optimal for specific tasks. Additionally,\nthey tend to overlook the inherent relationships between different\nindicators, limiting the prediction accuracy. Motivated by the re-\nmarkable abilities of large language models (LLMs) in commonsense\nreasoning, embedding, and multi-agent collaboration, in this work,\nwe synergize LLM agents and knowledge graph for socioeconomic\nprediction. We first construct a location-based knowledge graph\n(LBKG) to integrate multi-sourced LBSN data. Then we leverage\nthe reasoning power of LLM agent to identify relevant meta-paths\nin the LBKG for each type of socioeconomic prediction task, and\ndesign a semantic-guided attention module for knowledge fusion\nwith meta-paths. Moreover, we introduce a cross-task communi-\ncation mechanism to further enhance performance by enabling\nknowledge sharing across tasks at both LLM agent and KG levels.\nOn the one hand, the LLM agents for different tasks collaborate to\ngenerate more diverse and comprehensive meta-paths. On the other\nhand, the embeddings from different tasks are adaptively merged\nfor better socioeconomic prediction. Experiments on two datasets\ndemonstrate the effectiveness of the synergistic design between\nLLM and KG, providing insights for information sharing across\nsocioeconomic prediction tasks.\nKeywords\nLarge language models, knowledge graph, location-based social\nnetwork, socioeconomic prediction\nâˆ—Corresponding Author.\n1\nIntroduction\nThe development of location-based social networks (LBSNs) has\nsignificantly advanced socioeconomic prediction with rich web-\nsourced LBSN data such as user-generated content on review plat-\nforms. Socioeconomic indicators like regional population, user ac-\ntivity, and rating, provide a more comprehensive description of\nLBSN in turn, which can be leveraged by various web applica-\ntions to offer enhanced services such as location recommendation,\nweb page description, and personal assistants. As a result, socioe-\nconomic prediction in the context of LBSN has become increas-\ningly important, leading to a growing body of research in this\nfield [3, 7, 9, 17, 23, 24, 30, 32â€“35, 37]\nTraditionally people collect socioeconomic indicators from sur-\nveys, which are costly and time-consuming. Recently, data-driven\nmethods have become popular, which use machine learning models\nto predict the socioeconomic indicators based on various LBSN data.\nThe LBSN data comes from various sources and is heterogeneous.\nExisting studies have widely used graph structure to model the com-\nplex relationships within LBSN data, and predict the socioeconomic\nindicators through graph representation learning methods. They\nconstruct either multi-view graphs [9, 30, 35] or knowledge graphs\n(KGs) [16, 37] to model different factors in LBSN data like mobility,\nspatial proximity, and functionality. However, These approaches\nhighly rely on heuristic ideas and expertise to extract knowledge\nrelated to the tasks from LBSN data, such as the construction of sub-\ngraphs or definition of meta-structures, which may be sub-optimal\nfor different indicator prediction tasks. Moreover, the intrinsic cor-\nrelations and potential for knowledge sharing across different so-\ncioeconomic prediction tasks are often overlooked, limiting the\noverall prediction accuracy.\nThe recently emerged large language models (LLMs) provide a\npromising solution to these limitations. LLMs have demonstrated\nseveral remarkable abilities which could help socioeconomic pre-\ndiction [28]: (1) Latent semantic embedding. At the foundational\nlevel, LLMs are able to generate text embeddings with rich seman-\ntic information, which makes it possible to integrate LLM with\ndeep learning models to improve the performance by leveraging\nthe inherent semantic information in the LBSN data. (2) Explicit\narXiv:2411.00028v2  [cs.CL]  19 Nov 2024\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\ncommonsense reasoning. Moreover, LLMs possess vast com-\nmonsense knowledge, based on which they can perform complex\nreasoning [36]. This capability facilitates the automatic extraction\nof task-relevant knowledge from LBSN data. (3) Multi-agent col-\nlaboration. At the highest level, LLM agents can communicate\nwith other agents through natural language, and collaborate to\nsolve complex tasks which is difficult for a single agent [6, 11, 31].\nSuch ability enables LLM to transfer knowledge across different\nsocioeconomic prediction tasks via semantic-rich natural language,\nand collaboratively improve the performance.\nInspired by this, we propose a learning framework that Synergize\nLLM Agent and Knowledge Graph learning model (SLAK) for so-\ncioeconomic prediction. We first construct a location-based knowl-\nedge graph (LBKG) to comprehensively integrate LBSN data. To\nextract task-relevant knowledge, we construct an LLM agent to auto-\nmatically discover meta-paths in the LBKG that help the prediction\nfor specific indicators, and extract a corresponding meta-path-based\nsub-KG. Moreover, we leverage KG representation learning model\nto distil knowledge from each meta-path-based sub-KG, and de-\nsign a semantic-enhanced knowledge fusion module to adaptively\nfuse the knowledge based on semantic embeddings of meta-paths\nobtained from LLM. In addition, we propose a cross-task commu-\nnication mechanism to enable knowledge sharing across different\nsocioeconomic prediction tasks at both the LLM agent and KG level.\nSpecifically, the LLM agents collaborate to extract better meta-paths,\nand we also adaptively merge the KG embeddings from different\ntasks with the knowledge fusion module.\nOur contribution can be summarized as follows:\nâ€¢ We propose a framework to synergize LLM agents and KG\nfor socioeconomic prediction. We leverage the reasoning\ncapability of LLM agent to find task-relevant meta-paths\nfrom LBKG, and further use the semantic information of\nthe meta-paths to guide the knowledge fusion.\nâ€¢ We design a cross-task communication mechanism to en-\nable knowledge sharing across different socioeconomic pre-\ndiction tasks at both the LLM agent level through multi-\nagent collaboration and the KG level through semantic\nattention, which further improves the accuracy.\nâ€¢ Extensive experiments on two city-scale datasets show that\nour model surpasses existing methods by 2.9-74.2% in terms\nof ğ‘…2 on eight indicator prediction tasks, demonstrating\nthe effectiveness of our synergistic model between LLM\nand KG. Several in-depth analyses further show the advan-\ntage of our model design, providing insights for web-based\nsocioeconomic prediction in LBSN.\n2\nPreliminaries\n2.1\nProblem Statement\nDefinition 2.1 (Urban Region). We define urban regions as non-\noverlapping irregular areas in a city, which are partitioned by main\nroad networks, such as a block, denoted as L = {ğ¿1, ğ¿2, . . . , ğ¿ğ‘ğ¿}.\nDefinition 2.2 (Socioeconomic Prediction Problem). Given a\nset of socioeconomic indicators I = {ğ¼1, . . . , ğ¼ğ‘ğ¼} in LBSN such\nas population, commercial activity, user activity and rating, the\nsocioeconomic prediction task aims to predict the value of these\nindicators for urban regions based on various LBSN data, i.e., learn a\nmapping function ğ‘“: L â†’VI, where VI is the range of indicator\nğ¼âˆˆI.\n2.2\nLocation-based Knowledge Graph\nKG is a multi-relational graph structure, defined as G = {E, R, F },\nwhere E is the entity set, R is the relation set, and F is the fact\nset. Each fact in F is denoted as a triplet (â„,ğ‘Ÿ,ğ‘¡), representing a\ndirectional edge from the head entity â„âˆˆE to tail entity ğ‘¡âˆˆE\nwith relation type ğ‘ŸâˆˆR. Due to its remarkable ability to represent\nheterogeneous data and integrate diverse knowledge, KG has been\nwidely used in the study of LBSN [13, 15, 25, 37]. Inspired by this, we\nconstruct an LBKG to integrate multi-sourced LBSN data [14, 37].\nThe LBKG contains various elements in LBSN such as regions,\nPOIs, POI categories, brands, business areas, and various relations\nbetween them. The details of LBKG are presented in Appendix A.\nPrevious studies have shown the promising ability of LBKG in\nsocioeconomic prediction [37]. However, there are still two chal-\nlenges to be addressed. First, the LBKG consists of many different\nentities and relations, containing knowledge in various domains,\nsome of which may not be related to the specific socioeconomic\nindicator or may even harm the prediction performance, which\nimplies the difficulty of extracting relevant knowledge manually.\nSecond, different socioeconomic indicators are inherently corre-\nlated, with many influenced by similar knowledge in the LBKG. For\nexample, the presence of business areas near a region may simul-\ntaneously enhance its commercial vitality and attract population\ngrowth. It remains unclear how to leverage the shared knowledge\namong different indicators to improve the prediction performance.\n3\nMethods\n3.1\nFramework Overview\nTo address the aforementioned challenges, we propose a framework\nsynergizing the capability of LLM agent and KG, as shown in Fig-\nure 1. To overcome the first challenge, we construct an LLM agent\nto extract task-relevant knowledge by prompting it to find meta-\npaths related to the socioeconomic prediction task from the LBKG,\nand extract a corresponding sub-KG based on each meta-path. The\nmeta-path-based sub-KGs are fed into a KG learning model to distil\nknowledge from each sub-KG, and we further use the semantic em-\nbeddings of meta-paths to guide the knowledge fusion. The output\nregion embeddings are used for socioeconomic prediction through\na final MLP output layer. As for the second challenge, we design a\ncross-task communication mechanism, as shown in Figure 2. Dif-\nferent indicator prediction tasks share knowledge at both the LLM\nagent level and KG level. Specifically, the LLM agents recommend\npotential meta-paths for other tasks from diverse perspectives, and\nupdate their own meta-paths selection based on knowledge from\nother tasks. Moreover, we leverage embedding LLM to obtain a\nsemantic embedding for each task, which is used to adaptively fuse\nthe region embeddings from different tasks.\n3.2\nSingle-task Learning\n3.2.1\nMeta-path Extraction. The LBKG integrates various LBSN\ndata comprehensively and incorporates knowledge from various do-\nmains, such as the spatial knowledge of geographical relationships\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\nLBKG\nğ‘©ğ‘©ğ‘©ğ‘©ğŸğŸ\nğ‘©ğ‘©ğ‘©ğ‘©ğŸğŸ\nğ‘·ğ‘·ğŸğŸ\nğ‘·ğ‘·ğŸğŸ\nğ‘¹ğ‘¹ğŸğŸ\nKG \nEncoder\n1: ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…\nğ‘†ğ‘†ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ\nğ¶ğ¶ğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒ\n2: ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…\nğ»ğ»ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğµğµğµğµğµğµğµğµğµğµ\nğ»ğ»ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘…\nâ€¦\nğ‘©ğ‘©1\nğ‘¹ğ‘¹ğŸğŸ\nğ‘¹ğ‘¹ğŸğŸ\nğ‘©ğ‘©ğ‘©ğ‘©ğŸğŸ\nğ‘©ğ‘©ğ‘©ğ‘©ğŸğŸ\nğ‘©ğ‘©1\nğ‘·ğ‘·ğŸğŸ\nğ‘·ğ‘·ğŸğŸ\nğ‘¹ğ‘¹ğŸğŸ\nğ‘¹ğ‘¹ğŸğŸ\nâ€¦\nSub-KG \nEncoder\nSub-KG \nEncoder\nSemantic-guided \nKnowledge Fusion\nPlease find some meta-paths that may help the \nPopulation prediction task.\nNatural language encoding of meta-paths\n1: Region THAT is served by BusinessArea THAT contains POI\n2: Region THAT has store of Brand THAT has placed store at Region \nâ€¦\nMLP\nSocioeconomic \nIndicator\nMeta-path-\nbased Sub-KGs\nLLM Agent\nEmbedding \nLLM\nğ‘¬ğ‘¬ğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿ\nğ‘¬ğ‘¬ğ‘€ğ‘€ğ‘€ğ‘€\nğ‘¹ğ‘¹\nğ‘©ğ‘©ğ‘©ğ‘©\nğ‘©ğ‘©\nğ‘·ğ‘·\nRegion\nBusinessArea\nBrand\nPOI\nFigure 1: The overall framework of our proposed model SLAK.\nbetween regions, the functional knowledge regarding POIs and POI\ncategories, and mobility knowledge about population flow [37]. It\nis crucial to identify relevant information that can aid in predicting\nspecific socioeconomic indicators. Inspired by the ability of meta-\npaths in KG to capture certain semantic contexts, we aim to find the\nmost relevant meta-paths that contribute to the prediction tasks.\nWe first provide the definition of meta-path as follows [21].\nDefinition 3.1 (Meta-path). A meta-path in KG can be repre-\nsented in the form of ğ¸1\nğ‘…1\nâˆ’âˆ’â†’ğ¸2\nğ‘…2\nâˆ’âˆ’â†’. . .\nğ‘…ğ‘™âˆ’1\nâˆ’âˆ’âˆ’âˆ’â†’ğ¸ğ‘™, denoting a path\nfrom entity ğ¸1, ğ¸2, . . . to ğ¸ğ‘™through relations ğ‘…1, . . . , ğ‘…ğ‘™âˆ’1.\nMeta-paths provide rich semantic contexts in the LBKG. For ex-\nample, the meta-pathğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›captures the competitive relationships between POIs in two\nregions, which may affect the commercial activity of these regions.\nHowever, given the large number of entities and relations in\nLBKG, it is not trivial to find helpful meta-paths. Here we draw\ninspiration from the emergent commonsense reasoning ability of\nLLMs. It has been demonstrated that LLM can identify important\nmeta-structures in heterogeneous information networks through\nreasoning [2]. Therefore, we construct an LLM agent to automati-\ncally find relevant meta-paths from LBKG. To enable the agent to\nunderstand the LBKG, we input the schema of LBKG described in\nnatural language. Then we prompt the agent to generate several\npotential meta-path schemes for the socioeconomic prediction task.\nThe detailed prompts are shown in Appendix B.\n3.2.2\nKG Learning Model. Following previous work [37], we em-\nploy a hierarchical KG learning model to learn region embeddings\nfrom LBKG based on the extracted meta-paths. First, we use a KG\nencoder to extract global knowledge from the LBKG. Here we adopt\na graph convolution model called R-GCN [20] as the KG encoder.\nDifferent from vanilla GCN, R-GCN aggregates information from\nneighboring nodes through each type of relation separately, which\ncan better capture the structural information in KG. Specifically, let\nğ’†(ğ‘™)\nğ‘–\ndenote the embedding of entity ğ‘’ğ‘–at the ğ‘™-th R-GCN layer, the\ninformation aggregation function is:\nğ’†(ğ‘™+1)\nğ‘–\n= ğœ(\nâˆ‘ï¸\nğ‘ŸâˆˆR\nâˆ‘ï¸\nğ‘—âˆˆNğ‘Ÿ\nğ‘–\nğ‘Š(ğ‘™)\nğ‘Ÿ\nğ’†(ğ‘™)\nğ‘—\n+ğ‘Š(ğ‘™)\n0\nğ’†(ğ‘™)\nğ‘–\n),\n(1)\nwhere ğ’†(ğ‘™+1)\nğ‘–\nis the embedding at the (ğ‘™+ 1)-th layer, Nğ‘Ÿ\nğ‘–is the\nneighboring entities of ğ‘’ğ‘–with respect to relation ğ‘Ÿ, andğ‘Š(ğ‘™)\nğ‘Ÿ\n,ğ‘Š(ğ‘™)\n0\nare learnable weight matrices.\nThen we distil domain knowledge from the meta-paths. Given\na meta-path scheme generated by LLM agent, we first extract all\nmeta-paths with such scheme from the LBKG to construct a sub-\nKG, as shown in Figure 1. The sub-KG preserves all the contextual\nknowledge defined by the meta-path scheme in LBKG. In practice,\nwe use the graph database Neo4j1 to store the LBKG and query it\nto get the meta-paths with Cypher language. Consequently, each\nsub-KG is fed into a sub-KG encoder, which is also R-GCN model,\nto obtain region embeddings from each meta-path.\n3.2.3\nSemantic-guided Knowledge Fusion. Different meta-paths\nhave different importance in socioeconomic indicator prediction\ntasks. Therefore, we propose a semantic-guided knowledge fusion\nmodule to dynamically fuse the knowledge of different meta-paths.\nWe first obtain the natural language encoding of meta-paths using\nmethods in [2], which provides a description of the meta-path easy\nfor LLM to understand. Specifically, we use the conjunction word\nTHAT to construct a nested clause for each meta-path, as shown in\nFigure 1. The constructed sentences align with commonly-used Eng-\nlish grammar, and thus are suitable for language models. Moreover,\nwe use an embedding LLM to generate semantic embeddings for\nthese sentences. We choose the GTE-based model [12], which is one\nof the top models on the text embedding leaderboard MTEB [18],\n1https://neo4j.com/\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\nto obtain a ğ‘‘ğ¿ğ¿ğ‘€= 768 dimensional semantic embedding for each\nmeta-path.\nLet ğ‘ƒ1, . . . , ğ‘ƒğ‘ğ‘ƒdenote the meta-paths, and ğ‘¬ğ‘€ğ‘ƒâˆˆRğ‘ğ‘ƒÃ—ğ‘‘ğ¿ğ¿ğ‘€\nare the semantic embeddings of meta-paths. We first project the em-\nbeddings to get the query vector ğ‘¸= ğ‘¬ğ‘€ğ‘ƒğ‘¾ğ‘„âˆˆRğ‘ğ‘ƒÃ—ğ‘‘â„, where ğ‘‘â„\nis output embedding size of the sub-KG encoder. Then we calculate\nthe attention weights as:\nğ›¼ğ‘–= softmax(\nğ‘¸âŠ¤\nğ‘–ğ’†ğ‘ƒğ‘–\nğ‘—\nâˆšï¸\nğ‘‘â„\n),ğ‘–âˆˆ{1, 2, . . . , ğ‘ğ‘ƒ},\n(2)\nwhere ğ’†ğ‘ƒğ‘–\nğ‘—\nâˆˆRğ‘‘â„is the embedding of region ğ¿ğ‘—at the meta-path-\nbased sub-KG of ğ‘ƒğ‘–. Then, the output embedding of region ğ¿ğ‘—is\ncalculated as:\nğ’†ğ‘—=\nğ‘ğ‘ƒ\nâˆ‘ï¸\nğ‘–=1\nğ›¼ğ‘–ğ’†ğ‘ƒğ‘–\nğ‘—.\n(3)\nFinally, the above embeddings are added to the output of the\nKG encoder through a residual connection, and fed into an MLP\nlayer for indicator prediction. We train our model in a supervised\nmanner and employ MSE loss to optimize it.\n3.3\nCross-task Communication\nTask 1\nTask 2\nTask 3\nTask 4\nMeta-path recommendation\nMeta-path self-update\nSemantic-guided \nKnowledge Fusion\nEmbedding \nLLM\nTextual description of tasks\nThe population prediction task \naims to predict the population \nof urban regions based on \nurban knowledge graph.\nâ€¦\nğ‘¬ğ‘¬ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“\nğ‘¬ğ‘¬ğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿ\nRegion embedding \nfrom other tasks\nMLP\nSocioeconomic \nIndicator\nğ‘¬ğ‘¬ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡\n(a)\n(b)\nFigure 2: Cross-task communication mechanism. (a) Agent-\nlevel communication through multi-agent collaboration.\n(b) KG embedding level communication through semantic-\nguided knowledge fusion.\nSince different socioeconomic indicators are inherently corre-\nlated, we further design a cross-task communication mechanism\nto enable knowledge sharing across different tasks regarding both\nthe meta-paths finding and the embedding learning, as shown in\nFigure 2. We first leverage the multi-agent collaboration ability of\nLLMs to optimize the meta-paths extracted from LBKG for each\ntask. Then we dynamically fuse the embeddings from different tasks\nfor indicator prediction.\nPrevious studies regarding multi-agent collaboration have shown\nthat when assigned different roles, multiple LLM agents can think\nfrom different perspectives and communicate with each other to pro-\nvide a more comprehensive and accurate answer to questions [1, 10].\nInspired by this, we provide the agents with the previously found\nmeta-paths of all tasks, and ask them to recommend a new meta-\npath to each of the other agents from their own taskâ€™s perspective.\nWe leverage the chain-of-thought prompting techniques [29], and\nask the agent to consider the relationships between two tasks and\nAlgorithm 1 Training algorithm of our model\n1: Round 1: Single-task training\n2:\nfor Indicator ğ¼ğ‘–âˆˆ{ğ¼1, . . . , ğ¼ğ‘ğ¼} do\n3:\nGenerate meta-paths Pğ‘–= {ğ‘ƒğ‘–\n1, . . . , ğ‘ƒğ‘–\nğ‘ğ‘ƒ} through LLM\nagent ğ´ğ‘–\n4:\nExtract corresponding sub-KGs from LBKG\n5:\nGenerate semantic embeddings of meta-paths ğ¸ğ‘€ğ‘ƒ\n6:\nTrain the KG learning model to predict ğ¼ğ‘–for many\nepochs with early-stopping\n7:\nSave the region embeddings ğ¸ğ¼ğ‘–ğ‘Ÿğ‘’ğ‘”at the best epoch\n8: Round 2: Cross-task communication\n9:\nâŠ²Meta-paths update\n10:\nfor Indicator ğ¼ğ‘–âˆˆ{ğ¼1, . . . , ğ¼ğ‘ğ¼} do\n11:\nAgent ğ´ğ‘–updates its own meta-paths Pğ‘–\nğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’\n=\n{ğ‘ƒğ‘–\n1,ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’, . . . , ğ‘ƒğ‘–\nğ‘ğ‘ƒ,ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’}\n12:\nAgent ğ´ğ‘–recommends a meta-path to each other task\nğ‘ƒğ‘—â†ğ‘–, ğ‘—â‰ ğ‘–\n13:\nâŠ²Model training\n14:\nfor Indicator ğ¼ğ‘–âˆˆ{ğ¼1, . . . , ğ¼ğ‘ğ¼} do\n15:\nObtain the final meta-paths Pğ‘–ğ‘›ğ‘’ğ‘¤\n=\nPğ‘–\nğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’âˆª\n{ğ‘ƒğ‘–â†ğ‘—|ğ‘—â‰ ğ‘–}\n16:\nTrain the model to predict ğ¼ğ‘–with meta-paths Pğ‘–ğ‘›ğ‘’ğ‘¤and\nembeddings {ğ¸ğ¼ğ‘—\nğ‘Ÿğ‘’ğ‘”|ğ‘—â‰ ğ‘–}\nprovide the detailed thinking process. For example, the agent re-\nsponsible for the population prediction task may think about how\nthe population affects the commercial activity, and recommend a\nrelevant meta-path to the commercial activity prediction task. In\naddition, we ask each agent to update the previous meta-paths of\nits own tasks based on those from other tasks. We combine the\nself-updated meta-paths as well as meta-paths recommended by\nother agents as the final meta-paths for each task.\nMoreover, we transfer the region embeddings across tasks to\nfurther enhance the performance, as shown in Figure 2(b). We only\nmodify the final layer of the KG learning model in Figure 1 by\ncombining the current task embedding ğ¸ğ‘Ÿğ‘’ğ‘”with embeddings pre-\nviously learned from other tasks. Here we adopt the same semantic-\nguided knowledge fusion module as mentioned in Section 3.2.3. We\nfirst construct a description of each task in natural language, and\nleverage the embedding LLM to obtain the semantic embedding of\neach task, denoted as ğ¸ğ‘¡ğ‘ğ‘ ğ‘˜. Then ğ¸ğ‘¡ğ‘ğ‘ ğ‘˜is used as the query of the\nattention module to adaptively fuse the embeddings using Equa-\ntion 2 and 3. The output of the semantic-guided attention module\nis added to ğ‘¬ğ‘Ÿğ‘’ğ‘”of the current task through a residual connection,\nand the obtained region embeddings ğ‘¬ğ‘“ğ‘¢ğ‘ ğ‘’ğ‘‘are finally used for\nsocioeconomic prediction.\nThe overall training algorithm of our model is presented in Al-\ngorithm 1. Note that it consists of two rounds of training. In the\nfirst round, we train the model for each task separately, and save\nthe final region embeddings ğ¸ğ¼ğ‘–ğ‘Ÿğ‘’ğ‘”. In the second round, the LLM\nagents communicate to generate new meta-paths Pğ‘–ğ‘›ğ‘’ğ‘¤for each\ntask, and we train the model for each task based on Pğ‘–ğ‘›ğ‘’ğ‘¤and region\nembeddings from the previous round.\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\n4\nExperiments\nTable 1: The basic information of two real-world datasets.\nCity\nBeijing\nShanghai\nBasic\nInfo.\n#Regions\n523\n2032\nIndicators\npopulation, commercial activity,\nuser activity, rating\nLBKG\nStatistics\n#Entities\n23,754\n41,338\n#Relations\n35\n35\n#Facts\n330,652\n589,850\n4.1\nDatasets\nWe conduct experiments on two real-world datasets, Beijing and\nShanghai, to evaluate our model.\nBeijing dataset. It contains 523 regions in Beijing within the Fifth\nRing Road, which are partitioned by main road networks. We col-\nlect the population data from WorldPop2. The commercial activity\nindicators are reflected by the number of firms [4]. We also col-\nlected restaurant data from Dianping, one of the most popular\nreview platforms in China. We use the total number of reviews of\nall restaurants to reflect the user activity of a region. The rating\nindicator is calculated as the average user rating of all restaurants\nin a region.\nShanghai dataset. It contains 2032 regions in Shanghai, which are\nalso divided by main road networks. The indicators in Shanghai\nand their data sources are the same as Beijing dataset. The basic\nstatistics of these datasets are shown in Table 1.\n4.2\nExperiment Settings\n4.2.1\nBaselines. We compare our model with state-of-the-art graph\nembedding methods as well as socioeconomic prediction methods.\nGraph embedding methods.\nâ€¢ GAT [22]: It is a graph convolution network that aggregates\ninformation from neighboring nodes with learnable weights.\nSocioeconomic prediction methods.\nâ€¢ HUGAT [9]: It constructs a heterogeneous graph to model LBSN\ndata, and uses a heterogeneous graph attention network to learn\nlocation embeddings for socioeconomic indicator prediction.\nâ€¢ MGFN [30]: It constructs mobility graphs and leverages multi-\nlevel attention mechanism to learn region embeddings.\nâ€¢ HKGL [37]: It uses a hierarchical KG learning model to learn\nglobal and domain knowledge from LBKG. We also evaluate a\nvariant of this model named HKGL-trans by transferring region\nembeddings across tasks. Specifically, we concatenate the task-\nspecific embeddings with embeddings learned from other tasks\nat the final layer.\nFor our proposed SLAK model, we compare two versions of it.\nSLAK-single denotes the model training on different tasks sepa-\nrately, i.e., the round 1 in Algorithm 1. SLAK-comm denotes the\nmodel with cross-task communication, i.e., the round 2 in Algo-\nrithm 1.\n2https://hub.worldpop.org/geodata/summary?id=24924\n4.2.2\nEvaluation Metrics. We randomly split the regions into train,\nvalidation, and test set by 6:2:2, and adopt the commonly used\nMean Absolute Error (MAE), Root Mean Square Error (RMSE), and\ncoefficient of determination (ğ‘…2) as evaluation metrics.\n4.3\nOverall Performance\nWe present the overall performance of our model and baselines in\nTable 2 and 3, from which we have the following observations.\nFirst, our model outperforms baseline methods on all eight indi-\ncator prediction tasks across two datasets, with improvements in\nterms of ğ‘…2 ranging from 2.9% to 159.8%, demonstrating the effec-\ntiveness and robustness of our model. Specifically, our SLAK-single\nmodel is better than baselines on six of the eight indicators, indi-\ncating that leveraging LLM agents to extract relevant meta-paths\non a single task is promising but not robust enough. Moreover,\nthe cross-task communication mechanism further improves our\nperformance by 1.9% to 23.8% in terms of ğ‘…2, achieving the best\nresults.\nSecond, HKGL generally achieves the best performance among\nbaselines because it uses LBKG to effectively integrate LBSN data,\nand defines several sub-KGs to capture diverse knowledge in LBKG.\nHowever, it still performs worse than our model, which suggests\nthat manually extracting relevant knowledge from LBSN data may\nlead to sub-optimal results. On the contrary, we leverage the rea-\nsoning and multi-agent collaboration ability of LLM agents to auto-\nmatically find and optimize meta-paths, thus showing considerable\nperformance gain.\nThird, it is natural to question whether other methods can also\nbenefit from transferring knowledge across tasks. Therefore, we\ncompare with a variant of the best baseline model by concatenat-\ning region embeddings learned from other indicators (HKGL vs.\nHKGL-trans). We notice that the performance becomes worse on\nall indicators with embedding transfer. This is because embeddings\nfrom different tasks are trained with supervised signals from other\nindicators, which may not be suitable for the current task. This\nsuggests that it is non-trivial to transfer knowledge across differ-\nent tasks through embedding. However, our model shows better\nperformance with cross-task communication mechanism, which\nfurther demonstrates the effectiveness of semantic-guided knowl-\nedge fusion as well as knowledge sharing through multi-agent\ncollaboration.\nTo intuitively understand the socioeconomic prediction result,\nwe visualize the indicator prediction error on test regions of our\nmodel and the best baseline model on user activity prediction task.\nAs shown in Figure 3, our model generally shows smaller errors\ncompared with HKGL. Specifically, our model shows better accuracy\nin Haidian and Wangjing areas, which are known for their high\ndensity of tech companies as well as vibrant user activities in LBSN.\nIn addition, our model also performs better in Fengxian district\nin southwestern Shanghai. Such results further demonstrate the\naccuracy of our model in socioeconomic indicator prediction tasks.\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\nTable 2: Performance comparison with baselines on Beijing dataset. Best result are presented in bold, and the second best\nresults are underlined.\nPopulation\nCommercial\nUser activity\nRating\nModel\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nGAT\n0.676\n0.916\n0.305\n1.293\n1.712\n0.270\n2.164\n3.125\n0.115\n0.706\n1.056\n0.058\nMGFN\n0.667\n0.904\n0.324\n3.235\n6.155\n0.200\n5.552\n8.657\n0.179\n0.772\n1.002\n0.152\nHUGAT\n0.695\n0.919\n0.301\n1.165\n1.558\n0.396\n1.947\n2.987\n0.191\n0.728\n1.080\n0.014\nHKGL\n0.660\n0.886\n0.350\n1.000\n1.238\n0.619\n1.864\n2.618\n0.379\n0.752\n1.031\n0.102\nHKGL-trans\n0.790\n1.007\n0.162\n1.066\n1.379\n0.527\n1.827\n2.726\n0.326\n0.736\n1.058\n0.055\nSLAG-single\n0.660\n0.895\n0.337\n0.982\n1.227\n0.626\n1.690\n2.516\n0.426\n0.666\n0.964\n0.214\nSLAG-comm\n0.651\n0.879\n0.360\n0.971\n1.204\n0.640\n1.557\n2.438\n0.461\n0.655\n0.933\n0.265\nTable 3: Performance comparison with baselines on Shanghai dataset. Best result are presented in bold, and the second best\nresults are underlined.\nPopulation\nCommercial\nUser activity\nRating\nModel\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nMAE\nRMSE\nR2\nGAT\n0.667\n0.844\n0.446\n1.390\n1.777\n0.068\n2.368\n2.950\n0.236\n0.917\n1.209\n0.086\nMGFN\n0.747\n0.954\n0.293\n2.355\n4.613\n0.085\n6.136\n9.353\n0.160\n0.896\n1.185\n0.122\nHUGAT\n0.662\n0.844\n0.446\n1.408\n1.787\n0.056\n2.342\n2.891\n0.267\n0.957\n1.220\n0.068\nHKGL\n0.658\n0.852\n0.436\n1.309\n1.686\n0.160\n1.964\n2.505\n0.449\n0.870\n1.140\n0.186\nHKGL-trans\n0.698\n0.936\n0.319\n1.381\n1.752\n0.094\n2.055\n2.598\n0.408\n0.891\n1.167\n0.191\nSLAG-single\n0.620\n0.849\n0.440\n1.323\n1.678\n0.168\n1.864\n2.336\n0.521\n0.864\n1.137\n0.191\nSLAG-comm\n0.627\n0.812\n0.488\n1.294\n1.664\n0.183\n1.816\n2.311\n0.531\n0.838\n1.114\n0.224\nOurs\nBeijing\nHKGL\nShanghai\nError\nShanghai\nBeijing\nFigure 3: Visualization of prediction error of user activity\n(measured in log scale). We use red squares to mark the re-\ngions where baseline performs worse.\n4.4\nAblation Study\nTo demonstrate the effectiveness of our model design, we further\nconduct ablation studies. We first examine the influence of multi-\nagent collaboration by removing the meta-path self-update or meta-\npath recommendation. For example, removing self-update means\nthat we only use the meta-paths recommended by other agents\nPopulation\nCommercial User activity\nRating\nIndicator\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nR2\nOurs\nw/o self-update\nw/o rec.\n(a) Beijing\nPopulation\nCommercial User activity\nRating\nIndicator\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nR2\nOurs\nw/o self-update\nw/o rec.\n(b) Shanghai\nPopulation\nCommercial User activity\nRating\nIndicator\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nR2\nOurs\nw/o trans.\nw/o attn.\n(c) Beijing\nPopulation\nCommercial User activity\nRating\nIndicator\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nR2\nOurs\nw/o trans.\nw/o attn.\n(d) Shanghai\nFigure 4: Performance comparison of models without self-\nupdate meta-paths (w/o self-update), recommended meta-\npaths (w/o rec.), embedding transferred from other tasks\n(w/o trans.), and semantic attention (w/o attn.).\nfor each task, while removing recommendation indicates that we\nonly use the self-update meta-paths. As shown in Figure 4(a-b), the\nperformance becomes worse on all indicators across two datasets,\nwith a significant drop over 5.5% in terms of ğ‘…2. Such a result\ndemonstrates the importance of multi-agent collaboration in knowl-\nedge sharing across tasks, where different agents find meta-paths\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\nfrom diverse perspectives, enabling better and more comprehensive\nknowledge extraction.\nMoreover, we evaluate our key designs in the KG learning model,\ni.e., the embedding transfer across tasks as well as the semantic-\nguided knowledge fusion. For the former, we omit the embedding\nfusion module in Figure 2(b) and only use embeddings from the\ncurrent task for prediction. For the latter, we use a traditional self-\nattention module to replace our semantic-guided knowledge fusion\nmodule in our model. It can be observed in Figure 4(c-d) that the\nğ‘…2 drops on almost all indicators without these designs, showing\nthat the semantic information of meta-paths and tasks plays an\nimportant role in fusing diverse knowledge from different meta-\npaths and different tasks. Overall, the results of ablation studies\nvalidate that synergizing LLM agents and KG are crucial for better\nsocioeconomic indicator prediction.\n4.5\nEfficiency of Meta-path Optimization\nTable 4: Performance and time cost comparison with meta-\npath searching algorithms on user activity prediction task.\nGA and Random represent genetic algorithm and random\nsearch, respectively.\nBeijing\nShanghai\nMethod\nMAE\nRMSE\nR2\nTime\nMAE\nRMSE\nR2\nTime\nRandom\n1.621\n2.485\n0.440\n32 min\n1.887\n2.384\n0.501\n85 min\nGA\n1.688\n2.532\n0.419\n37 min\n1.870\n2.315\n0.515\n90 min\nOurs\n1.557\n2.438\n0.461\n4 min\n1.816\n2.311\n0.531\n6 min\nHere we demonstrate the advantage of our meta-paths extraction\nmethod over traditional meta-path searching algorithms. We com-\npare our model with two meta-path searching algorithms, random\nsearch and genetic algorithms.\nIn the genetic algorithm, we define a meta-path as a gene, and the\nchromosome of an individual as a set of 6 meta-paths, which has the\nsame number as our model (3 self-update and 3 recommended meta-\npaths) for fair comparison. The fitness is calculated as the prediction\nğ‘…2 when using these meta-paths to train our model. We generate\n5 individuals in each generation, and calculate the fitness of each.\nThen we select the best two individuals as parents to perform\ncrossover and mutation to produce the next generation. Specifically,\nin the crossover operation, one random meta-path is exchanged\nfrom the parents. Besides, each meta-path has a probability of 10%\nto mutate, i.e., be replaced by a new randomly generated meta-path.\nAs for the random search algorithm, we also set the number of\nmeta-paths as 6 for each individual, and randomly generate 6 meta-\npaths with lengths ranging from 2 to 4. Particularly, we start from\nthe entity type Region, and sequentially sample a relation with such\nentity type as the head entity. We repeat the search for 6 iterations,\nand 5 individuals are generated in each iteration.\nThe performance and time cost of these algorithms and our\nmodel are shown in Table 4. It can be observed that our model\nachieves better performance and lower time cost. Specifically, our\nSLAK model outperforms traditional algorithms by 4.7% and 3.1%\nin terms of ğ‘…2 on Beijing and Shanghai datasets, respectively. This\nis probably because the number of meta-paths in LBKG is large\nand the potential combination of meta-paths is even significantly\nlarger, making it difficult to find better meta-paths through search-\ning. In comparison, the main difference between our method and\nsearching algorithms is that we find meta-paths through reasoning\ninstead of searching. Leveraging the capability of commonsense\nreasoning, LLM can effectively find meta-paths relevant to the indi-\ncator prediction task. Moreover, LLM can optimize the meta-paths\nthrough multi-agent collaboration by enabling multiple agents to\nreason from diverse perspectives, thus leading to better results.\nIn addition, our model reduces the time cost by over 8Ã—, which\nis because when evaluating each combination of meta-paths, the\nsearching algorithms need to train the KG learning model once,\nwhich makes it substantially time-consuming when searching from\na large number of individuals. On the contrary, our methods only\nneed to train the KG learning model for a few times. Furthermore,\nthe time cost of LLM communication is much smaller compared\nwith training the model over and over again.\n4.6\nCase Study of Discovered Meta-paths\nWe present the meta-paths found by our model, random search,\nand genetic algorithms in Table 5. It can be observed that com-\npared with SLAK-single, the meta-paths discovered in the second\nround through multi-agent collaboration are generally longer and\nmore diverse. This is probably because these meta-paths are gen-\nerated by LLM agents based on the previously found ones, which\nenables agents to consider more complex meta-paths. Moreover,\nwe find that the meta-paths recommended by other agents are\nchosen from their own taskâ€™s perspective. For example, in Bei-\njing dataset, the meta-path recommended by population prediction\ntask ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\nğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦1\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›reflect the population\nflow influence, the one from commercial prediction taskğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\nğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğµğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›consider the commercial factors between entities like Busi-\nnessArea, POI, and Brand. The meta-paths from rating prediction\ntask ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›cap-\ntures the competitive relationships between POIs in regions, which\nmay impact the rating as well as user activity. Therefore, the meta-\npaths found through multi-agent collaboration capture diverse\nknowledge more comprehensively. In comparison, the meta-paths\ngenerated by searching algorithms are less meaningful and diverse.\nFor example, among the meta-paths generated by the genetic algo-\nrithms in Beijing, five out of six meta-paths model the population\nflow between regions, which may lead to information redundancy.\n5\nRelated Work\n5.1\nGraph Learning for Socioeconomic\nPrediction\nDue to the remarkable ability to model non-Euclidean and heteroge-\nneous data, the graph structure and graph learning model have long\nbeen utilized for socioeconomic prediction in LBSN. Some studies\nleverage the mobility data and construct mobility graphs to model\nthe population flow patterns between locations [7, 30, 32]. Moreover,\nsome studies further consider knowledge in LBSN from different\nperspectives through multiple graphs. For instance, HDGE [24]\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\nTable 5: Best meta-paths found by our model, random search and genetic algorithms on user activity prediction task in\nBeijing. \"Rec by Pop/Com/Rat\" indicates the meta-paths recommended by agent of population prediction, commercial activity\nprediction, and rating prediction tasks.\nModel\nMeta-paths\nSLAG-single\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦1\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nSLAG-comm\nSelf-update\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğµğ‘’ğ‘™ğ‘œğ‘›ğ‘”ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦1\nğ»ğ‘ğ‘ ğµğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nRec by Pop.\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦1\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nRec by Com\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğµğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ¸ğ‘¥ğ‘–ğ‘ ğ‘¡ğ¼ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nRec by Rat\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nGenetic Algorithm\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¶ğ‘œğ‘šğ‘ğ‘’ğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¼ğ‘›ğ‘“ğ‘™ğ‘œğ‘¤ğ¹ğ‘Ÿğ‘œğ‘š\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¼ğ‘›ğ‘“ğ‘™ğ‘œğ‘¤ğ¹ğ‘Ÿğ‘œğ‘š\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ¹ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ¹ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ğ‘’ğ‘ğ‘Ÿğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ‘…ğ‘’ğ‘™ğ‘ğ‘¡ğ‘’ğ‘‘ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nRandom Search\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦2\nğ¼ğ‘ ğ‘†ğ‘¢ğ‘ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦1\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ \nâˆ’âˆ’âˆ’â†’ğ‘ƒğ‘‚ğ¼\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ¶ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦2\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ¹ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ»ğ‘ğ‘ ğ‘ƒğ‘™ğ‘ğ‘ğ‘’ğ‘‘ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¼ğ‘›ğ‘“ğ‘™ğ‘œğ‘¤ğ¹ğ‘Ÿğ‘œğ‘š\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ¹ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ğµğ‘¦\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘¢ğ‘ ğ‘–ğ‘›ğ‘’ğ‘ ğ‘ ğ´ğ‘Ÿğ‘’ğ‘\nğ‘†ğ‘’ğ‘Ÿğ‘£ğ‘’\nâˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ»ğ‘ğ‘ ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‚ğ‘“\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğµğ‘Ÿğ‘ğ‘›ğ‘‘\nğ»ğ‘ğ‘ ğ‘ƒğ‘™ğ‘ğ‘ğ‘’ğ‘‘ğ‘†ğ‘¡ğ‘œğ‘Ÿğ‘’ğ´ğ‘¡\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nğ‘ƒğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ¹ğ‘™ğ‘œğ‘¤ğ‘‡ğ‘œ\nâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ğ‘…ğ‘’ğ‘”ğ‘–ğ‘œğ‘›\nconstructs a mobility flow graph and spatial graph, and some stud-\nies [17, 35] propose models to dynamically fuse mobility, POI, and\nspatial graphs for indicator prediction.\nRecently, some studies introduce heterogeneous graph or KG to\nintegrate heterogeneous LBSN data in a single graph. HUGAT [9]\ndesigns several meta-paths to capture different relationships in\nLBSN from a heterogeneous graph, and aggregate information\nfrom meta-path-based neighbors of locations. Zhou et al. propose\na hierarchical KG learning model to learn the global knowledge\nand domain knowledge from LBKG, achieving considerable perfor-\nmance [37]. However, existing methods rely on human expertise\nto identify relevant knowledge from LBSN data that may help the\ndownstream tasks, which may usually be sub-optimal.\n5.2\nSynergy of LLM and KG\nLLMs excel in understanding and generating human language but\noften suffer from hallucination and a lack of factual accuracy. In\ncontrast, KGs store structured, factual knowledge, which is explicit\nand interpretable. Therefore, in recent years, researchers have in-\ncreasingly explored the synergy between LLM and KG to leverage\ntheir complementary strengths [19]. Some studies combine LLM\nwith KG for better knowledge representations by fusing the neural\nnetworks of language models with KG [26, 38]. Moreover, some\nstudies construct LLM agents that interact with KG for better rea-\nsoning. For example, KSL [5] lets LLM search on KG to retrieve facts\nrelevant to the questions, StructGPT [8] enables LLM to perform\nreasoning by traversing on KGs, and Wang et al. [27] traverses\na knowledge graph across multiple documents to enhance multi-\ndocument question answering.\n6\nConclusion\nIn this work, we propose a framework that synergizes the abil-\nity of LLM agent and KG learning model for better socioeconomic\nprediction in LBSN. Specifically, we leverage LLM agent to automat-\nically find task-relevant meta-paths, and propose a semantic-guided\nknowledge fusion model to adaptively fuse diverse knowledge based\non semantic information of the meta-paths. Moreover, we enable\ncross-task knowledge transfer by LLM agent-level collaboration\nand embedding-level knowledge fusion. Such synergistic model\ndesign shows better performance compared with socioeconomic\nprediction baselines as well as meta-path searching algorithms.\nIn the future, we plan to consider the dynamic update of LBKG\nand socioeconomic indicators as the LBSN changes over time, and\nleverage LLM to further capture the temporal patterns of such dy-\nnamics. Another promising direction is to explore the integration\nof LLM and KG throughout the lifecycle from LBKG construction\nand representation to downstream applications.\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\nReferences\n[1] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang\nZhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based\nevaluators through multi-agent debate. arXiv preprint arXiv:2308.07201 (2023).\n[2] Lin Chen, Fengli Xu, Nian Li, Zhenyu Han, Meng Wang, Yong Li, and Pan Hui.\n2024. Large Language Model-driven Meta-structure Discovery in Heterogeneous\nInformation Network. In Proceedings of the 30th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining. 307â€“318.\n[3] Lei Dong, Carlo Ratti, and Siqi Zheng. 2019. Predicting neighborhoodsâ€™ socioe-\nconomic attributes using restaurant data. Proceedings of the National Academy\nof Sciences 116, 31 (2019), 15447â€“15452.\n[4] Lei Dong, Xiaohui Yuan, Meng Li, Carlo Ratti, and Yu Liu. 2021. A gridded\nestablishment dataset as a proxy for economic activity in China. Scientific Data\n8, 1 (2021), 1â€“9.\n[5] Chao Feng, Xinyu Zhang, and Zichu Fei. 2023. Knowledge solver: Teaching\nllms to search for domain knowledge from knowledge graphs. arXiv preprint\narXiv:2309.03118 (2023).\n[6] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng,\nCeyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang\nZhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and JÃ¼rgen Schmidhuber. 2023.\nMetaGPT: Meta Programming for A Multi-Agent Collaborative Framework.\narXiv:2308.00352 [cs.AI]\n[7] Mingliang Hou, Feng Xia, Haoran Gao, Xin Chen, and Honglong Chen. 2022.\nUrban Region Profiling With Spatio-Temporal Graph Neural Networks. IEEE\nTransactions on Computational Social Systems (2022).\n[8] Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong\nWen. 2023. Structgpt: A general framework for large language model to reason\nover structured data. arXiv preprint arXiv:2305.09645 (2023).\n[9] Namwoo Kim and Yoonjin Yoon. 2022. Effective Urban Region Representation\nLearning Using Heterogeneous Urban Graph Attention Network (HUGAT). arXiv\npreprint arXiv:2202.09021 (2022).\n[10] Xiaochong Lan, Chen Gao, Depeng Jin, and Yong Li. 2024. Stance detection with\ncollaborative role-infused llm-based agents. In Proceedings of the International\nAAAI Conference on Web and Social Media, Vol. 18. 891â€“903.\n[11] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,\nand Bernard Ghanem. 2023. CAMEL: Communicative Agents for â€Mindâ€ Explo-\nration of Large Language Model Society. In Thirty-seventh Conference on Neural\nInformation Processing Systems. https://openreview.net/forum?id=3IyL2XWDkG\n[12] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan\nZhang. 2023. Towards general text embeddings with multi-stage contrastive\nlearning. arXiv preprint arXiv:2308.03281 (2023).\n[13] Chang Liu, Chen Gao, Depeng Jin, and Yong Li. 2021. Improving Location\nRecommendation with Urban Knowledge Graph. arXiv preprint arXiv:2111.01013\n(2021).\n[14] Yu Liu, Jingtao Ding, Yanjie Fu, and Yong Li. 2023. Urbankg: An urban knowledge\ngraph system. ACM Transactions on Intelligent Systems and Technology 14, 4\n(2023), 1â€“25.\n[15] Yu Liu, Jingtao Ding, and Yong Li. 2023. KnowSite: Leveraging Urban Knowledge\nGraph for Site Selection. In Proceedings of the 31st ACM International Conference\non Advances in Geographic Information Systems. 1â€“12.\n[16] Yu Liu, Xin Zhang, Jingtao Ding, Yanxin Xi, and Yong Li. 2023. Knowledge-\ninfused contrastive learning for urban imagery-based socioeconomic prediction.\nIn Proceedings of the ACM Web Conference 2023. 4150â€“4160.\n[17] Yan Luo, Fu-lai Chung, and Kai Chen. 2022. Urban Region Profiling via A Multi-\nGraph Representation Learning Framework. arXiv preprint arXiv:2202.02074\n(2022).\n[18] Niklas Muennighoff, Nouamane Tazi, LoÃ¯c Magne, and Nils Reimers. 2022. MTEB:\nMassive text embedding benchmark. arXiv preprint arXiv:2210.07316 (2022).\n[19] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu.\n2024. Unifying large language models and knowledge graphs: A roadmap. IEEE\nTransactions on Knowledge and Data Engineering (2024).\n[20] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan\nTitov, and Max Welling. 2018. Modeling relational data with graph convolutional\nnetworks. In European Semantic Web Conference. Springer, 593â€“607.\n[21] Yizhou Sun and Jiawei Han. 2012. Mining heterogeneous information networks:\nprinciples and methodologies. Morgan & Claypool Publishers.\n[22] Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro\nLio, and Yoshua Bengio. 2017.\nGraph attention networks.\narXiv preprint\narXiv:1710.10903 (2017).\n[23] Hongjian Wang, Daniel Kifer, Corina Graif, and Zhenhui Li. 2016. Crime rate\ninference with big data. In Proceedings of the 22nd ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining. 635â€“644.\n[24] Hongjian Wang and Zhenhui Li. 2017. Region representation learning via mo-\nbility flow. In Proceedings of the 2017 ACM on Conference on Information and\nKnowledge Management. 237â€“246.\n[25] Huandong Wang, Qiaohong Yu, Yu Liu, Depeng Jin, and Yong Li. 2021. Spatio-\nTemporal Urban Knowledge Graph Enabled Mobility Prediction. Proceedings of\nthe ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 4 (2021),\n1â€“24.\n[26] Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu,\nJuanzi Li, and Jian Tang. 2021. KEPLER: A unified model for knowledge embed-\nding and pre-trained language representation. Transactions of the Association for\nComputational Linguistics 9 (2021), 176â€“194.\n[27] Yu Wang, Nedim Lipka, Ryan A Rossi, Alexa Siu, Ruiyi Zhang, and Tyler Derr.\n2024. Knowledge graph prompting for multi-document question answering. In\nProceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 19206â€“19214.\n[28] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian\nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.\n2022. Emergent Abilities of Large Language Models. Transactions on Machine\nLearning Research (2022).\n[29] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,\nQuoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reason-\ning in large language models. Advances in neural information processing systems\n35 (2022), 24824â€“24837.\n[30] Shangbin Wu, Xu Yan, Xiaoliang Fan, Shirui Pan, Shichao Zhu, Chuanpan Zheng,\nMing Cheng, and Cheng Wang. 2022. Multi-Graph Fusion Networks for Urban\nRegion Embedding. arXiv preprint arXiv:2201.09760 (2022).\n[31] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang,\nXiongwei Han, Xiaojin Fu, Tao Zhong, Jia Zeng, Mingli Song, et al. 2023. Chain-\nof-Experts: When LLMs Meet Complex Operations Research Problems. In The\nTwelfth International Conference on Learning Representations.\n[32] Fengli Xu, Yong Li, and Shusheng Xu. 2020. Attentional multi-graph convo-\nlutional network for regional economy prediction with open migration data.\nIn Proceedings of the 26th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining. 2225â€“2233.\n[33] Su Yang, Minjie Wang, Wenshan Wang, Yi Sun, Jun Gao, Weishan Zhang, and\nJiulong Zhang. 2017. Predicting commercial activeness over urban big data. Pro-\nceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\n1, 3 (2017), 1â€“20.\n[34] Zijun Yao, Yanjie Fu, Bin Liu, Wangsu Hu, and Hui Xiong. 2018. Representing\nurban functions through zone embedding with human mobility patterns. In\nProceedings of the Twenty-Seventh International Joint Conference on Artificial\nIntelligence (IJCAI-18).\n[35] Mingyang Zhang, Tong Li, Yong Li, and Pan Hui. 2021. Multi-view joint graph\nrepresentation learning for urban region embedding. In Proceedings of the Twenty-\nNinth International Conference on International Joint Conferences on Artificial\nIntelligence. 4431â€“4437.\n[36] Zirui Zhao, Wee Sun Lee, and David Hsu. 2024. Large language models as\ncommonsense knowledge for large-scale task planning. Advances in Neural\nInformation Processing Systems 36 (2024).\n[37] Zhilun Zhou, Yu Liu, Jingtao Ding, Depeng Jin, and Yong Li. 2023. Hierarchi-\ncal knowledge graph learning enabled socioeconomic indicator prediction in\nlocation-based social network. In Proceedings of the ACM Web Conference 2023.\n122â€“132.\n[38] Hongyin Zhu, Hao Peng, Zhiheng Lyu, Lei Hou, Juanzi Li, and Jinghui Xiao.\n2023. Pre-training language model incorporating domain-specific heterogeneous\nknowledge into a unified representation. Expert Systems with Applications 215\n(2023), 119369.\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\nA\nDetails of LBKG\nWe present the relations in LBKG and their meanings in Table 6. We\nincorporate three level of POI category, i.e., coarse-grained, medium-\ngrained, and find-grained categories, which are represented as Cat-\negory1, Category2, and Category3, respectively.\nB\nPrompts\nWe present the detailed prompts and examples of LLM agent re-\nsponse in this Section. Specifically, we introduce the basic informa-\ntion of LBKG to LLM agent as shown in Figure 5. Figure 6 shows\nthe examples of prompt and response on single task. Figure 7 and 8\nshows the prompt of meta-paths self-update and recommendation\nin cross-task communication. We ask the LLM agents to name each\nmeta-path and provide reasons in all prompts.\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\nTable 6: The details of relations in LBKG.\nRelation\nHead & Tail Entity Types\nMeaning\nHasCategory1Of\n(POI, Category1)\nCoarse-grained category of POI\nHasCategory2Of\n(POI, Category2)\nMedium-grained category of POI\nHasCategory3Of\n(POI, Category3)\nFine-grained category of POI\nCategory1ExistIn\n(Category1, POI)\nCoarse-grained category contains POI\nCategory2ExistIn\n(Category2, POI)\nMedium-grained category contains POI\nCategory3ExistIn\n(Category3, POI)\nFine-grained category contains POI\nBelongToCategory1\n(Brand, Category1)\nCoarse-grained category of Brand\nBelongToCategory2\n(Brand, Category2)\nMedium-grained category of Brand\nBelongToCategory3\n(Brand, Category3)\nFine-grained category of Brand\nCategory1HasBrandOf\n(Category1, Brand)\nCoarse-grained category contains Brand\nCategory2HasBrandOf\n(Category2, Brand)\nMedium-grained category contains Brand\nCategory3HasBrandOf\n(Category3, Brand)\nFine-grained category contains Brand\nHas\n(Region, POI)\nRegion contains POI\nLocateAt\n(POI, Region)\nPOI locates at the region\nBelongTo\n(POI, BusinessArea)\nPOI locates at the BusinessArea\nContain\n(BusinessArea, POI)\nBusinessArea contains POI\nIsSubCategoryOf_2to1\n(Category2, Category1)\nCategory2 is a sub-category of Category1\nIsSubCategoryOf_3to1\n(Category3, Category1)\nCategory3 is a sub-category of Category1\nIsSubCategoryOf_3to2\n(Category3, Category2)\nCategory3 is a sub-category of Category2\nIsBroadCategoryOf_1to2\n(Category1, Category2)\nCategory1 is a broad-category of Category2\nIsBroadCategoryOf_1to3\n(Category1, Category3)\nCategory1 is a broad-category of Category3\nIsBroadCategoryOf_2to3\n(Category2, Category3)\nCategory2 is a broad-category of Category3\nPopulationInflowFrom\n(Region, Region)\nRegion has a large population flow to Region\nPopulationFlowTo\n(Region, Region)\nRegion has a large population flow from Region\nHasPlacedStoreAt\n(Brand, Region)\nBrand has opened store at Region\nHasStoreOf\n(Region, Brand)\nRegion contains POI of the Brand\nBrandExistIn\n(Brand, POI)\nBrand contains POI\nHasBrandOf\n(POI, Brand)\nBrand of POI\nServedBy\n(Region, BusinessArea)\nRegion covered by BusinessArea\nServe\n(BusinessArea, Region)\nBusinessArea covers the region\nRelatedBrand\n(Brand, Brand)\nBrands related to each other\nCompetitive\n(POI, POI)\nNearby POIs with the same brand\nBorderBy\n(Region, Region)\nRegions share part of the boundary\nNearBy\n(Region, Region)\nRegions lie within a certain distance\nSimilarFunction\n(Region, Region)\nRegions with similar POI distribution\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\n[Prompt of introduction to LBKG]\nLet's start with some concepts of the urban knowledge graph, which captures facts related to a city. In the following, we \nwill introduce the entities and relations in it.\nThe urban knowledge graph contains 7 types of entities, i.e., Brand, Point of Interest (POI), Region, Business Area, \nCategory1(coarse-grained category), Category2(medium-grained category), Cateory3(fine-grained category). In this context, \nfine-grained categorys is subcategory of medium-grained category and medium-grained category is subcategory of coarse-\ngrained category.\nThe urban knowledge graph contains 35 types of relations to describe the connections between entities. The name of each \nrelation consists of the entity type corresponding to the origin of this relation, the meaning of the relation, and the entity \ntype corresponding to the destination of this relation, in order from left to right, separated by _, which indicates the \nrelation to be experienced from the head entity to the tail entity. \nMapping of relation names to IDs:\nrel_1: POI_HasCategoryOf_Category1\nrel_2: POI_HasCategoryOf_Category2\nrel_3: POI_HasCategoryOf_Category3\nrel_4: Category1_ExistIn_POI\nrel_5: Category2_ExistIn_POI\nrel_6: Category3_ExistIn_POI\nrel_7: Brand_BelongTo_Category1\nrel_8: Brand_BelongTo_Category2\nrel_9: Brand_BelongTo_Category3\nrel_10: Category1_HasBrandOf_Brand\nrel_11: Category2_HasBrandOf_Brand\nrel_12: Category3_HasBrandOf_Brand\nrel_13: Region_Has_POI\nrel_14: POI_LocateAt_Region\nrel_15: POI_BelongTo_BusinessArea\nrel_16: BusinessArea_Contain_POI\nrel_17: Category2_IsSubCategoryOf_Category1\nrel_18: Category3_IsSubCategoryOf_Category1\nrel_19: Category3_IsSubCategoryOf_Category2\nrel_20: Category1_IsBroadCategoryOf_Category2\nrel_21: Category1_IsBroadCategoryOf_Category3\nrel_22: Category2_IsBroadCategoryOf_Category3\nrel_23: Region_PopulationInflowFrom_Region\nrel_24: Region_PopulationFlowTo_Region\nrel_25: Brand_HasPlacedStoreAt_Region\nrel_26: Region_HasStoreOf_Brand\nrel_27: Brand_ExistIn_POI\nrel_28: POI_HasBrandOf_Brand\nrel_29: Region_ServedBy_BusinessArea\nrel_30: BusinessArea_Serve_Region\nrel_31: Brand_RelatedBrand_Brand\nrel_32: POI_Competitive_POI\nrel_33: Region_BorderBy_Region\nrel_34: Region_NearBy_Region\nrel_35: Region_SimilarFunction_Region\nFor example, \"rel_1\" represents the relation \"HasCategoryOf\". It links a head entity with type \"POI\" to a tail entity with \ntype \"Category1\", indicating that the POI has the specific coarse-grained category.\nA metapath consists of one or several relations in KG. For two neighboring relations in a metapath, the tail entity type of \nthe former relation must be the same as the head entity type of the latter relation. For example, (rel_3, rel_19) is a valid \nmetapath because the tail entity type of rel_3 is Category3 and the head entity type of rel_19 is also Category3. This \nmetapath can be expressed as: POI_HasCategoryOf_Category3_IsSubCategoryOf_Category2.\nThe metapath (rel_3, rel_4) is invalid because the tail entity type of rel_3 is Category3, while the head entity type of rel_4 is \nCategory1.\nFigure 5: The description of LBKG in the prompts.\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\n[Prompt of single task]\n{Introduction to LBKG}\nNow we are using this knowledge graph for the \"Population_Prediction\" task, i.e., predicting the population in urban \nregions. Please help me find some metapaths in this KG which may help this task. \nSince a metapath usually has semantic meaning in the KG, please name each metapath based on its meaning. For example, \nthe metapath (rel_34, rel_33), i.e., Region_NearBy_Region_BorderBy_Region, can be named as 'Geographical Proximity'. \nPlease also provide the reason for why you choose each metapath.\n{reference}\nPlease choose 3 metapaths. Note that: \n1. You must make sure that all triplets in the metapaths exist in the KG. \n2. Each metapath must contain the entity type \"Region\", i.e., at least one relation in the metapath must have \"Region\" as \nthe head entity type or the tail entity type.\n3. You must answer in json format. For example:\n[{{\"name\":\"xxx\", \"reason\":\"xxx\", \"metapath\":\"Region_BorderBy_Region_...\"}}, ...]\nYour answer: \n[LLM agent response]\n[\n{\n\"name\": \"Regional Population Flow\",\n\"reason\": \"This metapath captures the movement of people between regions, which is a direct indicator of population \nchanges and can help predict population dynamics.\",\n\"metapath\": \"Region_PopulationFlowTo_Region_PopulationInflowFrom_Region\"\n},\n{\n\"name\": \"Brand Influence on Population\",\n\"reason\": \"This metapath explores how the presence of certain brands in a region might attract people, influencing \npopulation predictions. Popular brands can draw more visitors or residents to a region.\",\n\"metapath\": \"Region_HasStoreOf_Brand_HasPlacedStoreAt_Region\"\n},\n{\n\"name\": \"Business Area Impact\",\n\"reason\": \"This metapath examines how business areas serving a region can affect its population. Business areas with \nmore services and amenities can attract more people to live or work in the region.\",\n\"metapath\": \"Region_ServedBy_BusinessArea_Serve_Region\"\n}\n]\nFigure 6: The prompt and response example on single task.\n\nZhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li\n[Prompt of self-update]\n{Introduction to LBKG}\nNow we are using this knowledge graph for some socioeconomic indicator prediction tasks, including:\n1. Population_Prediction: predicting the population in urban regions.\n2. Economic_Prediction: predicting the economic level of urban regions.\n3. Comments_Prediction: predicting the number of reviews of restaurants on review platform in an urban region.\n4. Rating_Prediction: predicting the average ratings of restaurants on review platform in an urban region.\nNow we are responsible for the \"Population_Prediction\" task, i.e., predicting the population in urban regions. Please help \nme find some metapaths in this KG which may help this task. \nFor your reference, here are the metapaths that we have discovered so far:\n{Previous LLM response for each task}\nSince the other 3 tasks are highly related to the current task, please consider their relationship with the current task, and\nfind 3 new metapaths that may help the current task. The new metapaths should not be the same as the current \nmetapaths.\nSince a metapath usually has semantic meaning in the KG, please name each metapath based on its meaning. For example, \nthe metapath (rel_34, rel33), i.e., Region_NearBy_Region_BorderBy_Region, can be named as 'Geographical Proximity'. \nYou should also provide a detailed step-by-step reasoning process for why you choose each metapath. Note that: \n1. You must make sure that all triplets in the metapaths exist in the KG.\n2. Each metapath must contain the entity type \"Region\", i.e., at least one relation in the metapath must have \"Region\" as \nthe head entity type or the tail entity type.\n3. You must answer in json format. For example:\n[{\"reason\":\"xxx\", \"name\":\"xxx\", \"metapath\":\"Region_BorderBy_Region_...\"}, ...]\nYour Answer: \n[LLM agent response]\n[\n{\n\"name\": \"Regional Competitive Dynamics\",\n\"reason\": \"This metapath explores how competition between POIs in a region might influence population dynamics. \nCompetitive POIs can attract more visitors and residents, impacting the population of the region.\",\n\"metapath\": \"Region_Has_POI_Competitive_POI_LocateAt_Region\"\n},\n{\n\"name\": \"Geographical and Functional Similarity\",\n\"reason\": \"This metapath examines how regions that are geographically nearby and have similar functions might \nexperience similar population trends. Regions that are similar in function and location might share population \ncharacteristics.\",\n\"metapath\": \"Region_NearBy_Region_SimilarFunction_Region\"\n},\n{\n\"name\": \"Brand and Business Area Synergy\",\n\"reason\": \"This metapath investigates how the presence of brands in business areas serving a region can influence \npopulation. The synergy between brands and business areas can attract more people to the region, affecting its \npopulation.\",\n\"metapath\": \"Region_ServedBy_BusinessArea_Contain_POI_HasBrandOf_Brand_HasPlacedStoreAt_Region\"\n}\n]\nFigure 7: The prompt and response example of meta-paths self-update in cross-task communication.\n\nSynergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN\n[Prompt of meta-path recommendation]\n{Same as previous prompt}\nBased on the above information, please recommend a metapath which you think can best help the Population_Prediction task. You \nshould consider relationship between the two tasks, and how knowledge from our task can help the target task. The metapath should not \nbe the same as the current metapaths.\nSince a metapath usually has semantic meaning in the KG, please name each metapath based on its meaning. For example, the metapath\n(rel_34, rel33), i.e., Region_NearBy_Region_BorderBy_Region, can be named as 'Geographical Proximity'. You should also provide a detailed \nstep-by-step reasoning process for why you choose each metapath. Note that: \n1. You must make sure that all triplets in the metapaths exist in the KG. \n2. Each metapath must contain the entity type \"Region\", i.e., at least one relation in the metapath must have \"Region\" as the head entity \ntype or the tail entity type.\nYour Answer: \n[LLM agent response]\nTo recommend a metapath for the Population_Prediction task, we need to consider how the economic factors of a region might influence \npopulation dynamics. Economic conditions can affect population distribution by attracting or repelling residents based on job opportunities, \ncost of living, and overall quality of life. Therefore, a metapath that captures the economic influence on population movement would be \nbeneficial.\n### Recommended Metapath for Population_Prediction:\n**Metapath Name:** Economic Attraction\n**Metapath:** Region_Has_POI_HasCategoryOf_Category1_HasBrandOf_Brand_HasPlacedStoreAt_Region\n**Reasoning Process:**\n1. **Start with Region:** The metapath begins with a \"Region\" entity, which is essential as the task is to predict population dynamics within \nurban regions.\n2. **Region_Has_POI:** This relation indicates that a region contains certain Points of Interest (POIs). POIs can include businesses, \nattractions, and other facilities that contribute to the economic activity of a region.\n3. **POI_HasCategoryOf_Category1:** This step links POIs to a coarse-grained category, which helps identify the type of economic activity \nprevalent in the region. For example, a region with many POIs in the \"Retail\" category might indicate a strong commercial presence.\n4. **Category1_HasBrandOf_Brand:** This relation connects the category to specific brands. Brands associated with a category can indicate \nthe economic strength and attractiveness of the region. Well-known brands can draw more visitors and potential residents.\n5. **Brand_HasPlacedStoreAt_Region:** Finally, this relation shows that a brand has established a store in a region, which can be a \nsignificant economic indicator. The presence of popular brands can attract people to the region, influencing population growth or movement.\n### Justification:\n- **Economic Influence on Population:** The presence of well-known brands and a high concentration of economically significant POIs can \nattract people to a region, either for employment opportunities or for the amenities and services offered. This metapath captures the \neconomic attractiveness of a region, which is a key factor in population dynamics.\n- **Complementary to Existing Metapaths:** This metapath complements existing ones by focusing on the economic pull factors rather than \njust the movement of people or the presence of business areas. It provides a different perspective by linking economic activity directly to \npopulation changes.\n- **Semantic Meaning:** The metapath \"Economic Attraction\" effectively captures the idea that economic factors, represented by the \npresence of brands and POIs, can attract people to a region, thereby influencing population distribution.\nBy considering the economic aspects of a region, this metapath provides a valuable angle for predicting population changes, leveraging the \ninterconnectedness of economic activity and population dynamics.\nFigure 8: The prompt and response example of meta-paths recommendation in cross-task communication.",
    "pdf_filename": "Synergizing_LLM_Agents_and_Knowledge_Graph_for_Socioeconomic_Prediction_in_LBSN.pdf"
}