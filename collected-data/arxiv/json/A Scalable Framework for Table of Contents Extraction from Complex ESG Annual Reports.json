{
    "title": "A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports",
    "context": "Table of contents (ToC) extraction centres on structuring documents in a hierarchical man- ner. In this paper, we propose a new dataset, ESGDoc, comprising 1,093 ESG annual reports from 563 companies spanning from 2001 to 2022. These reports pose significant challenges due to their diverse structures and extensive length. To address these challenges, we pro- pose a new framework for Toc extraction, con- sisting of three steps: (1) Constructing an initial tree of text blocks based on reading order and font sizes; (2) Modelling each tree node (or text block) independently by considering its con- textual information captured in node-centric subtree; (3) Modifying the original tree by tak- ing appropriate action on each tree node (Keep, Delete, or Move). This construction-modelling- modification (CMM) process offers several ben- efits. It eliminates the need for pairwise mod- elling of section headings as in previous ap- proaches, making document segmentation prac- tically feasible. By incorporating structured information, each section heading can leverage both local and long-distance context relevant to itself. Experimental results show that our approach outperforms the previous state-of-the- art baseline with a fraction of running time. Our framework proves its scalability by effectively handling documents of any length.1 1 A considerable amount of research has been pro- posed to comprehend documents (Xu et al., 2019; Zhang et al., 2021; Xu et al., 2021a,b; Peng et al., 2022; Li et al., 2022; Gu et al., 2022; Shen et al., 2022; Lee et al., 2022, 2023) , which typically involves the classification of different parts of a document such as title, caption, table, footer, and so on. However, such prevailing classification of- ten centres on a document’s local layout structure, sidelining a holistic comprehension of its content 1Available at https://github.com/xnyuwg/cmm. and organisation. While traditional summarisation offers a concise representation of a document’s content, a Table of Contents (ToC) presents a struc- tured and hierarchical summary. This structural organisation in a ToC provides a comprehensive pathway for pinpointing specific information. For example, when seeking information about a com- pany’s carbon dioxide emissions, a ToC enables a systematic navigation through the information hierarchy. In contrast, conventional summarisa- tion might only provide a vague indication of such information, requiring sifting through the entire document for precise detail. Several datasets have been proposed to facilitate the research in document understanding (Zhong et al., 2019b; Li et al., 2020; Pfitzmann et al., 2022). Most of these studies lack a structured construc- tion of documents and primarily focus on well- structured scientific papers. A dataset called Hier- Doc (Hierarchical academic Document) (Hu et al., 2022) was introduced to facilitate the development of methods for extracting the table of contents (ToC) from documents. This dataset was compiled from scientific papers downloaded from arXiv2, which are typically short and well-structured. The hierarchical structure can often be inferred directly from the headings themselves. For example, the heading “1. Introduction” can be easily identified as a first-level heading based on the section number- ing. Moreover, due to the relatively short length of scientific papers, it is feasible to process the entire document as a whole. Hu et al. (2022) proposed the multimodal tree decoder (MTD) for ToC extrac- tion from HierDoc. MTD first utilises text, visual, and layout information to encode text blocks identi- fied by a PDF parser; then classifies all text blocks into two categories, headings and non-headings; and finally predicts the relationship of each pair of headings, facilitating the parsing of these headings into a tree structure representing ToC. 2https://arxiv.org/ arXiv:2310.18073v1  [cs.CL]  27 Oct 2023",
    "body": "A Scalable Framework for Table of Contents Extraction\nfrom Complex ESG Annual Reports\nXinyu Wang1,2, Lin Gui2, Yulan He1,2,3\n1Department of Computer Science, University of Warwick\n2Department of Informatics, King’s College London\n3The Alan Turing Institute\nXinyu.Wang.11@warwick.ac.uk\n{lin.1.gui, yulan.he}@kcl.ac.uk\nAbstract\nTable of contents (ToC) extraction centres on\nstructuring documents in a hierarchical man-\nner. In this paper, we propose a new dataset,\nESGDoc, comprising 1,093 ESG annual reports\nfrom 563 companies spanning from 2001 to\n2022. These reports pose significant challenges\ndue to their diverse structures and extensive\nlength. To address these challenges, we pro-\npose a new framework for Toc extraction, con-\nsisting of three steps: (1) Constructing an initial\ntree of text blocks based on reading order and\nfont sizes; (2) Modelling each tree node (or text\nblock) independently by considering its con-\ntextual information captured in node-centric\nsubtree; (3) Modifying the original tree by tak-\ning appropriate action on each tree node (Keep,\nDelete, or Move). This construction-modelling-\nmodification (CMM) process offers several ben-\nefits. It eliminates the need for pairwise mod-\nelling of section headings as in previous ap-\nproaches, making document segmentation prac-\ntically feasible. By incorporating structured\ninformation, each section heading can leverage\nboth local and long-distance context relevant\nto itself. Experimental results show that our\napproach outperforms the previous state-of-the-\nart baseline with a fraction of running time. Our\nframework proves its scalability by effectively\nhandling documents of any length.1\n1\nIntroduction\nA considerable amount of research has been pro-\nposed to comprehend documents (Xu et al., 2019;\nZhang et al., 2021; Xu et al., 2021a,b; Peng et al.,\n2022; Li et al., 2022; Gu et al., 2022; Shen et al.,\n2022; Lee et al., 2022, 2023) , which typically\ninvolves the classification of different parts of a\ndocument such as title, caption, table, footer, and\nso on. However, such prevailing classification of-\nten centres on a document’s local layout structure,\nsidelining a holistic comprehension of its content\n1Available at https://github.com/xnyuwg/cmm.\nand organisation. While traditional summarisation\noffers a concise representation of a document’s\ncontent, a Table of Contents (ToC) presents a struc-\ntured and hierarchical summary. This structural\norganisation in a ToC provides a comprehensive\npathway for pinpointing specific information. For\nexample, when seeking information about a com-\npany’s carbon dioxide emissions, a ToC enables\na systematic navigation through the information\nhierarchy. In contrast, conventional summarisa-\ntion might only provide a vague indication of such\ninformation, requiring sifting through the entire\ndocument for precise detail.\nSeveral datasets have been proposed to facilitate\nthe research in document understanding (Zhong\net al., 2019b; Li et al., 2020; Pfitzmann et al., 2022).\nMost of these studies lack a structured construc-\ntion of documents and primarily focus on well-\nstructured scientific papers. A dataset called Hier-\nDoc (Hierarchical academic Document) (Hu et al.,\n2022) was introduced to facilitate the development\nof methods for extracting the table of contents\n(ToC) from documents. This dataset was compiled\nfrom scientific papers downloaded from arXiv2,\nwhich are typically short and well-structured. The\nhierarchical structure can often be inferred directly\nfrom the headings themselves. For example, the\nheading “1. Introduction” can be easily identified\nas a first-level heading based on the section number-\ning. Moreover, due to the relatively short length of\nscientific papers, it is feasible to process the entire\ndocument as a whole. Hu et al. (2022) proposed\nthe multimodal tree decoder (MTD) for ToC extrac-\ntion from HierDoc. MTD first utilises text, visual,\nand layout information to encode text blocks identi-\nfied by a PDF parser; then classifies all text blocks\ninto two categories, headings and non-headings;\nand finally predicts the relationship of each pair of\nheadings, facilitating the parsing of these headings\ninto a tree structure representing ToC.\n2https://arxiv.org/\narXiv:2310.18073v1  [cs.CL]  27 Oct 2023\n\nFigure 1: Five examples of ESG reports, with the left three presented in portrait orientation and the right-most two\nin landscape orientation. They show a wide range of diverse structures. It is common to observe the absence of\nsection numbering.\nHowever, understanding long documents such\nas ESG (Environmental, Social, and Governance)\nannual reports poses significant challenges com-\npared to commonly used scientific papers. First,\nESG reports tend to be extensive, often exceed-\ning 100 pages, which is uncommon for scientific\npapers. Second, while scientific papers generally\nadhere to a standard structure that includes abstract,\nintroduction, methods, results, discussion, and con-\nclusion sections, ESG reports exhibit more diverse\nstructures with a wide range of font types and sizes.\nThird, ESG reports often include visual elements\nsuch as charts, graphs, tables, and infographics to\npresent data and key findings in a visually appeal-\ning manner, which adds complexity to the docu-\nment parsing process. Some example ESG reports\nare illustrated in Figure 1.\nIn this paper, we develop a new dataset, ESGDoc,\ncollected from public ESG annual reports3 from\n563 companies spanning from 2001 to 2022 for\nthe task of ToC extraction. The existing approach,\nMTD (Hu et al., 2022), faces difficulties when deal-\ning with challenges presented in ESGDoc. MTD\nmodels relationships of every possible heading\npairs and thus requires the processing of the entire\ndocument simultaneously, making it impractical\nfor lengthy documents. As will be discussed in our\nexperiments section, MTD run into out-of-memory\nissue when processing some lengthy documents in\nESGDoc. Moreover, MTD only uses Gated Recur-\nrent Unit (GRU) (Cho et al., 2014) to capture the\ncontext of a section heading, lacking long-distance\ninteraction, particularly for high-level headings that\nmay be tens of pages apart.\n3https://www.responsibilityreports.com/\nIn order to overcome the challenges presented\nin ESGDoc, we propose a new scalable framework,\nconsisting of three main steps: (1) Constructing an\ninitial tree of text blocks based on reading order\nand font sizes; (2) Modelling each tree node (or\ntext block) independently by considering its contex-\ntual information captured in node-centric subtree;\n(3) Modifying the original tree by taking appro-\npriate action on each tree node (Keep, Delete, or\nMove). Our method is named as CMM (Construction-\nModelling-Modification).\nThis approach allows higher-level headings to\nfocus on capturing high-level and long-distance in-\nformation, while lower-level headings focus more\non local information. Additionally, CMM also mod-\nels each heading independently, removing the need\nfor modelling pairwise relationships among head-\nings and enabling more effective document seg-\nmentation. Here, we can divide documents based\non the tree structure instead of relying on page di-\nvisions. This ensures that each segment maintains\nboth local and long-distance relationships, preserv-\ning the long-distance connections that would be\nlost if division were based on page boundaries. As\nCMM does not require the processing of a document\nas a whole, it can be easily scaled to deal with\nlengthy documents. Experimental results show that\nour approach outperforms the previous state-of-the-\nart baseline with only a fraction of running time,\nverifying the scalability of our model as it is ap-\nplicable to documents of any length. Our main\ncontributions are summarised as follows:\n• We introduce a new dataset, ESGDoc, com-\nprising 1,093 ESG annual reports specifically\ndesigned for table of contents extraction.\n\n• We propose a novel framework that pro-\ncesses documents in a construction-modelling-\nmodification manner, allowing for the decou-\npling of each heading, preserving both local\nand long-distance relationships, and incorpo-\nrating structured information.\n• We present a novel graph-based method for\ndocument segmentation and modelling, en-\nabling the retention of both local and long-\ndistance information within each segment.\n2\nRelated Work\nDatasets\nMany datasets have been proposed\nfor document understanding. PubLayNet dataset\n(Zhong et al., 2019b) is a large-scale dataset col-\nlected from PubMed Central Open Access, which\nuses scientific papers in PDF and XML versions for\nautomatic document layout identification and anno-\ntation. Article-regions dataset (Soto and Yoo, 2019)\noffers more consistent and tight-fitting annotations.\nDocBank dataset (Li et al., 2020) leverages the la-\ntex source files and font colour to automatically an-\nnotate a vast number of scientific papers from arXiv.\nDocLayNet dataset (Pfitzmann et al., 2022) extends\nthe scope from scientific papers to other types of\ndocuments. However, these datasets primarily con-\ntain annotations of the type and bounding box of\neach text, such as title, caption, table, and figure,\nbut lack structured information of documents.\nApproaches for Document Understanding\nIn\nterms of methods for document understanding, a\ncommon approach is the fusion of text, visual, and\nlayout features (Xu et al., 2019; Zhang et al., 2021;\nXu et al., 2021a,b; Peng et al., 2022; Li et al., 2022),\nwhere visual features represent images of texts and\nthe document, and layout features comprise bound-\ning box positions of texts. Some methods also\nintroduced additional features. For instance, XY-\nLayoutLM (Gu et al., 2022) incorporates the read-\ning order, VILA (Shen et al., 2022) utilises visual\nlayout group, FormNet (Lee et al., 2022, 2023)\nemploys graph learning and contrastive learning.\nThe aforementioned methods focus on classifying\nindividual parts of the document rather than under-\nstanding the structure of the entire document.\nTable of Contents (ToC) Extraction\nIn addition\nto document understanding, some work has been\nconducted on the extraction of ToC. Early meth-\nods primarily relied on manually designed rules\nto extract the structure of documents (Nambood-\niri and Jain, 2007; Doucet et al., 2011). Tuarob\net al. (2015) designed some features and use Ran-\ndom Forest (Breiman, 2001) and Support Vector\nMachine (Bishop and Nasrabadi, 2006) to predict\nsection headings. Mysore Gopinath et al. (2018)\npropose a system for section titles separation. MTD\n(Hu et al., 2022) represents a more recent approach,\nfusing text, visual, and layout information to detect\nsection headings from scientific papers in the Hi-\nerDoc (Hu et al., 2022) dataset. It also uses GRU\n(Cho et al., 2014) and attention mechanism to clas-\nsify the relationships between headings, generating\nthe tree of ToC. While MTD performs well on Hi-\nerDoc, it requires modelling all headings in the\nentire document simultaneously, which is impracti-\ncal for long documents. To address this limitation,\nwe propose a new framework that decouples the\nrelationships of headings for ToC extraction and\nintroduces more structural information by utilis-\ning font size and reading order, offering a more\npractical solution for long documents.\n3\nDataset Construction\nTo tackle the more challenging task of ToC extrac-\ntion from complex ESG reports, we construct a new\ndataset, ESGDoc, from ResponsibilityReports.com4.\nInitially, we have downloaded 10,639 reports in the\nPDF format. However, only less than 2,000 reports\nhave ToC in their original reports. To facilitate the\ndevelopment of an automated method for ToC ex-\ntraction from ESG reports, we selectively retrain\nreports that already possess a ToC. The existing\nToC serves as the reference label for each ESG re-\nport, while the report with the ToC removed is used\nfor training our framework specifically designed\nfor ToC extraction.\nOur final dataset comprises 1,093 publicly avail-\nable ESG annual reports, sourced from 563 distinct\ncompanies, and spans the period from 2001 to 2022.\nThe reports vary in length, ranging from 4 pages to\n521 pages, with an average of 72 pages. In contrast,\nHierDoc (Hu et al., 2022) has a total of 650 scien-\ntific papers, which have an average of 19 pages in\nlength. We randomly partitioned the dataset into\na training set with 765 reports, a development set\nwith 110 reports, and a test set with 218 reports.\nText content from ESG reports was extracted us-\ning PyMuPDF5 in a format referred to as “block”.\nA block, defined as a text object in the PDF stan-\n4https://www.responsibilityreports.com/\n5https://pymupdf.readthedocs.io/\n\ndard, which is usually a paragraph, can encompass\nmultiple lines of text. We assume that the text\nwithin a text object is coherent and should be inter-\npreted as a cohesive unit. Each block comprises the\nfollowing elements: text content, font, size, colour,\nposition, and id. The id is a unique identifier as-\nsigned to each block to distinguish blocks that con-\ntain identical text content. The position refers to the\nposition of the block within a page in the ESG PDF\nreport, represented by four coordinates that denote\nthe top-left and bottom-right points of the block\nbounding box. Other elements, such as font, size,\nand colour, provide additional information about\nthe text.\n4\nMethodology\nWe propose a framework for ToC extraction based\non the following assumptions:\nAssumption 1 Humans typically read documents\nin a left-to-right, top-to-bottom order, and a higher-\nlevel heading is read before its corresponding sub-\nheading and body text.\nAssumption 2 In a table of contents, the font size\nof a higher-level heading is no smaller than that of\na lower-level heading or body text.\nAssumption 3 In a table of contents, headings of\nthe same hierarchical level share the same font size.\nIn our task, a document is defined as a set of\nblocks. To replicate the reading order of humans,\nwe reorder the blocks from the top-left to the\nbottom-right of the document. We employ the XY-\ncut algorithm (Ha et al., 1995) to sort the blocks.\nThe sorted blocks are denoted as {xi}nb\nn=1, where\n{x<i} precedes xi and {x>i} follows xi. Here, nb\nrepresents the total number of blocks. For each\nblock xi, we define si as its size.\nProblem Setup\nGiven a list of blocks, ToC ex-\ntraction aims to generate a tree structure represent-\ning the table of contents, where each node corre-\nsponds to a specific block x. We introduce a pseudo\nroot node r as the root of the ToC tree.\nWe propose to initially construct a full tree con-\ntaining all the blocks, where the hierarchical rela-\ntion between blocks is simply determined by their\nrespective font sizes. Specifically, when two blocks,\nxi and xj, are read in sequence, if they are close\nto each other and their font sizes si > sj, then xj\nbecomes a child of xi. We then modify the tree by\nremoving or rearranging nodes as necessary. Es-\nsentially, for a node (i.e., a block) xi, we need to\nlearn a function which determines the operation\n(‘Keep’, ‘Delete’, or ‘Move’) to be performed on\nthe node. In order to enable document segmenta-\ntion and capture the contextual information relating\nto the node, our approach involves extracting a sub-\ntree encompassing its neighbourhood including the\nparent, children and siblings, within a range of nd\nhops. Subsequently, we use Graph Attention Net-\nworks (GATs) (Brody et al., 2021; Velickovic et al.,\n2017) to update the node information within the\nsubtree. An overview of our proposed framework\nis illustrated in Figure 2.\nBefore delving into the detail of our proposed\nframework, we first define some notations relating\nto node operations. PA(xi) as the parent node\nof node xi, PR(xi) as the preceding sibling node\nof xi. SU(xi) as the subsequent sibling node of\nxi. We also define PRS(xi) as all the preceding\nsibling nodes of xi.\n4.1\nTree Construction\nWe first construct a complete tree T , consisting\nof all identified blocks using PyMuPDF, based on\nreading order and font sizes. For each node xi, we\nfind a node in its previous nodes xj ∈{x<i} that\nis closest to xi and sj > si. Then xi becomes a\nchild of xj. A detailed algorithm is in Appendix A.\nFollowing the principles outlined in Assumptions 1,\n2 and 3, this approach assumes that the ToC is\ncontained within the tree structure, as shown in\nthe top-left portion of Figure 2. The subsequent\nsteps of our model involve modifying this tree T\nto generate the ToC.\n4.2\nTree Modelling\nIn this section, for a given tree node, we aim to\nlearn a function which takes the node representa-\ntion as input and generates the appropriate opera-\ntion for the node. In what follows, we first describe\nhow we encode the contextual information of a\nnode, and then present how to learn node represen-\ntations.\nNode-Centric Subtree Extraction\nTo effec-\ntively encode the contextual information of a tree\nnode and to avoid processing the whole document\nin one go, we propose to extract a node-centric sub-\ntree, ti, a tree consisting of neighbourhood nodes,\nincluding PR(xi) and SU(xi), of node xi, ex-\ntracted via Breadth First Search (BFS) on xi with\na depth nd. Here, nd is a hyper-parameter. The\nneighbourhood nodes consist of the parent node,\n\nroot\n1.\n3.\n1.1.\n1.2.\n3.1.\n3.2.1.\n3.2.\n4.\n...\n...\n...\nroot\n1.\n3.\n2.\n1.2.\n1.1.\n4.\nroot\n3.\n2.\n3.1.\n3.2.1.\n3.2.\n4.\nroot\n1.\n3.\n2.\n1.2.\n3.1.\n3.2.1.\n1.1.\n3.2.\n4.\n...\n...\n...\nSubtree Segmentation\nTree Modification\n...\nTree Modelling\nSubtree for\nSubtree for\n1.\n3.2.\n3.1\n3.2.1.\n1.\nkeep\ndelete\nkeep\ndelete\nmove\n...\nHeading Node\nBody Node\nNode of a Subtree\nInitial Full Tree\nTree of Table of \nContents\n2.\n...\n1.\n1.1.\n1.2.\n2.\n3.\n3.1.\n3.2.\n3.2.1.\n4.\n1.\n1.1.\n1.2.\n2.\n3.\n3.1.\n3.2.\n3.2.1.\n4.\n...\n...\nReorder (reading order)\nTree Construction\nDocument\nFigure 2: Overview of CMM. Initially, blocks across multiple pages in a document shown in top-left, are reordered\ninto a sequence based on reading order (Top-right). A full tree consisting of all text blocks is constructed based\non reading order and font size (Center-left). Subsequently, for each node, a node-centric subtree is extracted and\nmodelled by a graph neural network (GNN). In the subtree shown in center-right, the first-level heading ‘1.’ can\naccess both long-distance relationships with other first-level headings ‘2.’, ‘3.’, ‘4.’, and local relationships with\nheading ‘1.1’, ‘1.2’, and bodies. In contrast, in the subtree shown in bottom-right, the second-level heading ‘3.2.’\nconcentrates more on local information but also has access to some global information. When modelling with\nGNN, each node is connected with its neighbourhood nodes, including parent, children and siblings. After the\ntree modelling phase, the node-level operations (Keep, Delete, and Move) are predicted. The original tree is then\nmodified according to the node-level operations, resulting in the final Table of Contents (Bottom-left). The nodes\nnumbered and coloured in this figure are for illustrative purposes; some body nodes are omitted for brevity. During\ninference, the model is unaware of whether a node is a heading or non-heading.\nchildren nodes, and the sibling nodes of node xi,\nas shown in the right portion of Figure 2. Apart\nfrom the edges linking parent and child, we have\nadditionally added edges connecting neighbouring\nsibling nodes.\nNode Encoding\nBefore discussing how to update\nnode representations in a subtree, we first encode\neach node (or block) xi into a vector representation.\nWe employ a text encoder, which is a pre-trained\nlanguage model, to encode the text content of xi.\nWe also utilise additional features from xi defined\nas fi. These features include: (1) pdf page number;\n(2) font and font size; (3) colour as RGB; (4) the\nnumber of text lines and length; and (6) the position\nof the bounding box of the block, represented by\nthe coordinates of the top-left and bottom-right\npoints. The representation of xi is derived from\ntext encoder and fi with a Multilayer Perceptron\n(MLP) as follows:\nbi = MLP([TextEncoder(xi), fi])\n(1)\nwhere bi denotes the hidden representation of block\nxi and [., .] denotes concatenation.\nTo simulate the human reading order, we apply\na one-layer bi-directional Gated Recurrent Unit\n(GRU) (Cho et al., 2014) on nodes of the subtree\nwith in-order traversal as follows:\n{vi}|ti| = GRU(ti)\n(2)\nwhere {vi}|ti| denotes all hidden representations of\nthe nodes in ti after GRU encoding.\n\nNode Representation Update in a Subtree\nWe\ntransform each node-centric subtree ti to a graph\nG = (V, E), where the nodes V = {xj ∈ti},\nand the embedding of each node xj is assigned\nas vj. For each node xj, there are three types of\nedges, from its parent, from its children, and from\nits siblings.\nThe edges between the parent/siblings and xi\nmay span across multiple pages, as headings can\nbe widely separated. Such edges can provide long-\ndistance relationship information. On the other\nhand, the edges from children to xi provide lo-\ncalised information about the heading. Thus, xi\nbenefits from learning from both long-distance and\nlocal relationships.\nWe employ Graph Attention Networks (GAT)\nwith nd layers for graph learning, enabling each\nxi to focus on other nodes that are more relevant\nto itself. GAT also uses edge embeddings. In our\nmodel, we define edge features fj,i for edge ej,i\nas follows: (1) the edge type (parent, children, or\nsiblings); (2) size difference sj −si; (3) whether\nxj and xi have the same font or colour; (4) page\ndifference; (5) position difference as the differences\nof the coordinates of the top-left and bottom-right\npoints of the corresponding block bounding boxes.\nWith nodes V = {xi ∈ti}, node embeddings\n{vi}, edge E = {ej,i}, and edge embeddings fj,i,\nthe graph learning is performed as follows:\n{hi}|ti| = GAT(V, E)\n(3)\nwhere {hi}|ti| are the hidden representations of\nnodes {xi}|ti| in the node-centric subtree ti. In\npractice, multiple node-centric subtrees can be\nmerged and represented simultaneously in GPU\nto accelerate training and inference.\n4.3\nTree Modification\nIn this section, we discuss how the model predicts\nand executes modifications to the tree. We define\nthree types of operations for each node:\n1. Delete: This node is predicted as not a heading\nand will be deleted from the tree.\n2. Move: This node is predicted as a low-level\nheading that is a sibling of a high-level head-\ning due to having the same font size in rare\ncases. The node 3.2.1 in Figure 2 is an exam-\nple. This node will be relocated to be a child\nas its preceding sibling as non-heading nodes\nhave already been deleted.\n3. Keep: This node is predicted as a heading and\ndoes not require any operations.\nWe define three scores o[kp]\ni\n, o[de]\ni\nand o[mv]\ni\nto\nrepresent the likelihood that the node xi should be\nkept, deleted or moved. These scores are computed\nas follows:\no[kp]\ni\n= Wkphi + bkp\no[de]\ni\n= Wdehi + bde\no[mv]\ni\n= Wmv[POOL(PRS(hi)), hi] + bmv\n(4)\nwhere POOL(PRS(hi)) denotes a max pooling\nlayer on the representations of preceding siblings\nof xi; [., .] denotes the concatenation; Wkp, Wde,\nWmv, bkp, bde, and bmv are learnable parameters.\nThe score of Keep and Delete is inferred from the\nnode directly, as hi has gathered neighbourhood\ninformation with both long-distance and local rela-\ntionships. The score of Move is inferred from the\nnode and its preceding siblings so that the node can\ncompare itself with its preceding siblings to decide\nwhether it is a sub-heading of preceding siblings.\nThe probabilities of the node operations are com-\nputed with the softmax function as follows:\np[.]\ni =\neo[.]\ni\neo[kp]\ni\n+ eo[de]\ni\n+ eo[mv]\ni\n(5)\nwhere [.] could be [kp], [de] or [mv]. The final\noperation for node xi is determined as follows:\nˆyi = argmax(pi)\n(6)\nwhere each ˆyi could be Keep, Delete, or Move.\nFor each node-centric subtree ti, the model only\npredicts the operation ˆyi for node xi and ignores\nother nodes. With all {ˆyi}nb\ni=1 predicted for nodes\n{xi}nb\ni=1, the original tree T will be modified as\nshown in Algorithm 1, where node deletion is per-\nformed first, followed by node relocation.\nWe assume that all non-heading nodes have al-\nready been deleted during the deletion step. Each\nnode is then checked following the reading order\nwhether it should be moved. Therefore, for a node\nto be moved, we can simply set its preceding sib-\nling as its parent node.\nThe modified tree T ′ represents the final infer-\nence output of our method, which is a ToC.\n4.4\nInference and Training\nFor training the model, we define the ground truth\nlabel yi of operation for each node xi. If a node xi\nis not a heading, then its label is yi = Delete. If\na node xi is a heading, and there is a higher-level\n\nAlgorithm 1: Tree Modification\nInput: A tree T , node operations {ˆyi}nb\ni=1\nX[de] ←{xi ∈T , ˆyi = ‘delete′}\nT ′ = {xi ∈T \\ X[de]}\nReconstruct the tree T ′ with reading order\nand font size.\nforeach xi ∈T ′ do\nif ˆyi = ‘Move’ then\nPA(xi) ←PR(xi) /* Set the\nparent of xi as its\npreceding sibling\n*/\nend\nend\nOutput: The modified tree T ′\nheading in its preceding nodes, then the label is\nyi = Move. Otherwise, the label is yi = Keep.\nThe loss is the cross entropy between ˆyi and yi.\n5\nExperiments\n5.1\nExperimental Setup\nBaselines\nWe use MTD (Hu et al., 2022) as our\nbaseline, which utilises multimodal information\nfrom images, text, and layout. The MTD consists\nof two steps: firstly, classifying and selecting head-\nings from documents with a pre-trained language\nmodel, and secondly, modelling via GRU (Cho\net al., 2014) and decoding heading relations into a\nhierarchical tree.\nDataset\nWe evaluate CMM on the following ToC\nextraction datasets: (1) ESGDoc dataset consists of\n1,093 ESG annual report documents, with 765, 110,\nand 218 in the train, development, and test sets, re-\nspectively. In our experiments, MTD encounters\nout-of-memory issues when processing some long\ndocuments in ESGDoc as it needs to model the entire\ndocument as a whole. Therefore, we curated a sub-\ndataset, denoted as ESGDoc (Partial), which con-\nsists of documents from ESGDoc that are less than\n50 pages in length. This sub-dataset contains 274,\n40, and 78 documents in the train, development,\nand test sets, respectively. (2) HierDoc dataset (Hu\net al., 2022) contains 650 scientific papers with\n350, 300 in the train, and test sets, respectively.\nGiven that the extracted text from HierDoc does\nnot include font size, we extract font size from PDF\ndirectly using PyMuPDF.\nEvaluation Metrics\nWe evaluate our method in\ntwo aspects: heading detection (HD) and the tree\nof Toc. HD is evaluated using the F1-score, which\nmeasures the effectiveness of our method in identi-\nfying headings from the document, which primar-\nily relates to construction and modelling steps, as\nit does not measure the hierarchical structure of\nToC. For Toc, we use tree-edit-distance similar-\nity (TEDS) (Zhong et al., 2019a; Hu et al., 2022),\nwhich compares the similarity between two trees\nbased on their sizes and the tree-edit-distance (Paw-\nlik and Augsten, 2016) between them:\nTEDS(Tp, Tg) = 1 −TreeEditDist(Tp, Tg)\nmax(|Tp|, |Tg|)\n(7)\nFor each document, a TEDS is computed between\nthe predicted tree Tp and the ground-truth tree Tg.\nThe final TEDS is the average of the TEDSs of all\ndocuments.\nImplementation Detail\nWe use RoBERTa-base\n(Liu et al., 2019) as the text encoder model. We\nset the BFS depth nd = 2, and the hidden size\nof b, v, and h to 128. Our model is trained on\na NVIDIA A100 80G GPU using the Adam op-\ntimizer (Kingma and Ba, 2015) with a batch size\n32. We use a learning rate of 1e-5 for pretrained\nparameters, and a learning rate of 1e-3 for ran-\ndomly initialised parameters. In some instances,\nthe font size may be automatically adjusted slightly\ndepending on the volume of text to ensure that texts\nthat have varying fonts do not share the same font\nsizes. Texts with very small sizes are automatically\ndeleted during modification.\n5.2\nAssumption Violation Statistics\nDataset\nA1\nA2\nA3\nAny\nHierDoc\n0.0\n0.5\n4.1\n4.6\nESGDoc\n0.8\n1.7\n8.7\n10.8\nTable 1: The percentage (%) that each assumption is\nviolated. Any denotes the percentage that the heading\nviolates at least one assumption.\nOur method is based on Assumption 1, 2, and\n3. However, these assumptions do not always hold.\nThis section presents statistics on the percentage\nof headings that violate these assumptions by auto-\nmatically examining consecutive blocks along the\nsorted blocks {xi}nb\nn=1 with their labels. As shown\nin Table 1, there are 4.6% and 10.8% of headings\nthat contravene these assumptions in HierDoc and\nESGDoc, respectively. Our current method is unable\n\nto process these non-compliant headings. Despite\nthese limitations, our method still achieves good\nperformance, as will be detailed in Section 5.3.\n5.3\nOverall Results\nTable 2 presents the overall TEDS results on Hier-\nDoc and ESGDoc. Both models demonstrate good\nperformance on HierDoc with CMM slightly outper-\nforming MTD. However, we observe significant\nperformance drop on ESGDoc, indicating the chal-\nlenge of processing complex ESG reports com-\npared to scientific papers. MTD exhibits a notably\nlow TEDS score in ESGDoc (Full) due to the out-\nof-memory issue it encountered when processing\ncertain lengthy documents. To address this, we\nexclude documents longer than 50 pages, result-\ning in MTD achieving a TEDS score of 26.9% on\nESGDoc (Partial). Nevertheless, our approach CMM\noutperforms MTD by a substantial margin. The\nHD F1-score of our method outperforming MTD\nby 12.8% on ESGDocPartial also demonstrates the\neffectiveness of construction and modelling steps.\nDue to the violation of assumptions as discussed\nin Section 5.2, the improvement of our model over\nMTD in TOC is less pronounced compared to HD.\nModel\nHierDoc\nESGDoc F.\nESGDoc P.\nHD\nToC\nHD\nToC\nHD\nToC\nMTD\n96.1\n87.2\n12.7\n12.8\n40.4\n26.9\nCMM (Ours)\n97.0\n88.1\n55.6\n33.2\n53.2\n30.0\nTable 2: Heading detection (HD) in F1-score and ToC\nin TEDS (%) of MTD and CMM on HierDoc, ESGDocFull\n(F.), and ESGDocPartial (P.).\nOur model’s performance on ESGDoc (Full)\ndemonstrates its scalability in handling ESG re-\nports with diverse structures and significantly\nlengthy text. The comparable TEDS scores be-\ntween CMM and MTD on HierDoc can be potentially\nattributed to the nature of scientific papers. For\ninstance, headings in scientific papers such as “5\nExperiments” and “5.1 Experimental Setup”, pro-\nvide explicit indication of their hierarchical rela-\ntionships within the headings themselves. The pres-\nence of section numbering such as “5” and “5.1”\nmakes it easier to determine their hierarchical level\nsuch as the latter being a sub-heading of the former.\nOur method introduces hierarchical information\nvia the reading order and font sizes, and learns tree\nnode representations by simultaneously consider-\ning long-distance and local relationships. However,\nif the hierarchical information is already contained\nin the headings, our method may not offer many\nadditional hierarchical insights.\n5.4\nRun-Time Comparison\nModel\nHierDoc\nESGDoc Partial\nTime\nRatio\nTime\nRatio\nTraining\nMTD\n2420.6\n4.6x\n513.5\n2.1x\nCMM (Ours)\n525.4\n1.0x\n241.4\n1.0x\nInference\nMTD\n16.1\n4.2x\n2.7\n1.3x\nCMM (Ours)\n3.8\n1.0x\n2.1\n1.0x\nTable 3: The GPU training and inference time in min-\nutes for MTD and CMM on HierDoc and ESGDoc (Partial).\nTable 3 presents the run-time comparison be-\ntween MTD and CMM on HierDoc and ESGDoc (Par-\ntial). MTD consumes 4.6x and 2.1x more time for\ntraining and 4.2x and 1.3x more time for inference\non HierDoc and ESGDoc, respectively. Different\nfrom MTD, CMM does not need to model all possible\npairs of headings. Instead, it only predicts whether\na node should be deleted or relocated, thereby re-\nducing the computational time.\nCompared to MTD, our model exhibits higher\nefficiency on HierDoc compared to ESGDoc. This\ncould be attributed to the larger number of edges in\nthe graphs constructed from node-centric subtrees\nin our method for ESGDoc. ESG annual reports of-\nten contain numerous small text blocks, such as\n“$5,300m”, “14,000”, and “3,947 jobs”, as illus-\ntrated in the first example of Figure 1. Our method\ntreats these individual texts as separate nodes in\nboth the trees and graphs, leading to a significant\nincrease in the number of edges in ESGDoc com-\npared to HierDoc.\n5.5\nAblation Study\nTable 4 illustrates how different components in CMM\ncontribute to performance:\nw/ page-based division\nCMM divides the docu-\nment into subtrees based on the tree structure. We\nsubstitute the tree-based division with a page-based\none. Initially, the document is divided using a\nwindow of 6 pages with a 2-page overlap. All\nother steps remain unchanged, including the mod-\nelling of node-centric subtrees. The choice of the\n\nModel\nHierDoc\nESGDoc\nHD\nToC\nHD\nToC\nCMM\n97.0\n88.1\n55.6\n33.2\nw/ page division\n96.7\n87.8\n52.3\n30.1\nw/o GRU\n96.8\n87.7\n50.8\n30.5\nw/o GNN\n96.4\n87.4\n44.0\n24.9\nTable 4: Ablation Study of CMM on HierDoc and ESGDoc\nwith heading detection (HD) and ToC results reported\nin F1-score and TEDS (%), respectively.\npage number for division is made to keep a simi-\nlar GPU memory consumption. This results in a\nperformance drop of 0.3% on HierDoc and 3.1%\non ESGDoc. The page-based division impedes long-\ndistance interaction, resulting in a lack of connec-\ntion between high-level headings.\nw/o GRU\nWe exclude the GRU in Eq. (2) and di-\nrectly set vi = bi. The results show a performance\ndrop of 0.4% on HierDoc and 2.7% on ESGDoc.\nw/o GNN\nWe exclude the GNN in Eq. (3) and\ndirectly set hi = vi. This results in a more signif-\nicant performance drop of 0.7% on HierDoc and\n8.3% on ESGDoc. With GNN, each heading can\ngather information from other long-distance and\nlocal body nodes effectively and simultaneously.\nAs shown in Table 4, there is a larger perfor-\nmance drop on ESGDoc compared to HierDoc. This\ncan be attributed to the same reason outlined in Sec-\ntion 5.3: inferring hierarchical relationships from\nheadings themselves is easier in HierDoc than in\nESGDoc. Therefore, the removal of components\nthat introduce hierarchical relationships does not\nsignificantly harm the performance on HierDoc.\nFigure 3 demonstrates how performance varies\nwith different values of nd, the depth of neighbour-\nhood during BFS for constructing node-centric sub-\ntrees. Due to the nature of the data, there is limited\nimprovement observed on HierDoc as nd increases.\nNotably, there is a substantial increase in TEDS\nfrom nd = 1 to nd = 2, but the improvement be-\ncomes negligible when nd > 2. Therefore, we\nselect nd = 2 considering the trade-off between\nperformance and efficiency.\nThe primary factors contributing to the negligi-\nble improvement nd > 2 may include: (1) A signifi-\ncant portion of documents exhibit a linear structure.\nTo illustrate, when nd = 2, it corresponds to a hier-\narchical arrangement featuring primary headings,\n87.5\n88.0\n88.5\n1\n2\n3\n4\nHierDoc\n30.0\n31.0\n32.0\n33.0\n34.0\n1\n2\n3\n4\nESGDoc\nFigure 3: Study of BFS depth nd of CMM on HierDoc\nand ESGDoc in TEDS.\nsecondary headings, and main body content in a\nthree-tier configuration. (2) The constructed initial\ntree inherently positions related headings in close\nproximity according to their semantic relationships,\nwithout regard for their relative page placement.\nAs a consequence, a heading’s most relevant con-\ntextual information predominantly emerges from\nits immediate neighbours within the tree. For ex-\nample, when examining heading 1.2., information\nfrom heading 1. (nd = 1) offers a comprehensive\noverview of the encompassing chapter. Simultane-\nously, heading 2. (nd = 2) can provide supplemen-\ntary insights, such as affirming that heading 1.2. is\nnested within the domain of heading 1., rather than\nheading 2. However, delving into deeper levels\nmay become redundant. For example, a heading\nlike 2.2. (nd = 3), situated more distantly in the\nsemantic space, would not notably enhance the un-\nderstanding of heading 1.1.\nSome case studies illustrating the ToC extrac-\ntion results of CMM on ESGDoc are presented in Ap-\npendix C.\n6\nConclusion and Future Work\nIn this paper, we have constructed a new dataset,\nESGDoc, and proposed a novel framework, CMM, for\ntable of contents extraction. Our pipeline, con-\nsisting of tree construction, node-centric subtree\nmodelling, and tree modification stages, effectively\naddresses the challenges posed by the diverse struc-\ntures and lengthy nature of documents in ESGDoc.\nThe methodology of representing a document as an\ninitial full tree, and subsequently predicting node\noperations for tree modification, and further lever-\naging the tree structure for document segmentation,\ncan provide valuable insights for other document\nanalysis tasks.\n\nAcknowledgements\nThis work was funded by the the UK Engineering\nand Physical Sciences Research Council (grant no.\nEP/T017112/1, EP/T017112/2, EP/V048597/1).\nYH is supported by a Turing AI Fellowship funded\nby the UK Research and Innovation (grant no.\nEP/V020579/1, EP/V020579/2).\nLimitations\nOur method exhibits two primary limitations.\nFirstly, it relies on the extraction of font size. For\ndocuments in photographed or scanned forms, an\nadditional step is required to obtain the font size\nbefore applying our method. However, with the\nprevailing trend of storing documents in electronic\nformats, this limitation is expected to diminish in\nsignificance.\nSecondly, our method is grounded in Assump-\ntions 1, 2, and 3. As discussed in Section 5.2, our\ncurrent method encounters difficulties in scenarios\nwhere these assumptions are not met. Some ex-\namples of such assumption violations are provided\nin Appendix B. However, it is worth noting that\nthese assumption violations primarily impact the\nmodification step in our construction-modelling-\nmodification approach. If we focus solely on the\nconstruction and modelling steps, our method still\noutperforms MTD in heading detection. There-\nfore, future efforts to enhance the modification\nstep, which is susceptible to assumption violations,\ncould hold promise for improving the overall per-\nformance of our approach.\nEthics Statement\nThe ESG annual reports in ESGDoc are indepen-\ndently published by the companies and are publicly\naccessible. ResponsibilityReports.com6 compiles\nthese ESG annual reports, which are also accessi-\nble directly on the respective companies’ websites.\nThere are also other websites such as CSRWIRE7\nand sustainability-reports.com8 serve as reposito-\nries for these reports. Because these reports are\npublicly available, the use of such data for research\npurpose is not anticipated to present any ethical\nconcerns.\n6https://www.responsibilityreports.com/\n7https://www.csrwire.com/reports\n8https://www.sustainability-reports.com/\nReferences\nChristopher M. Bishop and Nasser M. Nasrabadi. 2006.\nPattern recognition and machine learning. J. Elec-\ntronic Imaging, 16:049901.\nL. Breiman. 2001. Random forests. Machine Learning,\n45:5–32.\nShaked Brody, Uri Alon, and Eran Yahav. 2021. How\nattentive are graph attention networks?\nArXiv,\nabs/2105.14491.\nKyunghyun Cho, Bart van Merriënboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014.\nLearning\nphrase representations using RNN encoder–decoder\nfor statistical machine translation. In Proceedings of\nthe 2014 Conference on Empirical Methods in Natu-\nral Language Processing, pages 1724–1734, Doha,\nQatar. Association for Computational Linguistics.\nAntoine Doucet, Gabriella Kazai, Bodin Dresevic, Alek-\nsandar Uzelac, Bogdan Radakovic, and Nikola Todic.\n2011. Setting up a competition framework for the\nevaluation of structure extraction from ocr-ed books.\nInternational Journal on Document Analysis and\nRecognition, 14:45–52.\nZhangxuan Gu, Changhua Meng, Ke Wang, Jun Lan,\nWeiqiang Wang, Ming Gu, and Liqing Zhang. 2022.\nXylayoutlm: Towards layout-aware multimodal net-\nworks for visually-rich document understanding.\n2022 IEEE/CVF Conference on Computer Vision and\nPattern Recognition, pages 4573–4582.\nJaekyu Ha, Robert M Haralick, and Ihsin T Phillips.\n1995. Recursive xy cut using bounding boxes of\nconnected components. In Proceedings of 3rd In-\nternational Conference on Document Analysis and\nRecognition, volume 2, pages 952–955. IEEE.\nPengfei Hu, Zhenrong Zhang, Jianshu Zhang, Jun Du,\nand Jiajia Wu. 2022. Multimodal tree decoder for ta-\nble of contents extraction in document images. 2022\n26th International Conference on Pattern Recogni-\ntion, pages 1756–1762.\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In 3rd Interna-\ntional Conference on Learning Representations.\nChen-Yu Lee, Chun-Liang Li, Timothy Dozat, Vincent\nPerot, Guolong Su, Nan Hua, Joshua Ainslie, Ren-\nshen Wang, Yasuhisa Fujii, and Tomas Pfister. 2022.\nFormNet: Structural encoding beyond sequential\nmodeling in form document information extraction.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 3735–3754, Dublin, Ireland.\nAssociation for Computational Linguistics.\nChen-Yu Lee, Chun-Liang Li, Hao Zhang, Timothy\nDozat, Vincent Perot, Guolong Su, Xiang Zhang,\nKihyuk Sohn, Nikolay Glushnev, Renshen Wang,\n\nJoshua Ainslie, Shangbang Long, Siyang Qin, Ya-\nsuhisa Fujii, Nan Hua, and Tomas Pfister. 2023.\nFormNetV2: Multimodal graph contrastive learn-\ning for form document information extraction. In\nProceedings of the 61st Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 9011–9026, Toronto, Canada.\nAssociation for Computational Linguistics.\nChenxia Li, Ruoyu Guo, Jun Zhou, Mengtao An, Yun-\ning Du, Lingfeng Zhu, Yi Liu, Xiaoguang Hu, and\nDianhai Yu. 2022. Pp-structurev2: A stronger docu-\nment analysis system. ArXiv, abs/2210.05391.\nMinghao Li, Yiheng Xu, Lei Cui, Shaohan Huang, Furu\nWei, Zhoujun Li, and Ming Zhou. 2020. DocBank:\nA benchmark dataset for document layout analy-\nsis. In Proceedings of the 28th International Confer-\nence on Computational Linguistics, pages 949–960,\nBarcelona, Spain (Online). International Committee\non Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nAbhijith Athreya Mysore Gopinath, Shomir Wilson, and\nNorman Sadeh. 2018. Supervised and unsupervised\nmethods for robust separation of section titles and\nprose text in web documents. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing, pages 850–855, Brussels, Bel-\ngium. Association for Computational Linguistics.\nAnoop M. Namboodiri and Anil K. Jain. 2007. Doc-\nument Structure and Layout Analysis, pages 29–48.\nSpringer London, London.\nMateusz Pawlik and Nikolaus Augsten. 2016. Tree edit\ndistance: Robust and memory-efficient. Information\nSystems, 56:157–173.\nQiming Peng, Yinxu Pan, Wenjin Wang, Bin Luo,\nZhenyu Zhang, Zhengjie Huang, Yuhui Cao, Wei-\nchong Yin, Yongfeng Chen, Yin Zhang, Shikun Feng,\nYu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2022.\nERNIE-layout: Layout knowledge enhanced pre-\ntraining for visually-rich document understanding.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022, pages 3744–3756, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nBirgit Pfitzmann, Christoph Auer, Michele Dolfi,\nAhmed S. Nassar, and Peter Staar. 2022. Doclaynet:\nA large human-annotated dataset for document-\nlayout segmentation.\nIn Proceedings of the 28th\nACM SIGKDD Conference on Knowledge Discov-\nery and Data Mining, KDD ’22, page 3743–3751,\nNew York, NY, USA. Association for Computing\nMachinery.\nZejiang Shen, Kyle Lo, Lucy Lu Wang, Bailey Kuehl,\nDaniel S. Weld, and Doug Downey. 2022. VILA: Im-\nproving structured content extraction from scientific\nPDFs using visual layout groups. Transactions of the\nAssociation for Computational Linguistics, 10:376–\n392.\nCarlos Soto and Shinjae Yoo. 2019. Visual detection\nwith context for document layout analysis. In Pro-\nceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th In-\nternational Joint Conference on Natural Language\nProcessing, pages 3464–3470, Hong Kong, China.\nAssociation for Computational Linguistics.\nSuppawong Tuarob, Prasenjit Mitra, and C. Lee Giles.\n2015. A hybrid approach to discover semantic hier-\narchical sections in scholarly documents. 2015 13th\nInternational Conference on Document Analysis and\nRecognition, pages 1081–1085.\nPetar Velickovic, Guillem Cucurull, Arantxa Casanova,\nAdriana Romero, Pietro Lio’, and Yoshua Ben-\ngio. 2017.\nGraph attention networks.\nArXiv,\nabs/1710.10903.\nYang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu\nWei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha\nZhang, Wanxiang Che, Min Zhang, and Lidong Zhou.\n2021a. LayoutLMv2: Multi-modal pre-training for\nvisually-rich document understanding. In Proceed-\nings of the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 2579–2591, Online.\nAssociation for Computational Linguistics.\nYiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu\nWei, and Ming Zhou. 2019. Layoutlm: Pre-training\nof text and layout for document image understanding.\nProceedings of the 26th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining.\nYiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yi-\njuan Lu, Dinei A. F. Florêncio, Cha Zhang, and Furu\nWei. 2021b. Layoutxlm: Multimodal pre-training for\nmultilingual visually-rich document understanding.\nArXiv, abs/2104.08836.\nPeng Zhang, Can Li, Liang Qiao, Zhanzhan Cheng,\nShiliang Pu, Yi Niu, and Fei Wu. 2021. Vsr: A\nunified framework for document layout analysis\ncombining vision, semantics and relations. ArXiv,\nabs/2105.06220.\nXu Zhong, Elaheh Shafieibavani, and Antonio Jimeno-\nYepes. 2019a. Image-based table recognition: Data,\nmodel, and evaluation. ArXiv, abs/1911.10683.\nXu Zhong, Jianbin Tang, and Antonio Jimeno-Yepes.\n2019b. Publaynet: Largest dataset ever for document\nlayout analysis. 2019 International Conference on\nDocument Analysis and Recognition, pages 1015–\n1022.\n\nAppendix\nA\nAlgorithm of Building an Initial Tree\nAlgorithm 2 describes how to build an initial full\ntree from a document.\nAlgorithm 2: Building a Tree based on\nReading Order and Font Sizes\nInput: Root node r, all blocks {xi}nb\ni=1 with\ntheir corresponding sizes {si}nb\ni=1.\nfor i = 1 to nb do\nj ←i −1\nwhile j >= 0 do\nif j = 0 then\nPA(xi) ←r /* Set r as the\nparent node of xi\n*/\nbreak\nelse if sj > si then\nPA(xi) ←xj /* Set xj as\nthe parent node of xi\n*/\nbreak\nend\nj ←j −1\nend\nend\nOutput: a tree T with root node r.\nB\nAssumption Violation Examples\nFor Assumption 1, upon manually inspecting some\nsamples, we found that errors in these particular\ncases were linked to the errors in the XY-cut al-\ngorithm (Ha et al., 1995), resulting in an incorrect\narrangement of text blocks.\nFigure A1 presents two examples where As-\nsumption 2 is not satisfied. In the first example,\nthe term “The way we work” serve as the parent-\nheading of “Corporate governance” which is a sub-\nheading, but featuring a smaller font size. Despite\nthe smaller font size of \"The way we work\", it is\nclearly delineated from the sub-headings below by\ntwo green horizontal lines. However, our method\nfocuses solely on text, neglecting visual cues such\nas these lines. In the second example, “COMMU-\nNITY OUTREACH” is a sub-heading under “SO-\nCIAL RESPONSIBILITY”, but is has a larger font\nsize, as this page emphasises community achieve-\nments.\nFigure A2 presents two instances where Assump-\ntion 3 is violated. In the first example, “indirect\neconomic impacts” and “Transmission System In-\nvestments” are headings situated at the same hi-\nerarchical level but have distinct font sizes. This\ndissimilarity could potentially lead to confusion\nfor human readers, questioning whether these two\nheadings should be placed within the same hierar-\nchical level. In the second example, “Sustainability\nFund purchases” and “Spend by solution type” are\nalso headings at the same level, with subtly differ-\nent font sizes, 11 and 10, respectively. While this\ndifference may go unnoticed by humans, it does\nimpact the performance of our method.\nC\nCase Study\nFigure A3 and Figure A4 illustrate a favourable\nscenario and an unfavorable one for CMM within\nthe context of ESGDoc. The favourable case in Fig-\nure A3 demonstrates the capability of our model\nto handle lengthy document, where it generates a\nhigh quality tree structure.\nConversely, Figure A4 represents a challeng-\ning scenario where our model encounters diffi-\nculties across multiple nodes. Figure A5 further\nelaborated on this issue, showcasing four example\npages of the unfavorable case illustrated in Fig-\nure A4. On the top-left page, CMM incorrectly re-\ntain the non-heading “ABOUT BRANDYWINE”.\nThis is a challenging case as “ABOUT BRANDY-\nWINE” is prominently displayed in a large font\nat the top-left corner of the page, making it diffi-\ncult to identify as a non-heading. A similar situ-\nation occurs on the top-right page, where CMM in-\ncorrectly keeps the non-heading “ENVIRONMEN-\nTAL PROGRESS”. In this instance, “ENVIRON-\nMENTAL PROGRESS” is enlarged to emphasise\nthe company’s achievements.\nFor the bottom two pages in Figure A5, CMM\nmight encounter confusion between headings with\ncoloured lead-in sentences.\nIn the bottom-left\npage, “MANAGING CLIMATE RISK” functions\nas a heading and follows a pattern similar to other\nlead-in sentences such as “GOVERNANCE” and\n“STRATEGY AND RISK MANAGEMENT”. They\ntypically begin with a large, colored sentence fol-\nlowed by a paragraph.\nThe bottom-right page\npresents a similar challenge. “OUR TENANTS”\nand “VALUED PARTNERSHIPS” share a similar\npattern, with the former being a heading, whereas\nthe latter not. The determination of “MANAGING\nCLIMATE RISK” and “OUR EMPLOYEES” as\nheadings is primarily based on their position and\n\nFigure A1: Two examples in ESGDoc where Assumption 2 is violated, one in portrait and the other in landscape\norientation.\nFigure A2: Two examples in ESGDoc where Assumption 3 is violated, one in portrait and the other in landscape\norientation.\ncolour. However, it is worth noting that CMM does\nnot use visual information, making it difficult for\nthe model to handle such scenarios. Future work\ncould explore the integration of visual information\nto enhance the model’s performance in handling\nthese situations.\n\nroot\nForeword from the Chief Executive Officer\nAbout this report\nStrategy and Governance\nProfile of BayWa\nSustainability approach of BayWa\nBinding values\nGood Corporate Governance\nCompliance and anti-corruption\nDialogue with stakeholders\nProcurement\nValue chain overview\nProtecting human rights across the supply chain\nEnvironment and Climate\nEnvironmental management: Binding values\nEnergy consumption and greenhouse gas emissions\nWaste and waste water\nTransport and logistics\nEmployees\nHuman resources strategy\nOccupational health and safety\nQuality of Life\nProduct responsibility\nBayWa Foundation and sponsorships\nBayWa’s sustainability objectives\nAssurance Statement\nGRI Content Index\nImprint\nDiversity and equal opportunity\nTraining and professional development\nFavourable Case (TEDS=93.3):\nGround-truth ToC Tree\nroot\nForeword from the Chief Executive Officer\nStrategy and Governance\nProfile of BayWa\nSustainability approach of BayWa\nBinding values\nGood Corporate Governance\nCompliance and anti-corruption\nDialogue with stakeholders\nProcurement\nValue chain overview\nProtecting human rights across the supply chain\nEnvironment and Climate\nEnvironmental management: Binding values\nEnergy consumption and greenhouse gas emissions\nWaste and waste water\nTransport and logistics\nEmployees\nHuman resources strategy\nOccupational health and safety\nQuality of Life\nProduct responsibility\nBayWa’s sustainability objectives\nAssurance Statement\nGRI Content Index\nImprint\nDiversity and equal opportunity\nTraining and professional development\nPredicted ToC Tree\nFigure A3: A favourable case for CMM on ESGDoc. Blocks highlighted in red represent incorrect predictions.\n\nroot\nA MESSAGE FROM OUR CEO\nAN ONGOING COMMITMENT\nESG LEADERSHIP AND RECOGNITION\nBUILDING CERTIFICATIONS\nUN SUSTAINABLE DEVELOPMENT GOALS\nMANAGING CLIMATE RISK\nENERGY EFFICIENCY\nWASTE REDUCTION\nWATER MANAGEMENT\nPRIORITIZING HEALTH AND WELLBEING\nOUR TENANTS\nQUALITY\nOUR EMPLOYEES\nESG GOVERNANCE\nEXECUTIVE TEAM\nSASB DISCLOSURES\nCOMMUNITY IMPACT\nDISCLOSURES\nUnfavourable Case (TEDS=17.4):\nGround-truth ToC Tree\nTHE BRANDYWINE DIFFERENCE\nINNOVATION\nINTEGRITY\nroot\nA MESSAGE FROM OUR CEO\nQUALITY\nAPPENDICES\nDEMOGRAPHICS\nEXECUTIVE TEAM\nPredicted ToC Tree\nTHE BRANDYWINE DIFFERENCE\nINNOVATION\nBOARD OF TRUSTEES\nABOUT BRANDYWINE\nENVIRONMENTAL PROGRESS\nINTEGRITY\nFigure A4: An unfavorable case for CMM on ESGDoc. Blocks highlighted in red represent incorrect predictions.\nFigure A5: Four example pages of the unfavorable case highlighted in Figure A4. CMM preserves non-headings in\nthe top two pages, while deleting headings in the bottom two pages.",
    "pdf_filename": "A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports.pdf"
}